import json
import os
from Hits import generate_fun
from parse_modified_ranges import reconstruct_code
from extract_functions import preprocessor_fun
from findComparison import from_two_path_get_closest_pairs
import re

import re


def extract_modified_files(patch_text):
    """
    Extract the list of modified files from a git patch text.

    Args:
        patch_text (str): The git patch text to parse.

    Returns:
        list: A list of modified file paths.
    """
    # Pattern to match the diff --git lines which show file changes
    pattern = re.compile(r'^diff --git a/(.*?) b/(.*?)$', re.MULTILINE)

    # Find all matches in the patch text
    matches = pattern.findall(patch_text)

    # Extract the 'b/' side filenames (after modification)
    modified_files = [b_file for a_file, b_file in matches]

    return modified_files


def find_all_files(path):
    file_list = []
    for root, dirs, files in os.walk(path):
        for name in files:
            if not name.endswith('.py'):
                continue
            file_list.append(os.path.join(root, name))
    return file_list


current_file_path = os.path.dirname(os.path.abspath(__file__))

patch_file_root_path = os.path.join(current_file_path, "data", r'PatchAnalyze')
patch_file_path = os.path.join(patch_file_root_path, 'patch_file')
vul_file_path = os.path.join(patch_file_root_path, 'vul_file')

patch_file_dir = os.path.join(current_file_path, "data", "patch")
lsh_max_similarity_res_path = os.path.join(current_file_path, "data", "lsh_pairs")


def write_lsh_max_similarity_res(commit_hash, com_name, patch_closest_pairs, vul_closest_pairs):
    if not patch_closest_pairs and not vul_closest_pairs:
        return

    file_path = os.path.join(lsh_max_similarity_res_path, commit_hash, com_name)

    folder_path = os.path.dirname(file_path)
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)

    write_cont = {}
    write_cont["patch_closest_pairs"] = patch_closest_pairs
    write_cont["vul_closest_pairs"] = vul_closest_pairs
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(write_cont, f, indent=4)


def analyze_results(patch_json, root_directory, commit_hash=None):
    with open(patch_json, "r", encoding="utf-8") as f:
        patch_raw = json.load(f)
    patch_data = reconstruct_code(patch_raw)

    file_list = []
    file_mapping = {}
    # if "all_files" in os.listdir(root_directory):
    #     root_file_list = json.load(open(os.path.join(root_directory,"all_files"), "r",encoding="utf-8"))
    # else:
    root_file_list = find_all_files(root_directory)
    # with open(os.path.join(root_directory,"all_files"), "w", encoding="utf-8") as f:
    #     json.dump(root_file_list, f, indent=4)
    all_file_set = set()
    _patch_path = os.path.join(patch_file_dir, commit_hash)
    modified_file_list = []
    if os.path.exists(_patch_path):
        with open(_patch_path, "r", encoding="utf-8", errors="ignore") as f:
            modified_file_list = extract_modified_files(f.read())
            for _file in modified_file_list:
                if _file.startswith(("test/", "tests/")):
                    continue
                if len(_file.split("/")) > 3:
                    all_file_set.add(os.sep.join(_file.split("/")[-2:]))
                else:
                    all_file_set.add(os.sep.join(_file.split("/")))

    commit_patch_file_path = os.path.join(patch_file_path, commit_hash)
    commit_vul_file_path = os.path.join(vul_file_path, commit_hash)

    commit_patch_file_list = find_all_files(commit_patch_file_path)
    commit_vul_file_list = find_all_files(commit_vul_file_path)

    for _file in commit_patch_file_list:
        all_file_set.add(os.sep.join((_file.split(os.sep)[-2:])))
    for _file in commit_vul_file_list:
        all_file_set.add(os.sep.join((_file.split(os.sep)[-2:])))

    for _file in root_file_list:
        if os.sep.join((_file.split(os.sep)[-2:])) in all_file_set:
            file_list.append(_file)

    patch_closest_pairs = from_two_path_get_closest_pairs(commit_patch_file_list, root_file_list)
    vul_closest_pairs = from_two_path_get_closest_pairs(commit_vul_file_list, root_file_list)

    write_lsh_max_similarity_res(commit_hash, root_directory.split(os.sep)[-1], patch_closest_pairs, vul_closest_pairs)
    for patch_closest_file_list in patch_closest_pairs:
        name = os.path.relpath(patch_closest_file_list[1][0], commit_patch_file_path).replace(os.sep, '/')
        file_list.append(patch_closest_file_list[1][1])
        file_mapping[name] = patch_closest_file_list[1][1]
    for vul_closest_file_list in vul_closest_pairs:
        name = os.path.relpath(vul_closest_file_list[1][0], commit_patch_file_path).replace(os.sep, '/')
        file_list.append(vul_closest_file_list[1][1])
        file_mapping[name] = vul_closest_file_list[1][1]

    # file_list = []
    # file_mapping = {}
    all_pyfile_list = find_all_files(root_directory)
    for relative_path in patch_data.keys():
        for file_name in all_pyfile_list:
            relative_path_list = relative_path.split('/')
            if len(relative_path_list) > 4:
                _relative_path = relative_path_list[-3:]
            elif len(relative_path_list) > 1:
                _relative_path = relative_path_list[-2:]
            elif len(relative_path_list) == 1:
                _relative_path = relative_path_list[0]

            _relative_path = os.sep.join(_relative_path)
            if file_name.endswith(_relative_path):
                file_list.append(file_name)
                file_mapping[relative_path] = file_name
    #
    file_list = list(set(file_list))
    # if file_list:
    #     return {}, file_list
    pre_results = preprocessor_fun(file_list, root_directory)

    pre_mapping = {}
    for item in pre_results:
        name_str = item.get('name', '')
        if "##" not in name_str:
            continue
        func_name, remainder = name_str.split("##", 1)
        parts = remainder.split("@@")
        file_name = parts[-1] if parts else ""
        pre_mapping[(func_name, file_name)] = item.get('details')

    results = {}
    for relative_path, info in patch_data.items():
        if relative_path not in file_mapping:
            continue
        full_file_name = file_mapping[relative_path]

        folder = os.path.basename(os.path.dirname(full_file_name))
        file_base = os.path.basename(full_file_name)
        out_set = set()
        patch_ids = set()
        for ent in info.get("code", []):
            name = ent.get("name")
            patch_ids.add(name)
            out_set.add(name)

        full_path = full_file_name
        if os.path.isfile(full_path):
            try:
                hits_list = generate_fun(full_path)
            except Exception as e:
                print(str(e))
                continue
            for element in hits_list:
                segments = element.split("\\")
                if not segments:
                    continue
                last_part = segments[-1]
                parts = last_part.split('.')
                if len(parts) < 2:
                    identifier = parts[0]
                else:
                    if parts[1] == "py":
                        hierarchy = parts[2:]
                    else:
                        hierarchy = parts[1:]
                    identifier = ".".join(hierarchy) if hierarchy else parts[0]
                main_id = identifier.split('.')[0]
                if main_id in patch_ids:
                    continue
                out_set.add(identifier)

        formatted_entries = []
        for ident in sorted(out_set):
            formatted_name = f"{ident}##{folder}@@{file_base}"
            if "##" in formatted_name and "@@" in formatted_name:
                func_name = formatted_name.split("##")[0]
                if "." in func_name:
                    func_name = func_name.split(".")[-1]
                file_name = formatted_name.split("@@")[-1]
                details = pre_mapping.get((func_name, file_name))
                if details:
                    entry = {"name": formatted_name, "details": details}
                else:
                    entry = {"name": formatted_name, "details": ""}
            else:
                entry = {"name": formatted_name}
            formatted_entries.append(entry)

        results[relative_path] = formatted_entries
    return results, file_list


if __name__ == "__main__":
    patch_json = os.path.join(
        r"D:\D\个人文件\开源软件供应链安全\python漏洞影响性分析实验\知识图谱创建\整理好的\patchDictNew",
        r"f77cbc607d6e2a62e63287d37ad320109a2cc78a")
    root_directory = r"D:\D\个人文件\开源软件供应链安全\python漏洞影响性分析实验\知识图谱创建\bishe\component\CVE-2015-5081\django-cms-3.1.4.tar.gz_extracted"

    combined = analyze_results(patch_json, root_directory)
    print(combined)

    for file_path, id_list in combined.items():
        print(file_path)
        for entry in id_list:
            if 'details' in entry:
                print(entry["name"].split('#')[0])
                print("  " + str(entry["details"]))
            else:
                print("  " + entry["name"])
