{
    "ckan/lib/uploader.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 291,
                "afterPatchRowNumber": 291,
                "PatchRowcode": "             resource['url_type'] = ''"
            },
            "1": {
                "beforePatchRowNumber": 292,
                "afterPatchRowNumber": 292,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 293,
                "afterPatchRowNumber": 293,
                "PatchRowcode": "     def get_directory(self, id):"
            },
            "3": {
                "beforePatchRowNumber": 294,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        directory = os.path.join(self.storage_path,"
            },
            "4": {
                "beforePatchRowNumber": 295,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                 id[0:3], id[3:6])"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 294,
                "PatchRowcode": "+        real_storage = os.path.realpath(self.storage_path)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 295,
                "PatchRowcode": "+        directory = os.path.join(real_storage, id[0:3], id[3:6])"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 296,
                "PatchRowcode": "+        if directory != os.path.realpath(directory):"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 297,
                "PatchRowcode": "+            raise logic.ValidationError({'upload': ['Invalid storage directory']})"
            },
            "9": {
                "beforePatchRowNumber": 296,
                "afterPatchRowNumber": 298,
                "PatchRowcode": "         return directory"
            },
            "10": {
                "beforePatchRowNumber": 297,
                "afterPatchRowNumber": 299,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 298,
                "afterPatchRowNumber": 300,
                "PatchRowcode": "     def get_path(self, id):"
            },
            "12": {
                "beforePatchRowNumber": 299,
                "afterPatchRowNumber": 301,
                "PatchRowcode": "         directory = self.get_directory(id)"
            },
            "13": {
                "beforePatchRowNumber": 300,
                "afterPatchRowNumber": 302,
                "PatchRowcode": "         filepath = os.path.join(directory, id[6:])"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 303,
                "PatchRowcode": "+"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 304,
                "PatchRowcode": "+        if filepath != os.path.realpath(filepath):"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 305,
                "PatchRowcode": "+            raise logic.ValidationError({'upload': ['Invalid storage path']})"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 306,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": 301,
                "afterPatchRowNumber": 307,
                "PatchRowcode": "         return filepath"
            },
            "19": {
                "beforePatchRowNumber": 302,
                "afterPatchRowNumber": 308,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 309,
                "PatchRowcode": "     def upload(self, id, max_size=10):"
            }
        },
        "frontPatchFile": [
            "# encoding: utf-8",
            "",
            "import os",
            "import cgi",
            "import datetime",
            "import logging",
            "import magic",
            "import mimetypes",
            "from six.moves.urllib.parse import urlparse",
            "",
            "from werkzeug.datastructures import FileStorage as FlaskFileStorage",
            "",
            "import ckan.lib.munge as munge",
            "import ckan.logic as logic",
            "import ckan.plugins as plugins",
            "from ckan.common import config, aslist",
            "",
            "ALLOWED_UPLOAD_TYPES = (cgi.FieldStorage, FlaskFileStorage)",
            "MB = 1 << 20",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "_storage_path = None",
            "_max_resource_size = None",
            "_max_image_size = None",
            "",
            "",
            "def _copy_file(input_file, output_file, max_size):",
            "    input_file.seek(0)",
            "    current_size = 0",
            "    while True:",
            "        current_size = current_size + 1",
            "        # MB chunks",
            "        data = input_file.read(MB)",
            "",
            "        if not data:",
            "            break",
            "        output_file.write(data)",
            "        if current_size > max_size:",
            "            raise logic.ValidationError({'upload': ['File upload too large']})",
            "",
            "",
            "def _get_underlying_file(wrapper):",
            "    if isinstance(wrapper, FlaskFileStorage):",
            "        return wrapper.stream",
            "    return wrapper.file",
            "",
            "",
            "def get_uploader(upload_to, old_filename=None):",
            "    '''Query IUploader plugins and return an uploader instance for general",
            "    files.'''",
            "    upload = None",
            "    for plugin in plugins.PluginImplementations(plugins.IUploader):",
            "        upload = plugin.get_uploader(upload_to, old_filename)",
            "        if upload:",
            "            break",
            "",
            "    # default uploader",
            "    if upload is None:",
            "        upload = Upload(upload_to, old_filename)",
            "",
            "    return upload",
            "",
            "",
            "def get_resource_uploader(data_dict):",
            "    '''Query IUploader plugins and return a resource uploader instance.'''",
            "    upload = None",
            "    for plugin in plugins.PluginImplementations(plugins.IUploader):",
            "        upload = plugin.get_resource_uploader(data_dict)",
            "        if upload:",
            "            break",
            "",
            "    # default uploader",
            "    if upload is None:",
            "        upload = ResourceUpload(data_dict)",
            "",
            "    return upload",
            "",
            "",
            "def get_storage_path():",
            "    '''Function to cache storage path'''",
            "    global _storage_path",
            "",
            "    # None means it has not been set. False means not in config.",
            "    if _storage_path is None:",
            "        storage_path = config.get('ckan.storage_path')",
            "        if storage_path:",
            "            _storage_path = storage_path",
            "        else:",
            "            log.critical('''Please specify a ckan.storage_path in your config",
            "                         for your uploads''')",
            "            _storage_path = False",
            "",
            "    return _storage_path",
            "",
            "",
            "def get_max_image_size():",
            "    global _max_image_size",
            "    if _max_image_size is None:",
            "        _max_image_size = int(config.get('ckan.max_image_size', 2))",
            "    return _max_image_size",
            "",
            "",
            "def get_max_resource_size():",
            "    global _max_resource_size",
            "    if _max_resource_size is None:",
            "        _max_resource_size = int(config.get('ckan.max_resource_size', 10))",
            "    return _max_resource_size",
            "",
            "",
            "class Upload(object):",
            "    def __init__(self, object_type, old_filename=None):",
            "        ''' Setup upload by creating a subdirectory of the storage directory",
            "        of name object_type. old_filename is the name of the file in the url",
            "        field last time'''",
            "",
            "        self.storage_path = None",
            "        self.filename = None",
            "        self.filepath = None",
            "        path = get_storage_path()",
            "        if not path:",
            "            return",
            "        self.storage_path = os.path.join(path, 'storage',",
            "                                         'uploads', object_type)",
            "        # check if the storage directory is already created by",
            "        # the user or third-party",
            "        if os.path.isdir(self.storage_path):",
            "            pass",
            "        else:",
            "            try:",
            "                os.makedirs(self.storage_path)",
            "            except OSError as e:",
            "                # errno 17 is file already exists",
            "                if e.errno != 17:",
            "                    raise",
            "        self.object_type = object_type",
            "        self.old_filename = old_filename",
            "        if old_filename:",
            "            self.old_filepath = os.path.join(self.storage_path, old_filename)",
            "",
            "    def update_data_dict(self, data_dict, url_field, file_field, clear_field):",
            "        ''' Manipulate data from the data_dict.  url_field is the name of the",
            "        field where the upload is going to be. file_field is name of the key",
            "        where the FieldStorage is kept (i.e the field where the file data",
            "        actually is). clear_field is the name of a boolean field which",
            "        requests the upload to be deleted.  This needs to be called before",
            "        it reaches any validators'''",
            "",
            "        self.url = data_dict.get(url_field, '')",
            "        self.clear = data_dict.pop(clear_field, None)",
            "        self.file_field = file_field",
            "        self.upload_field_storage = data_dict.pop(file_field, None)",
            "",
            "        if not self.storage_path:",
            "            return",
            "",
            "        if isinstance(self.upload_field_storage, ALLOWED_UPLOAD_TYPES):",
            "            if self.upload_field_storage.filename:",
            "                self.filename = self.upload_field_storage.filename",
            "                self.filename = str(datetime.datetime.utcnow()) + self.filename",
            "                self.filename = munge.munge_filename_legacy(self.filename)",
            "                self.filepath = os.path.join(self.storage_path, self.filename)",
            "                data_dict[url_field] = self.filename",
            "                self.upload_file = _get_underlying_file(",
            "                    self.upload_field_storage)",
            "                self.tmp_filepath = self.filepath + '~'",
            "        # keep the file if there has been no change",
            "        elif self.old_filename and not self.old_filename.startswith('http'):",
            "            if not self.clear:",
            "                data_dict[url_field] = self.old_filename",
            "            if self.clear and self.url == self.old_filename:",
            "                data_dict[url_field] = ''",
            "",
            "    def upload(self, max_size=2):",
            "        ''' Actually upload the file.",
            "        This should happen just before a commit but after the data has",
            "        been validated and flushed to the db. This is so we do not store",
            "        anything unless the request is actually good.",
            "        max_size is size in MB maximum of the file'''",
            "",
            "        self.verify_type()",
            "",
            "        if self.filename:",
            "            with open(self.tmp_filepath, 'wb+') as output_file:",
            "                try:",
            "                    _copy_file(self.upload_file, output_file, max_size)",
            "                except logic.ValidationError:",
            "                    os.remove(self.tmp_filepath)",
            "                    raise",
            "                finally:",
            "                    self.upload_file.close()",
            "            os.rename(self.tmp_filepath, self.filepath)",
            "            self.clear = True",
            "",
            "        if (self.clear and self.old_filename",
            "                and not self.old_filename.startswith('http')):",
            "            try:",
            "                os.remove(self.old_filepath)",
            "            except OSError:",
            "                pass",
            "",
            "    def verify_type(self):",
            "        if not self.filename:",
            "            return",
            "",
            "        mimetypes = aslist(",
            "            config.get(",
            "                \"ckan.upload.{}.mimetypes\".format(self.object_type),",
            "                [\"image/png\", \"image/gif\", \"image/jpeg\"]",
            "            )",
            "        )",
            "",
            "        types = aslist(",
            "            config.get(",
            "                \"ckan.upload.{}.types\".format(self.object_type),",
            "                [\"image\"]",
            "            )",
            "        )",
            "",
            "        if not mimetypes and not types:",
            "            return",
            "",
            "        actual = magic.from_buffer(self.upload_file.read(1024), mime=True)",
            "        self.upload_file.seek(0, os.SEEK_SET)",
            "        err = {self.file_field: [",
            "            \"Unsupported upload type: {actual}\".format(actual=actual)]}",
            "",
            "        if mimetypes and actual not in mimetypes:",
            "            raise logic.ValidationError(err)",
            "",
            "        type_ = actual.split(\"/\")[0]",
            "        if types and type_ not in types:",
            "            raise logic.ValidationError(err)",
            "",
            "",
            "class ResourceUpload(object):",
            "    def __init__(self, resource):",
            "        path = get_storage_path()",
            "        config_mimetype_guess = config.get('ckan.mimetype_guess', 'file_ext')",
            "",
            "        if not path:",
            "            self.storage_path = None",
            "            return",
            "        self.storage_path = os.path.join(path, 'resources')",
            "        try:",
            "            os.makedirs(self.storage_path)",
            "        except OSError as e:",
            "            # errno 17 is file already exists",
            "            if e.errno != 17:",
            "                raise",
            "        self.filename = None",
            "        self.mimetype = None",
            "",
            "        url = resource.get('url')",
            "",
            "        upload_field_storage = resource.pop('upload', None)",
            "        self.clear = resource.pop('clear_upload', None)",
            "",
            "        if url and config_mimetype_guess == 'file_ext' and urlparse(url).path:",
            "            self.mimetype = mimetypes.guess_type(url)[0]",
            "",
            "        if bool(upload_field_storage) and \\",
            "                isinstance(upload_field_storage, ALLOWED_UPLOAD_TYPES):",
            "            self.filesize = 0  # bytes",
            "",
            "            self.filename = upload_field_storage.filename",
            "            self.filename = munge.munge_filename(self.filename)",
            "            resource['url'] = self.filename",
            "            resource['url_type'] = 'upload'",
            "            resource['last_modified'] = datetime.datetime.utcnow()",
            "            self.upload_file = _get_underlying_file(upload_field_storage)",
            "            self.upload_file.seek(0, os.SEEK_END)",
            "            self.filesize = self.upload_file.tell()",
            "            # go back to the beginning of the file buffer",
            "            self.upload_file.seek(0, os.SEEK_SET)",
            "",
            "            # check if the mimetype failed from guessing with the url",
            "            if not self.mimetype and config_mimetype_guess == 'file_ext':",
            "                self.mimetype = mimetypes.guess_type(self.filename)[0]",
            "",
            "            if not self.mimetype and config_mimetype_guess == 'file_contents':",
            "                try:",
            "                    self.mimetype = magic.from_buffer(self.upload_file.read(),",
            "                                                      mime=True)",
            "                    self.upload_file.seek(0, os.SEEK_SET)",
            "                except IOError as e:",
            "                    # Not that important if call above fails",
            "                    self.mimetype = None",
            "",
            "        elif self.clear:",
            "            resource['url_type'] = ''",
            "",
            "    def get_directory(self, id):",
            "        directory = os.path.join(self.storage_path,",
            "                                 id[0:3], id[3:6])",
            "        return directory",
            "",
            "    def get_path(self, id):",
            "        directory = self.get_directory(id)",
            "        filepath = os.path.join(directory, id[6:])",
            "        return filepath",
            "",
            "    def upload(self, id, max_size=10):",
            "        '''Actually upload the file.",
            "",
            "        :returns: ``'file uploaded'`` if a new file was successfully uploaded",
            "            (whether it overwrote a previously uploaded file or not),",
            "            ``'file deleted'`` if an existing uploaded file was deleted,",
            "            or ``None`` if nothing changed",
            "        :rtype: ``string`` or ``None``",
            "",
            "        '''",
            "        if not self.storage_path:",
            "            return",
            "",
            "        # Get directory and filepath on the system",
            "        # where the file for this resource will be stored",
            "        directory = self.get_directory(id)",
            "        filepath = self.get_path(id)",
            "",
            "        # If a filename has been provided (a file is being uploaded)",
            "        # we write it to the filepath (and overwrite it if it already",
            "        # exists). This way the uploaded file will always be stored",
            "        # in the same location",
            "        if self.filename:",
            "            try:",
            "                os.makedirs(directory)",
            "            except OSError as e:",
            "                # errno 17 is file already exists",
            "                if e.errno != 17:",
            "                    raise",
            "            tmp_filepath = filepath + '~'",
            "            with open(tmp_filepath, 'wb+') as output_file:",
            "                try:",
            "                    _copy_file(self.upload_file, output_file, max_size)",
            "                except logic.ValidationError:",
            "                    os.remove(tmp_filepath)",
            "                    raise",
            "                finally:",
            "                    self.upload_file.close()",
            "            os.rename(tmp_filepath, filepath)",
            "            return",
            "",
            "        # The resource form only sets self.clear (via the input clear_upload)",
            "        # to True when an uploaded file is not replaced by another uploaded",
            "        # file, only if it is replaced by a link to file.",
            "        # If the uploaded file is replaced by a link, we should remove the",
            "        # previously uploaded file to clean up the file system.",
            "        if self.clear:",
            "            try:",
            "                os.remove(filepath)",
            "            except OSError as e:",
            "                pass"
        ],
        "afterPatchFile": [
            "# encoding: utf-8",
            "",
            "import os",
            "import cgi",
            "import datetime",
            "import logging",
            "import magic",
            "import mimetypes",
            "from six.moves.urllib.parse import urlparse",
            "",
            "from werkzeug.datastructures import FileStorage as FlaskFileStorage",
            "",
            "import ckan.lib.munge as munge",
            "import ckan.logic as logic",
            "import ckan.plugins as plugins",
            "from ckan.common import config, aslist",
            "",
            "ALLOWED_UPLOAD_TYPES = (cgi.FieldStorage, FlaskFileStorage)",
            "MB = 1 << 20",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "_storage_path = None",
            "_max_resource_size = None",
            "_max_image_size = None",
            "",
            "",
            "def _copy_file(input_file, output_file, max_size):",
            "    input_file.seek(0)",
            "    current_size = 0",
            "    while True:",
            "        current_size = current_size + 1",
            "        # MB chunks",
            "        data = input_file.read(MB)",
            "",
            "        if not data:",
            "            break",
            "        output_file.write(data)",
            "        if current_size > max_size:",
            "            raise logic.ValidationError({'upload': ['File upload too large']})",
            "",
            "",
            "def _get_underlying_file(wrapper):",
            "    if isinstance(wrapper, FlaskFileStorage):",
            "        return wrapper.stream",
            "    return wrapper.file",
            "",
            "",
            "def get_uploader(upload_to, old_filename=None):",
            "    '''Query IUploader plugins and return an uploader instance for general",
            "    files.'''",
            "    upload = None",
            "    for plugin in plugins.PluginImplementations(plugins.IUploader):",
            "        upload = plugin.get_uploader(upload_to, old_filename)",
            "        if upload:",
            "            break",
            "",
            "    # default uploader",
            "    if upload is None:",
            "        upload = Upload(upload_to, old_filename)",
            "",
            "    return upload",
            "",
            "",
            "def get_resource_uploader(data_dict):",
            "    '''Query IUploader plugins and return a resource uploader instance.'''",
            "    upload = None",
            "    for plugin in plugins.PluginImplementations(plugins.IUploader):",
            "        upload = plugin.get_resource_uploader(data_dict)",
            "        if upload:",
            "            break",
            "",
            "    # default uploader",
            "    if upload is None:",
            "        upload = ResourceUpload(data_dict)",
            "",
            "    return upload",
            "",
            "",
            "def get_storage_path():",
            "    '''Function to cache storage path'''",
            "    global _storage_path",
            "",
            "    # None means it has not been set. False means not in config.",
            "    if _storage_path is None:",
            "        storage_path = config.get('ckan.storage_path')",
            "        if storage_path:",
            "            _storage_path = storage_path",
            "        else:",
            "            log.critical('''Please specify a ckan.storage_path in your config",
            "                         for your uploads''')",
            "            _storage_path = False",
            "",
            "    return _storage_path",
            "",
            "",
            "def get_max_image_size():",
            "    global _max_image_size",
            "    if _max_image_size is None:",
            "        _max_image_size = int(config.get('ckan.max_image_size', 2))",
            "    return _max_image_size",
            "",
            "",
            "def get_max_resource_size():",
            "    global _max_resource_size",
            "    if _max_resource_size is None:",
            "        _max_resource_size = int(config.get('ckan.max_resource_size', 10))",
            "    return _max_resource_size",
            "",
            "",
            "class Upload(object):",
            "    def __init__(self, object_type, old_filename=None):",
            "        ''' Setup upload by creating a subdirectory of the storage directory",
            "        of name object_type. old_filename is the name of the file in the url",
            "        field last time'''",
            "",
            "        self.storage_path = None",
            "        self.filename = None",
            "        self.filepath = None",
            "        path = get_storage_path()",
            "        if not path:",
            "            return",
            "        self.storage_path = os.path.join(path, 'storage',",
            "                                         'uploads', object_type)",
            "        # check if the storage directory is already created by",
            "        # the user or third-party",
            "        if os.path.isdir(self.storage_path):",
            "            pass",
            "        else:",
            "            try:",
            "                os.makedirs(self.storage_path)",
            "            except OSError as e:",
            "                # errno 17 is file already exists",
            "                if e.errno != 17:",
            "                    raise",
            "        self.object_type = object_type",
            "        self.old_filename = old_filename",
            "        if old_filename:",
            "            self.old_filepath = os.path.join(self.storage_path, old_filename)",
            "",
            "    def update_data_dict(self, data_dict, url_field, file_field, clear_field):",
            "        ''' Manipulate data from the data_dict.  url_field is the name of the",
            "        field where the upload is going to be. file_field is name of the key",
            "        where the FieldStorage is kept (i.e the field where the file data",
            "        actually is). clear_field is the name of a boolean field which",
            "        requests the upload to be deleted.  This needs to be called before",
            "        it reaches any validators'''",
            "",
            "        self.url = data_dict.get(url_field, '')",
            "        self.clear = data_dict.pop(clear_field, None)",
            "        self.file_field = file_field",
            "        self.upload_field_storage = data_dict.pop(file_field, None)",
            "",
            "        if not self.storage_path:",
            "            return",
            "",
            "        if isinstance(self.upload_field_storage, ALLOWED_UPLOAD_TYPES):",
            "            if self.upload_field_storage.filename:",
            "                self.filename = self.upload_field_storage.filename",
            "                self.filename = str(datetime.datetime.utcnow()) + self.filename",
            "                self.filename = munge.munge_filename_legacy(self.filename)",
            "                self.filepath = os.path.join(self.storage_path, self.filename)",
            "                data_dict[url_field] = self.filename",
            "                self.upload_file = _get_underlying_file(",
            "                    self.upload_field_storage)",
            "                self.tmp_filepath = self.filepath + '~'",
            "        # keep the file if there has been no change",
            "        elif self.old_filename and not self.old_filename.startswith('http'):",
            "            if not self.clear:",
            "                data_dict[url_field] = self.old_filename",
            "            if self.clear and self.url == self.old_filename:",
            "                data_dict[url_field] = ''",
            "",
            "    def upload(self, max_size=2):",
            "        ''' Actually upload the file.",
            "        This should happen just before a commit but after the data has",
            "        been validated and flushed to the db. This is so we do not store",
            "        anything unless the request is actually good.",
            "        max_size is size in MB maximum of the file'''",
            "",
            "        self.verify_type()",
            "",
            "        if self.filename:",
            "            with open(self.tmp_filepath, 'wb+') as output_file:",
            "                try:",
            "                    _copy_file(self.upload_file, output_file, max_size)",
            "                except logic.ValidationError:",
            "                    os.remove(self.tmp_filepath)",
            "                    raise",
            "                finally:",
            "                    self.upload_file.close()",
            "            os.rename(self.tmp_filepath, self.filepath)",
            "            self.clear = True",
            "",
            "        if (self.clear and self.old_filename",
            "                and not self.old_filename.startswith('http')):",
            "            try:",
            "                os.remove(self.old_filepath)",
            "            except OSError:",
            "                pass",
            "",
            "    def verify_type(self):",
            "        if not self.filename:",
            "            return",
            "",
            "        mimetypes = aslist(",
            "            config.get(",
            "                \"ckan.upload.{}.mimetypes\".format(self.object_type),",
            "                [\"image/png\", \"image/gif\", \"image/jpeg\"]",
            "            )",
            "        )",
            "",
            "        types = aslist(",
            "            config.get(",
            "                \"ckan.upload.{}.types\".format(self.object_type),",
            "                [\"image\"]",
            "            )",
            "        )",
            "",
            "        if not mimetypes and not types:",
            "            return",
            "",
            "        actual = magic.from_buffer(self.upload_file.read(1024), mime=True)",
            "        self.upload_file.seek(0, os.SEEK_SET)",
            "        err = {self.file_field: [",
            "            \"Unsupported upload type: {actual}\".format(actual=actual)]}",
            "",
            "        if mimetypes and actual not in mimetypes:",
            "            raise logic.ValidationError(err)",
            "",
            "        type_ = actual.split(\"/\")[0]",
            "        if types and type_ not in types:",
            "            raise logic.ValidationError(err)",
            "",
            "",
            "class ResourceUpload(object):",
            "    def __init__(self, resource):",
            "        path = get_storage_path()",
            "        config_mimetype_guess = config.get('ckan.mimetype_guess', 'file_ext')",
            "",
            "        if not path:",
            "            self.storage_path = None",
            "            return",
            "        self.storage_path = os.path.join(path, 'resources')",
            "        try:",
            "            os.makedirs(self.storage_path)",
            "        except OSError as e:",
            "            # errno 17 is file already exists",
            "            if e.errno != 17:",
            "                raise",
            "        self.filename = None",
            "        self.mimetype = None",
            "",
            "        url = resource.get('url')",
            "",
            "        upload_field_storage = resource.pop('upload', None)",
            "        self.clear = resource.pop('clear_upload', None)",
            "",
            "        if url and config_mimetype_guess == 'file_ext' and urlparse(url).path:",
            "            self.mimetype = mimetypes.guess_type(url)[0]",
            "",
            "        if bool(upload_field_storage) and \\",
            "                isinstance(upload_field_storage, ALLOWED_UPLOAD_TYPES):",
            "            self.filesize = 0  # bytes",
            "",
            "            self.filename = upload_field_storage.filename",
            "            self.filename = munge.munge_filename(self.filename)",
            "            resource['url'] = self.filename",
            "            resource['url_type'] = 'upload'",
            "            resource['last_modified'] = datetime.datetime.utcnow()",
            "            self.upload_file = _get_underlying_file(upload_field_storage)",
            "            self.upload_file.seek(0, os.SEEK_END)",
            "            self.filesize = self.upload_file.tell()",
            "            # go back to the beginning of the file buffer",
            "            self.upload_file.seek(0, os.SEEK_SET)",
            "",
            "            # check if the mimetype failed from guessing with the url",
            "            if not self.mimetype and config_mimetype_guess == 'file_ext':",
            "                self.mimetype = mimetypes.guess_type(self.filename)[0]",
            "",
            "            if not self.mimetype and config_mimetype_guess == 'file_contents':",
            "                try:",
            "                    self.mimetype = magic.from_buffer(self.upload_file.read(),",
            "                                                      mime=True)",
            "                    self.upload_file.seek(0, os.SEEK_SET)",
            "                except IOError as e:",
            "                    # Not that important if call above fails",
            "                    self.mimetype = None",
            "",
            "        elif self.clear:",
            "            resource['url_type'] = ''",
            "",
            "    def get_directory(self, id):",
            "        real_storage = os.path.realpath(self.storage_path)",
            "        directory = os.path.join(real_storage, id[0:3], id[3:6])",
            "        if directory != os.path.realpath(directory):",
            "            raise logic.ValidationError({'upload': ['Invalid storage directory']})",
            "        return directory",
            "",
            "    def get_path(self, id):",
            "        directory = self.get_directory(id)",
            "        filepath = os.path.join(directory, id[6:])",
            "",
            "        if filepath != os.path.realpath(filepath):",
            "            raise logic.ValidationError({'upload': ['Invalid storage path']})",
            "",
            "        return filepath",
            "",
            "    def upload(self, id, max_size=10):",
            "        '''Actually upload the file.",
            "",
            "        :returns: ``'file uploaded'`` if a new file was successfully uploaded",
            "            (whether it overwrote a previously uploaded file or not),",
            "            ``'file deleted'`` if an existing uploaded file was deleted,",
            "            or ``None`` if nothing changed",
            "        :rtype: ``string`` or ``None``",
            "",
            "        '''",
            "        if not self.storage_path:",
            "            return",
            "",
            "        # Get directory and filepath on the system",
            "        # where the file for this resource will be stored",
            "        directory = self.get_directory(id)",
            "        filepath = self.get_path(id)",
            "",
            "        # If a filename has been provided (a file is being uploaded)",
            "        # we write it to the filepath (and overwrite it if it already",
            "        # exists). This way the uploaded file will always be stored",
            "        # in the same location",
            "        if self.filename:",
            "            try:",
            "                os.makedirs(directory)",
            "            except OSError as e:",
            "                # errno 17 is file already exists",
            "                if e.errno != 17:",
            "                    raise",
            "            tmp_filepath = filepath + '~'",
            "            with open(tmp_filepath, 'wb+') as output_file:",
            "                try:",
            "                    _copy_file(self.upload_file, output_file, max_size)",
            "                except logic.ValidationError:",
            "                    os.remove(tmp_filepath)",
            "                    raise",
            "                finally:",
            "                    self.upload_file.close()",
            "            os.rename(tmp_filepath, filepath)",
            "            return",
            "",
            "        # The resource form only sets self.clear (via the input clear_upload)",
            "        # to True when an uploaded file is not replaced by another uploaded",
            "        # file, only if it is replaced by a link to file.",
            "        # If the uploaded file is replaced by a link, we should remove the",
            "        # previously uploaded file to clean up the file system.",
            "        if self.clear:",
            "            try:",
            "                os.remove(filepath)",
            "            except OSError as e:",
            "                pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "294": [
                "ResourceUpload",
                "get_directory"
            ],
            "295": [
                "ResourceUpload",
                "get_directory"
            ]
        },
        "addLocation": []
    },
    "ckan/logic/schema.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " def default_resource_schema("
            },
            "1": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": "         ignore_empty, unicode_safe, ignore, ignore_missing,"
            },
            "2": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": "         remove_whitespace, if_empty_guess_format, clean_format, isodate,"
            },
            "3": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        int_validator, extras_valid_json, keep_extras):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+        int_validator, extras_valid_json, keep_extras,"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+        resource_id_validator, resource_id_does_not_exist):"
            },
            "6": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "     return {"
            },
            "7": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'id': [ignore_empty, unicode_safe],"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+        'id': [ignore_empty, resource_id_validator,"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+               resource_id_does_not_exist, unicode_safe],"
            },
            "10": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "         'package_id': [ignore],"
            },
            "11": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "         'url': [ignore_missing, unicode_safe, remove_whitespace],"
            },
            "12": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "         'description': [ignore_missing, unicode_safe],"
            }
        },
        "frontPatchFile": [
            "# encoding: utf-8",
            "",
            "from functools import wraps",
            "import inspect",
            "",
            "from six import text_type",
            "import ckan.model",
            "import ckan.plugins as plugins",
            "from ckan.logic import get_validator",
            "",
            "",
            "def validator_args(fn):",
            "    u'''collect validator names from argument names",
            "    and pass them to wrapped function'''",
            "",
            "    args = inspect.getargspec(fn).args",
            "",
            "    @wraps(fn)",
            "    def wrapper():",
            "        kwargs = {",
            "            arg: get_validator(arg)",
            "            for arg in args}",
            "        return fn(**kwargs)",
            "",
            "    return wrapper",
            "",
            "",
            "@validator_args",
            "def default_resource_schema(",
            "        ignore_empty, unicode_safe, ignore, ignore_missing,",
            "        remove_whitespace, if_empty_guess_format, clean_format, isodate,",
            "        int_validator, extras_valid_json, keep_extras):",
            "    return {",
            "        'id': [ignore_empty, unicode_safe],",
            "        'package_id': [ignore],",
            "        'url': [ignore_missing, unicode_safe, remove_whitespace],",
            "        'description': [ignore_missing, unicode_safe],",
            "        'format': [if_empty_guess_format, ignore_missing, clean_format,",
            "                   unicode_safe],",
            "        'hash': [ignore_missing, unicode_safe],",
            "        'state': [ignore],",
            "        'position': [ignore],",
            "        'name': [ignore_missing, unicode_safe],",
            "        'resource_type': [ignore_missing, unicode_safe],",
            "        'url_type': [ignore_missing, unicode_safe],",
            "        'mimetype': [ignore_missing, unicode_safe],",
            "        'mimetype_inner': [ignore_missing, unicode_safe],",
            "        'cache_url': [ignore_missing, unicode_safe],",
            "        'size': [ignore_missing, int_validator],",
            "        'created': [ignore_missing, isodate],",
            "        'last_modified': [ignore_missing, isodate],",
            "        'cache_last_updated': [ignore_missing, isodate],",
            "        'tracking_summary': [ignore_missing],",
            "        'datastore_active': [ignore_missing],",
            "        '__extras': [ignore_missing, extras_valid_json, keep_extras],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_update_resource_schema(ignore):",
            "    schema = default_resource_schema()",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_tags_schema(",
            "        not_missing, not_empty, unicode_safe, tag_length_validator,",
            "        tag_name_validator, ignore_missing, vocabulary_id_exists,",
            "        ignore):",
            "    return {",
            "        'name': [not_missing,",
            "                 not_empty,",
            "                 unicode_safe,",
            "                 tag_length_validator,",
            "                 tag_name_validator,",
            "                 ],",
            "        'vocabulary_id': [ignore_missing,",
            "                          unicode_safe,",
            "                          vocabulary_id_exists],",
            "        'revision_timestamp': [ignore],",
            "        'state': [ignore],",
            "        'display_name': [ignore],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_tag_schema(",
            "        not_missing, not_empty, unicode_safe, vocabulary_id_exists,",
            "        tag_not_in_vocabulary, empty):",
            "    schema = default_tags_schema()",
            "    # When creating a tag via the tag_create() logic action function, a",
            "    # vocabulary_id _must_ be given (you cannot create free tags via this",
            "    # function).",
            "    schema['vocabulary_id'] = [not_missing, not_empty, unicode_safe,",
            "                               vocabulary_id_exists, tag_not_in_vocabulary]",
            "    # You're not allowed to specify your own ID when creating a tag.",
            "    schema['id'] = [empty]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_create_package_schema(",
            "        duplicate_extras_key, ignore, empty_if_not_sysadmin, ignore_missing,",
            "        unicode_safe, package_id_does_not_exist, not_empty, name_validator,",
            "        package_name_validator, if_empty_same_as, email_validator,",
            "        package_version_validator, ignore_not_package_admin,",
            "        boolean_validator, datasets_with_no_organization_cannot_be_private,",
            "        empty, tag_string_convert, owner_org_validator, no_http):",
            "    return {",
            "        '__before': [duplicate_extras_key, ignore],",
            "        'id': [empty_if_not_sysadmin, ignore_missing, unicode_safe,",
            "               package_id_does_not_exist],",
            "        'name': [",
            "            not_empty, unicode_safe, name_validator, package_name_validator],",
            "        'title': [if_empty_same_as(\"name\"), unicode_safe],",
            "        'author': [ignore_missing, unicode_safe],",
            "        'author_email': [ignore_missing, unicode_safe, email_validator],",
            "        'maintainer': [ignore_missing, unicode_safe],",
            "        'maintainer_email': [ignore_missing, unicode_safe, email_validator],",
            "        'license_id': [ignore_missing, unicode_safe],",
            "        'notes': [ignore_missing, unicode_safe],",
            "        'url': [ignore_missing, unicode_safe],",
            "        'version': [ignore_missing, unicode_safe, package_version_validator],",
            "        'state': [ignore_not_package_admin, ignore_missing],",
            "        'type': [ignore_missing, unicode_safe],",
            "        'owner_org': [owner_org_validator, unicode_safe],",
            "        'log_message': [ignore_missing, unicode_safe, no_http],",
            "        'private': [ignore_missing, boolean_validator,",
            "                    datasets_with_no_organization_cannot_be_private],",
            "        '__extras': [ignore],",
            "        '__junk': [empty],",
            "        'resources': default_resource_schema(),",
            "        'tags': default_tags_schema(),",
            "        'tag_string': [ignore_missing, tag_string_convert],",
            "        'extras': default_extras_schema(),",
            "        'save': [ignore],",
            "        'return_to': [ignore],",
            "        'relationships_as_object': default_relationship_schema(),",
            "        'relationships_as_subject': default_relationship_schema(),",
            "        'groups': {",
            "            'id': [ignore_missing, unicode_safe],",
            "            'name': [ignore_missing, unicode_safe],",
            "            'title': [ignore_missing, unicode_safe],",
            "            '__extras': [ignore],",
            "        }",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_update_package_schema(",
            "        ignore_missing, package_id_not_changed, name_validator,",
            "        package_name_validator, unicode_safe, owner_org_validator):",
            "    schema = default_create_package_schema()",
            "",
            "    schema['resources'] = default_update_resource_schema()",
            "",
            "    # Users can (optionally) supply the package id when updating a package, but",
            "    # only to identify the package to be updated, they cannot change the id.",
            "    schema['id'] = [ignore_missing, package_id_not_changed]",
            "",
            "    # Supplying the package name when updating a package is optional (you can",
            "    # supply the id to identify the package instead).",
            "    schema['name'] = [ignore_missing, name_validator, package_name_validator,",
            "                      unicode_safe]",
            "",
            "    # Supplying the package title when updating a package is optional, if it's",
            "    # not supplied the title will not be changed.",
            "    schema['title'] = [ignore_missing, unicode_safe]",
            "",
            "    schema['owner_org'] = [ignore_missing, owner_org_validator, unicode_safe]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_show_package_schema(",
            "        keep_extras, ignore_missing, clean_format, unicode_safe, not_empty):",
            "    schema = default_create_package_schema()",
            "",
            "    # Don't strip ids from package dicts when validating them.",
            "    schema['id'] = []",
            "",
            "    schema.update({",
            "        'tags': {'__extras': [keep_extras]}})",
            "",
            "    # Add several keys to the 'resources' subschema so they don't get stripped",
            "    # from the resource dicts by validation.",
            "    schema['resources'].update({",
            "        'format': [ignore_missing, clean_format, unicode_safe],",
            "        'created': [ignore_missing],",
            "        'position': [not_empty],",
            "        'last_modified': [],",
            "        'cache_last_updated': [],",
            "        'package_id': [],",
            "        'size': [],",
            "        'state': [],",
            "        'mimetype': [],",
            "        'cache_url': [],",
            "        'name': [],",
            "        'description': [],",
            "        'mimetype_inner': [],",
            "        'resource_type': [],",
            "        'url_type': [],",
            "    })",
            "",
            "    schema.update({",
            "        'state': [ignore_missing],",
            "        'isopen': [ignore_missing],",
            "        'license_url': [ignore_missing],",
            "    })",
            "",
            "    schema['groups'].update({",
            "        'description': [ignore_missing],",
            "        'display_name': [ignore_missing],",
            "        'image_display_url': [ignore_missing],",
            "    })",
            "",
            "    # Remove validators for several keys from the schema so validation doesn't",
            "    # strip the keys from the package dicts if the values are 'missing' (i.e.",
            "    # None).",
            "    schema['author'] = []",
            "    schema['author_email'] = []",
            "    schema['maintainer'] = []",
            "    schema['maintainer_email'] = []",
            "    schema['license_id'] = []",
            "    schema['notes'] = []",
            "    schema['url'] = []",
            "    schema['version'] = []",
            "",
            "    # Add several keys that are missing from default_create_package_schema(),",
            "    # so validation doesn't strip the keys from the package dicts.",
            "    schema['metadata_created'] = []",
            "    schema['metadata_modified'] = []",
            "    schema['creator_user_id'] = []",
            "    schema['num_resources'] = []",
            "    schema['num_tags'] = []",
            "    schema['organization'] = []",
            "    schema['owner_org'] = []",
            "    schema['private'] = []",
            "    schema['tracking_summary'] = [ignore_missing]",
            "    schema['license_title'] = []",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_group_schema(",
            "        ignore_missing, unicode_safe, ignore, not_empty, name_validator,",
            "        group_name_validator, package_id_or_name_exists,",
            "        no_loops_in_hierarchy, ignore_not_group_admin):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe],",
            "        'name': [",
            "            not_empty, unicode_safe, name_validator, group_name_validator],",
            "        'title': [ignore_missing, unicode_safe],",
            "        'description': [ignore_missing, unicode_safe],",
            "        'image_url': [ignore_missing, unicode_safe],",
            "        'image_display_url': [ignore_missing, unicode_safe],",
            "        'type': [ignore_missing, unicode_safe],",
            "        'state': [ignore_not_group_admin, ignore_missing],",
            "        'created': [ignore],",
            "        'is_organization': [ignore_missing],",
            "        'approval_status': [ignore_missing, unicode_safe],",
            "        'extras': default_extras_schema(),",
            "        '__extras': [ignore],",
            "        '__junk': [ignore],",
            "        'packages': {",
            "            \"id\": [not_empty, unicode_safe, package_id_or_name_exists],",
            "            \"title\": [ignore_missing, unicode_safe],",
            "            \"name\": [ignore_missing, unicode_safe],",
            "            \"__extras\": [ignore]",
            "        },",
            "        'users': {",
            "            \"name\": [not_empty, unicode_safe],",
            "            \"capacity\": [ignore_missing],",
            "            \"__extras\": [ignore]",
            "        },",
            "        'groups': {",
            "            \"name\": [not_empty, no_loops_in_hierarchy, unicode_safe],",
            "            \"capacity\": [ignore_missing],",
            "            \"__extras\": [ignore]",
            "        }",
            "    }",
            "",
            "",
            "@validator_args",
            "def group_form_schema(",
            "        not_empty, unicode_safe, ignore_missing, ignore):",
            "    schema = default_group_schema()",
            "    # schema['extras_validation'] = [duplicate_extras_key, ignore]",
            "    schema['packages'] = {",
            "        \"name\": [not_empty, unicode_safe],",
            "        \"title\": [ignore_missing],",
            "        \"__extras\": [ignore]",
            "    }",
            "    schema['users'] = {",
            "        \"name\": [not_empty, unicode_safe],",
            "        \"capacity\": [ignore_missing],",
            "        \"__extras\": [ignore]",
            "    }",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_group_schema(",
            "        ignore_missing, group_name_validator, unicode_safe):",
            "    schema = default_group_schema()",
            "    schema[\"name\"] = [ignore_missing, group_name_validator, unicode_safe]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_show_group_schema(",
            "        keep_extras, ignore_missing):",
            "    schema = default_group_schema()",
            "",
            "    # make default show schema behave like when run with no validation",
            "    schema['num_followers'] = []",
            "    schema['created'] = []",
            "    schema['display_name'] = []",
            "    schema['extras'] = {'__extras': [keep_extras]}",
            "    schema['package_count'] = [ignore_missing]",
            "    schema['packages'] = {'__extras': [keep_extras]}",
            "    schema['state'] = []",
            "    schema['users'] = {'__extras': [keep_extras]}",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_extras_schema(",
            "        ignore, not_empty, extra_key_not_in_root_schema, unicode_safe,",
            "        not_missing, ignore_missing):",
            "    return {",
            "        'id': [ignore],",
            "        'key': [not_empty, extra_key_not_in_root_schema, unicode_safe],",
            "        'value': [not_missing],",
            "        'state': [ignore],",
            "        'deleted': [ignore_missing],",
            "        'revision_timestamp': [ignore],",
            "        '__extras': [ignore],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_relationship_schema(",
            "        ignore_missing, unicode_safe, not_empty, one_of, ignore):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe],",
            "        'subject': [ignore_missing, unicode_safe],",
            "        'object': [ignore_missing, unicode_safe],",
            "        'type': [not_empty,",
            "                 one_of(ckan.model.PackageRelationship.get_all_types())],",
            "        'comment': [ignore_missing, unicode_safe],",
            "        'state': [ignore],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_relationship_schema(",
            "        empty, not_empty, unicode_safe, package_id_or_name_exists):",
            "    schema = default_relationship_schema()",
            "    schema['id'] = [empty]",
            "    schema['subject'] = [not_empty, unicode_safe, package_id_or_name_exists]",
            "    schema['object'] = [not_empty, unicode_safe, package_id_or_name_exists]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_relationship_schema(",
            "        ignore_missing, package_id_not_changed):",
            "    schema = default_relationship_schema()",
            "    schema['id'] = [ignore_missing, package_id_not_changed]",
            "",
            "    # Todo: would like to check subject, object & type haven't changed, but",
            "    # no way to do this in schema",
            "    schema['subject'] = [ignore_missing]",
            "    schema['object'] = [ignore_missing]",
            "    schema['type'] = [ignore_missing]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_user_schema(",
            "        ignore_missing, unicode_safe, name_validator, user_name_validator,",
            "        user_password_validator, user_password_not_empty, email_is_unique,",
            "        ignore_not_sysadmin, not_empty, email_validator,",
            "        user_about_validator, ignore, boolean_validator, json_object):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe],",
            "        'name': [",
            "            not_empty, name_validator, user_name_validator, unicode_safe],",
            "        'fullname': [ignore_missing, unicode_safe],",
            "        'password': [user_password_validator, user_password_not_empty,",
            "                     ignore_missing, unicode_safe],",
            "        'password_hash': [ignore_missing, ignore_not_sysadmin, unicode_safe],",
            "        'email': [not_empty, email_validator, email_is_unique, unicode_safe],",
            "        'about': [ignore_missing, user_about_validator, unicode_safe],",
            "        'created': [ignore],",
            "        'sysadmin': [ignore_missing, ignore_not_sysadmin],",
            "        'apikey': [ignore],",
            "        'reset_key': [ignore],",
            "        'activity_streams_email_notifications': [ignore_missing,",
            "                                                 boolean_validator],",
            "        'state': [ignore_missing, ignore_not_sysadmin],",
            "        'image_url': [ignore_missing, unicode_safe],",
            "        'image_display_url': [ignore_missing, unicode_safe],",
            "        'plugin_extras': [ignore_missing, json_object, ignore_not_sysadmin],",
            "    }",
            "",
            "",
            "@validator_args",
            "def user_new_form_schema(",
            "        unicode_safe, user_both_passwords_entered,",
            "        user_password_validator, user_passwords_match):",
            "    schema = default_user_schema()",
            "",
            "    schema['password1'] = [text_type, user_both_passwords_entered,",
            "                           user_password_validator, user_passwords_match]",
            "    schema['password2'] = [text_type]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def user_edit_form_schema(",
            "        ignore_missing, unicode_safe, user_password_validator,",
            "        user_passwords_match):",
            "    schema = default_user_schema()",
            "",
            "    schema['password'] = [ignore_missing]",
            "    schema['password1'] = [ignore_missing, unicode_safe,",
            "                           user_password_validator, user_passwords_match]",
            "    schema['password2'] = [ignore_missing, unicode_safe]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_user_schema(",
            "        ignore_missing, name_validator, user_name_validator,",
            "        unicode_safe, user_password_validator, email_is_unique,",
            "        not_empty, email_validator):",
            "    schema = default_user_schema()",
            "",
            "    schema['name'] = [",
            "        ignore_missing, name_validator, user_name_validator, unicode_safe]",
            "    schema['password'] = [",
            "        user_password_validator, ignore_missing, unicode_safe]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_generate_apikey_user_schema(",
            "        not_empty, unicode_safe):",
            "    schema = default_update_user_schema()",
            "",
            "    schema['apikey'] = [not_empty, unicode_safe]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_user_invite_schema(",
            "        not_empty, email_validator, email_is_unique):",
            "    return {",
            "        'email': [not_empty, email_validator, email_is_unique, text_type],",
            "        'group_id': [not_empty],",
            "        'role': [not_empty],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_task_status_schema(",
            "        ignore, not_empty, unicode_safe, ignore_missing):",
            "    return {",
            "        'id': [ignore],",
            "        'entity_id': [not_empty, unicode_safe],",
            "        'entity_type': [not_empty, unicode_safe],",
            "        'task_type': [not_empty, unicode_safe],",
            "        'key': [not_empty, unicode_safe],",
            "        'value': [ignore_missing],",
            "        'state': [ignore_missing],",
            "        'last_updated': [ignore_missing],",
            "        'error': [ignore_missing]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_vocabulary_schema(",
            "        ignore_missing, unicode_safe, vocabulary_id_exists,",
            "        not_empty, vocabulary_name_validator):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe, vocabulary_id_exists],",
            "        'name': [not_empty, unicode_safe, vocabulary_name_validator],",
            "        'tags': default_tags_schema(),",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_vocabulary_schema(",
            "        empty):",
            "    schema = default_vocabulary_schema()",
            "    schema['id'] = [empty]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_vocabulary_schema(",
            "        ignore_missing, vocabulary_id_not_changed,",
            "        vocabulary_name_validator):",
            "    schema = default_vocabulary_schema()",
            "    schema['id'] = [ignore_missing, vocabulary_id_not_changed]",
            "    schema['name'] = [ignore_missing, vocabulary_name_validator]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_create_activity_schema(",
            "        ignore, not_missing, not_empty, unicode_safe,",
            "        convert_user_name_or_id_to_id, object_id_validator,",
            "        activity_type_exists, ignore_empty, ignore_missing):",
            "    return {",
            "        'id': [ignore],",
            "        'timestamp': [ignore],",
            "        'user_id': [not_missing, not_empty, unicode_safe,",
            "                    convert_user_name_or_id_to_id],",
            "        'object_id': [",
            "            not_missing, not_empty, unicode_safe, object_id_validator],",
            "        'activity_type': [not_missing, not_empty, unicode_safe,",
            "                          activity_type_exists],",
            "        'data': [ignore_empty, ignore_missing],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_follow_user_schema(",
            "        not_missing, not_empty, unicode_safe, convert_user_name_or_id_to_id,",
            "        ignore_missing):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe,",
            "               convert_user_name_or_id_to_id],",
            "        'q': [ignore_missing]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_follow_dataset_schema(",
            "        not_missing, not_empty, unicode_safe,",
            "        convert_package_name_or_id_to_id):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe,",
            "               convert_package_name_or_id_to_id]",
            "    }",
            "",
            "",
            "@validator_args",
            "def member_schema(",
            "        not_missing, group_id_or_name_exists, unicode_safe,",
            "        user_id_or_name_exists, role_exists):",
            "    return {",
            "        'id': [not_missing, group_id_or_name_exists, unicode_safe],",
            "        'username': [not_missing, user_id_or_name_exists, unicode_safe],",
            "        'role': [not_missing, role_exists, unicode_safe],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_follow_group_schema(",
            "        not_missing, not_empty, unicode_safe,",
            "        convert_group_name_or_id_to_id):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe,",
            "               convert_group_name_or_id_to_id]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_package_list_schema(",
            "        ignore_missing, natural_number_validator, is_positive_integer):",
            "    return {",
            "        'limit': [ignore_missing, natural_number_validator],",
            "        'offset': [ignore_missing, natural_number_validator],",
            "        'page': [ignore_missing, is_positive_integer]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_pagination_schema(ignore_missing, natural_number_validator):",
            "    return {",
            "        'limit': [ignore_missing, natural_number_validator],",
            "        'offset': [ignore_missing, natural_number_validator]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_dashboard_activity_list_schema(",
            "        configured_default, natural_number_validator,",
            "        limit_to_configured_maximum):",
            "    schema = default_pagination_schema()",
            "    schema['limit'] = [",
            "        configured_default('ckan.activity_list_limit', 31),",
            "        natural_number_validator,",
            "        limit_to_configured_maximum('ckan.activity_list_limit_max', 100)]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_activity_list_schema(",
            "        not_missing, unicode_safe, configured_default,",
            "        natural_number_validator, limit_to_configured_maximum,",
            "        ignore_missing, boolean_validator, ignore_not_sysadmin):",
            "    schema = default_pagination_schema()",
            "    schema['id'] = [not_missing, unicode_safe]",
            "    schema['limit'] = [",
            "        configured_default('ckan.activity_list_limit', 31),",
            "        natural_number_validator,",
            "        limit_to_configured_maximum('ckan.activity_list_limit_max', 100)]",
            "    schema['include_hidden_activity'] = [",
            "        ignore_missing, ignore_not_sysadmin, boolean_validator]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_autocomplete_schema(",
            "        not_missing, unicode_safe, ignore_missing, natural_number_validator):",
            "    return {",
            "        'q': [not_missing, unicode_safe],",
            "        'ignore_self': [ignore_missing],",
            "        'limit': [ignore_missing, natural_number_validator]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_package_search_schema(",
            "        ignore_missing, unicode_safe, list_of_strings,",
            "        natural_number_validator, int_validator, convert_to_json_if_string,",
            "        convert_to_list_if_string, limit_to_configured_maximum, default):",
            "    return {",
            "        'q': [ignore_missing, unicode_safe],",
            "        'fl': [ignore_missing, convert_to_list_if_string],",
            "        'fq': [ignore_missing, unicode_safe],",
            "        'rows': [default(10), natural_number_validator,",
            "                 limit_to_configured_maximum('ckan.search.rows_max', 1000)],",
            "        'sort': [ignore_missing, unicode_safe],",
            "        'start': [ignore_missing, natural_number_validator],",
            "        'qf': [ignore_missing, unicode_safe],",
            "        'facet': [ignore_missing, unicode_safe],",
            "        'facet.mincount': [ignore_missing, natural_number_validator],",
            "        'facet.limit': [ignore_missing, int_validator],",
            "        'facet.field': [ignore_missing, convert_to_json_if_string,",
            "                        list_of_strings],",
            "        'extras': [ignore_missing]  # Not used by Solr,",
            "                                    # but useful for extensions",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_resource_search_schema(",
            "        ignore_missing, unicode_safe, natural_number_validator):",
            "    schema = {",
            "        'query': [ignore_missing],  # string or list of strings",
            "        'fields': [ignore_missing],  # dict of fields",
            "        'order_by': [ignore_missing, unicode_safe],",
            "        'offset': [ignore_missing, natural_number_validator],",
            "        'limit': [ignore_missing, natural_number_validator]",
            "    }",
            "    return schema",
            "",
            "",
            "def create_schema_for_required_keys(keys):",
            "    ''' helper function that creates a schema definition where",
            "    each key from keys is validated against ``not_missing``.",
            "    '''",
            "    not_missing = get_validator('not_missing')",
            "    return {x: [not_missing] for x in keys}",
            "",
            "",
            "def default_create_resource_view_schema(resource_view):",
            "    if resource_view.info().get('filterable'):",
            "        return default_create_resource_view_schema_filtered()",
            "    return default_create_resource_view_schema_unfiltered()",
            "",
            "",
            "@validator_args",
            "def default_create_resource_view_schema_unfiltered(",
            "        not_empty, resource_id_exists, unicode_safe, ignore_missing, empty):",
            "    return {",
            "        'resource_id': [not_empty, resource_id_exists],",
            "        'title': [not_empty, unicode_safe],",
            "        'description': [ignore_missing, unicode_safe],",
            "        'view_type': [not_empty, unicode_safe],",
            "        '__extras': [empty],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_resource_view_schema_filtered(",
            "        ignore_missing, convert_to_list_if_string,",
            "        filter_fields_and_values_should_have_same_length,",
            "        filter_fields_and_values_exist_and_are_valid):",
            "    schema = default_create_resource_view_schema_unfiltered()",
            "    schema['filter_fields'] = [",
            "        ignore_missing,",
            "        convert_to_list_if_string,",
            "        filter_fields_and_values_should_have_same_length,",
            "        filter_fields_and_values_exist_and_are_valid]",
            "    schema['filter_values'] = [ignore_missing, convert_to_list_if_string]",
            "    return schema",
            "",
            "",
            "def default_update_resource_view_schema(resource_view):",
            "    schema = default_create_resource_view_schema(resource_view)",
            "    schema.update(default_update_resource_view_schema_changes())",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_resource_view_schema_changes(",
            "        not_missing, not_empty, unicode_safe, resource_id_exists, ignore,",
            "        ignore_missing):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe],",
            "        'resource_id': [ignore_missing, resource_id_exists],",
            "        'title': [ignore_missing, unicode_safe],",
            "        'view_type': [ignore],  # cannot change after create",
            "        'package_id': [ignore]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_update_configuration_schema(",
            "        unicode_safe, is_positive_integer, ignore_missing):",
            "    return {",
            "        'ckan.site_title': [ignore_missing, unicode_safe],",
            "        'ckan.site_logo': [ignore_missing, unicode_safe],",
            "        'ckan.site_url': [ignore_missing, unicode_safe],",
            "        'ckan.site_description': [ignore_missing, unicode_safe],",
            "        'ckan.site_about': [ignore_missing, unicode_safe],",
            "        'ckan.site_intro_text': [ignore_missing, unicode_safe],",
            "        'ckan.site_custom_css': [ignore_missing, unicode_safe],",
            "        'ckan.theme': [ignore_missing, unicode_safe],",
            "        'ckan.homepage_style': [ignore_missing, is_positive_integer],",
            "        'logo_upload': [ignore_missing, unicode_safe],",
            "        'clear_logo_upload': [ignore_missing, unicode_safe],",
            "    }",
            "",
            "",
            "def update_configuration_schema():",
            "    '''",
            "    Returns the schema for the config options that can be edited during runtime",
            "",
            "    By default these are the keys of the",
            "    :py:func:`ckan.logic.schema.default_update_configuration_schema`.",
            "    Extensions can add or remove keys from this schema using the",
            "    :py:meth:`ckan.plugins.interfaces.IConfigurer.update_config_schema`",
            "    method.",
            "",
            "    These configuration options can be edited during runtime via the web",
            "    interface or using",
            "    the :py:func:`ckan.logic.action.update.config_option_update` API call.",
            "",
            "    :returns: a dictionary mapping runtime-editable configuration option keys",
            "      to lists of validator and converter functions to be applied to those",
            "      keys",
            "    :rtype: dictionary",
            "    '''",
            "",
            "    schema = default_update_configuration_schema()",
            "    for plugin in plugins.PluginImplementations(plugins.IConfigurer):",
            "        if hasattr(plugin, 'update_config_schema'):",
            "            schema = plugin.update_config_schema(schema)",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def job_list_schema(ignore_missing, list_of_strings):",
            "    return {",
            "        u'queues': [ignore_missing, list_of_strings],",
            "    }",
            "",
            "",
            "@validator_args",
            "def job_clear_schema(ignore_missing, list_of_strings):",
            "    return {",
            "        u'queues': [ignore_missing, list_of_strings],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_api_token_schema(",
            "        not_empty, unicode_safe,",
            "        ignore_missing, json_object, ignore_not_sysadmin):",
            "    return {",
            "        u'name': [not_empty, unicode_safe],",
            "        u'user': [not_empty, unicode_safe],",
            "        u'plugin_extras': [ignore_missing, json_object, ignore_not_sysadmin],",
            "    }",
            "",
            "",
            "@validator_args",
            "def package_revise_schema(",
            "        ignore_missing, list_of_strings,",
            "        collect_prefix_validate, json_or_string,",
            "        json_list_or_string, dict_only):",
            "    return {",
            "        u'__before': [",
            "            collect_prefix_validate(",
            "                u'match__', u'json_or_string'),",
            "            collect_prefix_validate(",
            "                u'update__', u'json_or_string')],",
            "        u'match': [",
            "            ignore_missing, json_or_string, dict_only],",
            "        u'filter': [",
            "            ignore_missing, json_list_or_string, list_of_strings],",
            "        u'update': [",
            "            ignore_missing, json_or_string, dict_only],",
            "        u'include': [",
            "            ignore_missing, json_list_or_string, list_of_strings],",
            "        # collect_prefix moves values to these, always dicts:",
            "        u'match__': [],",
            "        u'update__': [],",
            "    }"
        ],
        "afterPatchFile": [
            "# encoding: utf-8",
            "",
            "from functools import wraps",
            "import inspect",
            "",
            "from six import text_type",
            "import ckan.model",
            "import ckan.plugins as plugins",
            "from ckan.logic import get_validator",
            "",
            "",
            "def validator_args(fn):",
            "    u'''collect validator names from argument names",
            "    and pass them to wrapped function'''",
            "",
            "    args = inspect.getargspec(fn).args",
            "",
            "    @wraps(fn)",
            "    def wrapper():",
            "        kwargs = {",
            "            arg: get_validator(arg)",
            "            for arg in args}",
            "        return fn(**kwargs)",
            "",
            "    return wrapper",
            "",
            "",
            "@validator_args",
            "def default_resource_schema(",
            "        ignore_empty, unicode_safe, ignore, ignore_missing,",
            "        remove_whitespace, if_empty_guess_format, clean_format, isodate,",
            "        int_validator, extras_valid_json, keep_extras,",
            "        resource_id_validator, resource_id_does_not_exist):",
            "    return {",
            "        'id': [ignore_empty, resource_id_validator,",
            "               resource_id_does_not_exist, unicode_safe],",
            "        'package_id': [ignore],",
            "        'url': [ignore_missing, unicode_safe, remove_whitespace],",
            "        'description': [ignore_missing, unicode_safe],",
            "        'format': [if_empty_guess_format, ignore_missing, clean_format,",
            "                   unicode_safe],",
            "        'hash': [ignore_missing, unicode_safe],",
            "        'state': [ignore],",
            "        'position': [ignore],",
            "        'name': [ignore_missing, unicode_safe],",
            "        'resource_type': [ignore_missing, unicode_safe],",
            "        'url_type': [ignore_missing, unicode_safe],",
            "        'mimetype': [ignore_missing, unicode_safe],",
            "        'mimetype_inner': [ignore_missing, unicode_safe],",
            "        'cache_url': [ignore_missing, unicode_safe],",
            "        'size': [ignore_missing, int_validator],",
            "        'created': [ignore_missing, isodate],",
            "        'last_modified': [ignore_missing, isodate],",
            "        'cache_last_updated': [ignore_missing, isodate],",
            "        'tracking_summary': [ignore_missing],",
            "        'datastore_active': [ignore_missing],",
            "        '__extras': [ignore_missing, extras_valid_json, keep_extras],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_update_resource_schema(ignore):",
            "    schema = default_resource_schema()",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_tags_schema(",
            "        not_missing, not_empty, unicode_safe, tag_length_validator,",
            "        tag_name_validator, ignore_missing, vocabulary_id_exists,",
            "        ignore):",
            "    return {",
            "        'name': [not_missing,",
            "                 not_empty,",
            "                 unicode_safe,",
            "                 tag_length_validator,",
            "                 tag_name_validator,",
            "                 ],",
            "        'vocabulary_id': [ignore_missing,",
            "                          unicode_safe,",
            "                          vocabulary_id_exists],",
            "        'revision_timestamp': [ignore],",
            "        'state': [ignore],",
            "        'display_name': [ignore],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_tag_schema(",
            "        not_missing, not_empty, unicode_safe, vocabulary_id_exists,",
            "        tag_not_in_vocabulary, empty):",
            "    schema = default_tags_schema()",
            "    # When creating a tag via the tag_create() logic action function, a",
            "    # vocabulary_id _must_ be given (you cannot create free tags via this",
            "    # function).",
            "    schema['vocabulary_id'] = [not_missing, not_empty, unicode_safe,",
            "                               vocabulary_id_exists, tag_not_in_vocabulary]",
            "    # You're not allowed to specify your own ID when creating a tag.",
            "    schema['id'] = [empty]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_create_package_schema(",
            "        duplicate_extras_key, ignore, empty_if_not_sysadmin, ignore_missing,",
            "        unicode_safe, package_id_does_not_exist, not_empty, name_validator,",
            "        package_name_validator, if_empty_same_as, email_validator,",
            "        package_version_validator, ignore_not_package_admin,",
            "        boolean_validator, datasets_with_no_organization_cannot_be_private,",
            "        empty, tag_string_convert, owner_org_validator, no_http):",
            "    return {",
            "        '__before': [duplicate_extras_key, ignore],",
            "        'id': [empty_if_not_sysadmin, ignore_missing, unicode_safe,",
            "               package_id_does_not_exist],",
            "        'name': [",
            "            not_empty, unicode_safe, name_validator, package_name_validator],",
            "        'title': [if_empty_same_as(\"name\"), unicode_safe],",
            "        'author': [ignore_missing, unicode_safe],",
            "        'author_email': [ignore_missing, unicode_safe, email_validator],",
            "        'maintainer': [ignore_missing, unicode_safe],",
            "        'maintainer_email': [ignore_missing, unicode_safe, email_validator],",
            "        'license_id': [ignore_missing, unicode_safe],",
            "        'notes': [ignore_missing, unicode_safe],",
            "        'url': [ignore_missing, unicode_safe],",
            "        'version': [ignore_missing, unicode_safe, package_version_validator],",
            "        'state': [ignore_not_package_admin, ignore_missing],",
            "        'type': [ignore_missing, unicode_safe],",
            "        'owner_org': [owner_org_validator, unicode_safe],",
            "        'log_message': [ignore_missing, unicode_safe, no_http],",
            "        'private': [ignore_missing, boolean_validator,",
            "                    datasets_with_no_organization_cannot_be_private],",
            "        '__extras': [ignore],",
            "        '__junk': [empty],",
            "        'resources': default_resource_schema(),",
            "        'tags': default_tags_schema(),",
            "        'tag_string': [ignore_missing, tag_string_convert],",
            "        'extras': default_extras_schema(),",
            "        'save': [ignore],",
            "        'return_to': [ignore],",
            "        'relationships_as_object': default_relationship_schema(),",
            "        'relationships_as_subject': default_relationship_schema(),",
            "        'groups': {",
            "            'id': [ignore_missing, unicode_safe],",
            "            'name': [ignore_missing, unicode_safe],",
            "            'title': [ignore_missing, unicode_safe],",
            "            '__extras': [ignore],",
            "        }",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_update_package_schema(",
            "        ignore_missing, package_id_not_changed, name_validator,",
            "        package_name_validator, unicode_safe, owner_org_validator):",
            "    schema = default_create_package_schema()",
            "",
            "    schema['resources'] = default_update_resource_schema()",
            "",
            "    # Users can (optionally) supply the package id when updating a package, but",
            "    # only to identify the package to be updated, they cannot change the id.",
            "    schema['id'] = [ignore_missing, package_id_not_changed]",
            "",
            "    # Supplying the package name when updating a package is optional (you can",
            "    # supply the id to identify the package instead).",
            "    schema['name'] = [ignore_missing, name_validator, package_name_validator,",
            "                      unicode_safe]",
            "",
            "    # Supplying the package title when updating a package is optional, if it's",
            "    # not supplied the title will not be changed.",
            "    schema['title'] = [ignore_missing, unicode_safe]",
            "",
            "    schema['owner_org'] = [ignore_missing, owner_org_validator, unicode_safe]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_show_package_schema(",
            "        keep_extras, ignore_missing, clean_format, unicode_safe, not_empty):",
            "    schema = default_create_package_schema()",
            "",
            "    # Don't strip ids from package dicts when validating them.",
            "    schema['id'] = []",
            "",
            "    schema.update({",
            "        'tags': {'__extras': [keep_extras]}})",
            "",
            "    # Add several keys to the 'resources' subschema so they don't get stripped",
            "    # from the resource dicts by validation.",
            "    schema['resources'].update({",
            "        'format': [ignore_missing, clean_format, unicode_safe],",
            "        'created': [ignore_missing],",
            "        'position': [not_empty],",
            "        'last_modified': [],",
            "        'cache_last_updated': [],",
            "        'package_id': [],",
            "        'size': [],",
            "        'state': [],",
            "        'mimetype': [],",
            "        'cache_url': [],",
            "        'name': [],",
            "        'description': [],",
            "        'mimetype_inner': [],",
            "        'resource_type': [],",
            "        'url_type': [],",
            "    })",
            "",
            "    schema.update({",
            "        'state': [ignore_missing],",
            "        'isopen': [ignore_missing],",
            "        'license_url': [ignore_missing],",
            "    })",
            "",
            "    schema['groups'].update({",
            "        'description': [ignore_missing],",
            "        'display_name': [ignore_missing],",
            "        'image_display_url': [ignore_missing],",
            "    })",
            "",
            "    # Remove validators for several keys from the schema so validation doesn't",
            "    # strip the keys from the package dicts if the values are 'missing' (i.e.",
            "    # None).",
            "    schema['author'] = []",
            "    schema['author_email'] = []",
            "    schema['maintainer'] = []",
            "    schema['maintainer_email'] = []",
            "    schema['license_id'] = []",
            "    schema['notes'] = []",
            "    schema['url'] = []",
            "    schema['version'] = []",
            "",
            "    # Add several keys that are missing from default_create_package_schema(),",
            "    # so validation doesn't strip the keys from the package dicts.",
            "    schema['metadata_created'] = []",
            "    schema['metadata_modified'] = []",
            "    schema['creator_user_id'] = []",
            "    schema['num_resources'] = []",
            "    schema['num_tags'] = []",
            "    schema['organization'] = []",
            "    schema['owner_org'] = []",
            "    schema['private'] = []",
            "    schema['tracking_summary'] = [ignore_missing]",
            "    schema['license_title'] = []",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_group_schema(",
            "        ignore_missing, unicode_safe, ignore, not_empty, name_validator,",
            "        group_name_validator, package_id_or_name_exists,",
            "        no_loops_in_hierarchy, ignore_not_group_admin):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe],",
            "        'name': [",
            "            not_empty, unicode_safe, name_validator, group_name_validator],",
            "        'title': [ignore_missing, unicode_safe],",
            "        'description': [ignore_missing, unicode_safe],",
            "        'image_url': [ignore_missing, unicode_safe],",
            "        'image_display_url': [ignore_missing, unicode_safe],",
            "        'type': [ignore_missing, unicode_safe],",
            "        'state': [ignore_not_group_admin, ignore_missing],",
            "        'created': [ignore],",
            "        'is_organization': [ignore_missing],",
            "        'approval_status': [ignore_missing, unicode_safe],",
            "        'extras': default_extras_schema(),",
            "        '__extras': [ignore],",
            "        '__junk': [ignore],",
            "        'packages': {",
            "            \"id\": [not_empty, unicode_safe, package_id_or_name_exists],",
            "            \"title\": [ignore_missing, unicode_safe],",
            "            \"name\": [ignore_missing, unicode_safe],",
            "            \"__extras\": [ignore]",
            "        },",
            "        'users': {",
            "            \"name\": [not_empty, unicode_safe],",
            "            \"capacity\": [ignore_missing],",
            "            \"__extras\": [ignore]",
            "        },",
            "        'groups': {",
            "            \"name\": [not_empty, no_loops_in_hierarchy, unicode_safe],",
            "            \"capacity\": [ignore_missing],",
            "            \"__extras\": [ignore]",
            "        }",
            "    }",
            "",
            "",
            "@validator_args",
            "def group_form_schema(",
            "        not_empty, unicode_safe, ignore_missing, ignore):",
            "    schema = default_group_schema()",
            "    # schema['extras_validation'] = [duplicate_extras_key, ignore]",
            "    schema['packages'] = {",
            "        \"name\": [not_empty, unicode_safe],",
            "        \"title\": [ignore_missing],",
            "        \"__extras\": [ignore]",
            "    }",
            "    schema['users'] = {",
            "        \"name\": [not_empty, unicode_safe],",
            "        \"capacity\": [ignore_missing],",
            "        \"__extras\": [ignore]",
            "    }",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_group_schema(",
            "        ignore_missing, group_name_validator, unicode_safe):",
            "    schema = default_group_schema()",
            "    schema[\"name\"] = [ignore_missing, group_name_validator, unicode_safe]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_show_group_schema(",
            "        keep_extras, ignore_missing):",
            "    schema = default_group_schema()",
            "",
            "    # make default show schema behave like when run with no validation",
            "    schema['num_followers'] = []",
            "    schema['created'] = []",
            "    schema['display_name'] = []",
            "    schema['extras'] = {'__extras': [keep_extras]}",
            "    schema['package_count'] = [ignore_missing]",
            "    schema['packages'] = {'__extras': [keep_extras]}",
            "    schema['state'] = []",
            "    schema['users'] = {'__extras': [keep_extras]}",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_extras_schema(",
            "        ignore, not_empty, extra_key_not_in_root_schema, unicode_safe,",
            "        not_missing, ignore_missing):",
            "    return {",
            "        'id': [ignore],",
            "        'key': [not_empty, extra_key_not_in_root_schema, unicode_safe],",
            "        'value': [not_missing],",
            "        'state': [ignore],",
            "        'deleted': [ignore_missing],",
            "        'revision_timestamp': [ignore],",
            "        '__extras': [ignore],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_relationship_schema(",
            "        ignore_missing, unicode_safe, not_empty, one_of, ignore):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe],",
            "        'subject': [ignore_missing, unicode_safe],",
            "        'object': [ignore_missing, unicode_safe],",
            "        'type': [not_empty,",
            "                 one_of(ckan.model.PackageRelationship.get_all_types())],",
            "        'comment': [ignore_missing, unicode_safe],",
            "        'state': [ignore],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_relationship_schema(",
            "        empty, not_empty, unicode_safe, package_id_or_name_exists):",
            "    schema = default_relationship_schema()",
            "    schema['id'] = [empty]",
            "    schema['subject'] = [not_empty, unicode_safe, package_id_or_name_exists]",
            "    schema['object'] = [not_empty, unicode_safe, package_id_or_name_exists]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_relationship_schema(",
            "        ignore_missing, package_id_not_changed):",
            "    schema = default_relationship_schema()",
            "    schema['id'] = [ignore_missing, package_id_not_changed]",
            "",
            "    # Todo: would like to check subject, object & type haven't changed, but",
            "    # no way to do this in schema",
            "    schema['subject'] = [ignore_missing]",
            "    schema['object'] = [ignore_missing]",
            "    schema['type'] = [ignore_missing]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_user_schema(",
            "        ignore_missing, unicode_safe, name_validator, user_name_validator,",
            "        user_password_validator, user_password_not_empty, email_is_unique,",
            "        ignore_not_sysadmin, not_empty, email_validator,",
            "        user_about_validator, ignore, boolean_validator, json_object):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe],",
            "        'name': [",
            "            not_empty, name_validator, user_name_validator, unicode_safe],",
            "        'fullname': [ignore_missing, unicode_safe],",
            "        'password': [user_password_validator, user_password_not_empty,",
            "                     ignore_missing, unicode_safe],",
            "        'password_hash': [ignore_missing, ignore_not_sysadmin, unicode_safe],",
            "        'email': [not_empty, email_validator, email_is_unique, unicode_safe],",
            "        'about': [ignore_missing, user_about_validator, unicode_safe],",
            "        'created': [ignore],",
            "        'sysadmin': [ignore_missing, ignore_not_sysadmin],",
            "        'apikey': [ignore],",
            "        'reset_key': [ignore],",
            "        'activity_streams_email_notifications': [ignore_missing,",
            "                                                 boolean_validator],",
            "        'state': [ignore_missing, ignore_not_sysadmin],",
            "        'image_url': [ignore_missing, unicode_safe],",
            "        'image_display_url': [ignore_missing, unicode_safe],",
            "        'plugin_extras': [ignore_missing, json_object, ignore_not_sysadmin],",
            "    }",
            "",
            "",
            "@validator_args",
            "def user_new_form_schema(",
            "        unicode_safe, user_both_passwords_entered,",
            "        user_password_validator, user_passwords_match):",
            "    schema = default_user_schema()",
            "",
            "    schema['password1'] = [text_type, user_both_passwords_entered,",
            "                           user_password_validator, user_passwords_match]",
            "    schema['password2'] = [text_type]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def user_edit_form_schema(",
            "        ignore_missing, unicode_safe, user_password_validator,",
            "        user_passwords_match):",
            "    schema = default_user_schema()",
            "",
            "    schema['password'] = [ignore_missing]",
            "    schema['password1'] = [ignore_missing, unicode_safe,",
            "                           user_password_validator, user_passwords_match]",
            "    schema['password2'] = [ignore_missing, unicode_safe]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_user_schema(",
            "        ignore_missing, name_validator, user_name_validator,",
            "        unicode_safe, user_password_validator, email_is_unique,",
            "        not_empty, email_validator):",
            "    schema = default_user_schema()",
            "",
            "    schema['name'] = [",
            "        ignore_missing, name_validator, user_name_validator, unicode_safe]",
            "    schema['password'] = [",
            "        user_password_validator, ignore_missing, unicode_safe]",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_generate_apikey_user_schema(",
            "        not_empty, unicode_safe):",
            "    schema = default_update_user_schema()",
            "",
            "    schema['apikey'] = [not_empty, unicode_safe]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_user_invite_schema(",
            "        not_empty, email_validator, email_is_unique):",
            "    return {",
            "        'email': [not_empty, email_validator, email_is_unique, text_type],",
            "        'group_id': [not_empty],",
            "        'role': [not_empty],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_task_status_schema(",
            "        ignore, not_empty, unicode_safe, ignore_missing):",
            "    return {",
            "        'id': [ignore],",
            "        'entity_id': [not_empty, unicode_safe],",
            "        'entity_type': [not_empty, unicode_safe],",
            "        'task_type': [not_empty, unicode_safe],",
            "        'key': [not_empty, unicode_safe],",
            "        'value': [ignore_missing],",
            "        'state': [ignore_missing],",
            "        'last_updated': [ignore_missing],",
            "        'error': [ignore_missing]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_vocabulary_schema(",
            "        ignore_missing, unicode_safe, vocabulary_id_exists,",
            "        not_empty, vocabulary_name_validator):",
            "    return {",
            "        'id': [ignore_missing, unicode_safe, vocabulary_id_exists],",
            "        'name': [not_empty, unicode_safe, vocabulary_name_validator],",
            "        'tags': default_tags_schema(),",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_vocabulary_schema(",
            "        empty):",
            "    schema = default_vocabulary_schema()",
            "    schema['id'] = [empty]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_vocabulary_schema(",
            "        ignore_missing, vocabulary_id_not_changed,",
            "        vocabulary_name_validator):",
            "    schema = default_vocabulary_schema()",
            "    schema['id'] = [ignore_missing, vocabulary_id_not_changed]",
            "    schema['name'] = [ignore_missing, vocabulary_name_validator]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_create_activity_schema(",
            "        ignore, not_missing, not_empty, unicode_safe,",
            "        convert_user_name_or_id_to_id, object_id_validator,",
            "        activity_type_exists, ignore_empty, ignore_missing):",
            "    return {",
            "        'id': [ignore],",
            "        'timestamp': [ignore],",
            "        'user_id': [not_missing, not_empty, unicode_safe,",
            "                    convert_user_name_or_id_to_id],",
            "        'object_id': [",
            "            not_missing, not_empty, unicode_safe, object_id_validator],",
            "        'activity_type': [not_missing, not_empty, unicode_safe,",
            "                          activity_type_exists],",
            "        'data': [ignore_empty, ignore_missing],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_follow_user_schema(",
            "        not_missing, not_empty, unicode_safe, convert_user_name_or_id_to_id,",
            "        ignore_missing):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe,",
            "               convert_user_name_or_id_to_id],",
            "        'q': [ignore_missing]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_follow_dataset_schema(",
            "        not_missing, not_empty, unicode_safe,",
            "        convert_package_name_or_id_to_id):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe,",
            "               convert_package_name_or_id_to_id]",
            "    }",
            "",
            "",
            "@validator_args",
            "def member_schema(",
            "        not_missing, group_id_or_name_exists, unicode_safe,",
            "        user_id_or_name_exists, role_exists):",
            "    return {",
            "        'id': [not_missing, group_id_or_name_exists, unicode_safe],",
            "        'username': [not_missing, user_id_or_name_exists, unicode_safe],",
            "        'role': [not_missing, role_exists, unicode_safe],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_follow_group_schema(",
            "        not_missing, not_empty, unicode_safe,",
            "        convert_group_name_or_id_to_id):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe,",
            "               convert_group_name_or_id_to_id]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_package_list_schema(",
            "        ignore_missing, natural_number_validator, is_positive_integer):",
            "    return {",
            "        'limit': [ignore_missing, natural_number_validator],",
            "        'offset': [ignore_missing, natural_number_validator],",
            "        'page': [ignore_missing, is_positive_integer]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_pagination_schema(ignore_missing, natural_number_validator):",
            "    return {",
            "        'limit': [ignore_missing, natural_number_validator],",
            "        'offset': [ignore_missing, natural_number_validator]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_dashboard_activity_list_schema(",
            "        configured_default, natural_number_validator,",
            "        limit_to_configured_maximum):",
            "    schema = default_pagination_schema()",
            "    schema['limit'] = [",
            "        configured_default('ckan.activity_list_limit', 31),",
            "        natural_number_validator,",
            "        limit_to_configured_maximum('ckan.activity_list_limit_max', 100)]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_activity_list_schema(",
            "        not_missing, unicode_safe, configured_default,",
            "        natural_number_validator, limit_to_configured_maximum,",
            "        ignore_missing, boolean_validator, ignore_not_sysadmin):",
            "    schema = default_pagination_schema()",
            "    schema['id'] = [not_missing, unicode_safe]",
            "    schema['limit'] = [",
            "        configured_default('ckan.activity_list_limit', 31),",
            "        natural_number_validator,",
            "        limit_to_configured_maximum('ckan.activity_list_limit_max', 100)]",
            "    schema['include_hidden_activity'] = [",
            "        ignore_missing, ignore_not_sysadmin, boolean_validator]",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_autocomplete_schema(",
            "        not_missing, unicode_safe, ignore_missing, natural_number_validator):",
            "    return {",
            "        'q': [not_missing, unicode_safe],",
            "        'ignore_self': [ignore_missing],",
            "        'limit': [ignore_missing, natural_number_validator]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_package_search_schema(",
            "        ignore_missing, unicode_safe, list_of_strings,",
            "        natural_number_validator, int_validator, convert_to_json_if_string,",
            "        convert_to_list_if_string, limit_to_configured_maximum, default):",
            "    return {",
            "        'q': [ignore_missing, unicode_safe],",
            "        'fl': [ignore_missing, convert_to_list_if_string],",
            "        'fq': [ignore_missing, unicode_safe],",
            "        'rows': [default(10), natural_number_validator,",
            "                 limit_to_configured_maximum('ckan.search.rows_max', 1000)],",
            "        'sort': [ignore_missing, unicode_safe],",
            "        'start': [ignore_missing, natural_number_validator],",
            "        'qf': [ignore_missing, unicode_safe],",
            "        'facet': [ignore_missing, unicode_safe],",
            "        'facet.mincount': [ignore_missing, natural_number_validator],",
            "        'facet.limit': [ignore_missing, int_validator],",
            "        'facet.field': [ignore_missing, convert_to_json_if_string,",
            "                        list_of_strings],",
            "        'extras': [ignore_missing]  # Not used by Solr,",
            "                                    # but useful for extensions",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_resource_search_schema(",
            "        ignore_missing, unicode_safe, natural_number_validator):",
            "    schema = {",
            "        'query': [ignore_missing],  # string or list of strings",
            "        'fields': [ignore_missing],  # dict of fields",
            "        'order_by': [ignore_missing, unicode_safe],",
            "        'offset': [ignore_missing, natural_number_validator],",
            "        'limit': [ignore_missing, natural_number_validator]",
            "    }",
            "    return schema",
            "",
            "",
            "def create_schema_for_required_keys(keys):",
            "    ''' helper function that creates a schema definition where",
            "    each key from keys is validated against ``not_missing``.",
            "    '''",
            "    not_missing = get_validator('not_missing')",
            "    return {x: [not_missing] for x in keys}",
            "",
            "",
            "def default_create_resource_view_schema(resource_view):",
            "    if resource_view.info().get('filterable'):",
            "        return default_create_resource_view_schema_filtered()",
            "    return default_create_resource_view_schema_unfiltered()",
            "",
            "",
            "@validator_args",
            "def default_create_resource_view_schema_unfiltered(",
            "        not_empty, resource_id_exists, unicode_safe, ignore_missing, empty):",
            "    return {",
            "        'resource_id': [not_empty, resource_id_exists],",
            "        'title': [not_empty, unicode_safe],",
            "        'description': [ignore_missing, unicode_safe],",
            "        'view_type': [not_empty, unicode_safe],",
            "        '__extras': [empty],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_resource_view_schema_filtered(",
            "        ignore_missing, convert_to_list_if_string,",
            "        filter_fields_and_values_should_have_same_length,",
            "        filter_fields_and_values_exist_and_are_valid):",
            "    schema = default_create_resource_view_schema_unfiltered()",
            "    schema['filter_fields'] = [",
            "        ignore_missing,",
            "        convert_to_list_if_string,",
            "        filter_fields_and_values_should_have_same_length,",
            "        filter_fields_and_values_exist_and_are_valid]",
            "    schema['filter_values'] = [ignore_missing, convert_to_list_if_string]",
            "    return schema",
            "",
            "",
            "def default_update_resource_view_schema(resource_view):",
            "    schema = default_create_resource_view_schema(resource_view)",
            "    schema.update(default_update_resource_view_schema_changes())",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def default_update_resource_view_schema_changes(",
            "        not_missing, not_empty, unicode_safe, resource_id_exists, ignore,",
            "        ignore_missing):",
            "    return {",
            "        'id': [not_missing, not_empty, unicode_safe],",
            "        'resource_id': [ignore_missing, resource_id_exists],",
            "        'title': [ignore_missing, unicode_safe],",
            "        'view_type': [ignore],  # cannot change after create",
            "        'package_id': [ignore]",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_update_configuration_schema(",
            "        unicode_safe, is_positive_integer, ignore_missing):",
            "    return {",
            "        'ckan.site_title': [ignore_missing, unicode_safe],",
            "        'ckan.site_logo': [ignore_missing, unicode_safe],",
            "        'ckan.site_url': [ignore_missing, unicode_safe],",
            "        'ckan.site_description': [ignore_missing, unicode_safe],",
            "        'ckan.site_about': [ignore_missing, unicode_safe],",
            "        'ckan.site_intro_text': [ignore_missing, unicode_safe],",
            "        'ckan.site_custom_css': [ignore_missing, unicode_safe],",
            "        'ckan.theme': [ignore_missing, unicode_safe],",
            "        'ckan.homepage_style': [ignore_missing, is_positive_integer],",
            "        'logo_upload': [ignore_missing, unicode_safe],",
            "        'clear_logo_upload': [ignore_missing, unicode_safe],",
            "    }",
            "",
            "",
            "def update_configuration_schema():",
            "    '''",
            "    Returns the schema for the config options that can be edited during runtime",
            "",
            "    By default these are the keys of the",
            "    :py:func:`ckan.logic.schema.default_update_configuration_schema`.",
            "    Extensions can add or remove keys from this schema using the",
            "    :py:meth:`ckan.plugins.interfaces.IConfigurer.update_config_schema`",
            "    method.",
            "",
            "    These configuration options can be edited during runtime via the web",
            "    interface or using",
            "    the :py:func:`ckan.logic.action.update.config_option_update` API call.",
            "",
            "    :returns: a dictionary mapping runtime-editable configuration option keys",
            "      to lists of validator and converter functions to be applied to those",
            "      keys",
            "    :rtype: dictionary",
            "    '''",
            "",
            "    schema = default_update_configuration_schema()",
            "    for plugin in plugins.PluginImplementations(plugins.IConfigurer):",
            "        if hasattr(plugin, 'update_config_schema'):",
            "            schema = plugin.update_config_schema(schema)",
            "",
            "    return schema",
            "",
            "",
            "@validator_args",
            "def job_list_schema(ignore_missing, list_of_strings):",
            "    return {",
            "        u'queues': [ignore_missing, list_of_strings],",
            "    }",
            "",
            "",
            "@validator_args",
            "def job_clear_schema(ignore_missing, list_of_strings):",
            "    return {",
            "        u'queues': [ignore_missing, list_of_strings],",
            "    }",
            "",
            "",
            "@validator_args",
            "def default_create_api_token_schema(",
            "        not_empty, unicode_safe,",
            "        ignore_missing, json_object, ignore_not_sysadmin):",
            "    return {",
            "        u'name': [not_empty, unicode_safe],",
            "        u'user': [not_empty, unicode_safe],",
            "        u'plugin_extras': [ignore_missing, json_object, ignore_not_sysadmin],",
            "    }",
            "",
            "",
            "@validator_args",
            "def package_revise_schema(",
            "        ignore_missing, list_of_strings,",
            "        collect_prefix_validate, json_or_string,",
            "        json_list_or_string, dict_only):",
            "    return {",
            "        u'__before': [",
            "            collect_prefix_validate(",
            "                u'match__', u'json_or_string'),",
            "            collect_prefix_validate(",
            "                u'update__', u'json_or_string')],",
            "        u'match': [",
            "            ignore_missing, json_or_string, dict_only],",
            "        u'filter': [",
            "            ignore_missing, json_list_or_string, list_of_strings],",
            "        u'update': [",
            "            ignore_missing, json_or_string, dict_only],",
            "        u'include': [",
            "            ignore_missing, json_list_or_string, list_of_strings],",
            "        # collect_prefix moves values to these, always dicts:",
            "        u'match__': [],",
            "        u'update__': [],",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "32": [
                "default_resource_schema"
            ],
            "34": [
                "default_resource_schema"
            ]
        },
        "addLocation": []
    },
    "ckan/logic/validators.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from six import string_types, iteritems"
            },
            "1": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " from six.moves.urllib.parse import urlparse"
            },
            "2": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 15,
                "PatchRowcode": "+from sqlalchemy.orm.exc import NoResultFound"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import ckan.lib.navl.dictization_functions as df"
            },
            "6": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " import ckan.logic as logic"
            },
            "7": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import ckan.lib.helpers as h"
            },
            "8": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 190,
                "PatchRowcode": "         raise Invalid(_('Dataset id already exists'))"
            },
            "9": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "     return value"
            },
            "10": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 192,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 193,
                "PatchRowcode": "+"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+def resource_id_does_not_exist(key, data, errors, context):"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+    session = context['session']"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 196,
                "PatchRowcode": "+    model = context['model']"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 197,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 198,
                "PatchRowcode": "+    if data[key] is missing:"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 199,
                "PatchRowcode": "+        return"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 200,
                "PatchRowcode": "+    resource_id = data[key]"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 201,
                "PatchRowcode": "+    assert key[0] == 'resources', ('validator depends on resource schema '"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 202,
                "PatchRowcode": "+                                   'validating as part of package schema')"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 203,
                "PatchRowcode": "+    package_id = data.get(('id',))"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 204,
                "PatchRowcode": "+    query = session.query(model.Resource.package_id).filter("
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 205,
                "PatchRowcode": "+        model.Resource.id == resource_id,"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 206,
                "PatchRowcode": "+        model.Resource.state != State.DELETED,"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+    )"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 208,
                "PatchRowcode": "+    try:"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+        [parent_id] = query.one()"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+    except NoResultFound:"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+        return"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+    if parent_id != package_id:"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+        errors[key].append(_('Resource id already exists.'))"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 215,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 216,
                "PatchRowcode": " def package_name_exists(value, context):"
            },
            "35": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 217,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 218,
                "PatchRowcode": "     model = context['model']"
            },
            "37": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 255,
                "PatchRowcode": "     return value"
            },
            "38": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": 256,
                "PatchRowcode": " "
            },
            "39": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 257,
                "PatchRowcode": " "
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+def resource_id_validator(value):"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+    pattern = re.compile(\"[^0-9a-zA-Z _-]\")"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+    if pattern.search(value):"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+        raise Invalid(_('Invalid characters in resource id'))"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+    if len(value) < 7 or len(value) > 100:"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+        raise Invalid(_('Invalid length for resource id'))"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+    return value"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 265,
                "PatchRowcode": "+"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 266,
                "PatchRowcode": "+"
            },
            "49": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 267,
                "PatchRowcode": " def user_id_exists(user_id, context):"
            },
            "50": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 268,
                "PatchRowcode": "     '''Raises Invalid if the given user_id does not exist in the model given"
            },
            "51": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 269,
                "PatchRowcode": "     in the context, otherwise returns the given user_id."
            }
        },
        "frontPatchFile": [
            "",
            "# encoding: utf-8",
            "",
            "import collections",
            "import datetime",
            "from itertools import count",
            "import re",
            "import mimetypes",
            "import string",
            "import json",
            "",
            "from six import string_types, iteritems",
            "from six.moves.urllib.parse import urlparse",
            "",
            "import ckan.lib.navl.dictization_functions as df",
            "import ckan.logic as logic",
            "import ckan.lib.helpers as h",
            "from ckan.model import (MAX_TAG_LENGTH, MIN_TAG_LENGTH,",
            "                        PACKAGE_NAME_MIN_LENGTH, PACKAGE_NAME_MAX_LENGTH,",
            "                        PACKAGE_VERSION_MAX_LENGTH,",
            "                        VOCABULARY_NAME_MAX_LENGTH,",
            "                        VOCABULARY_NAME_MIN_LENGTH)",
            "import ckan.authz as authz",
            "from ckan.model.core import State",
            "",
            "from ckan.common import _",
            "",
            "Invalid = df.Invalid",
            "StopOnError = df.StopOnError",
            "Missing = df.Missing",
            "missing = df.missing",
            "",
            "",
            "def owner_org_validator(key, data, errors, context):",
            "",
            "    value = data.get(key)",
            "",
            "    if value is missing or value is None:",
            "        if not authz.check_config_permission('create_unowned_dataset'):",
            "            raise Invalid(_('An organization must be provided'))",
            "        data.pop(key, None)",
            "        raise df.StopOnError",
            "",
            "    model = context['model']",
            "    user = context['user']",
            "    user = model.User.get(user)",
            "    package = context.get('package')",
            "",
            "    if value == '':",
            "        if not authz.check_config_permission('create_unowned_dataset'):",
            "            raise Invalid(_('An organization must be provided'))",
            "        return",
            "",
            "    if (authz.check_config_permission('allow_dataset_collaborators')",
            "            and not authz.check_config_permission('allow_collaborators_to_change_owner_org')):",
            "",
            "        if package and user and not user.sysadmin:",
            "            is_collaborator = authz.user_is_collaborator_on_dataset(",
            "                user.id, package.id, ['admin', 'editor'])",
            "            if is_collaborator:",
            "                # User is a collaborator, check if it's also a member with",
            "                # edit rights of the current organization (redundant, but possible)",
            "                user_orgs = logic.get_action(",
            "                    'organization_list_for_user')(",
            "                        {'ignore_auth': True}, {'id': user.id, 'permission': 'update_dataset'})",
            "                user_is_org_member = package.owner_org in [org['id'] for org in user_orgs]",
            "                if data.get(key) != package.owner_org and not user_is_org_member:",
            "                    raise Invalid(_('You cannot move this dataset to another organization'))",
            "",
            "    group = model.Group.get(value)",
            "    if not group:",
            "        raise Invalid(_('Organization does not exist'))",
            "    group_id = group.id",
            "",
            "    if not package or (package and package.owner_org != group_id):",
            "        # This is a new dataset or we are changing the organization",
            "        if not context.get(u'ignore_auth', False) and not(user.sysadmin or",
            "               authz.has_user_permission_for_group_or_org(",
            "                   group_id, user.name, 'create_dataset')):",
            "            raise Invalid(_('You cannot add a dataset to this organization'))",
            "",
            "    data[key] = group_id",
            "",
            "",
            "def package_id_not_changed(value, context):",
            "",
            "    package = context.get('package')",
            "    if package and value != package.id:",
            "        raise Invalid('Cannot change value of key from %s to %s. '",
            "                      'This key is read-only' % (package.id, value))",
            "    return value",
            "",
            "def int_validator(value, context):",
            "    '''",
            "    Return an integer for value, which may be a string in base 10 or",
            "    a numeric type (e.g. int, long, float, Decimal, Fraction). Return",
            "    None for None or empty/all-whitespace string values.",
            "",
            "    :raises: ckan.lib.navl.dictization_functions.Invalid for other",
            "        inputs or non-whole values",
            "    '''",
            "    if value is None:",
            "        return None",
            "    if hasattr(value, 'strip') and not value.strip():",
            "        return None",
            "",
            "    try:",
            "        whole, part = divmod(value, 1)",
            "    except TypeError:",
            "        try:",
            "            return int(value)",
            "        except (TypeError, ValueError):",
            "            pass",
            "    else:",
            "        if not part:",
            "            try:",
            "                return int(whole)",
            "            except TypeError:",
            "                pass  # complex number: fail like int(complex) does",
            "",
            "    raise Invalid(_('Invalid integer'))",
            "",
            "def natural_number_validator(value, context):",
            "    value = int_validator(value, context)",
            "    if value < 0:",
            "        raise Invalid(_('Must be a natural number'))",
            "    return value",
            "",
            "def is_positive_integer(value, context):",
            "    value = int_validator(value, context)",
            "    if value < 1:",
            "        raise Invalid(_('Must be a postive integer'))",
            "    return value",
            "",
            "def boolean_validator(value, context):",
            "    '''",
            "    Return a boolean for value.",
            "    Return value when value is a python bool type.",
            "    Return True for strings 'true', 'yes', 't', 'y', and '1'.",
            "    Return False in all other cases, including when value is an empty string or",
            "    None",
            "    '''",
            "    if value is missing or value is None:",
            "        return False",
            "    if isinstance(value, bool):",
            "        return value",
            "    if value.lower() in ['true', 'yes', 't', 'y', '1']:",
            "        return True",
            "    return False",
            "",
            "def isodate(value, context):",
            "    if isinstance(value, datetime.datetime):",
            "        return value",
            "    if value == '':",
            "        return None",
            "    try:",
            "        date = h.date_str_to_datetime(value)",
            "    except (TypeError, ValueError) as e:",
            "        raise Invalid(_('Date format incorrect'))",
            "    return date",
            "",
            "def no_http(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    if 'http:' in value:",
            "        raise Invalid(_('No links are allowed in the log_message.'))",
            "    return value",
            "",
            "def package_id_exists(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).get(value)",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Dataset')))",
            "    return value",
            "",
            "def package_id_does_not_exist(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).get(value)",
            "    if result:",
            "        raise Invalid(_('Dataset id already exists'))",
            "    return value",
            "",
            "def package_name_exists(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).filter_by(name=value).first()",
            "",
            "    if not result:",
            "        raise Invalid(_('Not found') + ': %s' % value)",
            "    return value",
            "",
            "def package_id_or_name_exists(package_id_or_name, context):",
            "    '''Return the given package_id_or_name if such a package exists.",
            "",
            "    :raises: ckan.lib.navl.dictization_functions.Invalid if there is no",
            "        package with the given id or name",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).get(package_id_or_name)",
            "    if result:",
            "        return package_id_or_name",
            "",
            "    result = session.query(model.Package).filter_by(",
            "            name=package_id_or_name).first()",
            "",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Dataset')))",
            "",
            "    return package_id_or_name",
            "",
            "",
            "def resource_id_exists(value, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    if not session.query(model.Resource).get(value):",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Resource')))",
            "    return value",
            "",
            "",
            "def user_id_exists(user_id, context):",
            "    '''Raises Invalid if the given user_id does not exist in the model given",
            "    in the context, otherwise returns the given user_id.",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.User).get(user_id)",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('User')))",
            "    return user_id",
            "",
            "def user_id_or_name_exists(user_id_or_name, context):",
            "    '''Return the given user_id_or_name if such a user exists.",
            "",
            "    :raises: ckan.lib.navl.dictization_functions.Invalid if no user can be",
            "        found with the given id or user name",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "    result = session.query(model.User).get(user_id_or_name)",
            "    if result:",
            "        return user_id_or_name",
            "    result = session.query(model.User).filter_by(name=user_id_or_name).first()",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('User')))",
            "    return user_id_or_name",
            "",
            "def group_id_exists(group_id, context):",
            "    '''Raises Invalid if the given group_id does not exist in the model given",
            "    in the context, otherwise returns the given group_id.",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Group).get(group_id)",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Group')))",
            "    return group_id",
            "",
            "def group_id_or_name_exists(reference, context):",
            "    '''",
            "    Raises Invalid if a group identified by the name or id cannot be found.",
            "    '''",
            "    model = context['model']",
            "    result = model.Group.get(reference)",
            "    if not result:",
            "        raise Invalid(_('That group name or ID does not exist.'))",
            "    return reference",
            "",
            "def activity_type_exists(activity_type):",
            "    '''Raises Invalid if there is no registered activity renderer for the",
            "    given activity_type. Otherwise returns the given activity_type.",
            "",
            "    This just uses object_id_validators as a lookup.",
            "    very safe.",
            "",
            "    '''",
            "    if activity_type in object_id_validators:",
            "        return activity_type",
            "    else:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Activity type')))",
            "",
            "",
            "# A dictionary mapping activity_type values from activity dicts to functions",
            "# for validating the object_id values from those same activity dicts.",
            "object_id_validators = {",
            "    'new package' : package_id_exists,",
            "    'changed package' : package_id_exists,",
            "    'deleted package' : package_id_exists,",
            "    'follow dataset' : package_id_exists,",
            "    'new user' : user_id_exists,",
            "    'changed user' : user_id_exists,",
            "    'follow user' : user_id_exists,",
            "    'new group' : group_id_exists,",
            "    'changed group' : group_id_exists,",
            "    'deleted group' : group_id_exists,",
            "    'new organization' : group_id_exists,",
            "    'changed organization' : group_id_exists,",
            "    'deleted organization' : group_id_exists,",
            "    'follow group' : group_id_exists,",
            "    }",
            "",
            "def object_id_validator(key, activity_dict, errors, context):",
            "    '''Validate the 'object_id' value of an activity_dict.",
            "",
            "    Uses the object_id_validators dict (above) to find and call an 'object_id'",
            "    validator function for the given activity_dict's 'activity_type' value.",
            "",
            "    Raises Invalid if the model given in context contains no object of the",
            "    correct type (according to the 'activity_type' value of the activity_dict)",
            "    with the given ID.",
            "",
            "    Raises Invalid if there is no object_id_validator for the activity_dict's",
            "    'activity_type' value.",
            "",
            "    '''",
            "    activity_type = activity_dict[('activity_type',)]",
            "    if activity_type in object_id_validators:",
            "        object_id = activity_dict[('object_id',)]",
            "        return object_id_validators[activity_type](object_id, context)",
            "    else:",
            "        raise Invalid('There is no object_id validator for '",
            "            'activity type \"%s\"' % activity_type)",
            "",
            "name_match = re.compile('[a-z0-9_\\-]*$')",
            "def name_validator(value, context):",
            "    '''Return the given value if it's a valid name, otherwise raise Invalid.",
            "",
            "    If it's a valid name, the given value will be returned unmodified.",
            "",
            "    This function applies general validation rules for names of packages,",
            "    groups, users, etc.",
            "",
            "    Most schemas also have their own custom name validator function to apply",
            "    custom validation rules after this function, for example a",
            "    ``package_name_validator()`` to check that no package with the given name",
            "    already exists.",
            "",
            "    :raises ckan.lib.navl.dictization_functions.Invalid: if ``value`` is not",
            "        a valid name",
            "",
            "    '''",
            "    if not isinstance(value, string_types):",
            "        raise Invalid(_('Names must be strings'))",
            "",
            "    # check basic textual rules",
            "    if value in ['new', 'edit', 'search']:",
            "        raise Invalid(_('That name cannot be used'))",
            "",
            "    if len(value) < 2:",
            "        raise Invalid(_('Must be at least %s characters long') % 2)",
            "    if len(value) > PACKAGE_NAME_MAX_LENGTH:",
            "        raise Invalid(_('Name must be a maximum of %i characters long') % \\",
            "                      PACKAGE_NAME_MAX_LENGTH)",
            "    if not name_match.match(value):",
            "        raise Invalid(_('Must be purely lowercase alphanumeric '",
            "                        '(ascii) characters and these symbols: -_'))",
            "    return value",
            "",
            "def package_name_validator(key, data, errors, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    package = context.get('package')",
            "",
            "    query = session.query(model.Package.state).filter_by(name=data[key])",
            "    if package:",
            "        package_id = package.id",
            "    else:",
            "        package_id = data.get(key[:-1] + ('id',))",
            "    if package_id and package_id is not missing:",
            "        query = query.filter(model.Package.id != package_id)",
            "    result = query.first()",
            "    if result and result.state != State.DELETED:",
            "        errors[key].append(_('That URL is already in use.'))",
            "",
            "    value = data[key]",
            "    if len(value) < PACKAGE_NAME_MIN_LENGTH:",
            "        raise Invalid(",
            "            _('Name \"%s\" length is less than minimum %s') % (value, PACKAGE_NAME_MIN_LENGTH)",
            "        )",
            "    if len(value) > PACKAGE_NAME_MAX_LENGTH:",
            "        raise Invalid(",
            "            _('Name \"%s\" length is more than maximum %s') % (value, PACKAGE_NAME_MAX_LENGTH)",
            "        )",
            "",
            "def package_version_validator(value, context):",
            "",
            "    if len(value) > PACKAGE_VERSION_MAX_LENGTH:",
            "        raise Invalid(_('Version must be a maximum of %i characters long') % \\",
            "                      PACKAGE_VERSION_MAX_LENGTH)",
            "    return value",
            "",
            "def duplicate_extras_key(key, data, errors, context):",
            "",
            "    unflattened = df.unflatten(data)",
            "    extras = unflattened.get('extras', [])",
            "    extras_keys = []",
            "    for extra in extras:",
            "        if not extra.get('deleted'):",
            "            extras_keys.append(extra['key'])",
            "",
            "    for extra_key in set(extras_keys):",
            "        extras_keys.remove(extra_key)",
            "    if extras_keys:",
            "        key_ = ('extras_validation',)",
            "        assert key_ not in errors",
            "        errors[key_] = [_('Duplicate key \"%s\"') % extras_keys[0]]",
            "",
            "def group_name_validator(key, data, errors, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    group = context.get('group')",
            "",
            "    query = session.query(model.Group.name).filter_by(name=data[key])",
            "    if group:",
            "        group_id = group.id",
            "    else:",
            "        group_id = data.get(key[:-1] + ('id',))",
            "    if group_id and group_id is not missing:",
            "        query = query.filter(model.Group.id != group_id)",
            "    result = query.first()",
            "    if result:",
            "        errors[key].append(_('Group name already exists in database'))",
            "",
            "def tag_length_validator(value, context):",
            "",
            "    if len(value) < MIN_TAG_LENGTH:",
            "        raise Invalid(",
            "            _('Tag \"%s\" length is less than minimum %s') % (value, MIN_TAG_LENGTH)",
            "        )",
            "    if len(value) > MAX_TAG_LENGTH:",
            "        raise Invalid(",
            "            _('Tag \"%s\" length is more than maximum %i') % (value, MAX_TAG_LENGTH)",
            "        )",
            "    return value",
            "",
            "def tag_name_validator(value, context):",
            "",
            "    tagname_match = re.compile('[\\w \\-.]*$', re.UNICODE)",
            "    if not tagname_match.match(value):",
            "        raise Invalid(_('Tag \"%s\" must be alphanumeric '",
            "                        'characters or symbols: -_.') % (value))",
            "    return value",
            "",
            "def tag_not_uppercase(value, context):",
            "",
            "    tagname_uppercase = re.compile('[A-Z]')",
            "    if tagname_uppercase.search(value):",
            "        raise Invalid(_('Tag \"%s\" must not be uppercase' % (value)))",
            "    return value",
            "",
            "def tag_string_convert(key, data, errors, context):",
            "    '''Takes a list of tags that is a comma-separated string (in data[key])",
            "    and parses tag names. These are added to the data dict, enumerated. They",
            "    are also validated.'''",
            "",
            "    if isinstance(data[key], string_types):",
            "        tags = [tag.strip() \\",
            "                for tag in data[key].split(',') \\",
            "                if tag.strip()]",
            "    else:",
            "        tags = data[key]",
            "",
            "    current_index = max( [int(k[1]) for k in data.keys() if len(k) == 3 and k[0] == 'tags'] + [-1] )",
            "",
            "    for num, tag in zip(count(current_index+1), tags):",
            "        data[('tags', num, 'name')] = tag",
            "",
            "    for tag in tags:",
            "        tag_length_validator(tag, context)",
            "        tag_name_validator(tag, context)",
            "",
            "def ignore_not_admin(key, data, errors, context):",
            "    # Deprecated in favour of ignore_not_package_admin",
            "    return ignore_not_package_admin(key, data, errors, context)",
            "",
            "def ignore_not_package_admin(key, data, errors, context):",
            "    '''Ignore if the user is not allowed to administer the package specified.'''",
            "",
            "    model = context['model']",
            "    user = context.get('user')",
            "",
            "    if 'ignore_auth' in context:",
            "        return",
            "",
            "    if user and authz.is_sysadmin(user):",
            "        return",
            "",
            "    authorized = False",
            "    pkg = context.get('package')",
            "    if pkg:",
            "        try:",
            "            logic.check_access('package_change_state',context)",
            "            authorized = True",
            "        except logic.NotAuthorized:",
            "            authorized = False",
            "",
            "    if (user and pkg and authorized):",
            "        return",
            "",
            "    # allow_state_change in the context will allow the state to be changed",
            "    # FIXME is this the best way to cjeck for state only?",
            "    if key == ('state',) and context.get('allow_state_change'):",
            "        return",
            "    data.pop(key)",
            "",
            "",
            "def ignore_not_sysadmin(key, data, errors, context):",
            "    '''Ignore the field if user not sysadmin or ignore_auth in context.'''",
            "",
            "    user = context.get('user')",
            "    ignore_auth = context.get('ignore_auth')",
            "    if ignore_auth or (user and authz.is_sysadmin(user)):",
            "        return",
            "",
            "    data.pop(key)",
            "",
            "",
            "def ignore_not_group_admin(key, data, errors, context):",
            "    '''Ignore if the user is not allowed to administer for the group specified.'''",
            "",
            "    model = context['model']",
            "    user = context.get('user')",
            "",
            "    if user and authz.is_sysadmin(user):",
            "        return",
            "",
            "    authorized = False",
            "    group = context.get('group')",
            "    if group:",
            "        try:",
            "            logic.check_access('group_change_state',context)",
            "            authorized = True",
            "        except logic.NotAuthorized:",
            "            authorized = False",
            "",
            "    if (user and group and authorized):",
            "        return",
            "",
            "    data.pop(key)",
            "",
            "def user_name_validator(key, data, errors, context):",
            "    '''Validate a new user name.",
            "",
            "    Append an error message to ``errors[key]`` if a user named ``data[key]``",
            "    already exists. Otherwise, do nothing.",
            "",
            "    :raises ckan.lib.navl.dictization_functions.Invalid: if ``data[key]`` is",
            "        not a string",
            "    :rtype: None",
            "",
            "    '''",
            "    model = context['model']",
            "    new_user_name = data[key]",
            "",
            "    if not isinstance(new_user_name, string_types):",
            "        raise Invalid(_('User names must be strings'))",
            "",
            "    user = model.User.get(new_user_name)",
            "    user_obj_from_context = context.get('user_obj')",
            "    if user is not None:",
            "        # A user with new_user_name already exists in the database.",
            "        if user_obj_from_context and user_obj_from_context.id == user.id:",
            "            # If there's a user_obj in context with the same id as the user",
            "            # found in the db, then we must be doing a user_update and not",
            "            # updating the user name, so don't return an error.",
            "            return",
            "        else:",
            "            # Otherwise return an error: there's already another user with that",
            "            # name, so you can create a new user with that name or update an",
            "            # existing user's name to that name.",
            "            errors[key].append(_('That login name is not available.'))",
            "    elif user_obj_from_context:",
            "        old_user = model.User.get(user_obj_from_context.id)",
            "        if old_user is not None and old_user.state != model.State.PENDING:",
            "            errors[key].append(_('That login name can not be modified.'))",
            "        else:",
            "            return",
            "",
            "def user_both_passwords_entered(key, data, errors, context):",
            "",
            "    password1 = data.get(('password1',),None)",
            "    password2 = data.get(('password2',),None)",
            "",
            "    if password1 is None or password1 == '' or \\",
            "       password2 is None or password2 == '':",
            "        errors[('password',)].append(_('Please enter both passwords'))",
            "",
            "def user_password_validator(key, data, errors, context):",
            "    value = data[key]",
            "",
            "    if isinstance(value, Missing):",
            "        pass",
            "    elif not isinstance(value, string_types):",
            "        errors[('password',)].append(_('Passwords must be strings'))",
            "    elif value == '':",
            "        pass",
            "    elif len(value) < 8:",
            "        errors[('password',)].append(_('Your password must be 8 characters or '",
            "                                       'longer'))",
            "",
            "def user_passwords_match(key, data, errors, context):",
            "",
            "    password1 = data.get(('password1',),None)",
            "    password2 = data.get(('password2',),None)",
            "",
            "    if not password1 == password2:",
            "        errors[key].append(_('The passwords you entered do not match'))",
            "    else:",
            "        #Set correct password",
            "        data[('password',)] = password1",
            "",
            "def user_password_not_empty(key, data, errors, context):",
            "    '''Only check if password is present if the user is created via action API.",
            "       If not, user_both_passwords_entered will handle the validation'''",
            "    # sysadmin may provide password_hash directly for importing users",
            "    if (data.get(('password_hash',), missing) is not missing and",
            "            authz.is_sysadmin(context.get('user'))):",
            "        return",
            "",
            "    if not ('password1',) in data and not ('password2',) in data:",
            "        password = data.get(('password',),None)",
            "        if not password:",
            "            errors[key].append(_('Missing value'))",
            "",
            "def user_about_validator(value,context):",
            "    if 'http://' in value or 'https://' in value:",
            "        raise Invalid(_('Edit not allowed as it looks like spam. Please avoid links in your description.'))",
            "",
            "    return value",
            "",
            "def vocabulary_name_validator(name, context):",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    if len(name) < VOCABULARY_NAME_MIN_LENGTH:",
            "        raise Invalid(_('Name must be at least %s characters long') %",
            "            VOCABULARY_NAME_MIN_LENGTH)",
            "    if len(name) > VOCABULARY_NAME_MAX_LENGTH:",
            "        raise Invalid(_('Name must be a maximum of %i characters long') %",
            "                      VOCABULARY_NAME_MAX_LENGTH)",
            "    query = session.query(model.Vocabulary.name).filter_by(name=name)",
            "    result = query.first()",
            "    if result:",
            "        raise Invalid(_('That vocabulary name is already in use.'))",
            "    return name",
            "",
            "def vocabulary_id_not_changed(value, context):",
            "    vocabulary = context.get('vocabulary')",
            "    if vocabulary and value != vocabulary.id:",
            "        raise Invalid(_('Cannot change value of key from %s to %s. '",
            "                        'This key is read-only') % (vocabulary.id, value))",
            "    return value",
            "",
            "def vocabulary_id_exists(value, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    result = session.query(model.Vocabulary).get(value)",
            "    if not result:",
            "        raise Invalid(_('Tag vocabulary was not found.'))",
            "    return value",
            "",
            "def tag_in_vocabulary_validator(value, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    vocabulary = context.get('vocabulary')",
            "    if vocabulary:",
            "        query = session.query(model.Tag)\\",
            "            .filter(model.Tag.vocabulary_id==vocabulary.id)\\",
            "            .filter(model.Tag.name==value)\\",
            "            .count()",
            "        if not query:",
            "            raise Invalid(_('Tag %s does not belong to vocabulary %s') % (value, vocabulary.name))",
            "    return value",
            "",
            "def tag_not_in_vocabulary(key, tag_dict, errors, context):",
            "    tag_name = tag_dict[('name',)]",
            "    if not tag_name:",
            "        raise Invalid(_('No tag name'))",
            "    if ('vocabulary_id',) in tag_dict:",
            "        vocabulary_id = tag_dict[('vocabulary_id',)]",
            "    else:",
            "        vocabulary_id = None",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    query = session.query(model.Tag)",
            "    query = query.filter(model.Tag.vocabulary_id==vocabulary_id)",
            "    query = query.filter(model.Tag.name==tag_name)",
            "    count = query.count()",
            "    if count > 0:",
            "        raise Invalid(_('Tag %s already belongs to vocabulary %s') %",
            "                (tag_name, vocabulary_id))",
            "    else:",
            "        return",
            "",
            "def url_validator(key, data, errors, context):",
            "    ''' Checks that the provided value (if it is present) is a valid URL '''",
            "",
            "    url = data.get(key, None)",
            "    if not url:",
            "        return",
            "",
            "    try:",
            "        pieces = urlparse(url)",
            "        if all([pieces.scheme, pieces.netloc]) and \\",
            "           set(pieces.netloc) <= set(string.ascii_letters + string.digits + '-.') and \\",
            "           pieces.scheme in ['http', 'https']:",
            "           return",
            "    except ValueError:",
            "        # url is invalid",
            "        pass",
            "",
            "    errors[key].append(_('Please provide a valid URL'))",
            "",
            "",
            "def user_name_exists(user_name, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    result = session.query(model.User).filter_by(name=user_name).first()",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('User')))",
            "    return result.name",
            "",
            "",
            "def role_exists(role, context):",
            "    if role not in authz.ROLE_PERMISSIONS:",
            "        raise Invalid(_('role does not exist.'))",
            "    return role",
            "",
            "",
            "def datasets_with_no_organization_cannot_be_private(key, data, errors,",
            "        context):",
            "",
            "    dataset_id = data.get(('id',))",
            "    owner_org = data.get(('owner_org',))",
            "    private = data[key] is True",
            "",
            "    check_passed = True",
            "",
            "    if not dataset_id and private and not owner_org:",
            "        # When creating a dataset, enforce it directly",
            "        check_passed = False",
            "    elif dataset_id and private and not owner_org:",
            "        # Check if the dataset actually has an owner_org, even if not provided",
            "        try:",
            "            dataset_dict = logic.get_action('package_show')({},",
            "                            {'id': dataset_id})",
            "            if not dataset_dict.get('owner_org'):",
            "                check_passed = False",
            "",
            "        except logic.NotFound:",
            "            check_passed = False",
            "",
            "    if not check_passed:",
            "        errors[key].append(",
            "                _(\"Datasets with no organization can't be private.\"))",
            "",
            "",
            "def list_of_strings(key, data, errors, context):",
            "    value = data.get(key)",
            "    if not isinstance(value, list):",
            "        raise Invalid(_('Not a list'))",
            "    for x in value:",
            "        if not isinstance(x, string_types):",
            "            raise Invalid('%s: %s' % (_('Not a string'), x))",
            "",
            "def if_empty_guess_format(key, data, errors, context):",
            "    value = data[key]",
            "    resource_id = data.get(key[:-1] + ('id',))",
            "",
            "    # if resource_id then an update",
            "    if (not value or value is Missing) and not resource_id:",
            "        url = data.get(key[:-1] + ('url',), '')",
            "        if not url:",
            "            return",
            "",
            "        # Uploaded files have only the filename as url, so check scheme to determine if it's an actual url",
            "        parsed = urlparse(url)",
            "        if parsed.scheme and not parsed.path:",
            "            return",
            "",
            "        mimetype, encoding = mimetypes.guess_type(url)",
            "        if mimetype:",
            "            data[key] = mimetype",
            "",
            "def clean_format(format):",
            "    return h.unified_resource_format(format)",
            "",
            "def no_loops_in_hierarchy(key, data, errors, context):",
            "    '''Checks that the parent groups specified in the data would not cause",
            "    a loop in the group hierarchy, and therefore cause the recursion up/down",
            "    the hierarchy to get into an infinite loop.",
            "    '''",
            "    if not 'id' in data:",
            "        # Must be a new group - has no children, so no chance of loops",
            "        return",
            "    group = context['model'].Group.get(data['id'])",
            "    allowable_parents = group.\\",
            "                        groups_allowed_to_be_its_parent(type=group.type)",
            "    for parent in data['groups']:",
            "        parent_name = parent['name']",
            "        # a blank name signifies top level, which is always allowed",
            "        if parent_name and context['model'].Group.get(parent_name) \\",
            "                not in allowable_parents:",
            "            raise Invalid(_('This parent would create a loop in the '",
            "                            'hierarchy'))",
            "",
            "",
            "def filter_fields_and_values_should_have_same_length(key, data, errors, context):",
            "    convert_to_list_if_string = logic.converters.convert_to_list_if_string",
            "    fields = convert_to_list_if_string(data.get(('filter_fields',), []))",
            "    values = convert_to_list_if_string(data.get(('filter_values',), []))",
            "",
            "    if len(fields) != len(values):",
            "        msg = _('\"filter_fields\" and \"filter_values\" should have the same length')",
            "        errors[('filter_fields',)].append(msg)",
            "        errors[('filter_values',)].append(msg)",
            "",
            "",
            "def filter_fields_and_values_exist_and_are_valid(key, data, errors, context):",
            "    convert_to_list_if_string = logic.converters.convert_to_list_if_string",
            "    fields = convert_to_list_if_string(data.get(('filter_fields',)))",
            "    values = convert_to_list_if_string(data.get(('filter_values',)))",
            "",
            "    if not fields:",
            "        errors[('filter_fields',)].append(_('\"filter_fields\" is required when '",
            "                                            '\"filter_values\" is filled'))",
            "    if not values:",
            "        errors[('filter_values',)].append(_('\"filter_values\" is required when '",
            "                                            '\"filter_fields\" is filled'))",
            "",
            "    filters = collections.defaultdict(list)",
            "    for field, value in zip(fields, values):",
            "        filters[field].append(value)",
            "",
            "    data[('filters',)] = dict(filters)",
            "",
            "",
            "def extra_key_not_in_root_schema(key, data, errors, context):",
            "",
            "    for schema_key in context.get('schema_keys', []):",
            "        if schema_key == data[key]:",
            "            raise Invalid(_('There is a schema field with the same name'))",
            "",
            "",
            "def empty_if_not_sysadmin(key, data, errors, context):",
            "    '''Only sysadmins may pass this value'''",
            "    from ckan.lib.navl.validators import empty",
            "",
            "    user = context.get('user')",
            "",
            "    ignore_auth = context.get('ignore_auth')",
            "    if ignore_auth or (user and authz.is_sysadmin(user)):",
            "        return",
            "",
            "    empty(key, data, errors, context)",
            "",
            "#pattern from https://html.spec.whatwg.org/#e-mail-state-(type=email)",
            "email_pattern = re.compile(",
            "                            # additional pattern to reject malformed dots usage",
            "                            r\"^(?!\\.)(?!.*\\.$)(?!.*?\\.\\.)\"\\",
            "                            \"[a-zA-Z0-9.!#$%&'*+\\/=?^_`{|}~-]+@[a-zA-Z0-9]\"\\",
            "                            \"(?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9]\"\\",
            "                            \"(?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$\"",
            "                        )",
            "",
            "",
            "def email_validator(value, context):",
            "    '''Validate email input '''",
            "",
            "    if value:",
            "        if not email_pattern.match(value):",
            "            raise Invalid(_('Email {email} is not a valid format').format(email=value))",
            "    return value",
            "",
            "def collect_prefix_validate(prefix, *validator_names):",
            "    \"\"\"",
            "    Return a validator that will collect top-level keys starting with",
            "    prefix then apply validator_names to each one. Results are moved",
            "    to a dict under the prefix name, with prefix removed from keys",
            "    \"\"\"",
            "    validator_fns = [logic.get_validator(v) for v in validator_names]",
            "",
            "    def prefix_validator(key, data, errors, context):",
            "        out = {}",
            "        extras = data.get(('__extras',), {})",
            "",
            "        # values passed as lists of dicts will have been flattened into __junk",
            "        junk = df.unflatten(data.get(('__junk',), {}))",
            "        for field_name in junk:",
            "            if not field_name.startswith(prefix):",
            "                continue",
            "            extras[field_name] = junk[field_name]",
            "",
            "        for field_name in list(extras):",
            "            if not field_name.startswith(prefix):",
            "                continue",
            "            data[(field_name,)] = extras.pop(field_name)",
            "            for v in validator_fns:",
            "                try:",
            "                    df.convert(v, (field_name,), data, errors, context)",
            "                except df.StopOnError:",
            "                    break",
            "            out[field_name[len(prefix):]] = data.pop((field_name,))",
            "",
            "        data[(prefix,)] = out",
            "",
            "    return prefix_validator",
            "",
            "",
            "def dict_only(value):",
            "    if not isinstance(value, dict):",
            "        raise Invalid(_('Must be a dict'))",
            "    return value",
            "",
            "",
            "def email_is_unique(key, data, errors, context):",
            "    '''Validate email is unique'''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    users = session.query(model.User) \\",
            "        .filter(model.User.email == data[key]).all()",
            "    # is there is no users with this email it's free",
            "    if not users:",
            "        return",
            "    else:",
            "        # allow user to update their own email",
            "        for user in users:",
            "            if (user.name in (data.get((\"name\",)), data.get((\"id\",)))",
            "                    or user.id == data.get((\"id\",))):",
            "                return",
            "",
            "    raise Invalid(",
            "        _('The email address \\'{email}\\' belongs to a registered user.').format(email=data[key]))",
            "",
            "",
            "def one_of(list_of_value):",
            "    ''' Checks if the provided value is present in a list or is an empty string'''",
            "    def callable(value):",
            "        if value != \"\" and value not in list_of_value:",
            "            raise Invalid(_('Value must be one of {}'.format(list_of_value)))",
            "        return value",
            "    return callable",
            "",
            "",
            "def json_object(value):",
            "    ''' Make sure value can be serialized as a JSON object'''",
            "    if value is None or value == '':",
            "        return",
            "    try:",
            "        if not json.dumps(value).startswith('{'):",
            "            raise Invalid(_('The value should be a valid JSON object'))",
            "    except ValueError as e:",
            "        raise Invalid(_('Could not parse the value as a valid JSON object'))",
            "",
            "    return value",
            "",
            "",
            "def extras_valid_json(extras, context):",
            "    try:",
            "        for extra, value in iteritems(extras):",
            "            json.dumps(value)",
            "    except ValueError as e:",
            "        raise Invalid(_(u'Could not parse extra \\'{name}\\' as valid JSON').",
            "                format(name=extra))",
            "    return extras"
        ],
        "afterPatchFile": [
            "",
            "# encoding: utf-8",
            "",
            "import collections",
            "import datetime",
            "from itertools import count",
            "import re",
            "import mimetypes",
            "import string",
            "import json",
            "",
            "from six import string_types, iteritems",
            "from six.moves.urllib.parse import urlparse",
            "",
            "from sqlalchemy.orm.exc import NoResultFound",
            "",
            "import ckan.lib.navl.dictization_functions as df",
            "import ckan.logic as logic",
            "import ckan.lib.helpers as h",
            "from ckan.model import (MAX_TAG_LENGTH, MIN_TAG_LENGTH,",
            "                        PACKAGE_NAME_MIN_LENGTH, PACKAGE_NAME_MAX_LENGTH,",
            "                        PACKAGE_VERSION_MAX_LENGTH,",
            "                        VOCABULARY_NAME_MAX_LENGTH,",
            "                        VOCABULARY_NAME_MIN_LENGTH)",
            "import ckan.authz as authz",
            "from ckan.model.core import State",
            "",
            "from ckan.common import _",
            "",
            "Invalid = df.Invalid",
            "StopOnError = df.StopOnError",
            "Missing = df.Missing",
            "missing = df.missing",
            "",
            "",
            "def owner_org_validator(key, data, errors, context):",
            "",
            "    value = data.get(key)",
            "",
            "    if value is missing or value is None:",
            "        if not authz.check_config_permission('create_unowned_dataset'):",
            "            raise Invalid(_('An organization must be provided'))",
            "        data.pop(key, None)",
            "        raise df.StopOnError",
            "",
            "    model = context['model']",
            "    user = context['user']",
            "    user = model.User.get(user)",
            "    package = context.get('package')",
            "",
            "    if value == '':",
            "        if not authz.check_config_permission('create_unowned_dataset'):",
            "            raise Invalid(_('An organization must be provided'))",
            "        return",
            "",
            "    if (authz.check_config_permission('allow_dataset_collaborators')",
            "            and not authz.check_config_permission('allow_collaborators_to_change_owner_org')):",
            "",
            "        if package and user and not user.sysadmin:",
            "            is_collaborator = authz.user_is_collaborator_on_dataset(",
            "                user.id, package.id, ['admin', 'editor'])",
            "            if is_collaborator:",
            "                # User is a collaborator, check if it's also a member with",
            "                # edit rights of the current organization (redundant, but possible)",
            "                user_orgs = logic.get_action(",
            "                    'organization_list_for_user')(",
            "                        {'ignore_auth': True}, {'id': user.id, 'permission': 'update_dataset'})",
            "                user_is_org_member = package.owner_org in [org['id'] for org in user_orgs]",
            "                if data.get(key) != package.owner_org and not user_is_org_member:",
            "                    raise Invalid(_('You cannot move this dataset to another organization'))",
            "",
            "    group = model.Group.get(value)",
            "    if not group:",
            "        raise Invalid(_('Organization does not exist'))",
            "    group_id = group.id",
            "",
            "    if not package or (package and package.owner_org != group_id):",
            "        # This is a new dataset or we are changing the organization",
            "        if not context.get(u'ignore_auth', False) and not(user.sysadmin or",
            "               authz.has_user_permission_for_group_or_org(",
            "                   group_id, user.name, 'create_dataset')):",
            "            raise Invalid(_('You cannot add a dataset to this organization'))",
            "",
            "    data[key] = group_id",
            "",
            "",
            "def package_id_not_changed(value, context):",
            "",
            "    package = context.get('package')",
            "    if package and value != package.id:",
            "        raise Invalid('Cannot change value of key from %s to %s. '",
            "                      'This key is read-only' % (package.id, value))",
            "    return value",
            "",
            "def int_validator(value, context):",
            "    '''",
            "    Return an integer for value, which may be a string in base 10 or",
            "    a numeric type (e.g. int, long, float, Decimal, Fraction). Return",
            "    None for None or empty/all-whitespace string values.",
            "",
            "    :raises: ckan.lib.navl.dictization_functions.Invalid for other",
            "        inputs or non-whole values",
            "    '''",
            "    if value is None:",
            "        return None",
            "    if hasattr(value, 'strip') and not value.strip():",
            "        return None",
            "",
            "    try:",
            "        whole, part = divmod(value, 1)",
            "    except TypeError:",
            "        try:",
            "            return int(value)",
            "        except (TypeError, ValueError):",
            "            pass",
            "    else:",
            "        if not part:",
            "            try:",
            "                return int(whole)",
            "            except TypeError:",
            "                pass  # complex number: fail like int(complex) does",
            "",
            "    raise Invalid(_('Invalid integer'))",
            "",
            "def natural_number_validator(value, context):",
            "    value = int_validator(value, context)",
            "    if value < 0:",
            "        raise Invalid(_('Must be a natural number'))",
            "    return value",
            "",
            "def is_positive_integer(value, context):",
            "    value = int_validator(value, context)",
            "    if value < 1:",
            "        raise Invalid(_('Must be a postive integer'))",
            "    return value",
            "",
            "def boolean_validator(value, context):",
            "    '''",
            "    Return a boolean for value.",
            "    Return value when value is a python bool type.",
            "    Return True for strings 'true', 'yes', 't', 'y', and '1'.",
            "    Return False in all other cases, including when value is an empty string or",
            "    None",
            "    '''",
            "    if value is missing or value is None:",
            "        return False",
            "    if isinstance(value, bool):",
            "        return value",
            "    if value.lower() in ['true', 'yes', 't', 'y', '1']:",
            "        return True",
            "    return False",
            "",
            "def isodate(value, context):",
            "    if isinstance(value, datetime.datetime):",
            "        return value",
            "    if value == '':",
            "        return None",
            "    try:",
            "        date = h.date_str_to_datetime(value)",
            "    except (TypeError, ValueError) as e:",
            "        raise Invalid(_('Date format incorrect'))",
            "    return date",
            "",
            "def no_http(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    if 'http:' in value:",
            "        raise Invalid(_('No links are allowed in the log_message.'))",
            "    return value",
            "",
            "def package_id_exists(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).get(value)",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Dataset')))",
            "    return value",
            "",
            "def package_id_does_not_exist(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).get(value)",
            "    if result:",
            "        raise Invalid(_('Dataset id already exists'))",
            "    return value",
            "",
            "",
            "def resource_id_does_not_exist(key, data, errors, context):",
            "    session = context['session']",
            "    model = context['model']",
            "",
            "    if data[key] is missing:",
            "        return",
            "    resource_id = data[key]",
            "    assert key[0] == 'resources', ('validator depends on resource schema '",
            "                                   'validating as part of package schema')",
            "    package_id = data.get(('id',))",
            "    query = session.query(model.Resource.package_id).filter(",
            "        model.Resource.id == resource_id,",
            "        model.Resource.state != State.DELETED,",
            "    )",
            "    try:",
            "        [parent_id] = query.one()",
            "    except NoResultFound:",
            "        return",
            "    if parent_id != package_id:",
            "        errors[key].append(_('Resource id already exists.'))",
            "",
            "",
            "def package_name_exists(value, context):",
            "",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).filter_by(name=value).first()",
            "",
            "    if not result:",
            "        raise Invalid(_('Not found') + ': %s' % value)",
            "    return value",
            "",
            "def package_id_or_name_exists(package_id_or_name, context):",
            "    '''Return the given package_id_or_name if such a package exists.",
            "",
            "    :raises: ckan.lib.navl.dictization_functions.Invalid if there is no",
            "        package with the given id or name",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Package).get(package_id_or_name)",
            "    if result:",
            "        return package_id_or_name",
            "",
            "    result = session.query(model.Package).filter_by(",
            "            name=package_id_or_name).first()",
            "",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Dataset')))",
            "",
            "    return package_id_or_name",
            "",
            "",
            "def resource_id_exists(value, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    if not session.query(model.Resource).get(value):",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Resource')))",
            "    return value",
            "",
            "",
            "def resource_id_validator(value):",
            "    pattern = re.compile(\"[^0-9a-zA-Z _-]\")",
            "    if pattern.search(value):",
            "        raise Invalid(_('Invalid characters in resource id'))",
            "    if len(value) < 7 or len(value) > 100:",
            "        raise Invalid(_('Invalid length for resource id'))",
            "    return value",
            "",
            "",
            "def user_id_exists(user_id, context):",
            "    '''Raises Invalid if the given user_id does not exist in the model given",
            "    in the context, otherwise returns the given user_id.",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.User).get(user_id)",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('User')))",
            "    return user_id",
            "",
            "def user_id_or_name_exists(user_id_or_name, context):",
            "    '''Return the given user_id_or_name if such a user exists.",
            "",
            "    :raises: ckan.lib.navl.dictization_functions.Invalid if no user can be",
            "        found with the given id or user name",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "    result = session.query(model.User).get(user_id_or_name)",
            "    if result:",
            "        return user_id_or_name",
            "    result = session.query(model.User).filter_by(name=user_id_or_name).first()",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('User')))",
            "    return user_id_or_name",
            "",
            "def group_id_exists(group_id, context):",
            "    '''Raises Invalid if the given group_id does not exist in the model given",
            "    in the context, otherwise returns the given group_id.",
            "",
            "    '''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    result = session.query(model.Group).get(group_id)",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Group')))",
            "    return group_id",
            "",
            "def group_id_or_name_exists(reference, context):",
            "    '''",
            "    Raises Invalid if a group identified by the name or id cannot be found.",
            "    '''",
            "    model = context['model']",
            "    result = model.Group.get(reference)",
            "    if not result:",
            "        raise Invalid(_('That group name or ID does not exist.'))",
            "    return reference",
            "",
            "def activity_type_exists(activity_type):",
            "    '''Raises Invalid if there is no registered activity renderer for the",
            "    given activity_type. Otherwise returns the given activity_type.",
            "",
            "    This just uses object_id_validators as a lookup.",
            "    very safe.",
            "",
            "    '''",
            "    if activity_type in object_id_validators:",
            "        return activity_type",
            "    else:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('Activity type')))",
            "",
            "",
            "# A dictionary mapping activity_type values from activity dicts to functions",
            "# for validating the object_id values from those same activity dicts.",
            "object_id_validators = {",
            "    'new package' : package_id_exists,",
            "    'changed package' : package_id_exists,",
            "    'deleted package' : package_id_exists,",
            "    'follow dataset' : package_id_exists,",
            "    'new user' : user_id_exists,",
            "    'changed user' : user_id_exists,",
            "    'follow user' : user_id_exists,",
            "    'new group' : group_id_exists,",
            "    'changed group' : group_id_exists,",
            "    'deleted group' : group_id_exists,",
            "    'new organization' : group_id_exists,",
            "    'changed organization' : group_id_exists,",
            "    'deleted organization' : group_id_exists,",
            "    'follow group' : group_id_exists,",
            "    }",
            "",
            "def object_id_validator(key, activity_dict, errors, context):",
            "    '''Validate the 'object_id' value of an activity_dict.",
            "",
            "    Uses the object_id_validators dict (above) to find and call an 'object_id'",
            "    validator function for the given activity_dict's 'activity_type' value.",
            "",
            "    Raises Invalid if the model given in context contains no object of the",
            "    correct type (according to the 'activity_type' value of the activity_dict)",
            "    with the given ID.",
            "",
            "    Raises Invalid if there is no object_id_validator for the activity_dict's",
            "    'activity_type' value.",
            "",
            "    '''",
            "    activity_type = activity_dict[('activity_type',)]",
            "    if activity_type in object_id_validators:",
            "        object_id = activity_dict[('object_id',)]",
            "        return object_id_validators[activity_type](object_id, context)",
            "    else:",
            "        raise Invalid('There is no object_id validator for '",
            "            'activity type \"%s\"' % activity_type)",
            "",
            "name_match = re.compile('[a-z0-9_\\-]*$')",
            "def name_validator(value, context):",
            "    '''Return the given value if it's a valid name, otherwise raise Invalid.",
            "",
            "    If it's a valid name, the given value will be returned unmodified.",
            "",
            "    This function applies general validation rules for names of packages,",
            "    groups, users, etc.",
            "",
            "    Most schemas also have their own custom name validator function to apply",
            "    custom validation rules after this function, for example a",
            "    ``package_name_validator()`` to check that no package with the given name",
            "    already exists.",
            "",
            "    :raises ckan.lib.navl.dictization_functions.Invalid: if ``value`` is not",
            "        a valid name",
            "",
            "    '''",
            "    if not isinstance(value, string_types):",
            "        raise Invalid(_('Names must be strings'))",
            "",
            "    # check basic textual rules",
            "    if value in ['new', 'edit', 'search']:",
            "        raise Invalid(_('That name cannot be used'))",
            "",
            "    if len(value) < 2:",
            "        raise Invalid(_('Must be at least %s characters long') % 2)",
            "    if len(value) > PACKAGE_NAME_MAX_LENGTH:",
            "        raise Invalid(_('Name must be a maximum of %i characters long') % \\",
            "                      PACKAGE_NAME_MAX_LENGTH)",
            "    if not name_match.match(value):",
            "        raise Invalid(_('Must be purely lowercase alphanumeric '",
            "                        '(ascii) characters and these symbols: -_'))",
            "    return value",
            "",
            "def package_name_validator(key, data, errors, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    package = context.get('package')",
            "",
            "    query = session.query(model.Package.state).filter_by(name=data[key])",
            "    if package:",
            "        package_id = package.id",
            "    else:",
            "        package_id = data.get(key[:-1] + ('id',))",
            "    if package_id and package_id is not missing:",
            "        query = query.filter(model.Package.id != package_id)",
            "    result = query.first()",
            "    if result and result.state != State.DELETED:",
            "        errors[key].append(_('That URL is already in use.'))",
            "",
            "    value = data[key]",
            "    if len(value) < PACKAGE_NAME_MIN_LENGTH:",
            "        raise Invalid(",
            "            _('Name \"%s\" length is less than minimum %s') % (value, PACKAGE_NAME_MIN_LENGTH)",
            "        )",
            "    if len(value) > PACKAGE_NAME_MAX_LENGTH:",
            "        raise Invalid(",
            "            _('Name \"%s\" length is more than maximum %s') % (value, PACKAGE_NAME_MAX_LENGTH)",
            "        )",
            "",
            "def package_version_validator(value, context):",
            "",
            "    if len(value) > PACKAGE_VERSION_MAX_LENGTH:",
            "        raise Invalid(_('Version must be a maximum of %i characters long') % \\",
            "                      PACKAGE_VERSION_MAX_LENGTH)",
            "    return value",
            "",
            "def duplicate_extras_key(key, data, errors, context):",
            "",
            "    unflattened = df.unflatten(data)",
            "    extras = unflattened.get('extras', [])",
            "    extras_keys = []",
            "    for extra in extras:",
            "        if not extra.get('deleted'):",
            "            extras_keys.append(extra['key'])",
            "",
            "    for extra_key in set(extras_keys):",
            "        extras_keys.remove(extra_key)",
            "    if extras_keys:",
            "        key_ = ('extras_validation',)",
            "        assert key_ not in errors",
            "        errors[key_] = [_('Duplicate key \"%s\"') % extras_keys[0]]",
            "",
            "def group_name_validator(key, data, errors, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    group = context.get('group')",
            "",
            "    query = session.query(model.Group.name).filter_by(name=data[key])",
            "    if group:",
            "        group_id = group.id",
            "    else:",
            "        group_id = data.get(key[:-1] + ('id',))",
            "    if group_id and group_id is not missing:",
            "        query = query.filter(model.Group.id != group_id)",
            "    result = query.first()",
            "    if result:",
            "        errors[key].append(_('Group name already exists in database'))",
            "",
            "def tag_length_validator(value, context):",
            "",
            "    if len(value) < MIN_TAG_LENGTH:",
            "        raise Invalid(",
            "            _('Tag \"%s\" length is less than minimum %s') % (value, MIN_TAG_LENGTH)",
            "        )",
            "    if len(value) > MAX_TAG_LENGTH:",
            "        raise Invalid(",
            "            _('Tag \"%s\" length is more than maximum %i') % (value, MAX_TAG_LENGTH)",
            "        )",
            "    return value",
            "",
            "def tag_name_validator(value, context):",
            "",
            "    tagname_match = re.compile('[\\w \\-.]*$', re.UNICODE)",
            "    if not tagname_match.match(value):",
            "        raise Invalid(_('Tag \"%s\" must be alphanumeric '",
            "                        'characters or symbols: -_.') % (value))",
            "    return value",
            "",
            "def tag_not_uppercase(value, context):",
            "",
            "    tagname_uppercase = re.compile('[A-Z]')",
            "    if tagname_uppercase.search(value):",
            "        raise Invalid(_('Tag \"%s\" must not be uppercase' % (value)))",
            "    return value",
            "",
            "def tag_string_convert(key, data, errors, context):",
            "    '''Takes a list of tags that is a comma-separated string (in data[key])",
            "    and parses tag names. These are added to the data dict, enumerated. They",
            "    are also validated.'''",
            "",
            "    if isinstance(data[key], string_types):",
            "        tags = [tag.strip() \\",
            "                for tag in data[key].split(',') \\",
            "                if tag.strip()]",
            "    else:",
            "        tags = data[key]",
            "",
            "    current_index = max( [int(k[1]) for k in data.keys() if len(k) == 3 and k[0] == 'tags'] + [-1] )",
            "",
            "    for num, tag in zip(count(current_index+1), tags):",
            "        data[('tags', num, 'name')] = tag",
            "",
            "    for tag in tags:",
            "        tag_length_validator(tag, context)",
            "        tag_name_validator(tag, context)",
            "",
            "def ignore_not_admin(key, data, errors, context):",
            "    # Deprecated in favour of ignore_not_package_admin",
            "    return ignore_not_package_admin(key, data, errors, context)",
            "",
            "def ignore_not_package_admin(key, data, errors, context):",
            "    '''Ignore if the user is not allowed to administer the package specified.'''",
            "",
            "    model = context['model']",
            "    user = context.get('user')",
            "",
            "    if 'ignore_auth' in context:",
            "        return",
            "",
            "    if user and authz.is_sysadmin(user):",
            "        return",
            "",
            "    authorized = False",
            "    pkg = context.get('package')",
            "    if pkg:",
            "        try:",
            "            logic.check_access('package_change_state',context)",
            "            authorized = True",
            "        except logic.NotAuthorized:",
            "            authorized = False",
            "",
            "    if (user and pkg and authorized):",
            "        return",
            "",
            "    # allow_state_change in the context will allow the state to be changed",
            "    # FIXME is this the best way to cjeck for state only?",
            "    if key == ('state',) and context.get('allow_state_change'):",
            "        return",
            "    data.pop(key)",
            "",
            "",
            "def ignore_not_sysadmin(key, data, errors, context):",
            "    '''Ignore the field if user not sysadmin or ignore_auth in context.'''",
            "",
            "    user = context.get('user')",
            "    ignore_auth = context.get('ignore_auth')",
            "    if ignore_auth or (user and authz.is_sysadmin(user)):",
            "        return",
            "",
            "    data.pop(key)",
            "",
            "",
            "def ignore_not_group_admin(key, data, errors, context):",
            "    '''Ignore if the user is not allowed to administer for the group specified.'''",
            "",
            "    model = context['model']",
            "    user = context.get('user')",
            "",
            "    if user and authz.is_sysadmin(user):",
            "        return",
            "",
            "    authorized = False",
            "    group = context.get('group')",
            "    if group:",
            "        try:",
            "            logic.check_access('group_change_state',context)",
            "            authorized = True",
            "        except logic.NotAuthorized:",
            "            authorized = False",
            "",
            "    if (user and group and authorized):",
            "        return",
            "",
            "    data.pop(key)",
            "",
            "def user_name_validator(key, data, errors, context):",
            "    '''Validate a new user name.",
            "",
            "    Append an error message to ``errors[key]`` if a user named ``data[key]``",
            "    already exists. Otherwise, do nothing.",
            "",
            "    :raises ckan.lib.navl.dictization_functions.Invalid: if ``data[key]`` is",
            "        not a string",
            "    :rtype: None",
            "",
            "    '''",
            "    model = context['model']",
            "    new_user_name = data[key]",
            "",
            "    if not isinstance(new_user_name, string_types):",
            "        raise Invalid(_('User names must be strings'))",
            "",
            "    user = model.User.get(new_user_name)",
            "    user_obj_from_context = context.get('user_obj')",
            "    if user is not None:",
            "        # A user with new_user_name already exists in the database.",
            "        if user_obj_from_context and user_obj_from_context.id == user.id:",
            "            # If there's a user_obj in context with the same id as the user",
            "            # found in the db, then we must be doing a user_update and not",
            "            # updating the user name, so don't return an error.",
            "            return",
            "        else:",
            "            # Otherwise return an error: there's already another user with that",
            "            # name, so you can create a new user with that name or update an",
            "            # existing user's name to that name.",
            "            errors[key].append(_('That login name is not available.'))",
            "    elif user_obj_from_context:",
            "        old_user = model.User.get(user_obj_from_context.id)",
            "        if old_user is not None and old_user.state != model.State.PENDING:",
            "            errors[key].append(_('That login name can not be modified.'))",
            "        else:",
            "            return",
            "",
            "def user_both_passwords_entered(key, data, errors, context):",
            "",
            "    password1 = data.get(('password1',),None)",
            "    password2 = data.get(('password2',),None)",
            "",
            "    if password1 is None or password1 == '' or \\",
            "       password2 is None or password2 == '':",
            "        errors[('password',)].append(_('Please enter both passwords'))",
            "",
            "def user_password_validator(key, data, errors, context):",
            "    value = data[key]",
            "",
            "    if isinstance(value, Missing):",
            "        pass",
            "    elif not isinstance(value, string_types):",
            "        errors[('password',)].append(_('Passwords must be strings'))",
            "    elif value == '':",
            "        pass",
            "    elif len(value) < 8:",
            "        errors[('password',)].append(_('Your password must be 8 characters or '",
            "                                       'longer'))",
            "",
            "def user_passwords_match(key, data, errors, context):",
            "",
            "    password1 = data.get(('password1',),None)",
            "    password2 = data.get(('password2',),None)",
            "",
            "    if not password1 == password2:",
            "        errors[key].append(_('The passwords you entered do not match'))",
            "    else:",
            "        #Set correct password",
            "        data[('password',)] = password1",
            "",
            "def user_password_not_empty(key, data, errors, context):",
            "    '''Only check if password is present if the user is created via action API.",
            "       If not, user_both_passwords_entered will handle the validation'''",
            "    # sysadmin may provide password_hash directly for importing users",
            "    if (data.get(('password_hash',), missing) is not missing and",
            "            authz.is_sysadmin(context.get('user'))):",
            "        return",
            "",
            "    if not ('password1',) in data and not ('password2',) in data:",
            "        password = data.get(('password',),None)",
            "        if not password:",
            "            errors[key].append(_('Missing value'))",
            "",
            "def user_about_validator(value,context):",
            "    if 'http://' in value or 'https://' in value:",
            "        raise Invalid(_('Edit not allowed as it looks like spam. Please avoid links in your description.'))",
            "",
            "    return value",
            "",
            "def vocabulary_name_validator(name, context):",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    if len(name) < VOCABULARY_NAME_MIN_LENGTH:",
            "        raise Invalid(_('Name must be at least %s characters long') %",
            "            VOCABULARY_NAME_MIN_LENGTH)",
            "    if len(name) > VOCABULARY_NAME_MAX_LENGTH:",
            "        raise Invalid(_('Name must be a maximum of %i characters long') %",
            "                      VOCABULARY_NAME_MAX_LENGTH)",
            "    query = session.query(model.Vocabulary.name).filter_by(name=name)",
            "    result = query.first()",
            "    if result:",
            "        raise Invalid(_('That vocabulary name is already in use.'))",
            "    return name",
            "",
            "def vocabulary_id_not_changed(value, context):",
            "    vocabulary = context.get('vocabulary')",
            "    if vocabulary and value != vocabulary.id:",
            "        raise Invalid(_('Cannot change value of key from %s to %s. '",
            "                        'This key is read-only') % (vocabulary.id, value))",
            "    return value",
            "",
            "def vocabulary_id_exists(value, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    result = session.query(model.Vocabulary).get(value)",
            "    if not result:",
            "        raise Invalid(_('Tag vocabulary was not found.'))",
            "    return value",
            "",
            "def tag_in_vocabulary_validator(value, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    vocabulary = context.get('vocabulary')",
            "    if vocabulary:",
            "        query = session.query(model.Tag)\\",
            "            .filter(model.Tag.vocabulary_id==vocabulary.id)\\",
            "            .filter(model.Tag.name==value)\\",
            "            .count()",
            "        if not query:",
            "            raise Invalid(_('Tag %s does not belong to vocabulary %s') % (value, vocabulary.name))",
            "    return value",
            "",
            "def tag_not_in_vocabulary(key, tag_dict, errors, context):",
            "    tag_name = tag_dict[('name',)]",
            "    if not tag_name:",
            "        raise Invalid(_('No tag name'))",
            "    if ('vocabulary_id',) in tag_dict:",
            "        vocabulary_id = tag_dict[('vocabulary_id',)]",
            "    else:",
            "        vocabulary_id = None",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    query = session.query(model.Tag)",
            "    query = query.filter(model.Tag.vocabulary_id==vocabulary_id)",
            "    query = query.filter(model.Tag.name==tag_name)",
            "    count = query.count()",
            "    if count > 0:",
            "        raise Invalid(_('Tag %s already belongs to vocabulary %s') %",
            "                (tag_name, vocabulary_id))",
            "    else:",
            "        return",
            "",
            "def url_validator(key, data, errors, context):",
            "    ''' Checks that the provided value (if it is present) is a valid URL '''",
            "",
            "    url = data.get(key, None)",
            "    if not url:",
            "        return",
            "",
            "    try:",
            "        pieces = urlparse(url)",
            "        if all([pieces.scheme, pieces.netloc]) and \\",
            "           set(pieces.netloc) <= set(string.ascii_letters + string.digits + '-.') and \\",
            "           pieces.scheme in ['http', 'https']:",
            "           return",
            "    except ValueError:",
            "        # url is invalid",
            "        pass",
            "",
            "    errors[key].append(_('Please provide a valid URL'))",
            "",
            "",
            "def user_name_exists(user_name, context):",
            "    model = context['model']",
            "    session = context['session']",
            "    result = session.query(model.User).filter_by(name=user_name).first()",
            "    if not result:",
            "        raise Invalid('%s: %s' % (_('Not found'), _('User')))",
            "    return result.name",
            "",
            "",
            "def role_exists(role, context):",
            "    if role not in authz.ROLE_PERMISSIONS:",
            "        raise Invalid(_('role does not exist.'))",
            "    return role",
            "",
            "",
            "def datasets_with_no_organization_cannot_be_private(key, data, errors,",
            "        context):",
            "",
            "    dataset_id = data.get(('id',))",
            "    owner_org = data.get(('owner_org',))",
            "    private = data[key] is True",
            "",
            "    check_passed = True",
            "",
            "    if not dataset_id and private and not owner_org:",
            "        # When creating a dataset, enforce it directly",
            "        check_passed = False",
            "    elif dataset_id and private and not owner_org:",
            "        # Check if the dataset actually has an owner_org, even if not provided",
            "        try:",
            "            dataset_dict = logic.get_action('package_show')({},",
            "                            {'id': dataset_id})",
            "            if not dataset_dict.get('owner_org'):",
            "                check_passed = False",
            "",
            "        except logic.NotFound:",
            "            check_passed = False",
            "",
            "    if not check_passed:",
            "        errors[key].append(",
            "                _(\"Datasets with no organization can't be private.\"))",
            "",
            "",
            "def list_of_strings(key, data, errors, context):",
            "    value = data.get(key)",
            "    if not isinstance(value, list):",
            "        raise Invalid(_('Not a list'))",
            "    for x in value:",
            "        if not isinstance(x, string_types):",
            "            raise Invalid('%s: %s' % (_('Not a string'), x))",
            "",
            "def if_empty_guess_format(key, data, errors, context):",
            "    value = data[key]",
            "    resource_id = data.get(key[:-1] + ('id',))",
            "",
            "    # if resource_id then an update",
            "    if (not value or value is Missing) and not resource_id:",
            "        url = data.get(key[:-1] + ('url',), '')",
            "        if not url:",
            "            return",
            "",
            "        # Uploaded files have only the filename as url, so check scheme to determine if it's an actual url",
            "        parsed = urlparse(url)",
            "        if parsed.scheme and not parsed.path:",
            "            return",
            "",
            "        mimetype, encoding = mimetypes.guess_type(url)",
            "        if mimetype:",
            "            data[key] = mimetype",
            "",
            "def clean_format(format):",
            "    return h.unified_resource_format(format)",
            "",
            "def no_loops_in_hierarchy(key, data, errors, context):",
            "    '''Checks that the parent groups specified in the data would not cause",
            "    a loop in the group hierarchy, and therefore cause the recursion up/down",
            "    the hierarchy to get into an infinite loop.",
            "    '''",
            "    if not 'id' in data:",
            "        # Must be a new group - has no children, so no chance of loops",
            "        return",
            "    group = context['model'].Group.get(data['id'])",
            "    allowable_parents = group.\\",
            "                        groups_allowed_to_be_its_parent(type=group.type)",
            "    for parent in data['groups']:",
            "        parent_name = parent['name']",
            "        # a blank name signifies top level, which is always allowed",
            "        if parent_name and context['model'].Group.get(parent_name) \\",
            "                not in allowable_parents:",
            "            raise Invalid(_('This parent would create a loop in the '",
            "                            'hierarchy'))",
            "",
            "",
            "def filter_fields_and_values_should_have_same_length(key, data, errors, context):",
            "    convert_to_list_if_string = logic.converters.convert_to_list_if_string",
            "    fields = convert_to_list_if_string(data.get(('filter_fields',), []))",
            "    values = convert_to_list_if_string(data.get(('filter_values',), []))",
            "",
            "    if len(fields) != len(values):",
            "        msg = _('\"filter_fields\" and \"filter_values\" should have the same length')",
            "        errors[('filter_fields',)].append(msg)",
            "        errors[('filter_values',)].append(msg)",
            "",
            "",
            "def filter_fields_and_values_exist_and_are_valid(key, data, errors, context):",
            "    convert_to_list_if_string = logic.converters.convert_to_list_if_string",
            "    fields = convert_to_list_if_string(data.get(('filter_fields',)))",
            "    values = convert_to_list_if_string(data.get(('filter_values',)))",
            "",
            "    if not fields:",
            "        errors[('filter_fields',)].append(_('\"filter_fields\" is required when '",
            "                                            '\"filter_values\" is filled'))",
            "    if not values:",
            "        errors[('filter_values',)].append(_('\"filter_values\" is required when '",
            "                                            '\"filter_fields\" is filled'))",
            "",
            "    filters = collections.defaultdict(list)",
            "    for field, value in zip(fields, values):",
            "        filters[field].append(value)",
            "",
            "    data[('filters',)] = dict(filters)",
            "",
            "",
            "def extra_key_not_in_root_schema(key, data, errors, context):",
            "",
            "    for schema_key in context.get('schema_keys', []):",
            "        if schema_key == data[key]:",
            "            raise Invalid(_('There is a schema field with the same name'))",
            "",
            "",
            "def empty_if_not_sysadmin(key, data, errors, context):",
            "    '''Only sysadmins may pass this value'''",
            "    from ckan.lib.navl.validators import empty",
            "",
            "    user = context.get('user')",
            "",
            "    ignore_auth = context.get('ignore_auth')",
            "    if ignore_auth or (user and authz.is_sysadmin(user)):",
            "        return",
            "",
            "    empty(key, data, errors, context)",
            "",
            "#pattern from https://html.spec.whatwg.org/#e-mail-state-(type=email)",
            "email_pattern = re.compile(",
            "                            # additional pattern to reject malformed dots usage",
            "                            r\"^(?!\\.)(?!.*\\.$)(?!.*?\\.\\.)\"\\",
            "                            \"[a-zA-Z0-9.!#$%&'*+\\/=?^_`{|}~-]+@[a-zA-Z0-9]\"\\",
            "                            \"(?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9]\"\\",
            "                            \"(?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$\"",
            "                        )",
            "",
            "",
            "def email_validator(value, context):",
            "    '''Validate email input '''",
            "",
            "    if value:",
            "        if not email_pattern.match(value):",
            "            raise Invalid(_('Email {email} is not a valid format').format(email=value))",
            "    return value",
            "",
            "def collect_prefix_validate(prefix, *validator_names):",
            "    \"\"\"",
            "    Return a validator that will collect top-level keys starting with",
            "    prefix then apply validator_names to each one. Results are moved",
            "    to a dict under the prefix name, with prefix removed from keys",
            "    \"\"\"",
            "    validator_fns = [logic.get_validator(v) for v in validator_names]",
            "",
            "    def prefix_validator(key, data, errors, context):",
            "        out = {}",
            "        extras = data.get(('__extras',), {})",
            "",
            "        # values passed as lists of dicts will have been flattened into __junk",
            "        junk = df.unflatten(data.get(('__junk',), {}))",
            "        for field_name in junk:",
            "            if not field_name.startswith(prefix):",
            "                continue",
            "            extras[field_name] = junk[field_name]",
            "",
            "        for field_name in list(extras):",
            "            if not field_name.startswith(prefix):",
            "                continue",
            "            data[(field_name,)] = extras.pop(field_name)",
            "            for v in validator_fns:",
            "                try:",
            "                    df.convert(v, (field_name,), data, errors, context)",
            "                except df.StopOnError:",
            "                    break",
            "            out[field_name[len(prefix):]] = data.pop((field_name,))",
            "",
            "        data[(prefix,)] = out",
            "",
            "    return prefix_validator",
            "",
            "",
            "def dict_only(value):",
            "    if not isinstance(value, dict):",
            "        raise Invalid(_('Must be a dict'))",
            "    return value",
            "",
            "",
            "def email_is_unique(key, data, errors, context):",
            "    '''Validate email is unique'''",
            "    model = context['model']",
            "    session = context['session']",
            "",
            "    users = session.query(model.User) \\",
            "        .filter(model.User.email == data[key]).all()",
            "    # is there is no users with this email it's free",
            "    if not users:",
            "        return",
            "    else:",
            "        # allow user to update their own email",
            "        for user in users:",
            "            if (user.name in (data.get((\"name\",)), data.get((\"id\",)))",
            "                    or user.id == data.get((\"id\",))):",
            "                return",
            "",
            "    raise Invalid(",
            "        _('The email address \\'{email}\\' belongs to a registered user.').format(email=data[key]))",
            "",
            "",
            "def one_of(list_of_value):",
            "    ''' Checks if the provided value is present in a list or is an empty string'''",
            "    def callable(value):",
            "        if value != \"\" and value not in list_of_value:",
            "            raise Invalid(_('Value must be one of {}'.format(list_of_value)))",
            "        return value",
            "    return callable",
            "",
            "",
            "def json_object(value):",
            "    ''' Make sure value can be serialized as a JSON object'''",
            "    if value is None or value == '':",
            "        return",
            "    try:",
            "        if not json.dumps(value).startswith('{'):",
            "            raise Invalid(_('The value should be a valid JSON object'))",
            "    except ValueError as e:",
            "        raise Invalid(_('Could not parse the value as a valid JSON object'))",
            "",
            "    return value",
            "",
            "",
            "def extras_valid_json(extras, context):",
            "    try:",
            "        for extra, value in iteritems(extras):",
            "            json.dumps(value)",
            "    except ValueError as e:",
            "        raise Invalid(_(u'Could not parse extra \\'{name}\\' as valid JSON').",
            "                format(name=extra))",
            "    return extras"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "tlslite.tlsrecordlayer"
        ]
    },
    "ckan/tests/lib/test_uploader.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " # encoding: utf-8"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+import pytest"
            },
            "2": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import six"
            },
            "3": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " "
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from werkzeug.datastructures import FileStorage"
            },
            "5": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 7,
                "PatchRowcode": "+from ckan.logic import ValidationError"
            },
            "7": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " import ckan.lib.uploader"
            },
            "8": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from ckan.lib.uploader import ResourceUpload, Upload"
            },
            "9": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "         assert res_upload.filesize == 0"
            },
            "11": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "         assert res_upload.filename == u'data.csv'"
            },
            "12": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+    def test_resource_with_dodgy_id("
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+            self, ckan_config, monkeypatch, tmpdir):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+        resource_id = u'aaabbb/../../../../nope.txt'"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+        res = {u'clear_upload': u'',"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+               u'format': u'PNG',"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+               u'url': u'https://example.com/data.csv',"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+               u'description': u'',"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+               u'upload': FileStorage(filename=u'data.csv', content_type=u'CSV'),"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+               u'package_id': u'dataset1',"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+               u'id': resource_id,"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+               u'name': u'data.csv'}"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+        res_upload = ResourceUpload(res)"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+        with pytest.raises(ValidationError):"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+            res_upload.upload(resource_id)"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+"
            },
            "32": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 86,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 87,
                "PatchRowcode": " class TestUpload(object):"
            },
            "34": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "     def test_group_upload(self, monkeypatch, tmpdir, make_app, ckan_config):"
            }
        },
        "frontPatchFile": [
            "# encoding: utf-8",
            "import six",
            "",
            "from werkzeug.datastructures import FileStorage",
            "",
            "import ckan.lib.uploader",
            "from ckan.lib.uploader import ResourceUpload, Upload",
            "",
            "",
            "class TestInitResourceUpload(object):",
            "    def test_resource_without_upload_with_old_werkzeug(",
            "            self, ckan_config, monkeypatch, tmpdir):",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "",
            "        # this test data is based on real observation using a browser",
            "        # and werkzeug 0.14.1",
            "        res = {u'clear_upload': u'true',",
            "               u'format': u'CSV',",
            "               u'url': u'https://example.com/data.csv',",
            "               u'description': u'',",
            "               u'upload': u'',",
            "               u'package_id': u'dataset1',",
            "               u'id': u'8a3a874e-5ee1-4e43-bdaf-e2569cf72344',",
            "               u'name': u'data.csv'}",
            "        res_upload = ResourceUpload(res)",
            "",
            "        assert res_upload.filename is None",
            "",
            "    def test_resource_without_upload(",
            "            self, ckan_config, monkeypatch, tmpdir):",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "        # this test data is based on real observation using a browser",
            "        res = {u'clear_upload': u'true',",
            "               u'format': u'PNG',",
            "               u'url': u'https://example.com/data.csv',",
            "               u'description': u'',",
            "               u'upload': FileStorage(filename=u''),",
            "               u'package_id': u'dataset1',",
            "               u'id': u'8a3a874e-5ee1-4e43-bdaf-e2569cf72344',",
            "               u'name': u'data.csv'}",
            "        res_upload = ResourceUpload(res)",
            "",
            "        assert res_upload.filename is None",
            "",
            "    def test_resource_with_upload(",
            "            self, ckan_config, monkeypatch, tmpdir):",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "        # this test data is based on real observation using a browser",
            "        res = {u'clear_upload': u'',",
            "               u'format': u'PNG',",
            "               u'url': u'https://example.com/data.csv',",
            "               u'description': u'',",
            "               u'upload': FileStorage(filename=u'data.csv', content_type=u'CSV'),",
            "               u'package_id': u'dataset1',",
            "               u'id': u'8a3a874e-5ee1-4e43-bdaf-e2569cf72344',",
            "               u'name': u'data.csv'}",
            "        res_upload = ResourceUpload(res)",
            "",
            "        assert res_upload.filesize == 0",
            "        assert res_upload.filename == u'data.csv'",
            "",
            "",
            "class TestUpload(object):",
            "    def test_group_upload(self, monkeypatch, tmpdir, make_app, ckan_config):",
            "        \"\"\"Reproduce group's logo upload and check that file available through",
            "        public url.",
            "",
            "        \"\"\"",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "        some_png = \"\"\"",
            "        89 50 4E 47 0D 0A 1A 0A 00 00 00 0D 49 48 44 52",
            "        00 00 00 01 00 00 00 01 08 02 00 00 00 90 77 53",
            "        DE 00 00 00 0C 49 44 41 54 08 D7 63 F8 CF C0 00",
            "        00 03 01 01 00 18 DD 8D B0 00 00 00 00 49 45 4E",
            "        44 AE 42 60 82\"\"\"",
            "        some_png = some_png.replace(u' ', u'').replace(u'\\n', u'')",
            "        some_png_bytes = bytes(bytearray.fromhex(some_png))",
            "",
            "        group = {u'clear_upload': u'',",
            "                 u'upload': FileStorage(",
            "                     six.BytesIO(some_png_bytes),",
            "                     filename=u'logo.png',",
            "                     content_type=u'PNG'",
            "                 ),",
            "                 u'name': u'test-group-upload'}",
            "        group_upload = Upload(u'group')",
            "        group_upload.update_data_dict(group, u'url', u'upload', u'clear_upload')",
            "        group_upload.upload()",
            "        uploads_dir = tmpdir / u'storage' / u'uploads' / u'group'",
            "        logo = uploads_dir.listdir()[0]",
            "        assert logo.basename == group[u'url']",
            "        app = make_app()",
            "        resp = app.get(u'/uploads/group/' + group[u'url'])",
            "        assert resp.status_code == 200",
            "        # PNG signature",
            "        if six.PY3:",
            "            assert resp.data.hex()[:16].upper() == u'89504E470D0A1A0A'",
            "        else:",
            "            assert resp.data.encode(u\"hex\")[:16].upper() == u'89504E470D0A1A0A'"
        ],
        "afterPatchFile": [
            "# encoding: utf-8",
            "import pytest",
            "import six",
            "",
            "from werkzeug.datastructures import FileStorage",
            "",
            "from ckan.logic import ValidationError",
            "import ckan.lib.uploader",
            "from ckan.lib.uploader import ResourceUpload, Upload",
            "",
            "",
            "class TestInitResourceUpload(object):",
            "    def test_resource_without_upload_with_old_werkzeug(",
            "            self, ckan_config, monkeypatch, tmpdir):",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "",
            "        # this test data is based on real observation using a browser",
            "        # and werkzeug 0.14.1",
            "        res = {u'clear_upload': u'true',",
            "               u'format': u'CSV',",
            "               u'url': u'https://example.com/data.csv',",
            "               u'description': u'',",
            "               u'upload': u'',",
            "               u'package_id': u'dataset1',",
            "               u'id': u'8a3a874e-5ee1-4e43-bdaf-e2569cf72344',",
            "               u'name': u'data.csv'}",
            "        res_upload = ResourceUpload(res)",
            "",
            "        assert res_upload.filename is None",
            "",
            "    def test_resource_without_upload(",
            "            self, ckan_config, monkeypatch, tmpdir):",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "        # this test data is based on real observation using a browser",
            "        res = {u'clear_upload': u'true',",
            "               u'format': u'PNG',",
            "               u'url': u'https://example.com/data.csv',",
            "               u'description': u'',",
            "               u'upload': FileStorage(filename=u''),",
            "               u'package_id': u'dataset1',",
            "               u'id': u'8a3a874e-5ee1-4e43-bdaf-e2569cf72344',",
            "               u'name': u'data.csv'}",
            "        res_upload = ResourceUpload(res)",
            "",
            "        assert res_upload.filename is None",
            "",
            "    def test_resource_with_upload(",
            "            self, ckan_config, monkeypatch, tmpdir):",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "        # this test data is based on real observation using a browser",
            "        res = {u'clear_upload': u'',",
            "               u'format': u'PNG',",
            "               u'url': u'https://example.com/data.csv',",
            "               u'description': u'',",
            "               u'upload': FileStorage(filename=u'data.csv', content_type=u'CSV'),",
            "               u'package_id': u'dataset1',",
            "               u'id': u'8a3a874e-5ee1-4e43-bdaf-e2569cf72344',",
            "               u'name': u'data.csv'}",
            "        res_upload = ResourceUpload(res)",
            "",
            "        assert res_upload.filesize == 0",
            "        assert res_upload.filename == u'data.csv'",
            "",
            "    def test_resource_with_dodgy_id(",
            "            self, ckan_config, monkeypatch, tmpdir):",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "",
            "        resource_id = u'aaabbb/../../../../nope.txt'",
            "        res = {u'clear_upload': u'',",
            "               u'format': u'PNG',",
            "               u'url': u'https://example.com/data.csv',",
            "               u'description': u'',",
            "               u'upload': FileStorage(filename=u'data.csv', content_type=u'CSV'),",
            "               u'package_id': u'dataset1',",
            "               u'id': resource_id,",
            "               u'name': u'data.csv'}",
            "        res_upload = ResourceUpload(res)",
            "",
            "        with pytest.raises(ValidationError):",
            "            res_upload.upload(resource_id)",
            "",
            "",
            "class TestUpload(object):",
            "    def test_group_upload(self, monkeypatch, tmpdir, make_app, ckan_config):",
            "        \"\"\"Reproduce group's logo upload and check that file available through",
            "        public url.",
            "",
            "        \"\"\"",
            "        monkeypatch.setitem(ckan_config, u'ckan.storage_path', str(tmpdir))",
            "        monkeypatch.setattr(ckan.lib.uploader, u'_storage_path', str(tmpdir))",
            "        some_png = \"\"\"",
            "        89 50 4E 47 0D 0A 1A 0A 00 00 00 0D 49 48 44 52",
            "        00 00 00 01 00 00 00 01 08 02 00 00 00 90 77 53",
            "        DE 00 00 00 0C 49 44 41 54 08 D7 63 F8 CF C0 00",
            "        00 03 01 01 00 18 DD 8D B0 00 00 00 00 49 45 4E",
            "        44 AE 42 60 82\"\"\"",
            "        some_png = some_png.replace(u' ', u'').replace(u'\\n', u'')",
            "        some_png_bytes = bytes(bytearray.fromhex(some_png))",
            "",
            "        group = {u'clear_upload': u'',",
            "                 u'upload': FileStorage(",
            "                     six.BytesIO(some_png_bytes),",
            "                     filename=u'logo.png',",
            "                     content_type=u'PNG'",
            "                 ),",
            "                 u'name': u'test-group-upload'}",
            "        group_upload = Upload(u'group')",
            "        group_upload.update_data_dict(group, u'url', u'upload', u'clear_upload')",
            "        group_upload.upload()",
            "        uploads_dir = tmpdir / u'storage' / u'uploads' / u'group'",
            "        logo = uploads_dir.listdir()[0]",
            "        assert logo.basename == group[u'url']",
            "        app = make_app()",
            "        resp = app.get(u'/uploads/group/' + group[u'url'])",
            "        assert resp.status_code == 200",
            "        # PNG signature",
            "        if six.PY3:",
            "            assert resp.data.hex()[:16].upper() == u'89504E470D0A1A0A'",
            "        else:",
            "            assert resp.data.encode(u\"hex\")[:16].upper() == u'89504E470D0A1A0A'"
        ],
        "action": [
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "tlslite.tlsrecordlayer"
        ]
    },
    "ckan/tests/logic/action/test_create.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 395,
                "afterPatchRowNumber": 395,
                "PatchRowcode": "         with pytest.raises(logic.ValidationError):"
            },
            "1": {
                "beforePatchRowNumber": 396,
                "afterPatchRowNumber": 396,
                "PatchRowcode": "             helpers.call_action(\"resource_create\", **data_dict)"
            },
            "2": {
                "beforePatchRowNumber": 397,
                "afterPatchRowNumber": 397,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 398,
                "PatchRowcode": "+    def test_invalid_characters_in_id(self):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 399,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 400,
                "PatchRowcode": "+        data_dict = {"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 401,
                "PatchRowcode": "+            \"id\": \"../../nope.txt\","
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 402,
                "PatchRowcode": "+            \"package_id\": factories.Dataset()[\"id\"],"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 403,
                "PatchRowcode": "+            \"url\": \"http://data\","
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 404,
                "PatchRowcode": "+            \"name\": \"A nice resource\","
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 405,
                "PatchRowcode": "+        }"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 406,
                "PatchRowcode": "+"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 407,
                "PatchRowcode": "+        with pytest.raises(logic.ValidationError):"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 408,
                "PatchRowcode": "+            helpers.call_action(\"resource_create\", **data_dict)"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 409,
                "PatchRowcode": "+"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 410,
                "PatchRowcode": "+    def test_id_too_long(self):"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 411,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 412,
                "PatchRowcode": "+        data_dict = {"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 413,
                "PatchRowcode": "+            \"id\": \"x\" * 111,"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 414,
                "PatchRowcode": "+            \"package_id\": factories.Dataset()[\"id\"],"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 415,
                "PatchRowcode": "+            \"url\": \"http://data\","
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 416,
                "PatchRowcode": "+            \"name\": \"A nice resource\","
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 417,
                "PatchRowcode": "+        }"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 418,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 419,
                "PatchRowcode": "+        with pytest.raises(logic.ValidationError):"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 420,
                "PatchRowcode": "+            helpers.call_action(\"resource_create\", **data_dict)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 421,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 422,
                "PatchRowcode": "+    def test_id_already_exists(self):"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 423,
                "PatchRowcode": "+        data_dict = {"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 424,
                "PatchRowcode": "+            'id': 'wont-be-fooled-again',"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 425,
                "PatchRowcode": "+            'package_id': factories.Dataset()['id'],"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 426,
                "PatchRowcode": "+        }"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 427,
                "PatchRowcode": "+        helpers.call_action('resource_create', **data_dict)"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 428,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 429,
                "PatchRowcode": "+        data_dict['package_id'] = factories.Dataset()['id']"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 430,
                "PatchRowcode": "+"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 431,
                "PatchRowcode": "+        with pytest.raises(logic.ValidationError):"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 432,
                "PatchRowcode": "+            helpers.call_action('resource_create', **data_dict)"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 433,
                "PatchRowcode": "+"
            },
            "39": {
                "beforePatchRowNumber": 398,
                "afterPatchRowNumber": 434,
                "PatchRowcode": "     def test_doesnt_require_url(self):"
            },
            "40": {
                "beforePatchRowNumber": 399,
                "afterPatchRowNumber": 435,
                "PatchRowcode": "         dataset = factories.Dataset()"
            },
            "41": {
                "beforePatchRowNumber": 400,
                "afterPatchRowNumber": 436,
                "PatchRowcode": "         data_dict = {\"package_id\": dataset[\"id\"]}"
            }
        },
        "frontPatchFile": [
            "# encoding: utf-8",
            "\"\"\"Unit tests for ckan/logic/action/create.py.",
            "",
            "\"\"\"",
            "import datetime",
            "import mock",
            "import pytest",
            "",
            "import ckan",
            "import ckan.logic as logic",
            "import ckan.model as model",
            "import ckan.tests.factories as factories",
            "import ckan.tests.helpers as helpers",
            "from ckan.common import config",
            "",
            "from six import string_types",
            "",
            "from freezegun import freeze_time",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestUserInvite(object):",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_invited_user_is_created_as_pending(self, _):",
            "        invited_user = self._invite_user_to_group()",
            "",
            "        assert invited_user is not None",
            "        assert invited_user.is_pending()",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_creates_user_with_valid_username(self, _):",
            "        email = \"user$%+abc@email.com\"",
            "        invited_user = self._invite_user_to_group(email)",
            "",
            "        assert invited_user.name.startswith(\"user---abc\"), invited_user",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_assigns_user_to_group_in_expected_role(self, _):",
            "        role = \"admin\"",
            "        invited_user = self._invite_user_to_group(role=role)",
            "",
            "        group_ids = invited_user.get_group_ids(capacity=role)",
            "        assert len(group_ids) == 1, group_ids",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_sends_invite(self, send_invite):",
            "        invited_user = self._invite_user_to_group()",
            "",
            "        assert send_invite.called",
            "        assert send_invite.call_args[0][0].id == invited_user.id",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    @mock.patch(\"random.SystemRandom\")",
            "    def test_works_even_if_username_already_exists(self, rand, _):",
            "        # usernames",
            "        rand.return_value.random.side_effect = [1000, 1000, 2000, 3000]",
            "        # passwords (need to set something, otherwise choice will break)",
            "        rand.return_value.choice.side_effect = \"TestPassword1\" * 3",
            "",
            "        for _ in range(3):",
            "            invited_user = self._invite_user_to_group(",
            "                email=\"same{}@email.com\".format(_))",
            "            assert invited_user is not None, invited_user",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_requires_email(self, _):",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(email=None)",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_existed_email(self, _):",
            "        factories.User(email=\"email@example.com\")",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(email=\"email@example.com\")",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_requires_role(self, _):",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(role=None)",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_raises_not_found(self, _):",
            "        user = factories.User()",
            "",
            "        context = {\"user\": user[\"name\"]}",
            "        params = {",
            "            \"email\": \"a@example.com\",",
            "            \"group_id\": \"group_not_found\",",
            "            \"role\": \"admin\",",
            "        }",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(\"user_invite\", context, **params)",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_requires_group_id(self, _):",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(group={\"id\": None})",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_user_name_lowercase_when_email_is_uppercase(self, _):",
            "        invited_user = self._invite_user_to_group(email=\"Maria@example.com\")",
            "",
            "        assert invited_user.name.split(\"-\")[0] == \"maria\"",
            "",
            "    @pytest.mark.ckan_config(\"smtp.server\", \"email.example.com\")",
            "    @pytest.mark.usefixtures(\"with_request_context\")",
            "    def test_smtp_error_returns_error_message(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "        group = factories.Group()",
            "",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        params = {",
            "            \"email\": \"example-invited-user@example.com\",",
            "            \"group_id\": group[\"id\"],",
            "            \"role\": \"editor\",",
            "        }",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_invite\", context, **params)",
            "",
            "        # Check that the pending user was deleted",
            "        user = (",
            "            model.Session.query(model.User)",
            "            .filter(model.User.name.like(\"example-invited-user%\"))",
            "            .all()",
            "        )",
            "",
            "        assert user[0].state == \"deleted\"",
            "",
            "    def _invite_user_to_group(",
            "        self, email=\"user@email.com\", group=None, role=\"member\"",
            "    ):",
            "        user = factories.User()",
            "        group = group or factories.Group(user=user)",
            "",
            "        context = {\"user\": user[\"name\"]}",
            "        params = {\"email\": email, \"group_id\": group[\"id\"], \"role\": role}",
            "",
            "        result = helpers.call_action(\"user_invite\", context, **params)",
            "",
            "        return model.User.get(result[\"id\"])",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\")",
            "class TestResourceViewCreate(object):",
            "    def test_resource_view_create(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "        result.pop(\"id\")",
            "        result.pop(\"package_id\")",
            "",
            "        assert params == result",
            "",
            "    def test_requires_resource_id(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "        params.pop(\"resource_id\")",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_requires_title(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "        params.pop(\"title\")",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    @mock.patch(\"ckan.lib.datapreview.get_view_plugin\")",
            "    def test_requires_view_type(self, get_view_plugin):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "        params.pop(\"view_type\")",
            "",
            "        get_view_plugin.return_value = \"mock_view_plugin\"",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_raises_if_couldnt_find_resource(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes(resource_id=\"unknown\")",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_raises_if_couldnt_find_view_extension(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes(view_type=\"unknown\")",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_dont_require_any_extra_fields(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "        result.pop(\"id\")",
            "        result.pop(\"package_id\")",
            "",
            "        assert params == result",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_converts_filter_fields_and_values_into_filters_dict(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        filters = {",
            "            \"filter_fields\": [\"country\", \"weather\", \"country\"],",
            "            \"filter_values\": [\"Brazil\", \"warm\", \"Argentina\"],",
            "        }",
            "        params = self._default_resource_view_attributes(**filters)",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "        expected_filters = {",
            "            \"country\": [\"Brazil\", \"Argentina\"],",
            "            \"weather\": [\"warm\"],",
            "        }",
            "        assert result[\"filters\"] == expected_filters",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_converts_filter_fields_and_values_to_list(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        filters = {\"filter_fields\": \"country\", \"filter_values\": \"Brazil\"}",
            "        params = self._default_resource_view_attributes(**filters)",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "        assert result[\"filter_fields\"] == [\"country\"]",
            "        assert result[\"filter_values\"] == [\"Brazil\"]",
            "        assert result[\"filters\"] == {\"country\": [\"Brazil\"]}",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_require_filter_fields_and_values_to_have_same_length(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        filters = {",
            "            \"filter_fields\": [\"country\", \"country\"],",
            "            \"filter_values\": \"Brazil\",",
            "        }",
            "        params = self._default_resource_view_attributes(**filters)",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_non_filterable_views_dont_accept_filter_fields_and_values(self):",
            "        context = {}",
            "        filters = {\"filter_fields\": \"country\", \"filter_values\": \"Brazil\"}",
            "        params = self._default_resource_view_attributes(**filters)",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def _default_resource_view_attributes(self, **kwargs):",
            "        default_attributes = {",
            "            \"resource_id\": factories.Resource()[\"id\"],",
            "            \"view_type\": \"image_view\",",
            "            \"title\": \"View\",",
            "            \"description\": \"A nice view\",",
            "        }",
            "",
            "        default_attributes.update(kwargs)",
            "",
            "        return default_attributes",
            "",
            "    def _configure_datapreview_to_return_filterable_view(",
            "        self, datapreview_mock",
            "    ):",
            "        filterable_view = mock.MagicMock()",
            "        filterable_view.info.return_value = {\"filterable\": True}",
            "        datapreview_mock.get_view_plugin.return_value = filterable_view",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.views.default_views\", \"\")",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\")",
            "class TestCreateDefaultResourceViews(object):",
            "    def test_add_default_views_to_dataset_resources(self):",
            "",
            "        # New resources have no views",
            "        dataset_dict = factories.Dataset(",
            "            resources=[",
            "                {",
            "                    \"url\": \"http://some.image.png\",",
            "                    \"format\": \"png\",",
            "                    \"name\": \"Image 1\",",
            "                },",
            "                {",
            "                    \"url\": \"http://some.image.png\",",
            "                    \"format\": \"png\",",
            "                    \"name\": \"Image 2\",",
            "                },",
            "            ]",
            "        )",
            "",
            "        # Change default views config setting",
            "        config[\"ckan.views.default_views\"] = \"image_view\"",
            "",
            "        context = {\"user\": helpers.call_action(\"get_site_user\")[\"name\"]}",
            "        created_views = helpers.call_action(",
            "            \"package_create_default_resource_views\",",
            "            context,",
            "            package=dataset_dict,",
            "        )",
            "",
            "        assert len(created_views) == 2",
            "",
            "        assert created_views[0][\"view_type\"] == \"image_view\"",
            "        assert created_views[1][\"view_type\"] == \"image_view\"",
            "",
            "    def test_add_default_views_to_resource(self):",
            "",
            "        # New resources have no views",
            "        dataset_dict = factories.Dataset()",
            "        resource_dict = factories.Resource(",
            "            package_id=dataset_dict[\"id\"],",
            "            url=\"http://some.image.png\",",
            "            format=\"png\",",
            "        )",
            "",
            "        # Change default views config setting",
            "        config[\"ckan.views.default_views\"] = \"image_view\"",
            "",
            "        context = {\"user\": helpers.call_action(\"get_site_user\")[\"name\"]}",
            "        created_views = helpers.call_action(",
            "            \"resource_create_default_resource_views\",",
            "            context,",
            "            resource=resource_dict,",
            "            package=dataset_dict,",
            "        )",
            "",
            "        assert len(created_views) == 1",
            "",
            "        assert created_views[0][\"view_type\"] == \"image_view\"",
            "",
            "    def test_add_default_views_to_resource_no_dataset_passed(self):",
            "",
            "        # New resources have no views",
            "        dataset_dict = factories.Dataset()",
            "        resource_dict = factories.Resource(",
            "            package_id=dataset_dict[\"id\"],",
            "            url=\"http://some.image.png\",",
            "            format=\"png\",",
            "        )",
            "",
            "        # Change default views config setting",
            "        config[\"ckan.views.default_views\"] = \"image_view\"",
            "",
            "        context = {\"user\": helpers.call_action(\"get_site_user\")[\"name\"]}",
            "        created_views = helpers.call_action(",
            "            \"resource_create_default_resource_views\",",
            "            context,",
            "            resource=resource_dict,",
            "        )",
            "",
            "        assert len(created_views) == 1",
            "",
            "        assert created_views[0][\"view_type\"] == \"image_view\"",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "class TestResourceCreate:",
            "    def test_resource_create(self):",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        id = result.pop(\"id\")",
            "",
            "        assert id",
            "",
            "        params.pop(\"package_id\")",
            "        for key in params.keys():",
            "            assert params[key] == result[key]",
            "",
            "    def test_it_requires_package_id(self):",
            "",
            "        data_dict = {\"url\": \"http://data\"}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_create\", **data_dict)",
            "",
            "    def test_doesnt_require_url(self):",
            "        dataset = factories.Dataset()",
            "        data_dict = {\"package_id\": dataset[\"id\"]}",
            "        new_resouce = helpers.call_action(\"resource_create\", **data_dict)",
            "",
            "        data_dict = {\"id\": new_resouce[\"id\"]}",
            "        stored_resource = helpers.call_action(\"resource_show\", **data_dict)",
            "",
            "        assert not stored_resource[\"url\"]",
            "",
            "    def test_mimetype_by_url(self, monkeypatch, tmpdir):",
            "        \"\"\"The mimetype is guessed from the url",
            "",
            "        Real world usage would be externally linking the resource and",
            "        the mimetype would be guessed, based on the url",
            "",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://localhost/data.csv\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        monkeypatch.setattr(ckan.lib.uploader, \"_storage_path\", str(tmpdir))",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "",
            "        assert mimetype",
            "        assert mimetype == \"text/csv\"",
            "",
            "    def test_mimetype_by_url_without_path(self):",
            "        \"\"\"",
            "        The mimetype should not be guessed from url if url contains only domain",
            "",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://example.com\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "        assert mimetype is None",
            "",
            "    def test_mimetype_by_user(self):",
            "        \"\"\"",
            "        The mimetype is supplied by the user",
            "",
            "        Real world usage would be using the FileStore API or web UI form to create a resource",
            "        and the user wanted to specify the mimetype themselves",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://localhost/data.csv\",",
            "            \"name\": \"A nice resource\",",
            "            \"mimetype\": \"application/csv\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "        assert mimetype == \"application/csv\"",
            "",
            "    def test_mimetype_by_upload_by_filename(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file with a filename",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, with a filename plus extension If",
            "        there's no url or the mimetype can't be guessed by the url,",
            "        mimetype will be guessed by the extension in the filename",
            "",
            "        \"\"\"",
            "        content = \"\"\"",
            "        \"info\": {",
            "            \"title\": \"BC Data Catalogue API\",",
            "            \"description\": \"This API provides information about datasets in the BC Data Catalogue.\",",
            "            \"termsOfService\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/API_Terms_of_Use.pdf\",",
            "            \"contact\": {",
            "                \"name\": \"Data BC\",",
            "                \"url\": \"http://data.gov.bc.ca/\",",
            "                \"email\": \"\"",
            "            },",
            "            \"license\": {",
            "                \"name\": \"Open Government License - British Columbia\",",
            "                \"url\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/OGL-vbc2.0.pdf\"",
            "            },",
            "            \"version\": \"3.0.0\"",
            "        }",
            "        \"\"\"",
            "",
            "        result = create_with_upload(",
            "            content, 'test.json', url=\"http://data\",",
            "            package_id=factories.Dataset()[u\"id\"]",
            "        )",
            "        mimetype = result.pop(\"mimetype\")",
            "",
            "        assert mimetype",
            "        assert mimetype == \"application/json\"",
            "",
            "    @pytest.mark.ckan_config(\"ckan.mimetype_guess\", \"file_contents\")",
            "    def test_mimetype_by_upload_by_file(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file by the contents inside",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, that has no extension If the mimetype",
            "        can't be guessed by the url or filename, mimetype will be",
            "        guessed by the contents inside the file",
            "",
            "        \"\"\"",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm,\\",
            "        Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, \\",
            "        Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "        result = create_with_upload(",
            "            content, 'test.csv', url=\"http://data\",",
            "            package_id=factories.Dataset()[u\"id\"]",
            "        )",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "",
            "        assert mimetype",
            "        assert mimetype == \"text/plain\"",
            "",
            "    def test_size_of_resource_by_upload(self, create_with_upload):",
            "        \"\"\"",
            "        The size of the resource determined by the uploaded file",
            "        \"\"\"",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm,\\",
            "        Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, \\",
            "        Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "        result = create_with_upload(",
            "            content, 'test.csv', url=\"http://data\",",
            "            package_id=factories.Dataset()[u\"id\"]",
            "        )",
            "",
            "        size = result.pop(\"size\")",
            "",
            "        assert size",
            "        assert size > 0",
            "",
            "    def test_size_of_resource_by_user(self):",
            "        \"\"\"",
            "        The size of the resource is provided by the users",
            "",
            "        Real world usage would be using the FileStore API and the user provides a size for the resource",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "            \"size\": 500,",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        size = int(result.pop(\"size\"))",
            "        assert size == 500",
            "",
            "    @pytest.mark.usefixtures(\"with_request_context\")",
            "    def test_extras(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        resource = helpers.call_action(",
            "            \"resource_create\",",
            "            package_id=dataset[\"id\"],",
            "            somekey=\"somevalue\",  # this is how to do resource extras",
            "            extras={u\"someotherkey\": u\"alt234\"},  # this isnt",
            "            subobject={u'hello': u'there'},  # JSON objects supported",
            "            sublist=[1, 2, 3],  # JSON lists suppoted",
            "            format=u\"plain text\",",
            "            url=u\"http://datahub.io/download/\",",
            "        )",
            "",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "        assert resource[\"subobject\"] == {u\"hello\": u\"there\"}",
            "        assert resource[\"sublist\"] == [1, 2, 3]",
            "        resource = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ][0]",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "        assert resource[\"subobject\"] == {u\"hello\": u\"there\"}",
            "        assert resource[\"sublist\"] == [1, 2, 3]",
            "",
            "    @freeze_time('2020-02-25 12:00:00')",
            "    def test_metadata_modified_is_set_to_utcnow_when_created(self):",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        assert (result['metadata_modified'] ==",
            "                datetime.datetime.utcnow().isoformat())",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_dataset_collaborators', True)",
            "    @pytest.mark.ckan_config('ckan.auth.allow_admin_collaborators', True)",
            "    @pytest.mark.parametrize('role', ['admin', 'editor'])",
            "    def test_collaborators_can_create_resources(self, role):",
            "",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        user = factories.User()",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=role)",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        created_resource = helpers.call_action(",
            "            'resource_create',",
            "            context=context,",
            "            package_id=dataset['id'],",
            "            name='created by collaborator',",
            "            url='https://example.com')",
            "",
            "        assert created_resource['name'] == 'created by collaborator'",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestMemberCreate(object):",
            "    def test_group_member_creation(self):",
            "        user = factories.User()",
            "        group = factories.Group()",
            "",
            "        new_membership = helpers.call_action(",
            "            \"group_member_create\",",
            "            id=group[\"id\"],",
            "            username=user[\"name\"],",
            "            role=\"member\",",
            "        )",
            "",
            "        assert new_membership[\"group_id\"] == group[\"id\"]",
            "        assert new_membership[\"table_name\"] == \"user\"",
            "        assert new_membership[\"table_id\"] == user[\"id\"]",
            "        assert new_membership[\"capacity\"] == \"member\"",
            "",
            "    def test_organization_member_creation(self):",
            "        user = factories.User()",
            "        organization = factories.Organization()",
            "",
            "        new_membership = helpers.call_action(",
            "            \"organization_member_create\",",
            "            id=organization[\"id\"],",
            "            username=user[\"name\"],",
            "            role=\"member\",",
            "        )",
            "",
            "        assert new_membership[\"group_id\"] == organization[\"id\"]",
            "        assert new_membership[\"table_name\"] == \"user\"",
            "        assert new_membership[\"table_id\"] == user[\"id\"]",
            "        assert new_membership[\"capacity\"] == \"member\"",
            "",
            "    def test_group_member_creation_raises_validation_error_if_id_missing(self):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"group_member_create\", username=\"someuser\", role=\"member\"",
            "            )",
            "",
            "    def test_group_member_creation_raises_validation_error_if_username_missing(",
            "        self,",
            "    ):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"group_member_create\", id=\"someid\", role=\"member\"",
            "            )",
            "",
            "    def test_group_member_creation_raises_validation_error_if_role_missing(",
            "        self,",
            "    ):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"group_member_create\", id=\"someid\", username=\"someuser\"",
            "            )",
            "",
            "    def test_org_member_creation_raises_validation_error_if_id_missing(self):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"organization_member_create\",",
            "                username=\"someuser\",",
            "                role=\"member\",",
            "            )",
            "",
            "    def test_org_member_creation_raises_validation_error_if_username_missing(",
            "        self,",
            "    ):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"organization_member_create\", id=\"someid\", role=\"member\"",
            "            )",
            "",
            "    def test_org_member_creation_raises_validation_error_if_role_missing(self):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"organization_member_create\", id=\"someid\", username=\"someuser\"",
            "            )",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDatasetCreate(object):",
            "    def test_normal_user_cant_set_id(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": False}",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"package_create\",",
            "                context=context,",
            "                id=\"1234\",",
            "                name=\"test-dataset\",",
            "            )",
            "",
            "    def test_sysadmin_can_set_id(self):",
            "        user = factories.Sysadmin()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": False}",
            "        dataset = helpers.call_action(",
            "            \"package_create\", context=context, id=\"1234\", name=\"test-dataset\"",
            "        )",
            "        assert dataset[\"id\"] == \"1234\"",
            "",
            "    def test_context_is_not_polluted(self):",
            "        user = factories.Sysadmin()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": False}",
            "        helpers.call_action(",
            "            \"package_create\", context=context, id=\"1234\", name=\"test-dataset\"",
            "        )",
            "        assert \"id\" not in context",
            "        assert \"package\" not in context",
            "",
            "    def test_id_cant_already_exist(self):",
            "        dataset = factories.Dataset()",
            "        user = factories.Sysadmin()",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"package_create\", id=dataset[\"id\"], name=\"test-dataset\"",
            "            )",
            "",
            "    def test_name_not_changed_during_deletion(self):",
            "        dataset = factories.Dataset()",
            "        helpers.call_action(\"package_delete\", id=dataset[\"id\"])",
            "        deleted_dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert deleted_dataset[\"name\"] == dataset[\"name\"]",
            "",
            "    def test_name_not_changed_after_restoring(self):",
            "        dataset = factories.Dataset()",
            "        context = {\"user\": factories.Sysadmin()[\"name\"]}",
            "        helpers.call_action(\"package_delete\", id=dataset[\"id\"])",
            "        deleted_dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        restored_dataset = helpers.call_action(",
            "            \"package_patch\", context=context, id=dataset[\"id\"], state=\"active\"",
            "        )",
            "        assert deleted_dataset[\"name\"] == restored_dataset[\"name\"]",
            "        assert deleted_dataset[\"id\"] == restored_dataset[\"id\"]",
            "",
            "    def test_creation_of_dataset_with_name_same_as_of_previously_removed(self):",
            "        dataset = factories.Dataset()",
            "        initial_name = dataset[\"name\"]",
            "        helpers.call_action(\"package_delete\", id=dataset[\"id\"])",
            "        new_dataset = helpers.call_action(\"package_create\", name=initial_name)",
            "        assert new_dataset[\"name\"] == initial_name",
            "        deleted_dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        assert new_dataset[\"id\"] != deleted_dataset[\"id\"]",
            "        assert deleted_dataset[\"name\"] == deleted_dataset[\"id\"]",
            "",
            "    def test_missing_id(self):",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"package_create\")",
            "",
            "    def test_name(self):",
            "        dataset = helpers.call_action(\"package_create\", name=\"some-name\")",
            "",
            "        assert dataset[\"name\"] == \"some-name\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"name\"]",
            "            == \"some-name\"",
            "        )",
            "",
            "    def test_title(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\", name=\"test_title\", title=\"New Title\"",
            "        )",
            "",
            "        assert dataset[\"title\"] == \"New Title\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"title\"]",
            "            == \"New Title\"",
            "        )",
            "",
            "    def test_extras(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-extras\",",
            "            title=\"Test Extras\",",
            "            extras=[{\"key\": u\"original media\", \"value\": u'\"book\"'}],",
            "        )",
            "",
            "        assert dataset[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset[\"extras\"][0][\"value\"] == '\"book\"'",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset[\"extras\"][0][\"value\"] == '\"book\"'",
            "",
            "    def test_license(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-license\",",
            "            title=\"Test License\",",
            "            license_id=\"other-open\",",
            "        )",
            "",
            "        assert dataset[\"license_id\"] == \"other-open\"",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset[\"license_id\"] == \"other-open\"",
            "",
            "    def test_notes(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-notes\",",
            "            title=\"Test Notes\",",
            "            notes=\"some notes\",",
            "        )",
            "",
            "        assert dataset[\"notes\"] == \"some notes\"",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset[\"notes\"] == \"some notes\"",
            "",
            "    def test_resources(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-resources\",",
            "            title=\"Test Resources\",",
            "            resources=[",
            "                {",
            "                    \"alt_url\": u\"alt123\",",
            "                    \"description\": u\"Full text.\",",
            "                    \"somekey\": \"somevalue\",  # this is how to do resource extras",
            "                    \"extras\": {u\"someotherkey\": u\"alt234\"},  # this isnt",
            "                    \"format\": u\"plain text\",",
            "                    \"hash\": u\"abc123\",",
            "                    \"position\": 0,",
            "                    \"url\": u\"http://datahub.io/download/\",",
            "                },",
            "                {",
            "                    \"description\": u\"Index of the novel\",",
            "                    \"format\": u\"JSON\",",
            "                    \"position\": 1,",
            "                    \"url\": u\"http://datahub.io/index.json\",",
            "                },",
            "            ],",
            "        )",
            "",
            "        resources = dataset[\"resources\"]",
            "        assert resources[0][\"alt_url\"] == \"alt123\"",
            "        assert resources[0][\"description\"] == \"Full text.\"",
            "        assert resources[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources[0]",
            "        assert \"someotherkey\" not in resources[0]",
            "        assert resources[0][\"format\"] == \"plain text\"",
            "        assert resources[0][\"hash\"] == \"abc123\"",
            "        assert resources[0][\"position\"] == 0",
            "        assert resources[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources[1][\"description\"] == \"Index of the novel\"",
            "        assert resources[1][\"format\"] == \"JSON\"",
            "        assert resources[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources[1][\"position\"] == 1",
            "        resources = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ]",
            "        assert resources[0][\"alt_url\"] == \"alt123\"",
            "        assert resources[0][\"description\"] == \"Full text.\"",
            "        assert resources[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources[0]",
            "        assert \"someotherkey\" not in resources[0]",
            "        assert resources[0][\"format\"] == \"plain text\"",
            "        assert resources[0][\"hash\"] == \"abc123\"",
            "        assert resources[0][\"position\"] == 0",
            "        assert resources[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources[1][\"description\"] == \"Index of the novel\"",
            "        assert resources[1][\"format\"] == \"JSON\"",
            "        assert resources[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources[1][\"position\"] == 1",
            "",
            "    def test_tags(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-tags\",",
            "            title=\"Test Tags\",",
            "            tags=[{\"name\": u\"russian\"}, {\"name\": u\"tolstoy\"}],",
            "        )",
            "",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "",
            "    def test_return_id_only(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\", name=\"test-id\", context={\"return_id_only\": True}",
            "        )",
            "",
            "        assert isinstance(dataset, string_types)",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestGroupCreate(object):",
            "    def test_create_group(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        group = helpers.call_action(",
            "            \"group_create\", context=context, name=\"test-group\"",
            "        )",
            "",
            "        assert len(group[\"users\"]) == 1",
            "        assert group[\"display_name\"] == u\"test-group\"",
            "        assert group[\"package_count\"] == 0",
            "        assert not group[\"is_organization\"]",
            "        assert group[\"type\"] == \"group\"",
            "",
            "    def test_create_group_validation_fail(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            group = helpers.call_action(",
            "                \"group_create\", context=context, name=\"\"",
            "            )",
            "",
            "    def test_create_group_return_id(self):",
            "        import re",
            "",
            "        user = factories.User()",
            "        context = {",
            "            \"user\": user[\"name\"],",
            "            \"ignore_auth\": True,",
            "            \"return_id_only\": True,",
            "        }",
            "",
            "        group = helpers.call_action(",
            "            \"group_create\", context=context, name=\"test-group\"",
            "        )",
            "",
            "        assert isinstance(group, str)",
            "        assert re.match(r\"([a-f\\d]{8}(-[a-f\\d]{4}){3}-[a-f\\d]{12}?)\", group)",
            "",
            "    def test_create_matches_show(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        created = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        shown = helpers.call_action(",
            "            \"organization_show\", context=context, id=\"test-organization\"",
            "        )",
            "",
            "        assert sorted(created.keys()) == sorted(shown.keys())",
            "        for k in created.keys():",
            "            assert created[k] == shown[k], k",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestOrganizationCreate(object):",
            "    def test_create_organization(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        org = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        assert len(org[\"users\"]) == 1",
            "        assert org[\"display_name\"] == u\"test-organization\"",
            "        assert org[\"package_count\"] == 0",
            "        assert org[\"is_organization\"]",
            "        assert org[\"type\"] == \"organization\"",
            "",
            "    def test_create_organization_validation_fail(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            org = helpers.call_action(",
            "                \"organization_create\", context=context, name=\"\"",
            "            )",
            "",
            "    def test_create_organization_return_id(self):",
            "        import re",
            "",
            "        user = factories.User()",
            "        context = {",
            "            \"user\": user[\"name\"],",
            "            \"ignore_auth\": True,",
            "            \"return_id_only\": True,",
            "        }",
            "",
            "        org = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        assert isinstance(org, str)",
            "        assert re.match(r\"([a-f\\d]{8}(-[a-f\\d]{4}){3}-[a-f\\d]{12}?)\", org)",
            "",
            "    def test_create_matches_show(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        created = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        shown = helpers.call_action(",
            "            \"organization_show\", context=context, id=\"test-organization\"",
            "        )",
            "",
            "        assert sorted(created.keys()) == sorted(shown.keys())",
            "        for k in created.keys():",
            "            assert created[k] == shown[k], k",
            "",
            "    def test_create_organization_custom_type(self):",
            "        custom_org_type = \"some-custom-type\"",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        org = helpers.call_action(",
            "            \"organization_create\",",
            "            context=context,",
            "            name=\"test-organization\",",
            "            type=custom_org_type,",
            "        )",
            "",
            "        assert len(org[\"users\"]) == 1",
            "        assert org[\"display_name\"] == u\"test-organization\"",
            "        assert org[\"package_count\"] == 0",
            "        assert org[\"is_organization\"]",
            "        assert org[\"type\"] == custom_org_type",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "@pytest.mark.ckan_config(\"ckan.auth.create_user_via_web\", True)",
            "class TestUserCreate(object):",
            "    def test_user_create_with_password_hash(self):",
            "        sysadmin = factories.Sysadmin()",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "",
            "        user = helpers.call_action(",
            "            \"user_create\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            name=\"test\",",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password == \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_user_create_password_hash_not_for_normal_users(self):",
            "        normal_user = factories.User()",
            "        context = {\"user\": normal_user[\"name\"], \"ignore_auth\": False}",
            "",
            "        user = helpers.call_action(",
            "            \"user_create\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            name=\"test\",",
            "            password=\"required\",",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password != \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_anon_user_create_does_not_update(self):",
            "        user1 = factories.User(about=\"This is user 1\")",
            "        user_dict = {",
            "            \"id\": user1[\"id\"],",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": None,",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user2 = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user2[\"id\"] != user1[\"id\"]",
            "        assert user2[\"about\"] != \"This is user 1\"",
            "",
            "    def test_normal_user_create_does_not_update(self):",
            "        user1 = factories.User(about=\"This is user 1\")",
            "        user_dict = {",
            "            \"id\": user1[\"id\"],",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": factories.User()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user2 = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user2[\"id\"] != user1[\"id\"]",
            "        assert user2[\"about\"] != \"This is user 1\"",
            "",
            "    def test_sysadmin_user_create_does_not_update(self):",
            "        user1 = factories.User(about=\"This is user 1\")",
            "        user_dict = {",
            "            \"id\": user1[\"id\"],",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": factories.Sysadmin()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user2 = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user2[\"id\"] != user1[\"id\"]",
            "        assert user2[\"about\"] != \"This is user 1\"",
            "",
            "    def test_anon_users_can_not_provide_custom_id(self):",
            "",
            "        user_dict = {",
            "            \"id\": \"custom_id\",",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": None,",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user[\"id\"] != \"custom_id\"",
            "",
            "    def test_normal_users_can_not_provide_custom_id(self):",
            "",
            "        user_dict = {",
            "            \"id\": \"custom_id\",",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": factories.User()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user[\"id\"] != \"custom_id\"",
            "",
            "    def test_sysadmin_can_provide_custom_id(self):",
            "",
            "        user_dict = {",
            "            \"id\": \"custom_id\",",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "        context = {",
            "            \"user\": factories.Sysadmin()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user[\"id\"] == \"custom_id\"",
            "",
            "",
            "def _clear_activities():",
            "    from ckan import model",
            "",
            "    model.Session.query(model.ActivityDetail).delete()",
            "    model.Session.query(model.Activity).delete()",
            "    model.Session.flush()",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowDataset(object):",
            "    def test_no_activity(self, app):",
            "",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_dataset\", context={\"user\": user[\"name\"]}, **dataset",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowGroup(object):",
            "    def test_no_activity(self, app):",
            "        user = factories.User()",
            "        group = factories.Group(user=user)",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_group\", context={\"user\": user[\"name\"]}, **group",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowOrganization(object):",
            "    def test_no_activity(self, app):",
            "        user = factories.User()",
            "        org = factories.Organization(user=user)",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_group\", context={\"user\": user[\"name\"]}, **org",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowUser(object):",
            "    def test_no_activity(self, app):",
            "",
            "        user = factories.User()",
            "        user2 = factories.User()",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_user\", context={\"user\": user[\"name\"]}, **user2",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(u\"clean_db\")",
            "class TestApiToken(object):",
            "",
            "    def test_token_created(self):",
            "        from ckan.lib.api_token import decode",
            "        user = factories.User()",
            "        data = helpers.call_action(u\"api_token_create\", context={",
            "            u\"model\": model,",
            "            u\"user\": user[u\"name\"]",
            "        }, user=user[u\"name\"], name=u\"token-name\")",
            "        token = data[u'token']",
            "        jti = decode(token)[u'jti']",
            "        res = model.ApiToken.get(jti)",
            "        assert res.user_id == user[u\"id\"]",
            "        assert res.last_access is None",
            "        assert res.id == jti",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "@pytest.mark.ckan_config(u\"ckan.auth.allow_dataset_collaborators\", False)",
            "def test_create_package_collaborator_when_config_disabled():",
            "",
            "    dataset = factories.Dataset()",
            "    user = factories.User()",
            "    capacity = 'editor'",
            "",
            "    with pytest.raises(logic.ValidationError):",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "@pytest.mark.ckan_config(u\"ckan.auth.allow_dataset_collaborators\", True)",
            "class TestPackageMemberCreate(object):",
            "",
            "    def test_create(self):",
            "",
            "        dataset = factories.Dataset()",
            "        user = factories.User()",
            "        capacity = 'editor'",
            "",
            "        member = helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "        assert member['package_id'] == dataset['id']",
            "        assert member['user_id'] == user['id']",
            "        assert member['capacity'] == capacity",
            "",
            "        assert model.Session.query(model.PackageMember).count() == 1",
            "",
            "    def test_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "        user = factories.User()",
            "        capacity = 'editor'",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='member')",
            "",
            "        assert model.Session.query(model.PackageMember).count() == 1",
            "",
            "        assert model.Session.query(model.PackageMember).one().capacity == 'member'",
            "",
            "    def test_create_wrong_capacity(self):",
            "        dataset = factories.Dataset()",
            "        user = factories.User()",
            "        capacity = 'unknown'",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                'package_collaborator_create',",
            "                id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "    def test_create_dataset_not_found(self):",
            "        dataset = {'id': 'xxx'}",
            "        user = factories.User()",
            "        capacity = 'editor'",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(",
            "                'package_collaborator_create',",
            "                id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "    def test_create_user_not_found(self):",
            "        dataset = factories.Dataset()",
            "        user = {'id': 'yyy'}",
            "        capacity = 'editor'",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(",
            "                'package_collaborator_create',",
            "                id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "@pytest.mark.ckan_config(\"ckan.auth.create_user_via_web\", True)",
            "class TestUserPluginExtras(object):",
            "",
            "    def test_stored_on_create_if_sysadmin(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user_dict = {",
            "            'name': 'test-user',",
            "            'email': 'test@example.com',",
            "            'password': '12345678',",
            "            'plugin_extras': {",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        }",
            "",
            "        # helpers.call_action sets 'ignore_auth' to True by default",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_create', context=context, **user_dict)",
            "",
            "        assert created_user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1',",
            "            }",
            "        }",
            "",
            "        user_dict = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user_dict['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1',",
            "            }",
            "        }",
            "",
            "        plugin_extras_from_db = model.Session.execute(",
            "            'SELECT plugin_extras FROM \"user\" WHERE id=:id',",
            "            {'id': created_user['id']}",
            "        ).first().values()[0]",
            "",
            "        assert plugin_extras_from_db == {",
            "            'plugin1': {",
            "                'key1': 'value1',",
            "            }",
            "        }",
            "",
            "    def test_ignored_on_create_if_non_sysadmin(self):",
            "",
            "        author = factories.User()",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user_dict = {",
            "            'name': 'test-user',",
            "            'email': 'test@example.com',",
            "            'password': '12345678',",
            "            'plugin_extras': {",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        }",
            "",
            "        # helpers.call_action sets 'ignore_auth' to True by default",
            "        context = {'user': author['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_create', context=context, **user_dict)",
            "",
            "        assert 'plugin_extras' not in created_user",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user['plugin_extras'] is None",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "class TestUserImageUrl(object):",
            "    def test_external_picture(self):",
            "",
            "        params = {",
            "            'name': 'test_user',",
            "            'email': 'test@example.com',",
            "            'password': '12345678',",
            "            'image_url': 'https://example.com/mypic.png',",
            "        }",
            "",
            "        user_dict = helpers.call_action(\"user_create\", {}, **params)",
            "",
            "        assert user_dict[\"image_url\"] == \"https://example.com/mypic.png\"",
            "        assert (",
            "            user_dict[\"image_display_url\"] == \"https://example.com/mypic.png\"",
            "        )",
            "",
            "    def test_upload_non_picture_not_works_without_extra_config(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            assert create_with_upload(\"hello world\", \"file.txt\", **params)",
            "",
            "    def test_upload_svg_fails_without_extra_config(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload('<svg xmlns=\"http://www.w3.org/2000/svg\"></svg>', \"file.svg\", **params)",
            "",
            "    def test_upload_svg_wrong_extension_fails_without_extra_config(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload('<svg xmlns=\"http://www.w3.org/2000/svg\"></svg>', \"file.png\", **params)",
            "",
            "    @pytest.mark.ckan_config(\"ckan.upload.user.types\", \"image\")",
            "    def test_upload_non_picture(self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload(\"hello world\", \"file.txt\", **params)",
            "",
            "    @pytest.mark.ckan_config(\"ckan.upload.user.types\", \"image\")",
            "    def test_upload_non_picture_with_png_extension(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload(\"hello world\", \"file.png\", **params)",
            "",
            "    def test_upload_picture(self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "",
            "        some_png = \"\"\"",
            "        89 50 4E 47 0D 0A 1A 0A 00 00 00 0D 49 48 44 52",
            "        00 00 00 01 00 00 00 01 08 02 00 00 00 90 77 53",
            "        DE 00 00 00 0C 49 44 41 54 08 D7 63 F8 CF C0 00",
            "        00 03 01 01 00 18 DD 8D B0 00 00 00 00 49 45 4E",
            "        44 AE 42 60 82\"\"\"",
            "        some_png = some_png.replace(' ', '').replace('\\n', '')",
            "        some_png_bytes = bytes(bytearray.fromhex(some_png))",
            "        assert create_with_upload(some_png_bytes, \"file.png\", **params)"
        ],
        "afterPatchFile": [
            "# encoding: utf-8",
            "\"\"\"Unit tests for ckan/logic/action/create.py.",
            "",
            "\"\"\"",
            "import datetime",
            "import mock",
            "import pytest",
            "",
            "import ckan",
            "import ckan.logic as logic",
            "import ckan.model as model",
            "import ckan.tests.factories as factories",
            "import ckan.tests.helpers as helpers",
            "from ckan.common import config",
            "",
            "from six import string_types",
            "",
            "from freezegun import freeze_time",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestUserInvite(object):",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_invited_user_is_created_as_pending(self, _):",
            "        invited_user = self._invite_user_to_group()",
            "",
            "        assert invited_user is not None",
            "        assert invited_user.is_pending()",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_creates_user_with_valid_username(self, _):",
            "        email = \"user$%+abc@email.com\"",
            "        invited_user = self._invite_user_to_group(email)",
            "",
            "        assert invited_user.name.startswith(\"user---abc\"), invited_user",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_assigns_user_to_group_in_expected_role(self, _):",
            "        role = \"admin\"",
            "        invited_user = self._invite_user_to_group(role=role)",
            "",
            "        group_ids = invited_user.get_group_ids(capacity=role)",
            "        assert len(group_ids) == 1, group_ids",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_sends_invite(self, send_invite):",
            "        invited_user = self._invite_user_to_group()",
            "",
            "        assert send_invite.called",
            "        assert send_invite.call_args[0][0].id == invited_user.id",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    @mock.patch(\"random.SystemRandom\")",
            "    def test_works_even_if_username_already_exists(self, rand, _):",
            "        # usernames",
            "        rand.return_value.random.side_effect = [1000, 1000, 2000, 3000]",
            "        # passwords (need to set something, otherwise choice will break)",
            "        rand.return_value.choice.side_effect = \"TestPassword1\" * 3",
            "",
            "        for _ in range(3):",
            "            invited_user = self._invite_user_to_group(",
            "                email=\"same{}@email.com\".format(_))",
            "            assert invited_user is not None, invited_user",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_requires_email(self, _):",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(email=None)",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_existed_email(self, _):",
            "        factories.User(email=\"email@example.com\")",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(email=\"email@example.com\")",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_requires_role(self, _):",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(role=None)",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_raises_not_found(self, _):",
            "        user = factories.User()",
            "",
            "        context = {\"user\": user[\"name\"]}",
            "        params = {",
            "            \"email\": \"a@example.com\",",
            "            \"group_id\": \"group_not_found\",",
            "            \"role\": \"admin\",",
            "        }",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(\"user_invite\", context, **params)",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_requires_group_id(self, _):",
            "        with pytest.raises(logic.ValidationError):",
            "            self._invite_user_to_group(group={\"id\": None})",
            "",
            "    @mock.patch(\"ckan.lib.mailer.send_invite\")",
            "    def test_user_name_lowercase_when_email_is_uppercase(self, _):",
            "        invited_user = self._invite_user_to_group(email=\"Maria@example.com\")",
            "",
            "        assert invited_user.name.split(\"-\")[0] == \"maria\"",
            "",
            "    @pytest.mark.ckan_config(\"smtp.server\", \"email.example.com\")",
            "    @pytest.mark.usefixtures(\"with_request_context\")",
            "    def test_smtp_error_returns_error_message(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "        group = factories.Group()",
            "",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        params = {",
            "            \"email\": \"example-invited-user@example.com\",",
            "            \"group_id\": group[\"id\"],",
            "            \"role\": \"editor\",",
            "        }",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_invite\", context, **params)",
            "",
            "        # Check that the pending user was deleted",
            "        user = (",
            "            model.Session.query(model.User)",
            "            .filter(model.User.name.like(\"example-invited-user%\"))",
            "            .all()",
            "        )",
            "",
            "        assert user[0].state == \"deleted\"",
            "",
            "    def _invite_user_to_group(",
            "        self, email=\"user@email.com\", group=None, role=\"member\"",
            "    ):",
            "        user = factories.User()",
            "        group = group or factories.Group(user=user)",
            "",
            "        context = {\"user\": user[\"name\"]}",
            "        params = {\"email\": email, \"group_id\": group[\"id\"], \"role\": role}",
            "",
            "        result = helpers.call_action(\"user_invite\", context, **params)",
            "",
            "        return model.User.get(result[\"id\"])",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\")",
            "class TestResourceViewCreate(object):",
            "    def test_resource_view_create(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "        result.pop(\"id\")",
            "        result.pop(\"package_id\")",
            "",
            "        assert params == result",
            "",
            "    def test_requires_resource_id(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "        params.pop(\"resource_id\")",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_requires_title(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "        params.pop(\"title\")",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    @mock.patch(\"ckan.lib.datapreview.get_view_plugin\")",
            "    def test_requires_view_type(self, get_view_plugin):",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "        params.pop(\"view_type\")",
            "",
            "        get_view_plugin.return_value = \"mock_view_plugin\"",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_raises_if_couldnt_find_resource(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes(resource_id=\"unknown\")",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_raises_if_couldnt_find_view_extension(self):",
            "        context = {}",
            "        params = self._default_resource_view_attributes(view_type=\"unknown\")",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_dont_require_any_extra_fields(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        params = self._default_resource_view_attributes()",
            "",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "        result.pop(\"id\")",
            "        result.pop(\"package_id\")",
            "",
            "        assert params == result",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_converts_filter_fields_and_values_into_filters_dict(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        filters = {",
            "            \"filter_fields\": [\"country\", \"weather\", \"country\"],",
            "            \"filter_values\": [\"Brazil\", \"warm\", \"Argentina\"],",
            "        }",
            "        params = self._default_resource_view_attributes(**filters)",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "        expected_filters = {",
            "            \"country\": [\"Brazil\", \"Argentina\"],",
            "            \"weather\": [\"warm\"],",
            "        }",
            "        assert result[\"filters\"] == expected_filters",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_converts_filter_fields_and_values_to_list(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        filters = {\"filter_fields\": \"country\", \"filter_values\": \"Brazil\"}",
            "        params = self._default_resource_view_attributes(**filters)",
            "        result = helpers.call_action(\"resource_view_create\", context, **params)",
            "        assert result[\"filter_fields\"] == [\"country\"]",
            "        assert result[\"filter_values\"] == [\"Brazil\"]",
            "        assert result[\"filters\"] == {\"country\": [\"Brazil\"]}",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_require_filter_fields_and_values_to_have_same_length(",
            "        self, datapreview_mock",
            "    ):",
            "        self._configure_datapreview_to_return_filterable_view(datapreview_mock)",
            "        context = {}",
            "        filters = {",
            "            \"filter_fields\": [\"country\", \"country\"],",
            "            \"filter_values\": \"Brazil\",",
            "        }",
            "        params = self._default_resource_view_attributes(**filters)",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def test_non_filterable_views_dont_accept_filter_fields_and_values(self):",
            "        context = {}",
            "        filters = {\"filter_fields\": \"country\", \"filter_values\": \"Brazil\"}",
            "        params = self._default_resource_view_attributes(**filters)",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_create\", context, **params)",
            "",
            "    def _default_resource_view_attributes(self, **kwargs):",
            "        default_attributes = {",
            "            \"resource_id\": factories.Resource()[\"id\"],",
            "            \"view_type\": \"image_view\",",
            "            \"title\": \"View\",",
            "            \"description\": \"A nice view\",",
            "        }",
            "",
            "        default_attributes.update(kwargs)",
            "",
            "        return default_attributes",
            "",
            "    def _configure_datapreview_to_return_filterable_view(",
            "        self, datapreview_mock",
            "    ):",
            "        filterable_view = mock.MagicMock()",
            "        filterable_view.info.return_value = {\"filterable\": True}",
            "        datapreview_mock.get_view_plugin.return_value = filterable_view",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.views.default_views\", \"\")",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\")",
            "class TestCreateDefaultResourceViews(object):",
            "    def test_add_default_views_to_dataset_resources(self):",
            "",
            "        # New resources have no views",
            "        dataset_dict = factories.Dataset(",
            "            resources=[",
            "                {",
            "                    \"url\": \"http://some.image.png\",",
            "                    \"format\": \"png\",",
            "                    \"name\": \"Image 1\",",
            "                },",
            "                {",
            "                    \"url\": \"http://some.image.png\",",
            "                    \"format\": \"png\",",
            "                    \"name\": \"Image 2\",",
            "                },",
            "            ]",
            "        )",
            "",
            "        # Change default views config setting",
            "        config[\"ckan.views.default_views\"] = \"image_view\"",
            "",
            "        context = {\"user\": helpers.call_action(\"get_site_user\")[\"name\"]}",
            "        created_views = helpers.call_action(",
            "            \"package_create_default_resource_views\",",
            "            context,",
            "            package=dataset_dict,",
            "        )",
            "",
            "        assert len(created_views) == 2",
            "",
            "        assert created_views[0][\"view_type\"] == \"image_view\"",
            "        assert created_views[1][\"view_type\"] == \"image_view\"",
            "",
            "    def test_add_default_views_to_resource(self):",
            "",
            "        # New resources have no views",
            "        dataset_dict = factories.Dataset()",
            "        resource_dict = factories.Resource(",
            "            package_id=dataset_dict[\"id\"],",
            "            url=\"http://some.image.png\",",
            "            format=\"png\",",
            "        )",
            "",
            "        # Change default views config setting",
            "        config[\"ckan.views.default_views\"] = \"image_view\"",
            "",
            "        context = {\"user\": helpers.call_action(\"get_site_user\")[\"name\"]}",
            "        created_views = helpers.call_action(",
            "            \"resource_create_default_resource_views\",",
            "            context,",
            "            resource=resource_dict,",
            "            package=dataset_dict,",
            "        )",
            "",
            "        assert len(created_views) == 1",
            "",
            "        assert created_views[0][\"view_type\"] == \"image_view\"",
            "",
            "    def test_add_default_views_to_resource_no_dataset_passed(self):",
            "",
            "        # New resources have no views",
            "        dataset_dict = factories.Dataset()",
            "        resource_dict = factories.Resource(",
            "            package_id=dataset_dict[\"id\"],",
            "            url=\"http://some.image.png\",",
            "            format=\"png\",",
            "        )",
            "",
            "        # Change default views config setting",
            "        config[\"ckan.views.default_views\"] = \"image_view\"",
            "",
            "        context = {\"user\": helpers.call_action(\"get_site_user\")[\"name\"]}",
            "        created_views = helpers.call_action(",
            "            \"resource_create_default_resource_views\",",
            "            context,",
            "            resource=resource_dict,",
            "        )",
            "",
            "        assert len(created_views) == 1",
            "",
            "        assert created_views[0][\"view_type\"] == \"image_view\"",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "class TestResourceCreate:",
            "    def test_resource_create(self):",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        id = result.pop(\"id\")",
            "",
            "        assert id",
            "",
            "        params.pop(\"package_id\")",
            "        for key in params.keys():",
            "            assert params[key] == result[key]",
            "",
            "    def test_it_requires_package_id(self):",
            "",
            "        data_dict = {\"url\": \"http://data\"}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_create\", **data_dict)",
            "",
            "    def test_invalid_characters_in_id(self):",
            "",
            "        data_dict = {",
            "            \"id\": \"../../nope.txt\",",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_create\", **data_dict)",
            "",
            "    def test_id_too_long(self):",
            "",
            "        data_dict = {",
            "            \"id\": \"x\" * 111,",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_create\", **data_dict)",
            "",
            "    def test_id_already_exists(self):",
            "        data_dict = {",
            "            'id': 'wont-be-fooled-again',",
            "            'package_id': factories.Dataset()['id'],",
            "        }",
            "        helpers.call_action('resource_create', **data_dict)",
            "",
            "        data_dict['package_id'] = factories.Dataset()['id']",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action('resource_create', **data_dict)",
            "",
            "    def test_doesnt_require_url(self):",
            "        dataset = factories.Dataset()",
            "        data_dict = {\"package_id\": dataset[\"id\"]}",
            "        new_resouce = helpers.call_action(\"resource_create\", **data_dict)",
            "",
            "        data_dict = {\"id\": new_resouce[\"id\"]}",
            "        stored_resource = helpers.call_action(\"resource_show\", **data_dict)",
            "",
            "        assert not stored_resource[\"url\"]",
            "",
            "    def test_mimetype_by_url(self, monkeypatch, tmpdir):",
            "        \"\"\"The mimetype is guessed from the url",
            "",
            "        Real world usage would be externally linking the resource and",
            "        the mimetype would be guessed, based on the url",
            "",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://localhost/data.csv\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        monkeypatch.setattr(ckan.lib.uploader, \"_storage_path\", str(tmpdir))",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "",
            "        assert mimetype",
            "        assert mimetype == \"text/csv\"",
            "",
            "    def test_mimetype_by_url_without_path(self):",
            "        \"\"\"",
            "        The mimetype should not be guessed from url if url contains only domain",
            "",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://example.com\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "        assert mimetype is None",
            "",
            "    def test_mimetype_by_user(self):",
            "        \"\"\"",
            "        The mimetype is supplied by the user",
            "",
            "        Real world usage would be using the FileStore API or web UI form to create a resource",
            "        and the user wanted to specify the mimetype themselves",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://localhost/data.csv\",",
            "            \"name\": \"A nice resource\",",
            "            \"mimetype\": \"application/csv\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "        assert mimetype == \"application/csv\"",
            "",
            "    def test_mimetype_by_upload_by_filename(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file with a filename",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, with a filename plus extension If",
            "        there's no url or the mimetype can't be guessed by the url,",
            "        mimetype will be guessed by the extension in the filename",
            "",
            "        \"\"\"",
            "        content = \"\"\"",
            "        \"info\": {",
            "            \"title\": \"BC Data Catalogue API\",",
            "            \"description\": \"This API provides information about datasets in the BC Data Catalogue.\",",
            "            \"termsOfService\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/API_Terms_of_Use.pdf\",",
            "            \"contact\": {",
            "                \"name\": \"Data BC\",",
            "                \"url\": \"http://data.gov.bc.ca/\",",
            "                \"email\": \"\"",
            "            },",
            "            \"license\": {",
            "                \"name\": \"Open Government License - British Columbia\",",
            "                \"url\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/OGL-vbc2.0.pdf\"",
            "            },",
            "            \"version\": \"3.0.0\"",
            "        }",
            "        \"\"\"",
            "",
            "        result = create_with_upload(",
            "            content, 'test.json', url=\"http://data\",",
            "            package_id=factories.Dataset()[u\"id\"]",
            "        )",
            "        mimetype = result.pop(\"mimetype\")",
            "",
            "        assert mimetype",
            "        assert mimetype == \"application/json\"",
            "",
            "    @pytest.mark.ckan_config(\"ckan.mimetype_guess\", \"file_contents\")",
            "    def test_mimetype_by_upload_by_file(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file by the contents inside",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, that has no extension If the mimetype",
            "        can't be guessed by the url or filename, mimetype will be",
            "        guessed by the contents inside the file",
            "",
            "        \"\"\"",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm,\\",
            "        Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, \\",
            "        Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "        result = create_with_upload(",
            "            content, 'test.csv', url=\"http://data\",",
            "            package_id=factories.Dataset()[u\"id\"]",
            "        )",
            "",
            "        mimetype = result.pop(\"mimetype\")",
            "",
            "        assert mimetype",
            "        assert mimetype == \"text/plain\"",
            "",
            "    def test_size_of_resource_by_upload(self, create_with_upload):",
            "        \"\"\"",
            "        The size of the resource determined by the uploaded file",
            "        \"\"\"",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm,\\",
            "        Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, \\",
            "        Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "        result = create_with_upload(",
            "            content, 'test.csv', url=\"http://data\",",
            "            package_id=factories.Dataset()[u\"id\"]",
            "        )",
            "",
            "        size = result.pop(\"size\")",
            "",
            "        assert size",
            "        assert size > 0",
            "",
            "    def test_size_of_resource_by_user(self):",
            "        \"\"\"",
            "        The size of the resource is provided by the users",
            "",
            "        Real world usage would be using the FileStore API and the user provides a size for the resource",
            "        \"\"\"",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "            \"size\": 500,",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        size = int(result.pop(\"size\"))",
            "        assert size == 500",
            "",
            "    @pytest.mark.usefixtures(\"with_request_context\")",
            "    def test_extras(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        resource = helpers.call_action(",
            "            \"resource_create\",",
            "            package_id=dataset[\"id\"],",
            "            somekey=\"somevalue\",  # this is how to do resource extras",
            "            extras={u\"someotherkey\": u\"alt234\"},  # this isnt",
            "            subobject={u'hello': u'there'},  # JSON objects supported",
            "            sublist=[1, 2, 3],  # JSON lists suppoted",
            "            format=u\"plain text\",",
            "            url=u\"http://datahub.io/download/\",",
            "        )",
            "",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "        assert resource[\"subobject\"] == {u\"hello\": u\"there\"}",
            "        assert resource[\"sublist\"] == [1, 2, 3]",
            "        resource = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ][0]",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "        assert resource[\"subobject\"] == {u\"hello\": u\"there\"}",
            "        assert resource[\"sublist\"] == [1, 2, 3]",
            "",
            "    @freeze_time('2020-02-25 12:00:00')",
            "    def test_metadata_modified_is_set_to_utcnow_when_created(self):",
            "        context = {}",
            "        params = {",
            "            \"package_id\": factories.Dataset()[\"id\"],",
            "            \"url\": \"http://data\",",
            "            \"name\": \"A nice resource\",",
            "        }",
            "        result = helpers.call_action(\"resource_create\", context, **params)",
            "",
            "        assert (result['metadata_modified'] ==",
            "                datetime.datetime.utcnow().isoformat())",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_dataset_collaborators', True)",
            "    @pytest.mark.ckan_config('ckan.auth.allow_admin_collaborators', True)",
            "    @pytest.mark.parametrize('role', ['admin', 'editor'])",
            "    def test_collaborators_can_create_resources(self, role):",
            "",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        user = factories.User()",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=role)",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        created_resource = helpers.call_action(",
            "            'resource_create',",
            "            context=context,",
            "            package_id=dataset['id'],",
            "            name='created by collaborator',",
            "            url='https://example.com')",
            "",
            "        assert created_resource['name'] == 'created by collaborator'",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestMemberCreate(object):",
            "    def test_group_member_creation(self):",
            "        user = factories.User()",
            "        group = factories.Group()",
            "",
            "        new_membership = helpers.call_action(",
            "            \"group_member_create\",",
            "            id=group[\"id\"],",
            "            username=user[\"name\"],",
            "            role=\"member\",",
            "        )",
            "",
            "        assert new_membership[\"group_id\"] == group[\"id\"]",
            "        assert new_membership[\"table_name\"] == \"user\"",
            "        assert new_membership[\"table_id\"] == user[\"id\"]",
            "        assert new_membership[\"capacity\"] == \"member\"",
            "",
            "    def test_organization_member_creation(self):",
            "        user = factories.User()",
            "        organization = factories.Organization()",
            "",
            "        new_membership = helpers.call_action(",
            "            \"organization_member_create\",",
            "            id=organization[\"id\"],",
            "            username=user[\"name\"],",
            "            role=\"member\",",
            "        )",
            "",
            "        assert new_membership[\"group_id\"] == organization[\"id\"]",
            "        assert new_membership[\"table_name\"] == \"user\"",
            "        assert new_membership[\"table_id\"] == user[\"id\"]",
            "        assert new_membership[\"capacity\"] == \"member\"",
            "",
            "    def test_group_member_creation_raises_validation_error_if_id_missing(self):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"group_member_create\", username=\"someuser\", role=\"member\"",
            "            )",
            "",
            "    def test_group_member_creation_raises_validation_error_if_username_missing(",
            "        self,",
            "    ):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"group_member_create\", id=\"someid\", role=\"member\"",
            "            )",
            "",
            "    def test_group_member_creation_raises_validation_error_if_role_missing(",
            "        self,",
            "    ):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"group_member_create\", id=\"someid\", username=\"someuser\"",
            "            )",
            "",
            "    def test_org_member_creation_raises_validation_error_if_id_missing(self):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"organization_member_create\",",
            "                username=\"someuser\",",
            "                role=\"member\",",
            "            )",
            "",
            "    def test_org_member_creation_raises_validation_error_if_username_missing(",
            "        self,",
            "    ):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"organization_member_create\", id=\"someid\", role=\"member\"",
            "            )",
            "",
            "    def test_org_member_creation_raises_validation_error_if_role_missing(self):",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"organization_member_create\", id=\"someid\", username=\"someuser\"",
            "            )",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDatasetCreate(object):",
            "    def test_normal_user_cant_set_id(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": False}",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"package_create\",",
            "                context=context,",
            "                id=\"1234\",",
            "                name=\"test-dataset\",",
            "            )",
            "",
            "    def test_sysadmin_can_set_id(self):",
            "        user = factories.Sysadmin()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": False}",
            "        dataset = helpers.call_action(",
            "            \"package_create\", context=context, id=\"1234\", name=\"test-dataset\"",
            "        )",
            "        assert dataset[\"id\"] == \"1234\"",
            "",
            "    def test_context_is_not_polluted(self):",
            "        user = factories.Sysadmin()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": False}",
            "        helpers.call_action(",
            "            \"package_create\", context=context, id=\"1234\", name=\"test-dataset\"",
            "        )",
            "        assert \"id\" not in context",
            "        assert \"package\" not in context",
            "",
            "    def test_id_cant_already_exist(self):",
            "        dataset = factories.Dataset()",
            "        user = factories.Sysadmin()",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"package_create\", id=dataset[\"id\"], name=\"test-dataset\"",
            "            )",
            "",
            "    def test_name_not_changed_during_deletion(self):",
            "        dataset = factories.Dataset()",
            "        helpers.call_action(\"package_delete\", id=dataset[\"id\"])",
            "        deleted_dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert deleted_dataset[\"name\"] == dataset[\"name\"]",
            "",
            "    def test_name_not_changed_after_restoring(self):",
            "        dataset = factories.Dataset()",
            "        context = {\"user\": factories.Sysadmin()[\"name\"]}",
            "        helpers.call_action(\"package_delete\", id=dataset[\"id\"])",
            "        deleted_dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        restored_dataset = helpers.call_action(",
            "            \"package_patch\", context=context, id=dataset[\"id\"], state=\"active\"",
            "        )",
            "        assert deleted_dataset[\"name\"] == restored_dataset[\"name\"]",
            "        assert deleted_dataset[\"id\"] == restored_dataset[\"id\"]",
            "",
            "    def test_creation_of_dataset_with_name_same_as_of_previously_removed(self):",
            "        dataset = factories.Dataset()",
            "        initial_name = dataset[\"name\"]",
            "        helpers.call_action(\"package_delete\", id=dataset[\"id\"])",
            "        new_dataset = helpers.call_action(\"package_create\", name=initial_name)",
            "        assert new_dataset[\"name\"] == initial_name",
            "        deleted_dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        assert new_dataset[\"id\"] != deleted_dataset[\"id\"]",
            "        assert deleted_dataset[\"name\"] == deleted_dataset[\"id\"]",
            "",
            "    def test_missing_id(self):",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"package_create\")",
            "",
            "    def test_name(self):",
            "        dataset = helpers.call_action(\"package_create\", name=\"some-name\")",
            "",
            "        assert dataset[\"name\"] == \"some-name\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"name\"]",
            "            == \"some-name\"",
            "        )",
            "",
            "    def test_title(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\", name=\"test_title\", title=\"New Title\"",
            "        )",
            "",
            "        assert dataset[\"title\"] == \"New Title\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"title\"]",
            "            == \"New Title\"",
            "        )",
            "",
            "    def test_extras(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-extras\",",
            "            title=\"Test Extras\",",
            "            extras=[{\"key\": u\"original media\", \"value\": u'\"book\"'}],",
            "        )",
            "",
            "        assert dataset[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset[\"extras\"][0][\"value\"] == '\"book\"'",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset[\"extras\"][0][\"value\"] == '\"book\"'",
            "",
            "    def test_license(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-license\",",
            "            title=\"Test License\",",
            "            license_id=\"other-open\",",
            "        )",
            "",
            "        assert dataset[\"license_id\"] == \"other-open\"",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset[\"license_id\"] == \"other-open\"",
            "",
            "    def test_notes(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-notes\",",
            "            title=\"Test Notes\",",
            "            notes=\"some notes\",",
            "        )",
            "",
            "        assert dataset[\"notes\"] == \"some notes\"",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset[\"notes\"] == \"some notes\"",
            "",
            "    def test_resources(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-resources\",",
            "            title=\"Test Resources\",",
            "            resources=[",
            "                {",
            "                    \"alt_url\": u\"alt123\",",
            "                    \"description\": u\"Full text.\",",
            "                    \"somekey\": \"somevalue\",  # this is how to do resource extras",
            "                    \"extras\": {u\"someotherkey\": u\"alt234\"},  # this isnt",
            "                    \"format\": u\"plain text\",",
            "                    \"hash\": u\"abc123\",",
            "                    \"position\": 0,",
            "                    \"url\": u\"http://datahub.io/download/\",",
            "                },",
            "                {",
            "                    \"description\": u\"Index of the novel\",",
            "                    \"format\": u\"JSON\",",
            "                    \"position\": 1,",
            "                    \"url\": u\"http://datahub.io/index.json\",",
            "                },",
            "            ],",
            "        )",
            "",
            "        resources = dataset[\"resources\"]",
            "        assert resources[0][\"alt_url\"] == \"alt123\"",
            "        assert resources[0][\"description\"] == \"Full text.\"",
            "        assert resources[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources[0]",
            "        assert \"someotherkey\" not in resources[0]",
            "        assert resources[0][\"format\"] == \"plain text\"",
            "        assert resources[0][\"hash\"] == \"abc123\"",
            "        assert resources[0][\"position\"] == 0",
            "        assert resources[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources[1][\"description\"] == \"Index of the novel\"",
            "        assert resources[1][\"format\"] == \"JSON\"",
            "        assert resources[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources[1][\"position\"] == 1",
            "        resources = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ]",
            "        assert resources[0][\"alt_url\"] == \"alt123\"",
            "        assert resources[0][\"description\"] == \"Full text.\"",
            "        assert resources[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources[0]",
            "        assert \"someotherkey\" not in resources[0]",
            "        assert resources[0][\"format\"] == \"plain text\"",
            "        assert resources[0][\"hash\"] == \"abc123\"",
            "        assert resources[0][\"position\"] == 0",
            "        assert resources[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources[1][\"description\"] == \"Index of the novel\"",
            "        assert resources[1][\"format\"] == \"JSON\"",
            "        assert resources[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources[1][\"position\"] == 1",
            "",
            "    def test_tags(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\",",
            "            name=\"test-tags\",",
            "            title=\"Test Tags\",",
            "            tags=[{\"name\": u\"russian\"}, {\"name\": u\"tolstoy\"}],",
            "        )",
            "",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "",
            "    def test_return_id_only(self):",
            "        dataset = helpers.call_action(",
            "            \"package_create\", name=\"test-id\", context={\"return_id_only\": True}",
            "        )",
            "",
            "        assert isinstance(dataset, string_types)",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestGroupCreate(object):",
            "    def test_create_group(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        group = helpers.call_action(",
            "            \"group_create\", context=context, name=\"test-group\"",
            "        )",
            "",
            "        assert len(group[\"users\"]) == 1",
            "        assert group[\"display_name\"] == u\"test-group\"",
            "        assert group[\"package_count\"] == 0",
            "        assert not group[\"is_organization\"]",
            "        assert group[\"type\"] == \"group\"",
            "",
            "    def test_create_group_validation_fail(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            group = helpers.call_action(",
            "                \"group_create\", context=context, name=\"\"",
            "            )",
            "",
            "    def test_create_group_return_id(self):",
            "        import re",
            "",
            "        user = factories.User()",
            "        context = {",
            "            \"user\": user[\"name\"],",
            "            \"ignore_auth\": True,",
            "            \"return_id_only\": True,",
            "        }",
            "",
            "        group = helpers.call_action(",
            "            \"group_create\", context=context, name=\"test-group\"",
            "        )",
            "",
            "        assert isinstance(group, str)",
            "        assert re.match(r\"([a-f\\d]{8}(-[a-f\\d]{4}){3}-[a-f\\d]{12}?)\", group)",
            "",
            "    def test_create_matches_show(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        created = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        shown = helpers.call_action(",
            "            \"organization_show\", context=context, id=\"test-organization\"",
            "        )",
            "",
            "        assert sorted(created.keys()) == sorted(shown.keys())",
            "        for k in created.keys():",
            "            assert created[k] == shown[k], k",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestOrganizationCreate(object):",
            "    def test_create_organization(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        org = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        assert len(org[\"users\"]) == 1",
            "        assert org[\"display_name\"] == u\"test-organization\"",
            "        assert org[\"package_count\"] == 0",
            "        assert org[\"is_organization\"]",
            "        assert org[\"type\"] == \"organization\"",
            "",
            "    def test_create_organization_validation_fail(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            org = helpers.call_action(",
            "                \"organization_create\", context=context, name=\"\"",
            "            )",
            "",
            "    def test_create_organization_return_id(self):",
            "        import re",
            "",
            "        user = factories.User()",
            "        context = {",
            "            \"user\": user[\"name\"],",
            "            \"ignore_auth\": True,",
            "            \"return_id_only\": True,",
            "        }",
            "",
            "        org = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        assert isinstance(org, str)",
            "        assert re.match(r\"([a-f\\d]{8}(-[a-f\\d]{4}){3}-[a-f\\d]{12}?)\", org)",
            "",
            "    def test_create_matches_show(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        created = helpers.call_action(",
            "            \"organization_create\", context=context, name=\"test-organization\"",
            "        )",
            "",
            "        shown = helpers.call_action(",
            "            \"organization_show\", context=context, id=\"test-organization\"",
            "        )",
            "",
            "        assert sorted(created.keys()) == sorted(shown.keys())",
            "        for k in created.keys():",
            "            assert created[k] == shown[k], k",
            "",
            "    def test_create_organization_custom_type(self):",
            "        custom_org_type = \"some-custom-type\"",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"], \"ignore_auth\": True}",
            "",
            "        org = helpers.call_action(",
            "            \"organization_create\",",
            "            context=context,",
            "            name=\"test-organization\",",
            "            type=custom_org_type,",
            "        )",
            "",
            "        assert len(org[\"users\"]) == 1",
            "        assert org[\"display_name\"] == u\"test-organization\"",
            "        assert org[\"package_count\"] == 0",
            "        assert org[\"is_organization\"]",
            "        assert org[\"type\"] == custom_org_type",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "@pytest.mark.ckan_config(\"ckan.auth.create_user_via_web\", True)",
            "class TestUserCreate(object):",
            "    def test_user_create_with_password_hash(self):",
            "        sysadmin = factories.Sysadmin()",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "",
            "        user = helpers.call_action(",
            "            \"user_create\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            name=\"test\",",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password == \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_user_create_password_hash_not_for_normal_users(self):",
            "        normal_user = factories.User()",
            "        context = {\"user\": normal_user[\"name\"], \"ignore_auth\": False}",
            "",
            "        user = helpers.call_action(",
            "            \"user_create\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            name=\"test\",",
            "            password=\"required\",",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password != \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_anon_user_create_does_not_update(self):",
            "        user1 = factories.User(about=\"This is user 1\")",
            "        user_dict = {",
            "            \"id\": user1[\"id\"],",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": None,",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user2 = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user2[\"id\"] != user1[\"id\"]",
            "        assert user2[\"about\"] != \"This is user 1\"",
            "",
            "    def test_normal_user_create_does_not_update(self):",
            "        user1 = factories.User(about=\"This is user 1\")",
            "        user_dict = {",
            "            \"id\": user1[\"id\"],",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": factories.User()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user2 = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user2[\"id\"] != user1[\"id\"]",
            "        assert user2[\"about\"] != \"This is user 1\"",
            "",
            "    def test_sysadmin_user_create_does_not_update(self):",
            "        user1 = factories.User(about=\"This is user 1\")",
            "        user_dict = {",
            "            \"id\": user1[\"id\"],",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": factories.Sysadmin()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user2 = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user2[\"id\"] != user1[\"id\"]",
            "        assert user2[\"about\"] != \"This is user 1\"",
            "",
            "    def test_anon_users_can_not_provide_custom_id(self):",
            "",
            "        user_dict = {",
            "            \"id\": \"custom_id\",",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": None,",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user[\"id\"] != \"custom_id\"",
            "",
            "    def test_normal_users_can_not_provide_custom_id(self):",
            "",
            "        user_dict = {",
            "            \"id\": \"custom_id\",",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "",
            "        context = {",
            "            \"user\": factories.User()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user[\"id\"] != \"custom_id\"",
            "",
            "    def test_sysadmin_can_provide_custom_id(self):",
            "",
            "        user_dict = {",
            "            \"id\": \"custom_id\",",
            "            \"name\": \"some_name\",",
            "            \"email\": \"some_email@example.com\",",
            "            \"password\": \"test1234\",",
            "        }",
            "        context = {",
            "            \"user\": factories.Sysadmin()[\"name\"],",
            "            \"ignore_auth\": False,",
            "        }",
            "",
            "        user = helpers.call_action(\"user_create\", context=context, **user_dict)",
            "        assert user[\"id\"] == \"custom_id\"",
            "",
            "",
            "def _clear_activities():",
            "    from ckan import model",
            "",
            "    model.Session.query(model.ActivityDetail).delete()",
            "    model.Session.query(model.Activity).delete()",
            "    model.Session.flush()",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowDataset(object):",
            "    def test_no_activity(self, app):",
            "",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_dataset\", context={\"user\": user[\"name\"]}, **dataset",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowGroup(object):",
            "    def test_no_activity(self, app):",
            "        user = factories.User()",
            "        group = factories.Group(user=user)",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_group\", context={\"user\": user[\"name\"]}, **group",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowOrganization(object):",
            "    def test_no_activity(self, app):",
            "        user = factories.User()",
            "        org = factories.Organization(user=user)",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_group\", context={\"user\": user[\"name\"]}, **org",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestFollowUser(object):",
            "    def test_no_activity(self, app):",
            "",
            "        user = factories.User()",
            "        user2 = factories.User()",
            "        _clear_activities()",
            "        helpers.call_action(",
            "            \"follow_user\", context={\"user\": user[\"name\"]}, **user2",
            "        )",
            "",
            "        activities = helpers.call_action(\"user_activity_list\", id=user[\"id\"])",
            "        assert [activity[\"activity_type\"] for activity in activities] == []",
            "        # A follow creates no Activity, since:",
            "        # https://github.com/ckan/ckan/pull/317",
            "",
            "",
            "@pytest.mark.usefixtures(u\"clean_db\")",
            "class TestApiToken(object):",
            "",
            "    def test_token_created(self):",
            "        from ckan.lib.api_token import decode",
            "        user = factories.User()",
            "        data = helpers.call_action(u\"api_token_create\", context={",
            "            u\"model\": model,",
            "            u\"user\": user[u\"name\"]",
            "        }, user=user[u\"name\"], name=u\"token-name\")",
            "        token = data[u'token']",
            "        jti = decode(token)[u'jti']",
            "        res = model.ApiToken.get(jti)",
            "        assert res.user_id == user[u\"id\"]",
            "        assert res.last_access is None",
            "        assert res.id == jti",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "@pytest.mark.ckan_config(u\"ckan.auth.allow_dataset_collaborators\", False)",
            "def test_create_package_collaborator_when_config_disabled():",
            "",
            "    dataset = factories.Dataset()",
            "    user = factories.User()",
            "    capacity = 'editor'",
            "",
            "    with pytest.raises(logic.ValidationError):",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "@pytest.mark.ckan_config(u\"ckan.auth.allow_dataset_collaborators\", True)",
            "class TestPackageMemberCreate(object):",
            "",
            "    def test_create(self):",
            "",
            "        dataset = factories.Dataset()",
            "        user = factories.User()",
            "        capacity = 'editor'",
            "",
            "        member = helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "        assert member['package_id'] == dataset['id']",
            "        assert member['user_id'] == user['id']",
            "        assert member['capacity'] == capacity",
            "",
            "        assert model.Session.query(model.PackageMember).count() == 1",
            "",
            "    def test_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "        user = factories.User()",
            "        capacity = 'editor'",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='member')",
            "",
            "        assert model.Session.query(model.PackageMember).count() == 1",
            "",
            "        assert model.Session.query(model.PackageMember).one().capacity == 'member'",
            "",
            "    def test_create_wrong_capacity(self):",
            "        dataset = factories.Dataset()",
            "        user = factories.User()",
            "        capacity = 'unknown'",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                'package_collaborator_create',",
            "                id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "    def test_create_dataset_not_found(self):",
            "        dataset = {'id': 'xxx'}",
            "        user = factories.User()",
            "        capacity = 'editor'",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(",
            "                'package_collaborator_create',",
            "                id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "    def test_create_user_not_found(self):",
            "        dataset = factories.Dataset()",
            "        user = {'id': 'yyy'}",
            "        capacity = 'editor'",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(",
            "                'package_collaborator_create',",
            "                id=dataset['id'], user_id=user['id'], capacity=capacity)",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "@pytest.mark.ckan_config(\"ckan.auth.create_user_via_web\", True)",
            "class TestUserPluginExtras(object):",
            "",
            "    def test_stored_on_create_if_sysadmin(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user_dict = {",
            "            'name': 'test-user',",
            "            'email': 'test@example.com',",
            "            'password': '12345678',",
            "            'plugin_extras': {",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        }",
            "",
            "        # helpers.call_action sets 'ignore_auth' to True by default",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_create', context=context, **user_dict)",
            "",
            "        assert created_user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1',",
            "            }",
            "        }",
            "",
            "        user_dict = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user_dict['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1',",
            "            }",
            "        }",
            "",
            "        plugin_extras_from_db = model.Session.execute(",
            "            'SELECT plugin_extras FROM \"user\" WHERE id=:id',",
            "            {'id': created_user['id']}",
            "        ).first().values()[0]",
            "",
            "        assert plugin_extras_from_db == {",
            "            'plugin1': {",
            "                'key1': 'value1',",
            "            }",
            "        }",
            "",
            "    def test_ignored_on_create_if_non_sysadmin(self):",
            "",
            "        author = factories.User()",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user_dict = {",
            "            'name': 'test-user',",
            "            'email': 'test@example.com',",
            "            'password': '12345678',",
            "            'plugin_extras': {",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        }",
            "",
            "        # helpers.call_action sets 'ignore_auth' to True by default",
            "        context = {'user': author['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_create', context=context, **user_dict)",
            "",
            "        assert 'plugin_extras' not in created_user",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user['plugin_extras'] is None",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "class TestUserImageUrl(object):",
            "    def test_external_picture(self):",
            "",
            "        params = {",
            "            'name': 'test_user',",
            "            'email': 'test@example.com',",
            "            'password': '12345678',",
            "            'image_url': 'https://example.com/mypic.png',",
            "        }",
            "",
            "        user_dict = helpers.call_action(\"user_create\", {}, **params)",
            "",
            "        assert user_dict[\"image_url\"] == \"https://example.com/mypic.png\"",
            "        assert (",
            "            user_dict[\"image_display_url\"] == \"https://example.com/mypic.png\"",
            "        )",
            "",
            "    def test_upload_non_picture_not_works_without_extra_config(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            assert create_with_upload(\"hello world\", \"file.txt\", **params)",
            "",
            "    def test_upload_svg_fails_without_extra_config(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload('<svg xmlns=\"http://www.w3.org/2000/svg\"></svg>', \"file.svg\", **params)",
            "",
            "    def test_upload_svg_wrong_extension_fails_without_extra_config(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload('<svg xmlns=\"http://www.w3.org/2000/svg\"></svg>', \"file.png\", **params)",
            "",
            "    @pytest.mark.ckan_config(\"ckan.upload.user.types\", \"image\")",
            "    def test_upload_non_picture(self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload(\"hello world\", \"file.txt\", **params)",
            "",
            "    @pytest.mark.ckan_config(\"ckan.upload.user.types\", \"image\")",
            "    def test_upload_non_picture_with_png_extension(",
            "            self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "        with pytest.raises(",
            "                logic.ValidationError, match=\"Unsupported upload type\"):",
            "            create_with_upload(\"hello world\", \"file.png\", **params)",
            "",
            "    def test_upload_picture(self, create_with_upload):",
            "        params = {",
            "            \"name\": \"test_user_1\",",
            "            \"email\": \"test1@example.com\",",
            "            \"password\": \"12345678\",",
            "            \"action\": \"user_create\",",
            "            \"upload_field_name\": \"image_upload\",",
            "        }",
            "",
            "        some_png = \"\"\"",
            "        89 50 4E 47 0D 0A 1A 0A 00 00 00 0D 49 48 44 52",
            "        00 00 00 01 00 00 00 01 08 02 00 00 00 90 77 53",
            "        DE 00 00 00 0C 49 44 41 54 08 D7 63 F8 CF C0 00",
            "        00 03 01 01 00 18 DD 8D B0 00 00 00 00 49 45 4E",
            "        44 AE 42 60 82\"\"\"",
            "        some_png = some_png.replace(' ', '').replace('\\n', '')",
            "        some_png_bytes = bytes(bytearray.fromhex(some_png))",
            "        assert create_with_upload(some_png_bytes, \"file.png\", **params)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "tlslite.tlsrecordlayer",
            "ckan.tests.logic.action.test_create.TestResourceCreate.self"
        ]
    },
    "ckan/tests/logic/action/test_patch.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from ckan.tests import helpers, factories"
            },
            "2": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from ckan.logic.action.get import package_show as core_package_show"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+from ckan.logic import ValidationError"
            },
            "4": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " @pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")"
            },
            "7": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 28,
                "PatchRowcode": "         assert dataset2[\"name\"] == \"somethingnew\""
            },
            "8": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 29,
                "PatchRowcode": "         assert dataset2[\"notes\"] == \"some test now\""
            },
            "9": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+    def test_package_patch_invalid_characters_in_resource_id(self):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+        user = factories.User()"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+        dataset = factories.Dataset(user=user)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+        with pytest.raises(ValidationError):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+            helpers.call_action("
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+                \"package_patch\","
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+                id=dataset[\"id\"],"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+                resources=["
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+                    {"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+                        \"id\": \"../../nope.txt\","
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+                        \"url\": \"http://data\","
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+                        \"name\": \"A nice resource\","
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+                    },"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+                ],"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+            )"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 48,
                "PatchRowcode": "     def test_resource_patch_updating_single_field(self):"
            },
            "28": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 49,
                "PatchRowcode": "         user = factories.User()"
            },
            "29": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "         dataset = factories.Dataset("
            }
        },
        "frontPatchFile": [
            "# encoding: utf-8",
            "\"\"\"Unit tests for ckan/logic/action/patch.py.\"\"\"",
            "import pytest",
            "import mock",
            "",
            "from ckan.tests import helpers, factories",
            "from ckan.logic.action.get import package_show as core_package_show",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestPatch(object):",
            "    def test_package_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            name=\"annakarenina\", notes=\"some test now\", user=user",
            "        )",
            "",
            "        dataset = helpers.call_action(",
            "            \"package_patch\", id=dataset[\"id\"], name=\"somethingnew\"",
            "        )",
            "",
            "        assert dataset[\"name\"] == \"somethingnew\"",
            "        assert dataset[\"notes\"] == \"some test now\"",
            "",
            "        dataset2 = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        assert dataset2[\"name\"] == \"somethingnew\"",
            "        assert dataset2[\"notes\"] == \"some test now\"",
            "",
            "    def test_resource_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            name=\"annakarenina\",",
            "            notes=\"some test now\",",
            "            user=user,",
            "            resources=[{\"url\": \"http://example.com/resource\"}],",
            "        )",
            "",
            "        resource = helpers.call_action(",
            "            \"resource_patch\",",
            "            id=dataset[\"resources\"][0][\"id\"],",
            "            name=\"somethingnew\",",
            "        )",
            "",
            "        assert resource[\"name\"] == \"somethingnew\"",
            "        assert resource[\"url\"] == \"http://example.com/resource\"",
            "",
            "        dataset2 = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        resource2 = dataset2[\"resources\"][0]",
            "        assert resource2[\"name\"] == \"somethingnew\"",
            "        assert resource2[\"url\"] == \"http://example.com/resource\"",
            "",
            "    def test_group_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        group = factories.Group(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\",",
            "            id=group[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert group[\"name\"] == \"economy\"",
            "        assert group[\"description\"] == \"somethingnew\"",
            "",
            "        group2 = helpers.call_action(\"group_show\", id=group[\"id\"])",
            "",
            "        assert group2[\"name\"] == \"economy\"",
            "        assert group2[\"description\"] == \"somethingnew\"",
            "",
            "    @pytest.mark.ckan_config(u\"ckan.auth.public_user_details\", u\"false\")",
            "    def test_group_patch_updating_single_field_when_public_user_details_is_false(self):",
            "        user = factories.User()",
            "        group = factories.Group(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\",",
            "            id=group[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert group[\"name\"] == \"economy\"",
            "        assert group[\"description\"] == \"somethingnew\"",
            "",
            "        group2 = helpers.call_action(\"group_show\", id=group[\"id\"], include_users=True)",
            "",
            "        assert group2[\"name\"] == \"economy\"",
            "        assert group2[\"description\"] == \"somethingnew\"",
            "        assert len(group2[\"users\"]) == 1",
            "        assert group2[\"users\"][0][\"name\"] == user[\"name\"]",
            "",
            "    def test_group_patch_preserve_datasets(self):",
            "        user = factories.User()",
            "        group = factories.Group(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "        factories.Dataset(groups=[{\"name\": group[\"name\"]}])",
            "",
            "        group2 = helpers.call_action(\"group_show\", id=group[\"id\"])",
            "        assert 1 == group2[\"package_count\"]",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\", id=group[\"id\"], context={\"user\": user[\"name\"]}",
            "        )",
            "",
            "        group3 = helpers.call_action(\"group_show\", id=group[\"id\"])",
            "        assert 1 == group3[\"package_count\"]",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\",",
            "            id=group[\"id\"],",
            "            packages=[],",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        group4 = helpers.call_action(",
            "            \"group_show\", id=group[\"id\"], include_datasets=True",
            "        )",
            "        assert 0 == group4[\"package_count\"]",
            "",
            "    def test_organization_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        organization = factories.Organization(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        organization = helpers.call_action(",
            "            \"organization_patch\",",
            "            id=organization[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert organization[\"name\"] == \"economy\"",
            "        assert organization[\"description\"] == \"somethingnew\"",
            "",
            "        organization2 = helpers.call_action(",
            "            \"organization_show\", id=organization[\"id\"]",
            "        )",
            "",
            "        assert organization2[\"name\"] == \"economy\"",
            "        assert organization2[\"description\"] == \"somethingnew\"",
            "",
            "    @pytest.mark.ckan_config(u\"ckan.auth.public_user_details\", u\"false\")",
            "    def test_organization_patch_updating_single_field_when_public_user_details_is_false(self):",
            "        user = factories.User()",
            "        organization = factories.Organization(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        organization = helpers.call_action(",
            "            \"organization_patch\",",
            "            id=organization[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert organization[\"name\"] == \"economy\"",
            "        assert organization[\"description\"] == \"somethingnew\"",
            "",
            "        organization2 = helpers.call_action(",
            "            \"organization_show\", id=organization[\"id\"], include_users=True",
            "        )",
            "",
            "        assert organization2[\"name\"] == \"economy\"",
            "        assert organization2[\"description\"] == \"somethingnew\"",
            "        assert len(organization2[\"users\"]) == 1",
            "        assert organization2[\"users\"][0][\"name\"] == user[\"name\"]",
            "",
            "    def test_package_patch_for_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "",
            "        mock_package_show = mock.MagicMock()",
            "        mock_package_show.side_effect = lambda context, data_dict: core_package_show(context, data_dict)",
            "",
            "        with mock.patch.dict('ckan.logic._actions', {'package_show': mock_package_show}):",
            "            helpers.call_action('package_patch', id=dataset['id'], notes='hey')",
            "            assert mock_package_show.call_args_list[0][0][0].get('for_update') is True",
            "",
            "    def test_resource_patch_for_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        mock_package_show = mock.MagicMock()",
            "        mock_package_show.side_effect = lambda context, data_dict: core_package_show(context, data_dict)",
            "",
            "        with mock.patch.dict('ckan.logic._actions', {'package_show': mock_package_show}):",
            "            helpers.call_action('resource_patch', id=resource['id'], description='hey')",
            "            assert mock_package_show.call_args_list[0][0][0].get('for_update') is True",
            "",
            "    def test_resource_update_for_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        mock_package_show = mock.MagicMock()",
            "        mock_package_show.side_effect = lambda context, data_dict: core_package_show(context, data_dict)",
            "",
            "        with mock.patch.dict('ckan.logic._actions', {'package_show': mock_package_show}):",
            "            helpers.call_action('resource_update', id=resource['id'], description='hey')",
            "            assert mock_package_show.call_args_list[0][0][0].get('for_update') is True",
            "",
            "    def test_user_patch_updating_single_field(self):",
            "        user = factories.User(",
            "            fullname=\"Mr. Test User\",",
            "            about=\"Just another test user.\",",
            "        )",
            "",
            "        user = helpers.call_action(",
            "            \"user_patch\",",
            "            id=user[\"id\"],",
            "            about=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert user[\"fullname\"] == \"Mr. Test User\"",
            "        assert user[\"about\"] == \"somethingnew\"",
            "",
            "        user2 = helpers.call_action(\"user_show\", id=user[\"id\"])",
            "",
            "        assert user2[\"fullname\"] == \"Mr. Test User\"",
            "        assert user2[\"about\"] == \"somethingnew\""
        ],
        "afterPatchFile": [
            "# encoding: utf-8",
            "\"\"\"Unit tests for ckan/logic/action/patch.py.\"\"\"",
            "import pytest",
            "import mock",
            "",
            "from ckan.tests import helpers, factories",
            "from ckan.logic.action.get import package_show as core_package_show",
            "from ckan.logic import ValidationError",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestPatch(object):",
            "    def test_package_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            name=\"annakarenina\", notes=\"some test now\", user=user",
            "        )",
            "",
            "        dataset = helpers.call_action(",
            "            \"package_patch\", id=dataset[\"id\"], name=\"somethingnew\"",
            "        )",
            "",
            "        assert dataset[\"name\"] == \"somethingnew\"",
            "        assert dataset[\"notes\"] == \"some test now\"",
            "",
            "        dataset2 = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        assert dataset2[\"name\"] == \"somethingnew\"",
            "        assert dataset2[\"notes\"] == \"some test now\"",
            "",
            "    def test_package_patch_invalid_characters_in_resource_id(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        with pytest.raises(ValidationError):",
            "            helpers.call_action(",
            "                \"package_patch\",",
            "                id=dataset[\"id\"],",
            "                resources=[",
            "                    {",
            "                        \"id\": \"../../nope.txt\",",
            "                        \"url\": \"http://data\",",
            "                        \"name\": \"A nice resource\",",
            "                    },",
            "                ],",
            "            )",
            "",
            "    def test_resource_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            name=\"annakarenina\",",
            "            notes=\"some test now\",",
            "            user=user,",
            "            resources=[{\"url\": \"http://example.com/resource\"}],",
            "        )",
            "",
            "        resource = helpers.call_action(",
            "            \"resource_patch\",",
            "            id=dataset[\"resources\"][0][\"id\"],",
            "            name=\"somethingnew\",",
            "        )",
            "",
            "        assert resource[\"name\"] == \"somethingnew\"",
            "        assert resource[\"url\"] == \"http://example.com/resource\"",
            "",
            "        dataset2 = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        resource2 = dataset2[\"resources\"][0]",
            "        assert resource2[\"name\"] == \"somethingnew\"",
            "        assert resource2[\"url\"] == \"http://example.com/resource\"",
            "",
            "    def test_group_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        group = factories.Group(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\",",
            "            id=group[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert group[\"name\"] == \"economy\"",
            "        assert group[\"description\"] == \"somethingnew\"",
            "",
            "        group2 = helpers.call_action(\"group_show\", id=group[\"id\"])",
            "",
            "        assert group2[\"name\"] == \"economy\"",
            "        assert group2[\"description\"] == \"somethingnew\"",
            "",
            "    @pytest.mark.ckan_config(u\"ckan.auth.public_user_details\", u\"false\")",
            "    def test_group_patch_updating_single_field_when_public_user_details_is_false(self):",
            "        user = factories.User()",
            "        group = factories.Group(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\",",
            "            id=group[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert group[\"name\"] == \"economy\"",
            "        assert group[\"description\"] == \"somethingnew\"",
            "",
            "        group2 = helpers.call_action(\"group_show\", id=group[\"id\"], include_users=True)",
            "",
            "        assert group2[\"name\"] == \"economy\"",
            "        assert group2[\"description\"] == \"somethingnew\"",
            "        assert len(group2[\"users\"]) == 1",
            "        assert group2[\"users\"][0][\"name\"] == user[\"name\"]",
            "",
            "    def test_group_patch_preserve_datasets(self):",
            "        user = factories.User()",
            "        group = factories.Group(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "        factories.Dataset(groups=[{\"name\": group[\"name\"]}])",
            "",
            "        group2 = helpers.call_action(\"group_show\", id=group[\"id\"])",
            "        assert 1 == group2[\"package_count\"]",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\", id=group[\"id\"], context={\"user\": user[\"name\"]}",
            "        )",
            "",
            "        group3 = helpers.call_action(\"group_show\", id=group[\"id\"])",
            "        assert 1 == group3[\"package_count\"]",
            "",
            "        group = helpers.call_action(",
            "            \"group_patch\",",
            "            id=group[\"id\"],",
            "            packages=[],",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        group4 = helpers.call_action(",
            "            \"group_show\", id=group[\"id\"], include_datasets=True",
            "        )",
            "        assert 0 == group4[\"package_count\"]",
            "",
            "    def test_organization_patch_updating_single_field(self):",
            "        user = factories.User()",
            "        organization = factories.Organization(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        organization = helpers.call_action(",
            "            \"organization_patch\",",
            "            id=organization[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert organization[\"name\"] == \"economy\"",
            "        assert organization[\"description\"] == \"somethingnew\"",
            "",
            "        organization2 = helpers.call_action(",
            "            \"organization_show\", id=organization[\"id\"]",
            "        )",
            "",
            "        assert organization2[\"name\"] == \"economy\"",
            "        assert organization2[\"description\"] == \"somethingnew\"",
            "",
            "    @pytest.mark.ckan_config(u\"ckan.auth.public_user_details\", u\"false\")",
            "    def test_organization_patch_updating_single_field_when_public_user_details_is_false(self):",
            "        user = factories.User()",
            "        organization = factories.Organization(",
            "            name=\"economy\", description=\"some test now\", user=user",
            "        )",
            "",
            "        organization = helpers.call_action(",
            "            \"organization_patch\",",
            "            id=organization[\"id\"],",
            "            description=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert organization[\"name\"] == \"economy\"",
            "        assert organization[\"description\"] == \"somethingnew\"",
            "",
            "        organization2 = helpers.call_action(",
            "            \"organization_show\", id=organization[\"id\"], include_users=True",
            "        )",
            "",
            "        assert organization2[\"name\"] == \"economy\"",
            "        assert organization2[\"description\"] == \"somethingnew\"",
            "        assert len(organization2[\"users\"]) == 1",
            "        assert organization2[\"users\"][0][\"name\"] == user[\"name\"]",
            "",
            "    def test_package_patch_for_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "",
            "        mock_package_show = mock.MagicMock()",
            "        mock_package_show.side_effect = lambda context, data_dict: core_package_show(context, data_dict)",
            "",
            "        with mock.patch.dict('ckan.logic._actions', {'package_show': mock_package_show}):",
            "            helpers.call_action('package_patch', id=dataset['id'], notes='hey')",
            "            assert mock_package_show.call_args_list[0][0][0].get('for_update') is True",
            "",
            "    def test_resource_patch_for_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        mock_package_show = mock.MagicMock()",
            "        mock_package_show.side_effect = lambda context, data_dict: core_package_show(context, data_dict)",
            "",
            "        with mock.patch.dict('ckan.logic._actions', {'package_show': mock_package_show}):",
            "            helpers.call_action('resource_patch', id=resource['id'], description='hey')",
            "            assert mock_package_show.call_args_list[0][0][0].get('for_update') is True",
            "",
            "    def test_resource_update_for_update(self):",
            "",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        mock_package_show = mock.MagicMock()",
            "        mock_package_show.side_effect = lambda context, data_dict: core_package_show(context, data_dict)",
            "",
            "        with mock.patch.dict('ckan.logic._actions', {'package_show': mock_package_show}):",
            "            helpers.call_action('resource_update', id=resource['id'], description='hey')",
            "            assert mock_package_show.call_args_list[0][0][0].get('for_update') is True",
            "",
            "    def test_user_patch_updating_single_field(self):",
            "        user = factories.User(",
            "            fullname=\"Mr. Test User\",",
            "            about=\"Just another test user.\",",
            "        )",
            "",
            "        user = helpers.call_action(",
            "            \"user_patch\",",
            "            id=user[\"id\"],",
            "            about=\"somethingnew\",",
            "            context={\"user\": user[\"name\"]},",
            "        )",
            "",
            "        assert user[\"fullname\"] == \"Mr. Test User\"",
            "        assert user[\"about\"] == \"somethingnew\"",
            "",
            "        user2 = helpers.call_action(\"user_show\", id=user[\"id\"])",
            "",
            "        assert user2[\"fullname\"] == \"Mr. Test User\"",
            "        assert user2[\"about\"] == \"somethingnew\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "tlslite.tlsrecordlayer",
            "ckan.tests.logic.action.test_patch.TestPatch.self"
        ]
    },
    "ckan/tests/logic/action/test_update.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 660,
                "afterPatchRowNumber": 660,
                "PatchRowcode": "         assert resources_[1][\"url\"] == \"http://datahub.io/index.json\""
            },
            "1": {
                "beforePatchRowNumber": 661,
                "afterPatchRowNumber": 661,
                "PatchRowcode": "         assert resources_[1][\"position\"] == 1"
            },
            "2": {
                "beforePatchRowNumber": 662,
                "afterPatchRowNumber": 662,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 663,
                "PatchRowcode": "+    def test_invalid_characters_in_resource_id(self):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 664,
                "PatchRowcode": "+        user = factories.User()"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 665,
                "PatchRowcode": "+        dataset = factories.Dataset(user=user)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 666,
                "PatchRowcode": "+"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 667,
                "PatchRowcode": "+        with pytest.raises(logic.ValidationError):"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 668,
                "PatchRowcode": "+            helpers.call_action("
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 669,
                "PatchRowcode": "+                \"package_update\","
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 670,
                "PatchRowcode": "+                id=dataset[\"id\"],"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 671,
                "PatchRowcode": "+                resources=["
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 672,
                "PatchRowcode": "+                    {"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 673,
                "PatchRowcode": "+                        \"id\": \"../../nope.txt\","
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 674,
                "PatchRowcode": "+                        \"url\": \"http://data\","
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 675,
                "PatchRowcode": "+                        \"name\": \"A nice resource\","
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 676,
                "PatchRowcode": "+                    },"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 677,
                "PatchRowcode": "+                ],"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 678,
                "PatchRowcode": "+            )"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 679,
                "PatchRowcode": "+"
            },
            "20": {
                "beforePatchRowNumber": 663,
                "afterPatchRowNumber": 680,
                "PatchRowcode": "     def test_tags(self):"
            },
            "21": {
                "beforePatchRowNumber": 664,
                "afterPatchRowNumber": 681,
                "PatchRowcode": "         user = factories.User()"
            },
            "22": {
                "beforePatchRowNumber": 665,
                "afterPatchRowNumber": 682,
                "PatchRowcode": "         dataset = factories.Dataset(user=user)"
            },
            "23": {
                "beforePatchRowNumber": 1925,
                "afterPatchRowNumber": 1942,
                "PatchRowcode": "         )"
            },
            "24": {
                "beforePatchRowNumber": 1926,
                "afterPatchRowNumber": 1943,
                "PatchRowcode": "         assert response['package']['resources'][0]['name'] == 'new resource'"
            },
            "25": {
                "beforePatchRowNumber": 1927,
                "afterPatchRowNumber": 1944,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1945,
                "PatchRowcode": "+    def test_revise_invalid_resource_id(self):"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1946,
                "PatchRowcode": "+        dataset = factories.Dataset()"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1947,
                "PatchRowcode": "+        with pytest.raises(logic.ValidationError):"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1948,
                "PatchRowcode": "+            helpers.call_action("
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1949,
                "PatchRowcode": "+                'package_revise',"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1950,
                "PatchRowcode": "+                match={'id': dataset['id']},"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1951,
                "PatchRowcode": "+                update__resources__extend=["
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1952,
                "PatchRowcode": "+                    {"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1953,
                "PatchRowcode": "+                        'id': '../../nope.txt',"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1954,
                "PatchRowcode": "+                        'name': 'new resource',"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1955,
                "PatchRowcode": "+                        'url': 'http://example.com'"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1956,
                "PatchRowcode": "+                    }"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1957,
                "PatchRowcode": "+                ],"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1958,
                "PatchRowcode": "+            )"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1959,
                "PatchRowcode": "+"
            },
            "41": {
                "beforePatchRowNumber": 1928,
                "afterPatchRowNumber": 1960,
                "PatchRowcode": "     def test_revise_resource_by_index(self):"
            },
            "42": {
                "beforePatchRowNumber": 1929,
                "afterPatchRowNumber": 1961,
                "PatchRowcode": "         dataset = factories.Dataset(resources=[{'url': 'http://example.com'}])"
            },
            "43": {
                "beforePatchRowNumber": 1930,
                "afterPatchRowNumber": 1962,
                "PatchRowcode": "         response = helpers.call_action("
            }
        },
        "frontPatchFile": [
            "# encoding: utf-8",
            "\"\"\"Unit tests for ckan/logic/action/update.py.\"\"\"",
            "import datetime",
            "",
            "import mock",
            "import pytest",
            "import six",
            "",
            "import ckan",
            "import ckan.lib.app_globals as app_globals",
            "import ckan.logic as logic",
            "import ckan.plugins as p",
            "import ckan.tests.factories as factories",
            "import ckan.tests.helpers as helpers",
            "from ckan import model",
            "",
            "from freezegun import freeze_time",
            "",
            "",
            "def datetime_from_string(s):",
            "    \"\"\"Return a standard datetime.datetime object initialised from a string in",
            "    the same format used for timestamps in dictized activities (the format",
            "    produced by datetime.datetime.isoformat())",
            "",
            "    \"\"\"",
            "    return datetime.datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S.%f\")",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestUpdate(object):",
            "    def teardown(self):",
            "        # Since some of the test methods below use the mock module to patch",
            "        # things, we use this teardown() method to remove remove all patches.",
            "        # (This makes sure the patches always get removed even if the test",
            "        # method aborts with an exception or something.)",
            "        mock.patch.stopall()",
            "",
            "    # START-AFTER",
            "",
            "    def test_user_update_name(self):",
            "        \"\"\"Test that updating a user's name works successfully.\"\"\"",
            "",
            "        # The canonical form of a test has four steps:",
            "        # 1. Setup any preconditions needed for the test.",
            "        # 2. Call the function that's being tested, once only.",
            "        # 3. Make assertions about the return value and/or side-effects of",
            "        #    of the function that's being tested.",
            "        # 4. Do nothing else!",
            "",
            "        # 1. Setup.",
            "        user = factories.User()",
            "        user[\"name\"] = \"updated\"",
            "",
            "        # 2. Make assertions about the return value and/or side-effects.",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    # END-BEFORE",
            "",
            "    def test_user_generate_apikey(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        result = helpers.call_action(",
            "            \"user_generate_apikey\", context=context, id=user[\"id\"]",
            "        )",
            "        updated_user = helpers.call_action(",
            "            \"user_show\", context=context, id=user[\"id\"]",
            "        )",
            "",
            "        assert updated_user[\"apikey\"] != user[\"apikey\"]",
            "        assert result[\"apikey\"] == updated_user[\"apikey\"]",
            "",
            "    def test_user_generate_apikey_sysadmin_user(self):",
            "        user = factories.User()",
            "        sysadmin = factories.Sysadmin()",
            "        context = {\"user\": sysadmin[\"name\"], \"ignore_auth\": False}",
            "        result = helpers.call_action(",
            "            \"user_generate_apikey\", context=context, id=user[\"id\"]",
            "        )",
            "        updated_user = helpers.call_action(",
            "            \"user_show\", context=context, id=user[\"id\"]",
            "        )",
            "",
            "        assert updated_user[\"apikey\"] != user[\"apikey\"]",
            "        assert result[\"apikey\"] == updated_user[\"apikey\"]",
            "",
            "    def test_user_generate_apikey_nonexistent_user(self):",
            "        user = {",
            "            \"id\": \"nonexistent\",",
            "            \"name\": \"nonexistent\",",
            "            \"email\": \"does@notexist.com\",",
            "        }",
            "        context = {\"user\": user[\"name\"]}",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(",
            "                \"user_generate_apikey\", context=context, id=user[\"id\"]",
            "            )",
            "",
            "    def test_user_update_with_id_that_does_not_exist(self):",
            "        user_dict = factories.User.attributes()()",
            "        user_dict[\"id\"] = \"there's no user with this id\"",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(\"user_update\", **user_dict)",
            "",
            "    def test_user_update_with_no_id(self):",
            "        user_dict = factories.User.attributes()()",
            "        assert \"id\" not in user_dict",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user_dict)",
            "",
            "    @pytest.mark.parametrize(",
            "        \"name\",",
            "        (",
            "            \"\",",
            "            \"a\",",
            "            False,",
            "            0,",
            "            -1,",
            "            23,",
            "            \"new\",",
            "            \"edit\",",
            "            \"search\",",
            "            \"a\" * 200,",
            "            \"Hi!\",",
            "            \"i++%\",",
            "        ),",
            "    )",
            "    def test_user_update_with_invalid_name(self, name):",
            "        user = factories.User()",
            "        user[\"name\"] = name",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_to_name_that_already_exists(self):",
            "        fred = factories.User(name=\"fred\")",
            "        bob = factories.User(name=\"bob\")",
            "",
            "        # Try to update fred and change his user name to bob, which is already",
            "        # bob's user name",
            "        fred[\"name\"] = bob[\"name\"]",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **fred)",
            "",
            "    def test_user_update_password(self):",
            "        \"\"\"Test that updating a user's password works successfully.\"\"\"",
            "",
            "        user = factories.User()",
            "",
            "        # FIXME we have to pass the email address to user_update even though",
            "        # we're not updating it, otherwise validation fails.",
            "        helpers.call_action(",
            "            \"user_update\",",
            "            id=user[\"id\"],",
            "            name=user[\"name\"],",
            "            email=user[\"email\"],",
            "            password=\"new password\",",
            "        )",
            "",
            "        # user_show() never returns the user's password, so we have to access",
            "        # the model directly to test it.",
            "        import ckan.model as model",
            "",
            "        updated_user = model.User.get(user[\"id\"])",
            "        assert updated_user.validate_password(\"new password\")",
            "",
            "    def test_user_update_with_short_password(self):",
            "        user = factories.User()",
            "",
            "        user[\"password\"] = \"xxx\"  # This password is too short.",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_with_empty_password(self):",
            "        \"\"\"If an empty password is passed to user_update, nothing should",
            "        happen.",
            "",
            "        No error (e.g. a validation error) is raised, but the password is not",
            "        changed either.",
            "",
            "        \"\"\"",
            "        user_dict = factories.User.attributes()()",
            "        original_password = user_dict[\"password\"]",
            "        user_dict = factories.User(**user_dict)",
            "",
            "        user_dict[\"password\"] = \"\"",
            "        helpers.call_action(\"user_update\", **user_dict)",
            "",
            "        import ckan.model as model",
            "",
            "        updated_user = model.User.get(user_dict[\"id\"])",
            "        assert updated_user.validate_password(original_password)",
            "",
            "    def test_user_update_with_null_password(self):",
            "        user = factories.User()",
            "",
            "        user[\"password\"] = None",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_with_invalid_password(self):",
            "        user = factories.User()",
            "",
            "        for password in (False, -1, 23, 30.7):",
            "            user[\"password\"] = password",
            "            with pytest.raises(logic.ValidationError):",
            "",
            "                helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_without_email_address(self):",
            "        \"\"\"You have to pass an email address when you call user_update.",
            "",
            "        Even if you don't want to change the user's email address, you still",
            "        have to pass their current email address to user_update.",
            "",
            "        FIXME: The point of this feature seems to be to prevent people from",
            "        removing email addresses from user accounts, but making them post the",
            "        current email address every time they post to user update is just",
            "        annoying, they should be able to post a dict with no 'email' key to",
            "        user_update and it should simply not change the current email.",
            "",
            "        \"\"\"",
            "        user = factories.User()",
            "        del user[\"email\"]",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    # TODO: Valid and invalid values for the rest of the user model's fields.",
            "",
            "    def test_user_update_activity_stream(self):",
            "        \"\"\"Test that the right activity is emitted when updating a user.\"\"\"",
            "",
            "        user = factories.User()",
            "        before = datetime.datetime.utcnow()",
            "",
            "        # FIXME we have to pass the email address and password to user_update",
            "        # even though we're not updating those fields, otherwise validation",
            "        # fails.",
            "        helpers.call_action(",
            "            \"user_update\",",
            "            id=user[\"id\"],",
            "            name=user[\"name\"],",
            "            email=user[\"email\"],",
            "            password=factories.User.password,",
            "            fullname=\"updated full name\",",
            "        )",
            "",
            "        activity_stream = helpers.call_action(",
            "            \"user_activity_list\", id=user[\"id\"]",
            "        )",
            "        latest_activity = activity_stream[0]",
            "        assert latest_activity[\"activity_type\"] == \"changed user\"",
            "        assert latest_activity[\"object_id\"] == user[\"id\"]",
            "        assert latest_activity[\"user_id\"] == user[\"id\"]",
            "        after = datetime.datetime.utcnow()",
            "        timestamp = datetime_from_string(latest_activity[\"timestamp\"])",
            "        assert timestamp >= before and timestamp <= after",
            "",
            "    def test_user_update_with_custom_schema(self):",
            "        \"\"\"Test that custom schemas passed to user_update do get used.",
            "",
            "        user_update allows a custom validation schema to be passed to it in the",
            "        context dict. This is just a simple test that if you pass a custom",
            "        schema user_update does at least call a custom method that's given in",
            "        the custom schema. We assume this means it did use the custom schema",
            "        instead of the default one for validation, so user_update's custom",
            "        schema feature does work.",
            "",
            "        \"\"\"",
            "        import ckan.logic.schema",
            "",
            "        user = factories.User()",
            "",
            "        # A mock validator method, it doesn't do anything but it records what",
            "        # params it gets called with and how many times.",
            "        mock_validator = mock.MagicMock()",
            "",
            "        # Build a custom schema by taking the default schema and adding our",
            "        # mock method to its 'id' field.",
            "        schema = ckan.logic.schema.default_update_user_schema()",
            "        schema[\"id\"].append(mock_validator)",
            "",
            "        # Call user_update and pass our custom schema in the context.",
            "        # FIXME: We have to pass email and password even though we're not",
            "        # trying to update them, or validation fails.",
            "        helpers.call_action(",
            "            \"user_update\",",
            "            context={\"schema\": schema},",
            "            id=user[\"id\"],",
            "            name=user[\"name\"],",
            "            email=user[\"email\"],",
            "            password=factories.User.password,",
            "            fullname=\"updated full name\",",
            "        )",
            "",
            "    def test_user_update_multiple(self):",
            "        \"\"\"Test that updating multiple user attributes at once works.\"\"\"",
            "",
            "        user = factories.User()",
            "",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            # FIXME: We shouldn't have to put email here since we're not",
            "            # updating it, but user_update sucks.",
            "            \"email\": user[\"email\"],",
            "            # FIXME: We shouldn't have to put password here since we're not",
            "            # updating it, but user_update sucks.",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        helpers.call_action(\"user_update\", **params)",
            "",
            "        updated_user = helpers.call_action(\"user_show\", id=user[\"id\"])",
            "        assert updated_user[\"fullname\"] == \"updated full name\"",
            "        assert updated_user[\"about\"] == \"updated about\"",
            "",
            "    def test_user_update_does_not_return_password(self):",
            "        \"\"\"The user dict that user_update returns should not include the user's",
            "        password.\"\"\"",
            "",
            "        user = factories.User()",
            "",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            \"email\": user[\"email\"],",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **params)",
            "        assert \"password\" not in updated_user",
            "",
            "    def test_user_update_does_not_return_apikey(self):",
            "        \"\"\"The user dict that user_update returns should not include the user's",
            "        API key.\"\"\"",
            "",
            "        user = factories.User()",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            \"email\": user[\"email\"],",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **params)",
            "        assert \"apikey\" not in updated_user",
            "",
            "    def test_user_update_does_not_return_reset_key(self):",
            "        \"\"\"The user dict that user_update returns should not include the user's",
            "        reset key.\"\"\"",
            "",
            "        import ckan.lib.mailer",
            "        import ckan.model",
            "",
            "        user = factories.User()",
            "        ckan.lib.mailer.create_reset_key(ckan.model.User.get(user[\"id\"]))",
            "",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            \"email\": user[\"email\"],",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **params)",
            "        assert \"reset_key\" not in updated_user",
            "",
            "    def test_resource_reorder(self):",
            "        resource_urls = [\"http://a.html\", \"http://b.html\", \"http://c.html\"]",
            "        dataset = {",
            "            \"name\": \"basic\",",
            "            \"resources\": [{\"url\": url} for url in resource_urls],",
            "        }",
            "",
            "        dataset = helpers.call_action(\"package_create\", **dataset)",
            "        created_resource_urls = [",
            "            resource[\"url\"] for resource in dataset[\"resources\"]",
            "        ]",
            "        assert created_resource_urls == resource_urls",
            "        mapping = dict(",
            "            (resource[\"url\"], resource[\"id\"])",
            "            for resource in dataset[\"resources\"]",
            "        )",
            "",
            "        # This should put c.html at the front",
            "        reorder = {\"id\": dataset[\"id\"], \"order\": [mapping[\"http://c.html\"]]}",
            "",
            "        helpers.call_action(\"package_resource_reorder\", **reorder)",
            "",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        reordered_resource_urls = [",
            "            resource[\"url\"] for resource in dataset[\"resources\"]",
            "        ]",
            "",
            "        assert reordered_resource_urls == [",
            "            \"http://c.html\",",
            "            \"http://a.html\",",
            "            \"http://b.html\",",
            "        ]",
            "",
            "        reorder = {",
            "            \"id\": dataset[\"id\"],",
            "            \"order\": [",
            "                mapping[\"http://b.html\"],",
            "                mapping[\"http://c.html\"],",
            "                mapping[\"http://a.html\"],",
            "            ],",
            "        }",
            "",
            "        helpers.call_action(\"package_resource_reorder\", **reorder)",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        reordered_resource_urls = [",
            "            resource[\"url\"] for resource in dataset[\"resources\"]",
            "        ]",
            "",
            "        assert reordered_resource_urls == [",
            "            \"http://b.html\",",
            "            \"http://c.html\",",
            "            \"http://a.html\",",
            "        ]",
            "",
            "    def test_normal_user_can_not_change_their_state(self):",
            "",
            "        user = factories.User(state='pending')",
            "",
            "        user['state'] = 'active'",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **user)",
            "",
            "        updated_user['state'] == 'pending'",
            "",
            "    def test_sysadmin_user_can_change_a_user_state(self):",
            "",
            "        user = factories.User(state='pending')",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user['state'] = 'active'",
            "",
            "        context = {'user': sysadmin['name']}",
            "",
            "        updated_user = helpers.call_action(\"user_update\", context=context, **user)",
            "",
            "        updated_user['state'] == 'active'",
            "",
            "    def test_update_dataset_cant_change_type(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            type=\"dataset\", name=\"unchanging\", user=user",
            "        )",
            "",
            "        dataset = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            name=\"unchanging\",",
            "            type=\"cabinet\",",
            "        )",
            "",
            "        assert dataset[\"type\"] == \"dataset\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=\"unchanging\")[\"type\"]",
            "            == \"dataset\"",
            "        )",
            "",
            "    def test_update_organization_cant_change_type(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        org = factories.Organization(",
            "            type=\"organization\", name=\"unchanging\", user=user",
            "        )",
            "",
            "        org = helpers.call_action(",
            "            \"organization_update\",",
            "            context=context,",
            "            id=org[\"id\"],",
            "            name=\"unchanging\",",
            "            type=\"ragtagband\",",
            "        )",
            "",
            "        assert org[\"type\"] == \"organization\"",
            "        assert (",
            "            helpers.call_action(\"organization_show\", id=\"unchanging\")[\"type\"]",
            "            == \"organization\"",
            "        )",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDatasetUpdate(object):",
            "    def test_missing_id(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"package_update\")",
            "",
            "    def test_name(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], name=\"new-name\"",
            "        )",
            "",
            "        assert dataset_[\"name\"] == \"new-name\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"name\"]",
            "            == \"new-name\"",
            "        )",
            "",
            "    def test_title(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], title=\"New Title\"",
            "        )",
            "",
            "        assert dataset_[\"title\"] == \"New Title\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"title\"]",
            "            == \"New Title\"",
            "        )",
            "",
            "    def test_extras(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[{\"key\": u\"original media\", \"value\": u'\"book\"'}],",
            "        )",
            "",
            "        assert dataset_[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset_[\"extras\"][0][\"value\"] == '\"book\"'",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset_[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset_[\"extras\"][0][\"value\"] == '\"book\"'",
            "",
            "    def test_extra_can_be_restored_after_deletion(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[",
            "                {\"key\": u\"old attribute\", \"value\": u'value'},",
            "                {\"key\": u\"original media\", \"value\": u'\"book\"'},",
            "            ],",
            "        )",
            "",
            "        assert len(dataset_[\"extras\"]) == 2",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[],",
            "        )",
            "",
            "        assert dataset_[\"extras\"] == []",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[",
            "                {\"key\": u\"original media\", \"value\": u'\"book\"'},",
            "                {\"key\": u\"new attribute\", \"value\": u'value'},",
            "            ],",
            "        )",
            "",
            "        assert len(dataset_[\"extras\"]) == 2",
            "",
            "    def test_license(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], license_id=\"other-open\"",
            "        )",
            "",
            "        assert dataset_[\"license_id\"] == \"other-open\"",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset_[\"license_id\"] == \"other-open\"",
            "",
            "    def test_notes(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], notes=\"some notes\"",
            "        )",
            "",
            "        assert dataset_[\"notes\"] == \"some notes\"",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset_[\"notes\"] == \"some notes\"",
            "",
            "    def test_resources(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            resources=[",
            "                {",
            "                    \"alt_url\": u\"alt123\",",
            "                    \"description\": u\"Full text.\",",
            "                    \"somekey\": \"somevalue\",  # this is how to do resource extras",
            "                    \"extras\": {u\"someotherkey\": u\"alt234\"},  # this isnt",
            "                    \"format\": u\"plain text\",",
            "                    \"hash\": u\"abc123\",",
            "                    \"position\": 0,",
            "                    \"url\": u\"http://datahub.io/download/\",",
            "                },",
            "                {",
            "                    \"description\": u\"Index of the novel\",",
            "                    \"format\": u\"JSON\",",
            "                    \"position\": 1,",
            "                    \"url\": u\"http://datahub.io/index.json\",",
            "                },",
            "            ],",
            "        )",
            "",
            "        resources_ = dataset_[\"resources\"]",
            "        assert resources_[0][\"alt_url\"] == \"alt123\"",
            "        assert resources_[0][\"description\"] == \"Full text.\"",
            "        assert resources_[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources_[0]",
            "        assert \"someotherkey\" not in resources_[0]",
            "        assert resources_[0][\"format\"] == \"plain text\"",
            "        assert resources_[0][\"hash\"] == \"abc123\"",
            "        assert resources_[0][\"position\"] == 0",
            "        assert resources_[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources_[1][\"description\"] == \"Index of the novel\"",
            "        assert resources_[1][\"format\"] == \"JSON\"",
            "        assert resources_[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources_[1][\"position\"] == 1",
            "        resources_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ]",
            "        assert resources_[0][\"alt_url\"] == \"alt123\"",
            "        assert resources_[0][\"description\"] == \"Full text.\"",
            "        assert resources_[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources_[0]",
            "        assert \"someotherkey\" not in resources_[0]",
            "        assert resources_[0][\"format\"] == \"plain text\"",
            "        assert resources_[0][\"hash\"] == \"abc123\"",
            "        assert resources_[0][\"position\"] == 0",
            "        assert resources_[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources_[1][\"description\"] == \"Index of the novel\"",
            "        assert resources_[1][\"format\"] == \"JSON\"",
            "        assert resources_[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources_[1][\"position\"] == 1",
            "",
            "    def test_tags(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            tags=[{\"name\": u\"russian\"}, {\"name\": u\"tolstoy\"}],",
            "        )",
            "",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset_[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset_[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "",
            "    def test_return_id_only(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        updated_dataset = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            notes=\"Test\",",
            "            context={\"return_id_only\": True},",
            "        )",
            "",
            "        assert updated_dataset == dataset[\"id\"]",
            "",
            "",
            "@pytest.mark.usefixtures(\"with_request_context\")",
            "class TestUpdateSendEmailNotifications(object):",
            "    @pytest.mark.ckan_config(\"ckan.activity_streams_email_notifications\", True)",
            "    @mock.patch(\"ckan.logic.action.update.request\")",
            "    def test_calling_through_paster_doesnt_validates_auth(self, mock_request):",
            "        mock_request.environ.get.return_value = True",
            "        helpers.call_action(\"send_email_notifications\")",
            "",
            "    @pytest.mark.ckan_config(\"ckan.activity_streams_email_notifications\", True)",
            "    @mock.patch(\"ckan.logic.action.update.request\")",
            "    def test_not_calling_through_paster_validates_auth(self, mock_request):",
            "        mock_request.environ.get.return_value = False",
            "        with pytest.raises(logic.NotAuthorized):",
            "            helpers.call_action(",
            "                \"send_email_notifications\", context={\"ignore_auth\": False}",
            "            )",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\", \"with_request_context\")",
            "class TestResourceViewUpdate(object):",
            "    def test_resource_view_update(self):",
            "        resource_view = factories.ResourceView()",
            "        params = {",
            "            \"id\": resource_view[\"id\"],",
            "            \"title\": \"new title\",",
            "            \"description\": \"new description\",",
            "        }",
            "",
            "        result = helpers.call_action(\"resource_view_update\", **params)",
            "",
            "        assert result[\"title\"] == params[\"title\"]",
            "        assert result[\"description\"] == params[\"description\"]",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_converts_filter_fields_and_values_into_filters_dict(",
            "        self, datapreview_mock",
            "    ):",
            "        filterable_view = mock.MagicMock()",
            "        filterable_view.info.return_value = {\"filterable\": True}",
            "        datapreview_mock.get_view_plugin.return_value = filterable_view",
            "        resource_view = factories.ResourceView()",
            "        context = {}",
            "        params = {",
            "            \"id\": resource_view[\"id\"],",
            "            \"filter_fields\": [\"country\", \"weather\", \"country\"],",
            "            \"filter_values\": [\"Brazil\", \"warm\", \"Argentina\"],",
            "        }",
            "        result = helpers.call_action(\"resource_view_update\", context, **params)",
            "        expected_filters = {",
            "            \"country\": [\"Brazil\", \"Argentina\"],",
            "            \"weather\": [\"warm\"],",
            "        }",
            "        assert result[\"filters\"] == expected_filters",
            "",
            "    def test_resource_view_update_requires_id(self):",
            "        params = {}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_update\", **params)",
            "",
            "    def test_resource_view_update_requires_existing_id(self):",
            "        params = {\"id\": \"inexistent_id\"}",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(\"resource_view_update\", **params)",
            "",
            "    def test_resource_view_list_reorder(self):",
            "        resource_view_1 = factories.ResourceView(title=\"View 1\")",
            "",
            "        resource_id = resource_view_1[\"resource_id\"]",
            "",
            "        resource_view_2 = factories.ResourceView(",
            "            resource_id=resource_id, title=\"View 2\"",
            "        )",
            "",
            "        resource_view_list = helpers.call_action(",
            "            \"resource_view_list\", id=resource_id",
            "        )",
            "",
            "        assert resource_view_list[0][\"title\"] == \"View 1\"",
            "        assert resource_view_list[1][\"title\"] == \"View 2\"",
            "",
            "        # Reorder views",
            "",
            "        result = helpers.call_action(",
            "            \"resource_view_reorder\",",
            "            id=resource_id,",
            "            order=[resource_view_2[\"id\"], resource_view_1[\"id\"]],",
            "        )",
            "        assert result[\"order\"] == [",
            "            resource_view_2[\"id\"],",
            "            resource_view_1[\"id\"],",
            "        ]",
            "",
            "        resource_view_list = helpers.call_action(",
            "            \"resource_view_list\", id=resource_id",
            "        )",
            "",
            "        assert resource_view_list[0][\"title\"] == \"View 2\"",
            "        assert resource_view_list[1][\"title\"] == \"View 1\"",
            "",
            "    def test_resource_view_list_reorder_just_one_id(self):",
            "        resource_view_1 = factories.ResourceView(title=\"View 1\")",
            "",
            "        resource_id = resource_view_1[\"resource_id\"]",
            "",
            "        resource_view_2 = factories.ResourceView(",
            "            resource_id=resource_id, title=\"View 2\"",
            "        )",
            "",
            "        # Reorder Views back just by specifiying a single view to go first",
            "",
            "        result = helpers.call_action(",
            "            \"resource_view_reorder\",",
            "            id=resource_id,",
            "            order=[resource_view_2[\"id\"]],",
            "        )",
            "        assert result[\"order\"] == [",
            "            resource_view_2[\"id\"],",
            "            resource_view_1[\"id\"],",
            "        ]",
            "",
            "        resource_view_list = helpers.call_action(",
            "            \"resource_view_list\", id=resource_id",
            "        )",
            "",
            "        assert resource_view_list[0][\"title\"] == \"View 2\"",
            "        assert resource_view_list[1][\"title\"] == \"View 1\"",
            "",
            "    def test_calling_with_only_id_doesnt_update_anything(self):",
            "        resource_view = factories.ResourceView()",
            "        params = {\"id\": resource_view[\"id\"]}",
            "",
            "        result = helpers.call_action(\"resource_view_update\", **params)",
            "        assert result == resource_view",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view recline_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\", \"with_request_context\")",
            "class TestResourceUpdate(object):",
            "",
            "    def test_url_only(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package=dataset, url=\"http://first\")",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\", id=resource[\"id\"], url=\"http://second\"",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert resource[\"url\"] == \"http://second\"",
            "",
            "    def test_extra_only(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package=dataset, newfield=\"first\")",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=resource[\"url\"],",
            "            newfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"newfield\"] == \"second\"",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert resource[\"newfield\"] == \"second\"",
            "",
            "    def test_both_extra_and_url(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://first\", newfield=\"first\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://second\",",
            "            newfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert res_returned[\"newfield\"] == \"second\"",
            "",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert resource[\"newfield\"] == \"second\"",
            "",
            "    def test_extra_gets_deleted_on_both_core_and_extra_update(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://first\", newfield=\"first\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://second\",",
            "            anotherfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "    def test_extra_gets_deleted_on_extra_only_update(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://first\", newfield=\"first\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://first\",",
            "            anotherfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://first\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert res_returned[\"url\"] == \"http://first\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "    def test_datastore_active_is_persisted_if_true_and_not_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=True",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "        )",
            "",
            "        assert res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_is_persisted_if_false_and_not_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=False",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "        )",
            "",
            "        assert not res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_is_updated_if_false_and_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=False",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "            datastore_active=True,",
            "        )",
            "",
            "        assert res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_is_updated_if_true_and_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=True",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "            datastore_active=False,",
            "        )",
            "",
            "        assert not res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_not_present_if_not_provided_and_not_datastore_plugin_enabled(",
            "        self,",
            "    ):",
            "        assert not p.plugin_loaded(\"datastore\")",
            "",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "        )",
            "",
            "        assert \"datastore_active\" not in res_returned",
            "",
            "    def test_mimetype_by_url(self, monkeypatch, tmpdir):",
            "        \"\"\"The mimetype is guessed from the url",
            "",
            "        Real world usage would be externally linking the resource and",
            "        the mimetype would be guessed, based on the url",
            "",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost/data.csv\", name=\"Test\"",
            "        )",
            "        monkeypatch.setattr(ckan.lib.uploader, \"_storage_path\", str(tmpdir))",
            "        res_update = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://localhost/data.json\",",
            "        )",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"application/json\"",
            "",
            "    def test_mimetype_by_user(self):",
            "        \"\"\"",
            "        The mimetype is supplied by the user",
            "",
            "        Real world usage would be using the FileStore API or web UI form to create a resource",
            "        and the user wanted to specify the mimetype themselves",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost/data.csv\", name=\"Test\"",
            "        )",
            "",
            "        res_update = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://localhost/data.csv\",",
            "            mimetype=\"text/plain\",",
            "        )",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"text/plain\"",
            "",
            "    @pytest.mark.ckan_config(\"ckan.mimetype_guess\", \"file_contents\")",
            "    def test_mimetype_by_upload_by_file(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file by the contents inside",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, that has no extension If the mimetype",
            "        can't be guessed by the url or filename, mimetype will be",
            "        guessed by the contents inside the file",
            "",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost/data.csv\", name=\"Test\"",
            "        )",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm, Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "",
            "        res_update = create_with_upload(",
            "            content, \"update_test\", action=\"resource_update\",",
            "            id=resource[\"id\"], url=\"http://localhost\",",
            "            package_id=dataset[\"id\"])",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"text/plain\"",
            "",
            "    def test_mimetype_by_upload_by_filename(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file with a filename",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, with a filename plus extension If",
            "        there's no url or the mimetype can't be guessed by the url,",
            "        mimetype will be guessed by the extension in the filename",
            "",
            "        \"\"\"",
            "        content = \"\"\"",
            "        \"info\": {",
            "            \"title\": \"BC Data Catalogue API\",",
            "            \"description\": \"This API provides information about datasets in the BC Data Catalogue.\",",
            "            \"termsOfService\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/API_Terms_of_Use.pdf\",",
            "            \"contact\": {",
            "                \"name\": \"Data BC\",",
            "                \"url\": \"http://data.gov.bc.ca/\",",
            "                \"email\": \"\"",
            "            },",
            "            \"license\": {",
            "                \"name\": \"Open Government License - British Columbia\",",
            "                \"url\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/OGL-vbc2.0.pdf\"",
            "            },",
            "            \"version\": \"3.0.0\"",
            "        }",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = create_with_upload(",
            "            content, 'test.json',",
            "            package_id=dataset['id'], url=\"http://localhost\")",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm, Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "",
            "        res_update = create_with_upload(",
            "            content, \"update_test.csv\", action=\"resource_update\",",
            "            id=resource[\"id\"], url=\"http://localhost\",",
            "            package_id=dataset['id'])",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"text/csv\"",
            "",
            "    def test_size_of_resource_by_user(self):",
            "        \"\"\"",
            "        The size of the resource is provided by the users",
            "",
            "        Real world usage would be using the FileStore API and the user provides a size for the resource",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset,",
            "            url=\"http://localhost/data.csv\",",
            "            name=\"Test\",",
            "            size=500,",
            "        )",
            "",
            "        res_update = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://localhost/data.csv\",",
            "            size=600,",
            "        )",
            "",
            "        org_size = int(resource.pop(\"size\"))",
            "        upd_size = int(res_update.pop(\"size\"))",
            "",
            "        assert org_size < upd_size",
            "",
            "    def test_size_of_resource_by_upload(self, create_with_upload):",
            "        \"\"\"The size of the resource determined by the uploaded file",
            "",
            "        \"\"\"",
            "        content = \"\"\"",
            "        \"info\": {",
            "            \"title\": \"BC Data Catalogue API\",",
            "            \"description\": \"This API provides information about datasets in the BC Data Catalogue.\",",
            "            \"termsOfService\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/API_Terms_of_Use.pdf\",",
            "            \"contact\": {",
            "                \"name\": \"Data BC\",",
            "                \"url\": \"http://data.gov.bc.ca/\",",
            "                \"email\": \"\"",
            "            },",
            "            \"license\": {",
            "                \"name\": \"Open Government License - British Columbia\",",
            "                \"url\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/OGL-vbc2.0.pdf\"",
            "            },",
            "            \"version\": \"3.0.0\"",
            "        }",
            "        \"\"\"",
            "",
            "        dataset = factories.Dataset()",
            "",
            "        resource = create_with_upload(",
            "            content, 'test.json',",
            "            package_id=dataset['id'], url=\"http://localhost\")",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm, Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "        res_update = create_with_upload(",
            "            content, \"update_test.csv\", action=\"resource_update\",",
            "            id=resource[\"id\"], url=\"http://localhost\",",
            "            package_id=dataset[\"id\"])",
            "",
            "        org_size = int(resource.pop(\"size\"))  # 669 bytes",
            "        upd_size = int(res_update.pop(\"size\"))  # 358 bytes",
            "",
            "        assert org_size > upd_size",
            "",
            "    def test_extras(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            user=user,",
            "            resources=[dict(format=u\"json\", url=u\"http://datahub.io/\")],",
            "        )",
            "",
            "        resource = helpers.call_action(",
            "            \"resource_update\",",
            "            id=dataset[\"resources\"][0][\"id\"],",
            "            somekey=\"somevalue\",  # this is how to do resource extras",
            "            extras={u\"someotherkey\": u\"alt234\"},  # this isnt",
            "            format=u\"plain text\",",
            "            url=u\"http://datahub.io/download/\",",
            "        )",
            "",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "        resource = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ][0]",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "",
            "    @helpers.change_config(",
            "        \"ckan.views.default_views\", \"image_view recline_view\"",
            "    )",
            "    def test_resource_format_update(self):",
            "        dataset = factories.Dataset()",
            "",
            "        # Create resource without format",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost\", name=\"Test\"",
            "        )",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 0",
            "",
            "        # Update resource with format",
            "        resource = helpers.call_action(",
            "            \"resource_update\", id=resource[\"id\"], format=\"CSV\"",
            "        )",
            "",
            "        # Format changed",
            "        assert resource[\"format\"] == \"CSV\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=resource[\"id\"]",
            "        )",
            "",
            "        # View for resource is created",
            "        assert len(res_views) == 1",
            "",
            "        second_resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost\", name=\"Test2\", format=\"CSV\"",
            "        )",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=second_resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 1",
            "",
            "        second_resource = helpers.call_action(",
            "            \"resource_update\", id=second_resource[\"id\"], format=\"PNG\"",
            "        )",
            "",
            "        # Format changed",
            "        assert second_resource[\"format\"] == \"PNG\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=second_resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 2",
            "",
            "        third_resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost\", name=\"Test2\"",
            "        )",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=third_resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 0",
            "",
            "        third_resource = helpers.call_action(",
            "            \"resource_update\", id=third_resource[\"id\"], format=\"Test format\"",
            "        )",
            "",
            "        # Format added",
            "        assert third_resource[\"format\"] == \"Test format\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=third_resource[\"id\"]",
            "        )",
            "",
            "        # No view created, cause no such format",
            "        assert len(res_views) == 0",
            "",
            "        third_resource = helpers.call_action(",
            "            \"resource_update\", id=third_resource[\"id\"], format=\"CSV\"",
            "        )",
            "",
            "        # Format changed",
            "        assert third_resource[\"format\"] == \"CSV\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=third_resource[\"id\"]",
            "        )",
            "",
            "        # View is created",
            "        assert len(res_views) == 1",
            "",
            "    def test_edit_metadata_updates_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='New Description',",
            "            )",
            "            assert resource['metadata_modified'] == '2020-02-25T12:00:00'",
            "",
            "    def test_same_values_dont_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(",
            "                package_id=dataset['id'],",
            "                description='Test',",
            "                some_custom_field='test',",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='Test',",
            "                some_custom_field='test',",
            "                url='http://link.to.some.data'  # Default Value from Factory",
            "            )",
            "            assert (resource['metadata_modified'] !=",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '1987-03-04T23:30:00')",
            "",
            "    def test_new_keys_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(package_id=dataset['id'], description='test')",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='test',",
            "                some_custom_field='test',",
            "                url='http://link.to.some.data'  # default value from factory",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '2020-02-25T12:00:00')",
            "",
            "    def test_remove_keys_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(",
            "                package_id=dataset['id'],",
            "                description='test',",
            "                some_custom_field='test',",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='test',",
            "                url='http://link.to.some.data'  # default value from factory",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '2020-02-25T12:00:00')",
            "",
            "    def test_update_keys_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(",
            "                package_id=dataset['id'],",
            "                description='test',",
            "                some_custom_field='test',",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='test',",
            "                some_custom_field='test2',",
            "                url='http://link.to.some.data'  # default value from factory",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '2020-02-25T12:00:00')",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestConfigOptionUpdate(object):",
            "",
            "    # NOTE: the opposite is tested in",
            "    # ckan/ckanext/example_iconfigurer/tests/test_iconfigurer_update_config.py",
            "    # as we need to enable an external config option from an extension",
            "",
            "    def test_app_globals_set_if_defined(self):",
            "        key = \"ckan.site_title\"",
            "        value = \"Test site title\"",
            "",
            "        params = {key: value}",
            "",
            "        helpers.call_action(\"config_option_update\", **params)",
            "",
            "        globals_key = app_globals.get_globals_key(key)",
            "        assert hasattr(app_globals.app_globals, globals_key)",
            "",
            "        assert getattr(app_globals.app_globals, globals_key) == value",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestUserUpdate(object):",
            "    def test_user_update_with_password_hash(self):",
            "        sysadmin = factories.Sysadmin()",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "",
            "        user = helpers.call_action(",
            "            \"user_update\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            id=sysadmin[\"name\"],",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password == \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_user_create_password_hash_not_for_normal_users(self):",
            "        normal_user = factories.User()",
            "        context = {\"user\": normal_user[\"name\"], \"ignore_auth\": False}",
            "",
            "        user = helpers.call_action(",
            "            \"user_update\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            id=normal_user[\"name\"],",
            "            password=\"required\",",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password != \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_user_update_image_url(self):",
            "        user = factories.User(image_url='user_image.jpg')",
            "        context = {\"user\": user[\"name\"]}",
            "",
            "        user = helpers.call_action(",
            "            \"user_update\",",
            "            context=context,",
            "            id=user[\"name\"],",
            "            email=\"test@example.com\",",
            "            image_url=\"new_image_url.jpg\",",
            "        )",
            "",
            "        assert user[\"image_url\"] == \"new_image_url.jpg\"",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestGroupUpdate(object):",
            "    def test_group_update_image_url_field(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        group = factories.Group(",
            "            type=\"group\",",
            "            name=\"testing\",",
            "            user=user,",
            "            image_url='group_image.jpg')",
            "",
            "        group = helpers.call_action(",
            "            \"group_update\",",
            "            context=context,",
            "            id=group[\"id\"],",
            "            name=group[\"name\"],",
            "            type=group[\"type\"],",
            "            image_url=\"new_image_url.jpg\"",
            "        )",
            "",
            "        assert group[\"image_url\"] == \"new_image_url.jpg\"",
            "",
            "    def test_group_update_cant_change_type(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        group = factories.Group(type=\"group\", name=\"unchanging\", user=user)",
            "",
            "        group = helpers.call_action(",
            "            \"group_update\",",
            "            context=context,",
            "            id=group[\"id\"],",
            "            name=\"unchanging\",",
            "            type=\"favouritecolour\",",
            "        )",
            "",
            "        assert group[\"type\"] == \"group\"",
            "        assert (",
            "            helpers.call_action(\"group_show\", id=\"unchanging\")[\"type\"]",
            "            == \"group\"",
            "        )",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestPackageOwnerOrgUpdate(object):",
            "    def test_package_owner_org_added(self):",
            "        \"\"\"A package without an owner_org can have one added.\"\"\"",
            "        sysadmin = factories.Sysadmin()",
            "        org = factories.Organization()",
            "        dataset = factories.Dataset()",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        assert dataset[\"owner_org\"] is None",
            "        helpers.call_action(",
            "            \"package_owner_org_update\",",
            "            context=context,",
            "            id=dataset[\"id\"],",
            "            organization_id=org[\"id\"],",
            "        )",
            "        dataset_obj = model.Package.get(dataset[\"id\"])",
            "        assert dataset_obj.owner_org == org[\"id\"]",
            "",
            "    def test_package_owner_org_changed(self):",
            "        \"\"\"A package with an owner_org can have it changed.\"\"\"",
            "",
            "        sysadmin = factories.Sysadmin()",
            "        org_1 = factories.Organization()",
            "        org_2 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org_1[\"id\"])",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        assert dataset[\"owner_org\"] == org_1[\"id\"]",
            "        helpers.call_action(",
            "            \"package_owner_org_update\",",
            "            context=context,",
            "            id=dataset[\"id\"],",
            "            organization_id=org_2[\"id\"],",
            "        )",
            "        dataset_obj = model.Package.get(dataset[\"id\"])",
            "        assert dataset_obj.owner_org == org_2[\"id\"]",
            "",
            "    def test_package_owner_org_removed(self):",
            "        \"\"\"A package with an owner_org can have it removed.\"\"\"",
            "        sysadmin = factories.Sysadmin()",
            "        org = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org[\"id\"])",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        assert dataset[\"owner_org\"] == org[\"id\"]",
            "        helpers.call_action(",
            "            \"package_owner_org_update\",",
            "            context=context,",
            "            id=dataset[\"id\"],",
            "            organization_id=None,",
            "        )",
            "        dataset_obj = model.Package.get(dataset[\"id\"])",
            "        assert dataset_obj.owner_org is None",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestBulkOperations(object):",
            "    def test_bulk_make_private(self):",
            "",
            "        org = factories.Organization()",
            "",
            "        dataset1 = factories.Dataset(owner_org=org[\"id\"])",
            "        dataset2 = factories.Dataset(owner_org=org[\"id\"])",
            "",
            "        helpers.call_action(",
            "            \"bulk_update_private\",",
            "            {},",
            "            datasets=[dataset1[\"id\"], dataset2[\"id\"]],",
            "            org_id=org[\"id\"],",
            "        )",
            "",
            "        # Check search index",
            "        datasets = helpers.call_action(",
            "            \"package_search\", {}, q=\"owner_org:{0}\".format(org[\"id\"])",
            "        )",
            "",
            "        for dataset in datasets[\"results\"]:",
            "            assert dataset[\"private\"]",
            "",
            "        # Check DB",
            "        datasets = (",
            "            model.Session.query(model.Package)",
            "            .filter(model.Package.owner_org == org[\"id\"])",
            "            .all()",
            "        )",
            "        for dataset in datasets:",
            "            assert dataset.private",
            "",
            "    def test_bulk_make_public(self):",
            "",
            "        org = factories.Organization()",
            "",
            "        dataset1 = factories.Dataset(owner_org=org[\"id\"], private=True)",
            "        dataset2 = factories.Dataset(owner_org=org[\"id\"], private=True)",
            "",
            "        helpers.call_action(",
            "            \"bulk_update_public\",",
            "            {},",
            "            datasets=[dataset1[\"id\"], dataset2[\"id\"]],",
            "            org_id=org[\"id\"],",
            "        )",
            "",
            "        # Check search index",
            "        datasets = helpers.call_action(",
            "            \"package_search\", {}, q=\"owner_org:{0}\".format(org[\"id\"])",
            "        )",
            "",
            "        for dataset in datasets[\"results\"]:",
            "            assert not (dataset[\"private\"])",
            "",
            "        # Check DB",
            "        datasets = (",
            "            model.Session.query(model.Package)",
            "            .filter(model.Package.owner_org == org[\"id\"])",
            "            .all()",
            "        )",
            "        for dataset in datasets:",
            "            assert not (dataset.private)",
            "        activities = helpers.call_action(",
            "            \"organization_activity_list\", id=org[\"id\"]",
            "        )",
            "        assert activities[0]['activity_type'] == 'changed package'",
            "",
            "    def test_bulk_delete(self):",
            "",
            "        org = factories.Organization()",
            "",
            "        dataset1 = factories.Dataset(owner_org=org[\"id\"])",
            "        dataset2 = factories.Dataset(owner_org=org[\"id\"])",
            "",
            "        helpers.call_action(",
            "            \"bulk_update_delete\",",
            "            {},",
            "            datasets=[dataset1[\"id\"], dataset2[\"id\"]],",
            "            org_id=org[\"id\"],",
            "        )",
            "",
            "        # Check search index",
            "        datasets = helpers.call_action(",
            "            \"package_search\", {}, q=\"owner_org:{0}\".format(org[\"id\"])",
            "        )",
            "",
            "        assert datasets[\"results\"] == []",
            "",
            "        # Check DB",
            "        datasets = (",
            "            model.Session.query(model.Package)",
            "            .filter(model.Package.owner_org == org[\"id\"])",
            "            .all()",
            "        )",
            "        for dataset in datasets:",
            "            assert dataset.state == \"deleted\"",
            "",
            "        activities = helpers.call_action(",
            "            \"organization_activity_list\", id=org[\"id\"]",
            "        )",
            "        assert activities[0]['activity_type'] == 'deleted package'",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDashboardMarkActivitiesOld(object):",
            "    def test_mark_as_old_some_activities_by_a_followed_user(self):",
            "        # do some activity that will show up on user's dashboard",
            "        user = factories.User()",
            "        # now some activity that is \"new\" because it is by a followed user",
            "        followed_user = factories.User()",
            "        helpers.call_action(",
            "            \"follow_user\", context={\"user\": user[\"name\"]}, **followed_user",
            "        )",
            "        dataset = factories.Dataset(user=followed_user)",
            "        dataset[\"title\"] = \"Dataset with changed title\"",
            "        helpers.call_action(",
            "            \"package_update\",",
            "            context={\"user\": followed_user[\"name\"]},",
            "            **dataset",
            "        )",
            "        assert (",
            "            helpers.call_action(",
            "                \"dashboard_new_activities_count\", context={\"user\": user[\"id\"]}",
            "            )",
            "            == 3",
            "        )",
            "        activities = helpers.call_action(",
            "            \"dashboard_activity_list\", context={\"user\": user[\"id\"]}",
            "        )",
            "        assert [",
            "            (activity[\"activity_type\"], activity[\"is_new\"])",
            "            for activity in activities[::-1]",
            "        ] == [",
            "            (\"new user\", False),",
            "            (\"new user\", True),",
            "            (\"new package\", True),",
            "            (\"changed package\", True),",
            "        ]",
            "",
            "        helpers.call_action(",
            "            \"dashboard_mark_activities_old\", context={\"user\": user[\"name\"]}",
            "        )",
            "",
            "        assert (",
            "            helpers.call_action(",
            "                \"dashboard_new_activities_count\", context={\"user\": user[\"id\"]}",
            "            )",
            "            == 0",
            "        )",
            "        activities = helpers.call_action(",
            "            \"dashboard_activity_list\", context={\"user\": user[\"id\"]}",
            "        )",
            "        assert [",
            "            (activity[\"activity_type\"], activity[\"is_new\"])",
            "            for activity in activities[::-1]",
            "        ] == [",
            "            (\"new user\", False),",
            "            (\"new user\", False),",
            "            (\"new package\", False),",
            "            (\"changed package\", False),",
            "        ]",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "@pytest.mark.ckan_config('ckan.auth.allow_dataset_collaborators', True)",
            "class TestCollaboratorsUpdate(object):",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_admin_collaborators', True)",
            "    @pytest.mark.parametrize('role', ['admin', 'editor'])",
            "    def test_collaborators_can_update_resources(self, role):",
            "",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        user = factories.User()",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=role)",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        updated_resource = helpers.call_action(",
            "            'resource_update',",
            "            context=context,",
            "            id=resource['id'],",
            "            description='updated')",
            "",
            "        assert updated_resource['description'] == 'updated'",
            "",
            "    def test_collaborators_can_not_change_owner_org_by_default(self):",
            "",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        user = factories.User()",
            "        org2 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='editor')",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        dataset['owner_org'] = org2['id']",
            "",
            "        with pytest.raises(logic.ValidationError) as e:",
            "            helpers.call_action('package_update', context=context, **dataset)",
            "",
            "        assert e.value.error_dict['owner_org'] == [",
            "            'You cannot move this dataset to another organization']",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_collaborators_to_change_owner_org', True)",
            "    def test_collaborators_can_change_owner_org_if_config_true(self):",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        user = factories.User()",
            "        org2 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='editor')",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        dataset['owner_org'] = org2['id']",
            "",
            "        updated_dataset = helpers.call_action('package_update', context=context, **dataset)",
            "",
            "        assert updated_dataset['owner_org'] == org2['id']",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_collaborators_to_change_owner_org', True)",
            "    def test_editors_can_change_owner_org_even_if_collaborators(self):",
            "",
            "        user = factories.User()",
            "",
            "        org1 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        org2 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='editor')",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        dataset['owner_org'] = org2['id']",
            "",
            "        updated_dataset = helpers.call_action('package_update', context=context, **dataset)",
            "",
            "        assert updated_dataset['owner_org'] == org2['id']",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDatasetRevise(object):",
            "    def test_revise_description(self):",
            "        factories.Dataset(name='xyz', notes='old notes')",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'notes': 'old notes', 'name': 'xyz'},",
            "            update={'notes': 'new notes'},",
            "        )",
            "        assert response['package']['notes'] == 'new notes'",
            "",
            "    def test_revise_failed_match(self):",
            "        factories.Dataset(name='xyz', notes='old notes')",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                'package_revise',",
            "                match={'notes': 'wrong notes', 'name': 'xyz'},",
            "                update={'notes': 'new notes'},",
            "            )",
            "",
            "    def test_revise_description_flattened(self):",
            "        factories.Dataset(name='xyz', notes='old notes')",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match__notes='old notes',",
            "            match__name='xyz',",
            "            update__notes='new notes',",
            "        )",
            "        assert response['package']['notes'] == 'new notes'",
            "",
            "    def test_revise_dataset_fields_only(self):",
            "        dataset = factories.Dataset(",
            "            name='xyz',",
            "            notes='old notes',",
            "            resources=[{'url': 'http://example.com'}])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            filter=[",
            "                '+resources',  # keep everything under resources",
            "                '-*',  # remove everything else",
            "            ],",
            "            update={'name': 'fresh-start', 'title': 'Fresh Start'},",
            "        )",
            "        assert response['package']['notes'] is None",
            "        assert response['package']['name'] == 'fresh-start'",
            "        assert response['package']['resources'][0]['url'] == 'http://example.com'",
            "",
            "    def test_revise_add_resource(self):",
            "        dataset = factories.Dataset()",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            update__resources__extend=[{'name': 'new resource', 'url': 'http://example.com'}],",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new resource'",
            "",
            "    def test_revise_resource_by_index(self):",
            "        dataset = factories.Dataset(resources=[{'url': 'http://example.com'}])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            update__resources__0={'name': 'new name'},",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new name'",
            "",
            "    def test_revise_resource_by_id(self):",
            "        dataset = factories.Dataset(resources=[{",
            "            'id': '34a12bc-1420-cbad-1922',",
            "            'url': 'http://example.com',",
            "            'name': 'old name',",
            "        }])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            update__resources__34a12={'name': 'new name'},  # prefixes allowed >4 chars",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new name'",
            "",
            "    def test_revise_resource_replace_all(self):",
            "        dataset = factories.Dataset(resources=[{",
            "            'id': '34a12bc-1420-cbad-1922',",
            "            'url': 'http://example.com',",
            "            'name': 'old name',",
            "        }])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            filter=['+resources__34a12__id', '-resources__34a12__*'],",
            "            update__resources__34a12={'name': 'new name'},",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new name'",
            "        assert response['package']['resources'][0]['url'] == ''",
            "",
            "    def test_revise_normal_user(self):",
            "        user = factories.User()",
            "        org = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "        # make sure normal users can use package_revise",
            "        context = {'user': user['name'], 'ignore_auth': False}",
            "        ds = factories.Dataset(owner_org=org['id'])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': ds['id']},",
            "            update={'notes': 'new notes'},",
            "            context=context,",
            "        )",
            "        assert response['package']['notes'] == 'new notes'",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "class TestUserPluginExtras(object):",
            "",
            "    def test_stored_on_update_if_sysadmin(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user = factories.User(",
            "            plugin_extras={",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        )",
            "",
            "        user['plugin_extras'] = {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2'",
            "            }",
            "        }",
            "",
            "        # helpers.call_action sets 'ignore_auth' to True by default",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "",
            "        updated_user = helpers.call_action(",
            "            'user_update', context=context, **user)",
            "",
            "        assert updated_user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2',",
            "            }",
            "        }",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=user['id'], include_plugin_extras=True)",
            "",
            "        assert updated_user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2',",
            "            }",
            "        }",
            "",
            "        plugin_extras_from_db = model.Session.execute(",
            "            'SELECT plugin_extras FROM \"user\" WHERE id=:id',",
            "            {'id': user['id']}",
            "        ).first().values()[0]",
            "",
            "        assert plugin_extras_from_db == {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2',",
            "            }",
            "        }",
            "",
            "    def test_ignored_on_update_if_non_sysadmin(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user = factories.User(",
            "            plugin_extras={",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        )",
            "",
            "        user['plugin_extras'] = {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2'",
            "            }",
            "        }",
            "",
            "        # User edits themselves",
            "        context = {'user': user['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_update', context=context, **user)",
            "",
            "        assert 'plugin_extras' not in created_user",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1'",
            "            }",
            "        }",
            "",
            "    def test_ignored_on_update_if_non_sysadmin_when_empty(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user = factories.User()",
            "",
            "        user['plugin_extras'] = {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2'",
            "            }",
            "        }",
            "",
            "        # User edits themselves",
            "        context = {'user': user['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_update', context=context, **user)",
            "",
            "        assert 'plugin_extras' not in created_user",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user['plugin_extras'] is None",
            "",
            "    def test_nested_updates_are_reflected_in_db(self):",
            "",
            "        user = factories.User(",
            "            plugin_extras={",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        )",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        context = {'user': sysadmin['name']}",
            "",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=user['id'], include_plugin_extras=True)",
            "",
            "        user['plugin_extras']['plugin1']['key1'] = 'value2'",
            "",
            "        updated_user = helpers.call_action('user_update', context=context, **user)",
            "",
            "        assert updated_user['plugin_extras']['plugin1']['key1'] == 'value2'",
            "",
            "        # Hold on, partner",
            "",
            "        plugin_extras = model.Session.execute(",
            "            'SELECT plugin_extras FROM \"user\" WHERE id=:id',",
            "            {'id': user['id']}",
            "        ).first().values()[0]",
            "",
            "        assert plugin_extras['plugin1']['key1'] == 'value2'"
        ],
        "afterPatchFile": [
            "# encoding: utf-8",
            "\"\"\"Unit tests for ckan/logic/action/update.py.\"\"\"",
            "import datetime",
            "",
            "import mock",
            "import pytest",
            "import six",
            "",
            "import ckan",
            "import ckan.lib.app_globals as app_globals",
            "import ckan.logic as logic",
            "import ckan.plugins as p",
            "import ckan.tests.factories as factories",
            "import ckan.tests.helpers as helpers",
            "from ckan import model",
            "",
            "from freezegun import freeze_time",
            "",
            "",
            "def datetime_from_string(s):",
            "    \"\"\"Return a standard datetime.datetime object initialised from a string in",
            "    the same format used for timestamps in dictized activities (the format",
            "    produced by datetime.datetime.isoformat())",
            "",
            "    \"\"\"",
            "    return datetime.datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S.%f\")",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestUpdate(object):",
            "    def teardown(self):",
            "        # Since some of the test methods below use the mock module to patch",
            "        # things, we use this teardown() method to remove remove all patches.",
            "        # (This makes sure the patches always get removed even if the test",
            "        # method aborts with an exception or something.)",
            "        mock.patch.stopall()",
            "",
            "    # START-AFTER",
            "",
            "    def test_user_update_name(self):",
            "        \"\"\"Test that updating a user's name works successfully.\"\"\"",
            "",
            "        # The canonical form of a test has four steps:",
            "        # 1. Setup any preconditions needed for the test.",
            "        # 2. Call the function that's being tested, once only.",
            "        # 3. Make assertions about the return value and/or side-effects of",
            "        #    of the function that's being tested.",
            "        # 4. Do nothing else!",
            "",
            "        # 1. Setup.",
            "        user = factories.User()",
            "        user[\"name\"] = \"updated\"",
            "",
            "        # 2. Make assertions about the return value and/or side-effects.",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    # END-BEFORE",
            "",
            "    def test_user_generate_apikey(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        result = helpers.call_action(",
            "            \"user_generate_apikey\", context=context, id=user[\"id\"]",
            "        )",
            "        updated_user = helpers.call_action(",
            "            \"user_show\", context=context, id=user[\"id\"]",
            "        )",
            "",
            "        assert updated_user[\"apikey\"] != user[\"apikey\"]",
            "        assert result[\"apikey\"] == updated_user[\"apikey\"]",
            "",
            "    def test_user_generate_apikey_sysadmin_user(self):",
            "        user = factories.User()",
            "        sysadmin = factories.Sysadmin()",
            "        context = {\"user\": sysadmin[\"name\"], \"ignore_auth\": False}",
            "        result = helpers.call_action(",
            "            \"user_generate_apikey\", context=context, id=user[\"id\"]",
            "        )",
            "        updated_user = helpers.call_action(",
            "            \"user_show\", context=context, id=user[\"id\"]",
            "        )",
            "",
            "        assert updated_user[\"apikey\"] != user[\"apikey\"]",
            "        assert result[\"apikey\"] == updated_user[\"apikey\"]",
            "",
            "    def test_user_generate_apikey_nonexistent_user(self):",
            "        user = {",
            "            \"id\": \"nonexistent\",",
            "            \"name\": \"nonexistent\",",
            "            \"email\": \"does@notexist.com\",",
            "        }",
            "        context = {\"user\": user[\"name\"]}",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(",
            "                \"user_generate_apikey\", context=context, id=user[\"id\"]",
            "            )",
            "",
            "    def test_user_update_with_id_that_does_not_exist(self):",
            "        user_dict = factories.User.attributes()()",
            "        user_dict[\"id\"] = \"there's no user with this id\"",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(\"user_update\", **user_dict)",
            "",
            "    def test_user_update_with_no_id(self):",
            "        user_dict = factories.User.attributes()()",
            "        assert \"id\" not in user_dict",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user_dict)",
            "",
            "    @pytest.mark.parametrize(",
            "        \"name\",",
            "        (",
            "            \"\",",
            "            \"a\",",
            "            False,",
            "            0,",
            "            -1,",
            "            23,",
            "            \"new\",",
            "            \"edit\",",
            "            \"search\",",
            "            \"a\" * 200,",
            "            \"Hi!\",",
            "            \"i++%\",",
            "        ),",
            "    )",
            "    def test_user_update_with_invalid_name(self, name):",
            "        user = factories.User()",
            "        user[\"name\"] = name",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_to_name_that_already_exists(self):",
            "        fred = factories.User(name=\"fred\")",
            "        bob = factories.User(name=\"bob\")",
            "",
            "        # Try to update fred and change his user name to bob, which is already",
            "        # bob's user name",
            "        fred[\"name\"] = bob[\"name\"]",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **fred)",
            "",
            "    def test_user_update_password(self):",
            "        \"\"\"Test that updating a user's password works successfully.\"\"\"",
            "",
            "        user = factories.User()",
            "",
            "        # FIXME we have to pass the email address to user_update even though",
            "        # we're not updating it, otherwise validation fails.",
            "        helpers.call_action(",
            "            \"user_update\",",
            "            id=user[\"id\"],",
            "            name=user[\"name\"],",
            "            email=user[\"email\"],",
            "            password=\"new password\",",
            "        )",
            "",
            "        # user_show() never returns the user's password, so we have to access",
            "        # the model directly to test it.",
            "        import ckan.model as model",
            "",
            "        updated_user = model.User.get(user[\"id\"])",
            "        assert updated_user.validate_password(\"new password\")",
            "",
            "    def test_user_update_with_short_password(self):",
            "        user = factories.User()",
            "",
            "        user[\"password\"] = \"xxx\"  # This password is too short.",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_with_empty_password(self):",
            "        \"\"\"If an empty password is passed to user_update, nothing should",
            "        happen.",
            "",
            "        No error (e.g. a validation error) is raised, but the password is not",
            "        changed either.",
            "",
            "        \"\"\"",
            "        user_dict = factories.User.attributes()()",
            "        original_password = user_dict[\"password\"]",
            "        user_dict = factories.User(**user_dict)",
            "",
            "        user_dict[\"password\"] = \"\"",
            "        helpers.call_action(\"user_update\", **user_dict)",
            "",
            "        import ckan.model as model",
            "",
            "        updated_user = model.User.get(user_dict[\"id\"])",
            "        assert updated_user.validate_password(original_password)",
            "",
            "    def test_user_update_with_null_password(self):",
            "        user = factories.User()",
            "",
            "        user[\"password\"] = None",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_with_invalid_password(self):",
            "        user = factories.User()",
            "",
            "        for password in (False, -1, 23, 30.7):",
            "            user[\"password\"] = password",
            "            with pytest.raises(logic.ValidationError):",
            "",
            "                helpers.call_action(\"user_update\", **user)",
            "",
            "    def test_user_update_without_email_address(self):",
            "        \"\"\"You have to pass an email address when you call user_update.",
            "",
            "        Even if you don't want to change the user's email address, you still",
            "        have to pass their current email address to user_update.",
            "",
            "        FIXME: The point of this feature seems to be to prevent people from",
            "        removing email addresses from user accounts, but making them post the",
            "        current email address every time they post to user update is just",
            "        annoying, they should be able to post a dict with no 'email' key to",
            "        user_update and it should simply not change the current email.",
            "",
            "        \"\"\"",
            "        user = factories.User()",
            "        del user[\"email\"]",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "",
            "            helpers.call_action(\"user_update\", **user)",
            "",
            "    # TODO: Valid and invalid values for the rest of the user model's fields.",
            "",
            "    def test_user_update_activity_stream(self):",
            "        \"\"\"Test that the right activity is emitted when updating a user.\"\"\"",
            "",
            "        user = factories.User()",
            "        before = datetime.datetime.utcnow()",
            "",
            "        # FIXME we have to pass the email address and password to user_update",
            "        # even though we're not updating those fields, otherwise validation",
            "        # fails.",
            "        helpers.call_action(",
            "            \"user_update\",",
            "            id=user[\"id\"],",
            "            name=user[\"name\"],",
            "            email=user[\"email\"],",
            "            password=factories.User.password,",
            "            fullname=\"updated full name\",",
            "        )",
            "",
            "        activity_stream = helpers.call_action(",
            "            \"user_activity_list\", id=user[\"id\"]",
            "        )",
            "        latest_activity = activity_stream[0]",
            "        assert latest_activity[\"activity_type\"] == \"changed user\"",
            "        assert latest_activity[\"object_id\"] == user[\"id\"]",
            "        assert latest_activity[\"user_id\"] == user[\"id\"]",
            "        after = datetime.datetime.utcnow()",
            "        timestamp = datetime_from_string(latest_activity[\"timestamp\"])",
            "        assert timestamp >= before and timestamp <= after",
            "",
            "    def test_user_update_with_custom_schema(self):",
            "        \"\"\"Test that custom schemas passed to user_update do get used.",
            "",
            "        user_update allows a custom validation schema to be passed to it in the",
            "        context dict. This is just a simple test that if you pass a custom",
            "        schema user_update does at least call a custom method that's given in",
            "        the custom schema. We assume this means it did use the custom schema",
            "        instead of the default one for validation, so user_update's custom",
            "        schema feature does work.",
            "",
            "        \"\"\"",
            "        import ckan.logic.schema",
            "",
            "        user = factories.User()",
            "",
            "        # A mock validator method, it doesn't do anything but it records what",
            "        # params it gets called with and how many times.",
            "        mock_validator = mock.MagicMock()",
            "",
            "        # Build a custom schema by taking the default schema and adding our",
            "        # mock method to its 'id' field.",
            "        schema = ckan.logic.schema.default_update_user_schema()",
            "        schema[\"id\"].append(mock_validator)",
            "",
            "        # Call user_update and pass our custom schema in the context.",
            "        # FIXME: We have to pass email and password even though we're not",
            "        # trying to update them, or validation fails.",
            "        helpers.call_action(",
            "            \"user_update\",",
            "            context={\"schema\": schema},",
            "            id=user[\"id\"],",
            "            name=user[\"name\"],",
            "            email=user[\"email\"],",
            "            password=factories.User.password,",
            "            fullname=\"updated full name\",",
            "        )",
            "",
            "    def test_user_update_multiple(self):",
            "        \"\"\"Test that updating multiple user attributes at once works.\"\"\"",
            "",
            "        user = factories.User()",
            "",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            # FIXME: We shouldn't have to put email here since we're not",
            "            # updating it, but user_update sucks.",
            "            \"email\": user[\"email\"],",
            "            # FIXME: We shouldn't have to put password here since we're not",
            "            # updating it, but user_update sucks.",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        helpers.call_action(\"user_update\", **params)",
            "",
            "        updated_user = helpers.call_action(\"user_show\", id=user[\"id\"])",
            "        assert updated_user[\"fullname\"] == \"updated full name\"",
            "        assert updated_user[\"about\"] == \"updated about\"",
            "",
            "    def test_user_update_does_not_return_password(self):",
            "        \"\"\"The user dict that user_update returns should not include the user's",
            "        password.\"\"\"",
            "",
            "        user = factories.User()",
            "",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            \"email\": user[\"email\"],",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **params)",
            "        assert \"password\" not in updated_user",
            "",
            "    def test_user_update_does_not_return_apikey(self):",
            "        \"\"\"The user dict that user_update returns should not include the user's",
            "        API key.\"\"\"",
            "",
            "        user = factories.User()",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            \"email\": user[\"email\"],",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **params)",
            "        assert \"apikey\" not in updated_user",
            "",
            "    def test_user_update_does_not_return_reset_key(self):",
            "        \"\"\"The user dict that user_update returns should not include the user's",
            "        reset key.\"\"\"",
            "",
            "        import ckan.lib.mailer",
            "        import ckan.model",
            "",
            "        user = factories.User()",
            "        ckan.lib.mailer.create_reset_key(ckan.model.User.get(user[\"id\"]))",
            "",
            "        params = {",
            "            \"id\": user[\"id\"],",
            "            \"fullname\": \"updated full name\",",
            "            \"about\": \"updated about\",",
            "            \"email\": user[\"email\"],",
            "            \"password\": factories.User.password,",
            "        }",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **params)",
            "        assert \"reset_key\" not in updated_user",
            "",
            "    def test_resource_reorder(self):",
            "        resource_urls = [\"http://a.html\", \"http://b.html\", \"http://c.html\"]",
            "        dataset = {",
            "            \"name\": \"basic\",",
            "            \"resources\": [{\"url\": url} for url in resource_urls],",
            "        }",
            "",
            "        dataset = helpers.call_action(\"package_create\", **dataset)",
            "        created_resource_urls = [",
            "            resource[\"url\"] for resource in dataset[\"resources\"]",
            "        ]",
            "        assert created_resource_urls == resource_urls",
            "        mapping = dict(",
            "            (resource[\"url\"], resource[\"id\"])",
            "            for resource in dataset[\"resources\"]",
            "        )",
            "",
            "        # This should put c.html at the front",
            "        reorder = {\"id\": dataset[\"id\"], \"order\": [mapping[\"http://c.html\"]]}",
            "",
            "        helpers.call_action(\"package_resource_reorder\", **reorder)",
            "",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        reordered_resource_urls = [",
            "            resource[\"url\"] for resource in dataset[\"resources\"]",
            "        ]",
            "",
            "        assert reordered_resource_urls == [",
            "            \"http://c.html\",",
            "            \"http://a.html\",",
            "            \"http://b.html\",",
            "        ]",
            "",
            "        reorder = {",
            "            \"id\": dataset[\"id\"],",
            "            \"order\": [",
            "                mapping[\"http://b.html\"],",
            "                mapping[\"http://c.html\"],",
            "                mapping[\"http://a.html\"],",
            "            ],",
            "        }",
            "",
            "        helpers.call_action(\"package_resource_reorder\", **reorder)",
            "        dataset = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "",
            "        reordered_resource_urls = [",
            "            resource[\"url\"] for resource in dataset[\"resources\"]",
            "        ]",
            "",
            "        assert reordered_resource_urls == [",
            "            \"http://b.html\",",
            "            \"http://c.html\",",
            "            \"http://a.html\",",
            "        ]",
            "",
            "    def test_normal_user_can_not_change_their_state(self):",
            "",
            "        user = factories.User(state='pending')",
            "",
            "        user['state'] = 'active'",
            "",
            "        updated_user = helpers.call_action(\"user_update\", **user)",
            "",
            "        updated_user['state'] == 'pending'",
            "",
            "    def test_sysadmin_user_can_change_a_user_state(self):",
            "",
            "        user = factories.User(state='pending')",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user['state'] = 'active'",
            "",
            "        context = {'user': sysadmin['name']}",
            "",
            "        updated_user = helpers.call_action(\"user_update\", context=context, **user)",
            "",
            "        updated_user['state'] == 'active'",
            "",
            "    def test_update_dataset_cant_change_type(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            type=\"dataset\", name=\"unchanging\", user=user",
            "        )",
            "",
            "        dataset = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            name=\"unchanging\",",
            "            type=\"cabinet\",",
            "        )",
            "",
            "        assert dataset[\"type\"] == \"dataset\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=\"unchanging\")[\"type\"]",
            "            == \"dataset\"",
            "        )",
            "",
            "    def test_update_organization_cant_change_type(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        org = factories.Organization(",
            "            type=\"organization\", name=\"unchanging\", user=user",
            "        )",
            "",
            "        org = helpers.call_action(",
            "            \"organization_update\",",
            "            context=context,",
            "            id=org[\"id\"],",
            "            name=\"unchanging\",",
            "            type=\"ragtagband\",",
            "        )",
            "",
            "        assert org[\"type\"] == \"organization\"",
            "        assert (",
            "            helpers.call_action(\"organization_show\", id=\"unchanging\")[\"type\"]",
            "            == \"organization\"",
            "        )",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDatasetUpdate(object):",
            "    def test_missing_id(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"package_update\")",
            "",
            "    def test_name(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], name=\"new-name\"",
            "        )",
            "",
            "        assert dataset_[\"name\"] == \"new-name\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"name\"]",
            "            == \"new-name\"",
            "        )",
            "",
            "    def test_title(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], title=\"New Title\"",
            "        )",
            "",
            "        assert dataset_[\"title\"] == \"New Title\"",
            "        assert (",
            "            helpers.call_action(\"package_show\", id=dataset[\"id\"])[\"title\"]",
            "            == \"New Title\"",
            "        )",
            "",
            "    def test_extras(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[{\"key\": u\"original media\", \"value\": u'\"book\"'}],",
            "        )",
            "",
            "        assert dataset_[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset_[\"extras\"][0][\"value\"] == '\"book\"'",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset_[\"extras\"][0][\"key\"] == \"original media\"",
            "        assert dataset_[\"extras\"][0][\"value\"] == '\"book\"'",
            "",
            "    def test_extra_can_be_restored_after_deletion(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[",
            "                {\"key\": u\"old attribute\", \"value\": u'value'},",
            "                {\"key\": u\"original media\", \"value\": u'\"book\"'},",
            "            ],",
            "        )",
            "",
            "        assert len(dataset_[\"extras\"]) == 2",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[],",
            "        )",
            "",
            "        assert dataset_[\"extras\"] == []",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            extras=[",
            "                {\"key\": u\"original media\", \"value\": u'\"book\"'},",
            "                {\"key\": u\"new attribute\", \"value\": u'value'},",
            "            ],",
            "        )",
            "",
            "        assert len(dataset_[\"extras\"]) == 2",
            "",
            "    def test_license(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], license_id=\"other-open\"",
            "        )",
            "",
            "        assert dataset_[\"license_id\"] == \"other-open\"",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset_[\"license_id\"] == \"other-open\"",
            "",
            "    def test_notes(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\", id=dataset[\"id\"], notes=\"some notes\"",
            "        )",
            "",
            "        assert dataset_[\"notes\"] == \"some notes\"",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        assert dataset_[\"notes\"] == \"some notes\"",
            "",
            "    def test_resources(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            resources=[",
            "                {",
            "                    \"alt_url\": u\"alt123\",",
            "                    \"description\": u\"Full text.\",",
            "                    \"somekey\": \"somevalue\",  # this is how to do resource extras",
            "                    \"extras\": {u\"someotherkey\": u\"alt234\"},  # this isnt",
            "                    \"format\": u\"plain text\",",
            "                    \"hash\": u\"abc123\",",
            "                    \"position\": 0,",
            "                    \"url\": u\"http://datahub.io/download/\",",
            "                },",
            "                {",
            "                    \"description\": u\"Index of the novel\",",
            "                    \"format\": u\"JSON\",",
            "                    \"position\": 1,",
            "                    \"url\": u\"http://datahub.io/index.json\",",
            "                },",
            "            ],",
            "        )",
            "",
            "        resources_ = dataset_[\"resources\"]",
            "        assert resources_[0][\"alt_url\"] == \"alt123\"",
            "        assert resources_[0][\"description\"] == \"Full text.\"",
            "        assert resources_[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources_[0]",
            "        assert \"someotherkey\" not in resources_[0]",
            "        assert resources_[0][\"format\"] == \"plain text\"",
            "        assert resources_[0][\"hash\"] == \"abc123\"",
            "        assert resources_[0][\"position\"] == 0",
            "        assert resources_[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources_[1][\"description\"] == \"Index of the novel\"",
            "        assert resources_[1][\"format\"] == \"JSON\"",
            "        assert resources_[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources_[1][\"position\"] == 1",
            "        resources_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ]",
            "        assert resources_[0][\"alt_url\"] == \"alt123\"",
            "        assert resources_[0][\"description\"] == \"Full text.\"",
            "        assert resources_[0][\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resources_[0]",
            "        assert \"someotherkey\" not in resources_[0]",
            "        assert resources_[0][\"format\"] == \"plain text\"",
            "        assert resources_[0][\"hash\"] == \"abc123\"",
            "        assert resources_[0][\"position\"] == 0",
            "        assert resources_[0][\"url\"] == \"http://datahub.io/download/\"",
            "        assert resources_[1][\"description\"] == \"Index of the novel\"",
            "        assert resources_[1][\"format\"] == \"JSON\"",
            "        assert resources_[1][\"url\"] == \"http://datahub.io/index.json\"",
            "        assert resources_[1][\"position\"] == 1",
            "",
            "    def test_invalid_characters_in_resource_id(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                \"package_update\",",
            "                id=dataset[\"id\"],",
            "                resources=[",
            "                    {",
            "                        \"id\": \"../../nope.txt\",",
            "                        \"url\": \"http://data\",",
            "                        \"name\": \"A nice resource\",",
            "                    },",
            "                ],",
            "            )",
            "",
            "    def test_tags(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        dataset_ = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            tags=[{\"name\": u\"russian\"}, {\"name\": u\"tolstoy\"}],",
            "        )",
            "",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset_[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "        dataset_ = helpers.call_action(\"package_show\", id=dataset[\"id\"])",
            "        tag_names = sorted([tag_dict[\"name\"] for tag_dict in dataset_[\"tags\"]])",
            "        assert tag_names == [\"russian\", \"tolstoy\"]",
            "",
            "    def test_return_id_only(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(user=user)",
            "",
            "        updated_dataset = helpers.call_action(",
            "            \"package_update\",",
            "            id=dataset[\"id\"],",
            "            notes=\"Test\",",
            "            context={\"return_id_only\": True},",
            "        )",
            "",
            "        assert updated_dataset == dataset[\"id\"]",
            "",
            "",
            "@pytest.mark.usefixtures(\"with_request_context\")",
            "class TestUpdateSendEmailNotifications(object):",
            "    @pytest.mark.ckan_config(\"ckan.activity_streams_email_notifications\", True)",
            "    @mock.patch(\"ckan.logic.action.update.request\")",
            "    def test_calling_through_paster_doesnt_validates_auth(self, mock_request):",
            "        mock_request.environ.get.return_value = True",
            "        helpers.call_action(\"send_email_notifications\")",
            "",
            "    @pytest.mark.ckan_config(\"ckan.activity_streams_email_notifications\", True)",
            "    @mock.patch(\"ckan.logic.action.update.request\")",
            "    def test_not_calling_through_paster_validates_auth(self, mock_request):",
            "        mock_request.environ.get.return_value = False",
            "        with pytest.raises(logic.NotAuthorized):",
            "            helpers.call_action(",
            "                \"send_email_notifications\", context={\"ignore_auth\": False}",
            "            )",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\", \"with_request_context\")",
            "class TestResourceViewUpdate(object):",
            "    def test_resource_view_update(self):",
            "        resource_view = factories.ResourceView()",
            "        params = {",
            "            \"id\": resource_view[\"id\"],",
            "            \"title\": \"new title\",",
            "            \"description\": \"new description\",",
            "        }",
            "",
            "        result = helpers.call_action(\"resource_view_update\", **params)",
            "",
            "        assert result[\"title\"] == params[\"title\"]",
            "        assert result[\"description\"] == params[\"description\"]",
            "",
            "    @mock.patch(\"ckan.lib.datapreview\")",
            "    def test_filterable_views_converts_filter_fields_and_values_into_filters_dict(",
            "        self, datapreview_mock",
            "    ):",
            "        filterable_view = mock.MagicMock()",
            "        filterable_view.info.return_value = {\"filterable\": True}",
            "        datapreview_mock.get_view_plugin.return_value = filterable_view",
            "        resource_view = factories.ResourceView()",
            "        context = {}",
            "        params = {",
            "            \"id\": resource_view[\"id\"],",
            "            \"filter_fields\": [\"country\", \"weather\", \"country\"],",
            "            \"filter_values\": [\"Brazil\", \"warm\", \"Argentina\"],",
            "        }",
            "        result = helpers.call_action(\"resource_view_update\", context, **params)",
            "        expected_filters = {",
            "            \"country\": [\"Brazil\", \"Argentina\"],",
            "            \"weather\": [\"warm\"],",
            "        }",
            "        assert result[\"filters\"] == expected_filters",
            "",
            "    def test_resource_view_update_requires_id(self):",
            "        params = {}",
            "",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(\"resource_view_update\", **params)",
            "",
            "    def test_resource_view_update_requires_existing_id(self):",
            "        params = {\"id\": \"inexistent_id\"}",
            "",
            "        with pytest.raises(logic.NotFound):",
            "            helpers.call_action(\"resource_view_update\", **params)",
            "",
            "    def test_resource_view_list_reorder(self):",
            "        resource_view_1 = factories.ResourceView(title=\"View 1\")",
            "",
            "        resource_id = resource_view_1[\"resource_id\"]",
            "",
            "        resource_view_2 = factories.ResourceView(",
            "            resource_id=resource_id, title=\"View 2\"",
            "        )",
            "",
            "        resource_view_list = helpers.call_action(",
            "            \"resource_view_list\", id=resource_id",
            "        )",
            "",
            "        assert resource_view_list[0][\"title\"] == \"View 1\"",
            "        assert resource_view_list[1][\"title\"] == \"View 2\"",
            "",
            "        # Reorder views",
            "",
            "        result = helpers.call_action(",
            "            \"resource_view_reorder\",",
            "            id=resource_id,",
            "            order=[resource_view_2[\"id\"], resource_view_1[\"id\"]],",
            "        )",
            "        assert result[\"order\"] == [",
            "            resource_view_2[\"id\"],",
            "            resource_view_1[\"id\"],",
            "        ]",
            "",
            "        resource_view_list = helpers.call_action(",
            "            \"resource_view_list\", id=resource_id",
            "        )",
            "",
            "        assert resource_view_list[0][\"title\"] == \"View 2\"",
            "        assert resource_view_list[1][\"title\"] == \"View 1\"",
            "",
            "    def test_resource_view_list_reorder_just_one_id(self):",
            "        resource_view_1 = factories.ResourceView(title=\"View 1\")",
            "",
            "        resource_id = resource_view_1[\"resource_id\"]",
            "",
            "        resource_view_2 = factories.ResourceView(",
            "            resource_id=resource_id, title=\"View 2\"",
            "        )",
            "",
            "        # Reorder Views back just by specifiying a single view to go first",
            "",
            "        result = helpers.call_action(",
            "            \"resource_view_reorder\",",
            "            id=resource_id,",
            "            order=[resource_view_2[\"id\"]],",
            "        )",
            "        assert result[\"order\"] == [",
            "            resource_view_2[\"id\"],",
            "            resource_view_1[\"id\"],",
            "        ]",
            "",
            "        resource_view_list = helpers.call_action(",
            "            \"resource_view_list\", id=resource_id",
            "        )",
            "",
            "        assert resource_view_list[0][\"title\"] == \"View 2\"",
            "        assert resource_view_list[1][\"title\"] == \"View 1\"",
            "",
            "    def test_calling_with_only_id_doesnt_update_anything(self):",
            "        resource_view = factories.ResourceView()",
            "        params = {\"id\": resource_view[\"id\"]}",
            "",
            "        result = helpers.call_action(\"resource_view_update\", **params)",
            "        assert result == resource_view",
            "",
            "",
            "@pytest.mark.ckan_config(\"ckan.plugins\", \"image_view recline_view\")",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_plugins\", \"with_request_context\")",
            "class TestResourceUpdate(object):",
            "",
            "    def test_url_only(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package=dataset, url=\"http://first\")",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\", id=resource[\"id\"], url=\"http://second\"",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert resource[\"url\"] == \"http://second\"",
            "",
            "    def test_extra_only(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package=dataset, newfield=\"first\")",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=resource[\"url\"],",
            "            newfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"newfield\"] == \"second\"",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert resource[\"newfield\"] == \"second\"",
            "",
            "    def test_both_extra_and_url(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://first\", newfield=\"first\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://second\",",
            "            newfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert res_returned[\"newfield\"] == \"second\"",
            "",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert resource[\"newfield\"] == \"second\"",
            "",
            "    def test_extra_gets_deleted_on_both_core_and_extra_update(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://first\", newfield=\"first\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://second\",",
            "            anotherfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert res_returned[\"url\"] == \"http://second\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "    def test_extra_gets_deleted_on_extra_only_update(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://first\", newfield=\"first\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://first\",",
            "            anotherfield=\"second\",",
            "        )",
            "",
            "        assert res_returned[\"url\"] == \"http://first\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "        resource = helpers.call_action(\"resource_show\", id=resource[\"id\"])",
            "        assert res_returned[\"url\"] == \"http://first\"",
            "        assert res_returned[\"anotherfield\"] == \"second\"",
            "        assert \"newfield\" not in res_returned",
            "",
            "    def test_datastore_active_is_persisted_if_true_and_not_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=True",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "        )",
            "",
            "        assert res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_is_persisted_if_false_and_not_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=False",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "        )",
            "",
            "        assert not res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_is_updated_if_false_and_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=False",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "            datastore_active=True,",
            "        )",
            "",
            "        assert res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_is_updated_if_true_and_provided(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\", datastore_active=True",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "            datastore_active=False,",
            "        )",
            "",
            "        assert not res_returned[\"datastore_active\"]",
            "",
            "    def test_datastore_active_not_present_if_not_provided_and_not_datastore_plugin_enabled(",
            "        self,",
            "    ):",
            "        assert not p.plugin_loaded(\"datastore\")",
            "",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://example.com\"",
            "        )",
            "",
            "        res_returned = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://example.com\",",
            "            name=\"Test\",",
            "        )",
            "",
            "        assert \"datastore_active\" not in res_returned",
            "",
            "    def test_mimetype_by_url(self, monkeypatch, tmpdir):",
            "        \"\"\"The mimetype is guessed from the url",
            "",
            "        Real world usage would be externally linking the resource and",
            "        the mimetype would be guessed, based on the url",
            "",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost/data.csv\", name=\"Test\"",
            "        )",
            "        monkeypatch.setattr(ckan.lib.uploader, \"_storage_path\", str(tmpdir))",
            "        res_update = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://localhost/data.json\",",
            "        )",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"application/json\"",
            "",
            "    def test_mimetype_by_user(self):",
            "        \"\"\"",
            "        The mimetype is supplied by the user",
            "",
            "        Real world usage would be using the FileStore API or web UI form to create a resource",
            "        and the user wanted to specify the mimetype themselves",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost/data.csv\", name=\"Test\"",
            "        )",
            "",
            "        res_update = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://localhost/data.csv\",",
            "            mimetype=\"text/plain\",",
            "        )",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"text/plain\"",
            "",
            "    @pytest.mark.ckan_config(\"ckan.mimetype_guess\", \"file_contents\")",
            "    def test_mimetype_by_upload_by_file(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file by the contents inside",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, that has no extension If the mimetype",
            "        can't be guessed by the url or filename, mimetype will be",
            "        guessed by the contents inside the file",
            "",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost/data.csv\", name=\"Test\"",
            "        )",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm, Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "",
            "        res_update = create_with_upload(",
            "            content, \"update_test\", action=\"resource_update\",",
            "            id=resource[\"id\"], url=\"http://localhost\",",
            "            package_id=dataset[\"id\"])",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"text/plain\"",
            "",
            "    def test_mimetype_by_upload_by_filename(self, create_with_upload):",
            "        \"\"\"The mimetype is guessed from an uploaded file with a filename",
            "",
            "        Real world usage would be using the FileStore API or web UI",
            "        form to upload a file, with a filename plus extension If",
            "        there's no url or the mimetype can't be guessed by the url,",
            "        mimetype will be guessed by the extension in the filename",
            "",
            "        \"\"\"",
            "        content = \"\"\"",
            "        \"info\": {",
            "            \"title\": \"BC Data Catalogue API\",",
            "            \"description\": \"This API provides information about datasets in the BC Data Catalogue.\",",
            "            \"termsOfService\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/API_Terms_of_Use.pdf\",",
            "            \"contact\": {",
            "                \"name\": \"Data BC\",",
            "                \"url\": \"http://data.gov.bc.ca/\",",
            "                \"email\": \"\"",
            "            },",
            "            \"license\": {",
            "                \"name\": \"Open Government License - British Columbia\",",
            "                \"url\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/OGL-vbc2.0.pdf\"",
            "            },",
            "            \"version\": \"3.0.0\"",
            "        }",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = create_with_upload(",
            "            content, 'test.json',",
            "            package_id=dataset['id'], url=\"http://localhost\")",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm, Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "",
            "        res_update = create_with_upload(",
            "            content, \"update_test.csv\", action=\"resource_update\",",
            "            id=resource[\"id\"], url=\"http://localhost\",",
            "            package_id=dataset['id'])",
            "",
            "        org_mimetype = resource.pop(\"mimetype\")",
            "        upd_mimetype = res_update.pop(\"mimetype\")",
            "",
            "        assert org_mimetype != upd_mimetype",
            "        assert upd_mimetype == \"text/csv\"",
            "",
            "    def test_size_of_resource_by_user(self):",
            "        \"\"\"",
            "        The size of the resource is provided by the users",
            "",
            "        Real world usage would be using the FileStore API and the user provides a size for the resource",
            "        \"\"\"",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(",
            "            package=dataset,",
            "            url=\"http://localhost/data.csv\",",
            "            name=\"Test\",",
            "            size=500,",
            "        )",
            "",
            "        res_update = helpers.call_action(",
            "            \"resource_update\",",
            "            id=resource[\"id\"],",
            "            url=\"http://localhost/data.csv\",",
            "            size=600,",
            "        )",
            "",
            "        org_size = int(resource.pop(\"size\"))",
            "        upd_size = int(res_update.pop(\"size\"))",
            "",
            "        assert org_size < upd_size",
            "",
            "    def test_size_of_resource_by_upload(self, create_with_upload):",
            "        \"\"\"The size of the resource determined by the uploaded file",
            "",
            "        \"\"\"",
            "        content = \"\"\"",
            "        \"info\": {",
            "            \"title\": \"BC Data Catalogue API\",",
            "            \"description\": \"This API provides information about datasets in the BC Data Catalogue.\",",
            "            \"termsOfService\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/API_Terms_of_Use.pdf\",",
            "            \"contact\": {",
            "                \"name\": \"Data BC\",",
            "                \"url\": \"http://data.gov.bc.ca/\",",
            "                \"email\": \"\"",
            "            },",
            "            \"license\": {",
            "                \"name\": \"Open Government License - British Columbia\",",
            "                \"url\": \"http://www.data.gov.bc.ca/local/dbc/docs/license/OGL-vbc2.0.pdf\"",
            "            },",
            "            \"version\": \"3.0.0\"",
            "        }",
            "        \"\"\"",
            "",
            "        dataset = factories.Dataset()",
            "",
            "        resource = create_with_upload(",
            "            content, 'test.json',",
            "            package_id=dataset['id'], url=\"http://localhost\")",
            "",
            "        content = \"\"\"",
            "        Snow Course Name, Number, Elev. metres, Date of Survey, Snow Depth cm, Water Equiv. mm, Survey Code, % of Normal, Density %, Survey Period, Normal mm",
            "        SKINS LAKE,1B05,890,2015/12/30,34,53,,98,16,JAN-01,54",
            "        MCGILLIVRAY PASS,1C05,1725,2015/12/31,88,239,,87,27,JAN-01,274",
            "        NAZKO,1C08,1070,2016/01/05,20,31,,76,16,JAN-01,41",
            "        \"\"\"",
            "        res_update = create_with_upload(",
            "            content, \"update_test.csv\", action=\"resource_update\",",
            "            id=resource[\"id\"], url=\"http://localhost\",",
            "            package_id=dataset[\"id\"])",
            "",
            "        org_size = int(resource.pop(\"size\"))  # 669 bytes",
            "        upd_size = int(res_update.pop(\"size\"))  # 358 bytes",
            "",
            "        assert org_size > upd_size",
            "",
            "    def test_extras(self):",
            "        user = factories.User()",
            "        dataset = factories.Dataset(",
            "            user=user,",
            "            resources=[dict(format=u\"json\", url=u\"http://datahub.io/\")],",
            "        )",
            "",
            "        resource = helpers.call_action(",
            "            \"resource_update\",",
            "            id=dataset[\"resources\"][0][\"id\"],",
            "            somekey=\"somevalue\",  # this is how to do resource extras",
            "            extras={u\"someotherkey\": u\"alt234\"},  # this isnt",
            "            format=u\"plain text\",",
            "            url=u\"http://datahub.io/download/\",",
            "        )",
            "",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "        resource = helpers.call_action(\"package_show\", id=dataset[\"id\"])[",
            "            \"resources\"",
            "        ][0]",
            "        assert resource[\"somekey\"] == \"somevalue\"",
            "        assert \"extras\" not in resource",
            "        assert \"someotherkey\" not in resource",
            "",
            "    @helpers.change_config(",
            "        \"ckan.views.default_views\", \"image_view recline_view\"",
            "    )",
            "    def test_resource_format_update(self):",
            "        dataset = factories.Dataset()",
            "",
            "        # Create resource without format",
            "        resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost\", name=\"Test\"",
            "        )",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 0",
            "",
            "        # Update resource with format",
            "        resource = helpers.call_action(",
            "            \"resource_update\", id=resource[\"id\"], format=\"CSV\"",
            "        )",
            "",
            "        # Format changed",
            "        assert resource[\"format\"] == \"CSV\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=resource[\"id\"]",
            "        )",
            "",
            "        # View for resource is created",
            "        assert len(res_views) == 1",
            "",
            "        second_resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost\", name=\"Test2\", format=\"CSV\"",
            "        )",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=second_resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 1",
            "",
            "        second_resource = helpers.call_action(",
            "            \"resource_update\", id=second_resource[\"id\"], format=\"PNG\"",
            "        )",
            "",
            "        # Format changed",
            "        assert second_resource[\"format\"] == \"PNG\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=second_resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 2",
            "",
            "        third_resource = factories.Resource(",
            "            package=dataset, url=\"http://localhost\", name=\"Test2\"",
            "        )",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=third_resource[\"id\"]",
            "        )",
            "",
            "        assert len(res_views) == 0",
            "",
            "        third_resource = helpers.call_action(",
            "            \"resource_update\", id=third_resource[\"id\"], format=\"Test format\"",
            "        )",
            "",
            "        # Format added",
            "        assert third_resource[\"format\"] == \"Test format\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=third_resource[\"id\"]",
            "        )",
            "",
            "        # No view created, cause no such format",
            "        assert len(res_views) == 0",
            "",
            "        third_resource = helpers.call_action(",
            "            \"resource_update\", id=third_resource[\"id\"], format=\"CSV\"",
            "        )",
            "",
            "        # Format changed",
            "        assert third_resource[\"format\"] == \"CSV\"",
            "",
            "        res_views = helpers.call_action(",
            "            \"resource_view_list\", id=third_resource[\"id\"]",
            "        )",
            "",
            "        # View is created",
            "        assert len(res_views) == 1",
            "",
            "    def test_edit_metadata_updates_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='New Description',",
            "            )",
            "            assert resource['metadata_modified'] == '2020-02-25T12:00:00'",
            "",
            "    def test_same_values_dont_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(",
            "                package_id=dataset['id'],",
            "                description='Test',",
            "                some_custom_field='test',",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='Test',",
            "                some_custom_field='test',",
            "                url='http://link.to.some.data'  # Default Value from Factory",
            "            )",
            "            assert (resource['metadata_modified'] !=",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '1987-03-04T23:30:00')",
            "",
            "    def test_new_keys_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(package_id=dataset['id'], description='test')",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='test',",
            "                some_custom_field='test',",
            "                url='http://link.to.some.data'  # default value from factory",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '2020-02-25T12:00:00')",
            "",
            "    def test_remove_keys_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(",
            "                package_id=dataset['id'],",
            "                description='test',",
            "                some_custom_field='test',",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='test',",
            "                url='http://link.to.some.data'  # default value from factory",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '2020-02-25T12:00:00')",
            "",
            "    def test_update_keys_update_metadata_modified_field(self):",
            "        dataset = factories.Dataset()",
            "",
            "        with freeze_time('1987-03-04 23:30:00'):",
            "            resource = factories.Resource(",
            "                package_id=dataset['id'],",
            "                description='test',",
            "                some_custom_field='test',",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "",
            "        with freeze_time('2020-02-25 12:00:00'):",
            "            resource = helpers.call_action(",
            "                \"resource_update\",",
            "                id=resource[\"id\"],",
            "                description='test',",
            "                some_custom_field='test2',",
            "                url='http://link.to.some.data'  # default value from factory",
            "            )",
            "            assert (resource['metadata_modified'] ==",
            "                    datetime.datetime.utcnow().isoformat())",
            "            assert (resource['metadata_modified'] ==",
            "                    '2020-02-25T12:00:00')",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestConfigOptionUpdate(object):",
            "",
            "    # NOTE: the opposite is tested in",
            "    # ckan/ckanext/example_iconfigurer/tests/test_iconfigurer_update_config.py",
            "    # as we need to enable an external config option from an extension",
            "",
            "    def test_app_globals_set_if_defined(self):",
            "        key = \"ckan.site_title\"",
            "        value = \"Test site title\"",
            "",
            "        params = {key: value}",
            "",
            "        helpers.call_action(\"config_option_update\", **params)",
            "",
            "        globals_key = app_globals.get_globals_key(key)",
            "        assert hasattr(app_globals.app_globals, globals_key)",
            "",
            "        assert getattr(app_globals.app_globals, globals_key) == value",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestUserUpdate(object):",
            "    def test_user_update_with_password_hash(self):",
            "        sysadmin = factories.Sysadmin()",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "",
            "        user = helpers.call_action(",
            "            \"user_update\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            id=sysadmin[\"name\"],",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password == \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_user_create_password_hash_not_for_normal_users(self):",
            "        normal_user = factories.User()",
            "        context = {\"user\": normal_user[\"name\"], \"ignore_auth\": False}",
            "",
            "        user = helpers.call_action(",
            "            \"user_update\",",
            "            context=context,",
            "            email=\"test@example.com\",",
            "            id=normal_user[\"name\"],",
            "            password=\"required\",",
            "            password_hash=\"pretend-this-is-a-valid-hash\",",
            "        )",
            "",
            "        user_obj = model.User.get(user[\"id\"])",
            "        assert user_obj.password != \"pretend-this-is-a-valid-hash\"",
            "",
            "    def test_user_update_image_url(self):",
            "        user = factories.User(image_url='user_image.jpg')",
            "        context = {\"user\": user[\"name\"]}",
            "",
            "        user = helpers.call_action(",
            "            \"user_update\",",
            "            context=context,",
            "            id=user[\"name\"],",
            "            email=\"test@example.com\",",
            "            image_url=\"new_image_url.jpg\",",
            "        )",
            "",
            "        assert user[\"image_url\"] == \"new_image_url.jpg\"",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestGroupUpdate(object):",
            "    def test_group_update_image_url_field(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        group = factories.Group(",
            "            type=\"group\",",
            "            name=\"testing\",",
            "            user=user,",
            "            image_url='group_image.jpg')",
            "",
            "        group = helpers.call_action(",
            "            \"group_update\",",
            "            context=context,",
            "            id=group[\"id\"],",
            "            name=group[\"name\"],",
            "            type=group[\"type\"],",
            "            image_url=\"new_image_url.jpg\"",
            "        )",
            "",
            "        assert group[\"image_url\"] == \"new_image_url.jpg\"",
            "",
            "    def test_group_update_cant_change_type(self):",
            "        user = factories.User()",
            "        context = {\"user\": user[\"name\"]}",
            "        group = factories.Group(type=\"group\", name=\"unchanging\", user=user)",
            "",
            "        group = helpers.call_action(",
            "            \"group_update\",",
            "            context=context,",
            "            id=group[\"id\"],",
            "            name=\"unchanging\",",
            "            type=\"favouritecolour\",",
            "        )",
            "",
            "        assert group[\"type\"] == \"group\"",
            "        assert (",
            "            helpers.call_action(\"group_show\", id=\"unchanging\")[\"type\"]",
            "            == \"group\"",
            "        )",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestPackageOwnerOrgUpdate(object):",
            "    def test_package_owner_org_added(self):",
            "        \"\"\"A package without an owner_org can have one added.\"\"\"",
            "        sysadmin = factories.Sysadmin()",
            "        org = factories.Organization()",
            "        dataset = factories.Dataset()",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        assert dataset[\"owner_org\"] is None",
            "        helpers.call_action(",
            "            \"package_owner_org_update\",",
            "            context=context,",
            "            id=dataset[\"id\"],",
            "            organization_id=org[\"id\"],",
            "        )",
            "        dataset_obj = model.Package.get(dataset[\"id\"])",
            "        assert dataset_obj.owner_org == org[\"id\"]",
            "",
            "    def test_package_owner_org_changed(self):",
            "        \"\"\"A package with an owner_org can have it changed.\"\"\"",
            "",
            "        sysadmin = factories.Sysadmin()",
            "        org_1 = factories.Organization()",
            "        org_2 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org_1[\"id\"])",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        assert dataset[\"owner_org\"] == org_1[\"id\"]",
            "        helpers.call_action(",
            "            \"package_owner_org_update\",",
            "            context=context,",
            "            id=dataset[\"id\"],",
            "            organization_id=org_2[\"id\"],",
            "        )",
            "        dataset_obj = model.Package.get(dataset[\"id\"])",
            "        assert dataset_obj.owner_org == org_2[\"id\"]",
            "",
            "    def test_package_owner_org_removed(self):",
            "        \"\"\"A package with an owner_org can have it removed.\"\"\"",
            "        sysadmin = factories.Sysadmin()",
            "        org = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org[\"id\"])",
            "        context = {\"user\": sysadmin[\"name\"]}",
            "        assert dataset[\"owner_org\"] == org[\"id\"]",
            "        helpers.call_action(",
            "            \"package_owner_org_update\",",
            "            context=context,",
            "            id=dataset[\"id\"],",
            "            organization_id=None,",
            "        )",
            "        dataset_obj = model.Package.get(dataset[\"id\"])",
            "        assert dataset_obj.owner_org is None",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestBulkOperations(object):",
            "    def test_bulk_make_private(self):",
            "",
            "        org = factories.Organization()",
            "",
            "        dataset1 = factories.Dataset(owner_org=org[\"id\"])",
            "        dataset2 = factories.Dataset(owner_org=org[\"id\"])",
            "",
            "        helpers.call_action(",
            "            \"bulk_update_private\",",
            "            {},",
            "            datasets=[dataset1[\"id\"], dataset2[\"id\"]],",
            "            org_id=org[\"id\"],",
            "        )",
            "",
            "        # Check search index",
            "        datasets = helpers.call_action(",
            "            \"package_search\", {}, q=\"owner_org:{0}\".format(org[\"id\"])",
            "        )",
            "",
            "        for dataset in datasets[\"results\"]:",
            "            assert dataset[\"private\"]",
            "",
            "        # Check DB",
            "        datasets = (",
            "            model.Session.query(model.Package)",
            "            .filter(model.Package.owner_org == org[\"id\"])",
            "            .all()",
            "        )",
            "        for dataset in datasets:",
            "            assert dataset.private",
            "",
            "    def test_bulk_make_public(self):",
            "",
            "        org = factories.Organization()",
            "",
            "        dataset1 = factories.Dataset(owner_org=org[\"id\"], private=True)",
            "        dataset2 = factories.Dataset(owner_org=org[\"id\"], private=True)",
            "",
            "        helpers.call_action(",
            "            \"bulk_update_public\",",
            "            {},",
            "            datasets=[dataset1[\"id\"], dataset2[\"id\"]],",
            "            org_id=org[\"id\"],",
            "        )",
            "",
            "        # Check search index",
            "        datasets = helpers.call_action(",
            "            \"package_search\", {}, q=\"owner_org:{0}\".format(org[\"id\"])",
            "        )",
            "",
            "        for dataset in datasets[\"results\"]:",
            "            assert not (dataset[\"private\"])",
            "",
            "        # Check DB",
            "        datasets = (",
            "            model.Session.query(model.Package)",
            "            .filter(model.Package.owner_org == org[\"id\"])",
            "            .all()",
            "        )",
            "        for dataset in datasets:",
            "            assert not (dataset.private)",
            "        activities = helpers.call_action(",
            "            \"organization_activity_list\", id=org[\"id\"]",
            "        )",
            "        assert activities[0]['activity_type'] == 'changed package'",
            "",
            "    def test_bulk_delete(self):",
            "",
            "        org = factories.Organization()",
            "",
            "        dataset1 = factories.Dataset(owner_org=org[\"id\"])",
            "        dataset2 = factories.Dataset(owner_org=org[\"id\"])",
            "",
            "        helpers.call_action(",
            "            \"bulk_update_delete\",",
            "            {},",
            "            datasets=[dataset1[\"id\"], dataset2[\"id\"]],",
            "            org_id=org[\"id\"],",
            "        )",
            "",
            "        # Check search index",
            "        datasets = helpers.call_action(",
            "            \"package_search\", {}, q=\"owner_org:{0}\".format(org[\"id\"])",
            "        )",
            "",
            "        assert datasets[\"results\"] == []",
            "",
            "        # Check DB",
            "        datasets = (",
            "            model.Session.query(model.Package)",
            "            .filter(model.Package.owner_org == org[\"id\"])",
            "            .all()",
            "        )",
            "        for dataset in datasets:",
            "            assert dataset.state == \"deleted\"",
            "",
            "        activities = helpers.call_action(",
            "            \"organization_activity_list\", id=org[\"id\"]",
            "        )",
            "        assert activities[0]['activity_type'] == 'deleted package'",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDashboardMarkActivitiesOld(object):",
            "    def test_mark_as_old_some_activities_by_a_followed_user(self):",
            "        # do some activity that will show up on user's dashboard",
            "        user = factories.User()",
            "        # now some activity that is \"new\" because it is by a followed user",
            "        followed_user = factories.User()",
            "        helpers.call_action(",
            "            \"follow_user\", context={\"user\": user[\"name\"]}, **followed_user",
            "        )",
            "        dataset = factories.Dataset(user=followed_user)",
            "        dataset[\"title\"] = \"Dataset with changed title\"",
            "        helpers.call_action(",
            "            \"package_update\",",
            "            context={\"user\": followed_user[\"name\"]},",
            "            **dataset",
            "        )",
            "        assert (",
            "            helpers.call_action(",
            "                \"dashboard_new_activities_count\", context={\"user\": user[\"id\"]}",
            "            )",
            "            == 3",
            "        )",
            "        activities = helpers.call_action(",
            "            \"dashboard_activity_list\", context={\"user\": user[\"id\"]}",
            "        )",
            "        assert [",
            "            (activity[\"activity_type\"], activity[\"is_new\"])",
            "            for activity in activities[::-1]",
            "        ] == [",
            "            (\"new user\", False),",
            "            (\"new user\", True),",
            "            (\"new package\", True),",
            "            (\"changed package\", True),",
            "        ]",
            "",
            "        helpers.call_action(",
            "            \"dashboard_mark_activities_old\", context={\"user\": user[\"name\"]}",
            "        )",
            "",
            "        assert (",
            "            helpers.call_action(",
            "                \"dashboard_new_activities_count\", context={\"user\": user[\"id\"]}",
            "            )",
            "            == 0",
            "        )",
            "        activities = helpers.call_action(",
            "            \"dashboard_activity_list\", context={\"user\": user[\"id\"]}",
            "        )",
            "        assert [",
            "            (activity[\"activity_type\"], activity[\"is_new\"])",
            "            for activity in activities[::-1]",
            "        ] == [",
            "            (\"new user\", False),",
            "            (\"new user\", False),",
            "            (\"new package\", False),",
            "            (\"changed package\", False),",
            "        ]",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "@pytest.mark.ckan_config('ckan.auth.allow_dataset_collaborators', True)",
            "class TestCollaboratorsUpdate(object):",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_admin_collaborators', True)",
            "    @pytest.mark.parametrize('role', ['admin', 'editor'])",
            "    def test_collaborators_can_update_resources(self, role):",
            "",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "        resource = factories.Resource(package_id=dataset['id'])",
            "",
            "        user = factories.User()",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity=role)",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        updated_resource = helpers.call_action(",
            "            'resource_update',",
            "            context=context,",
            "            id=resource['id'],",
            "            description='updated')",
            "",
            "        assert updated_resource['description'] == 'updated'",
            "",
            "    def test_collaborators_can_not_change_owner_org_by_default(self):",
            "",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        user = factories.User()",
            "        org2 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='editor')",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        dataset['owner_org'] = org2['id']",
            "",
            "        with pytest.raises(logic.ValidationError) as e:",
            "            helpers.call_action('package_update', context=context, **dataset)",
            "",
            "        assert e.value.error_dict['owner_org'] == [",
            "            'You cannot move this dataset to another organization']",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_collaborators_to_change_owner_org', True)",
            "    def test_collaborators_can_change_owner_org_if_config_true(self):",
            "        org1 = factories.Organization()",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        user = factories.User()",
            "        org2 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='editor')",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        dataset['owner_org'] = org2['id']",
            "",
            "        updated_dataset = helpers.call_action('package_update', context=context, **dataset)",
            "",
            "        assert updated_dataset['owner_org'] == org2['id']",
            "",
            "    @pytest.mark.ckan_config('ckan.auth.allow_collaborators_to_change_owner_org', True)",
            "    def test_editors_can_change_owner_org_even_if_collaborators(self):",
            "",
            "        user = factories.User()",
            "",
            "        org1 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "        dataset = factories.Dataset(owner_org=org1['id'])",
            "",
            "        org2 = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "",
            "        helpers.call_action(",
            "            'package_collaborator_create',",
            "            id=dataset['id'], user_id=user['id'], capacity='editor')",
            "",
            "        context = {",
            "            'user': user['name'],",
            "            'ignore_auth': False,",
            "",
            "        }",
            "",
            "        dataset['owner_org'] = org2['id']",
            "",
            "        updated_dataset = helpers.call_action('package_update', context=context, **dataset)",
            "",
            "        assert updated_dataset['owner_org'] == org2['id']",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\", \"with_request_context\")",
            "class TestDatasetRevise(object):",
            "    def test_revise_description(self):",
            "        factories.Dataset(name='xyz', notes='old notes')",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'notes': 'old notes', 'name': 'xyz'},",
            "            update={'notes': 'new notes'},",
            "        )",
            "        assert response['package']['notes'] == 'new notes'",
            "",
            "    def test_revise_failed_match(self):",
            "        factories.Dataset(name='xyz', notes='old notes')",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                'package_revise',",
            "                match={'notes': 'wrong notes', 'name': 'xyz'},",
            "                update={'notes': 'new notes'},",
            "            )",
            "",
            "    def test_revise_description_flattened(self):",
            "        factories.Dataset(name='xyz', notes='old notes')",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match__notes='old notes',",
            "            match__name='xyz',",
            "            update__notes='new notes',",
            "        )",
            "        assert response['package']['notes'] == 'new notes'",
            "",
            "    def test_revise_dataset_fields_only(self):",
            "        dataset = factories.Dataset(",
            "            name='xyz',",
            "            notes='old notes',",
            "            resources=[{'url': 'http://example.com'}])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            filter=[",
            "                '+resources',  # keep everything under resources",
            "                '-*',  # remove everything else",
            "            ],",
            "            update={'name': 'fresh-start', 'title': 'Fresh Start'},",
            "        )",
            "        assert response['package']['notes'] is None",
            "        assert response['package']['name'] == 'fresh-start'",
            "        assert response['package']['resources'][0]['url'] == 'http://example.com'",
            "",
            "    def test_revise_add_resource(self):",
            "        dataset = factories.Dataset()",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            update__resources__extend=[{'name': 'new resource', 'url': 'http://example.com'}],",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new resource'",
            "",
            "    def test_revise_invalid_resource_id(self):",
            "        dataset = factories.Dataset()",
            "        with pytest.raises(logic.ValidationError):",
            "            helpers.call_action(",
            "                'package_revise',",
            "                match={'id': dataset['id']},",
            "                update__resources__extend=[",
            "                    {",
            "                        'id': '../../nope.txt',",
            "                        'name': 'new resource',",
            "                        'url': 'http://example.com'",
            "                    }",
            "                ],",
            "            )",
            "",
            "    def test_revise_resource_by_index(self):",
            "        dataset = factories.Dataset(resources=[{'url': 'http://example.com'}])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            update__resources__0={'name': 'new name'},",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new name'",
            "",
            "    def test_revise_resource_by_id(self):",
            "        dataset = factories.Dataset(resources=[{",
            "            'id': '34a12bc-1420-cbad-1922',",
            "            'url': 'http://example.com',",
            "            'name': 'old name',",
            "        }])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            update__resources__34a12={'name': 'new name'},  # prefixes allowed >4 chars",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new name'",
            "",
            "    def test_revise_resource_replace_all(self):",
            "        dataset = factories.Dataset(resources=[{",
            "            'id': '34a12bc-1420-cbad-1922',",
            "            'url': 'http://example.com',",
            "            'name': 'old name',",
            "        }])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': dataset['id']},",
            "            filter=['+resources__34a12__id', '-resources__34a12__*'],",
            "            update__resources__34a12={'name': 'new name'},",
            "        )",
            "        assert response['package']['resources'][0]['name'] == 'new name'",
            "        assert response['package']['resources'][0]['url'] == ''",
            "",
            "    def test_revise_normal_user(self):",
            "        user = factories.User()",
            "        org = factories.Organization(users=[{'name': user['id'], 'capacity': 'admin'}])",
            "        # make sure normal users can use package_revise",
            "        context = {'user': user['name'], 'ignore_auth': False}",
            "        ds = factories.Dataset(owner_org=org['id'])",
            "        response = helpers.call_action(",
            "            'package_revise',",
            "            match={'id': ds['id']},",
            "            update={'notes': 'new notes'},",
            "            context=context,",
            "        )",
            "        assert response['package']['notes'] == 'new notes'",
            "",
            "",
            "@pytest.mark.usefixtures(\"clean_db\")",
            "class TestUserPluginExtras(object):",
            "",
            "    def test_stored_on_update_if_sysadmin(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user = factories.User(",
            "            plugin_extras={",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        )",
            "",
            "        user['plugin_extras'] = {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2'",
            "            }",
            "        }",
            "",
            "        # helpers.call_action sets 'ignore_auth' to True by default",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "",
            "        updated_user = helpers.call_action(",
            "            'user_update', context=context, **user)",
            "",
            "        assert updated_user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2',",
            "            }",
            "        }",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=user['id'], include_plugin_extras=True)",
            "",
            "        assert updated_user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2',",
            "            }",
            "        }",
            "",
            "        plugin_extras_from_db = model.Session.execute(",
            "            'SELECT plugin_extras FROM \"user\" WHERE id=:id',",
            "            {'id': user['id']}",
            "        ).first().values()[0]",
            "",
            "        assert plugin_extras_from_db == {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2',",
            "            }",
            "        }",
            "",
            "    def test_ignored_on_update_if_non_sysadmin(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user = factories.User(",
            "            plugin_extras={",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        )",
            "",
            "        user['plugin_extras'] = {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2'",
            "            }",
            "        }",
            "",
            "        # User edits themselves",
            "        context = {'user': user['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_update', context=context, **user)",
            "",
            "        assert 'plugin_extras' not in created_user",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user['plugin_extras'] == {",
            "            'plugin1': {",
            "                'key1': 'value1'",
            "            }",
            "        }",
            "",
            "    def test_ignored_on_update_if_non_sysadmin_when_empty(self):",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        user = factories.User()",
            "",
            "        user['plugin_extras'] = {",
            "            'plugin1': {",
            "                'key1': 'value1.2',",
            "                'key2': 'value2'",
            "            }",
            "        }",
            "",
            "        # User edits themselves",
            "        context = {'user': user['name'], 'ignore_auth': False}",
            "",
            "        created_user = helpers.call_action(",
            "            'user_update', context=context, **user)",
            "",
            "        assert 'plugin_extras' not in created_user",
            "",
            "        context = {'user': sysadmin['name'], 'ignore_auth': False}",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=created_user['id'], include_plugin_extras=True)",
            "",
            "        assert user['plugin_extras'] is None",
            "",
            "    def test_nested_updates_are_reflected_in_db(self):",
            "",
            "        user = factories.User(",
            "            plugin_extras={",
            "                'plugin1': {",
            "                    'key1': 'value1'",
            "                }",
            "            }",
            "        )",
            "",
            "        sysadmin = factories.Sysadmin()",
            "",
            "        context = {'user': sysadmin['name']}",
            "",
            "        user = helpers.call_action(",
            "            'user_show', context=context, id=user['id'], include_plugin_extras=True)",
            "",
            "        user['plugin_extras']['plugin1']['key1'] = 'value2'",
            "",
            "        updated_user = helpers.call_action('user_update', context=context, **user)",
            "",
            "        assert updated_user['plugin_extras']['plugin1']['key1'] == 'value2'",
            "",
            "        # Hold on, partner",
            "",
            "        plugin_extras = model.Session.execute(",
            "            'SELECT plugin_extras FROM \"user\" WHERE id=:id',",
            "            {'id': user['id']}",
            "        ).first().values()[0]",
            "",
            "        assert plugin_extras['plugin1']['key1'] == 'value2'"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "tlslite.tlsrecordlayer",
            "ckan.tests.logic.action.test_update.TestDatasetRevise.self",
            "ckan.tests.logic.action.test_update.TestDatasetUpdate.self"
        ]
    }
}