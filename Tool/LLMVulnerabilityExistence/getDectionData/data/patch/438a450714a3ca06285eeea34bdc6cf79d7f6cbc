{
    "mlflow/environment_variables.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": 266,
                "PatchRowcode": "     \"MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE\", str, \"500MB\""
            },
            "1": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": 267,
                "PatchRowcode": " )"
            },
            "2": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": 268,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-#: Specifies whether or not to allow using a file URI as a model version source."
            },
            "4": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-#: Please be aware that setting this environment variable to True is potentially risky"
            },
            "5": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-#: because it can allow access to arbitrary files on the specified filesystem"
            },
            "6": {
                "beforePatchRowNumber": 272,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-#: (default: ``False``)."
            },
            "7": {
                "beforePatchRowNumber": 273,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE = _BooleanEnvironmentVariable("
            },
            "8": {
                "beforePatchRowNumber": 274,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE\", False"
            },
            "9": {
                "beforePatchRowNumber": 275,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-)"
            },
            "10": {
                "beforePatchRowNumber": 276,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "11": {
                "beforePatchRowNumber": 277,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "12": {
                "beforePatchRowNumber": 278,
                "afterPatchRowNumber": 269,
                "PatchRowcode": " #: Specifies the name of the Databricks secret scope to use for storing OpenAI API keys."
            },
            "13": {
                "beforePatchRowNumber": 279,
                "afterPatchRowNumber": 270,
                "PatchRowcode": " MLFLOW_OPENAI_SECRET_SCOPE = _EnvironmentVariable(\"MLFLOW_OPENAI_SECRET_SCOPE\", str, None)"
            },
            "14": {
                "beforePatchRowNumber": 280,
                "afterPatchRowNumber": 271,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "This module defines environment variables used in MLflow.",
            "\"\"\"",
            "import os",
            "from pathlib import Path",
            "",
            "",
            "class _EnvironmentVariable:",
            "    \"\"\"",
            "    Represents an environment variable.",
            "    \"\"\"",
            "",
            "    def __init__(self, name, type_, default):",
            "        self.name = name",
            "        self.type = type_",
            "        self.default = default",
            "",
            "    @property",
            "    def defined(self):",
            "        return self.name in os.environ",
            "",
            "    def get_raw(self):",
            "        return os.getenv(self.name)",
            "",
            "    def set(self, value):",
            "        os.environ[self.name] = str(value)",
            "",
            "    def unset(self):",
            "        os.environ.pop(self.name, None)",
            "",
            "    def get(self):",
            "        \"\"\"",
            "        Reads the value of the environment variable if it exists and converts it to the desired",
            "        type. Otherwise, returns the default value.",
            "        \"\"\"",
            "        if (val := self.get_raw()) is not None:",
            "            try:",
            "                return self.type(val)",
            "            except Exception as e:",
            "                raise ValueError(f\"Failed to convert {val!r} to {self.type} for {self.name}: {e}\")",
            "        return self.default",
            "",
            "    def __str__(self):",
            "        return f\"{self.name} (default: {self.default}, type: {self.type.__name__})\"",
            "",
            "    def __repr__(self):",
            "        return repr(self.name)",
            "",
            "    def __format__(self, format_spec: str) -> str:",
            "        return self.name.__format__(format_spec)",
            "",
            "",
            "class _BooleanEnvironmentVariable(_EnvironmentVariable):",
            "    \"\"\"",
            "    Represents a boolean environment variable.",
            "    \"\"\"",
            "",
            "    def __init__(self, name, default):",
            "        # `default not in [True, False, None]` doesn't work because `1 in [True]`",
            "        # (or `0 in [False]`) returns True.",
            "        if not (default is True or default is False or default is None):",
            "            raise ValueError(f\"{name} default value must be one of [True, False, None]\")",
            "        super().__init__(name, bool, default)",
            "",
            "    def get(self):",
            "        if not self.defined:",
            "            return self.default",
            "",
            "        val = os.getenv(self.name)",
            "        lowercased = val.lower()",
            "        if lowercased not in [\"true\", \"false\", \"1\", \"0\"]:",
            "            raise ValueError(",
            "                f\"{self.name} value must be one of ['true', 'false', '1', '0'] (case-insensitive), \"",
            "                f\"but got {val}\"",
            "            )",
            "        return lowercased in [\"true\", \"1\"]",
            "",
            "",
            "#: Specifies the tracking URI.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_URI = _EnvironmentVariable(\"MLFLOW_TRACKING_URI\", str, None)",
            "",
            "#: Specifies the registry URI.",
            "#: (default: ``None``)",
            "MLFLOW_REGISTRY_URI = _EnvironmentVariable(\"MLFLOW_REGISTRY_URI\", str, None)",
            "",
            "#: Specifies the ``dfs_tmpdir`` parameter to use for ``mlflow.spark.save_model``,",
            "#: ``mlflow.spark.log_model`` and ``mlflow.spark.load_model``. See",
            "#: https://www.mlflow.org/docs/latest/python_api/mlflow.spark.html#mlflow.spark.save_model",
            "#: for more information.",
            "#: (default: ``/tmp/mlflow``)",
            "MLFLOW_DFS_TMP = _EnvironmentVariable(\"MLFLOW_DFS_TMP\", str, \"/tmp/mlflow\")",
            "",
            "#: Specifies the maximum number of retries for MLflow HTTP requests",
            "#: (default: ``5``)",
            "MLFLOW_HTTP_REQUEST_MAX_RETRIES = _EnvironmentVariable(\"MLFLOW_HTTP_REQUEST_MAX_RETRIES\", int, 5)",
            "",
            "#: Specifies the backoff increase factor between MLflow HTTP request failures",
            "#: (default: ``2``)",
            "MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR = _EnvironmentVariable(",
            "    \"MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR\", int, 2",
            ")",
            "",
            "#: Specifies the backoff jitter between MLflow HTTP request failures",
            "#: (default: ``1.0``)",
            "MLFLOW_HTTP_REQUEST_BACKOFF_JITTER = _EnvironmentVariable(",
            "    \"MLFLOW_HTTP_REQUEST_BACKOFF_JITTER\", float, 1.0",
            ")",
            "",
            "#: Specifies the timeout in seconds for MLflow HTTP requests",
            "#: (default: ``120``)",
            "MLFLOW_HTTP_REQUEST_TIMEOUT = _EnvironmentVariable(\"MLFLOW_HTTP_REQUEST_TIMEOUT\", int, 120)",
            "",
            "#: Specifies whether MLflow HTTP requests should be signed using AWS signature V4. It will overwrite",
            "#: (default: ``False``). When set, it will overwrite the \"Authorization\" HTTP header.",
            "#: See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html for more information.",
            "MLFLOW_TRACKING_AWS_SIGV4 = _BooleanEnvironmentVariable(\"MLFLOW_TRACKING_AWS_SIGV4\", False)",
            "",
            "#: Specifies the auth provider to sign the MLflow HTTP request",
            "#: (default: ``None``). When set, it will overwrite the \"Authorization\" HTTP header.",
            "MLFLOW_TRACKING_AUTH = _EnvironmentVariable(\"MLFLOW_TRACKING_AUTH\", str, None)",
            "",
            "#: Specifies the chunk size to use when downloading a file from GCS",
            "#: (default: ``None``). If None, the chunk size is automatically determined by the",
            "#: ``google-cloud-storage`` package.",
            "MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE = _EnvironmentVariable(\"MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE\", int, None)",
            "",
            "#: Specifies the chunk size to use when uploading a file to GCS.",
            "#: (default: ``None``). If None, the chunk size is automatically determined by the",
            "#: ``google-cloud-storage`` package.",
            "MLFLOW_GCS_UPLOAD_CHUNK_SIZE = _EnvironmentVariable(\"MLFLOW_GCS_UPLOAD_CHUNK_SIZE\", int, None)",
            "",
            "#: (Deprecated, please use ``MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT``)",
            "#: Specifies the default timeout to use when downloading/uploading a file from/to GCS",
            "#: (default: ``None``). If None, ``google.cloud.storage.constants._DEFAULT_TIMEOUT`` is used.",
            "MLFLOW_GCS_DEFAULT_TIMEOUT = _EnvironmentVariable(\"MLFLOW_GCS_DEFAULT_TIMEOUT\", int, None)",
            "",
            "#: Specifies whether to disable model logging and loading via mlflowdbfs.",
            "#: (default: ``None``)",
            "_DISABLE_MLFLOWDBFS = _EnvironmentVariable(\"DISABLE_MLFLOWDBFS\", str, None)",
            "",
            "#: Specifies the S3 endpoint URL to use for S3 artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_S3_ENDPOINT_URL = _EnvironmentVariable(\"MLFLOW_S3_ENDPOINT_URL\", str, None)",
            "",
            "#: Specifies whether or not to skip TLS certificate verification for S3 artifact operations.",
            "#: (default: ``False``)",
            "MLFLOW_S3_IGNORE_TLS = _BooleanEnvironmentVariable(\"MLFLOW_S3_IGNORE_TLS\", False)",
            "",
            "#: Specifies extra arguments for S3 artifact uploads.",
            "#: (default: ``None``)",
            "MLFLOW_S3_UPLOAD_EXTRA_ARGS = _EnvironmentVariable(\"MLFLOW_S3_UPLOAD_EXTRA_ARGS\", str, None)",
            "",
            "#: Specifies the location of a Kerberos ticket cache to use for HDFS artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_KERBEROS_TICKET_CACHE = _EnvironmentVariable(\"MLFLOW_KERBEROS_TICKET_CACHE\", str, None)",
            "",
            "#: Specifies a Kerberos user for HDFS artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_KERBEROS_USER = _EnvironmentVariable(\"MLFLOW_KERBEROS_USER\", str, None)",
            "",
            "#: Specifies extra pyarrow configurations for HDFS artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_PYARROW_EXTRA_CONF = _EnvironmentVariable(\"MLFLOW_PYARROW_EXTRA_CONF\", str, None)",
            "",
            "#: Specifies the ``pool_size`` parameter to use for ``sqlalchemy.create_engine`` in the SQLAlchemy",
            "#: tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.pool_size",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_POOL_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_POOL_SIZE\", int, None",
            ")",
            "",
            "#: Specifies the ``pool_recycle`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.pool_recycle",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_POOL_RECYCLE = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_POOL_RECYCLE\", int, None",
            ")",
            "",
            "#: Specifies the ``max_overflow`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.max_overflow",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_MAX_OVERFLOW = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_MAX_OVERFLOW\", int, None",
            ")",
            "",
            "#: Specifies the ``echo`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.echo",
            "#: for more information.",
            "#: (default: ``False``)",
            "MLFLOW_SQLALCHEMYSTORE_ECHO = _BooleanEnvironmentVariable(\"MLFLOW_SQLALCHEMYSTORE_ECHO\", False)",
            "",
            "#: Specifies whether or not to print a warning when `--env-manager=conda` is specified.",
            "#: (default: ``False``)",
            "MLFLOW_DISABLE_ENV_MANAGER_CONDA_WARNING = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_DISABLE_ENV_MANAGER_CONDA_WARNING\", False",
            ")",
            "#: Specifies the ``poolclass`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.poolclass",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_POOLCLASS = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_POOLCLASS\", str, None",
            ")",
            "",
            "#: Specifies the ``timeout_seconds`` for MLflow Model dependency inference operations.",
            "#: (default: ``120``)",
            "MLFLOW_REQUIREMENTS_INFERENCE_TIMEOUT = _EnvironmentVariable(",
            "    \"MLFLOW_REQUIREMENTS_INFERENCE_TIMEOUT\", int, 120",
            ")",
            "",
            "#: Specifies the MLflow Model Scoring server request timeout in seconds",
            "#: (default: ``60``)",
            "MLFLOW_SCORING_SERVER_REQUEST_TIMEOUT = _EnvironmentVariable(",
            "    \"MLFLOW_SCORING_SERVER_REQUEST_TIMEOUT\", int, 60",
            ")",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the timeout to use when uploading or downloading a file",
            "#: (default: ``None``). If None, individual artifact stores will choose defaults.",
            "MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT = _EnvironmentVariable(",
            "    \"MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT\", int, None",
            ")",
            "",
            "#: Specifies the device intended for use in the predict function - can be used",
            "#: to override behavior where the GPU is used by default when available by",
            "#: setting this environment variable to be ``cpu``. Currently, this",
            "#: variable is only supported for the MLflow PyTorch and HuggingFace flavors.",
            "#: For the HuggingFace flavor, note that device must be parseable as an integer.",
            "MLFLOW_DEFAULT_PREDICTION_DEVICE = _EnvironmentVariable(",
            "    \"MLFLOW_DEFAULT_PREDICTION_DEVICE\", str, None",
            ")",
            "",
            "#: Specifies to Huggingface whether to use the automatic device placement logic of",
            "# HuggingFace accelerate. If it's set to false, the low_cpu_mem_usage flag will not be",
            "# set to True and device_map will not be set to \"auto\".",
            "MLFLOW_HUGGINGFACE_DISABLE_ACCELERATE_FEATURES = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_DISABLE_HUGGINGFACE_ACCELERATE_FEATURES\", False",
            ")",
            "",
            "#: Specifies to Huggingface whether to use the automatic device placement logic of",
            "# HuggingFace accelerate. If it's set to false, the low_cpu_mem_usage flag will not be",
            "# set to True and device_map will not be set to \"auto\".",
            "MLFLOW_HUGGINGFACE_USE_DEVICE_MAP = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_USE_DEVICE_MAP\", True",
            ")",
            "",
            "#: Specifies to Huggingface to use the automatic device placement logic of HuggingFace accelerate.",
            "#: This can be set to values supported by the version of HuggingFace Accelerate being installed.",
            "MLFLOW_HUGGINGFACE_DEVICE_MAP_STRATEGY = _EnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_DEVICE_MAP_STRATEGY\", str, \"auto\"",
            ")",
            "",
            "#: Specifies to Huggingface to use the low_cpu_mem_usage flag powered by HuggingFace accelerate.",
            "#: If it's set to false, the low_cpu_mem_usage flag will be set to False.",
            "MLFLOW_HUGGINGFACE_USE_LOW_CPU_MEM_USAGE = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_USE_LOW_CPU_MEM_USAGE\", True",
            ")",
            "",
            "#: Specifies the max_shard_size to use when mlflow transformers flavor saves the model checkpoint.",
            "#: This can be set to override the 500MB default.",
            "MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE\", str, \"500MB\"",
            ")",
            "",
            "#: Specifies whether or not to allow using a file URI as a model version source.",
            "#: Please be aware that setting this environment variable to True is potentially risky",
            "#: because it can allow access to arbitrary files on the specified filesystem",
            "#: (default: ``False``).",
            "MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE\", False",
            ")",
            "",
            "",
            "#: Specifies the name of the Databricks secret scope to use for storing OpenAI API keys.",
            "MLFLOW_OPENAI_SECRET_SCOPE = _EnvironmentVariable(\"MLFLOW_OPENAI_SECRET_SCOPE\", str, None)",
            "",
            "#: Specifier whether or not to retry OpenAI API calls.",
            "MLFLOW_OPENAI_RETRIES_ENABLED = _BooleanEnvironmentVariable(\"MLFLOW_OPENAI_RETRIES_ENABLED\", True)",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the download options to be used by pip wheel when `add_libraries_to_model` is used to",
            "#: create and log model dependencies as model artifacts. The default behavior only uses dependency",
            "#: binaries and no source packages.",
            "#: (default: ``--only-binary=:all:``).",
            "MLFLOW_WHEELED_MODEL_PIP_DOWNLOAD_OPTIONS = _EnvironmentVariable(",
            "    \"MLFLOW_WHEELED_MODEL_PIP_DOWNLOAD_OPTIONS\", str, \"--only-binary=:all:\"",
            ")",
            "",
            "# Specifies whether or not to use multipart download when downloading a large file on Databricks.",
            "MLFLOW_ENABLE_MULTIPART_DOWNLOAD = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_MULTIPART_DOWNLOAD\", True",
            ")",
            "",
            "# Specifies whether or not to use multipart upload when uploading large artifacts.",
            "MLFLOW_ENABLE_MULTIPART_UPLOAD = _BooleanEnvironmentVariable(\"MLFLOW_ENABLE_MULTIPART_UPLOAD\", True)",
            "",
            "#: Specifies whether or not to use multipart upload for proxied artifact access.",
            "#: (default: ``False``)",
            "MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", False",
            ")",
            "",
            "#: Private environment variable that's set to ``True`` while running tests.",
            "_MLFLOW_TESTING = _BooleanEnvironmentVariable(\"MLFLOW_TESTING\", False)",
            "",
            "#: Specifies the username used to authenticate with a tracking server.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_USERNAME = _EnvironmentVariable(\"MLFLOW_TRACKING_USERNAME\", str, None)",
            "",
            "#: Specifies the password used to authenticate with a tracking server.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_PASSWORD = _EnvironmentVariable(\"MLFLOW_TRACKING_PASSWORD\", str, None)",
            "",
            "#: Specifies and takes precedence for setting the basic/bearer auth on http requests.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_TOKEN = _EnvironmentVariable(\"MLFLOW_TRACKING_TOKEN\", str, None)",
            "",
            "#: Specifies whether to verify TLS connection in ``requests.request`` function,",
            "#: see https://requests.readthedocs.io/en/master/api/",
            "#: (default: ``False``).",
            "MLFLOW_TRACKING_INSECURE_TLS = _BooleanEnvironmentVariable(\"MLFLOW_TRACKING_INSECURE_TLS\", False)",
            "",
            "#: Sets the ``verify`` param in ``requests.request`` function,",
            "#: see https://requests.readthedocs.io/en/master/api/",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_SERVER_CERT_PATH = _EnvironmentVariable(",
            "    \"MLFLOW_TRACKING_SERVER_CERT_PATH\", str, None",
            ")",
            "",
            "#: Sets the ``cert`` param in ``requests.request`` function,",
            "#: see https://requests.readthedocs.io/en/master/api/",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_CLIENT_CERT_PATH = _EnvironmentVariable(",
            "    \"MLFLOW_TRACKING_CLIENT_CERT_PATH\", str, None",
            ")",
            "",
            "#: Specified the ID of the run to log data to.",
            "#: (default: ``None``)",
            "MLFLOW_RUN_ID = _EnvironmentVariable(\"MLFLOW_RUN_ID\", str, None)",
            "",
            "#: Specifies the default root directory for tracking `FileStore`.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_DIR = _EnvironmentVariable(\"MLFLOW_TRACKING_DIR\", str, None)",
            "",
            "#: Specifies the default root directory for registry `FileStore`.",
            "#: (default: ``None``)",
            "MLFLOW_REGISTRY_DIR = _EnvironmentVariable(\"MLFLOW_REGISTRY_DIR\", str, None)",
            "",
            "#: Specifies the default experiment ID to create run to.",
            "#: (default: ``None``)",
            "MLFLOW_EXPERIMENT_ID = _EnvironmentVariable(\"MLFLOW_EXPERIMENT_ID\", str, None)",
            "",
            "#: Specifies the default experiment name to create run to.",
            "#: (default: ``None``)",
            "MLFLOW_EXPERIMENT_NAME = _EnvironmentVariable(\"MLFLOW_EXPERIMENT_NAME\", str, None)",
            "",
            "#: Specified the path to the configuration file for MLflow Authentication.",
            "#: (default: ``None``)",
            "MLFLOW_AUTH_CONFIG_PATH = _EnvironmentVariable(\"MLFLOW_AUTH_CONFIG_PATH\", str, None)",
            "",
            "#: Specifies the root directory to create Python virtual environments in.",
            "#: (default: ``~/.mlflow/envs``)",
            "MLFLOW_ENV_ROOT = _EnvironmentVariable(",
            "    \"MLFLOW_ENV_ROOT\", str, str(Path.home().joinpath(\".mlflow\", \"envs\"))",
            ")",
            "",
            "#: Specifies whether or not to use DBFS FUSE mount to store artifacts on Databricks",
            "#: (default: ``False``)",
            "MLFLOW_ENABLE_DBFS_FUSE_ARTIFACT_REPO = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_DBFS_FUSE_ARTIFACT_REPO\", True",
            ")",
            "",
            "#: Private environment variable that should be set to ``True`` when running autologging tests.",
            "#: (default: ``False``)",
            "_MLFLOW_AUTOLOGGING_TESTING = _BooleanEnvironmentVariable(\"MLFLOW_AUTOLOGGING_TESTING\", False)",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the uri of a MLflow Gateway Server instance to be used with the Gateway Client APIs",
            "#: (default: ``None``)",
            "MLFLOW_GATEWAY_URI = _EnvironmentVariable(\"MLFLOW_GATEWAY_URI\", str, None)",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the uri of a MLflow Deployments Server instance to be used with the Deployments",
            "#: Client APIs",
            "#: (default: ``None``)",
            "MLFLOW_DEPLOYMENTS_TARGET = _EnvironmentVariable(\"MLFLOW_DEPLOYMENTS_TARGET\", str, None)",
            "",
            "#: Specifies the path of the config file for MLflow AI Gateway.",
            "#: (default: ``None``)",
            "MLFLOW_GATEWAY_CONFIG = _EnvironmentVariable(\"MLFLOW_GATEWAY_CONFIG\", str, None)",
            "",
            "#: Specifies the path of the config file for the MLflow Deployments server.",
            "#: (default: ``None``)",
            "MLFLOW_DEPLOYMENTS_CONFIG = _EnvironmentVariable(\"MLFLOW_DEPLOYMENTS_CONFIG\", str, None)",
            "",
            "#: Specifies whether to display the progress bar when uploading/downloading artifacts.",
            "#: (default: ``True``)",
            "MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR\", True",
            ")",
            "",
            "#: Specifies the conda home directory to use.",
            "#: (default: ``conda``)",
            "MLFLOW_CONDA_HOME = _EnvironmentVariable(\"MLFLOW_CONDA_HOME\", str, None)",
            "",
            "#: Specifies the name of the command to use when creating the environments.",
            "#: For example, let's say we want to use mamba (https://github.com/mamba-org/mamba)",
            "#: instead of conda to create environments.",
            "#: Then: > conda install mamba -n base -c conda-forge",
            "#: If not set, use the same as conda_path",
            "#: (default: ``conda``)",
            "MLFLOW_CONDA_CREATE_ENV_CMD = _EnvironmentVariable(\"MLFLOW_CONDA_CREATE_ENV_CMD\", str, \"conda\")",
            "",
            "#: Specifies the execution directory for recipes.",
            "#: (default: ``None``)",
            "MLFLOW_RECIPES_EXECUTION_DIRECTORY = _EnvironmentVariable(",
            "    \"MLFLOW_RECIPES_EXECUTION_DIRECTORY\", str, None",
            ")",
            "",
            "#: Specifies the target step to execute for recipes.",
            "#: (default: ``None``)",
            "MLFLOW_RECIPES_EXECUTION_TARGET_STEP_NAME = _EnvironmentVariable(",
            "    \"MLFLOW_RECIPES_EXECUTION_TARGET_STEP_NAME\", str, None",
            ")",
            "",
            "#: Specifies the flavor to serve in the scoring server.",
            "#: (default ``None``)",
            "MLFLOW_DEPLOYMENT_FLAVOR_NAME = _EnvironmentVariable(\"MLFLOW_DEPLOYMENT_FLAVOR_NAME\", str, None)",
            "",
            "#: Specifies the profile to use for recipes.",
            "#: (default: ``None``)",
            "MLFLOW_RECIPES_PROFILE = _EnvironmentVariable(\"MLFLOW_RECIPES_PROFILE\", str, None)",
            "",
            "#: Specifies the MLflow Run context",
            "#: (default: ``None``)",
            "MLFLOW_RUN_CONTEXT = _EnvironmentVariable(\"MLFLOW_RUN_CONTEXT\", str, None)",
            "",
            "#: Specifies the URL of the ECR-hosted Docker image a model is deployed into for SageMaker.",
            "# (default: ``None``)",
            "MLFLOW_SAGEMAKER_DEPLOY_IMG_URL = _EnvironmentVariable(\"MLFLOW_SAGEMAKER_DEPLOY_IMG_URL\", str, None)",
            "",
            "#: Specifies whether to disable creating a new conda environment for `mlflow models build-docker`.",
            "#: (default: ``False``)",
            "MLFLOW_DISABLE_ENV_CREATION = _BooleanEnvironmentVariable(\"MLFLOW_DISABLE_ENV_CREATION\", False)",
            "",
            "#: Specifies the timeout value for downloading chunks of mlflow artifacts.",
            "#: (default: ``300``)",
            "MLFLOW_DOWNLOAD_CHUNK_TIMEOUT = _EnvironmentVariable(\"MLFLOW_DOWNLOAD_CHUNK_TIMEOUT\", int, 300)",
            "",
            "#: Specifies if system metrics logging should be enabled.",
            "MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\", False",
            ")",
            "",
            "#: Specifies the sampling interval for system metrics logging.",
            "MLFLOW_SYSTEM_METRICS_SAMPLING_INTERVAL = _EnvironmentVariable(",
            "    \"MLFLOW_SYSTEM_METRICS_SAMPLING_INTERVAL\", float, None",
            ")",
            "",
            "#: Specifies the number of samples before logging system metrics.",
            "MLFLOW_SYSTEM_METRICS_SAMPLES_BEFORE_LOGGING = _EnvironmentVariable(",
            "    \"MLFLOW_SYSTEM_METRICS_SAMPLES_BEFORE_LOGGING\", int, None",
            ")",
            "",
            "# Private environment variable to specify the number of chunk download retries for multipart",
            "# download.",
            "_MLFLOW_MPD_NUM_RETRIES = _EnvironmentVariable(\"_MLFLOW_MPD_NUM_RETRIES\", int, 3)",
            "",
            "# Private environment variable to specify the interval between chunk download retries for multipart",
            "# download.",
            "_MLFLOW_MPD_RETRY_INTERVAL_SECONDS = _EnvironmentVariable(",
            "    \"_MLFLOW_MPD_RETRY_INTERVAL_SECONDS\", int, 1",
            ")",
            "",
            "#: Specifies the minimum file size in bytes to use multipart upload when logging artifacts",
            "#: (default: ``524_288_000`` (500 MB))",
            "MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE\", int, 500 * 1024**2",
            ")",
            "",
            "#: Specifies the chunk size in bytes to use when performing multipart upload",
            "#: (default: ``104_857_60`` (10 MB))",
            "MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE\", int, 10 * 1024**2",
            ")",
            "",
            "#: Specifies the chunk size in bytes to use when performing multipart download",
            "#: (default: ``104_857_600`` (100 MB))",
            "MLFLOW_MULTIPART_DOWNLOAD_CHUNK_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_MULTIPART_DOWNLOAD_CHUNK_SIZE\", int, 100 * 1024**2",
            ")",
            "",
            "#: Specifies whether or not to allow the MLflow server to follow redirects when",
            "#: making HTTP requests. If set to False, the server will throw an exception if it",
            "#: encounters a redirect response.",
            "#: (default: ``True``)",
            "MLFLOW_ALLOW_HTTP_REDIRECTS = _BooleanEnvironmentVariable(\"MLFLOW_ALLOW_HTTP_REDIRECTS\", True)"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "This module defines environment variables used in MLflow.",
            "\"\"\"",
            "import os",
            "from pathlib import Path",
            "",
            "",
            "class _EnvironmentVariable:",
            "    \"\"\"",
            "    Represents an environment variable.",
            "    \"\"\"",
            "",
            "    def __init__(self, name, type_, default):",
            "        self.name = name",
            "        self.type = type_",
            "        self.default = default",
            "",
            "    @property",
            "    def defined(self):",
            "        return self.name in os.environ",
            "",
            "    def get_raw(self):",
            "        return os.getenv(self.name)",
            "",
            "    def set(self, value):",
            "        os.environ[self.name] = str(value)",
            "",
            "    def unset(self):",
            "        os.environ.pop(self.name, None)",
            "",
            "    def get(self):",
            "        \"\"\"",
            "        Reads the value of the environment variable if it exists and converts it to the desired",
            "        type. Otherwise, returns the default value.",
            "        \"\"\"",
            "        if (val := self.get_raw()) is not None:",
            "            try:",
            "                return self.type(val)",
            "            except Exception as e:",
            "                raise ValueError(f\"Failed to convert {val!r} to {self.type} for {self.name}: {e}\")",
            "        return self.default",
            "",
            "    def __str__(self):",
            "        return f\"{self.name} (default: {self.default}, type: {self.type.__name__})\"",
            "",
            "    def __repr__(self):",
            "        return repr(self.name)",
            "",
            "    def __format__(self, format_spec: str) -> str:",
            "        return self.name.__format__(format_spec)",
            "",
            "",
            "class _BooleanEnvironmentVariable(_EnvironmentVariable):",
            "    \"\"\"",
            "    Represents a boolean environment variable.",
            "    \"\"\"",
            "",
            "    def __init__(self, name, default):",
            "        # `default not in [True, False, None]` doesn't work because `1 in [True]`",
            "        # (or `0 in [False]`) returns True.",
            "        if not (default is True or default is False or default is None):",
            "            raise ValueError(f\"{name} default value must be one of [True, False, None]\")",
            "        super().__init__(name, bool, default)",
            "",
            "    def get(self):",
            "        if not self.defined:",
            "            return self.default",
            "",
            "        val = os.getenv(self.name)",
            "        lowercased = val.lower()",
            "        if lowercased not in [\"true\", \"false\", \"1\", \"0\"]:",
            "            raise ValueError(",
            "                f\"{self.name} value must be one of ['true', 'false', '1', '0'] (case-insensitive), \"",
            "                f\"but got {val}\"",
            "            )",
            "        return lowercased in [\"true\", \"1\"]",
            "",
            "",
            "#: Specifies the tracking URI.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_URI = _EnvironmentVariable(\"MLFLOW_TRACKING_URI\", str, None)",
            "",
            "#: Specifies the registry URI.",
            "#: (default: ``None``)",
            "MLFLOW_REGISTRY_URI = _EnvironmentVariable(\"MLFLOW_REGISTRY_URI\", str, None)",
            "",
            "#: Specifies the ``dfs_tmpdir`` parameter to use for ``mlflow.spark.save_model``,",
            "#: ``mlflow.spark.log_model`` and ``mlflow.spark.load_model``. See",
            "#: https://www.mlflow.org/docs/latest/python_api/mlflow.spark.html#mlflow.spark.save_model",
            "#: for more information.",
            "#: (default: ``/tmp/mlflow``)",
            "MLFLOW_DFS_TMP = _EnvironmentVariable(\"MLFLOW_DFS_TMP\", str, \"/tmp/mlflow\")",
            "",
            "#: Specifies the maximum number of retries for MLflow HTTP requests",
            "#: (default: ``5``)",
            "MLFLOW_HTTP_REQUEST_MAX_RETRIES = _EnvironmentVariable(\"MLFLOW_HTTP_REQUEST_MAX_RETRIES\", int, 5)",
            "",
            "#: Specifies the backoff increase factor between MLflow HTTP request failures",
            "#: (default: ``2``)",
            "MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR = _EnvironmentVariable(",
            "    \"MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR\", int, 2",
            ")",
            "",
            "#: Specifies the backoff jitter between MLflow HTTP request failures",
            "#: (default: ``1.0``)",
            "MLFLOW_HTTP_REQUEST_BACKOFF_JITTER = _EnvironmentVariable(",
            "    \"MLFLOW_HTTP_REQUEST_BACKOFF_JITTER\", float, 1.0",
            ")",
            "",
            "#: Specifies the timeout in seconds for MLflow HTTP requests",
            "#: (default: ``120``)",
            "MLFLOW_HTTP_REQUEST_TIMEOUT = _EnvironmentVariable(\"MLFLOW_HTTP_REQUEST_TIMEOUT\", int, 120)",
            "",
            "#: Specifies whether MLflow HTTP requests should be signed using AWS signature V4. It will overwrite",
            "#: (default: ``False``). When set, it will overwrite the \"Authorization\" HTTP header.",
            "#: See https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html for more information.",
            "MLFLOW_TRACKING_AWS_SIGV4 = _BooleanEnvironmentVariable(\"MLFLOW_TRACKING_AWS_SIGV4\", False)",
            "",
            "#: Specifies the auth provider to sign the MLflow HTTP request",
            "#: (default: ``None``). When set, it will overwrite the \"Authorization\" HTTP header.",
            "MLFLOW_TRACKING_AUTH = _EnvironmentVariable(\"MLFLOW_TRACKING_AUTH\", str, None)",
            "",
            "#: Specifies the chunk size to use when downloading a file from GCS",
            "#: (default: ``None``). If None, the chunk size is automatically determined by the",
            "#: ``google-cloud-storage`` package.",
            "MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE = _EnvironmentVariable(\"MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE\", int, None)",
            "",
            "#: Specifies the chunk size to use when uploading a file to GCS.",
            "#: (default: ``None``). If None, the chunk size is automatically determined by the",
            "#: ``google-cloud-storage`` package.",
            "MLFLOW_GCS_UPLOAD_CHUNK_SIZE = _EnvironmentVariable(\"MLFLOW_GCS_UPLOAD_CHUNK_SIZE\", int, None)",
            "",
            "#: (Deprecated, please use ``MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT``)",
            "#: Specifies the default timeout to use when downloading/uploading a file from/to GCS",
            "#: (default: ``None``). If None, ``google.cloud.storage.constants._DEFAULT_TIMEOUT`` is used.",
            "MLFLOW_GCS_DEFAULT_TIMEOUT = _EnvironmentVariable(\"MLFLOW_GCS_DEFAULT_TIMEOUT\", int, None)",
            "",
            "#: Specifies whether to disable model logging and loading via mlflowdbfs.",
            "#: (default: ``None``)",
            "_DISABLE_MLFLOWDBFS = _EnvironmentVariable(\"DISABLE_MLFLOWDBFS\", str, None)",
            "",
            "#: Specifies the S3 endpoint URL to use for S3 artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_S3_ENDPOINT_URL = _EnvironmentVariable(\"MLFLOW_S3_ENDPOINT_URL\", str, None)",
            "",
            "#: Specifies whether or not to skip TLS certificate verification for S3 artifact operations.",
            "#: (default: ``False``)",
            "MLFLOW_S3_IGNORE_TLS = _BooleanEnvironmentVariable(\"MLFLOW_S3_IGNORE_TLS\", False)",
            "",
            "#: Specifies extra arguments for S3 artifact uploads.",
            "#: (default: ``None``)",
            "MLFLOW_S3_UPLOAD_EXTRA_ARGS = _EnvironmentVariable(\"MLFLOW_S3_UPLOAD_EXTRA_ARGS\", str, None)",
            "",
            "#: Specifies the location of a Kerberos ticket cache to use for HDFS artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_KERBEROS_TICKET_CACHE = _EnvironmentVariable(\"MLFLOW_KERBEROS_TICKET_CACHE\", str, None)",
            "",
            "#: Specifies a Kerberos user for HDFS artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_KERBEROS_USER = _EnvironmentVariable(\"MLFLOW_KERBEROS_USER\", str, None)",
            "",
            "#: Specifies extra pyarrow configurations for HDFS artifact operations.",
            "#: (default: ``None``)",
            "MLFLOW_PYARROW_EXTRA_CONF = _EnvironmentVariable(\"MLFLOW_PYARROW_EXTRA_CONF\", str, None)",
            "",
            "#: Specifies the ``pool_size`` parameter to use for ``sqlalchemy.create_engine`` in the SQLAlchemy",
            "#: tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.pool_size",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_POOL_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_POOL_SIZE\", int, None",
            ")",
            "",
            "#: Specifies the ``pool_recycle`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.pool_recycle",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_POOL_RECYCLE = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_POOL_RECYCLE\", int, None",
            ")",
            "",
            "#: Specifies the ``max_overflow`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.max_overflow",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_MAX_OVERFLOW = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_MAX_OVERFLOW\", int, None",
            ")",
            "",
            "#: Specifies the ``echo`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.echo",
            "#: for more information.",
            "#: (default: ``False``)",
            "MLFLOW_SQLALCHEMYSTORE_ECHO = _BooleanEnvironmentVariable(\"MLFLOW_SQLALCHEMYSTORE_ECHO\", False)",
            "",
            "#: Specifies whether or not to print a warning when `--env-manager=conda` is specified.",
            "#: (default: ``False``)",
            "MLFLOW_DISABLE_ENV_MANAGER_CONDA_WARNING = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_DISABLE_ENV_MANAGER_CONDA_WARNING\", False",
            ")",
            "#: Specifies the ``poolclass`` parameter to use for ``sqlalchemy.create_engine`` in the",
            "#: SQLAlchemy tracking store. See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine.params.poolclass",
            "#: for more information.",
            "#: (default: ``None``)",
            "MLFLOW_SQLALCHEMYSTORE_POOLCLASS = _EnvironmentVariable(",
            "    \"MLFLOW_SQLALCHEMYSTORE_POOLCLASS\", str, None",
            ")",
            "",
            "#: Specifies the ``timeout_seconds`` for MLflow Model dependency inference operations.",
            "#: (default: ``120``)",
            "MLFLOW_REQUIREMENTS_INFERENCE_TIMEOUT = _EnvironmentVariable(",
            "    \"MLFLOW_REQUIREMENTS_INFERENCE_TIMEOUT\", int, 120",
            ")",
            "",
            "#: Specifies the MLflow Model Scoring server request timeout in seconds",
            "#: (default: ``60``)",
            "MLFLOW_SCORING_SERVER_REQUEST_TIMEOUT = _EnvironmentVariable(",
            "    \"MLFLOW_SCORING_SERVER_REQUEST_TIMEOUT\", int, 60",
            ")",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the timeout to use when uploading or downloading a file",
            "#: (default: ``None``). If None, individual artifact stores will choose defaults.",
            "MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT = _EnvironmentVariable(",
            "    \"MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT\", int, None",
            ")",
            "",
            "#: Specifies the device intended for use in the predict function - can be used",
            "#: to override behavior where the GPU is used by default when available by",
            "#: setting this environment variable to be ``cpu``. Currently, this",
            "#: variable is only supported for the MLflow PyTorch and HuggingFace flavors.",
            "#: For the HuggingFace flavor, note that device must be parseable as an integer.",
            "MLFLOW_DEFAULT_PREDICTION_DEVICE = _EnvironmentVariable(",
            "    \"MLFLOW_DEFAULT_PREDICTION_DEVICE\", str, None",
            ")",
            "",
            "#: Specifies to Huggingface whether to use the automatic device placement logic of",
            "# HuggingFace accelerate. If it's set to false, the low_cpu_mem_usage flag will not be",
            "# set to True and device_map will not be set to \"auto\".",
            "MLFLOW_HUGGINGFACE_DISABLE_ACCELERATE_FEATURES = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_DISABLE_HUGGINGFACE_ACCELERATE_FEATURES\", False",
            ")",
            "",
            "#: Specifies to Huggingface whether to use the automatic device placement logic of",
            "# HuggingFace accelerate. If it's set to false, the low_cpu_mem_usage flag will not be",
            "# set to True and device_map will not be set to \"auto\".",
            "MLFLOW_HUGGINGFACE_USE_DEVICE_MAP = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_USE_DEVICE_MAP\", True",
            ")",
            "",
            "#: Specifies to Huggingface to use the automatic device placement logic of HuggingFace accelerate.",
            "#: This can be set to values supported by the version of HuggingFace Accelerate being installed.",
            "MLFLOW_HUGGINGFACE_DEVICE_MAP_STRATEGY = _EnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_DEVICE_MAP_STRATEGY\", str, \"auto\"",
            ")",
            "",
            "#: Specifies to Huggingface to use the low_cpu_mem_usage flag powered by HuggingFace accelerate.",
            "#: If it's set to false, the low_cpu_mem_usage flag will be set to False.",
            "MLFLOW_HUGGINGFACE_USE_LOW_CPU_MEM_USAGE = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_USE_LOW_CPU_MEM_USAGE\", True",
            ")",
            "",
            "#: Specifies the max_shard_size to use when mlflow transformers flavor saves the model checkpoint.",
            "#: This can be set to override the 500MB default.",
            "MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE\", str, \"500MB\"",
            ")",
            "",
            "#: Specifies the name of the Databricks secret scope to use for storing OpenAI API keys.",
            "MLFLOW_OPENAI_SECRET_SCOPE = _EnvironmentVariable(\"MLFLOW_OPENAI_SECRET_SCOPE\", str, None)",
            "",
            "#: Specifier whether or not to retry OpenAI API calls.",
            "MLFLOW_OPENAI_RETRIES_ENABLED = _BooleanEnvironmentVariable(\"MLFLOW_OPENAI_RETRIES_ENABLED\", True)",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the download options to be used by pip wheel when `add_libraries_to_model` is used to",
            "#: create and log model dependencies as model artifacts. The default behavior only uses dependency",
            "#: binaries and no source packages.",
            "#: (default: ``--only-binary=:all:``).",
            "MLFLOW_WHEELED_MODEL_PIP_DOWNLOAD_OPTIONS = _EnvironmentVariable(",
            "    \"MLFLOW_WHEELED_MODEL_PIP_DOWNLOAD_OPTIONS\", str, \"--only-binary=:all:\"",
            ")",
            "",
            "# Specifies whether or not to use multipart download when downloading a large file on Databricks.",
            "MLFLOW_ENABLE_MULTIPART_DOWNLOAD = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_MULTIPART_DOWNLOAD\", True",
            ")",
            "",
            "# Specifies whether or not to use multipart upload when uploading large artifacts.",
            "MLFLOW_ENABLE_MULTIPART_UPLOAD = _BooleanEnvironmentVariable(\"MLFLOW_ENABLE_MULTIPART_UPLOAD\", True)",
            "",
            "#: Specifies whether or not to use multipart upload for proxied artifact access.",
            "#: (default: ``False``)",
            "MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", False",
            ")",
            "",
            "#: Private environment variable that's set to ``True`` while running tests.",
            "_MLFLOW_TESTING = _BooleanEnvironmentVariable(\"MLFLOW_TESTING\", False)",
            "",
            "#: Specifies the username used to authenticate with a tracking server.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_USERNAME = _EnvironmentVariable(\"MLFLOW_TRACKING_USERNAME\", str, None)",
            "",
            "#: Specifies the password used to authenticate with a tracking server.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_PASSWORD = _EnvironmentVariable(\"MLFLOW_TRACKING_PASSWORD\", str, None)",
            "",
            "#: Specifies and takes precedence for setting the basic/bearer auth on http requests.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_TOKEN = _EnvironmentVariable(\"MLFLOW_TRACKING_TOKEN\", str, None)",
            "",
            "#: Specifies whether to verify TLS connection in ``requests.request`` function,",
            "#: see https://requests.readthedocs.io/en/master/api/",
            "#: (default: ``False``).",
            "MLFLOW_TRACKING_INSECURE_TLS = _BooleanEnvironmentVariable(\"MLFLOW_TRACKING_INSECURE_TLS\", False)",
            "",
            "#: Sets the ``verify`` param in ``requests.request`` function,",
            "#: see https://requests.readthedocs.io/en/master/api/",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_SERVER_CERT_PATH = _EnvironmentVariable(",
            "    \"MLFLOW_TRACKING_SERVER_CERT_PATH\", str, None",
            ")",
            "",
            "#: Sets the ``cert`` param in ``requests.request`` function,",
            "#: see https://requests.readthedocs.io/en/master/api/",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_CLIENT_CERT_PATH = _EnvironmentVariable(",
            "    \"MLFLOW_TRACKING_CLIENT_CERT_PATH\", str, None",
            ")",
            "",
            "#: Specified the ID of the run to log data to.",
            "#: (default: ``None``)",
            "MLFLOW_RUN_ID = _EnvironmentVariable(\"MLFLOW_RUN_ID\", str, None)",
            "",
            "#: Specifies the default root directory for tracking `FileStore`.",
            "#: (default: ``None``)",
            "MLFLOW_TRACKING_DIR = _EnvironmentVariable(\"MLFLOW_TRACKING_DIR\", str, None)",
            "",
            "#: Specifies the default root directory for registry `FileStore`.",
            "#: (default: ``None``)",
            "MLFLOW_REGISTRY_DIR = _EnvironmentVariable(\"MLFLOW_REGISTRY_DIR\", str, None)",
            "",
            "#: Specifies the default experiment ID to create run to.",
            "#: (default: ``None``)",
            "MLFLOW_EXPERIMENT_ID = _EnvironmentVariable(\"MLFLOW_EXPERIMENT_ID\", str, None)",
            "",
            "#: Specifies the default experiment name to create run to.",
            "#: (default: ``None``)",
            "MLFLOW_EXPERIMENT_NAME = _EnvironmentVariable(\"MLFLOW_EXPERIMENT_NAME\", str, None)",
            "",
            "#: Specified the path to the configuration file for MLflow Authentication.",
            "#: (default: ``None``)",
            "MLFLOW_AUTH_CONFIG_PATH = _EnvironmentVariable(\"MLFLOW_AUTH_CONFIG_PATH\", str, None)",
            "",
            "#: Specifies the root directory to create Python virtual environments in.",
            "#: (default: ``~/.mlflow/envs``)",
            "MLFLOW_ENV_ROOT = _EnvironmentVariable(",
            "    \"MLFLOW_ENV_ROOT\", str, str(Path.home().joinpath(\".mlflow\", \"envs\"))",
            ")",
            "",
            "#: Specifies whether or not to use DBFS FUSE mount to store artifacts on Databricks",
            "#: (default: ``False``)",
            "MLFLOW_ENABLE_DBFS_FUSE_ARTIFACT_REPO = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_DBFS_FUSE_ARTIFACT_REPO\", True",
            ")",
            "",
            "#: Private environment variable that should be set to ``True`` when running autologging tests.",
            "#: (default: ``False``)",
            "_MLFLOW_AUTOLOGGING_TESTING = _BooleanEnvironmentVariable(\"MLFLOW_AUTOLOGGING_TESTING\", False)",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the uri of a MLflow Gateway Server instance to be used with the Gateway Client APIs",
            "#: (default: ``None``)",
            "MLFLOW_GATEWAY_URI = _EnvironmentVariable(\"MLFLOW_GATEWAY_URI\", str, None)",
            "",
            "#: (Experimental, may be changed or removed)",
            "#: Specifies the uri of a MLflow Deployments Server instance to be used with the Deployments",
            "#: Client APIs",
            "#: (default: ``None``)",
            "MLFLOW_DEPLOYMENTS_TARGET = _EnvironmentVariable(\"MLFLOW_DEPLOYMENTS_TARGET\", str, None)",
            "",
            "#: Specifies the path of the config file for MLflow AI Gateway.",
            "#: (default: ``None``)",
            "MLFLOW_GATEWAY_CONFIG = _EnvironmentVariable(\"MLFLOW_GATEWAY_CONFIG\", str, None)",
            "",
            "#: Specifies the path of the config file for the MLflow Deployments server.",
            "#: (default: ``None``)",
            "MLFLOW_DEPLOYMENTS_CONFIG = _EnvironmentVariable(\"MLFLOW_DEPLOYMENTS_CONFIG\", str, None)",
            "",
            "#: Specifies whether to display the progress bar when uploading/downloading artifacts.",
            "#: (default: ``True``)",
            "MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR\", True",
            ")",
            "",
            "#: Specifies the conda home directory to use.",
            "#: (default: ``conda``)",
            "MLFLOW_CONDA_HOME = _EnvironmentVariable(\"MLFLOW_CONDA_HOME\", str, None)",
            "",
            "#: Specifies the name of the command to use when creating the environments.",
            "#: For example, let's say we want to use mamba (https://github.com/mamba-org/mamba)",
            "#: instead of conda to create environments.",
            "#: Then: > conda install mamba -n base -c conda-forge",
            "#: If not set, use the same as conda_path",
            "#: (default: ``conda``)",
            "MLFLOW_CONDA_CREATE_ENV_CMD = _EnvironmentVariable(\"MLFLOW_CONDA_CREATE_ENV_CMD\", str, \"conda\")",
            "",
            "#: Specifies the execution directory for recipes.",
            "#: (default: ``None``)",
            "MLFLOW_RECIPES_EXECUTION_DIRECTORY = _EnvironmentVariable(",
            "    \"MLFLOW_RECIPES_EXECUTION_DIRECTORY\", str, None",
            ")",
            "",
            "#: Specifies the target step to execute for recipes.",
            "#: (default: ``None``)",
            "MLFLOW_RECIPES_EXECUTION_TARGET_STEP_NAME = _EnvironmentVariable(",
            "    \"MLFLOW_RECIPES_EXECUTION_TARGET_STEP_NAME\", str, None",
            ")",
            "",
            "#: Specifies the flavor to serve in the scoring server.",
            "#: (default ``None``)",
            "MLFLOW_DEPLOYMENT_FLAVOR_NAME = _EnvironmentVariable(\"MLFLOW_DEPLOYMENT_FLAVOR_NAME\", str, None)",
            "",
            "#: Specifies the profile to use for recipes.",
            "#: (default: ``None``)",
            "MLFLOW_RECIPES_PROFILE = _EnvironmentVariable(\"MLFLOW_RECIPES_PROFILE\", str, None)",
            "",
            "#: Specifies the MLflow Run context",
            "#: (default: ``None``)",
            "MLFLOW_RUN_CONTEXT = _EnvironmentVariable(\"MLFLOW_RUN_CONTEXT\", str, None)",
            "",
            "#: Specifies the URL of the ECR-hosted Docker image a model is deployed into for SageMaker.",
            "# (default: ``None``)",
            "MLFLOW_SAGEMAKER_DEPLOY_IMG_URL = _EnvironmentVariable(\"MLFLOW_SAGEMAKER_DEPLOY_IMG_URL\", str, None)",
            "",
            "#: Specifies whether to disable creating a new conda environment for `mlflow models build-docker`.",
            "#: (default: ``False``)",
            "MLFLOW_DISABLE_ENV_CREATION = _BooleanEnvironmentVariable(\"MLFLOW_DISABLE_ENV_CREATION\", False)",
            "",
            "#: Specifies the timeout value for downloading chunks of mlflow artifacts.",
            "#: (default: ``300``)",
            "MLFLOW_DOWNLOAD_CHUNK_TIMEOUT = _EnvironmentVariable(\"MLFLOW_DOWNLOAD_CHUNK_TIMEOUT\", int, 300)",
            "",
            "#: Specifies if system metrics logging should be enabled.",
            "MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING = _BooleanEnvironmentVariable(",
            "    \"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\", False",
            ")",
            "",
            "#: Specifies the sampling interval for system metrics logging.",
            "MLFLOW_SYSTEM_METRICS_SAMPLING_INTERVAL = _EnvironmentVariable(",
            "    \"MLFLOW_SYSTEM_METRICS_SAMPLING_INTERVAL\", float, None",
            ")",
            "",
            "#: Specifies the number of samples before logging system metrics.",
            "MLFLOW_SYSTEM_METRICS_SAMPLES_BEFORE_LOGGING = _EnvironmentVariable(",
            "    \"MLFLOW_SYSTEM_METRICS_SAMPLES_BEFORE_LOGGING\", int, None",
            ")",
            "",
            "# Private environment variable to specify the number of chunk download retries for multipart",
            "# download.",
            "_MLFLOW_MPD_NUM_RETRIES = _EnvironmentVariable(\"_MLFLOW_MPD_NUM_RETRIES\", int, 3)",
            "",
            "# Private environment variable to specify the interval between chunk download retries for multipart",
            "# download.",
            "_MLFLOW_MPD_RETRY_INTERVAL_SECONDS = _EnvironmentVariable(",
            "    \"_MLFLOW_MPD_RETRY_INTERVAL_SECONDS\", int, 1",
            ")",
            "",
            "#: Specifies the minimum file size in bytes to use multipart upload when logging artifacts",
            "#: (default: ``524_288_000`` (500 MB))",
            "MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE\", int, 500 * 1024**2",
            ")",
            "",
            "#: Specifies the chunk size in bytes to use when performing multipart upload",
            "#: (default: ``104_857_60`` (10 MB))",
            "MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE\", int, 10 * 1024**2",
            ")",
            "",
            "#: Specifies the chunk size in bytes to use when performing multipart download",
            "#: (default: ``104_857_600`` (100 MB))",
            "MLFLOW_MULTIPART_DOWNLOAD_CHUNK_SIZE = _EnvironmentVariable(",
            "    \"MLFLOW_MULTIPART_DOWNLOAD_CHUNK_SIZE\", int, 100 * 1024**2",
            ")",
            "",
            "#: Specifies whether or not to allow the MLflow server to follow redirects when",
            "#: making HTTP requests. If set to False, the server will throw an exception if it",
            "#: encounters a redirect response.",
            "#: (default: ``True``)",
            "MLFLOW_ALLOW_HTTP_REDIRECTS = _BooleanEnvironmentVariable(\"MLFLOW_ALLOW_HTTP_REDIRECTS\", True)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "269": [],
            "270": [],
            "271": [],
            "272": [],
            "273": [
                "MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE"
            ],
            "274": [],
            "275": [],
            "276": [],
            "277": []
        },
        "addLocation": []
    },
    "mlflow/server/handlers.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " from mlflow.entities import DatasetInput, ExperimentTag, FileInfo, Metric, Param, RunTag, ViewType"
            },
            "1": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from mlflow.entities.model_registry import ModelVersionTag, RegisteredModelTag"
            },
            "2": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from mlflow.entities.multipart_upload import MultipartUploadPart"
            },
            "3": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from mlflow.environment_variables import ("
            },
            "4": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE,"
            },
            "5": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    MLFLOW_DEPLOYMENTS_TARGET,"
            },
            "6": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-)"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+from mlflow.environment_variables import MLFLOW_DEPLOYMENTS_TARGET"
            },
            "8": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from mlflow.exceptions import MlflowException, _UnsupportedMultipartUploadException"
            },
            "9": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from mlflow.models import Model"
            },
            "10": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from mlflow.protos import databricks_pb2"
            },
            "11": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 102,
                "PatchRowcode": " from mlflow.utils.promptlab_utils import _create_promptlab_run_impl"
            },
            "12": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 103,
                "PatchRowcode": " from mlflow.utils.proto_json_utils import message_to_json, parse_dict"
            },
            "13": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": 104,
                "PatchRowcode": " from mlflow.utils.string_utils import is_string_type"
            },
            "14": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from mlflow.utils.uri import is_file_uri, is_local_uri, validate_path_is_safe, validate_query_string"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+from mlflow.utils.uri import is_local_uri, validate_path_is_safe, validate_query_string"
            },
            "16": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 106,
                "PatchRowcode": " from mlflow.utils.validation import _validate_batch_log_api_req"
            },
            "17": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 107,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": 108,
                "PatchRowcode": " _logger = logging.getLogger(__name__)"
            },
            "19": {
                "beforePatchRowNumber": 1604,
                "afterPatchRowNumber": 1601,
                "PatchRowcode": "             INVALID_PARAMETER_VALUE,"
            },
            "20": {
                "beforePatchRowNumber": 1605,
                "afterPatchRowNumber": 1602,
                "PatchRowcode": "         )"
            },
            "21": {
                "beforePatchRowNumber": 1606,
                "afterPatchRowNumber": 1603,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 1607,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # There might be file URIs that are local but can bypass the above check. To prevent this, we"
            },
            "23": {
                "beforePatchRowNumber": 1608,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # disallow using file URIs as model version sources by default unless it's explicitly allowed"
            },
            "24": {
                "beforePatchRowNumber": 1609,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # by setting the MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE environment variable to True."
            },
            "25": {
                "beforePatchRowNumber": 1610,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if not MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE.get() and is_file_uri(source):"
            },
            "26": {
                "beforePatchRowNumber": 1611,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        raise MlflowException("
            },
            "27": {
                "beforePatchRowNumber": 1612,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            f\"Invalid model version source: '{source}'. MLflow tracking server doesn't allow using \""
            },
            "28": {
                "beforePatchRowNumber": 1613,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"a file URI as a model version source for security reasons. To disable this check, set \""
            },
            "29": {
                "beforePatchRowNumber": 1614,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            f\"the {MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE} environment variable to \""
            },
            "30": {
                "beforePatchRowNumber": 1615,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"True.\","
            },
            "31": {
                "beforePatchRowNumber": 1616,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            INVALID_PARAMETER_VALUE,"
            },
            "32": {
                "beforePatchRowNumber": 1617,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        )"
            },
            "33": {
                "beforePatchRowNumber": 1618,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "34": {
                "beforePatchRowNumber": 1619,
                "afterPatchRowNumber": 1604,
                "PatchRowcode": "     # Checks if relative paths are present in the source (a security threat). If any are present,"
            },
            "35": {
                "beforePatchRowNumber": 1620,
                "afterPatchRowNumber": 1605,
                "PatchRowcode": "     # raises an Exception."
            },
            "36": {
                "beforePatchRowNumber": 1621,
                "afterPatchRowNumber": 1606,
                "PatchRowcode": "     _validate_non_local_source_contains_relative_paths(source)"
            }
        },
        "frontPatchFile": [
            "# Define all the service endpoint handlers here.",
            "import json",
            "import logging",
            "import os",
            "import pathlib",
            "import posixpath",
            "import re",
            "import tempfile",
            "import time",
            "import urllib",
            "from functools import wraps",
            "",
            "import requests",
            "from flask import Response, current_app, request, send_file",
            "from google.protobuf import descriptor",
            "from google.protobuf.json_format import ParseError",
            "",
            "from mlflow.entities import DatasetInput, ExperimentTag, FileInfo, Metric, Param, RunTag, ViewType",
            "from mlflow.entities.model_registry import ModelVersionTag, RegisteredModelTag",
            "from mlflow.entities.multipart_upload import MultipartUploadPart",
            "from mlflow.environment_variables import (",
            "    MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE,",
            "    MLFLOW_DEPLOYMENTS_TARGET,",
            ")",
            "from mlflow.exceptions import MlflowException, _UnsupportedMultipartUploadException",
            "from mlflow.models import Model",
            "from mlflow.protos import databricks_pb2",
            "from mlflow.protos.databricks_pb2 import (",
            "    INVALID_PARAMETER_VALUE,",
            "    RESOURCE_DOES_NOT_EXIST,",
            ")",
            "from mlflow.protos.mlflow_artifacts_pb2 import (",
            "    AbortMultipartUpload,",
            "    CompleteMultipartUpload,",
            "    CreateMultipartUpload,",
            "    DeleteArtifact,",
            "    DownloadArtifact,",
            "    MlflowArtifactsService,",
            "    UploadArtifact,",
            ")",
            "from mlflow.protos.mlflow_artifacts_pb2 import (",
            "    ListArtifacts as ListArtifactsMlflowArtifacts,",
            ")",
            "from mlflow.protos.model_registry_pb2 import (",
            "    CreateModelVersion,",
            "    CreateRegisteredModel,",
            "    DeleteModelVersion,",
            "    DeleteModelVersionTag,",
            "    DeleteRegisteredModel,",
            "    DeleteRegisteredModelAlias,",
            "    DeleteRegisteredModelTag,",
            "    GetLatestVersions,",
            "    GetModelVersion,",
            "    GetModelVersionByAlias,",
            "    GetModelVersionDownloadUri,",
            "    GetRegisteredModel,",
            "    ModelRegistryService,",
            "    RenameRegisteredModel,",
            "    SearchModelVersions,",
            "    SearchRegisteredModels,",
            "    SetModelVersionTag,",
            "    SetRegisteredModelAlias,",
            "    SetRegisteredModelTag,",
            "    TransitionModelVersionStage,",
            "    UpdateModelVersion,",
            "    UpdateRegisteredModel,",
            ")",
            "from mlflow.protos.service_pb2 import (",
            "    CreateExperiment,",
            "    CreateRun,",
            "    DeleteExperiment,",
            "    DeleteRun,",
            "    DeleteTag,",
            "    GetExperiment,",
            "    GetExperimentByName,",
            "    GetMetricHistory,",
            "    GetRun,",
            "    ListArtifacts,",
            "    LogBatch,",
            "    LogInputs,",
            "    LogMetric,",
            "    LogModel,",
            "    LogParam,",
            "    MlflowService,",
            "    RestoreExperiment,",
            "    RestoreRun,",
            "    SearchExperiments,",
            "    SearchRuns,",
            "    SetExperimentTag,",
            "    SetTag,",
            "    UpdateExperiment,",
            "    UpdateRun,",
            ")",
            "from mlflow.server.validation import _validate_content_type",
            "from mlflow.store.artifact.artifact_repo import MultipartUploadMixin",
            "from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository",
            "from mlflow.store.db.db_types import DATABASE_ENGINES",
            "from mlflow.tracking._model_registry import utils as registry_utils",
            "from mlflow.tracking._model_registry.registry import ModelRegistryStoreRegistry",
            "from mlflow.tracking._tracking_service import utils",
            "from mlflow.tracking._tracking_service.registry import TrackingStoreRegistry",
            "from mlflow.tracking.registry import UnsupportedModelRegistryStoreURIException",
            "from mlflow.utils.file_utils import local_file_uri_to_path",
            "from mlflow.utils.mime_type_utils import _guess_mime_type",
            "from mlflow.utils.promptlab_utils import _create_promptlab_run_impl",
            "from mlflow.utils.proto_json_utils import message_to_json, parse_dict",
            "from mlflow.utils.string_utils import is_string_type",
            "from mlflow.utils.uri import is_file_uri, is_local_uri, validate_path_is_safe, validate_query_string",
            "from mlflow.utils.validation import _validate_batch_log_api_req",
            "",
            "_logger = logging.getLogger(__name__)",
            "_tracking_store = None",
            "_model_registry_store = None",
            "_artifact_repo = None",
            "STATIC_PREFIX_ENV_VAR = \"_MLFLOW_STATIC_PREFIX\"",
            "",
            "",
            "class TrackingStoreRegistryWrapper(TrackingStoreRegistry):",
            "    def __init__(self):",
            "        super().__init__()",
            "        self.register(\"\", self._get_file_store)",
            "        self.register(\"file\", self._get_file_store)",
            "        for scheme in DATABASE_ENGINES:",
            "            self.register(scheme, self._get_sqlalchemy_store)",
            "        self.register_entrypoints()",
            "",
            "    @classmethod",
            "    def _get_file_store(cls, store_uri, artifact_uri):",
            "        from mlflow.store.tracking.file_store import FileStore",
            "",
            "        return FileStore(store_uri, artifact_uri)",
            "",
            "    @classmethod",
            "    def _get_sqlalchemy_store(cls, store_uri, artifact_uri):",
            "        from mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore",
            "",
            "        return SqlAlchemyStore(store_uri, artifact_uri)",
            "",
            "",
            "class ModelRegistryStoreRegistryWrapper(ModelRegistryStoreRegistry):",
            "    def __init__(self):",
            "        super().__init__()",
            "        self.register(\"\", self._get_file_store)",
            "        self.register(\"file\", self._get_file_store)",
            "        for scheme in DATABASE_ENGINES:",
            "            self.register(scheme, self._get_sqlalchemy_store)",
            "        self.register_entrypoints()",
            "",
            "    @classmethod",
            "    def _get_file_store(cls, store_uri):",
            "        from mlflow.store.model_registry.file_store import FileStore",
            "",
            "        return FileStore(store_uri)",
            "",
            "    @classmethod",
            "    def _get_sqlalchemy_store(cls, store_uri):",
            "        from mlflow.store.model_registry.sqlalchemy_store import SqlAlchemyStore",
            "",
            "        return SqlAlchemyStore(store_uri)",
            "",
            "",
            "_tracking_store_registry = TrackingStoreRegistryWrapper()",
            "_model_registry_store_registry = ModelRegistryStoreRegistryWrapper()",
            "",
            "",
            "def _get_artifact_repo_mlflow_artifacts():",
            "    \"\"\"",
            "    Get an artifact repository specified by ``--artifacts-destination`` option for ``mlflow server``",
            "    command.",
            "    \"\"\"",
            "    from mlflow.server import ARTIFACTS_DESTINATION_ENV_VAR",
            "",
            "    global _artifact_repo",
            "    if _artifact_repo is None:",
            "        _artifact_repo = get_artifact_repository(os.environ[ARTIFACTS_DESTINATION_ENV_VAR])",
            "    return _artifact_repo",
            "",
            "",
            "def _is_serving_proxied_artifacts():",
            "    \"\"\"",
            "    :return: ``True`` if the MLflow server is serving proxied artifacts (i.e. acting as a proxy for",
            "             artifact upload / download / list operations), as would be enabled by specifying the",
            "             ``--serve-artifacts`` configuration option. ``False`` otherwise.",
            "    \"\"\"",
            "    from mlflow.server import SERVE_ARTIFACTS_ENV_VAR",
            "",
            "    return os.environ.get(SERVE_ARTIFACTS_ENV_VAR, \"false\") == \"true\"",
            "",
            "",
            "def _is_servable_proxied_run_artifact_root(run_artifact_root):",
            "    \"\"\"",
            "    Determines whether or not the following are true:",
            "",
            "    - The specified Run artifact root is a proxied artifact root (i.e. an artifact root with scheme",
            "      ``http``, ``https``, or ``mlflow-artifacts``).",
            "",
            "    - The MLflow server is capable of resolving and accessing the underlying storage location",
            "      corresponding to the proxied artifact root, allowing it to fulfill artifact list and",
            "      download requests by using this storage location directly.",
            "",
            "    :param run_artifact_root: The Run artifact root location (URI).",
            "    :return: ``True`` if the specified Run artifact root refers to proxied artifacts that can be",
            "             served by this MLflow server (i.e. the server has access to the destination and",
            "             can respond to list and download requests for the artifact). ``False`` otherwise.",
            "    \"\"\"",
            "    parsed_run_artifact_root = urllib.parse.urlparse(run_artifact_root)",
            "    # NB: If the run artifact root is a proxied artifact root (has scheme `http`, `https`, or",
            "    # `mlflow-artifacts`) *and* the MLflow server is configured to serve artifacts, the MLflow",
            "    # server always assumes that it has access to the underlying storage location for the proxied",
            "    # artifacts. This may not always be accurate. For example:",
            "    #",
            "    # An organization may initially use the MLflow server to serve Tracking API requests and proxy",
            "    # access to artifacts stored in Location A (via `mlflow server --serve-artifacts`). Then, for",
            "    # scalability and / or security purposes, the organization may decide to store artifacts in a",
            "    # new location B and set up a separate server (e.g. `mlflow server --artifacts-only`) to proxy",
            "    # access to artifacts stored in Location B.",
            "    #",
            "    # In this scenario, requests for artifacts stored in Location B that are sent to the original",
            "    # MLflow server will fail if the original MLflow server does not have access to Location B",
            "    # because it will assume that it can serve all proxied artifacts regardless of the underlying",
            "    # location. Such failures can be remediated by granting the original MLflow server access to",
            "    # Location B.",
            "    return (",
            "        parsed_run_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]",
            "        and _is_serving_proxied_artifacts()",
            "    )",
            "",
            "",
            "def _get_proxied_run_artifact_destination_path(proxied_artifact_root, relative_path=None):",
            "    \"\"\"",
            "    Resolves the specified proxied artifact location within a Run to a concrete storage location.",
            "",
            "    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,",
            "                                  ``https``, or `mlflow-artifacts` that can be resolved by the",
            "                                  MLflow server to a concrete storage location.",
            "    :param relative_path: The relative path of the destination within the specified",
            "                          ``proxied_artifact_root``. If ``None``, the destination is assumed to be",
            "                          the resolved ``proxied_artifact_root``.",
            "    :return: The storage location of the specified artifact.",
            "    \"\"\"",
            "    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)",
            "    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]",
            "",
            "    if parsed_proxied_artifact_root.scheme == \"mlflow-artifacts\":",
            "        # If the proxied artifact root is an `mlflow-artifacts` URI, the run artifact root path is",
            "        # simply the path component of the URI, since the fully-qualified format of an",
            "        # `mlflow-artifacts` URI is `mlflow-artifacts://<netloc>/path/to/artifact`",
            "        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.lstrip(\"/\")",
            "    else:",
            "        # In this case, the proxied artifact root is an HTTP(S) URL referring to an mlflow-artifacts",
            "        # API route that can be used to download the artifact. These routes are always anchored at",
            "        # `/api/2.0/mlflow-artifacts/artifacts`. Accordingly, we split the path on this route anchor",
            "        # and interpret the rest of the path (everything after the route anchor) as the run artifact",
            "        # root path",
            "        mlflow_artifacts_http_route_anchor = \"/api/2.0/mlflow-artifacts/artifacts/\"",
            "        assert mlflow_artifacts_http_route_anchor in parsed_proxied_artifact_root.path",
            "",
            "        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.split(",
            "            mlflow_artifacts_http_route_anchor",
            "        )[1].lstrip(\"/\")",
            "",
            "    return (",
            "        posixpath.join(proxied_run_artifact_root_path, relative_path)",
            "        if relative_path is not None",
            "        else proxied_run_artifact_root_path",
            "    )",
            "",
            "",
            "def _get_tracking_store(backend_store_uri=None, default_artifact_root=None):",
            "    from mlflow.server import ARTIFACT_ROOT_ENV_VAR, BACKEND_STORE_URI_ENV_VAR",
            "",
            "    global _tracking_store",
            "    if _tracking_store is None:",
            "        store_uri = backend_store_uri or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)",
            "        artifact_root = default_artifact_root or os.environ.get(ARTIFACT_ROOT_ENV_VAR, None)",
            "        _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)",
            "        utils.set_tracking_uri(store_uri)",
            "    return _tracking_store",
            "",
            "",
            "def _get_model_registry_store(registry_store_uri=None):",
            "    from mlflow.server import BACKEND_STORE_URI_ENV_VAR, REGISTRY_STORE_URI_ENV_VAR",
            "",
            "    global _model_registry_store",
            "    if _model_registry_store is None:",
            "        store_uri = (",
            "            registry_store_uri",
            "            or os.environ.get(REGISTRY_STORE_URI_ENV_VAR, None)",
            "            or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)",
            "        )",
            "        _model_registry_store = _model_registry_store_registry.get_store(store_uri)",
            "        registry_utils.set_registry_uri(store_uri)",
            "    return _model_registry_store",
            "",
            "",
            "def initialize_backend_stores(",
            "    backend_store_uri=None, registry_store_uri=None, default_artifact_root=None",
            "):",
            "    _get_tracking_store(backend_store_uri, default_artifact_root)",
            "    try:",
            "        _get_model_registry_store(registry_store_uri)",
            "    except UnsupportedModelRegistryStoreURIException:",
            "        pass",
            "",
            "",
            "def _assert_string(x):",
            "    assert isinstance(x, str)",
            "",
            "",
            "def _assert_intlike(x):",
            "    try:",
            "        x = int(x)",
            "    except ValueError:",
            "        pass",
            "",
            "    assert isinstance(x, int)",
            "",
            "",
            "def _assert_bool(x):",
            "    assert isinstance(x, bool)",
            "",
            "",
            "def _assert_floatlike(x):",
            "    try:",
            "        x = float(x)",
            "    except ValueError:",
            "        pass",
            "",
            "    assert isinstance(x, float)",
            "",
            "",
            "def _assert_array(x):",
            "    assert isinstance(x, list)",
            "",
            "",
            "def _assert_required(x):",
            "    assert x is not None",
            "    # When parsing JSON payloads via proto, absent string fields",
            "    # are expressed as empty strings",
            "    assert x != \"\"",
            "",
            "",
            "def _assert_less_than_or_equal(x, max_value):",
            "    assert x <= max_value",
            "",
            "",
            "def _assert_item_type_string(x):",
            "    assert all(isinstance(item, str) for item in x)",
            "",
            "",
            "_TYPE_VALIDATORS = {",
            "    _assert_intlike,",
            "    _assert_string,",
            "    _assert_bool,",
            "    _assert_floatlike,",
            "    _assert_array,",
            "    _assert_item_type_string,",
            "}",
            "",
            "",
            "def _validate_param_against_schema(schema, param, value, proto_parsing_succeeded=False):",
            "    \"\"\"",
            "    Attempts to validate a single parameter against a specified schema.",
            "    Examples of the elements of the schema are type assertions and checks for required parameters.",
            "    Returns None on validation success. Otherwise, raises an MLFlowException if an assertion fails.",
            "    This method is intended to be called for side effects.",
            "",
            "            Parameters:",
            "    :param schema: A list of functions to validate the parameter against.",
            "    :param param: The string name of the parameter being validated.",
            "    :param value: The corresponding value of the `param` being validated.",
            "    :param proto_parsing_succeeded: A boolean value indicating whether proto parsing succeeded.",
            "                                    If the proto was successfully parsed, we assume all of the types",
            "                                    of the parameters in the request body were correctly specified,",
            "                                    and thus we skip validating types. If proto parsing failed,",
            "                                    then we validate types in addition to the rest of the schema.",
            "                                    For details, see https://github.com/mlflow/mlflow/pull/",
            "                                    5458#issuecomment-1080880870.",
            "    \"\"\"",
            "",
            "    for f in schema:",
            "        if f in _TYPE_VALIDATORS and proto_parsing_succeeded:",
            "            continue",
            "",
            "        try:",
            "            f(value)",
            "        except AssertionError:",
            "            if f == _assert_required:",
            "                message = f\"Missing value for required parameter '{param}'.\"",
            "            else:",
            "                message = (",
            "                    f\"Invalid value {value} for parameter '{param}' supplied.\"",
            "                    f\" Hint: Value was of type '{type(value).__name__}'.\"",
            "                )",
            "            raise MlflowException(",
            "                message=(",
            "                    message + \" See the API docs for more information about request parameters.\"",
            "                ),",
            "                error_code=INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "    return None",
            "",
            "",
            "def _get_request_json(flask_request=request):",
            "    _validate_content_type(flask_request, [\"application/json\"])",
            "    return flask_request.get_json(force=True, silent=True)",
            "",
            "",
            "def _get_request_message(request_message, flask_request=request, schema=None):",
            "    from querystring_parser import parser",
            "",
            "    if flask_request.method == \"GET\" and len(flask_request.query_string) > 0:",
            "        # This is a hack to make arrays of length 1 work with the parser.",
            "        # for example experiment_ids%5B%5D=0 should be parsed to {experiment_ids: [0]}",
            "        # but it gets parsed to {experiment_ids: 0}",
            "        # but it doesn't. However, experiment_ids%5B0%5D=0 will get parsed to the right",
            "        # result.",
            "        query_string = re.sub(\"%5B%5D\", \"%5B0%5D\", flask_request.query_string.decode(\"utf-8\"))",
            "        request_dict = parser.parse(query_string, normalized=True)",
            "        # Convert atomic values of repeated fields to lists before calling protobuf deserialization.",
            "        # Context: We parse the parameter string into a dictionary outside of protobuf since",
            "        # protobuf does not know how to read the query parameters directly. The query parser above",
            "        # has no type information and hence any parameter that occurs exactly once is parsed as an",
            "        # atomic value. Since protobuf requires that the values of repeated fields are lists,",
            "        # deserialization will fail unless we do the fix below.",
            "        for field in request_message.DESCRIPTOR.fields:",
            "            if (",
            "                field.label == descriptor.FieldDescriptor.LABEL_REPEATED",
            "                and field.name in request_dict",
            "            ):",
            "                if not isinstance(request_dict[field.name], list):",
            "                    request_dict[field.name] = [request_dict[field.name]]",
            "        parse_dict(request_dict, request_message)",
            "        return request_message",
            "",
            "    request_json = _get_request_json(flask_request)",
            "",
            "    # Older clients may post their JSON double-encoded as strings, so the get_json",
            "    # above actually converts it to a string. Therefore, we check this condition",
            "    # (which we can tell for sure because any proper request should be a dictionary),",
            "    # and decode it a second time.",
            "    if is_string_type(request_json):",
            "        request_json = json.loads(request_json)",
            "",
            "    # If request doesn't have json body then assume it's empty.",
            "    if request_json is None:",
            "        request_json = {}",
            "",
            "    proto_parsing_succeeded = True",
            "    try:",
            "        parse_dict(request_json, request_message)",
            "    except ParseError:",
            "        proto_parsing_succeeded = False",
            "",
            "    schema = schema or {}",
            "    for schema_key, schema_validation_fns in schema.items():",
            "        if schema_key in request_json or _assert_required in schema_validation_fns:",
            "            value = request_json.get(schema_key)",
            "            if schema_key == \"run_id\" and value is None and \"run_uuid\" in request_json:",
            "                value = request_json.get(\"run_uuid\")",
            "            _validate_param_against_schema(",
            "                schema=schema_validation_fns,",
            "                param=schema_key,",
            "                value=value,",
            "                proto_parsing_succeeded=proto_parsing_succeeded,",
            "            )",
            "",
            "    return request_message",
            "",
            "",
            "def _response_with_file_attachment_headers(file_path, response):",
            "    mime_type = _guess_mime_type(file_path)",
            "    filename = pathlib.Path(file_path).name",
            "    response.mimetype = mime_type",
            "    content_disposition_header_name = \"Content-Disposition\"",
            "    if content_disposition_header_name not in response.headers:",
            "        response.headers[content_disposition_header_name] = f\"attachment; filename={filename}\"",
            "    response.headers[\"X-Content-Type-Options\"] = \"nosniff\"",
            "    response.headers[\"Content-Type\"] = mime_type",
            "    return response",
            "",
            "",
            "def _send_artifact(artifact_repository, path):",
            "    file_path = os.path.abspath(artifact_repository.download_artifacts(path))",
            "    # Always send artifacts as attachments to prevent the browser from displaying them on our web",
            "    # server's domain, which might enable XSS.",
            "    mime_type = _guess_mime_type(file_path)",
            "    file_sender_response = send_file(file_path, mimetype=mime_type, as_attachment=True)",
            "    return _response_with_file_attachment_headers(file_path, file_sender_response)",
            "",
            "",
            "def catch_mlflow_exception(func):",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        try:",
            "            return func(*args, **kwargs)",
            "        except MlflowException as e:",
            "            response = Response(mimetype=\"application/json\")",
            "            response.set_data(e.serialize_as_json())",
            "            response.status_code = e.get_http_status_code()",
            "            return response",
            "",
            "    return wrapper",
            "",
            "",
            "def _disable_unless_serve_artifacts(func):",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        if not _is_serving_proxied_artifacts():",
            "            return Response(",
            "                (",
            "                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"",
            "                    \"with `--no-serve-artifacts`. To enable artifacts server functionality, \"",
            "                    \"run `mlflow server` with `--serve-artifacts`\"",
            "                ),",
            "                503,",
            "            )",
            "        return func(*args, **kwargs)",
            "",
            "    return wrapper",
            "",
            "",
            "def _disable_if_artifacts_only(func):",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        from mlflow.server import ARTIFACTS_ONLY_ENV_VAR",
            "",
            "        if os.environ.get(ARTIFACTS_ONLY_ENV_VAR):",
            "            return Response(",
            "                (",
            "                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"",
            "                    \"in `--artifacts-only` mode. To enable tracking server functionality, run \"",
            "                    \"`mlflow server` without `--artifacts-only`\"",
            "                ),",
            "                503,",
            "            )",
            "        return func(*args, **kwargs)",
            "",
            "    return wrapper",
            "",
            "",
            "@catch_mlflow_exception",
            "def get_artifact_handler():",
            "    from querystring_parser import parser",
            "",
            "    query_string = request.query_string.decode(\"utf-8\")",
            "    request_dict = parser.parse(query_string, normalized=True)",
            "    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")",
            "    path = request_dict[\"path\"]",
            "    path = validate_path_is_safe(path)",
            "    run = _get_tracking_store().get_run(run_id)",
            "",
            "    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):",
            "        artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "        artifact_path = _get_proxied_run_artifact_destination_path(",
            "            proxied_artifact_root=run.info.artifact_uri,",
            "            relative_path=path,",
            "        )",
            "    else:",
            "        artifact_repo = _get_artifact_repo(run)",
            "        artifact_path = path",
            "",
            "    return _send_artifact(artifact_repo, artifact_path)",
            "",
            "",
            "def _not_implemented():",
            "    response = Response()",
            "    response.status_code = 404",
            "    return response",
            "",
            "",
            "# Tracking Server APIs",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_experiment():",
            "    request_message = _get_request_message(",
            "        CreateExperiment(),",
            "        schema={",
            "            \"name\": [_assert_required, _assert_string],",
            "            \"artifact_location\": [_assert_string],",
            "            \"tags\": [_assert_array],",
            "        },",
            "    )",
            "",
            "    tags = [ExperimentTag(tag.key, tag.value) for tag in request_message.tags]",
            "",
            "    # Validate query string in artifact location to prevent attacks",
            "    parsed_artifact_locaion = urllib.parse.urlparse(request_message.artifact_location)",
            "    validate_query_string(parsed_artifact_locaion.query)",
            "",
            "    experiment_id = _get_tracking_store().create_experiment(",
            "        request_message.name, request_message.artifact_location, tags",
            "    )",
            "    response_message = CreateExperiment.Response()",
            "    response_message.experiment_id = experiment_id",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_experiment():",
            "    request_message = _get_request_message(",
            "        GetExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}",
            "    )",
            "    response_message = GetExperiment.Response()",
            "    experiment = _get_tracking_store().get_experiment(request_message.experiment_id).to_proto()",
            "    response_message.experiment.MergeFrom(experiment)",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_experiment_by_name():",
            "    request_message = _get_request_message(",
            "        GetExperimentByName(), schema={\"experiment_name\": [_assert_required, _assert_string]}",
            "    )",
            "    response_message = GetExperimentByName.Response()",
            "    store_exp = _get_tracking_store().get_experiment_by_name(request_message.experiment_name)",
            "    if store_exp is None:",
            "        raise MlflowException(",
            "            f\"Could not find experiment with name '{request_message.experiment_name}'\",",
            "            error_code=RESOURCE_DOES_NOT_EXIST,",
            "        )",
            "    experiment = store_exp.to_proto()",
            "    response_message.experiment.MergeFrom(experiment)",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_experiment():",
            "    request_message = _get_request_message(",
            "        DeleteExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().delete_experiment(request_message.experiment_id)",
            "    response_message = DeleteExperiment.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _restore_experiment():",
            "    request_message = _get_request_message(",
            "        RestoreExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().restore_experiment(request_message.experiment_id)",
            "    response_message = RestoreExperiment.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_experiment():",
            "    request_message = _get_request_message(",
            "        UpdateExperiment(),",
            "        schema={",
            "            \"experiment_id\": [_assert_required, _assert_string],",
            "            \"new_name\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    if request_message.new_name:",
            "        _get_tracking_store().rename_experiment(",
            "            request_message.experiment_id, request_message.new_name",
            "        )",
            "    response_message = UpdateExperiment.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_run():",
            "    request_message = _get_request_message(",
            "        CreateRun(),",
            "        schema={",
            "            \"experiment_id\": [_assert_string],",
            "            \"start_time\": [_assert_intlike],",
            "            \"run_name\": [_assert_string],",
            "        },",
            "    )",
            "",
            "    tags = [RunTag(tag.key, tag.value) for tag in request_message.tags]",
            "    run = _get_tracking_store().create_run(",
            "        experiment_id=request_message.experiment_id,",
            "        user_id=request_message.user_id,",
            "        start_time=request_message.start_time,",
            "        tags=tags,",
            "        run_name=request_message.run_name,",
            "    )",
            "",
            "    response_message = CreateRun.Response()",
            "    response_message.run.MergeFrom(run.to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_run():",
            "    request_message = _get_request_message(",
            "        UpdateRun(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"end_time\": [_assert_intlike],",
            "            \"status\": [_assert_string],",
            "            \"run_name\": [_assert_string],",
            "        },",
            "    )",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    run_name = request_message.run_name if request_message.HasField(\"run_name\") else None",
            "    end_time = request_message.end_time if request_message.HasField(\"end_time\") else None",
            "    status = request_message.status if request_message.HasField(\"status\") else None",
            "    updated_info = _get_tracking_store().update_run_info(run_id, status, end_time, run_name)",
            "    response_message = UpdateRun.Response(run_info=updated_info.to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_run():",
            "    request_message = _get_request_message(",
            "        DeleteRun(), schema={\"run_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().delete_run(request_message.run_id)",
            "    response_message = DeleteRun.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _restore_run():",
            "    request_message = _get_request_message(",
            "        RestoreRun(), schema={\"run_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().restore_run(request_message.run_id)",
            "    response_message = RestoreRun.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_metric():",
            "    request_message = _get_request_message(",
            "        LogMetric(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_required, _assert_floatlike],",
            "            \"timestamp\": [_assert_intlike, _assert_required],",
            "            \"step\": [_assert_intlike],",
            "        },",
            "    )",
            "    metric = Metric(",
            "        request_message.key, request_message.value, request_message.timestamp, request_message.step",
            "    )",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    _get_tracking_store().log_metric(run_id, metric)",
            "    response_message = LogMetric.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_param():",
            "    request_message = _get_request_message(",
            "        LogParam(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    param = Param(request_message.key, request_message.value)",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    _get_tracking_store().log_param(run_id, param)",
            "    response_message = LogParam.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_inputs():",
            "    request_message = _get_request_message(",
            "        LogInputs(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"datasets\": [_assert_required, _assert_array],",
            "        },",
            "    )",
            "    run_id = request_message.run_id",
            "    datasets = [",
            "        DatasetInput.from_proto(proto_dataset_input)",
            "        for proto_dataset_input in request_message.datasets",
            "    ]",
            "",
            "    _get_tracking_store().log_inputs(run_id, datasets=datasets)",
            "    response_message = LogInputs.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_experiment_tag():",
            "    request_message = _get_request_message(",
            "        SetExperimentTag(),",
            "        schema={",
            "            \"experiment_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = ExperimentTag(request_message.key, request_message.value)",
            "    _get_tracking_store().set_experiment_tag(request_message.experiment_id, tag)",
            "    response_message = SetExperimentTag.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_tag():",
            "    request_message = _get_request_message(",
            "        SetTag(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = RunTag(request_message.key, request_message.value)",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    _get_tracking_store().set_tag(run_id, tag)",
            "    response_message = SetTag.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_tag():",
            "    request_message = _get_request_message(",
            "        DeleteTag(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "        },",
            "    )",
            "    _get_tracking_store().delete_tag(request_message.run_id, request_message.key)",
            "    response_message = DeleteTag.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_run():",
            "    request_message = _get_request_message(",
            "        GetRun(), schema={\"run_id\": [_assert_required, _assert_string]}",
            "    )",
            "    response_message = GetRun.Response()",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    response_message.run.MergeFrom(_get_tracking_store().get_run(run_id).to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_runs():",
            "    request_message = _get_request_message(",
            "        SearchRuns(),",
            "        schema={",
            "            \"experiment_ids\": [_assert_array],",
            "            \"filter\": [_assert_string],",
            "            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 50000)],",
            "            \"order_by\": [_assert_array, _assert_item_type_string],",
            "        },",
            "    )",
            "    response_message = SearchRuns.Response()",
            "    run_view_type = ViewType.ACTIVE_ONLY",
            "    if request_message.HasField(\"run_view_type\"):",
            "        run_view_type = ViewType.from_proto(request_message.run_view_type)",
            "    filter_string = request_message.filter",
            "    max_results = request_message.max_results",
            "    experiment_ids = request_message.experiment_ids",
            "    order_by = request_message.order_by",
            "    page_token = request_message.page_token",
            "    run_entities = _get_tracking_store().search_runs(",
            "        experiment_ids, filter_string, run_view_type, max_results, order_by, page_token",
            "    )",
            "    response_message.runs.extend([r.to_proto() for r in run_entities])",
            "    if run_entities.token:",
            "        response_message.next_page_token = run_entities.token",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _list_artifacts():",
            "    request_message = _get_request_message(",
            "        ListArtifacts(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"path\": [_assert_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    response_message = ListArtifacts.Response()",
            "    if request_message.HasField(\"path\"):",
            "        path = request_message.path",
            "        path = validate_path_is_safe(path)",
            "    else:",
            "        path = None",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    run = _get_tracking_store().get_run(run_id)",
            "",
            "    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):",
            "        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(",
            "            proxied_artifact_root=run.info.artifact_uri,",
            "            relative_path=path,",
            "        )",
            "    else:",
            "        artifact_entities = _get_artifact_repo(run).list_artifacts(path)",
            "",
            "    response_message.files.extend([a.to_proto() for a in artifact_entities])",
            "    response_message.root_uri = run.info.artifact_uri",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "def _list_artifacts_for_proxied_run_artifact_root(proxied_artifact_root, relative_path=None):",
            "    \"\"\"",
            "    Lists artifacts from the specified ``relative_path`` within the specified proxied Run artifact",
            "    root (i.e. a Run artifact root with scheme ``http``, ``https``, or ``mlflow-artifacts``).",
            "",
            "    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,",
            "                                  ``https``, or ``mlflow-artifacts`` that can be resolved by the",
            "                                  MLflow server to a concrete storage location.",
            "    :param relative_path: The relative path within the specified ``proxied_artifact_root`` under",
            "                          which to list artifact contents. If ``None``, artifacts are listed from",
            "                          the ``proxied_artifact_root`` directory.",
            "    \"\"\"",
            "    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)",
            "    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]",
            "",
            "    artifact_destination_repo = _get_artifact_repo_mlflow_artifacts()",
            "    artifact_destination_path = _get_proxied_run_artifact_destination_path(",
            "        proxied_artifact_root=proxied_artifact_root,",
            "        relative_path=relative_path,",
            "    )",
            "",
            "    artifact_entities = []",
            "    for file_info in artifact_destination_repo.list_artifacts(artifact_destination_path):",
            "        basename = posixpath.basename(file_info.path)",
            "        run_relative_artifact_path = (",
            "            posixpath.join(relative_path, basename) if relative_path else basename",
            "        )",
            "        artifact_entities.append(",
            "            FileInfo(run_relative_artifact_path, file_info.is_dir, file_info.file_size)",
            "        )",
            "",
            "    return artifact_entities",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_metric_history():",
            "    request_message = _get_request_message(",
            "        GetMetricHistory(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"metric_key\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    response_message = GetMetricHistory.Response()",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    metric_entities = _get_tracking_store().get_metric_history(run_id, request_message.metric_key)",
            "    response_message.metrics.extend([m.to_proto() for m in metric_entities])",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def get_metric_history_bulk_handler():",
            "    MAX_HISTORY_RESULTS = 25000",
            "    MAX_RUN_IDS_PER_REQUEST = 20",
            "    run_ids = request.args.to_dict(flat=False).get(\"run_id\", [])",
            "    if not run_ids:",
            "        raise MlflowException(",
            "            message=\"GetMetricHistoryBulk request must specify at least one run_id.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    if len(run_ids) > MAX_RUN_IDS_PER_REQUEST:",
            "        raise MlflowException(",
            "            message=(",
            "                f\"GetMetricHistoryBulk request cannot specify more than {MAX_RUN_IDS_PER_REQUEST}\"",
            "                f\" run_ids. Received {len(run_ids)} run_ids.\"",
            "            ),",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    metric_key = request.args.get(\"metric_key\")",
            "    if metric_key is None:",
            "        raise MlflowException(",
            "            message=\"GetMetricHistoryBulk request must specify a metric_key.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    max_results = int(request.args.get(\"max_results\", MAX_HISTORY_RESULTS))",
            "    max_results = min(max_results, MAX_HISTORY_RESULTS)",
            "",
            "    store = _get_tracking_store()",
            "",
            "    def _default_history_bulk_impl():",
            "        metrics_with_run_ids = []",
            "        for run_id in sorted(run_ids):",
            "            metrics_for_run = sorted(",
            "                store.get_metric_history(",
            "                    run_id=run_id,",
            "                    metric_key=metric_key,",
            "                    max_results=max_results,",
            "                ),",
            "                key=lambda metric: (metric.timestamp, metric.step, metric.value),",
            "            )",
            "            metrics_with_run_ids.extend(",
            "                [",
            "                    {",
            "                        \"key\": metric.key,",
            "                        \"value\": metric.value,",
            "                        \"timestamp\": metric.timestamp,",
            "                        \"step\": metric.step,",
            "                        \"run_id\": run_id,",
            "                    }",
            "                    for metric in metrics_for_run",
            "                ]",
            "            )",
            "        return metrics_with_run_ids",
            "",
            "    if hasattr(store, \"get_metric_history_bulk\"):",
            "        metrics_with_run_ids = [",
            "            metric.to_dict()",
            "            for metric in store.get_metric_history_bulk(",
            "                run_ids=run_ids,",
            "                metric_key=metric_key,",
            "                max_results=max_results,",
            "            )",
            "        ]",
            "    else:",
            "        metrics_with_run_ids = _default_history_bulk_impl()",
            "",
            "    return {",
            "        \"metrics\": metrics_with_run_ids[:max_results],",
            "    }",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def search_datasets_handler():",
            "    MAX_EXPERIMENT_IDS_PER_REQUEST = 20",
            "    _validate_content_type(request, [\"application/json\"])",
            "    experiment_ids = request.json.get(\"experiment_ids\", [])",
            "    if not experiment_ids:",
            "        raise MlflowException(",
            "            message=\"SearchDatasets request must specify at least one experiment_id.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    if len(experiment_ids) > MAX_EXPERIMENT_IDS_PER_REQUEST:",
            "        raise MlflowException(",
            "            message=(",
            "                f\"SearchDatasets request cannot specify more than {MAX_EXPERIMENT_IDS_PER_REQUEST}\"",
            "                f\" experiment_ids. Received {len(experiment_ids)} experiment_ids.\"",
            "            ),",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    store = _get_tracking_store()",
            "",
            "    if hasattr(store, \"_search_datasets\"):",
            "        return {",
            "            \"dataset_summaries\": [",
            "                summary.to_dict() for summary in store._search_datasets(experiment_ids)",
            "            ]",
            "        }",
            "    else:",
            "        return _not_implemented()",
            "",
            "",
            "@catch_mlflow_exception",
            "def gateway_proxy_handler():",
            "    target_uri = MLFLOW_DEPLOYMENTS_TARGET.get()",
            "    if not target_uri:",
            "        # Pretend an empty gateway service is running",
            "        return {\"endpoints\": []}",
            "",
            "    args = request.args if request.method == \"GET\" else request.json",
            "",
            "    gateway_path = args.get(\"gateway_path\")",
            "    if not gateway_path:",
            "        raise MlflowException(",
            "            message=\"Deployments proxy request must specify a gateway_path.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    request_type = request.method",
            "    json_data = args.get(\"json_data\", None)",
            "",
            "    response = requests.request(request_type, f\"{target_uri}/{gateway_path}\", json=json_data)",
            "",
            "    if response.status_code == 200:",
            "        return response.json()",
            "    else:",
            "        raise MlflowException(",
            "            message=f\"Deployments proxy request failed with error code {response.status_code}. \"",
            "            f\"Error message: {response.text}\",",
            "            error_code=response.status_code,",
            "        )",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def create_promptlab_run_handler():",
            "    def assert_arg_exists(arg_name, arg):",
            "        if not arg:",
            "            raise MlflowException(",
            "                message=f\"CreatePromptlabRun request must specify {arg_name}.\",",
            "                error_code=INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "    _validate_content_type(request, [\"application/json\"])",
            "",
            "    args = request.json",
            "    experiment_id = args.get(\"experiment_id\")",
            "    assert_arg_exists(\"experiment_id\", experiment_id)",
            "    run_name = args.get(\"run_name\", None)",
            "    tags = args.get(\"tags\", [])",
            "    prompt_template = args.get(\"prompt_template\")",
            "    assert_arg_exists(\"prompt_template\", prompt_template)",
            "    raw_prompt_parameters = args.get(\"prompt_parameters\")",
            "    assert_arg_exists(\"prompt_parameters\", raw_prompt_parameters)",
            "    prompt_parameters = [",
            "        Param(param.get(\"key\"), param.get(\"value\")) for param in args.get(\"prompt_parameters\")",
            "    ]",
            "    model_route = args.get(\"model_route\")",
            "    assert_arg_exists(\"model_route\", model_route)",
            "    raw_model_parameters = args.get(\"model_parameters\", [])",
            "    model_parameters = [",
            "        Param(param.get(\"key\"), param.get(\"value\")) for param in raw_model_parameters",
            "    ]",
            "    model_input = args.get(\"model_input\")",
            "    assert_arg_exists(\"model_input\", model_input)",
            "    model_output = args.get(\"model_output\", None)",
            "    raw_model_output_parameters = args.get(\"model_output_parameters\", [])",
            "    model_output_parameters = [",
            "        Param(param.get(\"key\"), param.get(\"value\")) for param in raw_model_output_parameters",
            "    ]",
            "    mlflow_version = args.get(\"mlflow_version\")",
            "    assert_arg_exists(\"mlflow_version\", mlflow_version)",
            "    user_id = args.get(\"user_id\", \"unknown\")",
            "",
            "    # use current time if not provided",
            "    start_time = args.get(\"start_time\", int(time.time() * 1000))",
            "",
            "    store = _get_tracking_store()",
            "",
            "    run = _create_promptlab_run_impl(",
            "        store,",
            "        experiment_id=experiment_id,",
            "        run_name=run_name,",
            "        tags=tags,",
            "        prompt_template=prompt_template,",
            "        prompt_parameters=prompt_parameters,",
            "        model_route=model_route,",
            "        model_parameters=model_parameters,",
            "        model_input=model_input,",
            "        model_output=model_output,",
            "        model_output_parameters=model_output_parameters,",
            "        mlflow_version=mlflow_version,",
            "        user_id=user_id,",
            "        start_time=start_time,",
            "    )",
            "    response_message = CreateRun.Response()",
            "    response_message.run.MergeFrom(run.to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "def upload_artifact_handler():",
            "    args = request.args",
            "    run_uuid = args.get(\"run_uuid\")",
            "    if not run_uuid:",
            "        raise MlflowException(",
            "            message=\"Request must specify run_uuid.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    path = args.get(\"path\")",
            "    if not path:",
            "        raise MlflowException(",
            "            message=\"Request must specify path.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    path = validate_path_is_safe(path)",
            "",
            "    if request.content_length and request.content_length > 10 * 1024 * 1024:",
            "        raise MlflowException(",
            "            message=\"Artifact size is too large. Max size is 10MB.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    data = request.data",
            "    if not data:",
            "        raise MlflowException(",
            "            message=\"Request must specify data.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    run = _get_tracking_store().get_run(run_uuid)",
            "    artifact_dir = run.info.artifact_uri",
            "",
            "    basename = posixpath.basename(path)",
            "    dirname = posixpath.dirname(path)",
            "",
            "    def _log_artifact_to_repo(file, run, dirname, artifact_dir):",
            "        if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):",
            "            artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "            path_to_log = (",
            "                os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\", dirname)",
            "                if dirname",
            "                else os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\")",
            "            )",
            "        else:",
            "            artifact_repo = get_artifact_repository(artifact_dir)",
            "            path_to_log = dirname",
            "",
            "        artifact_repo.log_artifact(file, path_to_log)",
            "",
            "    with tempfile.TemporaryDirectory() as tmpdir:",
            "        dir_path = os.path.join(tmpdir, dirname) if dirname else tmpdir",
            "        file_path = os.path.join(dir_path, basename)",
            "",
            "        os.makedirs(dir_path, exist_ok=True)",
            "",
            "        with open(file_path, \"wb\") as f:",
            "            f.write(data)",
            "",
            "        _log_artifact_to_repo(file_path, run, dirname, artifact_dir)",
            "",
            "    return Response(mimetype=\"application/json\")",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_experiments():",
            "    request_message = _get_request_message(",
            "        SearchExperiments(),",
            "        schema={",
            "            \"view_type\": [_assert_intlike],",
            "            \"max_results\": [_assert_intlike],",
            "            \"order_by\": [_assert_array],",
            "            \"filter\": [_assert_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    experiment_entities = _get_tracking_store().search_experiments(",
            "        view_type=request_message.view_type,",
            "        max_results=request_message.max_results,",
            "        order_by=request_message.order_by,",
            "        filter_string=request_message.filter,",
            "        page_token=request_message.page_token,",
            "    )",
            "    response_message = SearchExperiments.Response()",
            "    response_message.experiments.extend([e.to_proto() for e in experiment_entities])",
            "    if experiment_entities.token:",
            "        response_message.next_page_token = experiment_entities.token",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "def _get_artifact_repo(run):",
            "    return get_artifact_repository(run.info.artifact_uri)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_batch():",
            "    def _assert_metrics_fields_present(metrics):",
            "        for m in metrics:",
            "            _assert_required(m.get(\"key\"))",
            "            _assert_required(m.get(\"value\"))",
            "            _assert_required(m.get(\"timestamp\"))",
            "",
            "    def _assert_params_tags_fields_present(params_or_tags):",
            "        for param_or_tag in params_or_tags:",
            "            _assert_required(param_or_tag.get(\"key\"))",
            "",
            "    _validate_batch_log_api_req(_get_request_json())",
            "    request_message = _get_request_message(",
            "        LogBatch(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"metrics\": [_assert_array, _assert_metrics_fields_present],",
            "            \"params\": [_assert_array, _assert_params_tags_fields_present],",
            "            \"tags\": [_assert_array, _assert_params_tags_fields_present],",
            "        },",
            "    )",
            "    metrics = [Metric.from_proto(proto_metric) for proto_metric in request_message.metrics]",
            "    params = [Param.from_proto(proto_param) for proto_param in request_message.params]",
            "    tags = [RunTag.from_proto(proto_tag) for proto_tag in request_message.tags]",
            "    _get_tracking_store().log_batch(",
            "        run_id=request_message.run_id, metrics=metrics, params=params, tags=tags",
            "    )",
            "    response_message = LogBatch.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_model():",
            "    request_message = _get_request_message(",
            "        LogModel(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"model_json\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    try:",
            "        model = json.loads(request_message.model_json)",
            "    except Exception:",
            "        raise MlflowException(",
            "            f\"Malformed model info. \\n {request_message.model_json} \\n is not a valid JSON.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    missing_fields = {\"artifact_path\", \"flavors\", \"utc_time_created\", \"run_id\"} - set(model.keys())",
            "",
            "    if missing_fields:",
            "        raise MlflowException(",
            "            f\"Model json is missing mandatory fields: {missing_fields}\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    _get_tracking_store().record_logged_model(",
            "        run_id=request_message.run_id, mlflow_model=Model.from_dict(model)",
            "    )",
            "    response_message = LogModel.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "def _wrap_response(response_message):",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "# Model Registry APIs",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_registered_model():",
            "    request_message = _get_request_message(",
            "        CreateRegisteredModel(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"tags\": [_assert_array],",
            "            \"description\": [_assert_string],",
            "        },",
            "    )",
            "    registered_model = _get_model_registry_store().create_registered_model(",
            "        name=request_message.name,",
            "        tags=request_message.tags,",
            "        description=request_message.description,",
            "    )",
            "    response_message = CreateRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_registered_model():",
            "    request_message = _get_request_message(",
            "        GetRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}",
            "    )",
            "    registered_model = _get_model_registry_store().get_registered_model(name=request_message.name)",
            "    response_message = GetRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_registered_model():",
            "    request_message = _get_request_message(",
            "        UpdateRegisteredModel(),",
            "        schema={\"name\": [_assert_string, _assert_required], \"description\": [_assert_string]},",
            "    )",
            "    name = request_message.name",
            "    new_description = request_message.description",
            "    registered_model = _get_model_registry_store().update_registered_model(",
            "        name=name, description=new_description",
            "    )",
            "    response_message = UpdateRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _rename_registered_model():",
            "    request_message = _get_request_message(",
            "        RenameRegisteredModel(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"new_name\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    name = request_message.name",
            "    new_name = request_message.new_name",
            "    registered_model = _get_model_registry_store().rename_registered_model(",
            "        name=name, new_name=new_name",
            "    )",
            "    response_message = RenameRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_registered_model():",
            "    request_message = _get_request_message(",
            "        DeleteRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}",
            "    )",
            "    _get_model_registry_store().delete_registered_model(name=request_message.name)",
            "    return _wrap_response(DeleteRegisteredModel.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_registered_models():",
            "    request_message = _get_request_message(",
            "        SearchRegisteredModels(),",
            "        schema={",
            "            \"filter\": [_assert_string],",
            "            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 1000)],",
            "            \"order_by\": [_assert_array, _assert_item_type_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    store = _get_model_registry_store()",
            "    registered_models = store.search_registered_models(",
            "        filter_string=request_message.filter,",
            "        max_results=request_message.max_results,",
            "        order_by=request_message.order_by,",
            "        page_token=request_message.page_token,",
            "    )",
            "    response_message = SearchRegisteredModels.Response()",
            "    response_message.registered_models.extend([e.to_proto() for e in registered_models])",
            "    if registered_models.token:",
            "        response_message.next_page_token = registered_models.token",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_latest_versions():",
            "    request_message = _get_request_message(",
            "        GetLatestVersions(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"stages\": [_assert_array, _assert_item_type_string],",
            "        },",
            "    )",
            "    latest_versions = _get_model_registry_store().get_latest_versions(",
            "        name=request_message.name, stages=request_message.stages",
            "    )",
            "    response_message = GetLatestVersions.Response()",
            "    response_message.model_versions.extend([e.to_proto() for e in latest_versions])",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_registered_model_tag():",
            "    request_message = _get_request_message(",
            "        SetRegisteredModelTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = RegisteredModelTag(key=request_message.key, value=request_message.value)",
            "    _get_model_registry_store().set_registered_model_tag(name=request_message.name, tag=tag)",
            "    return _wrap_response(SetRegisteredModelTag.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_registered_model_tag():",
            "    request_message = _get_request_message(",
            "        DeleteRegisteredModelTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_registered_model_tag(",
            "        name=request_message.name, key=request_message.key",
            "    )",
            "    return _wrap_response(DeleteRegisteredModelTag.Response())",
            "",
            "",
            "def _validate_non_local_source_contains_relative_paths(source: str):",
            "    \"\"\"",
            "    Validation check to ensure that sources that are provided that conform to the schemes:",
            "    http, https, or mlflow-artifacts do not contain relative path designations that are intended",
            "    to access local file system paths on the tracking server.",
            "",
            "    Example paths that this validation function is intended to find and raise an Exception if",
            "    passed:",
            "    \"mlflow-artifacts://host:port/../../../../\"",
            "    \"http://host:port/api/2.0/mlflow-artifacts/artifacts/../../../../\"",
            "    \"https://host:port/api/2.0/mlflow-artifacts/artifacts/../../../../\"",
            "    \"/models/artifacts/../../../\"",
            "    \"s3:/my_bucket/models/path/../../other/path\"",
            "    \"file://path/to/../../../../some/where/you/should/not/be\"",
            "    \"mlflow-artifacts://host:port/..%2f..%2f..%2f..%2f\"",
            "    \"http://host:port/api/2.0/mlflow-artifacts/artifacts%00\"",
            "    \"\"\"",
            "    invalid_source_error_message = (",
            "        f\"Invalid model version source: '{source}'. If supplying a source as an http, https, \"",
            "        \"local file path, ftp, objectstore, or mlflow-artifacts uri, an absolute path must be \"",
            "        \"provided without relative path references present. \"",
            "        \"Please provide an absolute path.\"",
            "    )",
            "",
            "    while (unquoted := urllib.parse.unquote_plus(source)) != source:",
            "        source = unquoted",
            "    source_path = re.sub(r\"/+\", \"/\", urllib.parse.urlparse(source).path.rstrip(\"/\"))",
            "    if \"\\x00\" in source_path:",
            "        raise MlflowException(invalid_source_error_message, INVALID_PARAMETER_VALUE)",
            "    resolved_source = pathlib.Path(source_path).resolve().as_posix()",
            "    # NB: drive split is specifically for Windows since WindowsPath.resolve() will append the",
            "    # drive path of the pwd to a given path. We don't care about the drive here, though.",
            "    _, resolved_path = os.path.splitdrive(resolved_source)",
            "",
            "    if resolved_path != source_path:",
            "        raise MlflowException(invalid_source_error_message, INVALID_PARAMETER_VALUE)",
            "",
            "",
            "def _validate_source(source: str, run_id: str) -> None:",
            "    if is_local_uri(source):",
            "        if run_id:",
            "            store = _get_tracking_store()",
            "            run = store.get_run(run_id)",
            "            source = pathlib.Path(local_file_uri_to_path(source)).resolve()",
            "            run_artifact_dir = pathlib.Path(local_file_uri_to_path(run.info.artifact_uri)).resolve()",
            "            if run_artifact_dir in [source, *source.parents]:",
            "                return",
            "",
            "        raise MlflowException(",
            "            f\"Invalid model version source: '{source}'. To use a local path as a model version \"",
            "            \"source, the run_id request parameter has to be specified and the local path has to be \"",
            "            \"contained within the artifact directory of the run specified by the run_id.\",",
            "            INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    # There might be file URIs that are local but can bypass the above check. To prevent this, we",
            "    # disallow using file URIs as model version sources by default unless it's explicitly allowed",
            "    # by setting the MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE environment variable to True.",
            "    if not MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE.get() and is_file_uri(source):",
            "        raise MlflowException(",
            "            f\"Invalid model version source: '{source}'. MLflow tracking server doesn't allow using \"",
            "            \"a file URI as a model version source for security reasons. To disable this check, set \"",
            "            f\"the {MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE} environment variable to \"",
            "            \"True.\",",
            "            INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    # Checks if relative paths are present in the source (a security threat). If any are present,",
            "    # raises an Exception.",
            "    _validate_non_local_source_contains_relative_paths(source)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_model_version():",
            "    request_message = _get_request_message(",
            "        CreateModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"source\": [_assert_string, _assert_required],",
            "            \"run_id\": [_assert_string],",
            "            \"tags\": [_assert_array],",
            "            \"run_link\": [_assert_string],",
            "            \"description\": [_assert_string],",
            "        },",
            "    )",
            "",
            "    _validate_source(request_message.source, request_message.run_id)",
            "",
            "    model_version = _get_model_registry_store().create_model_version(",
            "        name=request_message.name,",
            "        source=request_message.source,",
            "        run_id=request_message.run_id,",
            "        run_link=request_message.run_link,",
            "        tags=request_message.tags,",
            "        description=request_message.description,",
            "    )",
            "    response_message = CreateModelVersion.Response(model_version=model_version.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def get_model_version_artifact_handler():",
            "    from querystring_parser import parser",
            "",
            "    query_string = request.query_string.decode(\"utf-8\")",
            "    request_dict = parser.parse(query_string, normalized=True)",
            "    name = request_dict.get(\"name\")",
            "    version = request_dict.get(\"version\")",
            "    path = request_dict[\"path\"]",
            "    path = validate_path_is_safe(path)",
            "    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)",
            "    if _is_servable_proxied_run_artifact_root(artifact_uri):",
            "        artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "        artifact_path = _get_proxied_run_artifact_destination_path(",
            "            proxied_artifact_root=artifact_uri,",
            "            relative_path=path,",
            "        )",
            "    else:",
            "        artifact_repo = get_artifact_repository(artifact_uri)",
            "        artifact_path = path",
            "",
            "    return _send_artifact(artifact_repo, artifact_path)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_model_version():",
            "    request_message = _get_request_message(",
            "        GetModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    model_version = _get_model_registry_store().get_model_version(",
            "        name=request_message.name, version=request_message.version",
            "    )",
            "    response_proto = model_version.to_proto()",
            "    response_message = GetModelVersion.Response(model_version=response_proto)",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_model_version():",
            "    request_message = _get_request_message(",
            "        UpdateModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"description\": [_assert_string],",
            "        },",
            "    )",
            "    new_description = None",
            "    if request_message.HasField(\"description\"):",
            "        new_description = request_message.description",
            "    model_version = _get_model_registry_store().update_model_version(",
            "        name=request_message.name, version=request_message.version, description=new_description",
            "    )",
            "    return _wrap_response(UpdateModelVersion.Response(model_version=model_version.to_proto()))",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _transition_stage():",
            "    request_message = _get_request_message(",
            "        TransitionModelVersionStage(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"stage\": [_assert_string, _assert_required],",
            "            \"archive_existing_versions\": [_assert_bool],",
            "        },",
            "    )",
            "    model_version = _get_model_registry_store().transition_model_version_stage(",
            "        name=request_message.name,",
            "        version=request_message.version,",
            "        stage=request_message.stage,",
            "        archive_existing_versions=request_message.archive_existing_versions,",
            "    )",
            "    return _wrap_response(",
            "        TransitionModelVersionStage.Response(model_version=model_version.to_proto())",
            "    )",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_model_version():",
            "    request_message = _get_request_message(",
            "        DeleteModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_model_version(",
            "        name=request_message.name, version=request_message.version",
            "    )",
            "    return _wrap_response(DeleteModelVersion.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_model_version_download_uri():",
            "    request_message = _get_request_message(GetModelVersionDownloadUri())",
            "    download_uri = _get_model_registry_store().get_model_version_download_uri(",
            "        name=request_message.name, version=request_message.version",
            "    )",
            "    response_message = GetModelVersionDownloadUri.Response(artifact_uri=download_uri)",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_model_versions():",
            "    request_message = _get_request_message(",
            "        SearchModelVersions(),",
            "        schema={",
            "            \"filter\": [_assert_string],",
            "            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 200_000)],",
            "            \"order_by\": [_assert_array, _assert_item_type_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    store = _get_model_registry_store()",
            "    model_versions = store.search_model_versions(",
            "        filter_string=request_message.filter,",
            "        max_results=request_message.max_results,",
            "        order_by=request_message.order_by,",
            "        page_token=request_message.page_token,",
            "    )",
            "    response_message = SearchModelVersions.Response()",
            "    response_message.model_versions.extend([e.to_proto() for e in model_versions])",
            "    if model_versions.token:",
            "        response_message.next_page_token = model_versions.token",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_model_version_tag():",
            "    request_message = _get_request_message(",
            "        SetModelVersionTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = ModelVersionTag(key=request_message.key, value=request_message.value)",
            "    _get_model_registry_store().set_model_version_tag(",
            "        name=request_message.name, version=request_message.version, tag=tag",
            "    )",
            "    return _wrap_response(SetModelVersionTag.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_model_version_tag():",
            "    request_message = _get_request_message(",
            "        DeleteModelVersionTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_model_version_tag(",
            "        name=request_message.name, version=request_message.version, key=request_message.key",
            "    )",
            "    return _wrap_response(DeleteModelVersionTag.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_registered_model_alias():",
            "    request_message = _get_request_message(",
            "        SetRegisteredModelAlias(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"alias\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().set_registered_model_alias(",
            "        name=request_message.name, alias=request_message.alias, version=request_message.version",
            "    )",
            "    return _wrap_response(SetRegisteredModelAlias.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_registered_model_alias():",
            "    request_message = _get_request_message(",
            "        DeleteRegisteredModelAlias(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"alias\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_registered_model_alias(",
            "        name=request_message.name, alias=request_message.alias",
            "    )",
            "    return _wrap_response(DeleteRegisteredModelAlias.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_model_version_by_alias():",
            "    request_message = _get_request_message(",
            "        GetModelVersionByAlias(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"alias\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    model_version = _get_model_registry_store().get_model_version_by_alias(",
            "        name=request_message.name, alias=request_message.alias",
            "    )",
            "    response_proto = model_version.to_proto()",
            "    response_message = GetModelVersionByAlias.Response(model_version=response_proto)",
            "    return _wrap_response(response_message)",
            "",
            "",
            "# MLflow Artifacts APIs",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _download_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `GET /mlflow-artifacts/artifacts/<artifact_path>` to download an artifact",
            "    from `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "    tmp_dir = tempfile.TemporaryDirectory()",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    dst = artifact_repo.download_artifacts(artifact_path, tmp_dir.name)",
            "",
            "    # Ref: https://stackoverflow.com/a/24613980/6943581",
            "    file_handle = open(dst, \"rb\")  # noqa: SIM115",
            "",
            "    def stream_and_remove_file():",
            "        yield from file_handle",
            "        file_handle.close()",
            "        tmp_dir.cleanup()",
            "",
            "    file_sender_response = current_app.response_class(stream_and_remove_file())",
            "",
            "    return _response_with_file_attachment_headers(artifact_path, file_sender_response)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `PUT /mlflow-artifacts/artifacts/<artifact_path>` to upload an artifact",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "    head, tail = posixpath.split(artifact_path)",
            "    with tempfile.TemporaryDirectory() as tmp_dir:",
            "        tmp_path = os.path.join(tmp_dir, tail)",
            "        with open(tmp_path, \"wb\") as f:",
            "            chunk_size = 1024 * 1024  # 1 MB",
            "            while True:",
            "                chunk = request.stream.read(chunk_size)",
            "                if len(chunk) == 0:",
            "                    break",
            "                f.write(chunk)",
            "",
            "        artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "        artifact_repo.log_artifact(tmp_path, artifact_path=head or None)",
            "",
            "    return _wrap_response(UploadArtifact.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _list_artifacts_mlflow_artifacts():",
            "    \"\"\"",
            "    A request handler for `GET /mlflow-artifacts/artifacts?path=<value>` to list artifacts in `path`",
            "    (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    request_message = _get_request_message(ListArtifactsMlflowArtifacts())",
            "    path = validate_path_is_safe(request_message.path) if request_message.HasField(\"path\") else None",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    files = []",
            "    for file_info in artifact_repo.list_artifacts(path):",
            "        basename = posixpath.basename(file_info.path)",
            "        new_file_info = FileInfo(basename, file_info.is_dir, file_info.file_size)",
            "        files.append(new_file_info.to_proto())",
            "    response_message = ListArtifacts.Response()",
            "    response_message.files.extend(files)",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _delete_artifact_mlflow_artifacts(artifact_path):",
            "    \"\"\"",
            "    A request handler for `DELETE /mlflow-artifacts/artifacts?path=<value>` to delete artifacts in",
            "    `path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "    _get_request_message(DeleteArtifact())",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    artifact_repo.delete_artifacts(artifact_path)",
            "    response_message = DeleteArtifact.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "def _validate_support_multipart_upload(artifact_repo):",
            "    if not isinstance(artifact_repo, MultipartUploadMixin):",
            "        raise _UnsupportedMultipartUploadException()",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _create_multipart_upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `POST /mlflow-artifacts/mpu/create` to create a multipart upload",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "",
            "    request_message = _get_request_message(",
            "        CreateMultipartUpload(),",
            "        schema={",
            "            \"path\": [_assert_required, _assert_string],",
            "            \"num_parts\": [_assert_intlike],",
            "        },",
            "    )",
            "    path = request_message.path",
            "    num_parts = request_message.num_parts",
            "",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    _validate_support_multipart_upload(artifact_repo)",
            "",
            "    create_response = artifact_repo.create_multipart_upload(",
            "        path,",
            "        num_parts,",
            "        artifact_path,",
            "    )",
            "    response_message = create_response.to_proto()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _complete_multipart_upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `POST /mlflow-artifacts/mpu/complete` to complete a multipart upload",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "",
            "    request_message = _get_request_message(",
            "        CompleteMultipartUpload(),",
            "        schema={",
            "            \"path\": [_assert_required, _assert_string],",
            "            \"upload_id\": [_assert_string],",
            "            \"parts\": [_assert_required],",
            "        },",
            "    )",
            "    path = request_message.path",
            "    upload_id = request_message.upload_id",
            "    parts = [MultipartUploadPart.from_proto(part) for part in request_message.parts]",
            "",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    _validate_support_multipart_upload(artifact_repo)",
            "",
            "    artifact_repo.complete_multipart_upload(",
            "        path,",
            "        upload_id,",
            "        parts,",
            "        artifact_path,",
            "    )",
            "    return _wrap_response(CompleteMultipartUpload.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _abort_multipart_upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `POST /mlflow-artifacts/mpu/abort` to abort a multipart upload",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "",
            "    request_message = _get_request_message(",
            "        AbortMultipartUpload(),",
            "        schema={",
            "            \"path\": [_assert_required, _assert_string],",
            "            \"upload_id\": [_assert_string],",
            "        },",
            "    )",
            "    path = request_message.path",
            "    upload_id = request_message.upload_id",
            "",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    _validate_support_multipart_upload(artifact_repo)",
            "",
            "    artifact_repo.abort_multipart_upload(",
            "        path,",
            "        upload_id,",
            "        artifact_path,",
            "    )",
            "    return _wrap_response(AbortMultipartUpload.Response())",
            "",
            "",
            "def _get_rest_path(base_path):",
            "    return f\"/api/2.0{base_path}\"",
            "",
            "",
            "def _get_ajax_path(base_path):",
            "    return _add_static_prefix(f\"/ajax-api/2.0{base_path}\")",
            "",
            "",
            "def _add_static_prefix(route):",
            "    prefix = os.environ.get(STATIC_PREFIX_ENV_VAR)",
            "    if prefix:",
            "        return prefix + route",
            "    return route",
            "",
            "",
            "def _get_paths(base_path):",
            "    \"\"\"",
            "    A service endpoints base path is typically something like /mlflow/experiment.",
            "    We should register paths like /api/2.0/mlflow/experiment and",
            "    /ajax-api/2.0/mlflow/experiment in the Flask router.",
            "    \"\"\"",
            "    return [_get_rest_path(base_path), _get_ajax_path(base_path)]",
            "",
            "",
            "def get_handler(request_class):",
            "    \"\"\"",
            "    :param request_class: The type of protobuf message",
            "    :return:",
            "    \"\"\"",
            "    return HANDLERS.get(request_class, _not_implemented)",
            "",
            "",
            "def get_service_endpoints(service, get_handler):",
            "    ret = []",
            "    for service_method in service.DESCRIPTOR.methods:",
            "        endpoints = service_method.GetOptions().Extensions[databricks_pb2.rpc].endpoints",
            "        for endpoint in endpoints:",
            "            for http_path in _get_paths(endpoint.path):",
            "                handler = get_handler(service().GetRequestClass(service_method))",
            "                ret.append((http_path, handler, [endpoint.method]))",
            "    return ret",
            "",
            "",
            "def get_endpoints(get_handler=get_handler):",
            "    \"\"\"",
            "    :return: List of tuples (path, handler, methods)",
            "    \"\"\"",
            "    return (",
            "        get_service_endpoints(MlflowService, get_handler)",
            "        + get_service_endpoints(ModelRegistryService, get_handler)",
            "        + get_service_endpoints(MlflowArtifactsService, get_handler)",
            "    )",
            "",
            "",
            "HANDLERS = {",
            "    # Tracking Server APIs",
            "    CreateExperiment: _create_experiment,",
            "    GetExperiment: _get_experiment,",
            "    GetExperimentByName: _get_experiment_by_name,",
            "    DeleteExperiment: _delete_experiment,",
            "    RestoreExperiment: _restore_experiment,",
            "    UpdateExperiment: _update_experiment,",
            "    CreateRun: _create_run,",
            "    UpdateRun: _update_run,",
            "    DeleteRun: _delete_run,",
            "    RestoreRun: _restore_run,",
            "    LogParam: _log_param,",
            "    LogMetric: _log_metric,",
            "    SetExperimentTag: _set_experiment_tag,",
            "    SetTag: _set_tag,",
            "    DeleteTag: _delete_tag,",
            "    LogBatch: _log_batch,",
            "    LogModel: _log_model,",
            "    GetRun: _get_run,",
            "    SearchRuns: _search_runs,",
            "    ListArtifacts: _list_artifacts,",
            "    GetMetricHistory: _get_metric_history,",
            "    SearchExperiments: _search_experiments,",
            "    LogInputs: _log_inputs,",
            "    # Model Registry APIs",
            "    CreateRegisteredModel: _create_registered_model,",
            "    GetRegisteredModel: _get_registered_model,",
            "    DeleteRegisteredModel: _delete_registered_model,",
            "    UpdateRegisteredModel: _update_registered_model,",
            "    RenameRegisteredModel: _rename_registered_model,",
            "    SearchRegisteredModels: _search_registered_models,",
            "    GetLatestVersions: _get_latest_versions,",
            "    CreateModelVersion: _create_model_version,",
            "    GetModelVersion: _get_model_version,",
            "    DeleteModelVersion: _delete_model_version,",
            "    UpdateModelVersion: _update_model_version,",
            "    TransitionModelVersionStage: _transition_stage,",
            "    GetModelVersionDownloadUri: _get_model_version_download_uri,",
            "    SearchModelVersions: _search_model_versions,",
            "    SetRegisteredModelTag: _set_registered_model_tag,",
            "    DeleteRegisteredModelTag: _delete_registered_model_tag,",
            "    SetModelVersionTag: _set_model_version_tag,",
            "    DeleteModelVersionTag: _delete_model_version_tag,",
            "    SetRegisteredModelAlias: _set_registered_model_alias,",
            "    DeleteRegisteredModelAlias: _delete_registered_model_alias,",
            "    GetModelVersionByAlias: _get_model_version_by_alias,",
            "    # MLflow Artifacts APIs",
            "    DownloadArtifact: _download_artifact,",
            "    UploadArtifact: _upload_artifact,",
            "    ListArtifactsMlflowArtifacts: _list_artifacts_mlflow_artifacts,",
            "    DeleteArtifact: _delete_artifact_mlflow_artifacts,",
            "    CreateMultipartUpload: _create_multipart_upload_artifact,",
            "    CompleteMultipartUpload: _complete_multipart_upload_artifact,",
            "    AbortMultipartUpload: _abort_multipart_upload_artifact,",
            "}"
        ],
        "afterPatchFile": [
            "# Define all the service endpoint handlers here.",
            "import json",
            "import logging",
            "import os",
            "import pathlib",
            "import posixpath",
            "import re",
            "import tempfile",
            "import time",
            "import urllib",
            "from functools import wraps",
            "",
            "import requests",
            "from flask import Response, current_app, request, send_file",
            "from google.protobuf import descriptor",
            "from google.protobuf.json_format import ParseError",
            "",
            "from mlflow.entities import DatasetInput, ExperimentTag, FileInfo, Metric, Param, RunTag, ViewType",
            "from mlflow.entities.model_registry import ModelVersionTag, RegisteredModelTag",
            "from mlflow.entities.multipart_upload import MultipartUploadPart",
            "from mlflow.environment_variables import MLFLOW_DEPLOYMENTS_TARGET",
            "from mlflow.exceptions import MlflowException, _UnsupportedMultipartUploadException",
            "from mlflow.models import Model",
            "from mlflow.protos import databricks_pb2",
            "from mlflow.protos.databricks_pb2 import (",
            "    INVALID_PARAMETER_VALUE,",
            "    RESOURCE_DOES_NOT_EXIST,",
            ")",
            "from mlflow.protos.mlflow_artifacts_pb2 import (",
            "    AbortMultipartUpload,",
            "    CompleteMultipartUpload,",
            "    CreateMultipartUpload,",
            "    DeleteArtifact,",
            "    DownloadArtifact,",
            "    MlflowArtifactsService,",
            "    UploadArtifact,",
            ")",
            "from mlflow.protos.mlflow_artifacts_pb2 import (",
            "    ListArtifacts as ListArtifactsMlflowArtifacts,",
            ")",
            "from mlflow.protos.model_registry_pb2 import (",
            "    CreateModelVersion,",
            "    CreateRegisteredModel,",
            "    DeleteModelVersion,",
            "    DeleteModelVersionTag,",
            "    DeleteRegisteredModel,",
            "    DeleteRegisteredModelAlias,",
            "    DeleteRegisteredModelTag,",
            "    GetLatestVersions,",
            "    GetModelVersion,",
            "    GetModelVersionByAlias,",
            "    GetModelVersionDownloadUri,",
            "    GetRegisteredModel,",
            "    ModelRegistryService,",
            "    RenameRegisteredModel,",
            "    SearchModelVersions,",
            "    SearchRegisteredModels,",
            "    SetModelVersionTag,",
            "    SetRegisteredModelAlias,",
            "    SetRegisteredModelTag,",
            "    TransitionModelVersionStage,",
            "    UpdateModelVersion,",
            "    UpdateRegisteredModel,",
            ")",
            "from mlflow.protos.service_pb2 import (",
            "    CreateExperiment,",
            "    CreateRun,",
            "    DeleteExperiment,",
            "    DeleteRun,",
            "    DeleteTag,",
            "    GetExperiment,",
            "    GetExperimentByName,",
            "    GetMetricHistory,",
            "    GetRun,",
            "    ListArtifacts,",
            "    LogBatch,",
            "    LogInputs,",
            "    LogMetric,",
            "    LogModel,",
            "    LogParam,",
            "    MlflowService,",
            "    RestoreExperiment,",
            "    RestoreRun,",
            "    SearchExperiments,",
            "    SearchRuns,",
            "    SetExperimentTag,",
            "    SetTag,",
            "    UpdateExperiment,",
            "    UpdateRun,",
            ")",
            "from mlflow.server.validation import _validate_content_type",
            "from mlflow.store.artifact.artifact_repo import MultipartUploadMixin",
            "from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository",
            "from mlflow.store.db.db_types import DATABASE_ENGINES",
            "from mlflow.tracking._model_registry import utils as registry_utils",
            "from mlflow.tracking._model_registry.registry import ModelRegistryStoreRegistry",
            "from mlflow.tracking._tracking_service import utils",
            "from mlflow.tracking._tracking_service.registry import TrackingStoreRegistry",
            "from mlflow.tracking.registry import UnsupportedModelRegistryStoreURIException",
            "from mlflow.utils.file_utils import local_file_uri_to_path",
            "from mlflow.utils.mime_type_utils import _guess_mime_type",
            "from mlflow.utils.promptlab_utils import _create_promptlab_run_impl",
            "from mlflow.utils.proto_json_utils import message_to_json, parse_dict",
            "from mlflow.utils.string_utils import is_string_type",
            "from mlflow.utils.uri import is_local_uri, validate_path_is_safe, validate_query_string",
            "from mlflow.utils.validation import _validate_batch_log_api_req",
            "",
            "_logger = logging.getLogger(__name__)",
            "_tracking_store = None",
            "_model_registry_store = None",
            "_artifact_repo = None",
            "STATIC_PREFIX_ENV_VAR = \"_MLFLOW_STATIC_PREFIX\"",
            "",
            "",
            "class TrackingStoreRegistryWrapper(TrackingStoreRegistry):",
            "    def __init__(self):",
            "        super().__init__()",
            "        self.register(\"\", self._get_file_store)",
            "        self.register(\"file\", self._get_file_store)",
            "        for scheme in DATABASE_ENGINES:",
            "            self.register(scheme, self._get_sqlalchemy_store)",
            "        self.register_entrypoints()",
            "",
            "    @classmethod",
            "    def _get_file_store(cls, store_uri, artifact_uri):",
            "        from mlflow.store.tracking.file_store import FileStore",
            "",
            "        return FileStore(store_uri, artifact_uri)",
            "",
            "    @classmethod",
            "    def _get_sqlalchemy_store(cls, store_uri, artifact_uri):",
            "        from mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore",
            "",
            "        return SqlAlchemyStore(store_uri, artifact_uri)",
            "",
            "",
            "class ModelRegistryStoreRegistryWrapper(ModelRegistryStoreRegistry):",
            "    def __init__(self):",
            "        super().__init__()",
            "        self.register(\"\", self._get_file_store)",
            "        self.register(\"file\", self._get_file_store)",
            "        for scheme in DATABASE_ENGINES:",
            "            self.register(scheme, self._get_sqlalchemy_store)",
            "        self.register_entrypoints()",
            "",
            "    @classmethod",
            "    def _get_file_store(cls, store_uri):",
            "        from mlflow.store.model_registry.file_store import FileStore",
            "",
            "        return FileStore(store_uri)",
            "",
            "    @classmethod",
            "    def _get_sqlalchemy_store(cls, store_uri):",
            "        from mlflow.store.model_registry.sqlalchemy_store import SqlAlchemyStore",
            "",
            "        return SqlAlchemyStore(store_uri)",
            "",
            "",
            "_tracking_store_registry = TrackingStoreRegistryWrapper()",
            "_model_registry_store_registry = ModelRegistryStoreRegistryWrapper()",
            "",
            "",
            "def _get_artifact_repo_mlflow_artifacts():",
            "    \"\"\"",
            "    Get an artifact repository specified by ``--artifacts-destination`` option for ``mlflow server``",
            "    command.",
            "    \"\"\"",
            "    from mlflow.server import ARTIFACTS_DESTINATION_ENV_VAR",
            "",
            "    global _artifact_repo",
            "    if _artifact_repo is None:",
            "        _artifact_repo = get_artifact_repository(os.environ[ARTIFACTS_DESTINATION_ENV_VAR])",
            "    return _artifact_repo",
            "",
            "",
            "def _is_serving_proxied_artifacts():",
            "    \"\"\"",
            "    :return: ``True`` if the MLflow server is serving proxied artifacts (i.e. acting as a proxy for",
            "             artifact upload / download / list operations), as would be enabled by specifying the",
            "             ``--serve-artifacts`` configuration option. ``False`` otherwise.",
            "    \"\"\"",
            "    from mlflow.server import SERVE_ARTIFACTS_ENV_VAR",
            "",
            "    return os.environ.get(SERVE_ARTIFACTS_ENV_VAR, \"false\") == \"true\"",
            "",
            "",
            "def _is_servable_proxied_run_artifact_root(run_artifact_root):",
            "    \"\"\"",
            "    Determines whether or not the following are true:",
            "",
            "    - The specified Run artifact root is a proxied artifact root (i.e. an artifact root with scheme",
            "      ``http``, ``https``, or ``mlflow-artifacts``).",
            "",
            "    - The MLflow server is capable of resolving and accessing the underlying storage location",
            "      corresponding to the proxied artifact root, allowing it to fulfill artifact list and",
            "      download requests by using this storage location directly.",
            "",
            "    :param run_artifact_root: The Run artifact root location (URI).",
            "    :return: ``True`` if the specified Run artifact root refers to proxied artifacts that can be",
            "             served by this MLflow server (i.e. the server has access to the destination and",
            "             can respond to list and download requests for the artifact). ``False`` otherwise.",
            "    \"\"\"",
            "    parsed_run_artifact_root = urllib.parse.urlparse(run_artifact_root)",
            "    # NB: If the run artifact root is a proxied artifact root (has scheme `http`, `https`, or",
            "    # `mlflow-artifacts`) *and* the MLflow server is configured to serve artifacts, the MLflow",
            "    # server always assumes that it has access to the underlying storage location for the proxied",
            "    # artifacts. This may not always be accurate. For example:",
            "    #",
            "    # An organization may initially use the MLflow server to serve Tracking API requests and proxy",
            "    # access to artifacts stored in Location A (via `mlflow server --serve-artifacts`). Then, for",
            "    # scalability and / or security purposes, the organization may decide to store artifacts in a",
            "    # new location B and set up a separate server (e.g. `mlflow server --artifacts-only`) to proxy",
            "    # access to artifacts stored in Location B.",
            "    #",
            "    # In this scenario, requests for artifacts stored in Location B that are sent to the original",
            "    # MLflow server will fail if the original MLflow server does not have access to Location B",
            "    # because it will assume that it can serve all proxied artifacts regardless of the underlying",
            "    # location. Such failures can be remediated by granting the original MLflow server access to",
            "    # Location B.",
            "    return (",
            "        parsed_run_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]",
            "        and _is_serving_proxied_artifacts()",
            "    )",
            "",
            "",
            "def _get_proxied_run_artifact_destination_path(proxied_artifact_root, relative_path=None):",
            "    \"\"\"",
            "    Resolves the specified proxied artifact location within a Run to a concrete storage location.",
            "",
            "    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,",
            "                                  ``https``, or `mlflow-artifacts` that can be resolved by the",
            "                                  MLflow server to a concrete storage location.",
            "    :param relative_path: The relative path of the destination within the specified",
            "                          ``proxied_artifact_root``. If ``None``, the destination is assumed to be",
            "                          the resolved ``proxied_artifact_root``.",
            "    :return: The storage location of the specified artifact.",
            "    \"\"\"",
            "    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)",
            "    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]",
            "",
            "    if parsed_proxied_artifact_root.scheme == \"mlflow-artifacts\":",
            "        # If the proxied artifact root is an `mlflow-artifacts` URI, the run artifact root path is",
            "        # simply the path component of the URI, since the fully-qualified format of an",
            "        # `mlflow-artifacts` URI is `mlflow-artifacts://<netloc>/path/to/artifact`",
            "        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.lstrip(\"/\")",
            "    else:",
            "        # In this case, the proxied artifact root is an HTTP(S) URL referring to an mlflow-artifacts",
            "        # API route that can be used to download the artifact. These routes are always anchored at",
            "        # `/api/2.0/mlflow-artifacts/artifacts`. Accordingly, we split the path on this route anchor",
            "        # and interpret the rest of the path (everything after the route anchor) as the run artifact",
            "        # root path",
            "        mlflow_artifacts_http_route_anchor = \"/api/2.0/mlflow-artifacts/artifacts/\"",
            "        assert mlflow_artifacts_http_route_anchor in parsed_proxied_artifact_root.path",
            "",
            "        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.split(",
            "            mlflow_artifacts_http_route_anchor",
            "        )[1].lstrip(\"/\")",
            "",
            "    return (",
            "        posixpath.join(proxied_run_artifact_root_path, relative_path)",
            "        if relative_path is not None",
            "        else proxied_run_artifact_root_path",
            "    )",
            "",
            "",
            "def _get_tracking_store(backend_store_uri=None, default_artifact_root=None):",
            "    from mlflow.server import ARTIFACT_ROOT_ENV_VAR, BACKEND_STORE_URI_ENV_VAR",
            "",
            "    global _tracking_store",
            "    if _tracking_store is None:",
            "        store_uri = backend_store_uri or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)",
            "        artifact_root = default_artifact_root or os.environ.get(ARTIFACT_ROOT_ENV_VAR, None)",
            "        _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)",
            "        utils.set_tracking_uri(store_uri)",
            "    return _tracking_store",
            "",
            "",
            "def _get_model_registry_store(registry_store_uri=None):",
            "    from mlflow.server import BACKEND_STORE_URI_ENV_VAR, REGISTRY_STORE_URI_ENV_VAR",
            "",
            "    global _model_registry_store",
            "    if _model_registry_store is None:",
            "        store_uri = (",
            "            registry_store_uri",
            "            or os.environ.get(REGISTRY_STORE_URI_ENV_VAR, None)",
            "            or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)",
            "        )",
            "        _model_registry_store = _model_registry_store_registry.get_store(store_uri)",
            "        registry_utils.set_registry_uri(store_uri)",
            "    return _model_registry_store",
            "",
            "",
            "def initialize_backend_stores(",
            "    backend_store_uri=None, registry_store_uri=None, default_artifact_root=None",
            "):",
            "    _get_tracking_store(backend_store_uri, default_artifact_root)",
            "    try:",
            "        _get_model_registry_store(registry_store_uri)",
            "    except UnsupportedModelRegistryStoreURIException:",
            "        pass",
            "",
            "",
            "def _assert_string(x):",
            "    assert isinstance(x, str)",
            "",
            "",
            "def _assert_intlike(x):",
            "    try:",
            "        x = int(x)",
            "    except ValueError:",
            "        pass",
            "",
            "    assert isinstance(x, int)",
            "",
            "",
            "def _assert_bool(x):",
            "    assert isinstance(x, bool)",
            "",
            "",
            "def _assert_floatlike(x):",
            "    try:",
            "        x = float(x)",
            "    except ValueError:",
            "        pass",
            "",
            "    assert isinstance(x, float)",
            "",
            "",
            "def _assert_array(x):",
            "    assert isinstance(x, list)",
            "",
            "",
            "def _assert_required(x):",
            "    assert x is not None",
            "    # When parsing JSON payloads via proto, absent string fields",
            "    # are expressed as empty strings",
            "    assert x != \"\"",
            "",
            "",
            "def _assert_less_than_or_equal(x, max_value):",
            "    assert x <= max_value",
            "",
            "",
            "def _assert_item_type_string(x):",
            "    assert all(isinstance(item, str) for item in x)",
            "",
            "",
            "_TYPE_VALIDATORS = {",
            "    _assert_intlike,",
            "    _assert_string,",
            "    _assert_bool,",
            "    _assert_floatlike,",
            "    _assert_array,",
            "    _assert_item_type_string,",
            "}",
            "",
            "",
            "def _validate_param_against_schema(schema, param, value, proto_parsing_succeeded=False):",
            "    \"\"\"",
            "    Attempts to validate a single parameter against a specified schema.",
            "    Examples of the elements of the schema are type assertions and checks for required parameters.",
            "    Returns None on validation success. Otherwise, raises an MLFlowException if an assertion fails.",
            "    This method is intended to be called for side effects.",
            "",
            "            Parameters:",
            "    :param schema: A list of functions to validate the parameter against.",
            "    :param param: The string name of the parameter being validated.",
            "    :param value: The corresponding value of the `param` being validated.",
            "    :param proto_parsing_succeeded: A boolean value indicating whether proto parsing succeeded.",
            "                                    If the proto was successfully parsed, we assume all of the types",
            "                                    of the parameters in the request body were correctly specified,",
            "                                    and thus we skip validating types. If proto parsing failed,",
            "                                    then we validate types in addition to the rest of the schema.",
            "                                    For details, see https://github.com/mlflow/mlflow/pull/",
            "                                    5458#issuecomment-1080880870.",
            "    \"\"\"",
            "",
            "    for f in schema:",
            "        if f in _TYPE_VALIDATORS and proto_parsing_succeeded:",
            "            continue",
            "",
            "        try:",
            "            f(value)",
            "        except AssertionError:",
            "            if f == _assert_required:",
            "                message = f\"Missing value for required parameter '{param}'.\"",
            "            else:",
            "                message = (",
            "                    f\"Invalid value {value} for parameter '{param}' supplied.\"",
            "                    f\" Hint: Value was of type '{type(value).__name__}'.\"",
            "                )",
            "            raise MlflowException(",
            "                message=(",
            "                    message + \" See the API docs for more information about request parameters.\"",
            "                ),",
            "                error_code=INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "    return None",
            "",
            "",
            "def _get_request_json(flask_request=request):",
            "    _validate_content_type(flask_request, [\"application/json\"])",
            "    return flask_request.get_json(force=True, silent=True)",
            "",
            "",
            "def _get_request_message(request_message, flask_request=request, schema=None):",
            "    from querystring_parser import parser",
            "",
            "    if flask_request.method == \"GET\" and len(flask_request.query_string) > 0:",
            "        # This is a hack to make arrays of length 1 work with the parser.",
            "        # for example experiment_ids%5B%5D=0 should be parsed to {experiment_ids: [0]}",
            "        # but it gets parsed to {experiment_ids: 0}",
            "        # but it doesn't. However, experiment_ids%5B0%5D=0 will get parsed to the right",
            "        # result.",
            "        query_string = re.sub(\"%5B%5D\", \"%5B0%5D\", flask_request.query_string.decode(\"utf-8\"))",
            "        request_dict = parser.parse(query_string, normalized=True)",
            "        # Convert atomic values of repeated fields to lists before calling protobuf deserialization.",
            "        # Context: We parse the parameter string into a dictionary outside of protobuf since",
            "        # protobuf does not know how to read the query parameters directly. The query parser above",
            "        # has no type information and hence any parameter that occurs exactly once is parsed as an",
            "        # atomic value. Since protobuf requires that the values of repeated fields are lists,",
            "        # deserialization will fail unless we do the fix below.",
            "        for field in request_message.DESCRIPTOR.fields:",
            "            if (",
            "                field.label == descriptor.FieldDescriptor.LABEL_REPEATED",
            "                and field.name in request_dict",
            "            ):",
            "                if not isinstance(request_dict[field.name], list):",
            "                    request_dict[field.name] = [request_dict[field.name]]",
            "        parse_dict(request_dict, request_message)",
            "        return request_message",
            "",
            "    request_json = _get_request_json(flask_request)",
            "",
            "    # Older clients may post their JSON double-encoded as strings, so the get_json",
            "    # above actually converts it to a string. Therefore, we check this condition",
            "    # (which we can tell for sure because any proper request should be a dictionary),",
            "    # and decode it a second time.",
            "    if is_string_type(request_json):",
            "        request_json = json.loads(request_json)",
            "",
            "    # If request doesn't have json body then assume it's empty.",
            "    if request_json is None:",
            "        request_json = {}",
            "",
            "    proto_parsing_succeeded = True",
            "    try:",
            "        parse_dict(request_json, request_message)",
            "    except ParseError:",
            "        proto_parsing_succeeded = False",
            "",
            "    schema = schema or {}",
            "    for schema_key, schema_validation_fns in schema.items():",
            "        if schema_key in request_json or _assert_required in schema_validation_fns:",
            "            value = request_json.get(schema_key)",
            "            if schema_key == \"run_id\" and value is None and \"run_uuid\" in request_json:",
            "                value = request_json.get(\"run_uuid\")",
            "            _validate_param_against_schema(",
            "                schema=schema_validation_fns,",
            "                param=schema_key,",
            "                value=value,",
            "                proto_parsing_succeeded=proto_parsing_succeeded,",
            "            )",
            "",
            "    return request_message",
            "",
            "",
            "def _response_with_file_attachment_headers(file_path, response):",
            "    mime_type = _guess_mime_type(file_path)",
            "    filename = pathlib.Path(file_path).name",
            "    response.mimetype = mime_type",
            "    content_disposition_header_name = \"Content-Disposition\"",
            "    if content_disposition_header_name not in response.headers:",
            "        response.headers[content_disposition_header_name] = f\"attachment; filename={filename}\"",
            "    response.headers[\"X-Content-Type-Options\"] = \"nosniff\"",
            "    response.headers[\"Content-Type\"] = mime_type",
            "    return response",
            "",
            "",
            "def _send_artifact(artifact_repository, path):",
            "    file_path = os.path.abspath(artifact_repository.download_artifacts(path))",
            "    # Always send artifacts as attachments to prevent the browser from displaying them on our web",
            "    # server's domain, which might enable XSS.",
            "    mime_type = _guess_mime_type(file_path)",
            "    file_sender_response = send_file(file_path, mimetype=mime_type, as_attachment=True)",
            "    return _response_with_file_attachment_headers(file_path, file_sender_response)",
            "",
            "",
            "def catch_mlflow_exception(func):",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        try:",
            "            return func(*args, **kwargs)",
            "        except MlflowException as e:",
            "            response = Response(mimetype=\"application/json\")",
            "            response.set_data(e.serialize_as_json())",
            "            response.status_code = e.get_http_status_code()",
            "            return response",
            "",
            "    return wrapper",
            "",
            "",
            "def _disable_unless_serve_artifacts(func):",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        if not _is_serving_proxied_artifacts():",
            "            return Response(",
            "                (",
            "                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"",
            "                    \"with `--no-serve-artifacts`. To enable artifacts server functionality, \"",
            "                    \"run `mlflow server` with `--serve-artifacts`\"",
            "                ),",
            "                503,",
            "            )",
            "        return func(*args, **kwargs)",
            "",
            "    return wrapper",
            "",
            "",
            "def _disable_if_artifacts_only(func):",
            "    @wraps(func)",
            "    def wrapper(*args, **kwargs):",
            "        from mlflow.server import ARTIFACTS_ONLY_ENV_VAR",
            "",
            "        if os.environ.get(ARTIFACTS_ONLY_ENV_VAR):",
            "            return Response(",
            "                (",
            "                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"",
            "                    \"in `--artifacts-only` mode. To enable tracking server functionality, run \"",
            "                    \"`mlflow server` without `--artifacts-only`\"",
            "                ),",
            "                503,",
            "            )",
            "        return func(*args, **kwargs)",
            "",
            "    return wrapper",
            "",
            "",
            "@catch_mlflow_exception",
            "def get_artifact_handler():",
            "    from querystring_parser import parser",
            "",
            "    query_string = request.query_string.decode(\"utf-8\")",
            "    request_dict = parser.parse(query_string, normalized=True)",
            "    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")",
            "    path = request_dict[\"path\"]",
            "    path = validate_path_is_safe(path)",
            "    run = _get_tracking_store().get_run(run_id)",
            "",
            "    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):",
            "        artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "        artifact_path = _get_proxied_run_artifact_destination_path(",
            "            proxied_artifact_root=run.info.artifact_uri,",
            "            relative_path=path,",
            "        )",
            "    else:",
            "        artifact_repo = _get_artifact_repo(run)",
            "        artifact_path = path",
            "",
            "    return _send_artifact(artifact_repo, artifact_path)",
            "",
            "",
            "def _not_implemented():",
            "    response = Response()",
            "    response.status_code = 404",
            "    return response",
            "",
            "",
            "# Tracking Server APIs",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_experiment():",
            "    request_message = _get_request_message(",
            "        CreateExperiment(),",
            "        schema={",
            "            \"name\": [_assert_required, _assert_string],",
            "            \"artifact_location\": [_assert_string],",
            "            \"tags\": [_assert_array],",
            "        },",
            "    )",
            "",
            "    tags = [ExperimentTag(tag.key, tag.value) for tag in request_message.tags]",
            "",
            "    # Validate query string in artifact location to prevent attacks",
            "    parsed_artifact_locaion = urllib.parse.urlparse(request_message.artifact_location)",
            "    validate_query_string(parsed_artifact_locaion.query)",
            "",
            "    experiment_id = _get_tracking_store().create_experiment(",
            "        request_message.name, request_message.artifact_location, tags",
            "    )",
            "    response_message = CreateExperiment.Response()",
            "    response_message.experiment_id = experiment_id",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_experiment():",
            "    request_message = _get_request_message(",
            "        GetExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}",
            "    )",
            "    response_message = GetExperiment.Response()",
            "    experiment = _get_tracking_store().get_experiment(request_message.experiment_id).to_proto()",
            "    response_message.experiment.MergeFrom(experiment)",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_experiment_by_name():",
            "    request_message = _get_request_message(",
            "        GetExperimentByName(), schema={\"experiment_name\": [_assert_required, _assert_string]}",
            "    )",
            "    response_message = GetExperimentByName.Response()",
            "    store_exp = _get_tracking_store().get_experiment_by_name(request_message.experiment_name)",
            "    if store_exp is None:",
            "        raise MlflowException(",
            "            f\"Could not find experiment with name '{request_message.experiment_name}'\",",
            "            error_code=RESOURCE_DOES_NOT_EXIST,",
            "        )",
            "    experiment = store_exp.to_proto()",
            "    response_message.experiment.MergeFrom(experiment)",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_experiment():",
            "    request_message = _get_request_message(",
            "        DeleteExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().delete_experiment(request_message.experiment_id)",
            "    response_message = DeleteExperiment.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _restore_experiment():",
            "    request_message = _get_request_message(",
            "        RestoreExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().restore_experiment(request_message.experiment_id)",
            "    response_message = RestoreExperiment.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_experiment():",
            "    request_message = _get_request_message(",
            "        UpdateExperiment(),",
            "        schema={",
            "            \"experiment_id\": [_assert_required, _assert_string],",
            "            \"new_name\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    if request_message.new_name:",
            "        _get_tracking_store().rename_experiment(",
            "            request_message.experiment_id, request_message.new_name",
            "        )",
            "    response_message = UpdateExperiment.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_run():",
            "    request_message = _get_request_message(",
            "        CreateRun(),",
            "        schema={",
            "            \"experiment_id\": [_assert_string],",
            "            \"start_time\": [_assert_intlike],",
            "            \"run_name\": [_assert_string],",
            "        },",
            "    )",
            "",
            "    tags = [RunTag(tag.key, tag.value) for tag in request_message.tags]",
            "    run = _get_tracking_store().create_run(",
            "        experiment_id=request_message.experiment_id,",
            "        user_id=request_message.user_id,",
            "        start_time=request_message.start_time,",
            "        tags=tags,",
            "        run_name=request_message.run_name,",
            "    )",
            "",
            "    response_message = CreateRun.Response()",
            "    response_message.run.MergeFrom(run.to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_run():",
            "    request_message = _get_request_message(",
            "        UpdateRun(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"end_time\": [_assert_intlike],",
            "            \"status\": [_assert_string],",
            "            \"run_name\": [_assert_string],",
            "        },",
            "    )",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    run_name = request_message.run_name if request_message.HasField(\"run_name\") else None",
            "    end_time = request_message.end_time if request_message.HasField(\"end_time\") else None",
            "    status = request_message.status if request_message.HasField(\"status\") else None",
            "    updated_info = _get_tracking_store().update_run_info(run_id, status, end_time, run_name)",
            "    response_message = UpdateRun.Response(run_info=updated_info.to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_run():",
            "    request_message = _get_request_message(",
            "        DeleteRun(), schema={\"run_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().delete_run(request_message.run_id)",
            "    response_message = DeleteRun.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _restore_run():",
            "    request_message = _get_request_message(",
            "        RestoreRun(), schema={\"run_id\": [_assert_required, _assert_string]}",
            "    )",
            "    _get_tracking_store().restore_run(request_message.run_id)",
            "    response_message = RestoreRun.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_metric():",
            "    request_message = _get_request_message(",
            "        LogMetric(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_required, _assert_floatlike],",
            "            \"timestamp\": [_assert_intlike, _assert_required],",
            "            \"step\": [_assert_intlike],",
            "        },",
            "    )",
            "    metric = Metric(",
            "        request_message.key, request_message.value, request_message.timestamp, request_message.step",
            "    )",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    _get_tracking_store().log_metric(run_id, metric)",
            "    response_message = LogMetric.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_param():",
            "    request_message = _get_request_message(",
            "        LogParam(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    param = Param(request_message.key, request_message.value)",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    _get_tracking_store().log_param(run_id, param)",
            "    response_message = LogParam.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_inputs():",
            "    request_message = _get_request_message(",
            "        LogInputs(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"datasets\": [_assert_required, _assert_array],",
            "        },",
            "    )",
            "    run_id = request_message.run_id",
            "    datasets = [",
            "        DatasetInput.from_proto(proto_dataset_input)",
            "        for proto_dataset_input in request_message.datasets",
            "    ]",
            "",
            "    _get_tracking_store().log_inputs(run_id, datasets=datasets)",
            "    response_message = LogInputs.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_experiment_tag():",
            "    request_message = _get_request_message(",
            "        SetExperimentTag(),",
            "        schema={",
            "            \"experiment_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = ExperimentTag(request_message.key, request_message.value)",
            "    _get_tracking_store().set_experiment_tag(request_message.experiment_id, tag)",
            "    response_message = SetExperimentTag.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_tag():",
            "    request_message = _get_request_message(",
            "        SetTag(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = RunTag(request_message.key, request_message.value)",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    _get_tracking_store().set_tag(run_id, tag)",
            "    response_message = SetTag.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_tag():",
            "    request_message = _get_request_message(",
            "        DeleteTag(),",
            "        schema={",
            "            \"run_id\": [_assert_required, _assert_string],",
            "            \"key\": [_assert_required, _assert_string],",
            "        },",
            "    )",
            "    _get_tracking_store().delete_tag(request_message.run_id, request_message.key)",
            "    response_message = DeleteTag.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_run():",
            "    request_message = _get_request_message(",
            "        GetRun(), schema={\"run_id\": [_assert_required, _assert_string]}",
            "    )",
            "    response_message = GetRun.Response()",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    response_message.run.MergeFrom(_get_tracking_store().get_run(run_id).to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_runs():",
            "    request_message = _get_request_message(",
            "        SearchRuns(),",
            "        schema={",
            "            \"experiment_ids\": [_assert_array],",
            "            \"filter\": [_assert_string],",
            "            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 50000)],",
            "            \"order_by\": [_assert_array, _assert_item_type_string],",
            "        },",
            "    )",
            "    response_message = SearchRuns.Response()",
            "    run_view_type = ViewType.ACTIVE_ONLY",
            "    if request_message.HasField(\"run_view_type\"):",
            "        run_view_type = ViewType.from_proto(request_message.run_view_type)",
            "    filter_string = request_message.filter",
            "    max_results = request_message.max_results",
            "    experiment_ids = request_message.experiment_ids",
            "    order_by = request_message.order_by",
            "    page_token = request_message.page_token",
            "    run_entities = _get_tracking_store().search_runs(",
            "        experiment_ids, filter_string, run_view_type, max_results, order_by, page_token",
            "    )",
            "    response_message.runs.extend([r.to_proto() for r in run_entities])",
            "    if run_entities.token:",
            "        response_message.next_page_token = run_entities.token",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _list_artifacts():",
            "    request_message = _get_request_message(",
            "        ListArtifacts(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"path\": [_assert_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    response_message = ListArtifacts.Response()",
            "    if request_message.HasField(\"path\"):",
            "        path = request_message.path",
            "        path = validate_path_is_safe(path)",
            "    else:",
            "        path = None",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    run = _get_tracking_store().get_run(run_id)",
            "",
            "    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):",
            "        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(",
            "            proxied_artifact_root=run.info.artifact_uri,",
            "            relative_path=path,",
            "        )",
            "    else:",
            "        artifact_entities = _get_artifact_repo(run).list_artifacts(path)",
            "",
            "    response_message.files.extend([a.to_proto() for a in artifact_entities])",
            "    response_message.root_uri = run.info.artifact_uri",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "def _list_artifacts_for_proxied_run_artifact_root(proxied_artifact_root, relative_path=None):",
            "    \"\"\"",
            "    Lists artifacts from the specified ``relative_path`` within the specified proxied Run artifact",
            "    root (i.e. a Run artifact root with scheme ``http``, ``https``, or ``mlflow-artifacts``).",
            "",
            "    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,",
            "                                  ``https``, or ``mlflow-artifacts`` that can be resolved by the",
            "                                  MLflow server to a concrete storage location.",
            "    :param relative_path: The relative path within the specified ``proxied_artifact_root`` under",
            "                          which to list artifact contents. If ``None``, artifacts are listed from",
            "                          the ``proxied_artifact_root`` directory.",
            "    \"\"\"",
            "    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)",
            "    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]",
            "",
            "    artifact_destination_repo = _get_artifact_repo_mlflow_artifacts()",
            "    artifact_destination_path = _get_proxied_run_artifact_destination_path(",
            "        proxied_artifact_root=proxied_artifact_root,",
            "        relative_path=relative_path,",
            "    )",
            "",
            "    artifact_entities = []",
            "    for file_info in artifact_destination_repo.list_artifacts(artifact_destination_path):",
            "        basename = posixpath.basename(file_info.path)",
            "        run_relative_artifact_path = (",
            "            posixpath.join(relative_path, basename) if relative_path else basename",
            "        )",
            "        artifact_entities.append(",
            "            FileInfo(run_relative_artifact_path, file_info.is_dir, file_info.file_size)",
            "        )",
            "",
            "    return artifact_entities",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_metric_history():",
            "    request_message = _get_request_message(",
            "        GetMetricHistory(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"metric_key\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    response_message = GetMetricHistory.Response()",
            "    run_id = request_message.run_id or request_message.run_uuid",
            "    metric_entities = _get_tracking_store().get_metric_history(run_id, request_message.metric_key)",
            "    response_message.metrics.extend([m.to_proto() for m in metric_entities])",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def get_metric_history_bulk_handler():",
            "    MAX_HISTORY_RESULTS = 25000",
            "    MAX_RUN_IDS_PER_REQUEST = 20",
            "    run_ids = request.args.to_dict(flat=False).get(\"run_id\", [])",
            "    if not run_ids:",
            "        raise MlflowException(",
            "            message=\"GetMetricHistoryBulk request must specify at least one run_id.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    if len(run_ids) > MAX_RUN_IDS_PER_REQUEST:",
            "        raise MlflowException(",
            "            message=(",
            "                f\"GetMetricHistoryBulk request cannot specify more than {MAX_RUN_IDS_PER_REQUEST}\"",
            "                f\" run_ids. Received {len(run_ids)} run_ids.\"",
            "            ),",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    metric_key = request.args.get(\"metric_key\")",
            "    if metric_key is None:",
            "        raise MlflowException(",
            "            message=\"GetMetricHistoryBulk request must specify a metric_key.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    max_results = int(request.args.get(\"max_results\", MAX_HISTORY_RESULTS))",
            "    max_results = min(max_results, MAX_HISTORY_RESULTS)",
            "",
            "    store = _get_tracking_store()",
            "",
            "    def _default_history_bulk_impl():",
            "        metrics_with_run_ids = []",
            "        for run_id in sorted(run_ids):",
            "            metrics_for_run = sorted(",
            "                store.get_metric_history(",
            "                    run_id=run_id,",
            "                    metric_key=metric_key,",
            "                    max_results=max_results,",
            "                ),",
            "                key=lambda metric: (metric.timestamp, metric.step, metric.value),",
            "            )",
            "            metrics_with_run_ids.extend(",
            "                [",
            "                    {",
            "                        \"key\": metric.key,",
            "                        \"value\": metric.value,",
            "                        \"timestamp\": metric.timestamp,",
            "                        \"step\": metric.step,",
            "                        \"run_id\": run_id,",
            "                    }",
            "                    for metric in metrics_for_run",
            "                ]",
            "            )",
            "        return metrics_with_run_ids",
            "",
            "    if hasattr(store, \"get_metric_history_bulk\"):",
            "        metrics_with_run_ids = [",
            "            metric.to_dict()",
            "            for metric in store.get_metric_history_bulk(",
            "                run_ids=run_ids,",
            "                metric_key=metric_key,",
            "                max_results=max_results,",
            "            )",
            "        ]",
            "    else:",
            "        metrics_with_run_ids = _default_history_bulk_impl()",
            "",
            "    return {",
            "        \"metrics\": metrics_with_run_ids[:max_results],",
            "    }",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def search_datasets_handler():",
            "    MAX_EXPERIMENT_IDS_PER_REQUEST = 20",
            "    _validate_content_type(request, [\"application/json\"])",
            "    experiment_ids = request.json.get(\"experiment_ids\", [])",
            "    if not experiment_ids:",
            "        raise MlflowException(",
            "            message=\"SearchDatasets request must specify at least one experiment_id.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    if len(experiment_ids) > MAX_EXPERIMENT_IDS_PER_REQUEST:",
            "        raise MlflowException(",
            "            message=(",
            "                f\"SearchDatasets request cannot specify more than {MAX_EXPERIMENT_IDS_PER_REQUEST}\"",
            "                f\" experiment_ids. Received {len(experiment_ids)} experiment_ids.\"",
            "            ),",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    store = _get_tracking_store()",
            "",
            "    if hasattr(store, \"_search_datasets\"):",
            "        return {",
            "            \"dataset_summaries\": [",
            "                summary.to_dict() for summary in store._search_datasets(experiment_ids)",
            "            ]",
            "        }",
            "    else:",
            "        return _not_implemented()",
            "",
            "",
            "@catch_mlflow_exception",
            "def gateway_proxy_handler():",
            "    target_uri = MLFLOW_DEPLOYMENTS_TARGET.get()",
            "    if not target_uri:",
            "        # Pretend an empty gateway service is running",
            "        return {\"endpoints\": []}",
            "",
            "    args = request.args if request.method == \"GET\" else request.json",
            "",
            "    gateway_path = args.get(\"gateway_path\")",
            "    if not gateway_path:",
            "        raise MlflowException(",
            "            message=\"Deployments proxy request must specify a gateway_path.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    request_type = request.method",
            "    json_data = args.get(\"json_data\", None)",
            "",
            "    response = requests.request(request_type, f\"{target_uri}/{gateway_path}\", json=json_data)",
            "",
            "    if response.status_code == 200:",
            "        return response.json()",
            "    else:",
            "        raise MlflowException(",
            "            message=f\"Deployments proxy request failed with error code {response.status_code}. \"",
            "            f\"Error message: {response.text}\",",
            "            error_code=response.status_code,",
            "        )",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def create_promptlab_run_handler():",
            "    def assert_arg_exists(arg_name, arg):",
            "        if not arg:",
            "            raise MlflowException(",
            "                message=f\"CreatePromptlabRun request must specify {arg_name}.\",",
            "                error_code=INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "    _validate_content_type(request, [\"application/json\"])",
            "",
            "    args = request.json",
            "    experiment_id = args.get(\"experiment_id\")",
            "    assert_arg_exists(\"experiment_id\", experiment_id)",
            "    run_name = args.get(\"run_name\", None)",
            "    tags = args.get(\"tags\", [])",
            "    prompt_template = args.get(\"prompt_template\")",
            "    assert_arg_exists(\"prompt_template\", prompt_template)",
            "    raw_prompt_parameters = args.get(\"prompt_parameters\")",
            "    assert_arg_exists(\"prompt_parameters\", raw_prompt_parameters)",
            "    prompt_parameters = [",
            "        Param(param.get(\"key\"), param.get(\"value\")) for param in args.get(\"prompt_parameters\")",
            "    ]",
            "    model_route = args.get(\"model_route\")",
            "    assert_arg_exists(\"model_route\", model_route)",
            "    raw_model_parameters = args.get(\"model_parameters\", [])",
            "    model_parameters = [",
            "        Param(param.get(\"key\"), param.get(\"value\")) for param in raw_model_parameters",
            "    ]",
            "    model_input = args.get(\"model_input\")",
            "    assert_arg_exists(\"model_input\", model_input)",
            "    model_output = args.get(\"model_output\", None)",
            "    raw_model_output_parameters = args.get(\"model_output_parameters\", [])",
            "    model_output_parameters = [",
            "        Param(param.get(\"key\"), param.get(\"value\")) for param in raw_model_output_parameters",
            "    ]",
            "    mlflow_version = args.get(\"mlflow_version\")",
            "    assert_arg_exists(\"mlflow_version\", mlflow_version)",
            "    user_id = args.get(\"user_id\", \"unknown\")",
            "",
            "    # use current time if not provided",
            "    start_time = args.get(\"start_time\", int(time.time() * 1000))",
            "",
            "    store = _get_tracking_store()",
            "",
            "    run = _create_promptlab_run_impl(",
            "        store,",
            "        experiment_id=experiment_id,",
            "        run_name=run_name,",
            "        tags=tags,",
            "        prompt_template=prompt_template,",
            "        prompt_parameters=prompt_parameters,",
            "        model_route=model_route,",
            "        model_parameters=model_parameters,",
            "        model_input=model_input,",
            "        model_output=model_output,",
            "        model_output_parameters=model_output_parameters,",
            "        mlflow_version=mlflow_version,",
            "        user_id=user_id,",
            "        start_time=start_time,",
            "    )",
            "    response_message = CreateRun.Response()",
            "    response_message.run.MergeFrom(run.to_proto())",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "def upload_artifact_handler():",
            "    args = request.args",
            "    run_uuid = args.get(\"run_uuid\")",
            "    if not run_uuid:",
            "        raise MlflowException(",
            "            message=\"Request must specify run_uuid.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    path = args.get(\"path\")",
            "    if not path:",
            "        raise MlflowException(",
            "            message=\"Request must specify path.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    path = validate_path_is_safe(path)",
            "",
            "    if request.content_length and request.content_length > 10 * 1024 * 1024:",
            "        raise MlflowException(",
            "            message=\"Artifact size is too large. Max size is 10MB.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    data = request.data",
            "    if not data:",
            "        raise MlflowException(",
            "            message=\"Request must specify data.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    run = _get_tracking_store().get_run(run_uuid)",
            "    artifact_dir = run.info.artifact_uri",
            "",
            "    basename = posixpath.basename(path)",
            "    dirname = posixpath.dirname(path)",
            "",
            "    def _log_artifact_to_repo(file, run, dirname, artifact_dir):",
            "        if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):",
            "            artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "            path_to_log = (",
            "                os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\", dirname)",
            "                if dirname",
            "                else os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\")",
            "            )",
            "        else:",
            "            artifact_repo = get_artifact_repository(artifact_dir)",
            "            path_to_log = dirname",
            "",
            "        artifact_repo.log_artifact(file, path_to_log)",
            "",
            "    with tempfile.TemporaryDirectory() as tmpdir:",
            "        dir_path = os.path.join(tmpdir, dirname) if dirname else tmpdir",
            "        file_path = os.path.join(dir_path, basename)",
            "",
            "        os.makedirs(dir_path, exist_ok=True)",
            "",
            "        with open(file_path, \"wb\") as f:",
            "            f.write(data)",
            "",
            "        _log_artifact_to_repo(file_path, run, dirname, artifact_dir)",
            "",
            "    return Response(mimetype=\"application/json\")",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_experiments():",
            "    request_message = _get_request_message(",
            "        SearchExperiments(),",
            "        schema={",
            "            \"view_type\": [_assert_intlike],",
            "            \"max_results\": [_assert_intlike],",
            "            \"order_by\": [_assert_array],",
            "            \"filter\": [_assert_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    experiment_entities = _get_tracking_store().search_experiments(",
            "        view_type=request_message.view_type,",
            "        max_results=request_message.max_results,",
            "        order_by=request_message.order_by,",
            "        filter_string=request_message.filter,",
            "        page_token=request_message.page_token,",
            "    )",
            "    response_message = SearchExperiments.Response()",
            "    response_message.experiments.extend([e.to_proto() for e in experiment_entities])",
            "    if experiment_entities.token:",
            "        response_message.next_page_token = experiment_entities.token",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "def _get_artifact_repo(run):",
            "    return get_artifact_repository(run.info.artifact_uri)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_batch():",
            "    def _assert_metrics_fields_present(metrics):",
            "        for m in metrics:",
            "            _assert_required(m.get(\"key\"))",
            "            _assert_required(m.get(\"value\"))",
            "            _assert_required(m.get(\"timestamp\"))",
            "",
            "    def _assert_params_tags_fields_present(params_or_tags):",
            "        for param_or_tag in params_or_tags:",
            "            _assert_required(param_or_tag.get(\"key\"))",
            "",
            "    _validate_batch_log_api_req(_get_request_json())",
            "    request_message = _get_request_message(",
            "        LogBatch(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"metrics\": [_assert_array, _assert_metrics_fields_present],",
            "            \"params\": [_assert_array, _assert_params_tags_fields_present],",
            "            \"tags\": [_assert_array, _assert_params_tags_fields_present],",
            "        },",
            "    )",
            "    metrics = [Metric.from_proto(proto_metric) for proto_metric in request_message.metrics]",
            "    params = [Param.from_proto(proto_param) for proto_param in request_message.params]",
            "    tags = [RunTag.from_proto(proto_tag) for proto_tag in request_message.tags]",
            "    _get_tracking_store().log_batch(",
            "        run_id=request_message.run_id, metrics=metrics, params=params, tags=tags",
            "    )",
            "    response_message = LogBatch.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _log_model():",
            "    request_message = _get_request_message(",
            "        LogModel(),",
            "        schema={",
            "            \"run_id\": [_assert_string, _assert_required],",
            "            \"model_json\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    try:",
            "        model = json.loads(request_message.model_json)",
            "    except Exception:",
            "        raise MlflowException(",
            "            f\"Malformed model info. \\n {request_message.model_json} \\n is not a valid JSON.\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    missing_fields = {\"artifact_path\", \"flavors\", \"utc_time_created\", \"run_id\"} - set(model.keys())",
            "",
            "    if missing_fields:",
            "        raise MlflowException(",
            "            f\"Model json is missing mandatory fields: {missing_fields}\",",
            "            error_code=INVALID_PARAMETER_VALUE,",
            "        )",
            "    _get_tracking_store().record_logged_model(",
            "        run_id=request_message.run_id, mlflow_model=Model.from_dict(model)",
            "    )",
            "    response_message = LogModel.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "def _wrap_response(response_message):",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "# Model Registry APIs",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_registered_model():",
            "    request_message = _get_request_message(",
            "        CreateRegisteredModel(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"tags\": [_assert_array],",
            "            \"description\": [_assert_string],",
            "        },",
            "    )",
            "    registered_model = _get_model_registry_store().create_registered_model(",
            "        name=request_message.name,",
            "        tags=request_message.tags,",
            "        description=request_message.description,",
            "    )",
            "    response_message = CreateRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_registered_model():",
            "    request_message = _get_request_message(",
            "        GetRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}",
            "    )",
            "    registered_model = _get_model_registry_store().get_registered_model(name=request_message.name)",
            "    response_message = GetRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_registered_model():",
            "    request_message = _get_request_message(",
            "        UpdateRegisteredModel(),",
            "        schema={\"name\": [_assert_string, _assert_required], \"description\": [_assert_string]},",
            "    )",
            "    name = request_message.name",
            "    new_description = request_message.description",
            "    registered_model = _get_model_registry_store().update_registered_model(",
            "        name=name, description=new_description",
            "    )",
            "    response_message = UpdateRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _rename_registered_model():",
            "    request_message = _get_request_message(",
            "        RenameRegisteredModel(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"new_name\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    name = request_message.name",
            "    new_name = request_message.new_name",
            "    registered_model = _get_model_registry_store().rename_registered_model(",
            "        name=name, new_name=new_name",
            "    )",
            "    response_message = RenameRegisteredModel.Response(registered_model=registered_model.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_registered_model():",
            "    request_message = _get_request_message(",
            "        DeleteRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}",
            "    )",
            "    _get_model_registry_store().delete_registered_model(name=request_message.name)",
            "    return _wrap_response(DeleteRegisteredModel.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_registered_models():",
            "    request_message = _get_request_message(",
            "        SearchRegisteredModels(),",
            "        schema={",
            "            \"filter\": [_assert_string],",
            "            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 1000)],",
            "            \"order_by\": [_assert_array, _assert_item_type_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    store = _get_model_registry_store()",
            "    registered_models = store.search_registered_models(",
            "        filter_string=request_message.filter,",
            "        max_results=request_message.max_results,",
            "        order_by=request_message.order_by,",
            "        page_token=request_message.page_token,",
            "    )",
            "    response_message = SearchRegisteredModels.Response()",
            "    response_message.registered_models.extend([e.to_proto() for e in registered_models])",
            "    if registered_models.token:",
            "        response_message.next_page_token = registered_models.token",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_latest_versions():",
            "    request_message = _get_request_message(",
            "        GetLatestVersions(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"stages\": [_assert_array, _assert_item_type_string],",
            "        },",
            "    )",
            "    latest_versions = _get_model_registry_store().get_latest_versions(",
            "        name=request_message.name, stages=request_message.stages",
            "    )",
            "    response_message = GetLatestVersions.Response()",
            "    response_message.model_versions.extend([e.to_proto() for e in latest_versions])",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_registered_model_tag():",
            "    request_message = _get_request_message(",
            "        SetRegisteredModelTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = RegisteredModelTag(key=request_message.key, value=request_message.value)",
            "    _get_model_registry_store().set_registered_model_tag(name=request_message.name, tag=tag)",
            "    return _wrap_response(SetRegisteredModelTag.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_registered_model_tag():",
            "    request_message = _get_request_message(",
            "        DeleteRegisteredModelTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_registered_model_tag(",
            "        name=request_message.name, key=request_message.key",
            "    )",
            "    return _wrap_response(DeleteRegisteredModelTag.Response())",
            "",
            "",
            "def _validate_non_local_source_contains_relative_paths(source: str):",
            "    \"\"\"",
            "    Validation check to ensure that sources that are provided that conform to the schemes:",
            "    http, https, or mlflow-artifacts do not contain relative path designations that are intended",
            "    to access local file system paths on the tracking server.",
            "",
            "    Example paths that this validation function is intended to find and raise an Exception if",
            "    passed:",
            "    \"mlflow-artifacts://host:port/../../../../\"",
            "    \"http://host:port/api/2.0/mlflow-artifacts/artifacts/../../../../\"",
            "    \"https://host:port/api/2.0/mlflow-artifacts/artifacts/../../../../\"",
            "    \"/models/artifacts/../../../\"",
            "    \"s3:/my_bucket/models/path/../../other/path\"",
            "    \"file://path/to/../../../../some/where/you/should/not/be\"",
            "    \"mlflow-artifacts://host:port/..%2f..%2f..%2f..%2f\"",
            "    \"http://host:port/api/2.0/mlflow-artifacts/artifacts%00\"",
            "    \"\"\"",
            "    invalid_source_error_message = (",
            "        f\"Invalid model version source: '{source}'. If supplying a source as an http, https, \"",
            "        \"local file path, ftp, objectstore, or mlflow-artifacts uri, an absolute path must be \"",
            "        \"provided without relative path references present. \"",
            "        \"Please provide an absolute path.\"",
            "    )",
            "",
            "    while (unquoted := urllib.parse.unquote_plus(source)) != source:",
            "        source = unquoted",
            "    source_path = re.sub(r\"/+\", \"/\", urllib.parse.urlparse(source).path.rstrip(\"/\"))",
            "    if \"\\x00\" in source_path:",
            "        raise MlflowException(invalid_source_error_message, INVALID_PARAMETER_VALUE)",
            "    resolved_source = pathlib.Path(source_path).resolve().as_posix()",
            "    # NB: drive split is specifically for Windows since WindowsPath.resolve() will append the",
            "    # drive path of the pwd to a given path. We don't care about the drive here, though.",
            "    _, resolved_path = os.path.splitdrive(resolved_source)",
            "",
            "    if resolved_path != source_path:",
            "        raise MlflowException(invalid_source_error_message, INVALID_PARAMETER_VALUE)",
            "",
            "",
            "def _validate_source(source: str, run_id: str) -> None:",
            "    if is_local_uri(source):",
            "        if run_id:",
            "            store = _get_tracking_store()",
            "            run = store.get_run(run_id)",
            "            source = pathlib.Path(local_file_uri_to_path(source)).resolve()",
            "            run_artifact_dir = pathlib.Path(local_file_uri_to_path(run.info.artifact_uri)).resolve()",
            "            if run_artifact_dir in [source, *source.parents]:",
            "                return",
            "",
            "        raise MlflowException(",
            "            f\"Invalid model version source: '{source}'. To use a local path as a model version \"",
            "            \"source, the run_id request parameter has to be specified and the local path has to be \"",
            "            \"contained within the artifact directory of the run specified by the run_id.\",",
            "            INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "    # Checks if relative paths are present in the source (a security threat). If any are present,",
            "    # raises an Exception.",
            "    _validate_non_local_source_contains_relative_paths(source)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _create_model_version():",
            "    request_message = _get_request_message(",
            "        CreateModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"source\": [_assert_string, _assert_required],",
            "            \"run_id\": [_assert_string],",
            "            \"tags\": [_assert_array],",
            "            \"run_link\": [_assert_string],",
            "            \"description\": [_assert_string],",
            "        },",
            "    )",
            "",
            "    _validate_source(request_message.source, request_message.run_id)",
            "",
            "    model_version = _get_model_registry_store().create_model_version(",
            "        name=request_message.name,",
            "        source=request_message.source,",
            "        run_id=request_message.run_id,",
            "        run_link=request_message.run_link,",
            "        tags=request_message.tags,",
            "        description=request_message.description,",
            "    )",
            "    response_message = CreateModelVersion.Response(model_version=model_version.to_proto())",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def get_model_version_artifact_handler():",
            "    from querystring_parser import parser",
            "",
            "    query_string = request.query_string.decode(\"utf-8\")",
            "    request_dict = parser.parse(query_string, normalized=True)",
            "    name = request_dict.get(\"name\")",
            "    version = request_dict.get(\"version\")",
            "    path = request_dict[\"path\"]",
            "    path = validate_path_is_safe(path)",
            "    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)",
            "    if _is_servable_proxied_run_artifact_root(artifact_uri):",
            "        artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "        artifact_path = _get_proxied_run_artifact_destination_path(",
            "            proxied_artifact_root=artifact_uri,",
            "            relative_path=path,",
            "        )",
            "    else:",
            "        artifact_repo = get_artifact_repository(artifact_uri)",
            "        artifact_path = path",
            "",
            "    return _send_artifact(artifact_repo, artifact_path)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_model_version():",
            "    request_message = _get_request_message(",
            "        GetModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    model_version = _get_model_registry_store().get_model_version(",
            "        name=request_message.name, version=request_message.version",
            "    )",
            "    response_proto = model_version.to_proto()",
            "    response_message = GetModelVersion.Response(model_version=response_proto)",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _update_model_version():",
            "    request_message = _get_request_message(",
            "        UpdateModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"description\": [_assert_string],",
            "        },",
            "    )",
            "    new_description = None",
            "    if request_message.HasField(\"description\"):",
            "        new_description = request_message.description",
            "    model_version = _get_model_registry_store().update_model_version(",
            "        name=request_message.name, version=request_message.version, description=new_description",
            "    )",
            "    return _wrap_response(UpdateModelVersion.Response(model_version=model_version.to_proto()))",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _transition_stage():",
            "    request_message = _get_request_message(",
            "        TransitionModelVersionStage(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"stage\": [_assert_string, _assert_required],",
            "            \"archive_existing_versions\": [_assert_bool],",
            "        },",
            "    )",
            "    model_version = _get_model_registry_store().transition_model_version_stage(",
            "        name=request_message.name,",
            "        version=request_message.version,",
            "        stage=request_message.stage,",
            "        archive_existing_versions=request_message.archive_existing_versions,",
            "    )",
            "    return _wrap_response(",
            "        TransitionModelVersionStage.Response(model_version=model_version.to_proto())",
            "    )",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_model_version():",
            "    request_message = _get_request_message(",
            "        DeleteModelVersion(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_model_version(",
            "        name=request_message.name, version=request_message.version",
            "    )",
            "    return _wrap_response(DeleteModelVersion.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_model_version_download_uri():",
            "    request_message = _get_request_message(GetModelVersionDownloadUri())",
            "    download_uri = _get_model_registry_store().get_model_version_download_uri(",
            "        name=request_message.name, version=request_message.version",
            "    )",
            "    response_message = GetModelVersionDownloadUri.Response(artifact_uri=download_uri)",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _search_model_versions():",
            "    request_message = _get_request_message(",
            "        SearchModelVersions(),",
            "        schema={",
            "            \"filter\": [_assert_string],",
            "            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 200_000)],",
            "            \"order_by\": [_assert_array, _assert_item_type_string],",
            "            \"page_token\": [_assert_string],",
            "        },",
            "    )",
            "    store = _get_model_registry_store()",
            "    model_versions = store.search_model_versions(",
            "        filter_string=request_message.filter,",
            "        max_results=request_message.max_results,",
            "        order_by=request_message.order_by,",
            "        page_token=request_message.page_token,",
            "    )",
            "    response_message = SearchModelVersions.Response()",
            "    response_message.model_versions.extend([e.to_proto() for e in model_versions])",
            "    if model_versions.token:",
            "        response_message.next_page_token = model_versions.token",
            "    return _wrap_response(response_message)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_model_version_tag():",
            "    request_message = _get_request_message(",
            "        SetModelVersionTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "            \"value\": [_assert_string],",
            "        },",
            "    )",
            "    tag = ModelVersionTag(key=request_message.key, value=request_message.value)",
            "    _get_model_registry_store().set_model_version_tag(",
            "        name=request_message.name, version=request_message.version, tag=tag",
            "    )",
            "    return _wrap_response(SetModelVersionTag.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_model_version_tag():",
            "    request_message = _get_request_message(",
            "        DeleteModelVersionTag(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "            \"key\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_model_version_tag(",
            "        name=request_message.name, version=request_message.version, key=request_message.key",
            "    )",
            "    return _wrap_response(DeleteModelVersionTag.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _set_registered_model_alias():",
            "    request_message = _get_request_message(",
            "        SetRegisteredModelAlias(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"alias\": [_assert_string, _assert_required],",
            "            \"version\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().set_registered_model_alias(",
            "        name=request_message.name, alias=request_message.alias, version=request_message.version",
            "    )",
            "    return _wrap_response(SetRegisteredModelAlias.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _delete_registered_model_alias():",
            "    request_message = _get_request_message(",
            "        DeleteRegisteredModelAlias(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"alias\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    _get_model_registry_store().delete_registered_model_alias(",
            "        name=request_message.name, alias=request_message.alias",
            "    )",
            "    return _wrap_response(DeleteRegisteredModelAlias.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_if_artifacts_only",
            "def _get_model_version_by_alias():",
            "    request_message = _get_request_message(",
            "        GetModelVersionByAlias(),",
            "        schema={",
            "            \"name\": [_assert_string, _assert_required],",
            "            \"alias\": [_assert_string, _assert_required],",
            "        },",
            "    )",
            "    model_version = _get_model_registry_store().get_model_version_by_alias(",
            "        name=request_message.name, alias=request_message.alias",
            "    )",
            "    response_proto = model_version.to_proto()",
            "    response_message = GetModelVersionByAlias.Response(model_version=response_proto)",
            "    return _wrap_response(response_message)",
            "",
            "",
            "# MLflow Artifacts APIs",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _download_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `GET /mlflow-artifacts/artifacts/<artifact_path>` to download an artifact",
            "    from `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "    tmp_dir = tempfile.TemporaryDirectory()",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    dst = artifact_repo.download_artifacts(artifact_path, tmp_dir.name)",
            "",
            "    # Ref: https://stackoverflow.com/a/24613980/6943581",
            "    file_handle = open(dst, \"rb\")  # noqa: SIM115",
            "",
            "    def stream_and_remove_file():",
            "        yield from file_handle",
            "        file_handle.close()",
            "        tmp_dir.cleanup()",
            "",
            "    file_sender_response = current_app.response_class(stream_and_remove_file())",
            "",
            "    return _response_with_file_attachment_headers(artifact_path, file_sender_response)",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `PUT /mlflow-artifacts/artifacts/<artifact_path>` to upload an artifact",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "    head, tail = posixpath.split(artifact_path)",
            "    with tempfile.TemporaryDirectory() as tmp_dir:",
            "        tmp_path = os.path.join(tmp_dir, tail)",
            "        with open(tmp_path, \"wb\") as f:",
            "            chunk_size = 1024 * 1024  # 1 MB",
            "            while True:",
            "                chunk = request.stream.read(chunk_size)",
            "                if len(chunk) == 0:",
            "                    break",
            "                f.write(chunk)",
            "",
            "        artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "        artifact_repo.log_artifact(tmp_path, artifact_path=head or None)",
            "",
            "    return _wrap_response(UploadArtifact.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _list_artifacts_mlflow_artifacts():",
            "    \"\"\"",
            "    A request handler for `GET /mlflow-artifacts/artifacts?path=<value>` to list artifacts in `path`",
            "    (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    request_message = _get_request_message(ListArtifactsMlflowArtifacts())",
            "    path = validate_path_is_safe(request_message.path) if request_message.HasField(\"path\") else None",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    files = []",
            "    for file_info in artifact_repo.list_artifacts(path):",
            "        basename = posixpath.basename(file_info.path)",
            "        new_file_info = FileInfo(basename, file_info.is_dir, file_info.file_size)",
            "        files.append(new_file_info.to_proto())",
            "    response_message = ListArtifacts.Response()",
            "    response_message.files.extend(files)",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _delete_artifact_mlflow_artifacts(artifact_path):",
            "    \"\"\"",
            "    A request handler for `DELETE /mlflow-artifacts/artifacts?path=<value>` to delete artifacts in",
            "    `path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "    _get_request_message(DeleteArtifact())",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    artifact_repo.delete_artifacts(artifact_path)",
            "    response_message = DeleteArtifact.Response()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "def _validate_support_multipart_upload(artifact_repo):",
            "    if not isinstance(artifact_repo, MultipartUploadMixin):",
            "        raise _UnsupportedMultipartUploadException()",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _create_multipart_upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `POST /mlflow-artifacts/mpu/create` to create a multipart upload",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "",
            "    request_message = _get_request_message(",
            "        CreateMultipartUpload(),",
            "        schema={",
            "            \"path\": [_assert_required, _assert_string],",
            "            \"num_parts\": [_assert_intlike],",
            "        },",
            "    )",
            "    path = request_message.path",
            "    num_parts = request_message.num_parts",
            "",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    _validate_support_multipart_upload(artifact_repo)",
            "",
            "    create_response = artifact_repo.create_multipart_upload(",
            "        path,",
            "        num_parts,",
            "        artifact_path,",
            "    )",
            "    response_message = create_response.to_proto()",
            "    response = Response(mimetype=\"application/json\")",
            "    response.set_data(message_to_json(response_message))",
            "    return response",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _complete_multipart_upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `POST /mlflow-artifacts/mpu/complete` to complete a multipart upload",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "",
            "    request_message = _get_request_message(",
            "        CompleteMultipartUpload(),",
            "        schema={",
            "            \"path\": [_assert_required, _assert_string],",
            "            \"upload_id\": [_assert_string],",
            "            \"parts\": [_assert_required],",
            "        },",
            "    )",
            "    path = request_message.path",
            "    upload_id = request_message.upload_id",
            "    parts = [MultipartUploadPart.from_proto(part) for part in request_message.parts]",
            "",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    _validate_support_multipart_upload(artifact_repo)",
            "",
            "    artifact_repo.complete_multipart_upload(",
            "        path,",
            "        upload_id,",
            "        parts,",
            "        artifact_path,",
            "    )",
            "    return _wrap_response(CompleteMultipartUpload.Response())",
            "",
            "",
            "@catch_mlflow_exception",
            "@_disable_unless_serve_artifacts",
            "def _abort_multipart_upload_artifact(artifact_path):",
            "    \"\"\"",
            "    A request handler for `POST /mlflow-artifacts/mpu/abort` to abort a multipart upload",
            "    to `artifact_path` (a relative path from the root artifact directory).",
            "    \"\"\"",
            "    artifact_path = validate_path_is_safe(artifact_path)",
            "",
            "    request_message = _get_request_message(",
            "        AbortMultipartUpload(),",
            "        schema={",
            "            \"path\": [_assert_required, _assert_string],",
            "            \"upload_id\": [_assert_string],",
            "        },",
            "    )",
            "    path = request_message.path",
            "    upload_id = request_message.upload_id",
            "",
            "    artifact_repo = _get_artifact_repo_mlflow_artifacts()",
            "    _validate_support_multipart_upload(artifact_repo)",
            "",
            "    artifact_repo.abort_multipart_upload(",
            "        path,",
            "        upload_id,",
            "        artifact_path,",
            "    )",
            "    return _wrap_response(AbortMultipartUpload.Response())",
            "",
            "",
            "def _get_rest_path(base_path):",
            "    return f\"/api/2.0{base_path}\"",
            "",
            "",
            "def _get_ajax_path(base_path):",
            "    return _add_static_prefix(f\"/ajax-api/2.0{base_path}\")",
            "",
            "",
            "def _add_static_prefix(route):",
            "    prefix = os.environ.get(STATIC_PREFIX_ENV_VAR)",
            "    if prefix:",
            "        return prefix + route",
            "    return route",
            "",
            "",
            "def _get_paths(base_path):",
            "    \"\"\"",
            "    A service endpoints base path is typically something like /mlflow/experiment.",
            "    We should register paths like /api/2.0/mlflow/experiment and",
            "    /ajax-api/2.0/mlflow/experiment in the Flask router.",
            "    \"\"\"",
            "    return [_get_rest_path(base_path), _get_ajax_path(base_path)]",
            "",
            "",
            "def get_handler(request_class):",
            "    \"\"\"",
            "    :param request_class: The type of protobuf message",
            "    :return:",
            "    \"\"\"",
            "    return HANDLERS.get(request_class, _not_implemented)",
            "",
            "",
            "def get_service_endpoints(service, get_handler):",
            "    ret = []",
            "    for service_method in service.DESCRIPTOR.methods:",
            "        endpoints = service_method.GetOptions().Extensions[databricks_pb2.rpc].endpoints",
            "        for endpoint in endpoints:",
            "            for http_path in _get_paths(endpoint.path):",
            "                handler = get_handler(service().GetRequestClass(service_method))",
            "                ret.append((http_path, handler, [endpoint.method]))",
            "    return ret",
            "",
            "",
            "def get_endpoints(get_handler=get_handler):",
            "    \"\"\"",
            "    :return: List of tuples (path, handler, methods)",
            "    \"\"\"",
            "    return (",
            "        get_service_endpoints(MlflowService, get_handler)",
            "        + get_service_endpoints(ModelRegistryService, get_handler)",
            "        + get_service_endpoints(MlflowArtifactsService, get_handler)",
            "    )",
            "",
            "",
            "HANDLERS = {",
            "    # Tracking Server APIs",
            "    CreateExperiment: _create_experiment,",
            "    GetExperiment: _get_experiment,",
            "    GetExperimentByName: _get_experiment_by_name,",
            "    DeleteExperiment: _delete_experiment,",
            "    RestoreExperiment: _restore_experiment,",
            "    UpdateExperiment: _update_experiment,",
            "    CreateRun: _create_run,",
            "    UpdateRun: _update_run,",
            "    DeleteRun: _delete_run,",
            "    RestoreRun: _restore_run,",
            "    LogParam: _log_param,",
            "    LogMetric: _log_metric,",
            "    SetExperimentTag: _set_experiment_tag,",
            "    SetTag: _set_tag,",
            "    DeleteTag: _delete_tag,",
            "    LogBatch: _log_batch,",
            "    LogModel: _log_model,",
            "    GetRun: _get_run,",
            "    SearchRuns: _search_runs,",
            "    ListArtifacts: _list_artifacts,",
            "    GetMetricHistory: _get_metric_history,",
            "    SearchExperiments: _search_experiments,",
            "    LogInputs: _log_inputs,",
            "    # Model Registry APIs",
            "    CreateRegisteredModel: _create_registered_model,",
            "    GetRegisteredModel: _get_registered_model,",
            "    DeleteRegisteredModel: _delete_registered_model,",
            "    UpdateRegisteredModel: _update_registered_model,",
            "    RenameRegisteredModel: _rename_registered_model,",
            "    SearchRegisteredModels: _search_registered_models,",
            "    GetLatestVersions: _get_latest_versions,",
            "    CreateModelVersion: _create_model_version,",
            "    GetModelVersion: _get_model_version,",
            "    DeleteModelVersion: _delete_model_version,",
            "    UpdateModelVersion: _update_model_version,",
            "    TransitionModelVersionStage: _transition_stage,",
            "    GetModelVersionDownloadUri: _get_model_version_download_uri,",
            "    SearchModelVersions: _search_model_versions,",
            "    SetRegisteredModelTag: _set_registered_model_tag,",
            "    DeleteRegisteredModelTag: _delete_registered_model_tag,",
            "    SetModelVersionTag: _set_model_version_tag,",
            "    DeleteModelVersionTag: _delete_model_version_tag,",
            "    SetRegisteredModelAlias: _set_registered_model_alias,",
            "    DeleteRegisteredModelAlias: _delete_registered_model_alias,",
            "    GetModelVersionByAlias: _get_model_version_by_alias,",
            "    # MLflow Artifacts APIs",
            "    DownloadArtifact: _download_artifact,",
            "    UploadArtifact: _upload_artifact,",
            "    ListArtifactsMlflowArtifacts: _list_artifacts_mlflow_artifacts,",
            "    DeleteArtifact: _delete_artifact_mlflow_artifacts,",
            "    CreateMultipartUpload: _create_multipart_upload_artifact,",
            "    CompleteMultipartUpload: _complete_multipart_upload_artifact,",
            "    AbortMultipartUpload: _abort_multipart_upload_artifact,",
            "}"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "21": [],
            "22": [],
            "23": [],
            "24": [],
            "108": [],
            "1607": [
                "_validate_source"
            ],
            "1608": [
                "_validate_source"
            ],
            "1609": [
                "_validate_source"
            ],
            "1610": [
                "_validate_source"
            ],
            "1611": [
                "_validate_source"
            ],
            "1612": [
                "_validate_source"
            ],
            "1613": [
                "_validate_source"
            ],
            "1614": [
                "_validate_source"
            ],
            "1615": [
                "_validate_source"
            ],
            "1616": [
                "_validate_source"
            ],
            "1617": [
                "_validate_source"
            ],
            "1618": [
                "_validate_source"
            ]
        },
        "addLocation": []
    },
    "mlflow/utils/uri.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "     if scheme == \"\":"
            },
            "1": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "         return True"
            },
            "2": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if parsed_uri.hostname and not ("
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+    is_remote_hostname = parsed_uri.hostname and not ("
            },
            "5": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 49,
                "PatchRowcode": "         parsed_uri.hostname == \".\""
            },
            "6": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "         or parsed_uri.hostname.startswith(\"localhost\")"
            },
            "7": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "         or parsed_uri.hostname.startswith(\"127.0.0.1\")"
            },
            "8": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ):"
            },
            "9": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return False"
            },
            "10": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+    )"
            },
            "12": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "     if scheme == \"file\":"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+        if is_remote_hostname:"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+            raise MlflowException("
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+                f\"{uri} is not a valid remote uri. For remote access \""
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+                \"on windows, please consider using a different scheme \""
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+                \"such as SMB (e.g. smb://<hostname>/<path>).\""
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+            )"
            },
            "19": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "         return True"
            },
            "20": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 61,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+    if is_remote_hostname:"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+        return False"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "     if is_windows() and len(scheme) == 1 and scheme.lower() == pathlib.Path(uri).drive.lower()[0]:"
            },
            "25": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "         return True"
            },
            "26": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "     return False"
            },
            "28": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 70,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 71,
                "PatchRowcode": " def is_file_uri(uri):"
            },
            "31": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return urllib.parse.urlparse(uri).scheme == \"file\""
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+    scheme = urllib.parse.urlparse(uri).scheme"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+    return scheme == \"file\""
            },
            "34": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 74,
                "PatchRowcode": " "
            },
            "35": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 75,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 76,
                "PatchRowcode": " def is_http_uri(uri):"
            }
        },
        "frontPatchFile": [
            "import os",
            "import pathlib",
            "import posixpath",
            "import re",
            "import urllib.parse",
            "import uuid",
            "from typing import Any, Tuple",
            "",
            "from mlflow.exceptions import MlflowException",
            "from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE",
            "from mlflow.store.db.db_types import DATABASE_ENGINES",
            "from mlflow.utils.os import is_windows",
            "from mlflow.utils.validation import _validate_db_type_string",
            "",
            "_INVALID_DB_URI_MSG = (",
            "    \"Please refer to https://mlflow.org/docs/latest/tracking.html#storage for \"",
            "    \"format specifications.\"",
            ")",
            "",
            "_DBFS_FUSE_PREFIX = \"/dbfs/\"",
            "_DBFS_HDFS_URI_PREFIX = \"dbfs:/\"",
            "_UC_VOLUMES_URI_PREFIX = \"/Volumes/\"",
            "_UC_DBFS_SYMLINK_PREFIX = \"/.fuse-mounts/\"",
            "_DATABRICKS_UNITY_CATALOG_SCHEME = \"databricks-uc\"",
            "",
            "",
            "def is_local_uri(uri, is_tracking_or_registry_uri=True):",
            "    \"\"\"",
            "    Returns true if the specified URI is a local file path (/foo or file:/foo).",
            "",
            "    :param uri: The URI.",
            "    :param is_tracking_uri: Whether or not the specified URI is an MLflow Tracking or MLflow",
            "                            Model Registry URI. Examples of other URIs are MLflow artifact URIs,",
            "                            filesystem paths, etc.",
            "    \"\"\"",
            "    if uri == \"databricks\" and is_tracking_or_registry_uri:",
            "        return False",
            "",
            "    if is_windows() and uri.startswith(\"\\\\\\\\\"):",
            "        # windows network drive path looks like: \"\\\\<server name>\\path\\...\"",
            "        return False",
            "",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "    scheme = parsed_uri.scheme",
            "    if scheme == \"\":",
            "        return True",
            "",
            "    if parsed_uri.hostname and not (",
            "        parsed_uri.hostname == \".\"",
            "        or parsed_uri.hostname.startswith(\"localhost\")",
            "        or parsed_uri.hostname.startswith(\"127.0.0.1\")",
            "    ):",
            "        return False",
            "",
            "    if scheme == \"file\":",
            "        return True",
            "",
            "    if is_windows() and len(scheme) == 1 and scheme.lower() == pathlib.Path(uri).drive.lower()[0]:",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def is_file_uri(uri):",
            "    return urllib.parse.urlparse(uri).scheme == \"file\"",
            "",
            "",
            "def is_http_uri(uri):",
            "    scheme = urllib.parse.urlparse(uri).scheme",
            "    return scheme == \"http\" or scheme == \"https\"",
            "",
            "",
            "def is_databricks_uri(uri):",
            "    \"\"\"",
            "    Databricks URIs look like 'databricks' (default profile) or 'databricks://profile'",
            "    or 'databricks://secret_scope:secret_key_prefix'.",
            "    \"\"\"",
            "    scheme = urllib.parse.urlparse(uri).scheme",
            "    return scheme == \"databricks\" or uri == \"databricks\"",
            "",
            "",
            "def is_fuse_or_uc_volumes_uri(uri):",
            "    \"\"\"",
            "    Validates whether a provided URI is directed to a FUSE mount point or a UC volumes mount point.",
            "    Multiple directory paths are collapsed into a single designator for root path validation.",
            "    example:",
            "    \"////Volumes/\" will resolve to \"/Volumes/\" for validation purposes.",
            "    \"\"\"",
            "    resolved_uri = re.sub(\"/+\", \"/\", uri)",
            "    return any(",
            "        resolved_uri.startswith(x)",
            "        for x in [",
            "            _DBFS_FUSE_PREFIX,",
            "            _DBFS_HDFS_URI_PREFIX,",
            "            _UC_VOLUMES_URI_PREFIX,",
            "            _UC_DBFS_SYMLINK_PREFIX,",
            "        ]",
            "    )",
            "",
            "",
            "def is_databricks_unity_catalog_uri(uri):",
            "    scheme = urllib.parse.urlparse(uri).scheme",
            "    return scheme == _DATABRICKS_UNITY_CATALOG_SCHEME or uri == _DATABRICKS_UNITY_CATALOG_SCHEME",
            "",
            "",
            "def construct_db_uri_from_profile(profile):",
            "    if profile:",
            "        return \"databricks://\" + profile",
            "",
            "",
            "# Both scope and key_prefix should not contain special chars for URIs, like '/'",
            "# and ':'.",
            "def validate_db_scope_prefix_info(scope, prefix):",
            "    for c in [\"/\", \":\", \" \"]:",
            "        if c in scope:",
            "            raise MlflowException(",
            "                f\"Unsupported Databricks profile name: {scope}.\"",
            "                f\" Profile names cannot contain '{c}'.\"",
            "            )",
            "        if prefix and c in prefix:",
            "            raise MlflowException(",
            "                f\"Unsupported Databricks profile key prefix: {prefix}.\"",
            "                f\" Key prefixes cannot contain '{c}'.\"",
            "            )",
            "    if prefix is not None and prefix.strip() == \"\":",
            "        raise MlflowException(",
            "            f\"Unsupported Databricks profile key prefix: '{prefix}'.\"",
            "            \" Key prefixes cannot be empty.\"",
            "        )",
            "",
            "",
            "def get_db_info_from_uri(uri):",
            "    \"\"\"",
            "    Get the Databricks profile specified by the tracking URI (if any), otherwise",
            "    returns None.",
            "    \"\"\"",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "    if parsed_uri.scheme == \"databricks\" or parsed_uri.scheme == _DATABRICKS_UNITY_CATALOG_SCHEME:",
            "        # netloc should not be an empty string unless URI is formatted incorrectly.",
            "        if parsed_uri.netloc == \"\":",
            "            raise MlflowException(",
            "                f\"URI is formatted incorrectly: no netloc in URI '{uri}'.\"",
            "                \" This may be the case if there is only one slash in the URI.\"",
            "            )",
            "        profile_tokens = parsed_uri.netloc.split(\":\")",
            "        parsed_scope = profile_tokens[0]",
            "        if len(profile_tokens) == 1:",
            "            parsed_key_prefix = None",
            "        elif len(profile_tokens) == 2:",
            "            parsed_key_prefix = profile_tokens[1]",
            "        else:",
            "            # parse the content before the first colon as the profile.",
            "            parsed_key_prefix = \":\".join(profile_tokens[1:])",
            "        validate_db_scope_prefix_info(parsed_scope, parsed_key_prefix)",
            "        return parsed_scope, parsed_key_prefix",
            "    return None, None",
            "",
            "",
            "def get_databricks_profile_uri_from_artifact_uri(uri, result_scheme=\"databricks\"):",
            "    \"\"\"",
            "    Retrieves the netloc portion of the URI as a ``databricks://`` or `databricks-uc://` URI,",
            "    if it is a proper Databricks profile specification, e.g.",
            "    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.",
            "    \"\"\"",
            "    parsed = urllib.parse.urlparse(uri)",
            "    if not parsed.netloc or parsed.hostname != result_scheme:",
            "        return None",
            "    if not parsed.username:  # no profile or scope:key",
            "        return result_scheme  # the default tracking/registry URI",
            "    validate_db_scope_prefix_info(parsed.username, parsed.password)",
            "    key_prefix = \":\" + parsed.password if parsed.password else \"\"",
            "    return f\"{result_scheme}://\" + parsed.username + key_prefix",
            "",
            "",
            "def remove_databricks_profile_info_from_artifact_uri(artifact_uri):",
            "    \"\"\"",
            "    Only removes the netloc portion of the URI if it is a Databricks",
            "    profile specification, e.g.",
            "    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.",
            "    \"\"\"",
            "    parsed = urllib.parse.urlparse(artifact_uri)",
            "    if not parsed.netloc or parsed.hostname != \"databricks\":",
            "        return artifact_uri",
            "    return urllib.parse.urlunparse(parsed._replace(netloc=\"\"))",
            "",
            "",
            "def add_databricks_profile_info_to_artifact_uri(artifact_uri, databricks_profile_uri):",
            "    \"\"\"",
            "    Throws an exception if ``databricks_profile_uri`` is not valid.",
            "    \"\"\"",
            "    if not databricks_profile_uri or not is_databricks_uri(databricks_profile_uri):",
            "        return artifact_uri",
            "    artifact_uri_parsed = urllib.parse.urlparse(artifact_uri)",
            "    # Do not overwrite the authority section if there is already one",
            "    if artifact_uri_parsed.netloc:",
            "        return artifact_uri",
            "",
            "    scheme = artifact_uri_parsed.scheme",
            "    if scheme == \"dbfs\" or scheme == \"runs\" or scheme == \"models\":",
            "        if databricks_profile_uri == \"databricks\":",
            "            netloc = \"databricks\"",
            "        else:",
            "            (profile, key_prefix) = get_db_info_from_uri(databricks_profile_uri)",
            "            prefix = \":\" + key_prefix if key_prefix else \"\"",
            "            netloc = profile + prefix + \"@databricks\"",
            "        new_parsed = artifact_uri_parsed._replace(netloc=netloc)",
            "        return urllib.parse.urlunparse(new_parsed)",
            "    else:",
            "        return artifact_uri",
            "",
            "",
            "def extract_db_type_from_uri(db_uri):",
            "    \"\"\"",
            "    Parse the specified DB URI to extract the database type. Confirm the database type is",
            "    supported. If a driver is specified, confirm it passes a plausible regex.",
            "    \"\"\"",
            "    scheme = urllib.parse.urlparse(db_uri).scheme",
            "    scheme_plus_count = scheme.count(\"+\")",
            "",
            "    if scheme_plus_count == 0:",
            "        db_type = scheme",
            "    elif scheme_plus_count == 1:",
            "        db_type, _ = scheme.split(\"+\")",
            "    else:",
            "        error_msg = f\"Invalid database URI: '{db_uri}'. {_INVALID_DB_URI_MSG}\"",
            "        raise MlflowException(error_msg, INVALID_PARAMETER_VALUE)",
            "",
            "    _validate_db_type_string(db_type)",
            "",
            "    return db_type",
            "",
            "",
            "def get_uri_scheme(uri_or_path):",
            "    scheme = urllib.parse.urlparse(uri_or_path).scheme",
            "    if any(scheme.lower().startswith(db) for db in DATABASE_ENGINES):",
            "        return extract_db_type_from_uri(uri_or_path)",
            "    return scheme",
            "",
            "",
            "def extract_and_normalize_path(uri):",
            "    parsed_uri_path = urllib.parse.urlparse(uri).path",
            "    normalized_path = posixpath.normpath(parsed_uri_path)",
            "    return normalized_path.lstrip(\"/\")",
            "",
            "",
            "def append_to_uri_path(uri, *paths):",
            "    \"\"\"",
            "    Appends the specified POSIX `paths` to the path component of the specified `uri`.",
            "",
            "    :param uri: The input URI, represented as a string.",
            "    :param paths: The POSIX paths to append to the specified `uri`'s path component.",
            "    :return: A new URI with a path component consisting of the specified `paths` appended to",
            "             the path component of the specified `uri`.",
            "",
            "    >>> uri1 = \"s3://root/base/path?param=value\"",
            "    >>> uri1 = append_to_uri_path(uri1, \"some/subpath\", \"/anotherpath\")",
            "    >>> assert uri1 == \"s3://root/base/path/some/subpath/anotherpath?param=value\"",
            "    >>> uri2 = \"a/posix/path\"",
            "    >>> uri2 = append_to_uri_path(uri2, \"/some\", \"subpath\")",
            "    >>> assert uri2 == \"a/posixpath/some/subpath\"",
            "    \"\"\"",
            "    path = \"\"",
            "    for subpath in paths:",
            "        path = _join_posixpaths_and_append_absolute_suffixes(path, subpath)",
            "",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "",
            "    # Validate query string not to contain any traveral path (../) before appending",
            "    # to the end of the path, otherwise they will be resolved as part of the path.",
            "    validate_query_string(parsed_uri.query)",
            "",
            "    if len(parsed_uri.scheme) == 0:",
            "        # If the input URI does not define a scheme, we assume that it is a POSIX path",
            "        # and join it with the specified input paths",
            "        return _join_posixpaths_and_append_absolute_suffixes(uri, path)",
            "",
            "    prefix = \"\"",
            "    if not parsed_uri.path.startswith(\"/\"):",
            "        # For certain URI schemes (e.g., \"file:\"), urllib's unparse routine does",
            "        # not preserve the relative URI path component properly. In certain cases,",
            "        # urlunparse converts relative paths to absolute paths. We introduce this logic",
            "        # to circumvent urlunparse's erroneous conversion",
            "        prefix = parsed_uri.scheme + \":\"",
            "        parsed_uri = parsed_uri._replace(scheme=\"\")",
            "",
            "    new_uri_path = _join_posixpaths_and_append_absolute_suffixes(parsed_uri.path, path)",
            "    new_parsed_uri = parsed_uri._replace(path=new_uri_path)",
            "    return prefix + urllib.parse.urlunparse(new_parsed_uri)",
            "",
            "",
            "def append_to_uri_query_params(uri, *query_params: Tuple[str, Any]) -> str:",
            "    \"\"\"",
            "    Appends the specified query parameters to an existing URI.",
            "",
            "    :param uri: The URI to which to append query parameters.",
            "    :param query_params: Query parameters to append. Each parameter should",
            "                         be a 2-element tuple. For example, ``(\"key\", \"value\")``.",
            "    \"\"\"",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "    parsed_query = urllib.parse.parse_qsl(parsed_uri.query)",
            "    new_parsed_query = parsed_query + list(query_params)",
            "    new_query = urllib.parse.urlencode(new_parsed_query)",
            "    new_parsed_uri = parsed_uri._replace(query=new_query)",
            "    return urllib.parse.urlunparse(new_parsed_uri)",
            "",
            "",
            "def _join_posixpaths_and_append_absolute_suffixes(prefix_path, suffix_path):",
            "    \"\"\"",
            "    Joins the POSIX path `prefix_path` with the POSIX path `suffix_path`. Unlike posixpath.join(),",
            "    if `suffix_path` is an absolute path, it is appended to prefix_path.",
            "",
            "    >>> result1 = _join_posixpaths_and_append_absolute_suffixes(\"relpath1\", \"relpath2\")",
            "    >>> assert result1 == \"relpath1/relpath2\"",
            "    >>> result2 = _join_posixpaths_and_append_absolute_suffixes(\"relpath\", \"/absolutepath\")",
            "    >>> assert result2 == \"relpath/absolutepath\"",
            "    >>> result3 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath\", \"relpath\")",
            "    >>> assert result3 == \"/absolutepath/relpath\"",
            "    >>> result4 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath1\", \"/absolutepath2\")",
            "    >>> assert result4 == \"/absolutepath1/absolutepath2\"",
            "    \"\"\"",
            "    if len(prefix_path) == 0:",
            "        return suffix_path",
            "",
            "    # If the specified prefix path is non-empty, we must relativize the suffix path by removing",
            "    # the leading slash, if present. Otherwise, posixpath.join() would omit the prefix from the",
            "    # joined path",
            "    suffix_path = suffix_path.lstrip(posixpath.sep)",
            "    return posixpath.join(prefix_path, suffix_path)",
            "",
            "",
            "def is_databricks_acled_artifacts_uri(artifact_uri):",
            "    _ACLED_ARTIFACT_URI = \"databricks/mlflow-tracking/\"",
            "    artifact_uri_path = extract_and_normalize_path(artifact_uri)",
            "    return artifact_uri_path.startswith(_ACLED_ARTIFACT_URI)",
            "",
            "",
            "def is_databricks_model_registry_artifacts_uri(artifact_uri):",
            "    _MODEL_REGISTRY_ARTIFACT_URI = \"databricks/mlflow-registry/\"",
            "    artifact_uri_path = extract_and_normalize_path(artifact_uri)",
            "    return artifact_uri_path.startswith(_MODEL_REGISTRY_ARTIFACT_URI)",
            "",
            "",
            "def is_valid_dbfs_uri(uri):",
            "    parsed = urllib.parse.urlparse(uri)",
            "    if parsed.scheme != \"dbfs\":",
            "        return False",
            "    try:",
            "        db_profile_uri = get_databricks_profile_uri_from_artifact_uri(uri)",
            "    except MlflowException:",
            "        db_profile_uri = None",
            "    return not parsed.netloc or db_profile_uri is not None",
            "",
            "",
            "def dbfs_hdfs_uri_to_fuse_path(dbfs_uri):",
            "    \"\"\"",
            "    Converts the provided DBFS URI into a DBFS FUSE path",
            "    :param dbfs_uri: A DBFS URI like \"dbfs:/my-directory\". Can also be a scheme-less URI like",
            "                     \"/my-directory\" if running in an environment where the default HDFS filesystem",
            "                     is \"dbfs:/\" (e.g. Databricks)",
            "    :return A DBFS FUSE-style path, e.g. \"/dbfs/my-directory\"",
            "    \"\"\"",
            "    if not is_valid_dbfs_uri(dbfs_uri) and dbfs_uri == posixpath.abspath(dbfs_uri):",
            "        # Convert posixpaths (e.g. \"/tmp/mlflow\") to DBFS URIs by adding \"dbfs:/\" as a prefix",
            "        dbfs_uri = \"dbfs:\" + dbfs_uri",
            "    if not dbfs_uri.startswith(_DBFS_HDFS_URI_PREFIX):",
            "        raise MlflowException(",
            "            f\"Path '{dbfs_uri}' did not start with expected DBFS URI \"",
            "            f\"prefix '{_DBFS_HDFS_URI_PREFIX}'\",",
            "        )",
            "",
            "    return _DBFS_FUSE_PREFIX + dbfs_uri[len(_DBFS_HDFS_URI_PREFIX) :]",
            "",
            "",
            "def resolve_uri_if_local(local_uri):",
            "    \"\"\"",
            "    if `local_uri` is passed in as a relative local path, this function",
            "    resolves it to absolute path relative to current working directory.",
            "",
            "    :param local_uri: Relative or absolute path or local file uri",
            "",
            "    :return: a fully-formed absolute uri path or an absolute filesystem path",
            "    \"\"\"",
            "    from mlflow.utils.file_utils import local_file_uri_to_path",
            "",
            "    if local_uri is not None and is_local_uri(local_uri):",
            "        scheme = get_uri_scheme(local_uri)",
            "        cwd = pathlib.Path.cwd()",
            "        local_path = local_file_uri_to_path(local_uri)",
            "        if not pathlib.Path(local_path).is_absolute():",
            "            if scheme == \"\":",
            "                if is_windows():",
            "                    return urllib.parse.urlunsplit(",
            "                        (",
            "                            \"file\",",
            "                            None,",
            "                            cwd.joinpath(local_path).as_posix(),",
            "                            None,",
            "                            None,",
            "                        )",
            "                    )",
            "                return cwd.joinpath(local_path).as_posix()",
            "            local_uri_split = urllib.parse.urlsplit(local_uri)",
            "            return urllib.parse.urlunsplit(",
            "                (",
            "                    local_uri_split.scheme,",
            "                    None,",
            "                    cwd.joinpath(local_path).as_posix(),",
            "                    local_uri_split.query,",
            "                    local_uri_split.fragment,",
            "                )",
            "            )",
            "    return local_uri",
            "",
            "",
            "def generate_tmp_dfs_path(dfs_tmp):",
            "    return posixpath.join(dfs_tmp, str(uuid.uuid4()))",
            "",
            "",
            "def join_paths(*paths: str) -> str:",
            "    stripped = (p.strip(\"/\") for p in paths)",
            "    return \"/\" + posixpath.normpath(posixpath.join(*stripped))",
            "",
            "",
            "_OS_ALT_SEPS = [sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"]",
            "",
            "",
            "def validate_path_is_safe(path):",
            "    \"\"\"",
            "    Validates that the specified path is safe to join with a trusted prefix. This is a security",
            "    measure to prevent path traversal attacks.",
            "    A valid path should:",
            "        not contain separators other than '/'",
            "        not contain .. to navigate to parent dir in path",
            "        not be an absolute path",
            "    \"\"\"",
            "    from mlflow.utils.file_utils import local_file_uri_to_path",
            "",
            "    # We must decode path before validating it",
            "    path = _decode(path)",
            "",
            "    exc = MlflowException(\"Invalid path\", error_code=INVALID_PARAMETER_VALUE)",
            "    if \"#\" in path:",
            "        raise exc",
            "",
            "    if is_file_uri(path):",
            "        path = local_file_uri_to_path(path)",
            "    if (",
            "        any((s in path) for s in _OS_ALT_SEPS)",
            "        or \"..\" in path.split(\"/\")",
            "        or pathlib.PureWindowsPath(path).is_absolute()",
            "        or pathlib.PurePosixPath(path).is_absolute()",
            "        or (is_windows() and len(path) >= 2 and path[1] == \":\")",
            "    ):",
            "        raise exc",
            "",
            "    return path",
            "",
            "",
            "def validate_query_string(query):",
            "    query = _decode(query)",
            "    # Block query strings contain any traveral path (../) because they",
            "    # could be resolved as part of the path and allow path traversal.",
            "    if \"..\" in query:",
            "        raise MlflowException(\"Invalid query string\", error_code=INVALID_PARAMETER_VALUE)",
            "",
            "",
            "def _decode(url):",
            "    # Keep decoding until the url stops changing (with a max of 10 iterations)",
            "    for _ in range(10):",
            "        decoded = urllib.parse.unquote(url)",
            "        if decoded == url:",
            "            return url",
            "        url = decoded",
            "",
            "    raise ValueError(\"Failed to decode url\")"
        ],
        "afterPatchFile": [
            "import os",
            "import pathlib",
            "import posixpath",
            "import re",
            "import urllib.parse",
            "import uuid",
            "from typing import Any, Tuple",
            "",
            "from mlflow.exceptions import MlflowException",
            "from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE",
            "from mlflow.store.db.db_types import DATABASE_ENGINES",
            "from mlflow.utils.os import is_windows",
            "from mlflow.utils.validation import _validate_db_type_string",
            "",
            "_INVALID_DB_URI_MSG = (",
            "    \"Please refer to https://mlflow.org/docs/latest/tracking.html#storage for \"",
            "    \"format specifications.\"",
            ")",
            "",
            "_DBFS_FUSE_PREFIX = \"/dbfs/\"",
            "_DBFS_HDFS_URI_PREFIX = \"dbfs:/\"",
            "_UC_VOLUMES_URI_PREFIX = \"/Volumes/\"",
            "_UC_DBFS_SYMLINK_PREFIX = \"/.fuse-mounts/\"",
            "_DATABRICKS_UNITY_CATALOG_SCHEME = \"databricks-uc\"",
            "",
            "",
            "def is_local_uri(uri, is_tracking_or_registry_uri=True):",
            "    \"\"\"",
            "    Returns true if the specified URI is a local file path (/foo or file:/foo).",
            "",
            "    :param uri: The URI.",
            "    :param is_tracking_uri: Whether or not the specified URI is an MLflow Tracking or MLflow",
            "                            Model Registry URI. Examples of other URIs are MLflow artifact URIs,",
            "                            filesystem paths, etc.",
            "    \"\"\"",
            "    if uri == \"databricks\" and is_tracking_or_registry_uri:",
            "        return False",
            "",
            "    if is_windows() and uri.startswith(\"\\\\\\\\\"):",
            "        # windows network drive path looks like: \"\\\\<server name>\\path\\...\"",
            "        return False",
            "",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "    scheme = parsed_uri.scheme",
            "    if scheme == \"\":",
            "        return True",
            "",
            "    is_remote_hostname = parsed_uri.hostname and not (",
            "        parsed_uri.hostname == \".\"",
            "        or parsed_uri.hostname.startswith(\"localhost\")",
            "        or parsed_uri.hostname.startswith(\"127.0.0.1\")",
            "    )",
            "    if scheme == \"file\":",
            "        if is_remote_hostname:",
            "            raise MlflowException(",
            "                f\"{uri} is not a valid remote uri. For remote access \"",
            "                \"on windows, please consider using a different scheme \"",
            "                \"such as SMB (e.g. smb://<hostname>/<path>).\"",
            "            )",
            "        return True",
            "",
            "    if is_remote_hostname:",
            "        return False",
            "",
            "    if is_windows() and len(scheme) == 1 and scheme.lower() == pathlib.Path(uri).drive.lower()[0]:",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def is_file_uri(uri):",
            "    scheme = urllib.parse.urlparse(uri).scheme",
            "    return scheme == \"file\"",
            "",
            "",
            "def is_http_uri(uri):",
            "    scheme = urllib.parse.urlparse(uri).scheme",
            "    return scheme == \"http\" or scheme == \"https\"",
            "",
            "",
            "def is_databricks_uri(uri):",
            "    \"\"\"",
            "    Databricks URIs look like 'databricks' (default profile) or 'databricks://profile'",
            "    or 'databricks://secret_scope:secret_key_prefix'.",
            "    \"\"\"",
            "    scheme = urllib.parse.urlparse(uri).scheme",
            "    return scheme == \"databricks\" or uri == \"databricks\"",
            "",
            "",
            "def is_fuse_or_uc_volumes_uri(uri):",
            "    \"\"\"",
            "    Validates whether a provided URI is directed to a FUSE mount point or a UC volumes mount point.",
            "    Multiple directory paths are collapsed into a single designator for root path validation.",
            "    example:",
            "    \"////Volumes/\" will resolve to \"/Volumes/\" for validation purposes.",
            "    \"\"\"",
            "    resolved_uri = re.sub(\"/+\", \"/\", uri)",
            "    return any(",
            "        resolved_uri.startswith(x)",
            "        for x in [",
            "            _DBFS_FUSE_PREFIX,",
            "            _DBFS_HDFS_URI_PREFIX,",
            "            _UC_VOLUMES_URI_PREFIX,",
            "            _UC_DBFS_SYMLINK_PREFIX,",
            "        ]",
            "    )",
            "",
            "",
            "def is_databricks_unity_catalog_uri(uri):",
            "    scheme = urllib.parse.urlparse(uri).scheme",
            "    return scheme == _DATABRICKS_UNITY_CATALOG_SCHEME or uri == _DATABRICKS_UNITY_CATALOG_SCHEME",
            "",
            "",
            "def construct_db_uri_from_profile(profile):",
            "    if profile:",
            "        return \"databricks://\" + profile",
            "",
            "",
            "# Both scope and key_prefix should not contain special chars for URIs, like '/'",
            "# and ':'.",
            "def validate_db_scope_prefix_info(scope, prefix):",
            "    for c in [\"/\", \":\", \" \"]:",
            "        if c in scope:",
            "            raise MlflowException(",
            "                f\"Unsupported Databricks profile name: {scope}.\"",
            "                f\" Profile names cannot contain '{c}'.\"",
            "            )",
            "        if prefix and c in prefix:",
            "            raise MlflowException(",
            "                f\"Unsupported Databricks profile key prefix: {prefix}.\"",
            "                f\" Key prefixes cannot contain '{c}'.\"",
            "            )",
            "    if prefix is not None and prefix.strip() == \"\":",
            "        raise MlflowException(",
            "            f\"Unsupported Databricks profile key prefix: '{prefix}'.\"",
            "            \" Key prefixes cannot be empty.\"",
            "        )",
            "",
            "",
            "def get_db_info_from_uri(uri):",
            "    \"\"\"",
            "    Get the Databricks profile specified by the tracking URI (if any), otherwise",
            "    returns None.",
            "    \"\"\"",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "    if parsed_uri.scheme == \"databricks\" or parsed_uri.scheme == _DATABRICKS_UNITY_CATALOG_SCHEME:",
            "        # netloc should not be an empty string unless URI is formatted incorrectly.",
            "        if parsed_uri.netloc == \"\":",
            "            raise MlflowException(",
            "                f\"URI is formatted incorrectly: no netloc in URI '{uri}'.\"",
            "                \" This may be the case if there is only one slash in the URI.\"",
            "            )",
            "        profile_tokens = parsed_uri.netloc.split(\":\")",
            "        parsed_scope = profile_tokens[0]",
            "        if len(profile_tokens) == 1:",
            "            parsed_key_prefix = None",
            "        elif len(profile_tokens) == 2:",
            "            parsed_key_prefix = profile_tokens[1]",
            "        else:",
            "            # parse the content before the first colon as the profile.",
            "            parsed_key_prefix = \":\".join(profile_tokens[1:])",
            "        validate_db_scope_prefix_info(parsed_scope, parsed_key_prefix)",
            "        return parsed_scope, parsed_key_prefix",
            "    return None, None",
            "",
            "",
            "def get_databricks_profile_uri_from_artifact_uri(uri, result_scheme=\"databricks\"):",
            "    \"\"\"",
            "    Retrieves the netloc portion of the URI as a ``databricks://`` or `databricks-uc://` URI,",
            "    if it is a proper Databricks profile specification, e.g.",
            "    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.",
            "    \"\"\"",
            "    parsed = urllib.parse.urlparse(uri)",
            "    if not parsed.netloc or parsed.hostname != result_scheme:",
            "        return None",
            "    if not parsed.username:  # no profile or scope:key",
            "        return result_scheme  # the default tracking/registry URI",
            "    validate_db_scope_prefix_info(parsed.username, parsed.password)",
            "    key_prefix = \":\" + parsed.password if parsed.password else \"\"",
            "    return f\"{result_scheme}://\" + parsed.username + key_prefix",
            "",
            "",
            "def remove_databricks_profile_info_from_artifact_uri(artifact_uri):",
            "    \"\"\"",
            "    Only removes the netloc portion of the URI if it is a Databricks",
            "    profile specification, e.g.",
            "    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.",
            "    \"\"\"",
            "    parsed = urllib.parse.urlparse(artifact_uri)",
            "    if not parsed.netloc or parsed.hostname != \"databricks\":",
            "        return artifact_uri",
            "    return urllib.parse.urlunparse(parsed._replace(netloc=\"\"))",
            "",
            "",
            "def add_databricks_profile_info_to_artifact_uri(artifact_uri, databricks_profile_uri):",
            "    \"\"\"",
            "    Throws an exception if ``databricks_profile_uri`` is not valid.",
            "    \"\"\"",
            "    if not databricks_profile_uri or not is_databricks_uri(databricks_profile_uri):",
            "        return artifact_uri",
            "    artifact_uri_parsed = urllib.parse.urlparse(artifact_uri)",
            "    # Do not overwrite the authority section if there is already one",
            "    if artifact_uri_parsed.netloc:",
            "        return artifact_uri",
            "",
            "    scheme = artifact_uri_parsed.scheme",
            "    if scheme == \"dbfs\" or scheme == \"runs\" or scheme == \"models\":",
            "        if databricks_profile_uri == \"databricks\":",
            "            netloc = \"databricks\"",
            "        else:",
            "            (profile, key_prefix) = get_db_info_from_uri(databricks_profile_uri)",
            "            prefix = \":\" + key_prefix if key_prefix else \"\"",
            "            netloc = profile + prefix + \"@databricks\"",
            "        new_parsed = artifact_uri_parsed._replace(netloc=netloc)",
            "        return urllib.parse.urlunparse(new_parsed)",
            "    else:",
            "        return artifact_uri",
            "",
            "",
            "def extract_db_type_from_uri(db_uri):",
            "    \"\"\"",
            "    Parse the specified DB URI to extract the database type. Confirm the database type is",
            "    supported. If a driver is specified, confirm it passes a plausible regex.",
            "    \"\"\"",
            "    scheme = urllib.parse.urlparse(db_uri).scheme",
            "    scheme_plus_count = scheme.count(\"+\")",
            "",
            "    if scheme_plus_count == 0:",
            "        db_type = scheme",
            "    elif scheme_plus_count == 1:",
            "        db_type, _ = scheme.split(\"+\")",
            "    else:",
            "        error_msg = f\"Invalid database URI: '{db_uri}'. {_INVALID_DB_URI_MSG}\"",
            "        raise MlflowException(error_msg, INVALID_PARAMETER_VALUE)",
            "",
            "    _validate_db_type_string(db_type)",
            "",
            "    return db_type",
            "",
            "",
            "def get_uri_scheme(uri_or_path):",
            "    scheme = urllib.parse.urlparse(uri_or_path).scheme",
            "    if any(scheme.lower().startswith(db) for db in DATABASE_ENGINES):",
            "        return extract_db_type_from_uri(uri_or_path)",
            "    return scheme",
            "",
            "",
            "def extract_and_normalize_path(uri):",
            "    parsed_uri_path = urllib.parse.urlparse(uri).path",
            "    normalized_path = posixpath.normpath(parsed_uri_path)",
            "    return normalized_path.lstrip(\"/\")",
            "",
            "",
            "def append_to_uri_path(uri, *paths):",
            "    \"\"\"",
            "    Appends the specified POSIX `paths` to the path component of the specified `uri`.",
            "",
            "    :param uri: The input URI, represented as a string.",
            "    :param paths: The POSIX paths to append to the specified `uri`'s path component.",
            "    :return: A new URI with a path component consisting of the specified `paths` appended to",
            "             the path component of the specified `uri`.",
            "",
            "    >>> uri1 = \"s3://root/base/path?param=value\"",
            "    >>> uri1 = append_to_uri_path(uri1, \"some/subpath\", \"/anotherpath\")",
            "    >>> assert uri1 == \"s3://root/base/path/some/subpath/anotherpath?param=value\"",
            "    >>> uri2 = \"a/posix/path\"",
            "    >>> uri2 = append_to_uri_path(uri2, \"/some\", \"subpath\")",
            "    >>> assert uri2 == \"a/posixpath/some/subpath\"",
            "    \"\"\"",
            "    path = \"\"",
            "    for subpath in paths:",
            "        path = _join_posixpaths_and_append_absolute_suffixes(path, subpath)",
            "",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "",
            "    # Validate query string not to contain any traveral path (../) before appending",
            "    # to the end of the path, otherwise they will be resolved as part of the path.",
            "    validate_query_string(parsed_uri.query)",
            "",
            "    if len(parsed_uri.scheme) == 0:",
            "        # If the input URI does not define a scheme, we assume that it is a POSIX path",
            "        # and join it with the specified input paths",
            "        return _join_posixpaths_and_append_absolute_suffixes(uri, path)",
            "",
            "    prefix = \"\"",
            "    if not parsed_uri.path.startswith(\"/\"):",
            "        # For certain URI schemes (e.g., \"file:\"), urllib's unparse routine does",
            "        # not preserve the relative URI path component properly. In certain cases,",
            "        # urlunparse converts relative paths to absolute paths. We introduce this logic",
            "        # to circumvent urlunparse's erroneous conversion",
            "        prefix = parsed_uri.scheme + \":\"",
            "        parsed_uri = parsed_uri._replace(scheme=\"\")",
            "",
            "    new_uri_path = _join_posixpaths_and_append_absolute_suffixes(parsed_uri.path, path)",
            "    new_parsed_uri = parsed_uri._replace(path=new_uri_path)",
            "    return prefix + urllib.parse.urlunparse(new_parsed_uri)",
            "",
            "",
            "def append_to_uri_query_params(uri, *query_params: Tuple[str, Any]) -> str:",
            "    \"\"\"",
            "    Appends the specified query parameters to an existing URI.",
            "",
            "    :param uri: The URI to which to append query parameters.",
            "    :param query_params: Query parameters to append. Each parameter should",
            "                         be a 2-element tuple. For example, ``(\"key\", \"value\")``.",
            "    \"\"\"",
            "    parsed_uri = urllib.parse.urlparse(uri)",
            "    parsed_query = urllib.parse.parse_qsl(parsed_uri.query)",
            "    new_parsed_query = parsed_query + list(query_params)",
            "    new_query = urllib.parse.urlencode(new_parsed_query)",
            "    new_parsed_uri = parsed_uri._replace(query=new_query)",
            "    return urllib.parse.urlunparse(new_parsed_uri)",
            "",
            "",
            "def _join_posixpaths_and_append_absolute_suffixes(prefix_path, suffix_path):",
            "    \"\"\"",
            "    Joins the POSIX path `prefix_path` with the POSIX path `suffix_path`. Unlike posixpath.join(),",
            "    if `suffix_path` is an absolute path, it is appended to prefix_path.",
            "",
            "    >>> result1 = _join_posixpaths_and_append_absolute_suffixes(\"relpath1\", \"relpath2\")",
            "    >>> assert result1 == \"relpath1/relpath2\"",
            "    >>> result2 = _join_posixpaths_and_append_absolute_suffixes(\"relpath\", \"/absolutepath\")",
            "    >>> assert result2 == \"relpath/absolutepath\"",
            "    >>> result3 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath\", \"relpath\")",
            "    >>> assert result3 == \"/absolutepath/relpath\"",
            "    >>> result4 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath1\", \"/absolutepath2\")",
            "    >>> assert result4 == \"/absolutepath1/absolutepath2\"",
            "    \"\"\"",
            "    if len(prefix_path) == 0:",
            "        return suffix_path",
            "",
            "    # If the specified prefix path is non-empty, we must relativize the suffix path by removing",
            "    # the leading slash, if present. Otherwise, posixpath.join() would omit the prefix from the",
            "    # joined path",
            "    suffix_path = suffix_path.lstrip(posixpath.sep)",
            "    return posixpath.join(prefix_path, suffix_path)",
            "",
            "",
            "def is_databricks_acled_artifacts_uri(artifact_uri):",
            "    _ACLED_ARTIFACT_URI = \"databricks/mlflow-tracking/\"",
            "    artifact_uri_path = extract_and_normalize_path(artifact_uri)",
            "    return artifact_uri_path.startswith(_ACLED_ARTIFACT_URI)",
            "",
            "",
            "def is_databricks_model_registry_artifacts_uri(artifact_uri):",
            "    _MODEL_REGISTRY_ARTIFACT_URI = \"databricks/mlflow-registry/\"",
            "    artifact_uri_path = extract_and_normalize_path(artifact_uri)",
            "    return artifact_uri_path.startswith(_MODEL_REGISTRY_ARTIFACT_URI)",
            "",
            "",
            "def is_valid_dbfs_uri(uri):",
            "    parsed = urllib.parse.urlparse(uri)",
            "    if parsed.scheme != \"dbfs\":",
            "        return False",
            "    try:",
            "        db_profile_uri = get_databricks_profile_uri_from_artifact_uri(uri)",
            "    except MlflowException:",
            "        db_profile_uri = None",
            "    return not parsed.netloc or db_profile_uri is not None",
            "",
            "",
            "def dbfs_hdfs_uri_to_fuse_path(dbfs_uri):",
            "    \"\"\"",
            "    Converts the provided DBFS URI into a DBFS FUSE path",
            "    :param dbfs_uri: A DBFS URI like \"dbfs:/my-directory\". Can also be a scheme-less URI like",
            "                     \"/my-directory\" if running in an environment where the default HDFS filesystem",
            "                     is \"dbfs:/\" (e.g. Databricks)",
            "    :return A DBFS FUSE-style path, e.g. \"/dbfs/my-directory\"",
            "    \"\"\"",
            "    if not is_valid_dbfs_uri(dbfs_uri) and dbfs_uri == posixpath.abspath(dbfs_uri):",
            "        # Convert posixpaths (e.g. \"/tmp/mlflow\") to DBFS URIs by adding \"dbfs:/\" as a prefix",
            "        dbfs_uri = \"dbfs:\" + dbfs_uri",
            "    if not dbfs_uri.startswith(_DBFS_HDFS_URI_PREFIX):",
            "        raise MlflowException(",
            "            f\"Path '{dbfs_uri}' did not start with expected DBFS URI \"",
            "            f\"prefix '{_DBFS_HDFS_URI_PREFIX}'\",",
            "        )",
            "",
            "    return _DBFS_FUSE_PREFIX + dbfs_uri[len(_DBFS_HDFS_URI_PREFIX) :]",
            "",
            "",
            "def resolve_uri_if_local(local_uri):",
            "    \"\"\"",
            "    if `local_uri` is passed in as a relative local path, this function",
            "    resolves it to absolute path relative to current working directory.",
            "",
            "    :param local_uri: Relative or absolute path or local file uri",
            "",
            "    :return: a fully-formed absolute uri path or an absolute filesystem path",
            "    \"\"\"",
            "    from mlflow.utils.file_utils import local_file_uri_to_path",
            "",
            "    if local_uri is not None and is_local_uri(local_uri):",
            "        scheme = get_uri_scheme(local_uri)",
            "        cwd = pathlib.Path.cwd()",
            "        local_path = local_file_uri_to_path(local_uri)",
            "        if not pathlib.Path(local_path).is_absolute():",
            "            if scheme == \"\":",
            "                if is_windows():",
            "                    return urllib.parse.urlunsplit(",
            "                        (",
            "                            \"file\",",
            "                            None,",
            "                            cwd.joinpath(local_path).as_posix(),",
            "                            None,",
            "                            None,",
            "                        )",
            "                    )",
            "                return cwd.joinpath(local_path).as_posix()",
            "            local_uri_split = urllib.parse.urlsplit(local_uri)",
            "            return urllib.parse.urlunsplit(",
            "                (",
            "                    local_uri_split.scheme,",
            "                    None,",
            "                    cwd.joinpath(local_path).as_posix(),",
            "                    local_uri_split.query,",
            "                    local_uri_split.fragment,",
            "                )",
            "            )",
            "    return local_uri",
            "",
            "",
            "def generate_tmp_dfs_path(dfs_tmp):",
            "    return posixpath.join(dfs_tmp, str(uuid.uuid4()))",
            "",
            "",
            "def join_paths(*paths: str) -> str:",
            "    stripped = (p.strip(\"/\") for p in paths)",
            "    return \"/\" + posixpath.normpath(posixpath.join(*stripped))",
            "",
            "",
            "_OS_ALT_SEPS = [sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"]",
            "",
            "",
            "def validate_path_is_safe(path):",
            "    \"\"\"",
            "    Validates that the specified path is safe to join with a trusted prefix. This is a security",
            "    measure to prevent path traversal attacks.",
            "    A valid path should:",
            "        not contain separators other than '/'",
            "        not contain .. to navigate to parent dir in path",
            "        not be an absolute path",
            "    \"\"\"",
            "    from mlflow.utils.file_utils import local_file_uri_to_path",
            "",
            "    # We must decode path before validating it",
            "    path = _decode(path)",
            "",
            "    exc = MlflowException(\"Invalid path\", error_code=INVALID_PARAMETER_VALUE)",
            "    if \"#\" in path:",
            "        raise exc",
            "",
            "    if is_file_uri(path):",
            "        path = local_file_uri_to_path(path)",
            "    if (",
            "        any((s in path) for s in _OS_ALT_SEPS)",
            "        or \"..\" in path.split(\"/\")",
            "        or pathlib.PureWindowsPath(path).is_absolute()",
            "        or pathlib.PurePosixPath(path).is_absolute()",
            "        or (is_windows() and len(path) >= 2 and path[1] == \":\")",
            "    ):",
            "        raise exc",
            "",
            "    return path",
            "",
            "",
            "def validate_query_string(query):",
            "    query = _decode(query)",
            "    # Block query strings contain any traveral path (../) because they",
            "    # could be resolved as part of the path and allow path traversal.",
            "    if \"..\" in query:",
            "        raise MlflowException(\"Invalid query string\", error_code=INVALID_PARAMETER_VALUE)",
            "",
            "",
            "def _decode(url):",
            "    # Keep decoding until the url stops changing (with a max of 10 iterations)",
            "    for _ in range(10):",
            "        decoded = urllib.parse.unquote(url)",
            "        if decoded == url:",
            "            return url",
            "        url = decoded",
            "",
            "    raise ValueError(\"Failed to decode url\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "48": [
                "is_local_uri"
            ],
            "52": [
                "is_local_uri"
            ],
            "53": [
                "is_local_uri"
            ],
            "54": [
                "is_local_uri"
            ],
            "65": [
                "is_file_uri"
            ]
        },
        "addLocation": []
    }
}