{
    "src/label_studio_sdk/_extensions/label_studio_tools/core/utils/io.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "     return cache_dir"
            },
            "1": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+def safe_build_path(base_dir: str, user_path: str) -> str:"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+    combined_path = os.path.join(base_dir, user_path)"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+    absolute_path = os.path.abspath(combined_path)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+    base_dir_abs = os.path.abspath(base_dir)"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+    if os.path.commonpath([absolute_path, base_dir_abs]) != base_dir_abs:"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+        raise ValueError(f\"Invalid path: {user_path}\")"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+    return absolute_path"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 51,
                "PatchRowcode": " def get_local_path("
            },
            "15": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "     url,"
            },
            "16": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "     cache_dir=None,"
            },
            "17": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "     # instead of downloading them from LS instance"
            },
            "18": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "     if is_local_storage_file:"
            },
            "19": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 116,
                "PatchRowcode": "         filepath = url.split(\"?d=\")[1]"
            },
            "20": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        filepath = os.path.join(LOCAL_FILES_DOCUMENT_ROOT, filepath)"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+        filepath = safe_build_path(LOCAL_FILES_DOCUMENT_ROOT, filepath)"
            },
            "22": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "         if os.path.exists(filepath):"
            },
            "23": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "             logger.debug("
            },
            "24": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 120,
                "PatchRowcode": "                 f\"Local Storage file path exists locally, use it as a local file: {filepath}\""
            }
        },
        "frontPatchFile": [
            "import hashlib",
            "import io",
            "import logging",
            "import os",
            "import shutil",
            "from contextlib import contextmanager",
            "from tempfile import mkdtemp",
            "from urllib.parse import urlparse",
            "",
            "import requests",
            "from appdirs import user_cache_dir, user_data_dir",
            "",
            "from label_studio_sdk._extensions.label_studio_tools.core.utils.params import get_env",
            "",
            "_DIR_APP_NAME = \"label-studio\"",
            "LOCAL_FILES_DOCUMENT_ROOT = get_env(",
            "    \"LOCAL_FILES_DOCUMENT_ROOT\", default=os.path.abspath(os.sep)",
            ")",
            "VERIFY_SSL = get_env(\"VERIFY_SSL\", default=True, is_bool=True)",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def concat_urls(base_url, url):",
            "    return base_url.rstrip(\"/\") + \"/\" + url.lstrip(\"/\")",
            "",
            "",
            "def get_data_dir():",
            "    data_dir = user_data_dir(appname=_DIR_APP_NAME)",
            "    os.makedirs(data_dir, exist_ok=True)",
            "    return data_dir",
            "",
            "",
            "def get_cache_dir():",
            "    cache_dir = user_cache_dir(appname=_DIR_APP_NAME)",
            "    os.makedirs(cache_dir, exist_ok=True)",
            "    return cache_dir",
            "",
            "",
            "def get_local_path(",
            "    url,",
            "    cache_dir=None,",
            "    project_dir=None,",
            "    hostname=None,",
            "    image_dir=None,",
            "    access_token=None,",
            "    download_resources=True,",
            "    task_id=None,",
            "):",
            "    f\"\"\"This helper function is used to download (cache) url and return local path to it.",
            "",
            "    :param url: File URL to download, it can be a uploaded file, local storage, cloud storage file or just http(s) url",
            "    :param cache_dir: Cache directory to download or copy files",
            "    :param project_dir: Project directory",
            "    :param hostname: Label Studio Hostname, it will be used for uploaded files, local storage files and cloud storage files",
            "      if not provided, it will be taken from LABEL_STUDIO_URL env variable",
            "    :param image_dir: Image and other media upload directory",
            "    :param access_token: Label Studio access token, it will be used for uploaded files, local storage files and cloud storage files",
            "      if not provided, it will be taken from LABEL_STUDIO_API_KEY env variable",
            "    :param download_resources: Download and cache a file from URL",
            "    :param task_id: Label Studio Task ID, required for cloud storage files ",
            "      because the URL will be rebuilt to `{hostname}/tasks/{task_id}/presign/?fileuri={url}` ",
            "",
            "    :return: filepath",
            "    \"\"\"",
            "    # get environment variables",
            "    hostname = (",
            "        hostname",
            "        or os.getenv(\"LABEL_STUDIO_URL\", \"\")",
            "        or os.getenv(\"LABEL_STUDIO_HOST\", \"\")",
            "    )",
            "    access_token = (",
            "        access_token",
            "        or os.getenv(\"LABEL_STUDIO_API_KEY\", \"\")",
            "        or os.getenv(\"LABEL_STUDIO_ACCESS_TOKEN\", \"\")",
            "    )",
            "    if \"localhost\" in hostname:",
            "        logger.warning(",
            "            f\"Using `localhost` ({hostname}) in LABEL_STUDIO_URL, \"",
            "            f\"`localhost` is not accessible inside of docker containers. \"",
            "            f\"You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\"",
            "        )",
            "    if hostname and not (",
            "        hostname.startswith(\"http://\") or hostname.startswith(\"https://\")",
            "    ):",
            "        raise ValueError(",
            "            f\"Invalid hostname in LABEL_STUDIO_URL: {hostname}. \"",
            "            \"Please provide full URL starting with protocol (http:// or https://).\"",
            "        )",
            "",
            "    # fix file upload url",
            "    if url.startswith(\"upload\") or url.startswith(\"/upload\"):",
            "        url = \"/data\" + (\"\" if url.startswith(\"/\") else \"/\") + url",
            "",
            "    is_uploaded_file = url.startswith(\"/data/upload\")",
            "    is_local_storage_file = url.startswith(\"/data/\") and \"?d=\" in url",
            "    is_cloud_storage_file = (",
            "        url.startswith(\"s3:\") or url.startswith(\"gs:\") or url.startswith(\"azure-blob:\")",
            "    )",
            "",
            "    # Local storage file: try to load locally otherwise download below",
            "    # this code allow to read Local Storage files directly from a directory",
            "    # instead of downloading them from LS instance",
            "    if is_local_storage_file:",
            "        filepath = url.split(\"?d=\")[1]",
            "        filepath = os.path.join(LOCAL_FILES_DOCUMENT_ROOT, filepath)",
            "        if os.path.exists(filepath):",
            "            logger.debug(",
            "                f\"Local Storage file path exists locally, use it as a local file: {filepath}\"",
            "            )",
            "            return filepath",
            "",
            "    # try to get local directories",
            "    if image_dir is None:",
            "        upload_dir = os.path.join(get_data_dir(), \"media\", \"upload\")",
            "        image_dir = project_dir and os.path.join(project_dir, \"upload\") or upload_dir",
            "        logger.debug(",
            "            f\"Image and upload dirs: image_dir={image_dir}, upload_dir={upload_dir}\"",
            "        )",
            "",
            "    # Uploaded file: try to load locally otherwise download below",
            "    # this code allow to read Uploaded files directly from a directory",
            "    # instead of downloading them from LS instance",
            "    if is_uploaded_file and os.path.exists(image_dir):",
            "        project_id = url.split(\"/\")[-2]  # To retrieve project_id",
            "        filepath = os.path.join(image_dir, project_id, os.path.basename(url))",
            "        if os.path.exists(filepath):",
            "            if cache_dir and download_resources:",
            "                shutil.copy(filepath, cache_dir)",
            "            logger.debug(f\"Uploaded file: Path exists in image_dir: {filepath}\")",
            "            return filepath",
            "",
            "    # Upload or Local Storage file",
            "    if is_uploaded_file or is_local_storage_file or is_cloud_storage_file:",
            "        # hostname check",
            "        if not hostname:",
            "            raise FileNotFoundError(",
            "                f\"Can't resolve url, neither hostname or project_dir passed: {url}. \"",
            "                \"You can set LABEL_STUDIO_URL environment variable to use it as a hostname.\"",
            "            )",
            "        # uploaded and local storage file",
            "        elif is_uploaded_file or is_local_storage_file:",
            "            url = concat_urls(hostname, url)",
            "            logger.info(\"Resolving url using hostname [\" + hostname + \"]: \" + url)",
            "        # s3, gs, azure-blob file",
            "        elif is_cloud_storage_file:",
            "            if task_id is None:",
            "                raise Exception(",
            "                    \"Label Studio Task ID is required for cloud storage files\"",
            "                )",
            "            url = concat_urls(hostname, f\"/tasks/{task_id}/presign/?fileuri={url}\")",
            "            logger.info(",
            "                \"Cloud storage file: Resolving url using hostname [\"",
            "                + hostname",
            "                + \"]: \"",
            "                + url",
            "            )",
            "",
            "        # check access token",
            "        if not access_token:",
            "            raise FileNotFoundError(",
            "                \"To access uploaded and local storage files you have to \"",
            "                \"set LABEL_STUDIO_API_KEY environment variable.\"",
            "            )",
            "",
            "    filepath = download_and_cache(",
            "        url,",
            "        cache_dir,",
            "        download_resources,",
            "        hostname,",
            "        access_token,",
            "        is_local_storage_file,",
            "        is_cloud_storage_file,",
            "    )",
            "    return filepath",
            "",
            "",
            "def download_and_cache(",
            "    url,",
            "    cache_dir,",
            "    download_resources,",
            "    hostname,",
            "    access_token,",
            "    is_local_storage_file,",
            "    is_cloud_storage_file,",
            "):",
            "    # File specified by remote URL - download and cache it",
            "    cache_dir = cache_dir or get_cache_dir()",
            "    parsed_url = urlparse(url)",
            "",
            "    # local storage: /data/local-files?d=dir/1.jpg => 1.jpg",
            "    if is_local_storage_file:",
            "        url_filename = os.path.basename(url.split('?d=')[1])",
            "    # cloud storage: s3://bucket/1.jpg => 1.jpg",
            "    elif is_cloud_storage_file:",
            "        url_filename = os.path.basename(url)",
            "    # all others: /some/url/1.jpg?expire=xxx => 1.jpg",
            "    else:",
            "        url_filename = os.path.basename(parsed_url.path)",
            "",
            "    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]",
            "    filepath = os.path.join(cache_dir, url_hash + \"__\" + url_filename)",
            "",
            "    if not os.path.exists(filepath):",
            "        logger.info(\"Download {url} to {filepath}. download_resources: {download_resources}\".format(url=url, filepath=filepath, download_resources=download_resources))",
            "        if download_resources:",
            "            headers = {",
            "                # avoid requests.exceptions.HTTPError: 403 Client Error: Forbidden. Please comply with the User-Agent policy:",
            "                \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"",
            "            }",
            "            # check if url matches hostname - then uses access token to this Label Studio instance",
            "            if (",
            "                access_token",
            "                and hostname",
            "                and parsed_url.netloc == urlparse(hostname).netloc",
            "            ):",
            "                headers[\"Authorization\"] = \"Token \" + access_token",
            "                logger.debug(\"Authorization token is used for download_and_cache\")",
            "            try:",
            "                r = requests.get(url, stream=True, headers=headers, verify=VERIFY_SSL)",
            "                r.raise_for_status()",
            "            except requests.exceptions.SSLError as e:",
            "                logger.error(",
            "                    f\"SSL error during requests.get('{url}'): {e}\\n\"",
            "                    f\"Try to set VERIFY_SSL=False in environment variables to bypass SSL verification.\"",
            "                )",
            "                raise e",
            "            with io.open(filepath, mode=\"wb\") as fout:",
            "                fout.write(r.content)",
            "                logger.info(f\"File downloaded to {filepath}\")",
            "    return filepath",
            "",
            "",
            "@contextmanager",
            "def get_temp_dir():",
            "    dirpath = mkdtemp()",
            "    yield dirpath",
            "    shutil.rmtree(dirpath)",
            "",
            "",
            "def get_all_files_from_dir(d):",
            "    out = []",
            "    for name in os.listdir(d):",
            "        filepath = os.path.join(d, name)",
            "        if os.path.isfile(filepath):",
            "            out.append(filepath)",
            "    return out"
        ],
        "afterPatchFile": [
            "import hashlib",
            "import io",
            "import logging",
            "import os",
            "import shutil",
            "from contextlib import contextmanager",
            "from tempfile import mkdtemp",
            "from urllib.parse import urlparse",
            "",
            "import requests",
            "from appdirs import user_cache_dir, user_data_dir",
            "",
            "from label_studio_sdk._extensions.label_studio_tools.core.utils.params import get_env",
            "",
            "_DIR_APP_NAME = \"label-studio\"",
            "LOCAL_FILES_DOCUMENT_ROOT = get_env(",
            "    \"LOCAL_FILES_DOCUMENT_ROOT\", default=os.path.abspath(os.sep)",
            ")",
            "VERIFY_SSL = get_env(\"VERIFY_SSL\", default=True, is_bool=True)",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def concat_urls(base_url, url):",
            "    return base_url.rstrip(\"/\") + \"/\" + url.lstrip(\"/\")",
            "",
            "",
            "def get_data_dir():",
            "    data_dir = user_data_dir(appname=_DIR_APP_NAME)",
            "    os.makedirs(data_dir, exist_ok=True)",
            "    return data_dir",
            "",
            "",
            "def get_cache_dir():",
            "    cache_dir = user_cache_dir(appname=_DIR_APP_NAME)",
            "    os.makedirs(cache_dir, exist_ok=True)",
            "    return cache_dir",
            "",
            "",
            "def safe_build_path(base_dir: str, user_path: str) -> str:",
            "    combined_path = os.path.join(base_dir, user_path)",
            "    absolute_path = os.path.abspath(combined_path)",
            "    base_dir_abs = os.path.abspath(base_dir)",
            "",
            "    if os.path.commonpath([absolute_path, base_dir_abs]) != base_dir_abs:",
            "        raise ValueError(f\"Invalid path: {user_path}\")",
            "",
            "    return absolute_path",
            "",
            "",
            "def get_local_path(",
            "    url,",
            "    cache_dir=None,",
            "    project_dir=None,",
            "    hostname=None,",
            "    image_dir=None,",
            "    access_token=None,",
            "    download_resources=True,",
            "    task_id=None,",
            "):",
            "    f\"\"\"This helper function is used to download (cache) url and return local path to it.",
            "",
            "    :param url: File URL to download, it can be a uploaded file, local storage, cloud storage file or just http(s) url",
            "    :param cache_dir: Cache directory to download or copy files",
            "    :param project_dir: Project directory",
            "    :param hostname: Label Studio Hostname, it will be used for uploaded files, local storage files and cloud storage files",
            "      if not provided, it will be taken from LABEL_STUDIO_URL env variable",
            "    :param image_dir: Image and other media upload directory",
            "    :param access_token: Label Studio access token, it will be used for uploaded files, local storage files and cloud storage files",
            "      if not provided, it will be taken from LABEL_STUDIO_API_KEY env variable",
            "    :param download_resources: Download and cache a file from URL",
            "    :param task_id: Label Studio Task ID, required for cloud storage files ",
            "      because the URL will be rebuilt to `{hostname}/tasks/{task_id}/presign/?fileuri={url}` ",
            "",
            "    :return: filepath",
            "    \"\"\"",
            "    # get environment variables",
            "    hostname = (",
            "        hostname",
            "        or os.getenv(\"LABEL_STUDIO_URL\", \"\")",
            "        or os.getenv(\"LABEL_STUDIO_HOST\", \"\")",
            "    )",
            "    access_token = (",
            "        access_token",
            "        or os.getenv(\"LABEL_STUDIO_API_KEY\", \"\")",
            "        or os.getenv(\"LABEL_STUDIO_ACCESS_TOKEN\", \"\")",
            "    )",
            "    if \"localhost\" in hostname:",
            "        logger.warning(",
            "            f\"Using `localhost` ({hostname}) in LABEL_STUDIO_URL, \"",
            "            f\"`localhost` is not accessible inside of docker containers. \"",
            "            f\"You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\"",
            "        )",
            "    if hostname and not (",
            "        hostname.startswith(\"http://\") or hostname.startswith(\"https://\")",
            "    ):",
            "        raise ValueError(",
            "            f\"Invalid hostname in LABEL_STUDIO_URL: {hostname}. \"",
            "            \"Please provide full URL starting with protocol (http:// or https://).\"",
            "        )",
            "",
            "    # fix file upload url",
            "    if url.startswith(\"upload\") or url.startswith(\"/upload\"):",
            "        url = \"/data\" + (\"\" if url.startswith(\"/\") else \"/\") + url",
            "",
            "    is_uploaded_file = url.startswith(\"/data/upload\")",
            "    is_local_storage_file = url.startswith(\"/data/\") and \"?d=\" in url",
            "    is_cloud_storage_file = (",
            "        url.startswith(\"s3:\") or url.startswith(\"gs:\") or url.startswith(\"azure-blob:\")",
            "    )",
            "",
            "    # Local storage file: try to load locally otherwise download below",
            "    # this code allow to read Local Storage files directly from a directory",
            "    # instead of downloading them from LS instance",
            "    if is_local_storage_file:",
            "        filepath = url.split(\"?d=\")[1]",
            "        filepath = safe_build_path(LOCAL_FILES_DOCUMENT_ROOT, filepath)",
            "        if os.path.exists(filepath):",
            "            logger.debug(",
            "                f\"Local Storage file path exists locally, use it as a local file: {filepath}\"",
            "            )",
            "            return filepath",
            "",
            "    # try to get local directories",
            "    if image_dir is None:",
            "        upload_dir = os.path.join(get_data_dir(), \"media\", \"upload\")",
            "        image_dir = project_dir and os.path.join(project_dir, \"upload\") or upload_dir",
            "        logger.debug(",
            "            f\"Image and upload dirs: image_dir={image_dir}, upload_dir={upload_dir}\"",
            "        )",
            "",
            "    # Uploaded file: try to load locally otherwise download below",
            "    # this code allow to read Uploaded files directly from a directory",
            "    # instead of downloading them from LS instance",
            "    if is_uploaded_file and os.path.exists(image_dir):",
            "        project_id = url.split(\"/\")[-2]  # To retrieve project_id",
            "        filepath = os.path.join(image_dir, project_id, os.path.basename(url))",
            "        if os.path.exists(filepath):",
            "            if cache_dir and download_resources:",
            "                shutil.copy(filepath, cache_dir)",
            "            logger.debug(f\"Uploaded file: Path exists in image_dir: {filepath}\")",
            "            return filepath",
            "",
            "    # Upload or Local Storage file",
            "    if is_uploaded_file or is_local_storage_file or is_cloud_storage_file:",
            "        # hostname check",
            "        if not hostname:",
            "            raise FileNotFoundError(",
            "                f\"Can't resolve url, neither hostname or project_dir passed: {url}. \"",
            "                \"You can set LABEL_STUDIO_URL environment variable to use it as a hostname.\"",
            "            )",
            "        # uploaded and local storage file",
            "        elif is_uploaded_file or is_local_storage_file:",
            "            url = concat_urls(hostname, url)",
            "            logger.info(\"Resolving url using hostname [\" + hostname + \"]: \" + url)",
            "        # s3, gs, azure-blob file",
            "        elif is_cloud_storage_file:",
            "            if task_id is None:",
            "                raise Exception(",
            "                    \"Label Studio Task ID is required for cloud storage files\"",
            "                )",
            "            url = concat_urls(hostname, f\"/tasks/{task_id}/presign/?fileuri={url}\")",
            "            logger.info(",
            "                \"Cloud storage file: Resolving url using hostname [\"",
            "                + hostname",
            "                + \"]: \"",
            "                + url",
            "            )",
            "",
            "        # check access token",
            "        if not access_token:",
            "            raise FileNotFoundError(",
            "                \"To access uploaded and local storage files you have to \"",
            "                \"set LABEL_STUDIO_API_KEY environment variable.\"",
            "            )",
            "",
            "    filepath = download_and_cache(",
            "        url,",
            "        cache_dir,",
            "        download_resources,",
            "        hostname,",
            "        access_token,",
            "        is_local_storage_file,",
            "        is_cloud_storage_file,",
            "    )",
            "    return filepath",
            "",
            "",
            "def download_and_cache(",
            "    url,",
            "    cache_dir,",
            "    download_resources,",
            "    hostname,",
            "    access_token,",
            "    is_local_storage_file,",
            "    is_cloud_storage_file,",
            "):",
            "    # File specified by remote URL - download and cache it",
            "    cache_dir = cache_dir or get_cache_dir()",
            "    parsed_url = urlparse(url)",
            "",
            "    # local storage: /data/local-files?d=dir/1.jpg => 1.jpg",
            "    if is_local_storage_file:",
            "        url_filename = os.path.basename(url.split('?d=')[1])",
            "    # cloud storage: s3://bucket/1.jpg => 1.jpg",
            "    elif is_cloud_storage_file:",
            "        url_filename = os.path.basename(url)",
            "    # all others: /some/url/1.jpg?expire=xxx => 1.jpg",
            "    else:",
            "        url_filename = os.path.basename(parsed_url.path)",
            "",
            "    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]",
            "    filepath = os.path.join(cache_dir, url_hash + \"__\" + url_filename)",
            "",
            "    if not os.path.exists(filepath):",
            "        logger.info(\"Download {url} to {filepath}. download_resources: {download_resources}\".format(url=url, filepath=filepath, download_resources=download_resources))",
            "        if download_resources:",
            "            headers = {",
            "                # avoid requests.exceptions.HTTPError: 403 Client Error: Forbidden. Please comply with the User-Agent policy:",
            "                \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"",
            "            }",
            "            # check if url matches hostname - then uses access token to this Label Studio instance",
            "            if (",
            "                access_token",
            "                and hostname",
            "                and parsed_url.netloc == urlparse(hostname).netloc",
            "            ):",
            "                headers[\"Authorization\"] = \"Token \" + access_token",
            "                logger.debug(\"Authorization token is used for download_and_cache\")",
            "            try:",
            "                r = requests.get(url, stream=True, headers=headers, verify=VERIFY_SSL)",
            "                r.raise_for_status()",
            "            except requests.exceptions.SSLError as e:",
            "                logger.error(",
            "                    f\"SSL error during requests.get('{url}'): {e}\\n\"",
            "                    f\"Try to set VERIFY_SSL=False in environment variables to bypass SSL verification.\"",
            "                )",
            "                raise e",
            "            with io.open(filepath, mode=\"wb\") as fout:",
            "                fout.write(r.content)",
            "                logger.info(f\"File downloaded to {filepath}\")",
            "    return filepath",
            "",
            "",
            "@contextmanager",
            "def get_temp_dir():",
            "    dirpath = mkdtemp()",
            "    yield dirpath",
            "    shutil.rmtree(dirpath)",
            "",
            "",
            "def get_all_files_from_dir(d):",
            "    out = []",
            "    for name in os.listdir(d):",
            "        filepath = os.path.join(d, name)",
            "        if os.path.isfile(filepath):",
            "            out.append(filepath)",
            "    return out"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "106": [
                "get_local_path"
            ]
        },
        "addLocation": [
            "src.label_studio_sdk._extensions.label_studio_tools.core.utils.io.get_local_path"
        ]
    },
    "src/label_studio_sdk/converter/utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from nltk.tokenize.treebank import TreebankWordTokenizer"
            },
            "1": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from label_studio_sdk._extensions.label_studio_tools.core.utils.params import get_env"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+from label_studio_sdk._extensions.label_studio_tools.core.utils.io import safe_build_path"
            },
            "4": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " logger = logging.getLogger(__name__)"
            },
            "6": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "     if is_uploaded_file:"
            },
            "8": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "         upload_dir = _get_upload_dir(project_dir, upload_dir)"
            },
            "9": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "         filename = urllib.parse.unquote(url.replace(\"/data/upload/\", \"\"))"
            },
            "10": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        filepath = os.path.join(upload_dir, filename)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+        filepath = safe_build_path(upload_dir, filename)"
            },
            "12": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "         logger.debug("
            },
            "13": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "             f\"Copy {filepath} to {output_dir}\".format("
            },
            "14": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 155,
                "PatchRowcode": "                 filepath=filepath, output_dir=output_dir"
            },
            "15": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 166,
                "PatchRowcode": "     if is_local_file:"
            },
            "16": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "         filename, dir_path = url.split(\"/data/\", 1)[-1].split(\"?d=\")"
            },
            "17": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "         dir_path = str(urllib.parse.unquote(dir_path))"
            },
            "18": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        filepath = os.path.join(LOCAL_FILES_DOCUMENT_ROOT, dir_path)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+        filepath = safe_build_path(LOCAL_FILES_DOCUMENT_ROOT, dir_path)"
            },
            "20": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "         if not os.path.exists(filepath):"
            },
            "21": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "             raise FileNotFoundError(filepath)"
            },
            "22": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 172,
                "PatchRowcode": "         if download_resources:"
            }
        },
        "frontPatchFile": [
            "import argparse",
            "import datetime",
            "import hashlib",
            "import io",
            "import logging",
            "import math",
            "import os",
            "import re",
            "import shutil",
            "import urllib",
            "import wave",
            "from collections import defaultdict",
            "from copy import deepcopy",
            "from operator import itemgetter",
            "from urllib.parse import urlparse",
            "",
            "import numpy as np",
            "import requests",
            "from PIL import Image",
            "from lxml import etree",
            "from nltk.tokenize.treebank import TreebankWordTokenizer",
            "",
            "from label_studio_sdk._extensions.label_studio_tools.core.utils.params import get_env",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "_LABEL_TAGS = {\"Label\", \"Choice\"}",
            "_NOT_CONTROL_TAGS = {",
            "    \"Filter\",",
            "}",
            "LOCAL_FILES_DOCUMENT_ROOT = get_env(",
            "    \"LOCAL_FILES_DOCUMENT_ROOT\", default=os.path.abspath(os.sep)",
            ")",
            "",
            "TreebankWordTokenizer.PUNCTUATION = [",
            "    (re.compile(r\"([:,])([^\\d])\"), r\" \\1 \\2\"),",
            "    (re.compile(r\"([:,])$\"), r\" \\1 \"),",
            "    (re.compile(r\"\\.\\.\\.\"), r\" ... \"),",
            "    (re.compile(r\"[;@#$/%&]\"), r\" \\g<0> \"),",
            "    (",
            "        re.compile(r'([^\\.])(\\.)([\\]\\)}>\"\\']*)\\s*$'),",
            "        r\"\\1 \\2\\3 \",",
            "    ),  # Handles the final period.",
            "    (re.compile(r\"[?!]\"), r\" \\g<0> \"),",
            "    (re.compile(r\"([^'])' \"), r\"\\1 ' \"),",
            "]",
            "",
            "",
            "class ExpandFullPath(argparse.Action):",
            "    def __call__(self, parser, namespace, values, option_string=None):",
            "        setattr(namespace, self.dest, os.path.abspath(os.path.expanduser(values)))",
            "",
            "",
            "def tokenize(text):",
            "    tok_start = 0",
            "    out = []",
            "    for tok in text.split():",
            "        if len(tok):",
            "            out.append((tok, tok_start))",
            "            tok_start += len(tok) + 1",
            "        else:",
            "            tok_start += 1",
            "    return out",
            "",
            "",
            "def create_tokens_and_tags(text, spans):",
            "    # tokens_and_idx = tokenize(text) # This function doesn't work properly if text contains multiple whitespaces...",
            "    token_index_tuples = [",
            "        token for token in TreebankWordTokenizer().span_tokenize(text)",
            "    ]",
            "    tokens_and_idx = [(text[start:end], start) for start, end in token_index_tuples]",
            "    if spans and all(",
            "        [",
            "            span.get(\"start\") is not None and span.get(\"end\") is not None",
            "            for span in spans",
            "        ]",
            "    ):",
            "        spans = list(sorted(spans, key=itemgetter(\"start\")))",
            "        span = spans.pop(0)",
            "        span_start = span[\"start\"]",
            "        span_end = span[\"end\"] - 1",
            "        prefix = \"B-\"",
            "        tokens, tags = [], []",
            "        for token, token_start in tokens_and_idx:",
            "            tokens.append(token)",
            "            token_end = (",
            "                token_start + len(token) - 1",
            "            )  # \"- 1\" - This substraction is wrong. token already uses the index E.g. \"Hello\" is 0-4",
            "            token_start_ind = token_start  # It seems like the token start is too early.. for whichever reason",
            "",
            "            # if for some reason end of span is missed.. pop the new span (Which is quite probable due to this method)",
            "            # Attention it seems like span['end'] is the index of first char afterwards. In case the whitespace is part of the",
            "            # labell we need to subtract one. Otherwise next token won't trigger the span update.. only the token after next..",
            "            if token_start_ind > span_end:",
            "                while spans:",
            "                    span = spans.pop(0)",
            "                    span_start = span[\"start\"]",
            "                    span_end = span[\"end\"] - 1",
            "                    prefix = \"B-\"",
            "                    if token_start <= span_end:",
            "                        break",
            "            # Add tag \"O\" for spans that:",
            "            # - are empty",
            "            # - span start has passed over token_end",
            "            # - do not have any label (None or empty list)",
            "            if not span or token_end < span_start or not span.get(\"labels\"):",
            "                tags.append(\"O\")",
            "            elif span_start <= token_end and span_end >= token_start_ind:",
            "                tags.append(prefix + span[\"labels\"][0])",
            "                prefix = \"I-\"",
            "            else:",
            "                tags.append(\"O\")",
            "    else:",
            "        tokens = [token for token, _ in tokens_and_idx]",
            "        tags = [\"O\"] * len(tokens)",
            "",
            "    return tokens, tags",
            "",
            "",
            "def _get_upload_dir(project_dir=None, upload_dir=None):",
            "    \"\"\"Return either upload_dir, or path by LS_UPLOAD_DIR, or project_dir/upload\"\"\"",
            "    if upload_dir:",
            "        return upload_dir",
            "    upload_dir = os.environ.get(\"LS_UPLOAD_DIR\")",
            "    if not upload_dir and project_dir:",
            "        upload_dir = os.path.join(project_dir, \"upload\")",
            "        if not os.path.exists(upload_dir):",
            "            upload_dir = None",
            "    if not upload_dir:",
            "        raise FileNotFoundError(",
            "            \"Can't find upload dir: either LS_UPLOAD_DIR or project should be passed to converter\"",
            "        )",
            "    return upload_dir",
            "",
            "",
            "def download(",
            "    url,",
            "    output_dir,",
            "    filename=None,",
            "    project_dir=None,",
            "    return_relative_path=False,",
            "    upload_dir=None,",
            "    download_resources=True,",
            "):",
            "    is_local_file = url.startswith(\"/data/\") and \"?d=\" in url",
            "    is_uploaded_file = url.startswith(\"/data/upload\")",
            "",
            "    if is_uploaded_file:",
            "        upload_dir = _get_upload_dir(project_dir, upload_dir)",
            "        filename = urllib.parse.unquote(url.replace(\"/data/upload/\", \"\"))",
            "        filepath = os.path.join(upload_dir, filename)",
            "        logger.debug(",
            "            f\"Copy {filepath} to {output_dir}\".format(",
            "                filepath=filepath, output_dir=output_dir",
            "            )",
            "        )",
            "        if download_resources:",
            "            shutil.copy(filepath, output_dir)",
            "        if return_relative_path:",
            "            return os.path.join(",
            "                os.path.basename(output_dir), os.path.basename(filename)",
            "            )",
            "        return filepath",
            "",
            "    if is_local_file:",
            "        filename, dir_path = url.split(\"/data/\", 1)[-1].split(\"?d=\")",
            "        dir_path = str(urllib.parse.unquote(dir_path))",
            "        filepath = os.path.join(LOCAL_FILES_DOCUMENT_ROOT, dir_path)",
            "        if not os.path.exists(filepath):",
            "            raise FileNotFoundError(filepath)",
            "        if download_resources:",
            "            shutil.copy(filepath, output_dir)",
            "        return filepath",
            "",
            "    if filename is None:",
            "        basename, ext = os.path.splitext(os.path.basename(urlparse(url).path))",
            "        filename = f\"{basename}{ext}\"",
            "        filepath = os.path.join(output_dir, filename)",
            "        if os.path.exists(filepath):",
            "            filename = (",
            "                basename",
            "                + \"_\"",
            "                + hashlib.md5(",
            "                    url.encode() + str(datetime.datetime.now().timestamp()).encode()",
            "                ).hexdigest()[:4]",
            "                + ext",
            "            )",
            "",
            "    filepath = os.path.join(output_dir, filename)",
            "    if not os.path.exists(filepath):",
            "        logger.info(\"Download {url} to {filepath}\".format(url=url, filepath=filepath))",
            "        if download_resources:",
            "            r = requests.get(url)",
            "            r.raise_for_status()",
            "            with io.open(filepath, mode=\"wb\") as fout:",
            "                fout.write(r.content)",
            "    if return_relative_path:",
            "        return os.path.join(os.path.basename(output_dir), os.path.basename(filename))",
            "    return filepath",
            "",
            "",
            "def get_image_size(image_path):",
            "    return Image.open(image_path).size",
            "",
            "",
            "def get_image_size_and_channels(image_path):",
            "    i = Image.open(image_path)",
            "    w, h = i.size",
            "    c = len(i.getbands())",
            "    return w, h, c",
            "",
            "",
            "def get_audio_duration(audio_path):",
            "    with wave.open(audio_path, mode=\"r\") as f:",
            "        return f.getnframes() / float(f.getframerate())",
            "",
            "",
            "def ensure_dir(dir_path):",
            "    if not os.path.exists(dir_path):",
            "        os.makedirs(dir_path)",
            "",
            "",
            "def parse_config(config_string):",
            "    \"\"\"",
            "    :param config_string: Label config string",
            "    :return: structured config of the form:",
            "    {",
            "        \"<ControlTag>.name\": {",
            "            \"type\": \"ControlTag\",",
            "            \"to_name\": [\"<ObjectTag1>.name\", \"<ObjectTag2>.name\"],",
            "            \"inputs: [",
            "                {\"type\": \"ObjectTag1\", \"value\": \"<ObjectTag1>.value\"},",
            "                {\"type\": \"ObjectTag2\", \"value\": \"<ObjectTag2>.value\"}",
            "            ],",
            "            \"labels\": [\"Label1\", \"Label2\", \"Label3\"] // taken from \"alias\" if exists or \"value\"",
            "    }",
            "    \"\"\"",
            "    if not config_string:",
            "        return {}",
            "",
            "    def _is_input_tag(tag):",
            "        return tag.attrib.get(\"name\") and tag.attrib.get(\"value\")",
            "",
            "    def _is_output_tag(tag):",
            "        return (",
            "            tag.attrib.get(\"name\")",
            "            and tag.attrib.get(\"toName\")",
            "            and tag.tag not in _NOT_CONTROL_TAGS",
            "        )",
            "",
            "    def _get_parent_output_tag_name(tag, outputs):",
            "        # Find parental <Choices> tag for nested tags like <Choices><View><View><Choice>...",
            "        parent = tag",
            "        while True:",
            "            parent = parent.getparent()",
            "            if parent is None:",
            "                return",
            "            name = parent.attrib.get(\"name\")",
            "            if name in outputs:",
            "                return name",
            "",
            "    try:",
            "        xml_tree = etree.fromstring(config_string)",
            "    except etree.XMLSyntaxError as e:",
            "        raise ValueError(str(e))",
            "",
            "    inputs, outputs, labels = {}, {}, defaultdict(dict)",
            "    for tag in xml_tree.iter():",
            "        if _is_output_tag(tag):",
            "            tag_info = {\"type\": tag.tag, \"to_name\": tag.attrib[\"toName\"].split(\",\")}",
            "            # Grab conditionals if any",
            "            conditionals = {}",
            "            if tag.attrib.get(\"perRegion\") == \"true\":",
            "                if tag.attrib.get(\"whenTagName\"):",
            "                    conditionals = {\"type\": \"tag\", \"name\": tag.attrib[\"whenTagName\"]}",
            "                elif tag.attrib.get(\"whenLabelValue\"):",
            "                    conditionals = {",
            "                        \"type\": \"label\",",
            "                        \"name\": tag.attrib[\"whenLabelValue\"],",
            "                    }",
            "                elif tag.attrib.get(\"whenChoiceValue\"):",
            "                    conditionals = {",
            "                        \"type\": \"choice\",",
            "                        \"name\": tag.attrib[\"whenChoiceValue\"],",
            "                    }",
            "            if conditionals:",
            "                tag_info[\"conditionals\"] = conditionals",
            "            outputs[tag.attrib[\"name\"]] = tag_info",
            "        elif _is_input_tag(tag):",
            "            inputs[tag.attrib[\"name\"]] = {",
            "                \"type\": tag.tag,",
            "                \"value\": tag.attrib[\"value\"].lstrip(\"$\"),",
            "            }",
            "        if tag.tag not in _LABEL_TAGS:",
            "            continue",
            "        parent_name = _get_parent_output_tag_name(tag, outputs)",
            "        if parent_name is not None:",
            "            actual_value = tag.attrib.get(\"alias\") or tag.attrib.get(\"value\")",
            "            if not actual_value:",
            "                logger.debug(",
            "                    'Inspecting tag {tag_name}... found no \"value\" or \"alias\" attributes.'.format(",
            "                        tag_name=etree.tostring(tag, encoding=\"unicode\").strip()[:50]",
            "                    )",
            "                )",
            "            else:",
            "                labels[parent_name][actual_value] = dict(tag.attrib)",
            "    for output_tag, tag_info in outputs.items():",
            "        tag_info[\"inputs\"] = []",
            "        for input_tag_name in tag_info[\"to_name\"]:",
            "            if input_tag_name not in inputs:",
            "                logger.debug(",
            "                    f\"to_name={input_tag_name} is specified for output tag name={output_tag}, \"",
            "                    \"but we can't find it among input tags\"",
            "                )",
            "                continue",
            "            tag_info[\"inputs\"].append(inputs[input_tag_name])",
            "        tag_info[\"labels\"] = list(labels[output_tag])",
            "        tag_info[\"labels_attrs\"] = labels[output_tag]",
            "    return outputs",
            "",
            "",
            "def get_polygon_area(x, y):",
            "    \"\"\"https://en.wikipedia.org/wiki/Shoelace_formula\"\"\"",
            "",
            "    assert len(x) == len(y)",
            "",
            "    return float(0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1))))",
            "",
            "",
            "def get_polygon_bounding_box(x, y):",
            "    assert len(x) == len(y)",
            "",
            "    x1, y1, x2, y2 = min(x), min(y), max(x), max(y)",
            "    return [x1, y1, x2 - x1, y2 - y1]",
            "",
            "",
            "def get_annotator(item, default=None, int_id=False):",
            "    \"\"\"Get annotator id or email from annotation\"\"\"",
            "    annotator = item[\"completed_by\"]",
            "    if isinstance(annotator, dict):",
            "        annotator = annotator.get(\"email\", default)",
            "        return annotator",
            "",
            "    if isinstance(annotator, int) and int_id:",
            "        return annotator",
            "",
            "    return str(annotator)",
            "",
            "",
            "def get_json_root_type(filename):",
            "    char = \"x\"",
            "    with open(filename, \"r\", encoding=\"utf-8\") as f:",
            "        # Read the file character by character",
            "        while char != \"\":",
            "            char = f.read(1)",
            "",
            "            # Skip any whitespace",
            "            if char.isspace():",
            "                continue",
            "",
            "            # If the first non-whitespace character is '{', it's a dict",
            "            if char == \"{\":",
            "                return \"dict\"",
            "",
            "            # If the first non-whitespace character is '[', it's an array",
            "            if char == \"[\":",
            "                return \"list\"",
            "",
            "            # If neither, the JSON file is invalid",
            "            return \"invalid\"",
            "",
            "    # If the file is empty, return \"empty\"",
            "    return \"empty\"",
            "",
            "",
            "def prettify_result(v):",
            "    \"\"\"",
            "    :param v: list of regions or results",
            "    :return: label name as is if there is only 1 item in result `v`, else list of label names",
            "    \"\"\"",
            "    out = []",
            "    tag_type = None",
            "    for i in v:",
            "        j = deepcopy(i)",
            "        tag_type = j.pop(\"type\")",
            "        if tag_type == \"Choices\" and len(j[\"choices\"]) == 1:",
            "            out.append(j[\"choices\"][0])",
            "        elif tag_type == \"TextArea\" and len(j[\"text\"]) == 1:",
            "            out.append(j[\"text\"][0])",
            "        else:",
            "            out.append(j)",
            "    return out[0] if tag_type in (\"Choices\", \"TextArea\") and len(out) == 1 else out",
            "",
            "",
            "def convert_annotation_to_yolo(label):",
            "    \"\"\"",
            "    Convert LS annotation to Yolo format.",
            "",
            "    Args:",
            "        label (dict): Dictionary containing annotation information including:",
            "            - width (float): Width of the object.",
            "            - height (float): Height of the object.",
            "            - x (float): X-coordinate of the top-left corner of the object.",
            "            - y (float): Y-coordinate of the top-left corner of the object.",
            "",
            "    Returns:",
            "        tuple or None: If the conversion is successful, returns a tuple (x, y, w, h) representing",
            "        the coordinates and dimensions of the object in Yolo format, where (x, y) are the center",
            "        coordinates of the object, and (w, h) are the width and height of the object respectively.",
            "    \"\"\"",
            "",
            "    if not (\"x\" in label and \"y\" in label and \"width\" in label and \"height\" in label):",
            "        return None",
            "",
            "    w = label[\"width\"]",
            "    h = label[\"height\"]",
            "",
            "    x = (label[\"x\"] + w / 2) / 100",
            "    y = (label[\"y\"] + h / 2) / 100",
            "    w = w / 100",
            "    h = h / 100",
            "",
            "    return x, y, w, h",
            "",
            "",
            "def convert_annotation_to_yolo_obb(label, normalize=True):",
            "    \"\"\"",
            "    Convert LS annotation to Yolo OBB format.",
            "",
            "    Args:",
            "        label (dict): Dictionary containing annotation information including:",
            "            - original_width (int): Original width of the image.",
            "            - original_height (int): Original height of the image.",
            "            - x (float): X-coordinate of the top-left corner of the object in percentage of the original width.",
            "            - y (float): Y-coordinate of the top-left corner of the object in percentage of the original height.",
            "            - width (float): Width of the object in percentage of the original width.",
            "            - height (float): Height of the object in percentage of the original height.",
            "            - rotation (float, optional): Rotation angle of the object in degrees (default is 0).",
            "        normalize (bool, optional): Whether to normalize the coordinates to the range [0, 1] (default is True).",
            "",
            "    Returns:",
            "        list of tuple or None: List of tuples containing the coordinates of the object in Yolo OBB format.",
            "            Each tuple represents a corner of the bounding box in the order:",
            "            (top-left, top-right, bottom-right, bottom-left).",
            "    \"\"\"",
            "",
            "    if not (",
            "        \"original_width\" in label",
            "        and \"original_height\" in label",
            "        and \"x\" in label",
            "        and \"y\" in label",
            "        and \"width\" in label",
            "        and \"height\" in label",
            "        and \"rotation\" in label",
            "    ):",
            "        return None",
            "",
            "    org_width, org_height = label[\"original_width\"], label[\"original_height\"]",
            "    x = label[\"x\"] / 100 * org_width",
            "    y = label[\"y\"] / 100 * org_height",
            "    w = label[\"width\"] / 100 * org_width",
            "    h = label[\"height\"] / 100 * org_height",
            "",
            "    rotation = math.radians(label.get(\"rotation\", 0))",
            "    cos, sin = math.cos(rotation), math.sin(rotation)",
            "",
            "    coords = [",
            "        (x, y),",
            "        (x + w * cos, y + w * sin),",
            "        (x + w * cos - h * sin, y + w * sin + h * cos),",
            "        (x - h * sin, y + h * cos),",
            "    ]",
            "",
            "    # Normalize coordinates",
            "    if normalize:",
            "        return [(coord[0] / org_width, coord[1] / org_height) for coord in coords]",
            "    else:",
            "        return coords",
            "",
            "",
            "def convert_yolo_obb_to_annotation(xyxyxyxy, original_width, original_height):",
            "    \"\"\"",
            "    Convert YOLO Oriented Bounding Box (OBB) format to Label Studio format.",
            "",
            "    Args:",
            "        xyxyxyxy (list): List of 8 float values representing the absolute pixel coordinates",
            "                         of the OBB in the format [x1, y1, x2, y2, x3, y3, x4, y4].",
            "        original_width (int): Original width of the image.",
            "        original_height (int): Original height of the image.",
            "",
            "    Returns:",
            "        dict: Dictionary containing the converted bounding box with the following keys:",
            "              - x: X-coordinate of the top-left corner of the bounding box in percentage.",
            "              - y: Y-coordinate of the top-left corner of the bounding box in percentage.",
            "              - width: Width of the bounding box in percentage.",
            "              - height: Height of the bounding box in percentage.",
            "              - rotation: Rotation angle of the bounding box in degrees.",
            "    \"\"\"",
            "    # Reshape the coordinates into a 4x2 matrix",
            "    coords = np.array(xyxyxyxy, dtype=np.float64).reshape((4, 2))",
            "",
            "    # Calculate the center of the bounding box",
            "    center_x = np.mean(coords[:, 0])",
            "    center_y = np.mean(coords[:, 1])",
            "",
            "    # Calculate the width and height of the bounding box",
            "    width = np.linalg.norm(coords[0] - coords[1])",
            "    height = np.linalg.norm(coords[0] - coords[3])",
            "",
            "    # Calculate the rotation angle",
            "    dx = coords[1, 0] - coords[0, 0]",
            "    dy = coords[1, 1] - coords[0, 1]",
            "    r = np.degrees(np.arctan2(dy, dx))",
            "",
            "    # Find the top-left corner (x, y)",
            "    top_left_x = (",
            "        center_x",
            "        - (width / 2) * np.cos(np.radians(r))",
            "        + (height / 2) * np.sin(np.radians(r))",
            "    )",
            "    top_left_y = (",
            "        center_y",
            "        - (width / 2) * np.sin(np.radians(r))",
            "        - (height / 2) * np.cos(np.radians(r))",
            "    )",
            "",
            "    # Normalize the values",
            "    x = (top_left_x / original_width) * 100",
            "    y = (top_left_y / original_height) * 100",
            "    width = (width / original_width) * 100",
            "    height = (height / original_height) * 100",
            "",
            "    # Create the dictionary for Label Studio",
            "    return {",
            "        \"x\": x,",
            "        \"y\": y,",
            "        \"width\": width,",
            "        \"height\": height,",
            "        \"rotation\": r,",
            "        \"original_width\": original_width,",
            "        \"original_height\": original_height,",
            "    }"
        ],
        "afterPatchFile": [
            "import argparse",
            "import datetime",
            "import hashlib",
            "import io",
            "import logging",
            "import math",
            "import os",
            "import re",
            "import shutil",
            "import urllib",
            "import wave",
            "from collections import defaultdict",
            "from copy import deepcopy",
            "from operator import itemgetter",
            "from urllib.parse import urlparse",
            "",
            "import numpy as np",
            "import requests",
            "from PIL import Image",
            "from lxml import etree",
            "from nltk.tokenize.treebank import TreebankWordTokenizer",
            "",
            "from label_studio_sdk._extensions.label_studio_tools.core.utils.params import get_env",
            "from label_studio_sdk._extensions.label_studio_tools.core.utils.io import safe_build_path",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "_LABEL_TAGS = {\"Label\", \"Choice\"}",
            "_NOT_CONTROL_TAGS = {",
            "    \"Filter\",",
            "}",
            "LOCAL_FILES_DOCUMENT_ROOT = get_env(",
            "    \"LOCAL_FILES_DOCUMENT_ROOT\", default=os.path.abspath(os.sep)",
            ")",
            "",
            "TreebankWordTokenizer.PUNCTUATION = [",
            "    (re.compile(r\"([:,])([^\\d])\"), r\" \\1 \\2\"),",
            "    (re.compile(r\"([:,])$\"), r\" \\1 \"),",
            "    (re.compile(r\"\\.\\.\\.\"), r\" ... \"),",
            "    (re.compile(r\"[;@#$/%&]\"), r\" \\g<0> \"),",
            "    (",
            "        re.compile(r'([^\\.])(\\.)([\\]\\)}>\"\\']*)\\s*$'),",
            "        r\"\\1 \\2\\3 \",",
            "    ),  # Handles the final period.",
            "    (re.compile(r\"[?!]\"), r\" \\g<0> \"),",
            "    (re.compile(r\"([^'])' \"), r\"\\1 ' \"),",
            "]",
            "",
            "",
            "class ExpandFullPath(argparse.Action):",
            "    def __call__(self, parser, namespace, values, option_string=None):",
            "        setattr(namespace, self.dest, os.path.abspath(os.path.expanduser(values)))",
            "",
            "",
            "def tokenize(text):",
            "    tok_start = 0",
            "    out = []",
            "    for tok in text.split():",
            "        if len(tok):",
            "            out.append((tok, tok_start))",
            "            tok_start += len(tok) + 1",
            "        else:",
            "            tok_start += 1",
            "    return out",
            "",
            "",
            "def create_tokens_and_tags(text, spans):",
            "    # tokens_and_idx = tokenize(text) # This function doesn't work properly if text contains multiple whitespaces...",
            "    token_index_tuples = [",
            "        token for token in TreebankWordTokenizer().span_tokenize(text)",
            "    ]",
            "    tokens_and_idx = [(text[start:end], start) for start, end in token_index_tuples]",
            "    if spans and all(",
            "        [",
            "            span.get(\"start\") is not None and span.get(\"end\") is not None",
            "            for span in spans",
            "        ]",
            "    ):",
            "        spans = list(sorted(spans, key=itemgetter(\"start\")))",
            "        span = spans.pop(0)",
            "        span_start = span[\"start\"]",
            "        span_end = span[\"end\"] - 1",
            "        prefix = \"B-\"",
            "        tokens, tags = [], []",
            "        for token, token_start in tokens_and_idx:",
            "            tokens.append(token)",
            "            token_end = (",
            "                token_start + len(token) - 1",
            "            )  # \"- 1\" - This substraction is wrong. token already uses the index E.g. \"Hello\" is 0-4",
            "            token_start_ind = token_start  # It seems like the token start is too early.. for whichever reason",
            "",
            "            # if for some reason end of span is missed.. pop the new span (Which is quite probable due to this method)",
            "            # Attention it seems like span['end'] is the index of first char afterwards. In case the whitespace is part of the",
            "            # labell we need to subtract one. Otherwise next token won't trigger the span update.. only the token after next..",
            "            if token_start_ind > span_end:",
            "                while spans:",
            "                    span = spans.pop(0)",
            "                    span_start = span[\"start\"]",
            "                    span_end = span[\"end\"] - 1",
            "                    prefix = \"B-\"",
            "                    if token_start <= span_end:",
            "                        break",
            "            # Add tag \"O\" for spans that:",
            "            # - are empty",
            "            # - span start has passed over token_end",
            "            # - do not have any label (None or empty list)",
            "            if not span or token_end < span_start or not span.get(\"labels\"):",
            "                tags.append(\"O\")",
            "            elif span_start <= token_end and span_end >= token_start_ind:",
            "                tags.append(prefix + span[\"labels\"][0])",
            "                prefix = \"I-\"",
            "            else:",
            "                tags.append(\"O\")",
            "    else:",
            "        tokens = [token for token, _ in tokens_and_idx]",
            "        tags = [\"O\"] * len(tokens)",
            "",
            "    return tokens, tags",
            "",
            "",
            "def _get_upload_dir(project_dir=None, upload_dir=None):",
            "    \"\"\"Return either upload_dir, or path by LS_UPLOAD_DIR, or project_dir/upload\"\"\"",
            "    if upload_dir:",
            "        return upload_dir",
            "    upload_dir = os.environ.get(\"LS_UPLOAD_DIR\")",
            "    if not upload_dir and project_dir:",
            "        upload_dir = os.path.join(project_dir, \"upload\")",
            "        if not os.path.exists(upload_dir):",
            "            upload_dir = None",
            "    if not upload_dir:",
            "        raise FileNotFoundError(",
            "            \"Can't find upload dir: either LS_UPLOAD_DIR or project should be passed to converter\"",
            "        )",
            "    return upload_dir",
            "",
            "",
            "def download(",
            "    url,",
            "    output_dir,",
            "    filename=None,",
            "    project_dir=None,",
            "    return_relative_path=False,",
            "    upload_dir=None,",
            "    download_resources=True,",
            "):",
            "    is_local_file = url.startswith(\"/data/\") and \"?d=\" in url",
            "    is_uploaded_file = url.startswith(\"/data/upload\")",
            "",
            "    if is_uploaded_file:",
            "        upload_dir = _get_upload_dir(project_dir, upload_dir)",
            "        filename = urllib.parse.unquote(url.replace(\"/data/upload/\", \"\"))",
            "        filepath = safe_build_path(upload_dir, filename)",
            "        logger.debug(",
            "            f\"Copy {filepath} to {output_dir}\".format(",
            "                filepath=filepath, output_dir=output_dir",
            "            )",
            "        )",
            "        if download_resources:",
            "            shutil.copy(filepath, output_dir)",
            "        if return_relative_path:",
            "            return os.path.join(",
            "                os.path.basename(output_dir), os.path.basename(filename)",
            "            )",
            "        return filepath",
            "",
            "    if is_local_file:",
            "        filename, dir_path = url.split(\"/data/\", 1)[-1].split(\"?d=\")",
            "        dir_path = str(urllib.parse.unquote(dir_path))",
            "        filepath = safe_build_path(LOCAL_FILES_DOCUMENT_ROOT, dir_path)",
            "        if not os.path.exists(filepath):",
            "            raise FileNotFoundError(filepath)",
            "        if download_resources:",
            "            shutil.copy(filepath, output_dir)",
            "        return filepath",
            "",
            "    if filename is None:",
            "        basename, ext = os.path.splitext(os.path.basename(urlparse(url).path))",
            "        filename = f\"{basename}{ext}\"",
            "        filepath = os.path.join(output_dir, filename)",
            "        if os.path.exists(filepath):",
            "            filename = (",
            "                basename",
            "                + \"_\"",
            "                + hashlib.md5(",
            "                    url.encode() + str(datetime.datetime.now().timestamp()).encode()",
            "                ).hexdigest()[:4]",
            "                + ext",
            "            )",
            "",
            "    filepath = os.path.join(output_dir, filename)",
            "    if not os.path.exists(filepath):",
            "        logger.info(\"Download {url} to {filepath}\".format(url=url, filepath=filepath))",
            "        if download_resources:",
            "            r = requests.get(url)",
            "            r.raise_for_status()",
            "            with io.open(filepath, mode=\"wb\") as fout:",
            "                fout.write(r.content)",
            "    if return_relative_path:",
            "        return os.path.join(os.path.basename(output_dir), os.path.basename(filename))",
            "    return filepath",
            "",
            "",
            "def get_image_size(image_path):",
            "    return Image.open(image_path).size",
            "",
            "",
            "def get_image_size_and_channels(image_path):",
            "    i = Image.open(image_path)",
            "    w, h = i.size",
            "    c = len(i.getbands())",
            "    return w, h, c",
            "",
            "",
            "def get_audio_duration(audio_path):",
            "    with wave.open(audio_path, mode=\"r\") as f:",
            "        return f.getnframes() / float(f.getframerate())",
            "",
            "",
            "def ensure_dir(dir_path):",
            "    if not os.path.exists(dir_path):",
            "        os.makedirs(dir_path)",
            "",
            "",
            "def parse_config(config_string):",
            "    \"\"\"",
            "    :param config_string: Label config string",
            "    :return: structured config of the form:",
            "    {",
            "        \"<ControlTag>.name\": {",
            "            \"type\": \"ControlTag\",",
            "            \"to_name\": [\"<ObjectTag1>.name\", \"<ObjectTag2>.name\"],",
            "            \"inputs: [",
            "                {\"type\": \"ObjectTag1\", \"value\": \"<ObjectTag1>.value\"},",
            "                {\"type\": \"ObjectTag2\", \"value\": \"<ObjectTag2>.value\"}",
            "            ],",
            "            \"labels\": [\"Label1\", \"Label2\", \"Label3\"] // taken from \"alias\" if exists or \"value\"",
            "    }",
            "    \"\"\"",
            "    if not config_string:",
            "        return {}",
            "",
            "    def _is_input_tag(tag):",
            "        return tag.attrib.get(\"name\") and tag.attrib.get(\"value\")",
            "",
            "    def _is_output_tag(tag):",
            "        return (",
            "            tag.attrib.get(\"name\")",
            "            and tag.attrib.get(\"toName\")",
            "            and tag.tag not in _NOT_CONTROL_TAGS",
            "        )",
            "",
            "    def _get_parent_output_tag_name(tag, outputs):",
            "        # Find parental <Choices> tag for nested tags like <Choices><View><View><Choice>...",
            "        parent = tag",
            "        while True:",
            "            parent = parent.getparent()",
            "            if parent is None:",
            "                return",
            "            name = parent.attrib.get(\"name\")",
            "            if name in outputs:",
            "                return name",
            "",
            "    try:",
            "        xml_tree = etree.fromstring(config_string)",
            "    except etree.XMLSyntaxError as e:",
            "        raise ValueError(str(e))",
            "",
            "    inputs, outputs, labels = {}, {}, defaultdict(dict)",
            "    for tag in xml_tree.iter():",
            "        if _is_output_tag(tag):",
            "            tag_info = {\"type\": tag.tag, \"to_name\": tag.attrib[\"toName\"].split(\",\")}",
            "            # Grab conditionals if any",
            "            conditionals = {}",
            "            if tag.attrib.get(\"perRegion\") == \"true\":",
            "                if tag.attrib.get(\"whenTagName\"):",
            "                    conditionals = {\"type\": \"tag\", \"name\": tag.attrib[\"whenTagName\"]}",
            "                elif tag.attrib.get(\"whenLabelValue\"):",
            "                    conditionals = {",
            "                        \"type\": \"label\",",
            "                        \"name\": tag.attrib[\"whenLabelValue\"],",
            "                    }",
            "                elif tag.attrib.get(\"whenChoiceValue\"):",
            "                    conditionals = {",
            "                        \"type\": \"choice\",",
            "                        \"name\": tag.attrib[\"whenChoiceValue\"],",
            "                    }",
            "            if conditionals:",
            "                tag_info[\"conditionals\"] = conditionals",
            "            outputs[tag.attrib[\"name\"]] = tag_info",
            "        elif _is_input_tag(tag):",
            "            inputs[tag.attrib[\"name\"]] = {",
            "                \"type\": tag.tag,",
            "                \"value\": tag.attrib[\"value\"].lstrip(\"$\"),",
            "            }",
            "        if tag.tag not in _LABEL_TAGS:",
            "            continue",
            "        parent_name = _get_parent_output_tag_name(tag, outputs)",
            "        if parent_name is not None:",
            "            actual_value = tag.attrib.get(\"alias\") or tag.attrib.get(\"value\")",
            "            if not actual_value:",
            "                logger.debug(",
            "                    'Inspecting tag {tag_name}... found no \"value\" or \"alias\" attributes.'.format(",
            "                        tag_name=etree.tostring(tag, encoding=\"unicode\").strip()[:50]",
            "                    )",
            "                )",
            "            else:",
            "                labels[parent_name][actual_value] = dict(tag.attrib)",
            "    for output_tag, tag_info in outputs.items():",
            "        tag_info[\"inputs\"] = []",
            "        for input_tag_name in tag_info[\"to_name\"]:",
            "            if input_tag_name not in inputs:",
            "                logger.debug(",
            "                    f\"to_name={input_tag_name} is specified for output tag name={output_tag}, \"",
            "                    \"but we can't find it among input tags\"",
            "                )",
            "                continue",
            "            tag_info[\"inputs\"].append(inputs[input_tag_name])",
            "        tag_info[\"labels\"] = list(labels[output_tag])",
            "        tag_info[\"labels_attrs\"] = labels[output_tag]",
            "    return outputs",
            "",
            "",
            "def get_polygon_area(x, y):",
            "    \"\"\"https://en.wikipedia.org/wiki/Shoelace_formula\"\"\"",
            "",
            "    assert len(x) == len(y)",
            "",
            "    return float(0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1))))",
            "",
            "",
            "def get_polygon_bounding_box(x, y):",
            "    assert len(x) == len(y)",
            "",
            "    x1, y1, x2, y2 = min(x), min(y), max(x), max(y)",
            "    return [x1, y1, x2 - x1, y2 - y1]",
            "",
            "",
            "def get_annotator(item, default=None, int_id=False):",
            "    \"\"\"Get annotator id or email from annotation\"\"\"",
            "    annotator = item[\"completed_by\"]",
            "    if isinstance(annotator, dict):",
            "        annotator = annotator.get(\"email\", default)",
            "        return annotator",
            "",
            "    if isinstance(annotator, int) and int_id:",
            "        return annotator",
            "",
            "    return str(annotator)",
            "",
            "",
            "def get_json_root_type(filename):",
            "    char = \"x\"",
            "    with open(filename, \"r\", encoding=\"utf-8\") as f:",
            "        # Read the file character by character",
            "        while char != \"\":",
            "            char = f.read(1)",
            "",
            "            # Skip any whitespace",
            "            if char.isspace():",
            "                continue",
            "",
            "            # If the first non-whitespace character is '{', it's a dict",
            "            if char == \"{\":",
            "                return \"dict\"",
            "",
            "            # If the first non-whitespace character is '[', it's an array",
            "            if char == \"[\":",
            "                return \"list\"",
            "",
            "            # If neither, the JSON file is invalid",
            "            return \"invalid\"",
            "",
            "    # If the file is empty, return \"empty\"",
            "    return \"empty\"",
            "",
            "",
            "def prettify_result(v):",
            "    \"\"\"",
            "    :param v: list of regions or results",
            "    :return: label name as is if there is only 1 item in result `v`, else list of label names",
            "    \"\"\"",
            "    out = []",
            "    tag_type = None",
            "    for i in v:",
            "        j = deepcopy(i)",
            "        tag_type = j.pop(\"type\")",
            "        if tag_type == \"Choices\" and len(j[\"choices\"]) == 1:",
            "            out.append(j[\"choices\"][0])",
            "        elif tag_type == \"TextArea\" and len(j[\"text\"]) == 1:",
            "            out.append(j[\"text\"][0])",
            "        else:",
            "            out.append(j)",
            "    return out[0] if tag_type in (\"Choices\", \"TextArea\") and len(out) == 1 else out",
            "",
            "",
            "def convert_annotation_to_yolo(label):",
            "    \"\"\"",
            "    Convert LS annotation to Yolo format.",
            "",
            "    Args:",
            "        label (dict): Dictionary containing annotation information including:",
            "            - width (float): Width of the object.",
            "            - height (float): Height of the object.",
            "            - x (float): X-coordinate of the top-left corner of the object.",
            "            - y (float): Y-coordinate of the top-left corner of the object.",
            "",
            "    Returns:",
            "        tuple or None: If the conversion is successful, returns a tuple (x, y, w, h) representing",
            "        the coordinates and dimensions of the object in Yolo format, where (x, y) are the center",
            "        coordinates of the object, and (w, h) are the width and height of the object respectively.",
            "    \"\"\"",
            "",
            "    if not (\"x\" in label and \"y\" in label and \"width\" in label and \"height\" in label):",
            "        return None",
            "",
            "    w = label[\"width\"]",
            "    h = label[\"height\"]",
            "",
            "    x = (label[\"x\"] + w / 2) / 100",
            "    y = (label[\"y\"] + h / 2) / 100",
            "    w = w / 100",
            "    h = h / 100",
            "",
            "    return x, y, w, h",
            "",
            "",
            "def convert_annotation_to_yolo_obb(label, normalize=True):",
            "    \"\"\"",
            "    Convert LS annotation to Yolo OBB format.",
            "",
            "    Args:",
            "        label (dict): Dictionary containing annotation information including:",
            "            - original_width (int): Original width of the image.",
            "            - original_height (int): Original height of the image.",
            "            - x (float): X-coordinate of the top-left corner of the object in percentage of the original width.",
            "            - y (float): Y-coordinate of the top-left corner of the object in percentage of the original height.",
            "            - width (float): Width of the object in percentage of the original width.",
            "            - height (float): Height of the object in percentage of the original height.",
            "            - rotation (float, optional): Rotation angle of the object in degrees (default is 0).",
            "        normalize (bool, optional): Whether to normalize the coordinates to the range [0, 1] (default is True).",
            "",
            "    Returns:",
            "        list of tuple or None: List of tuples containing the coordinates of the object in Yolo OBB format.",
            "            Each tuple represents a corner of the bounding box in the order:",
            "            (top-left, top-right, bottom-right, bottom-left).",
            "    \"\"\"",
            "",
            "    if not (",
            "        \"original_width\" in label",
            "        and \"original_height\" in label",
            "        and \"x\" in label",
            "        and \"y\" in label",
            "        and \"width\" in label",
            "        and \"height\" in label",
            "        and \"rotation\" in label",
            "    ):",
            "        return None",
            "",
            "    org_width, org_height = label[\"original_width\"], label[\"original_height\"]",
            "    x = label[\"x\"] / 100 * org_width",
            "    y = label[\"y\"] / 100 * org_height",
            "    w = label[\"width\"] / 100 * org_width",
            "    h = label[\"height\"] / 100 * org_height",
            "",
            "    rotation = math.radians(label.get(\"rotation\", 0))",
            "    cos, sin = math.cos(rotation), math.sin(rotation)",
            "",
            "    coords = [",
            "        (x, y),",
            "        (x + w * cos, y + w * sin),",
            "        (x + w * cos - h * sin, y + w * sin + h * cos),",
            "        (x - h * sin, y + h * cos),",
            "    ]",
            "",
            "    # Normalize coordinates",
            "    if normalize:",
            "        return [(coord[0] / org_width, coord[1] / org_height) for coord in coords]",
            "    else:",
            "        return coords",
            "",
            "",
            "def convert_yolo_obb_to_annotation(xyxyxyxy, original_width, original_height):",
            "    \"\"\"",
            "    Convert YOLO Oriented Bounding Box (OBB) format to Label Studio format.",
            "",
            "    Args:",
            "        xyxyxyxy (list): List of 8 float values representing the absolute pixel coordinates",
            "                         of the OBB in the format [x1, y1, x2, y2, x3, y3, x4, y4].",
            "        original_width (int): Original width of the image.",
            "        original_height (int): Original height of the image.",
            "",
            "    Returns:",
            "        dict: Dictionary containing the converted bounding box with the following keys:",
            "              - x: X-coordinate of the top-left corner of the bounding box in percentage.",
            "              - y: Y-coordinate of the top-left corner of the bounding box in percentage.",
            "              - width: Width of the bounding box in percentage.",
            "              - height: Height of the bounding box in percentage.",
            "              - rotation: Rotation angle of the bounding box in degrees.",
            "    \"\"\"",
            "    # Reshape the coordinates into a 4x2 matrix",
            "    coords = np.array(xyxyxyxy, dtype=np.float64).reshape((4, 2))",
            "",
            "    # Calculate the center of the bounding box",
            "    center_x = np.mean(coords[:, 0])",
            "    center_y = np.mean(coords[:, 1])",
            "",
            "    # Calculate the width and height of the bounding box",
            "    width = np.linalg.norm(coords[0] - coords[1])",
            "    height = np.linalg.norm(coords[0] - coords[3])",
            "",
            "    # Calculate the rotation angle",
            "    dx = coords[1, 0] - coords[0, 0]",
            "    dy = coords[1, 1] - coords[0, 1]",
            "    r = np.degrees(np.arctan2(dy, dx))",
            "",
            "    # Find the top-left corner (x, y)",
            "    top_left_x = (",
            "        center_x",
            "        - (width / 2) * np.cos(np.radians(r))",
            "        + (height / 2) * np.sin(np.radians(r))",
            "    )",
            "    top_left_y = (",
            "        center_y",
            "        - (width / 2) * np.sin(np.radians(r))",
            "        - (height / 2) * np.cos(np.radians(r))",
            "    )",
            "",
            "    # Normalize the values",
            "    x = (top_left_x / original_width) * 100",
            "    y = (top_left_y / original_height) * 100",
            "    width = (width / original_width) * 100",
            "    height = (height / original_height) * 100",
            "",
            "    # Create the dictionary for Label Studio",
            "    return {",
            "        \"x\": x,",
            "        \"y\": y,",
            "        \"width\": width,",
            "        \"height\": height,",
            "        \"rotation\": r,",
            "        \"original_width\": original_width,",
            "        \"original_height\": original_height,",
            "    }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "151": [
                "download"
            ],
            "168": [
                "download"
            ]
        },
        "addLocation": []
    }
}