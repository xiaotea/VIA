{
    "keras/layers/core/lambda_layer.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " import tensorflow.compat.v2 as tf"
            },
            "1": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from keras.engine.base_layer import Layer"
            },
            "3": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from keras.saving.legacy import serialization"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+from keras.saving import serialization_lib"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+from keras.saving.legacy import serialization as legacy_serialization"
            },
            "6": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from keras.utils import generic_utils"
            },
            "7": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " from keras.utils import tf_inspect"
            },
            "8": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " from keras.utils import tf_utils"
            },
            "9": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 382,
                "PatchRowcode": "         function_type = config.pop(func_type_attr_name)"
            },
            "10": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": 383,
                "PatchRowcode": "         if function_type == \"function\":"
            },
            "11": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "             # Simple lookup in custom objects"
            },
            "12": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            function = serialization.deserialize_keras_object("
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 385,
                "PatchRowcode": "+            function = legacy_serialization.deserialize_keras_object("
            },
            "14": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "                 config[func_attr_name],"
            },
            "15": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 387,
                "PatchRowcode": "                 custom_objects=custom_objects,"
            },
            "16": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": 388,
                "PatchRowcode": "                 printable_module_name=\"function in Lambda layer\","
            },
            "17": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 389,
                "PatchRowcode": "             )"
            },
            "18": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 390,
                "PatchRowcode": "         elif function_type == \"lambda\":"
            },
            "19": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # Unsafe deserialization from bytecode"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 391,
                "PatchRowcode": "+            if serialization_lib.in_safe_mode():"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 392,
                "PatchRowcode": "+                raise ValueError("
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 393,
                "PatchRowcode": "+                    \"Requested the deserialization of a Lambda layer with a \""
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 394,
                "PatchRowcode": "+                    \"Python `lambda` inside it. \""
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 395,
                "PatchRowcode": "+                    \"This carries a potential risk of arbitrary code execution \""
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+                    \"and thus it is disallowed by default. If you trust the \""
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+                    \"source of the saved model, you can pass `safe_mode=False` \""
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 398,
                "PatchRowcode": "+                    \"to the loading function in order to allow \""
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 399,
                "PatchRowcode": "+                    \"Lambda layer loading.\""
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 400,
                "PatchRowcode": "+                )"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 401,
                "PatchRowcode": "+            # /!\\ Unsafe deserialization from bytecode! Danger! /!\\"
            },
            "31": {
                "beforePatchRowNumber": 391,
                "afterPatchRowNumber": 402,
                "PatchRowcode": "             function = generic_utils.func_load("
            },
            "32": {
                "beforePatchRowNumber": 392,
                "afterPatchRowNumber": 403,
                "PatchRowcode": "                 config[func_attr_name], globs=globs"
            },
            "33": {
                "beforePatchRowNumber": 393,
                "afterPatchRowNumber": 404,
                "PatchRowcode": "             )"
            }
        },
        "frontPatchFile": [
            "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Contains the Lambda layer.\"\"\"",
            "",
            "import sys",
            "import textwrap",
            "import types as python_types",
            "import warnings",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "",
            "from keras.engine.base_layer import Layer",
            "from keras.saving.legacy import serialization",
            "from keras.utils import generic_utils",
            "from keras.utils import tf_inspect",
            "from keras.utils import tf_utils",
            "",
            "# isort: off",
            "from tensorflow.python.platform import tf_logging",
            "from tensorflow.python.util.tf_export import keras_export",
            "",
            "",
            "@keras_export(\"keras.layers.Lambda\")",
            "class Lambda(Layer):",
            "    \"\"\"Wraps arbitrary expressions as a `Layer` object.",
            "",
            "    The `Lambda` layer exists so that arbitrary expressions can be used",
            "    as a `Layer` when constructing `Sequential`",
            "    and Functional API models. `Lambda` layers are best suited for simple",
            "    operations or quick experimentation. For more advanced use cases, follow",
            "    [this guide](",
            "    https://www.tensorflow.org/guide/keras/custom_layers_and_models)",
            "    for subclassing `tf.keras.layers.Layer`.",
            "",
            "    WARNING: `tf.keras.layers.Lambda` layers have (de)serialization limitations!",
            "",
            "    The main reason to subclass `tf.keras.layers.Layer` instead of using a",
            "    `Lambda` layer is saving and inspecting a Model. `Lambda` layers",
            "    are saved by serializing the Python bytecode, which is fundamentally",
            "    non-portable. They should only be loaded in the same environment where",
            "    they were saved. Subclassed layers can be saved in a more portable way",
            "    by overriding their `get_config` method. Models that rely on",
            "    subclassed Layers are also often easier to visualize and reason about.",
            "",
            "    Examples:",
            "",
            "    ```python",
            "    # add a x -> x^2 layer",
            "    model.add(Lambda(lambda x: x ** 2))",
            "    ```",
            "    ```python",
            "    # add a layer that returns the concatenation",
            "    # of the positive part of the input and",
            "    # the opposite of the negative part",
            "",
            "    def antirectifier(x):",
            "        x -= K.mean(x, axis=1, keepdims=True)",
            "        x = K.l2_normalize(x, axis=1)",
            "        pos = K.relu(x)",
            "        neg = K.relu(-x)",
            "        return K.concatenate([pos, neg], axis=1)",
            "",
            "    model.add(Lambda(antirectifier))",
            "    ```",
            "",
            "    Variables:",
            "      While it is possible to use Variables with Lambda layers, this practice is",
            "      discouraged as it can easily lead to bugs. For instance, consider the",
            "      following layer:",
            "",
            "    ```python",
            "      scale = tf.Variable(1.)",
            "      scale_layer = tf.keras.layers.Lambda(lambda x: x * scale)",
            "    ```",
            "",
            "      Because scale_layer does not directly track the `scale` variable, it will",
            "      not appear in `scale_layer.trainable_weights` and will therefore not be",
            "      trained if `scale_layer` is used in a Model.",
            "",
            "      A better pattern is to write a subclassed Layer:",
            "",
            "    ```python",
            "      class ScaleLayer(tf.keras.layers.Layer):",
            "        def __init__(self):",
            "          super(ScaleLayer, self).__init__()",
            "          self.scale = tf.Variable(1.)",
            "",
            "        def call(self, inputs):",
            "          return inputs * self.scale",
            "    ```",
            "",
            "      In general, Lambda layers can be convenient for simple stateless",
            "      computation, but anything more complex should use a subclass Layer",
            "      instead.",
            "",
            "    Args:",
            "      function: The function to be evaluated. Takes input tensor as first",
            "        argument.",
            "      output_shape: Expected output shape from function. This argument can be",
            "        inferred if not explicitly provided. Can be a tuple or function. If a",
            "        tuple, it only specifies the first dimension onward;",
            "        sample dimension is assumed either the same as the input:",
            "        `output_shape = (input_shape[0], ) + output_shape` or, the input is",
            "        `None` and the sample dimension is also `None`:",
            "        `output_shape = (None, ) + output_shape` If a function, it specifies the",
            "        entire shape as a function of the input shape:",
            "        `output_shape = f(input_shape)`",
            "      mask: Either None (indicating no masking) or a callable with the same",
            "        signature as the `compute_mask` layer method, or a tensor that will be",
            "        returned as output mask regardless of what the input is.",
            "      arguments: Optional dictionary of keyword arguments to be passed to the",
            "        function.",
            "    Input shape: Arbitrary. Use the keyword argument input_shape (tuple of",
            "      integers, does not include the samples axis) when using this layer as the",
            "      first layer in a model.",
            "    Output shape: Specified by `output_shape` argument",
            "    \"\"\"",
            "",
            "    @tf.__internal__.tracking.no_automatic_dependency_tracking",
            "    def __init__(",
            "        self, function, output_shape=None, mask=None, arguments=None, **kwargs",
            "    ):",
            "        super().__init__(**kwargs)",
            "",
            "        self.arguments = arguments or {}",
            "        self.function = function",
            "",
            "        if mask is not None:",
            "            self.supports_masking = True",
            "        self.mask = mask",
            "        self._output_shape = output_shape",
            "",
            "        # Warning on every invocation will be quite irksome in Eager mode.",
            "        self._already_warned = False",
            "",
            "        function_args = tf_inspect.getfullargspec(function).args",
            "        self._fn_expects_training_arg = \"training\" in function_args",
            "        self._fn_expects_mask_arg = \"mask\" in function_args",
            "",
            "    @tf_utils.shape_type_conversion",
            "    def compute_output_shape(self, input_shape):",
            "        if self._output_shape is None:",
            "            # Make use of existing autocomputation but provide Lambda-specific",
            "            # error message. This is always safe to run even when the outer",
            "            # context is Graph mode because Lambda layers don't have side",
            "            # effects such as `add_loss`.",
            "            with tf.__internal__.eager_context.eager_mode():",
            "                try:",
            "                    return super().compute_output_shape(input_shape)",
            "                except NotImplementedError:",
            "                    raise NotImplementedError(",
            "                        \"We could not automatically infer the shape of \"",
            "                        \"the Lambda's output. Please specify `output_shape` \"",
            "                        \"for this Lambda.\"",
            "                    )",
            "",
            "        if callable(self._output_shape):",
            "            output_shapes = self._output_shape(input_shape)",
            "            return tf_utils.convert_shapes(output_shapes, to_tuples=False)",
            "",
            "        # Output shapes are passed directly and don't include batch dimension.",
            "        input_tensor_shape = tf_utils.convert_shapes(",
            "            input_shape, to_tuples=False",
            "        )",
            "        batch_size = (",
            "            tf.nest.flatten(input_tensor_shape)[0][0] if input_shape else None",
            "        )",
            "",
            "        def _add_batch(shape):",
            "            return tf.TensorShape([batch_size] + shape.as_list())",
            "",
            "        output_shapes = tf_utils.convert_shapes(",
            "            self._output_shape, to_tuples=False",
            "        )",
            "        return tf.nest.map_structure(_add_batch, output_shapes)",
            "",
            "    def call(self, inputs, mask=None, training=None):",
            "        # We must copy for thread safety, but it only needs to be a shallow",
            "        # copy.",
            "        kwargs = {k: v for k, v in self.arguments.items()}",
            "        if self._fn_expects_mask_arg:",
            "            kwargs[\"mask\"] = mask",
            "        if self._fn_expects_training_arg:",
            "            kwargs[\"training\"] = training",
            "",
            "        created_variables = []",
            "",
            "        def _variable_creator(next_creator, **kwargs):",
            "            var = next_creator(**kwargs)",
            "            created_variables.append(var)",
            "            return var",
            "",
            "        with tf.GradientTape(",
            "            watch_accessed_variables=True",
            "        ) as tape, tf.variable_creator_scope(_variable_creator):",
            "            result = self.function(inputs, **kwargs)",
            "        self._check_variables(created_variables, tape.watched_variables())",
            "        return result",
            "",
            "    def _check_variables(self, created_variables, accessed_variables):",
            "        if not created_variables and not accessed_variables:",
            "            # In the common case that a Lambda layer does not touch a Variable,",
            "            # we don't want to incur the runtime cost of assembling any state",
            "            # used for checking only to immediately discard it.",
            "            return",
            "",
            "        # Filter out the state variable in the tf.random.Generator, which is",
            "        # commonly used for initializer or droput. The variable is intentionally",
            "        # not tracked and it is not a trainable variable.",
            "        created_variables = [",
            "            v for v in created_variables if \"StateVar\" not in v.name",
            "        ]",
            "",
            "        tracked_weights = set(v.ref() for v in self.weights)",
            "        untracked_new_vars = [",
            "            v for v in created_variables if v.ref() not in tracked_weights",
            "        ]",
            "        if untracked_new_vars:",
            "            variable_str = \"\\n\".join(f\"  {i}\" for i in untracked_new_vars)",
            "            error_str = textwrap.dedent(",
            "                \"\"\"",
            "          The following Variables were created within a Lambda layer ({name})",
            "          but are not tracked by said layer:",
            "          {variable_str}",
            "          The layer cannot safely ensure proper Variable reuse across multiple",
            "          calls, and consequently this behavior is disallowed for safety. Lambda",
            "          layers are not well suited to stateful computation; instead, writing a",
            "          subclassed Layer is the recommend way to define layers with",
            "          Variables.\"\"\"",
            "            ).format(name=self.name, variable_str=variable_str)",
            "            raise ValueError(error_str)",
            "",
            "        untracked_used_vars = [",
            "            v for v in accessed_variables if v.ref() not in tracked_weights",
            "        ]",
            "        if untracked_used_vars and not self._already_warned:",
            "            variable_str = \"\\n\".join(f\"  {i}\" for i in untracked_used_vars)",
            "            self._warn(",
            "                textwrap.dedent(",
            "                    \"\"\"",
            "          The following Variables were used a Lambda layer's call ({name}), but",
            "          are not present in its tracked objects:",
            "          {variable_str}",
            "          It is possible that this is intended behavior, but it is more likely",
            "          an omission. This is a strong indication that this layer should be",
            "          formulated as a subclassed Layer rather than a Lambda layer.\"\"\"",
            "                ).format(name=self.name, variable_str=variable_str)",
            "            )",
            "            self._already_warned = True",
            "",
            "    def _warn(self, msg):",
            "        # This method will be overridden in a unit test to raise an error,",
            "        # because self.assertWarns is not universally implemented.",
            "        return tf_logging.warning(msg)",
            "",
            "    def compute_mask(self, inputs, mask=None):",
            "        if callable(self.mask):",
            "            return self.mask(inputs, mask)",
            "        return self.mask",
            "",
            "    def get_config(self):",
            "        function_config = self._serialize_function_to_config(self.function)",
            "        output_shape_config = self._serialize_function_to_config(",
            "            self._output_shape, allow_raw=True",
            "        )",
            "        config = {",
            "            \"function\": function_config[0],",
            "            \"function_type\": function_config[1],",
            "            \"module\": function_config[2],",
            "            \"output_shape\": output_shape_config[0],",
            "            \"output_shape_type\": output_shape_config[1],",
            "            \"output_shape_module\": output_shape_config[2],",
            "        }",
            "        if self.mask is not None:",
            "            mask_config = self._serialize_function_to_config(self.mask)",
            "            config.update(",
            "                {",
            "                    \"mask\": mask_config[0],",
            "                    \"mask_type\": mask_config[1],",
            "                    \"mask_module\": mask_config[2],",
            "                }",
            "            )",
            "        config[\"arguments\"] = self.arguments",
            "",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    def _serialize_function_to_config(self, inputs, allow_raw=False):",
            "        if isinstance(inputs, python_types.LambdaType):",
            "            output = generic_utils.func_dump(inputs)",
            "            output_type = \"lambda\"",
            "            module = inputs.__module__",
            "        elif callable(inputs):",
            "            output = inputs.__name__",
            "            output_type = \"function\"",
            "            module = inputs.__module__",
            "        elif allow_raw:",
            "            output = inputs",
            "            output_type = \"raw\"",
            "            module = None",
            "        else:",
            "            raise ValueError(",
            "                f\"Invalid input for serialization, type: {type(inputs)} \"",
            "            )",
            "",
            "        return output, output_type, module",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        config = config.copy()",
            "        function = cls._parse_function_from_config(",
            "            config, custom_objects, \"function\", \"module\", \"function_type\"",
            "        )",
            "",
            "        output_shape = cls._parse_function_from_config(",
            "            config,",
            "            custom_objects,",
            "            \"output_shape\",",
            "            \"output_shape_module\",",
            "            \"output_shape_type\",",
            "        )",
            "        if \"mask\" in config:",
            "            mask = cls._parse_function_from_config(",
            "                config, custom_objects, \"mask\", \"mask_module\", \"mask_type\"",
            "            )",
            "        else:",
            "            mask = None",
            "",
            "        config[\"function\"] = function",
            "        config[\"output_shape\"] = output_shape",
            "        config[\"mask\"] = mask",
            "",
            "        # If arguments were numpy array, they have been saved as",
            "        # list. We need to recover the ndarray",
            "        if \"arguments\" in config:",
            "            for key in config[\"arguments\"]:",
            "                if isinstance(config[\"arguments\"][key], dict):",
            "                    arg_dict = config[\"arguments\"][key]",
            "                    if \"type\" in arg_dict and arg_dict[\"type\"] == \"ndarray\":",
            "                        # Overwrite the argument with its numpy translation",
            "                        config[\"arguments\"][key] = np.array(arg_dict[\"value\"])",
            "",
            "        return cls(**config)",
            "",
            "    @classmethod",
            "    def _parse_function_from_config(",
            "        cls,",
            "        config,",
            "        custom_objects,",
            "        func_attr_name,",
            "        module_attr_name,",
            "        func_type_attr_name,",
            "    ):",
            "        globs = globals().copy()",
            "        module = config.pop(module_attr_name, None)",
            "        if module in sys.modules:",
            "            globs.update(sys.modules[module].__dict__)",
            "        elif module is not None:",
            "            # Note: we don't know the name of the function if it's a lambda.",
            "            warnings.warn(",
            "                \"{} is not loaded, but a Lambda layer uses it. \"",
            "                \"It may cause errors.\".format(module),",
            "                UserWarning,",
            "                stacklevel=2,",
            "            )",
            "        if custom_objects:",
            "            globs.update(custom_objects)",
            "        function_type = config.pop(func_type_attr_name)",
            "        if function_type == \"function\":",
            "            # Simple lookup in custom objects",
            "            function = serialization.deserialize_keras_object(",
            "                config[func_attr_name],",
            "                custom_objects=custom_objects,",
            "                printable_module_name=\"function in Lambda layer\",",
            "            )",
            "        elif function_type == \"lambda\":",
            "            # Unsafe deserialization from bytecode",
            "            function = generic_utils.func_load(",
            "                config[func_attr_name], globs=globs",
            "            )",
            "        elif function_type == \"raw\":",
            "            function = config[func_attr_name]",
            "        else:",
            "            supported_types = [\"function\", \"lambda\", \"raw\"]",
            "            raise TypeError(",
            "                \"Unsupported value for `function_type` argument. Received: \"",
            "                f\"function_type={function_type}. \"",
            "                f\"Expected one of {supported_types}\"",
            "            )",
            "        return function"
        ],
        "afterPatchFile": [
            "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Contains the Lambda layer.\"\"\"",
            "",
            "import sys",
            "import textwrap",
            "import types as python_types",
            "import warnings",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "",
            "from keras.engine.base_layer import Layer",
            "from keras.saving import serialization_lib",
            "from keras.saving.legacy import serialization as legacy_serialization",
            "from keras.utils import generic_utils",
            "from keras.utils import tf_inspect",
            "from keras.utils import tf_utils",
            "",
            "# isort: off",
            "from tensorflow.python.platform import tf_logging",
            "from tensorflow.python.util.tf_export import keras_export",
            "",
            "",
            "@keras_export(\"keras.layers.Lambda\")",
            "class Lambda(Layer):",
            "    \"\"\"Wraps arbitrary expressions as a `Layer` object.",
            "",
            "    The `Lambda` layer exists so that arbitrary expressions can be used",
            "    as a `Layer` when constructing `Sequential`",
            "    and Functional API models. `Lambda` layers are best suited for simple",
            "    operations or quick experimentation. For more advanced use cases, follow",
            "    [this guide](",
            "    https://www.tensorflow.org/guide/keras/custom_layers_and_models)",
            "    for subclassing `tf.keras.layers.Layer`.",
            "",
            "    WARNING: `tf.keras.layers.Lambda` layers have (de)serialization limitations!",
            "",
            "    The main reason to subclass `tf.keras.layers.Layer` instead of using a",
            "    `Lambda` layer is saving and inspecting a Model. `Lambda` layers",
            "    are saved by serializing the Python bytecode, which is fundamentally",
            "    non-portable. They should only be loaded in the same environment where",
            "    they were saved. Subclassed layers can be saved in a more portable way",
            "    by overriding their `get_config` method. Models that rely on",
            "    subclassed Layers are also often easier to visualize and reason about.",
            "",
            "    Examples:",
            "",
            "    ```python",
            "    # add a x -> x^2 layer",
            "    model.add(Lambda(lambda x: x ** 2))",
            "    ```",
            "    ```python",
            "    # add a layer that returns the concatenation",
            "    # of the positive part of the input and",
            "    # the opposite of the negative part",
            "",
            "    def antirectifier(x):",
            "        x -= K.mean(x, axis=1, keepdims=True)",
            "        x = K.l2_normalize(x, axis=1)",
            "        pos = K.relu(x)",
            "        neg = K.relu(-x)",
            "        return K.concatenate([pos, neg], axis=1)",
            "",
            "    model.add(Lambda(antirectifier))",
            "    ```",
            "",
            "    Variables:",
            "      While it is possible to use Variables with Lambda layers, this practice is",
            "      discouraged as it can easily lead to bugs. For instance, consider the",
            "      following layer:",
            "",
            "    ```python",
            "      scale = tf.Variable(1.)",
            "      scale_layer = tf.keras.layers.Lambda(lambda x: x * scale)",
            "    ```",
            "",
            "      Because scale_layer does not directly track the `scale` variable, it will",
            "      not appear in `scale_layer.trainable_weights` and will therefore not be",
            "      trained if `scale_layer` is used in a Model.",
            "",
            "      A better pattern is to write a subclassed Layer:",
            "",
            "    ```python",
            "      class ScaleLayer(tf.keras.layers.Layer):",
            "        def __init__(self):",
            "          super(ScaleLayer, self).__init__()",
            "          self.scale = tf.Variable(1.)",
            "",
            "        def call(self, inputs):",
            "          return inputs * self.scale",
            "    ```",
            "",
            "      In general, Lambda layers can be convenient for simple stateless",
            "      computation, but anything more complex should use a subclass Layer",
            "      instead.",
            "",
            "    Args:",
            "      function: The function to be evaluated. Takes input tensor as first",
            "        argument.",
            "      output_shape: Expected output shape from function. This argument can be",
            "        inferred if not explicitly provided. Can be a tuple or function. If a",
            "        tuple, it only specifies the first dimension onward;",
            "        sample dimension is assumed either the same as the input:",
            "        `output_shape = (input_shape[0], ) + output_shape` or, the input is",
            "        `None` and the sample dimension is also `None`:",
            "        `output_shape = (None, ) + output_shape` If a function, it specifies the",
            "        entire shape as a function of the input shape:",
            "        `output_shape = f(input_shape)`",
            "      mask: Either None (indicating no masking) or a callable with the same",
            "        signature as the `compute_mask` layer method, or a tensor that will be",
            "        returned as output mask regardless of what the input is.",
            "      arguments: Optional dictionary of keyword arguments to be passed to the",
            "        function.",
            "    Input shape: Arbitrary. Use the keyword argument input_shape (tuple of",
            "      integers, does not include the samples axis) when using this layer as the",
            "      first layer in a model.",
            "    Output shape: Specified by `output_shape` argument",
            "    \"\"\"",
            "",
            "    @tf.__internal__.tracking.no_automatic_dependency_tracking",
            "    def __init__(",
            "        self, function, output_shape=None, mask=None, arguments=None, **kwargs",
            "    ):",
            "        super().__init__(**kwargs)",
            "",
            "        self.arguments = arguments or {}",
            "        self.function = function",
            "",
            "        if mask is not None:",
            "            self.supports_masking = True",
            "        self.mask = mask",
            "        self._output_shape = output_shape",
            "",
            "        # Warning on every invocation will be quite irksome in Eager mode.",
            "        self._already_warned = False",
            "",
            "        function_args = tf_inspect.getfullargspec(function).args",
            "        self._fn_expects_training_arg = \"training\" in function_args",
            "        self._fn_expects_mask_arg = \"mask\" in function_args",
            "",
            "    @tf_utils.shape_type_conversion",
            "    def compute_output_shape(self, input_shape):",
            "        if self._output_shape is None:",
            "            # Make use of existing autocomputation but provide Lambda-specific",
            "            # error message. This is always safe to run even when the outer",
            "            # context is Graph mode because Lambda layers don't have side",
            "            # effects such as `add_loss`.",
            "            with tf.__internal__.eager_context.eager_mode():",
            "                try:",
            "                    return super().compute_output_shape(input_shape)",
            "                except NotImplementedError:",
            "                    raise NotImplementedError(",
            "                        \"We could not automatically infer the shape of \"",
            "                        \"the Lambda's output. Please specify `output_shape` \"",
            "                        \"for this Lambda.\"",
            "                    )",
            "",
            "        if callable(self._output_shape):",
            "            output_shapes = self._output_shape(input_shape)",
            "            return tf_utils.convert_shapes(output_shapes, to_tuples=False)",
            "",
            "        # Output shapes are passed directly and don't include batch dimension.",
            "        input_tensor_shape = tf_utils.convert_shapes(",
            "            input_shape, to_tuples=False",
            "        )",
            "        batch_size = (",
            "            tf.nest.flatten(input_tensor_shape)[0][0] if input_shape else None",
            "        )",
            "",
            "        def _add_batch(shape):",
            "            return tf.TensorShape([batch_size] + shape.as_list())",
            "",
            "        output_shapes = tf_utils.convert_shapes(",
            "            self._output_shape, to_tuples=False",
            "        )",
            "        return tf.nest.map_structure(_add_batch, output_shapes)",
            "",
            "    def call(self, inputs, mask=None, training=None):",
            "        # We must copy for thread safety, but it only needs to be a shallow",
            "        # copy.",
            "        kwargs = {k: v for k, v in self.arguments.items()}",
            "        if self._fn_expects_mask_arg:",
            "            kwargs[\"mask\"] = mask",
            "        if self._fn_expects_training_arg:",
            "            kwargs[\"training\"] = training",
            "",
            "        created_variables = []",
            "",
            "        def _variable_creator(next_creator, **kwargs):",
            "            var = next_creator(**kwargs)",
            "            created_variables.append(var)",
            "            return var",
            "",
            "        with tf.GradientTape(",
            "            watch_accessed_variables=True",
            "        ) as tape, tf.variable_creator_scope(_variable_creator):",
            "            result = self.function(inputs, **kwargs)",
            "        self._check_variables(created_variables, tape.watched_variables())",
            "        return result",
            "",
            "    def _check_variables(self, created_variables, accessed_variables):",
            "        if not created_variables and not accessed_variables:",
            "            # In the common case that a Lambda layer does not touch a Variable,",
            "            # we don't want to incur the runtime cost of assembling any state",
            "            # used for checking only to immediately discard it.",
            "            return",
            "",
            "        # Filter out the state variable in the tf.random.Generator, which is",
            "        # commonly used for initializer or droput. The variable is intentionally",
            "        # not tracked and it is not a trainable variable.",
            "        created_variables = [",
            "            v for v in created_variables if \"StateVar\" not in v.name",
            "        ]",
            "",
            "        tracked_weights = set(v.ref() for v in self.weights)",
            "        untracked_new_vars = [",
            "            v for v in created_variables if v.ref() not in tracked_weights",
            "        ]",
            "        if untracked_new_vars:",
            "            variable_str = \"\\n\".join(f\"  {i}\" for i in untracked_new_vars)",
            "            error_str = textwrap.dedent(",
            "                \"\"\"",
            "          The following Variables were created within a Lambda layer ({name})",
            "          but are not tracked by said layer:",
            "          {variable_str}",
            "          The layer cannot safely ensure proper Variable reuse across multiple",
            "          calls, and consequently this behavior is disallowed for safety. Lambda",
            "          layers are not well suited to stateful computation; instead, writing a",
            "          subclassed Layer is the recommend way to define layers with",
            "          Variables.\"\"\"",
            "            ).format(name=self.name, variable_str=variable_str)",
            "            raise ValueError(error_str)",
            "",
            "        untracked_used_vars = [",
            "            v for v in accessed_variables if v.ref() not in tracked_weights",
            "        ]",
            "        if untracked_used_vars and not self._already_warned:",
            "            variable_str = \"\\n\".join(f\"  {i}\" for i in untracked_used_vars)",
            "            self._warn(",
            "                textwrap.dedent(",
            "                    \"\"\"",
            "          The following Variables were used a Lambda layer's call ({name}), but",
            "          are not present in its tracked objects:",
            "          {variable_str}",
            "          It is possible that this is intended behavior, but it is more likely",
            "          an omission. This is a strong indication that this layer should be",
            "          formulated as a subclassed Layer rather than a Lambda layer.\"\"\"",
            "                ).format(name=self.name, variable_str=variable_str)",
            "            )",
            "            self._already_warned = True",
            "",
            "    def _warn(self, msg):",
            "        # This method will be overridden in a unit test to raise an error,",
            "        # because self.assertWarns is not universally implemented.",
            "        return tf_logging.warning(msg)",
            "",
            "    def compute_mask(self, inputs, mask=None):",
            "        if callable(self.mask):",
            "            return self.mask(inputs, mask)",
            "        return self.mask",
            "",
            "    def get_config(self):",
            "        function_config = self._serialize_function_to_config(self.function)",
            "        output_shape_config = self._serialize_function_to_config(",
            "            self._output_shape, allow_raw=True",
            "        )",
            "        config = {",
            "            \"function\": function_config[0],",
            "            \"function_type\": function_config[1],",
            "            \"module\": function_config[2],",
            "            \"output_shape\": output_shape_config[0],",
            "            \"output_shape_type\": output_shape_config[1],",
            "            \"output_shape_module\": output_shape_config[2],",
            "        }",
            "        if self.mask is not None:",
            "            mask_config = self._serialize_function_to_config(self.mask)",
            "            config.update(",
            "                {",
            "                    \"mask\": mask_config[0],",
            "                    \"mask_type\": mask_config[1],",
            "                    \"mask_module\": mask_config[2],",
            "                }",
            "            )",
            "        config[\"arguments\"] = self.arguments",
            "",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    def _serialize_function_to_config(self, inputs, allow_raw=False):",
            "        if isinstance(inputs, python_types.LambdaType):",
            "            output = generic_utils.func_dump(inputs)",
            "            output_type = \"lambda\"",
            "            module = inputs.__module__",
            "        elif callable(inputs):",
            "            output = inputs.__name__",
            "            output_type = \"function\"",
            "            module = inputs.__module__",
            "        elif allow_raw:",
            "            output = inputs",
            "            output_type = \"raw\"",
            "            module = None",
            "        else:",
            "            raise ValueError(",
            "                f\"Invalid input for serialization, type: {type(inputs)} \"",
            "            )",
            "",
            "        return output, output_type, module",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        config = config.copy()",
            "        function = cls._parse_function_from_config(",
            "            config, custom_objects, \"function\", \"module\", \"function_type\"",
            "        )",
            "",
            "        output_shape = cls._parse_function_from_config(",
            "            config,",
            "            custom_objects,",
            "            \"output_shape\",",
            "            \"output_shape_module\",",
            "            \"output_shape_type\",",
            "        )",
            "        if \"mask\" in config:",
            "            mask = cls._parse_function_from_config(",
            "                config, custom_objects, \"mask\", \"mask_module\", \"mask_type\"",
            "            )",
            "        else:",
            "            mask = None",
            "",
            "        config[\"function\"] = function",
            "        config[\"output_shape\"] = output_shape",
            "        config[\"mask\"] = mask",
            "",
            "        # If arguments were numpy array, they have been saved as",
            "        # list. We need to recover the ndarray",
            "        if \"arguments\" in config:",
            "            for key in config[\"arguments\"]:",
            "                if isinstance(config[\"arguments\"][key], dict):",
            "                    arg_dict = config[\"arguments\"][key]",
            "                    if \"type\" in arg_dict and arg_dict[\"type\"] == \"ndarray\":",
            "                        # Overwrite the argument with its numpy translation",
            "                        config[\"arguments\"][key] = np.array(arg_dict[\"value\"])",
            "",
            "        return cls(**config)",
            "",
            "    @classmethod",
            "    def _parse_function_from_config(",
            "        cls,",
            "        config,",
            "        custom_objects,",
            "        func_attr_name,",
            "        module_attr_name,",
            "        func_type_attr_name,",
            "    ):",
            "        globs = globals().copy()",
            "        module = config.pop(module_attr_name, None)",
            "        if module in sys.modules:",
            "            globs.update(sys.modules[module].__dict__)",
            "        elif module is not None:",
            "            # Note: we don't know the name of the function if it's a lambda.",
            "            warnings.warn(",
            "                \"{} is not loaded, but a Lambda layer uses it. \"",
            "                \"It may cause errors.\".format(module),",
            "                UserWarning,",
            "                stacklevel=2,",
            "            )",
            "        if custom_objects:",
            "            globs.update(custom_objects)",
            "        function_type = config.pop(func_type_attr_name)",
            "        if function_type == \"function\":",
            "            # Simple lookup in custom objects",
            "            function = legacy_serialization.deserialize_keras_object(",
            "                config[func_attr_name],",
            "                custom_objects=custom_objects,",
            "                printable_module_name=\"function in Lambda layer\",",
            "            )",
            "        elif function_type == \"lambda\":",
            "            if serialization_lib.in_safe_mode():",
            "                raise ValueError(",
            "                    \"Requested the deserialization of a Lambda layer with a \"",
            "                    \"Python `lambda` inside it. \"",
            "                    \"This carries a potential risk of arbitrary code execution \"",
            "                    \"and thus it is disallowed by default. If you trust the \"",
            "                    \"source of the saved model, you can pass `safe_mode=False` \"",
            "                    \"to the loading function in order to allow \"",
            "                    \"Lambda layer loading.\"",
            "                )",
            "            # /!\\ Unsafe deserialization from bytecode! Danger! /!\\",
            "            function = generic_utils.func_load(",
            "                config[func_attr_name], globs=globs",
            "            )",
            "        elif function_type == \"raw\":",
            "            function = config[func_attr_name]",
            "        else:",
            "            supported_types = [\"function\", \"lambda\", \"raw\"]",
            "            raise TypeError(",
            "                \"Unsupported value for `function_type` argument. Received: \"",
            "                f\"function_type={function_type}. \"",
            "                f\"Expected one of {supported_types}\"",
            "            )",
            "        return function"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "26": [],
            "384": [
                "Lambda",
                "_parse_function_from_config"
            ],
            "390": [
                "Lambda",
                "_parse_function_from_config"
            ]
        },
        "addLocation": []
    },
    "keras/layers/rnn/cell_wrappers.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " from keras.layers.rnn import lstm"
            },
            "2": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " from keras.layers.rnn.abstract_rnn_cell import AbstractRNNCell"
            },
            "3": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from keras.saving.legacy import serialization"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+from keras.saving import serialization_lib"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+from keras.saving.legacy import serialization as legacy_serialization"
            },
            "6": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " from keras.utils import generic_utils"
            },
            "7": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " from keras.utils import tf_inspect"
            },
            "8": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 658,
                "afterPatchRowNumber": 659,
                "PatchRowcode": "     function_type = config.pop(func_type_attr_name)"
            },
            "10": {
                "beforePatchRowNumber": 659,
                "afterPatchRowNumber": 660,
                "PatchRowcode": "     if function_type == \"function\":"
            },
            "11": {
                "beforePatchRowNumber": 660,
                "afterPatchRowNumber": 661,
                "PatchRowcode": "         # Simple lookup in custom objects"
            },
            "12": {
                "beforePatchRowNumber": 661,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        function = serialization.deserialize_keras_object("
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 662,
                "PatchRowcode": "+        function = legacy_serialization.deserialize_keras_object("
            },
            "14": {
                "beforePatchRowNumber": 662,
                "afterPatchRowNumber": 663,
                "PatchRowcode": "             config[func_attr_name],"
            },
            "15": {
                "beforePatchRowNumber": 663,
                "afterPatchRowNumber": 664,
                "PatchRowcode": "             custom_objects=custom_objects,"
            },
            "16": {
                "beforePatchRowNumber": 664,
                "afterPatchRowNumber": 665,
                "PatchRowcode": "             printable_module_name=\"function in wrapper\","
            },
            "17": {
                "beforePatchRowNumber": 665,
                "afterPatchRowNumber": 666,
                "PatchRowcode": "         )"
            },
            "18": {
                "beforePatchRowNumber": 666,
                "afterPatchRowNumber": 667,
                "PatchRowcode": "     elif function_type == \"lambda\":"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 668,
                "PatchRowcode": "+        if serialization_lib.in_safe_mode():"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 669,
                "PatchRowcode": "+            raise ValueError("
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 670,
                "PatchRowcode": "+                \"Requested the deserialization of a layer with a \""
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 671,
                "PatchRowcode": "+                \"Python `lambda` inside it. \""
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 672,
                "PatchRowcode": "+                \"This carries a potential risk of arbitrary code execution \""
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 673,
                "PatchRowcode": "+                \"and thus it is disallowed by default. If you trust the \""
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 674,
                "PatchRowcode": "+                \"source of the saved model, you can pass `safe_mode=False` to \""
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 675,
                "PatchRowcode": "+                \"the loading function in order to allow \""
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 676,
                "PatchRowcode": "+                \"`lambda` loading.\""
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 677,
                "PatchRowcode": "+            )"
            },
            "29": {
                "beforePatchRowNumber": 667,
                "afterPatchRowNumber": 678,
                "PatchRowcode": "         # Unsafe deserialization from bytecode"
            },
            "30": {
                "beforePatchRowNumber": 668,
                "afterPatchRowNumber": 679,
                "PatchRowcode": "         function = generic_utils.func_load(config[func_attr_name], globs=globs)"
            },
            "31": {
                "beforePatchRowNumber": 669,
                "afterPatchRowNumber": 680,
                "PatchRowcode": "     else:"
            }
        },
        "frontPatchFile": [
            "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Module implementing RNN wrappers.\"\"\"",
            "",
            "",
            "# Note that all the APIs under this module are exported as tf.nn.*. This is due",
            "# to the fact that those APIs were from tf.nn.rnn_cell_impl. They are ported",
            "# here to avoid the cyclic dependency issue for serialization. These APIs will",
            "# probably be deprecated and removed in future since similar API is available in",
            "# existing Keras RNN API.",
            "",
            "import hashlib",
            "import numbers",
            "import sys",
            "import types as python_types",
            "import warnings",
            "",
            "import tensorflow.compat.v2 as tf",
            "",
            "from keras.layers.rnn import lstm",
            "from keras.layers.rnn.abstract_rnn_cell import AbstractRNNCell",
            "from keras.saving.legacy import serialization",
            "from keras.utils import generic_utils",
            "from keras.utils import tf_inspect",
            "",
            "# isort: off",
            "from tensorflow.python.util.tf_export import tf_export",
            "from tensorflow.python.util.deprecation import deprecated",
            "",
            "",
            "class _RNNCellWrapper(AbstractRNNCell):",
            "    \"\"\"Base class for cells wrappers V2 compatibility.",
            "",
            "    This class along with `rnn_cell_impl._RNNCellWrapperV1` allows to define",
            "    wrappers that are compatible with V1 and V2, and defines helper methods for",
            "    this purpose.",
            "    \"\"\"",
            "",
            "    def __init__(self, cell, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.cell = cell",
            "        cell_call_spec = tf_inspect.getfullargspec(cell.call)",
            "        self._call_spec.expects_training_arg = (",
            "            \"training\" in cell_call_spec.args",
            "        ) or (cell_call_spec.varkw is not None)",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Calls the wrapped cell and performs the wrapping logic.",
            "",
            "        This method is called from the wrapper's `call` or `__call__` methods.",
            "",
            "        Args:",
            "          inputs: A tensor with wrapped cell's input.",
            "          state: A tensor or tuple of tensors with wrapped cell's state.",
            "          cell_call_fn: Wrapped cell's method to use for step computation",
            "            (cell's `__call__` or 'call' method).",
            "          **kwargs: Additional arguments.",
            "",
            "        Returns:",
            "          A pair containing:",
            "          - Output: A tensor with cell's output.",
            "          - New state: A tensor or tuple of tensors with new wrapped cell's",
            "            state.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def call(self, inputs, state, **kwargs):",
            "        \"\"\"Runs the RNN cell step computation.",
            "",
            "        When `call` is being used, we assume that the wrapper object has been",
            "        built, and therefore the wrapped cells has been built via its `build`",
            "        method and its `call` method can be used directly.",
            "",
            "        This allows to use the wrapped cell and the non-wrapped cell",
            "        equivalently when using `call` and `build`.",
            "",
            "        Args:",
            "          inputs: A tensor with wrapped cell's input.",
            "          state: A tensor or tuple of tensors with wrapped cell's state.",
            "          **kwargs: Additional arguments passed to the wrapped cell's `call`.",
            "",
            "        Returns:",
            "          A pair containing:",
            "",
            "          - Output: A tensor with cell's output.",
            "          - New state: A tensor or tuple of tensors with new wrapped cell's",
            "            state.",
            "        \"\"\"",
            "        return self._call_wrapped_cell(",
            "            inputs, state, cell_call_fn=self.cell.call, **kwargs",
            "        )",
            "",
            "    def build(self, inputs_shape):",
            "        \"\"\"Builds the wrapped cell.\"\"\"",
            "        self.cell.build(inputs_shape)",
            "        self.built = True",
            "",
            "    @property",
            "    def wrapped_cell(self):",
            "        return self.cell",
            "",
            "    @property",
            "    def state_size(self):",
            "        return self.cell.state_size",
            "",
            "    @property",
            "    def output_size(self):",
            "        return self.cell.output_size",
            "",
            "    def zero_state(self, batch_size, dtype):",
            "        with tf.name_scope(type(self).__name__ + \"ZeroState\"):",
            "            return self.cell.zero_state(batch_size, dtype)",
            "",
            "    def get_config(self):",
            "        config = {",
            "            \"cell\": {",
            "                \"class_name\": self.cell.__class__.__name__,",
            "                \"config\": self.cell.get_config(),",
            "            },",
            "        }",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        config = config.copy()",
            "        from keras.layers.serialization import deserialize as deserialize_layer",
            "",
            "        cell = deserialize_layer(",
            "            config.pop(\"cell\"), custom_objects=custom_objects",
            "        )",
            "        return cls(cell, **config)",
            "",
            "",
            "@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")",
            "@tf_export(\"nn.RNNCellDropoutWrapper\", v1=[])",
            "class DropoutWrapper(_RNNCellWrapper):",
            "    \"\"\"Operator adding dropout to inputs and outputs of the given cell.\"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        cell,",
            "        input_keep_prob=1.0,",
            "        output_keep_prob=1.0,",
            "        state_keep_prob=1.0,",
            "        variational_recurrent=False,",
            "        input_size=None,",
            "        dtype=None,",
            "        seed=None,",
            "        dropout_state_filter_visitor=None,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"Create a cell with added input, state, and/or output dropout.",
            "",
            "        If `variational_recurrent` is set to `True` (**NOT** the default",
            "        behavior), then the same dropout mask is applied at every step, as",
            "        described in: [A Theoretically Grounded Application of Dropout in",
            "        Recurrent Neural Networks. Y. Gal, Z.",
            "        Ghahramani](https://arxiv.org/abs/1512.05287).",
            "",
            "        Otherwise a different dropout mask is applied at every time step.",
            "",
            "        Note, by default (unless a custom `dropout_state_filter` is provided),",
            "        the memory state (`c` component of any `LSTMStateTuple`) passing through",
            "        a `DropoutWrapper` is never modified.  This behavior is described in the",
            "        above article.",
            "",
            "        Args:",
            "          cell: an RNNCell, a projection to output_size is added to it.",
            "          input_keep_prob: unit Tensor or float between 0 and 1, input keep",
            "            probability; if it is constant and 1, no input dropout will be",
            "            added.",
            "          output_keep_prob: unit Tensor or float between 0 and 1, output keep",
            "            probability; if it is constant and 1, no output dropout will be",
            "            added.",
            "          state_keep_prob: unit Tensor or float between 0 and 1, output keep",
            "            probability; if it is constant and 1, no output dropout will be",
            "            added.  State dropout is performed on the outgoing states of the",
            "            cell. **Note** the state components to which dropout is applied when",
            "            `state_keep_prob` is in `(0, 1)` are also determined by the argument",
            "            `dropout_state_filter_visitor` (e.g. by default dropout is never",
            "            applied to the `c` component of an `LSTMStateTuple`).",
            "          variational_recurrent: Python bool.  If `True`, then the same dropout",
            "            pattern is applied across all time steps per run call. If this",
            "            parameter is set, `input_size` **must** be provided.",
            "          input_size: (optional) (possibly nested tuple of) `TensorShape`",
            "            objects containing the depth(s) of the input tensors expected to be",
            "            passed in to the `DropoutWrapper`.  Required and used **iff**",
            "            `variational_recurrent = True` and `input_keep_prob < 1`.",
            "          dtype: (optional) The `dtype` of the input, state, and output tensors.",
            "            Required and used **iff** `variational_recurrent = True`.",
            "          seed: (optional) integer, the randomness seed.",
            "          dropout_state_filter_visitor: (optional), default: (see below).",
            "            Function that takes any hierarchical level of the state and returns",
            "            a scalar or depth=1 structure of Python booleans describing which",
            "            terms in the state should be dropped out.  In addition, if the",
            "            function returns `True`, dropout is applied across this sublevel.",
            "            If the function returns `False`, dropout is not applied across this",
            "            entire sublevel.  Default behavior: perform dropout on all terms",
            "            except the memory (`c`) state of `LSTMCellState` objects, and don't",
            "            try to apply dropout to",
            "            `TensorArray` objects:",
            "            ```",
            "            def dropout_state_filter_visitor(s):",
            "              # Never perform dropout on the c state.",
            "              if isinstance(s, LSTMCellState):",
            "                return LSTMCellState(c=False, h=True)",
            "              elif isinstance(s, TensorArray):",
            "                return False",
            "              return True",
            "            ```",
            "          **kwargs: dict of keyword arguments for base layer.",
            "",
            "        Raises:",
            "          TypeError: if `cell` is not an `RNNCell`, or `keep_state_fn` is",
            "            provided but not `callable`.",
            "          ValueError: if any of the keep_probs are not between 0 and 1.",
            "        \"\"\"",
            "        if isinstance(cell, lstm.LSTMCell):",
            "            raise ValueError(",
            "                \"keras LSTM cell does not work with DropoutWrapper. \"",
            "                \"Please use LSTMCell(dropout=x, recurrent_dropout=y) \"",
            "                \"instead.\"",
            "            )",
            "        super().__init__(cell, dtype=dtype, **kwargs)",
            "",
            "        if dropout_state_filter_visitor is not None and not callable(",
            "            dropout_state_filter_visitor",
            "        ):",
            "            raise TypeError(",
            "                \"dropout_state_filter_visitor must be callable. \"",
            "                f\"Received: {dropout_state_filter_visitor}\"",
            "            )",
            "        self._dropout_state_filter = (",
            "            dropout_state_filter_visitor",
            "            or _default_dropout_state_filter_visitor",
            "        )",
            "        with tf.name_scope(\"DropoutWrapperInit\"):",
            "",
            "            def tensor_and_const_value(v):",
            "                tensor_value = tf.convert_to_tensor(v)",
            "                const_value = tf.get_static_value(tensor_value)",
            "                return (tensor_value, const_value)",
            "",
            "            for prob, attr in [",
            "                (input_keep_prob, \"input_keep_prob\"),",
            "                (state_keep_prob, \"state_keep_prob\"),",
            "                (output_keep_prob, \"output_keep_prob\"),",
            "            ]:",
            "                tensor_prob, const_prob = tensor_and_const_value(prob)",
            "                if const_prob is not None:",
            "                    if const_prob < 0 or const_prob > 1:",
            "                        raise ValueError(",
            "                            f\"Parameter {attr} must be between 0 and 1. \"",
            "                            f\"Received {const_prob}\"",
            "                        )",
            "                    setattr(self, f\"_{attr}\", float(const_prob))",
            "                else:",
            "                    setattr(self, f\"_{attr}\", tensor_prob)",
            "",
            "        # Set variational_recurrent, seed before running the code below",
            "        self._variational_recurrent = variational_recurrent",
            "        self._input_size = input_size",
            "        self._seed = seed",
            "",
            "        self._recurrent_input_noise = None",
            "        self._recurrent_state_noise = None",
            "        self._recurrent_output_noise = None",
            "",
            "        if variational_recurrent:",
            "            if dtype is None:",
            "                raise ValueError(",
            "                    \"When variational_recurrent=True, dtype must be provided\"",
            "                )",
            "",
            "            def convert_to_batch_shape(s):",
            "                # Prepend a 1 for the batch dimension; for recurrent",
            "                # variational dropout we use the same dropout mask for all",
            "                # batch elements.",
            "                return tf.concat(([1], tf.TensorShape(s).as_list()), 0)",
            "",
            "            def batch_noise(s, inner_seed):",
            "                shape = convert_to_batch_shape(s)",
            "                return tf.random.uniform(shape, seed=inner_seed, dtype=dtype)",
            "",
            "            if (",
            "                not isinstance(self._input_keep_prob, numbers.Real)",
            "                or self._input_keep_prob < 1.0",
            "            ):",
            "                if input_size is None:",
            "                    raise ValueError(",
            "                        \"When variational_recurrent=True and input_keep_prob < \"",
            "                        \"1.0 or is unknown, input_size must be provided\"",
            "                    )",
            "                self._recurrent_input_noise = _enumerated_map_structure_up_to(",
            "                    input_size,",
            "                    lambda i, s: batch_noise(",
            "                        s, inner_seed=self._gen_seed(\"input\", i)",
            "                    ),",
            "                    input_size,",
            "                )",
            "            self._recurrent_state_noise = _enumerated_map_structure_up_to(",
            "                cell.state_size,",
            "                lambda i, s: batch_noise(",
            "                    s, inner_seed=self._gen_seed(\"state\", i)",
            "                ),",
            "                cell.state_size,",
            "            )",
            "            self._recurrent_output_noise = _enumerated_map_structure_up_to(",
            "                cell.output_size,",
            "                lambda i, s: batch_noise(",
            "                    s, inner_seed=self._gen_seed(\"output\", i)",
            "                ),",
            "                cell.output_size,",
            "            )",
            "",
            "    def _gen_seed(self, salt_prefix, index):",
            "        if self._seed is None:",
            "            return None",
            "        salt = \"%s_%d\" % (salt_prefix, index)",
            "        string = (str(self._seed) + salt).encode(\"utf-8\")",
            "        return int(hashlib.md5(string).hexdigest()[:8], 16) & 0x7FFFFFFF",
            "",
            "    def _variational_recurrent_dropout_value(",
            "        self, unused_index, value, noise, keep_prob",
            "    ):",
            "        \"\"\"Performs dropout given the pre-calculated noise tensor.\"\"\"",
            "        # uniform [keep_prob, 1.0 + keep_prob)",
            "        random_tensor = keep_prob + noise",
            "",
            "        # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)",
            "        binary_tensor = tf.floor(random_tensor)",
            "        ret = tf.divide(value, keep_prob) * binary_tensor",
            "        ret.set_shape(value.get_shape())",
            "        return ret",
            "",
            "    def _dropout(",
            "        self,",
            "        values,",
            "        salt_prefix,",
            "        recurrent_noise,",
            "        keep_prob,",
            "        shallow_filtered_substructure=None,",
            "    ):",
            "        \"\"\"Decides whether to perform standard dropout or recurrent dropout.\"\"\"",
            "",
            "        if shallow_filtered_substructure is None:",
            "            # Put something so we traverse the entire structure; inside the",
            "            # dropout function we check to see if leafs of this are bool or not.",
            "            shallow_filtered_substructure = values",
            "",
            "        if not self._variational_recurrent:",
            "",
            "            def dropout(i, do_dropout, v):",
            "                if not isinstance(do_dropout, bool) or do_dropout:",
            "                    return tf.nn.dropout(",
            "                        v,",
            "                        rate=1.0 - keep_prob,",
            "                        seed=self._gen_seed(salt_prefix, i),",
            "                    )",
            "                else:",
            "                    return v",
            "",
            "            return _enumerated_map_structure_up_to(",
            "                shallow_filtered_substructure,",
            "                dropout,",
            "                *[shallow_filtered_substructure, values],",
            "            )",
            "        else:",
            "",
            "            def dropout(i, do_dropout, v, n):",
            "                if not isinstance(do_dropout, bool) or do_dropout:",
            "                    return self._variational_recurrent_dropout_value(",
            "                        i, v, n, keep_prob",
            "                    )",
            "                else:",
            "                    return v",
            "",
            "            return _enumerated_map_structure_up_to(",
            "                shallow_filtered_substructure,",
            "                dropout,",
            "                *[shallow_filtered_substructure, values, recurrent_noise],",
            "            )",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Runs the wrapped cell and applies dropout.",
            "",
            "        Args:",
            "          inputs: A tensor with wrapped cell's input.",
            "          state: A tensor or tuple of tensors with wrapped cell's state.",
            "          cell_call_fn: Wrapped cell's method to use for step computation",
            "            (cell's `__call__` or 'call' method).",
            "          **kwargs: Additional arguments.",
            "",
            "        Returns:",
            "          A pair containing:",
            "",
            "          - Output: A tensor with cell's output.",
            "          - New state: A tensor or tuple of tensors with new wrapped cell's",
            "            state.",
            "        \"\"\"",
            "",
            "        def _should_dropout(p):",
            "            return (not isinstance(p, float)) or p < 1",
            "",
            "        if _should_dropout(self._input_keep_prob):",
            "            inputs = self._dropout(",
            "                inputs,",
            "                \"input\",",
            "                self._recurrent_input_noise,",
            "                self._input_keep_prob,",
            "            )",
            "        output, new_state = cell_call_fn(inputs, state, **kwargs)",
            "        if _should_dropout(self._state_keep_prob):",
            "            # Identify which subsets of the state to perform dropout on and",
            "            # which ones to keep.",
            "            shallow_filtered_substructure = (",
            "                tf.__internal__.nest.get_traverse_shallow_structure(",
            "                    self._dropout_state_filter, new_state",
            "                )",
            "            )",
            "            new_state = self._dropout(",
            "                new_state,",
            "                \"state\",",
            "                self._recurrent_state_noise,",
            "                self._state_keep_prob,",
            "                shallow_filtered_substructure,",
            "            )",
            "        if _should_dropout(self._output_keep_prob):",
            "            output = self._dropout(",
            "                output,",
            "                \"output\",",
            "                self._recurrent_output_noise,",
            "                self._output_keep_prob,",
            "            )",
            "        return output, new_state",
            "",
            "    def get_config(self):",
            "        \"\"\"Returns the config of the dropout wrapper.\"\"\"",
            "        config = {",
            "            \"input_keep_prob\": self._input_keep_prob,",
            "            \"output_keep_prob\": self._output_keep_prob,",
            "            \"state_keep_prob\": self._state_keep_prob,",
            "            \"variational_recurrent\": self._variational_recurrent,",
            "            \"input_size\": self._input_size,",
            "            \"seed\": self._seed,",
            "        }",
            "        if self._dropout_state_filter != _default_dropout_state_filter_visitor:",
            "            (",
            "                function,",
            "                function_type,",
            "                function_module,",
            "            ) = _serialize_function_to_config(self._dropout_state_filter)",
            "            config.update(",
            "                {",
            "                    \"dropout_fn\": function,",
            "                    \"dropout_fn_type\": function_type,",
            "                    \"dropout_fn_module\": function_module,",
            "                }",
            "            )",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        if \"dropout_fn\" in config:",
            "            config = config.copy()",
            "            dropout_state_filter = _parse_config_to_function(",
            "                config,",
            "                custom_objects,",
            "                \"dropout_fn\",",
            "                \"dropout_fn_type\",",
            "                \"dropout_fn_module\",",
            "            )",
            "            config.pop(\"dropout_fn\")",
            "            config[\"dropout_state_filter_visitor\"] = dropout_state_filter",
            "        return super(DropoutWrapper, cls).from_config(",
            "            config, custom_objects=custom_objects",
            "        )",
            "",
            "",
            "@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")",
            "@tf_export(\"nn.RNNCellResidualWrapper\", v1=[])",
            "class ResidualWrapper(_RNNCellWrapper):",
            "    \"\"\"RNNCell wrapper that ensures cell inputs are added to the outputs.\"\"\"",
            "",
            "    def __init__(self, cell, residual_fn=None, **kwargs):",
            "        \"\"\"Constructs a `ResidualWrapper` for `cell`.",
            "",
            "        Args:",
            "          cell: An instance of `RNNCell`.",
            "          residual_fn: (Optional) The function to map raw cell inputs and raw",
            "            cell outputs to the actual cell outputs of the residual network.",
            "            Defaults to calling nest.map_structure on (lambda i, o: i + o),",
            "            inputs and outputs.",
            "          **kwargs: dict of keyword arguments for base layer.",
            "        \"\"\"",
            "        super().__init__(cell, **kwargs)",
            "        self._residual_fn = residual_fn",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Run the cell and apply the residual_fn.",
            "",
            "        Args:",
            "          inputs: cell inputs.",
            "          state: cell state.",
            "          cell_call_fn: Wrapped cell's method to use for step computation",
            "            (cell's `__call__` or 'call' method).",
            "          **kwargs: Additional arguments passed to the wrapped cell's `call`.",
            "",
            "        Returns:",
            "          Tuple of cell outputs and new state.",
            "",
            "        Raises:",
            "          TypeError: If cell inputs and outputs have different structure (type).",
            "          ValueError: If cell inputs and outputs have different structure",
            "            (value).",
            "        \"\"\"",
            "        outputs, new_state = cell_call_fn(inputs, state, **kwargs)",
            "",
            "        # Ensure shapes match",
            "        def assert_shape_match(inp, out):",
            "            inp.get_shape().assert_is_compatible_with(out.get_shape())",
            "",
            "        def default_residual_fn(inputs, outputs):",
            "            tf.nest.assert_same_structure(inputs, outputs)",
            "            tf.nest.map_structure(assert_shape_match, inputs, outputs)",
            "            return tf.nest.map_structure(",
            "                lambda inp, out: inp + out, inputs, outputs",
            "            )",
            "",
            "        res_outputs = (self._residual_fn or default_residual_fn)(",
            "            inputs, outputs",
            "        )",
            "        return (res_outputs, new_state)",
            "",
            "    def get_config(self):",
            "        \"\"\"Returns the config of the residual wrapper.\"\"\"",
            "        if self._residual_fn is not None:",
            "            (",
            "                function,",
            "                function_type,",
            "                function_module,",
            "            ) = _serialize_function_to_config(self._residual_fn)",
            "            config = {",
            "                \"residual_fn\": function,",
            "                \"residual_fn_type\": function_type,",
            "                \"residual_fn_module\": function_module,",
            "            }",
            "        else:",
            "            config = {}",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        if \"residual_fn\" in config:",
            "            config = config.copy()",
            "            residual_function = _parse_config_to_function(",
            "                config,",
            "                custom_objects,",
            "                \"residual_fn\",",
            "                \"residual_fn_type\",",
            "                \"residual_fn_module\",",
            "            )",
            "            config[\"residual_fn\"] = residual_function",
            "        return super(ResidualWrapper, cls).from_config(",
            "            config, custom_objects=custom_objects",
            "        )",
            "",
            "",
            "@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")",
            "@tf_export(\"nn.RNNCellDeviceWrapper\", v1=[])",
            "class DeviceWrapper(_RNNCellWrapper):",
            "    \"\"\"Operator that ensures an RNNCell runs on a particular device.\"\"\"",
            "",
            "    def __init__(self, cell, device, **kwargs):",
            "        \"\"\"Construct a `DeviceWrapper` for `cell` with device `device`.",
            "",
            "        Ensures the wrapped `cell` is called with `tf.device(device)`.",
            "",
            "        Args:",
            "          cell: An instance of `RNNCell`.",
            "          device: A device string or function, for passing to `tf.device`.",
            "          **kwargs: dict of keyword arguments for base layer.",
            "        \"\"\"",
            "        super().__init__(cell, **kwargs)",
            "        self._device = device",
            "",
            "    def zero_state(self, batch_size, dtype):",
            "        with tf.name_scope(type(self).__name__ + \"ZeroState\"):",
            "            with tf.compat.v1.device(self._device):",
            "                return self.cell.zero_state(batch_size, dtype)",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Run the cell on specified device.\"\"\"",
            "        with tf.compat.v1.device(self._device):",
            "            return cell_call_fn(inputs, state, **kwargs)",
            "",
            "    def get_config(self):",
            "        config = {\"device\": self._device}",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "",
            "def _serialize_function_to_config(function):",
            "    \"\"\"Serialize the function for get_config().\"\"\"",
            "    if isinstance(function, python_types.LambdaType):",
            "        output = generic_utils.func_dump(function)",
            "        output_type = \"lambda\"",
            "        module = function.__module__",
            "    elif callable(function):",
            "        output = function.__name__",
            "        output_type = \"function\"",
            "        module = function.__module__",
            "    else:",
            "        raise ValueError(",
            "            f\"Unrecognized function type for input: {type(function)}\"",
            "        )",
            "",
            "    return output, output_type, module",
            "",
            "",
            "def _parse_config_to_function(",
            "    config,",
            "    custom_objects,",
            "    func_attr_name,",
            "    func_type_attr_name,",
            "    module_attr_name,",
            "):",
            "    \"\"\"Reconstruct the function from the config.\"\"\"",
            "    globs = globals()",
            "    module = config.pop(module_attr_name, None)",
            "    if module in sys.modules:",
            "        globs.update(sys.modules[module].__dict__)",
            "    elif module is not None:",
            "        # Note: we don't know the name of the function if it's a lambda.",
            "        warnings.warn(",
            "            \"{} is not loaded, but a layer uses it. \"",
            "            \"It may cause errors.\".format(module),",
            "            UserWarning,",
            "            stacklevel=2,",
            "        )",
            "    if custom_objects:",
            "        globs.update(custom_objects)",
            "    function_type = config.pop(func_type_attr_name)",
            "    if function_type == \"function\":",
            "        # Simple lookup in custom objects",
            "        function = serialization.deserialize_keras_object(",
            "            config[func_attr_name],",
            "            custom_objects=custom_objects,",
            "            printable_module_name=\"function in wrapper\",",
            "        )",
            "    elif function_type == \"lambda\":",
            "        # Unsafe deserialization from bytecode",
            "        function = generic_utils.func_load(config[func_attr_name], globs=globs)",
            "    else:",
            "        raise TypeError(",
            "            f\"Unknown function type received: {function_type}. \"",
            "            \"Expected types are ['function', 'lambda']\"",
            "        )",
            "    return function",
            "",
            "",
            "def _default_dropout_state_filter_visitor(substate):",
            "    return not isinstance(substate, tf.TensorArray)",
            "",
            "",
            "def _enumerated_map_structure_up_to(shallow_structure, map_fn, *args, **kwargs):",
            "    ix = [0]",
            "",
            "    def enumerated_fn(*inner_args, **inner_kwargs):",
            "        r = map_fn(ix[0], *inner_args, **inner_kwargs)",
            "        ix[0] += 1",
            "        return r",
            "",
            "    return tf.__internal__.nest.map_structure_up_to(",
            "        shallow_structure, enumerated_fn, *args, **kwargs",
            "    )"
        ],
        "afterPatchFile": [
            "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Module implementing RNN wrappers.\"\"\"",
            "",
            "",
            "# Note that all the APIs under this module are exported as tf.nn.*. This is due",
            "# to the fact that those APIs were from tf.nn.rnn_cell_impl. They are ported",
            "# here to avoid the cyclic dependency issue for serialization. These APIs will",
            "# probably be deprecated and removed in future since similar API is available in",
            "# existing Keras RNN API.",
            "",
            "import hashlib",
            "import numbers",
            "import sys",
            "import types as python_types",
            "import warnings",
            "",
            "import tensorflow.compat.v2 as tf",
            "",
            "from keras.layers.rnn import lstm",
            "from keras.layers.rnn.abstract_rnn_cell import AbstractRNNCell",
            "from keras.saving import serialization_lib",
            "from keras.saving.legacy import serialization as legacy_serialization",
            "from keras.utils import generic_utils",
            "from keras.utils import tf_inspect",
            "",
            "# isort: off",
            "from tensorflow.python.util.tf_export import tf_export",
            "from tensorflow.python.util.deprecation import deprecated",
            "",
            "",
            "class _RNNCellWrapper(AbstractRNNCell):",
            "    \"\"\"Base class for cells wrappers V2 compatibility.",
            "",
            "    This class along with `rnn_cell_impl._RNNCellWrapperV1` allows to define",
            "    wrappers that are compatible with V1 and V2, and defines helper methods for",
            "    this purpose.",
            "    \"\"\"",
            "",
            "    def __init__(self, cell, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.cell = cell",
            "        cell_call_spec = tf_inspect.getfullargspec(cell.call)",
            "        self._call_spec.expects_training_arg = (",
            "            \"training\" in cell_call_spec.args",
            "        ) or (cell_call_spec.varkw is not None)",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Calls the wrapped cell and performs the wrapping logic.",
            "",
            "        This method is called from the wrapper's `call` or `__call__` methods.",
            "",
            "        Args:",
            "          inputs: A tensor with wrapped cell's input.",
            "          state: A tensor or tuple of tensors with wrapped cell's state.",
            "          cell_call_fn: Wrapped cell's method to use for step computation",
            "            (cell's `__call__` or 'call' method).",
            "          **kwargs: Additional arguments.",
            "",
            "        Returns:",
            "          A pair containing:",
            "          - Output: A tensor with cell's output.",
            "          - New state: A tensor or tuple of tensors with new wrapped cell's",
            "            state.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def call(self, inputs, state, **kwargs):",
            "        \"\"\"Runs the RNN cell step computation.",
            "",
            "        When `call` is being used, we assume that the wrapper object has been",
            "        built, and therefore the wrapped cells has been built via its `build`",
            "        method and its `call` method can be used directly.",
            "",
            "        This allows to use the wrapped cell and the non-wrapped cell",
            "        equivalently when using `call` and `build`.",
            "",
            "        Args:",
            "          inputs: A tensor with wrapped cell's input.",
            "          state: A tensor or tuple of tensors with wrapped cell's state.",
            "          **kwargs: Additional arguments passed to the wrapped cell's `call`.",
            "",
            "        Returns:",
            "          A pair containing:",
            "",
            "          - Output: A tensor with cell's output.",
            "          - New state: A tensor or tuple of tensors with new wrapped cell's",
            "            state.",
            "        \"\"\"",
            "        return self._call_wrapped_cell(",
            "            inputs, state, cell_call_fn=self.cell.call, **kwargs",
            "        )",
            "",
            "    def build(self, inputs_shape):",
            "        \"\"\"Builds the wrapped cell.\"\"\"",
            "        self.cell.build(inputs_shape)",
            "        self.built = True",
            "",
            "    @property",
            "    def wrapped_cell(self):",
            "        return self.cell",
            "",
            "    @property",
            "    def state_size(self):",
            "        return self.cell.state_size",
            "",
            "    @property",
            "    def output_size(self):",
            "        return self.cell.output_size",
            "",
            "    def zero_state(self, batch_size, dtype):",
            "        with tf.name_scope(type(self).__name__ + \"ZeroState\"):",
            "            return self.cell.zero_state(batch_size, dtype)",
            "",
            "    def get_config(self):",
            "        config = {",
            "            \"cell\": {",
            "                \"class_name\": self.cell.__class__.__name__,",
            "                \"config\": self.cell.get_config(),",
            "            },",
            "        }",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        config = config.copy()",
            "        from keras.layers.serialization import deserialize as deserialize_layer",
            "",
            "        cell = deserialize_layer(",
            "            config.pop(\"cell\"), custom_objects=custom_objects",
            "        )",
            "        return cls(cell, **config)",
            "",
            "",
            "@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")",
            "@tf_export(\"nn.RNNCellDropoutWrapper\", v1=[])",
            "class DropoutWrapper(_RNNCellWrapper):",
            "    \"\"\"Operator adding dropout to inputs and outputs of the given cell.\"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        cell,",
            "        input_keep_prob=1.0,",
            "        output_keep_prob=1.0,",
            "        state_keep_prob=1.0,",
            "        variational_recurrent=False,",
            "        input_size=None,",
            "        dtype=None,",
            "        seed=None,",
            "        dropout_state_filter_visitor=None,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"Create a cell with added input, state, and/or output dropout.",
            "",
            "        If `variational_recurrent` is set to `True` (**NOT** the default",
            "        behavior), then the same dropout mask is applied at every step, as",
            "        described in: [A Theoretically Grounded Application of Dropout in",
            "        Recurrent Neural Networks. Y. Gal, Z.",
            "        Ghahramani](https://arxiv.org/abs/1512.05287).",
            "",
            "        Otherwise a different dropout mask is applied at every time step.",
            "",
            "        Note, by default (unless a custom `dropout_state_filter` is provided),",
            "        the memory state (`c` component of any `LSTMStateTuple`) passing through",
            "        a `DropoutWrapper` is never modified.  This behavior is described in the",
            "        above article.",
            "",
            "        Args:",
            "          cell: an RNNCell, a projection to output_size is added to it.",
            "          input_keep_prob: unit Tensor or float between 0 and 1, input keep",
            "            probability; if it is constant and 1, no input dropout will be",
            "            added.",
            "          output_keep_prob: unit Tensor or float between 0 and 1, output keep",
            "            probability; if it is constant and 1, no output dropout will be",
            "            added.",
            "          state_keep_prob: unit Tensor or float between 0 and 1, output keep",
            "            probability; if it is constant and 1, no output dropout will be",
            "            added.  State dropout is performed on the outgoing states of the",
            "            cell. **Note** the state components to which dropout is applied when",
            "            `state_keep_prob` is in `(0, 1)` are also determined by the argument",
            "            `dropout_state_filter_visitor` (e.g. by default dropout is never",
            "            applied to the `c` component of an `LSTMStateTuple`).",
            "          variational_recurrent: Python bool.  If `True`, then the same dropout",
            "            pattern is applied across all time steps per run call. If this",
            "            parameter is set, `input_size` **must** be provided.",
            "          input_size: (optional) (possibly nested tuple of) `TensorShape`",
            "            objects containing the depth(s) of the input tensors expected to be",
            "            passed in to the `DropoutWrapper`.  Required and used **iff**",
            "            `variational_recurrent = True` and `input_keep_prob < 1`.",
            "          dtype: (optional) The `dtype` of the input, state, and output tensors.",
            "            Required and used **iff** `variational_recurrent = True`.",
            "          seed: (optional) integer, the randomness seed.",
            "          dropout_state_filter_visitor: (optional), default: (see below).",
            "            Function that takes any hierarchical level of the state and returns",
            "            a scalar or depth=1 structure of Python booleans describing which",
            "            terms in the state should be dropped out.  In addition, if the",
            "            function returns `True`, dropout is applied across this sublevel.",
            "            If the function returns `False`, dropout is not applied across this",
            "            entire sublevel.  Default behavior: perform dropout on all terms",
            "            except the memory (`c`) state of `LSTMCellState` objects, and don't",
            "            try to apply dropout to",
            "            `TensorArray` objects:",
            "            ```",
            "            def dropout_state_filter_visitor(s):",
            "              # Never perform dropout on the c state.",
            "              if isinstance(s, LSTMCellState):",
            "                return LSTMCellState(c=False, h=True)",
            "              elif isinstance(s, TensorArray):",
            "                return False",
            "              return True",
            "            ```",
            "          **kwargs: dict of keyword arguments for base layer.",
            "",
            "        Raises:",
            "          TypeError: if `cell` is not an `RNNCell`, or `keep_state_fn` is",
            "            provided but not `callable`.",
            "          ValueError: if any of the keep_probs are not between 0 and 1.",
            "        \"\"\"",
            "        if isinstance(cell, lstm.LSTMCell):",
            "            raise ValueError(",
            "                \"keras LSTM cell does not work with DropoutWrapper. \"",
            "                \"Please use LSTMCell(dropout=x, recurrent_dropout=y) \"",
            "                \"instead.\"",
            "            )",
            "        super().__init__(cell, dtype=dtype, **kwargs)",
            "",
            "        if dropout_state_filter_visitor is not None and not callable(",
            "            dropout_state_filter_visitor",
            "        ):",
            "            raise TypeError(",
            "                \"dropout_state_filter_visitor must be callable. \"",
            "                f\"Received: {dropout_state_filter_visitor}\"",
            "            )",
            "        self._dropout_state_filter = (",
            "            dropout_state_filter_visitor",
            "            or _default_dropout_state_filter_visitor",
            "        )",
            "        with tf.name_scope(\"DropoutWrapperInit\"):",
            "",
            "            def tensor_and_const_value(v):",
            "                tensor_value = tf.convert_to_tensor(v)",
            "                const_value = tf.get_static_value(tensor_value)",
            "                return (tensor_value, const_value)",
            "",
            "            for prob, attr in [",
            "                (input_keep_prob, \"input_keep_prob\"),",
            "                (state_keep_prob, \"state_keep_prob\"),",
            "                (output_keep_prob, \"output_keep_prob\"),",
            "            ]:",
            "                tensor_prob, const_prob = tensor_and_const_value(prob)",
            "                if const_prob is not None:",
            "                    if const_prob < 0 or const_prob > 1:",
            "                        raise ValueError(",
            "                            f\"Parameter {attr} must be between 0 and 1. \"",
            "                            f\"Received {const_prob}\"",
            "                        )",
            "                    setattr(self, f\"_{attr}\", float(const_prob))",
            "                else:",
            "                    setattr(self, f\"_{attr}\", tensor_prob)",
            "",
            "        # Set variational_recurrent, seed before running the code below",
            "        self._variational_recurrent = variational_recurrent",
            "        self._input_size = input_size",
            "        self._seed = seed",
            "",
            "        self._recurrent_input_noise = None",
            "        self._recurrent_state_noise = None",
            "        self._recurrent_output_noise = None",
            "",
            "        if variational_recurrent:",
            "            if dtype is None:",
            "                raise ValueError(",
            "                    \"When variational_recurrent=True, dtype must be provided\"",
            "                )",
            "",
            "            def convert_to_batch_shape(s):",
            "                # Prepend a 1 for the batch dimension; for recurrent",
            "                # variational dropout we use the same dropout mask for all",
            "                # batch elements.",
            "                return tf.concat(([1], tf.TensorShape(s).as_list()), 0)",
            "",
            "            def batch_noise(s, inner_seed):",
            "                shape = convert_to_batch_shape(s)",
            "                return tf.random.uniform(shape, seed=inner_seed, dtype=dtype)",
            "",
            "            if (",
            "                not isinstance(self._input_keep_prob, numbers.Real)",
            "                or self._input_keep_prob < 1.0",
            "            ):",
            "                if input_size is None:",
            "                    raise ValueError(",
            "                        \"When variational_recurrent=True and input_keep_prob < \"",
            "                        \"1.0 or is unknown, input_size must be provided\"",
            "                    )",
            "                self._recurrent_input_noise = _enumerated_map_structure_up_to(",
            "                    input_size,",
            "                    lambda i, s: batch_noise(",
            "                        s, inner_seed=self._gen_seed(\"input\", i)",
            "                    ),",
            "                    input_size,",
            "                )",
            "            self._recurrent_state_noise = _enumerated_map_structure_up_to(",
            "                cell.state_size,",
            "                lambda i, s: batch_noise(",
            "                    s, inner_seed=self._gen_seed(\"state\", i)",
            "                ),",
            "                cell.state_size,",
            "            )",
            "            self._recurrent_output_noise = _enumerated_map_structure_up_to(",
            "                cell.output_size,",
            "                lambda i, s: batch_noise(",
            "                    s, inner_seed=self._gen_seed(\"output\", i)",
            "                ),",
            "                cell.output_size,",
            "            )",
            "",
            "    def _gen_seed(self, salt_prefix, index):",
            "        if self._seed is None:",
            "            return None",
            "        salt = \"%s_%d\" % (salt_prefix, index)",
            "        string = (str(self._seed) + salt).encode(\"utf-8\")",
            "        return int(hashlib.md5(string).hexdigest()[:8], 16) & 0x7FFFFFFF",
            "",
            "    def _variational_recurrent_dropout_value(",
            "        self, unused_index, value, noise, keep_prob",
            "    ):",
            "        \"\"\"Performs dropout given the pre-calculated noise tensor.\"\"\"",
            "        # uniform [keep_prob, 1.0 + keep_prob)",
            "        random_tensor = keep_prob + noise",
            "",
            "        # 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)",
            "        binary_tensor = tf.floor(random_tensor)",
            "        ret = tf.divide(value, keep_prob) * binary_tensor",
            "        ret.set_shape(value.get_shape())",
            "        return ret",
            "",
            "    def _dropout(",
            "        self,",
            "        values,",
            "        salt_prefix,",
            "        recurrent_noise,",
            "        keep_prob,",
            "        shallow_filtered_substructure=None,",
            "    ):",
            "        \"\"\"Decides whether to perform standard dropout or recurrent dropout.\"\"\"",
            "",
            "        if shallow_filtered_substructure is None:",
            "            # Put something so we traverse the entire structure; inside the",
            "            # dropout function we check to see if leafs of this are bool or not.",
            "            shallow_filtered_substructure = values",
            "",
            "        if not self._variational_recurrent:",
            "",
            "            def dropout(i, do_dropout, v):",
            "                if not isinstance(do_dropout, bool) or do_dropout:",
            "                    return tf.nn.dropout(",
            "                        v,",
            "                        rate=1.0 - keep_prob,",
            "                        seed=self._gen_seed(salt_prefix, i),",
            "                    )",
            "                else:",
            "                    return v",
            "",
            "            return _enumerated_map_structure_up_to(",
            "                shallow_filtered_substructure,",
            "                dropout,",
            "                *[shallow_filtered_substructure, values],",
            "            )",
            "        else:",
            "",
            "            def dropout(i, do_dropout, v, n):",
            "                if not isinstance(do_dropout, bool) or do_dropout:",
            "                    return self._variational_recurrent_dropout_value(",
            "                        i, v, n, keep_prob",
            "                    )",
            "                else:",
            "                    return v",
            "",
            "            return _enumerated_map_structure_up_to(",
            "                shallow_filtered_substructure,",
            "                dropout,",
            "                *[shallow_filtered_substructure, values, recurrent_noise],",
            "            )",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Runs the wrapped cell and applies dropout.",
            "",
            "        Args:",
            "          inputs: A tensor with wrapped cell's input.",
            "          state: A tensor or tuple of tensors with wrapped cell's state.",
            "          cell_call_fn: Wrapped cell's method to use for step computation",
            "            (cell's `__call__` or 'call' method).",
            "          **kwargs: Additional arguments.",
            "",
            "        Returns:",
            "          A pair containing:",
            "",
            "          - Output: A tensor with cell's output.",
            "          - New state: A tensor or tuple of tensors with new wrapped cell's",
            "            state.",
            "        \"\"\"",
            "",
            "        def _should_dropout(p):",
            "            return (not isinstance(p, float)) or p < 1",
            "",
            "        if _should_dropout(self._input_keep_prob):",
            "            inputs = self._dropout(",
            "                inputs,",
            "                \"input\",",
            "                self._recurrent_input_noise,",
            "                self._input_keep_prob,",
            "            )",
            "        output, new_state = cell_call_fn(inputs, state, **kwargs)",
            "        if _should_dropout(self._state_keep_prob):",
            "            # Identify which subsets of the state to perform dropout on and",
            "            # which ones to keep.",
            "            shallow_filtered_substructure = (",
            "                tf.__internal__.nest.get_traverse_shallow_structure(",
            "                    self._dropout_state_filter, new_state",
            "                )",
            "            )",
            "            new_state = self._dropout(",
            "                new_state,",
            "                \"state\",",
            "                self._recurrent_state_noise,",
            "                self._state_keep_prob,",
            "                shallow_filtered_substructure,",
            "            )",
            "        if _should_dropout(self._output_keep_prob):",
            "            output = self._dropout(",
            "                output,",
            "                \"output\",",
            "                self._recurrent_output_noise,",
            "                self._output_keep_prob,",
            "            )",
            "        return output, new_state",
            "",
            "    def get_config(self):",
            "        \"\"\"Returns the config of the dropout wrapper.\"\"\"",
            "        config = {",
            "            \"input_keep_prob\": self._input_keep_prob,",
            "            \"output_keep_prob\": self._output_keep_prob,",
            "            \"state_keep_prob\": self._state_keep_prob,",
            "            \"variational_recurrent\": self._variational_recurrent,",
            "            \"input_size\": self._input_size,",
            "            \"seed\": self._seed,",
            "        }",
            "        if self._dropout_state_filter != _default_dropout_state_filter_visitor:",
            "            (",
            "                function,",
            "                function_type,",
            "                function_module,",
            "            ) = _serialize_function_to_config(self._dropout_state_filter)",
            "            config.update(",
            "                {",
            "                    \"dropout_fn\": function,",
            "                    \"dropout_fn_type\": function_type,",
            "                    \"dropout_fn_module\": function_module,",
            "                }",
            "            )",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        if \"dropout_fn\" in config:",
            "            config = config.copy()",
            "            dropout_state_filter = _parse_config_to_function(",
            "                config,",
            "                custom_objects,",
            "                \"dropout_fn\",",
            "                \"dropout_fn_type\",",
            "                \"dropout_fn_module\",",
            "            )",
            "            config.pop(\"dropout_fn\")",
            "            config[\"dropout_state_filter_visitor\"] = dropout_state_filter",
            "        return super(DropoutWrapper, cls).from_config(",
            "            config, custom_objects=custom_objects",
            "        )",
            "",
            "",
            "@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")",
            "@tf_export(\"nn.RNNCellResidualWrapper\", v1=[])",
            "class ResidualWrapper(_RNNCellWrapper):",
            "    \"\"\"RNNCell wrapper that ensures cell inputs are added to the outputs.\"\"\"",
            "",
            "    def __init__(self, cell, residual_fn=None, **kwargs):",
            "        \"\"\"Constructs a `ResidualWrapper` for `cell`.",
            "",
            "        Args:",
            "          cell: An instance of `RNNCell`.",
            "          residual_fn: (Optional) The function to map raw cell inputs and raw",
            "            cell outputs to the actual cell outputs of the residual network.",
            "            Defaults to calling nest.map_structure on (lambda i, o: i + o),",
            "            inputs and outputs.",
            "          **kwargs: dict of keyword arguments for base layer.",
            "        \"\"\"",
            "        super().__init__(cell, **kwargs)",
            "        self._residual_fn = residual_fn",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Run the cell and apply the residual_fn.",
            "",
            "        Args:",
            "          inputs: cell inputs.",
            "          state: cell state.",
            "          cell_call_fn: Wrapped cell's method to use for step computation",
            "            (cell's `__call__` or 'call' method).",
            "          **kwargs: Additional arguments passed to the wrapped cell's `call`.",
            "",
            "        Returns:",
            "          Tuple of cell outputs and new state.",
            "",
            "        Raises:",
            "          TypeError: If cell inputs and outputs have different structure (type).",
            "          ValueError: If cell inputs and outputs have different structure",
            "            (value).",
            "        \"\"\"",
            "        outputs, new_state = cell_call_fn(inputs, state, **kwargs)",
            "",
            "        # Ensure shapes match",
            "        def assert_shape_match(inp, out):",
            "            inp.get_shape().assert_is_compatible_with(out.get_shape())",
            "",
            "        def default_residual_fn(inputs, outputs):",
            "            tf.nest.assert_same_structure(inputs, outputs)",
            "            tf.nest.map_structure(assert_shape_match, inputs, outputs)",
            "            return tf.nest.map_structure(",
            "                lambda inp, out: inp + out, inputs, outputs",
            "            )",
            "",
            "        res_outputs = (self._residual_fn or default_residual_fn)(",
            "            inputs, outputs",
            "        )",
            "        return (res_outputs, new_state)",
            "",
            "    def get_config(self):",
            "        \"\"\"Returns the config of the residual wrapper.\"\"\"",
            "        if self._residual_fn is not None:",
            "            (",
            "                function,",
            "                function_type,",
            "                function_module,",
            "            ) = _serialize_function_to_config(self._residual_fn)",
            "            config = {",
            "                \"residual_fn\": function,",
            "                \"residual_fn_type\": function_type,",
            "                \"residual_fn_module\": function_module,",
            "            }",
            "        else:",
            "            config = {}",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "    @classmethod",
            "    def from_config(cls, config, custom_objects=None):",
            "        if \"residual_fn\" in config:",
            "            config = config.copy()",
            "            residual_function = _parse_config_to_function(",
            "                config,",
            "                custom_objects,",
            "                \"residual_fn\",",
            "                \"residual_fn_type\",",
            "                \"residual_fn_module\",",
            "            )",
            "            config[\"residual_fn\"] = residual_function",
            "        return super(ResidualWrapper, cls).from_config(",
            "            config, custom_objects=custom_objects",
            "        )",
            "",
            "",
            "@deprecated(None, \"Please use tf.keras.layers.RNN instead.\")",
            "@tf_export(\"nn.RNNCellDeviceWrapper\", v1=[])",
            "class DeviceWrapper(_RNNCellWrapper):",
            "    \"\"\"Operator that ensures an RNNCell runs on a particular device.\"\"\"",
            "",
            "    def __init__(self, cell, device, **kwargs):",
            "        \"\"\"Construct a `DeviceWrapper` for `cell` with device `device`.",
            "",
            "        Ensures the wrapped `cell` is called with `tf.device(device)`.",
            "",
            "        Args:",
            "          cell: An instance of `RNNCell`.",
            "          device: A device string or function, for passing to `tf.device`.",
            "          **kwargs: dict of keyword arguments for base layer.",
            "        \"\"\"",
            "        super().__init__(cell, **kwargs)",
            "        self._device = device",
            "",
            "    def zero_state(self, batch_size, dtype):",
            "        with tf.name_scope(type(self).__name__ + \"ZeroState\"):",
            "            with tf.compat.v1.device(self._device):",
            "                return self.cell.zero_state(batch_size, dtype)",
            "",
            "    def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):",
            "        \"\"\"Run the cell on specified device.\"\"\"",
            "        with tf.compat.v1.device(self._device):",
            "            return cell_call_fn(inputs, state, **kwargs)",
            "",
            "    def get_config(self):",
            "        config = {\"device\": self._device}",
            "        base_config = super().get_config()",
            "        return dict(list(base_config.items()) + list(config.items()))",
            "",
            "",
            "def _serialize_function_to_config(function):",
            "    \"\"\"Serialize the function for get_config().\"\"\"",
            "    if isinstance(function, python_types.LambdaType):",
            "        output = generic_utils.func_dump(function)",
            "        output_type = \"lambda\"",
            "        module = function.__module__",
            "    elif callable(function):",
            "        output = function.__name__",
            "        output_type = \"function\"",
            "        module = function.__module__",
            "    else:",
            "        raise ValueError(",
            "            f\"Unrecognized function type for input: {type(function)}\"",
            "        )",
            "",
            "    return output, output_type, module",
            "",
            "",
            "def _parse_config_to_function(",
            "    config,",
            "    custom_objects,",
            "    func_attr_name,",
            "    func_type_attr_name,",
            "    module_attr_name,",
            "):",
            "    \"\"\"Reconstruct the function from the config.\"\"\"",
            "    globs = globals()",
            "    module = config.pop(module_attr_name, None)",
            "    if module in sys.modules:",
            "        globs.update(sys.modules[module].__dict__)",
            "    elif module is not None:",
            "        # Note: we don't know the name of the function if it's a lambda.",
            "        warnings.warn(",
            "            \"{} is not loaded, but a layer uses it. \"",
            "            \"It may cause errors.\".format(module),",
            "            UserWarning,",
            "            stacklevel=2,",
            "        )",
            "    if custom_objects:",
            "        globs.update(custom_objects)",
            "    function_type = config.pop(func_type_attr_name)",
            "    if function_type == \"function\":",
            "        # Simple lookup in custom objects",
            "        function = legacy_serialization.deserialize_keras_object(",
            "            config[func_attr_name],",
            "            custom_objects=custom_objects,",
            "            printable_module_name=\"function in wrapper\",",
            "        )",
            "    elif function_type == \"lambda\":",
            "        if serialization_lib.in_safe_mode():",
            "            raise ValueError(",
            "                \"Requested the deserialization of a layer with a \"",
            "                \"Python `lambda` inside it. \"",
            "                \"This carries a potential risk of arbitrary code execution \"",
            "                \"and thus it is disallowed by default. If you trust the \"",
            "                \"source of the saved model, you can pass `safe_mode=False` to \"",
            "                \"the loading function in order to allow \"",
            "                \"`lambda` loading.\"",
            "            )",
            "        # Unsafe deserialization from bytecode",
            "        function = generic_utils.func_load(config[func_attr_name], globs=globs)",
            "    else:",
            "        raise TypeError(",
            "            f\"Unknown function type received: {function_type}. \"",
            "            \"Expected types are ['function', 'lambda']\"",
            "        )",
            "    return function",
            "",
            "",
            "def _default_dropout_state_filter_visitor(substate):",
            "    return not isinstance(substate, tf.TensorArray)",
            "",
            "",
            "def _enumerated_map_structure_up_to(shallow_structure, map_fn, *args, **kwargs):",
            "    ix = [0]",
            "",
            "    def enumerated_fn(*inner_args, **inner_kwargs):",
            "        r = map_fn(ix[0], *inner_args, **inner_kwargs)",
            "        ix[0] += 1",
            "        return r",
            "",
            "    return tf.__internal__.nest.map_structure_up_to(",
            "        shallow_structure, enumerated_fn, *args, **kwargs",
            "    )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "34": [],
            "661": [
                "_parse_config_to_function"
            ]
        },
        "addLocation": []
    },
    "keras/saving/saving_api.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 152,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 153,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 154,
                "PatchRowcode": " @keras_export(\"keras.models.load_model\")"
            },
            "3": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def load_model(filepath, custom_objects=None, compile=True, **kwargs):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+def load_model("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 156,
                "PatchRowcode": "+    filepath, custom_objects=None, compile=True, safe_mode=True, **kwargs"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+):"
            },
            "7": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "     \"\"\"Loads a model saved via `model.save()`."
            },
            "8": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 159,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 160,
                "PatchRowcode": "     Args:"
            },
            "10": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "             (strings) to custom classes or functions to be"
            },
            "11": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "             considered during deserialization."
            },
            "12": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "         compile: Boolean, whether to compile the model after loading."
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 166,
                "PatchRowcode": "+        safe_mode: Boolean, whether to disallow unsafe `lambda` deserialization."
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+            When `safe_mode=False`, loading an object has the potential to"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 168,
                "PatchRowcode": "+            trigger arbitrary code execution. This argument is only"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+            applicable to the Keras v3 model format. Defaults to True."
            },
            "17": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": 170,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "     SavedModel format arguments:"
            },
            "19": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 172,
                "PatchRowcode": "         options: Only applies to SavedModel format."
            },
            "20": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": 202,
                "PatchRowcode": "                 f\"with the native Keras format: {list(kwargs.keys())}\""
            },
            "21": {
                "beforePatchRowNumber": 197,
                "afterPatchRowNumber": 203,
                "PatchRowcode": "             )"
            },
            "22": {
                "beforePatchRowNumber": 198,
                "afterPatchRowNumber": 204,
                "PatchRowcode": "         return saving_lib.load_model("
            },
            "23": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            filepath, custom_objects=custom_objects, compile=compile"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 205,
                "PatchRowcode": "+            filepath,"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 206,
                "PatchRowcode": "+            custom_objects=custom_objects,"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+            compile=compile,"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 208,
                "PatchRowcode": "+            safe_mode=safe_mode,"
            },
            "28": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "         )"
            },
            "29": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 210,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": 211,
                "PatchRowcode": "     # Legacy case."
            }
        },
        "frontPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Public API surface for saving APIs.\"\"\"",
            "",
            "import os",
            "import zipfile",
            "",
            "import tensorflow.compat.v2 as tf",
            "from tensorflow.python.util.tf_export import keras_export",
            "",
            "from keras.saving import saving_lib",
            "from keras.saving.legacy import save as legacy_sm_saving_lib",
            "from keras.utils import io_utils",
            "",
            "try:",
            "    import h5py",
            "except ImportError:",
            "    h5py = None",
            "",
            "",
            "@keras_export(\"keras.models.save_model\")",
            "def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):",
            "    \"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.",
            "",
            "    See the [Serialization and Saving guide](",
            "        https://keras.io/guides/serialization_and_saving/) for details.",
            "",
            "    Args:",
            "        model: Keras model instance to be saved.",
            "        filepath: `str` or `pathlib.Path` object. Path where to save the model.",
            "        overwrite: Whether we should overwrite any existing model at the target",
            "            location, or instead ask the user via an interactive prompt.",
            "        save_format: Either `\"keras\"`, `\"tf\"`, `\"h5\"`,",
            "            indicating whether to save the model",
            "            in the native Keras format (`.keras`),",
            "            in the TensorFlow SavedModel format (referred to as \"SavedModel\"",
            "            below), or in the legacy HDF5 format (`.h5`).",
            "            Defaults to `\"tf\"` in TF 2.X, and `\"h5\"` in TF 1.X.",
            "",
            "    SavedModel format arguments:",
            "        include_optimizer: Only applied to SavedModel and legacy HDF5 formats.",
            "            If False, do not save the optimizer state. Defaults to True.",
            "        signatures: Only applies to SavedModel format. Signatures to save",
            "            with the SavedModel. See the `signatures` argument in",
            "            `tf.saved_model.save` for details.",
            "        options: Only applies to SavedModel format.",
            "            `tf.saved_model.SaveOptions` object that specifies SavedModel",
            "            saving options.",
            "        save_traces: Only applies to SavedModel format. When enabled, the",
            "            SavedModel will store the function traces for each layer. This",
            "            can be disabled, so that only the configs of each layer are stored.",
            "            Defaults to `True`. Disabling this will decrease serialization time",
            "            and reduce file size, but it requires that all custom layers/models",
            "            implement a `get_config()` method.",
            "",
            "    Example:",
            "",
            "    ```python",
            "    model = tf.keras.Sequential([",
            "        tf.keras.layers.Dense(5, input_shape=(3,)),",
            "        tf.keras.layers.Softmax()])",
            "    model.save(\"model.keras\")",
            "    loaded_model = tf.keras.models.load_model(\"model.keras\")",
            "    x = tf.random.uniform((10, 3))",
            "    assert np.allclose(model.predict(x), loaded_model.predict(x))",
            "    ```",
            "",
            "    Note that `model.save()` is an alias for `tf.keras.models.save_model()`.",
            "",
            "    The SavedModel or HDF5 file contains:",
            "",
            "    - The model's configuration (architecture)",
            "    - The model's weights",
            "    - The model's optimizer's state (if any)",
            "",
            "    Thus models can be reinstantiated in the exact same state, without any of",
            "    the code used for model definition or training.",
            "",
            "    Note that the model weights may have different scoped names after being",
            "    loaded. Scoped names include the model/layer names, such as",
            "    `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to",
            "    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.",
            "",
            "    __SavedModel serialization format__",
            "",
            "    With `save_format=\"tf\"`, the model and all trackable objects attached",
            "    to the it (e.g. layers and variables) are saved as a TensorFlow SavedModel.",
            "    The model config, weights, and optimizer are included in the SavedModel.",
            "    Additionally, for every Keras layer attached to the model, the SavedModel",
            "    stores:",
            "",
            "    * The config and metadata -- e.g. name, dtype, trainable status",
            "    * Traced call and loss functions, which are stored as TensorFlow",
            "      subgraphs.",
            "",
            "    The traced functions allow the SavedModel format to save and load custom",
            "    layers without the original class definition.",
            "",
            "    You can choose to not save the traced functions by disabling the",
            "    `save_traces` option. This will decrease the time it takes to save the model",
            "    and the amount of disk space occupied by the output SavedModel. If you",
            "    enable this option, then you _must_ provide all custom class definitions",
            "    when loading the model. See the `custom_objects` argument in",
            "    `tf.keras.models.load_model`.",
            "    \"\"\"",
            "    save_format = get_save_format(filepath, save_format)",
            "    if save_format not in (\"keras\", \"tf\", \"h5\", \"keras_v3\"):",
            "        raise ValueError(",
            "            \"Unknown `save_format` argument. Expected one of \"",
            "            \"'keras', 'tf', or 'h5'. \"",
            "            f\"Received: save_format{save_format}\"",
            "        )",
            "    if save_format == \"keras_v3\" or (",
            "        saving_lib.saving_v3_enabled() and save_format == \"keras\"",
            "    ):",
            "        # If file exists and should not be overwritten.",
            "        try:",
            "            exists = os.path.exists(filepath)",
            "        except TypeError:",
            "            exists = False",
            "        if exists and not overwrite:",
            "            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)",
            "            if not proceed:",
            "                return",
            "        if kwargs:",
            "            raise ValueError(",
            "                \"The following argument(s) are not supported \"",
            "                f\"with the native Keras format: {list(kwargs.keys())}\"",
            "            )",
            "        saving_lib.save_model(model, filepath)",
            "    else:",
            "        # Legacy case",
            "        return legacy_sm_saving_lib.save_model(",
            "            model,",
            "            filepath,",
            "            overwrite=overwrite,",
            "            save_format=save_format,",
            "            **kwargs,",
            "        )",
            "",
            "",
            "@keras_export(\"keras.models.load_model\")",
            "def load_model(filepath, custom_objects=None, compile=True, **kwargs):",
            "    \"\"\"Loads a model saved via `model.save()`.",
            "",
            "    Args:",
            "        filepath: `str` or `pathlib.Path` object, path to the saved model file.",
            "        custom_objects: Optional dictionary mapping names",
            "            (strings) to custom classes or functions to be",
            "            considered during deserialization.",
            "        compile: Boolean, whether to compile the model after loading.",
            "",
            "    SavedModel format arguments:",
            "        options: Only applies to SavedModel format.",
            "            Optional `tf.saved_model.LoadOptions` object that specifies",
            "            SavedModel loading options.",
            "",
            "    Returns:",
            "        A Keras model instance. If the original model was compiled,",
            "        and the argument `compile=True` is set, then the returned model",
            "        will be compiled. Otherwise, the model will be left uncompiled.",
            "",
            "    Example:",
            "",
            "    ```python",
            "    model = tf.keras.Sequential([",
            "        tf.keras.layers.Dense(5, input_shape=(3,)),",
            "        tf.keras.layers.Softmax()])",
            "    model.save(\"model.keras\")",
            "    loaded_model = tf.keras.models.load_model(\"model.keras\")",
            "    x = tf.random.uniform((10, 3))",
            "    assert np.allclose(model.predict(x), loaded_model.predict(x))",
            "    ```",
            "",
            "    Note that the model variables may have different name values",
            "    (`var.name` property, e.g. `\"dense_1/kernel:0\"`) after being reloaded.",
            "    It is recommended that you use layer attributes to",
            "    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.",
            "    \"\"\"",
            "    if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):",
            "        if kwargs:",
            "            raise ValueError(",
            "                \"The following argument(s) are not supported \"",
            "                f\"with the native Keras format: {list(kwargs.keys())}\"",
            "            )",
            "        return saving_lib.load_model(",
            "            filepath, custom_objects=custom_objects, compile=compile",
            "        )",
            "",
            "    # Legacy case.",
            "    return legacy_sm_saving_lib.load_model(",
            "        filepath, custom_objects=custom_objects, compile=compile, **kwargs",
            "    )",
            "",
            "",
            "def save_weights(model, filepath, overwrite=True, **kwargs):",
            "    if str(filepath).endswith(\".weights.h5\"):",
            "        # If file exists and should not be overwritten.",
            "        try:",
            "            exists = os.path.exists(filepath)",
            "        except TypeError:",
            "            exists = False",
            "        if exists and not overwrite:",
            "            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)",
            "            if not proceed:",
            "                return",
            "        saving_lib.save_weights_only(model, filepath)",
            "    else:",
            "        legacy_sm_saving_lib.save_weights(",
            "            model, filepath, overwrite=overwrite, **kwargs",
            "        )",
            "",
            "",
            "def load_weights(model, filepath, skip_mismatch=False, **kwargs):",
            "    if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):",
            "        saving_lib.load_weights_only(",
            "            model, filepath, skip_mismatch=skip_mismatch",
            "        )",
            "    elif str(filepath).endswith(\".weights.h5\"):",
            "        saving_lib.load_weights_only(",
            "            model, filepath, skip_mismatch=skip_mismatch",
            "        )",
            "    else:",
            "        return legacy_sm_saving_lib.load_weights(",
            "            model, filepath, skip_mismatch=skip_mismatch, **kwargs",
            "        )",
            "",
            "",
            "def get_save_format(filepath, save_format):",
            "    if saving_lib.saving_v3_enabled():",
            "        default_format = \"keras\"",
            "    elif tf.__internal__.tf2.enabled():",
            "        default_format = \"tf\"",
            "    else:",
            "        default_format = \"h5\"",
            "",
            "    if (h5py is not None and isinstance(filepath, h5py.File)) or str(",
            "        filepath",
            "    ).endswith((\".h5\", \".hdf5\")):",
            "        if save_format and save_format != \"h5\":",
            "            raise ValueError(",
            "                \"Provided `save_format` is inconsistent with `filepath`. \"",
            "                f\"Received: save_format='{save_format}', filepath='{filepath}'\"",
            "            )",
            "        save_format = \"h5\"",
            "",
            "    return save_format or default_format"
        ],
        "afterPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Public API surface for saving APIs.\"\"\"",
            "",
            "import os",
            "import zipfile",
            "",
            "import tensorflow.compat.v2 as tf",
            "from tensorflow.python.util.tf_export import keras_export",
            "",
            "from keras.saving import saving_lib",
            "from keras.saving.legacy import save as legacy_sm_saving_lib",
            "from keras.utils import io_utils",
            "",
            "try:",
            "    import h5py",
            "except ImportError:",
            "    h5py = None",
            "",
            "",
            "@keras_export(\"keras.models.save_model\")",
            "def save_model(model, filepath, overwrite=True, save_format=None, **kwargs):",
            "    \"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.",
            "",
            "    See the [Serialization and Saving guide](",
            "        https://keras.io/guides/serialization_and_saving/) for details.",
            "",
            "    Args:",
            "        model: Keras model instance to be saved.",
            "        filepath: `str` or `pathlib.Path` object. Path where to save the model.",
            "        overwrite: Whether we should overwrite any existing model at the target",
            "            location, or instead ask the user via an interactive prompt.",
            "        save_format: Either `\"keras\"`, `\"tf\"`, `\"h5\"`,",
            "            indicating whether to save the model",
            "            in the native Keras format (`.keras`),",
            "            in the TensorFlow SavedModel format (referred to as \"SavedModel\"",
            "            below), or in the legacy HDF5 format (`.h5`).",
            "            Defaults to `\"tf\"` in TF 2.X, and `\"h5\"` in TF 1.X.",
            "",
            "    SavedModel format arguments:",
            "        include_optimizer: Only applied to SavedModel and legacy HDF5 formats.",
            "            If False, do not save the optimizer state. Defaults to True.",
            "        signatures: Only applies to SavedModel format. Signatures to save",
            "            with the SavedModel. See the `signatures` argument in",
            "            `tf.saved_model.save` for details.",
            "        options: Only applies to SavedModel format.",
            "            `tf.saved_model.SaveOptions` object that specifies SavedModel",
            "            saving options.",
            "        save_traces: Only applies to SavedModel format. When enabled, the",
            "            SavedModel will store the function traces for each layer. This",
            "            can be disabled, so that only the configs of each layer are stored.",
            "            Defaults to `True`. Disabling this will decrease serialization time",
            "            and reduce file size, but it requires that all custom layers/models",
            "            implement a `get_config()` method.",
            "",
            "    Example:",
            "",
            "    ```python",
            "    model = tf.keras.Sequential([",
            "        tf.keras.layers.Dense(5, input_shape=(3,)),",
            "        tf.keras.layers.Softmax()])",
            "    model.save(\"model.keras\")",
            "    loaded_model = tf.keras.models.load_model(\"model.keras\")",
            "    x = tf.random.uniform((10, 3))",
            "    assert np.allclose(model.predict(x), loaded_model.predict(x))",
            "    ```",
            "",
            "    Note that `model.save()` is an alias for `tf.keras.models.save_model()`.",
            "",
            "    The SavedModel or HDF5 file contains:",
            "",
            "    - The model's configuration (architecture)",
            "    - The model's weights",
            "    - The model's optimizer's state (if any)",
            "",
            "    Thus models can be reinstantiated in the exact same state, without any of",
            "    the code used for model definition or training.",
            "",
            "    Note that the model weights may have different scoped names after being",
            "    loaded. Scoped names include the model/layer names, such as",
            "    `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to",
            "    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.",
            "",
            "    __SavedModel serialization format__",
            "",
            "    With `save_format=\"tf\"`, the model and all trackable objects attached",
            "    to the it (e.g. layers and variables) are saved as a TensorFlow SavedModel.",
            "    The model config, weights, and optimizer are included in the SavedModel.",
            "    Additionally, for every Keras layer attached to the model, the SavedModel",
            "    stores:",
            "",
            "    * The config and metadata -- e.g. name, dtype, trainable status",
            "    * Traced call and loss functions, which are stored as TensorFlow",
            "      subgraphs.",
            "",
            "    The traced functions allow the SavedModel format to save and load custom",
            "    layers without the original class definition.",
            "",
            "    You can choose to not save the traced functions by disabling the",
            "    `save_traces` option. This will decrease the time it takes to save the model",
            "    and the amount of disk space occupied by the output SavedModel. If you",
            "    enable this option, then you _must_ provide all custom class definitions",
            "    when loading the model. See the `custom_objects` argument in",
            "    `tf.keras.models.load_model`.",
            "    \"\"\"",
            "    save_format = get_save_format(filepath, save_format)",
            "    if save_format not in (\"keras\", \"tf\", \"h5\", \"keras_v3\"):",
            "        raise ValueError(",
            "            \"Unknown `save_format` argument. Expected one of \"",
            "            \"'keras', 'tf', or 'h5'. \"",
            "            f\"Received: save_format{save_format}\"",
            "        )",
            "    if save_format == \"keras_v3\" or (",
            "        saving_lib.saving_v3_enabled() and save_format == \"keras\"",
            "    ):",
            "        # If file exists and should not be overwritten.",
            "        try:",
            "            exists = os.path.exists(filepath)",
            "        except TypeError:",
            "            exists = False",
            "        if exists and not overwrite:",
            "            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)",
            "            if not proceed:",
            "                return",
            "        if kwargs:",
            "            raise ValueError(",
            "                \"The following argument(s) are not supported \"",
            "                f\"with the native Keras format: {list(kwargs.keys())}\"",
            "            )",
            "        saving_lib.save_model(model, filepath)",
            "    else:",
            "        # Legacy case",
            "        return legacy_sm_saving_lib.save_model(",
            "            model,",
            "            filepath,",
            "            overwrite=overwrite,",
            "            save_format=save_format,",
            "            **kwargs,",
            "        )",
            "",
            "",
            "@keras_export(\"keras.models.load_model\")",
            "def load_model(",
            "    filepath, custom_objects=None, compile=True, safe_mode=True, **kwargs",
            "):",
            "    \"\"\"Loads a model saved via `model.save()`.",
            "",
            "    Args:",
            "        filepath: `str` or `pathlib.Path` object, path to the saved model file.",
            "        custom_objects: Optional dictionary mapping names",
            "            (strings) to custom classes or functions to be",
            "            considered during deserialization.",
            "        compile: Boolean, whether to compile the model after loading.",
            "        safe_mode: Boolean, whether to disallow unsafe `lambda` deserialization.",
            "            When `safe_mode=False`, loading an object has the potential to",
            "            trigger arbitrary code execution. This argument is only",
            "            applicable to the Keras v3 model format. Defaults to True.",
            "",
            "    SavedModel format arguments:",
            "        options: Only applies to SavedModel format.",
            "            Optional `tf.saved_model.LoadOptions` object that specifies",
            "            SavedModel loading options.",
            "",
            "    Returns:",
            "        A Keras model instance. If the original model was compiled,",
            "        and the argument `compile=True` is set, then the returned model",
            "        will be compiled. Otherwise, the model will be left uncompiled.",
            "",
            "    Example:",
            "",
            "    ```python",
            "    model = tf.keras.Sequential([",
            "        tf.keras.layers.Dense(5, input_shape=(3,)),",
            "        tf.keras.layers.Softmax()])",
            "    model.save(\"model.keras\")",
            "    loaded_model = tf.keras.models.load_model(\"model.keras\")",
            "    x = tf.random.uniform((10, 3))",
            "    assert np.allclose(model.predict(x), loaded_model.predict(x))",
            "    ```",
            "",
            "    Note that the model variables may have different name values",
            "    (`var.name` property, e.g. `\"dense_1/kernel:0\"`) after being reloaded.",
            "    It is recommended that you use layer attributes to",
            "    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.",
            "    \"\"\"",
            "    if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):",
            "        if kwargs:",
            "            raise ValueError(",
            "                \"The following argument(s) are not supported \"",
            "                f\"with the native Keras format: {list(kwargs.keys())}\"",
            "            )",
            "        return saving_lib.load_model(",
            "            filepath,",
            "            custom_objects=custom_objects,",
            "            compile=compile,",
            "            safe_mode=safe_mode,",
            "        )",
            "",
            "    # Legacy case.",
            "    return legacy_sm_saving_lib.load_model(",
            "        filepath, custom_objects=custom_objects, compile=compile, **kwargs",
            "    )",
            "",
            "",
            "def save_weights(model, filepath, overwrite=True, **kwargs):",
            "    if str(filepath).endswith(\".weights.h5\"):",
            "        # If file exists and should not be overwritten.",
            "        try:",
            "            exists = os.path.exists(filepath)",
            "        except TypeError:",
            "            exists = False",
            "        if exists and not overwrite:",
            "            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)",
            "            if not proceed:",
            "                return",
            "        saving_lib.save_weights_only(model, filepath)",
            "    else:",
            "        legacy_sm_saving_lib.save_weights(",
            "            model, filepath, overwrite=overwrite, **kwargs",
            "        )",
            "",
            "",
            "def load_weights(model, filepath, skip_mismatch=False, **kwargs):",
            "    if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):",
            "        saving_lib.load_weights_only(",
            "            model, filepath, skip_mismatch=skip_mismatch",
            "        )",
            "    elif str(filepath).endswith(\".weights.h5\"):",
            "        saving_lib.load_weights_only(",
            "            model, filepath, skip_mismatch=skip_mismatch",
            "        )",
            "    else:",
            "        return legacy_sm_saving_lib.load_weights(",
            "            model, filepath, skip_mismatch=skip_mismatch, **kwargs",
            "        )",
            "",
            "",
            "def get_save_format(filepath, save_format):",
            "    if saving_lib.saving_v3_enabled():",
            "        default_format = \"keras\"",
            "    elif tf.__internal__.tf2.enabled():",
            "        default_format = \"tf\"",
            "    else:",
            "        default_format = \"h5\"",
            "",
            "    if (h5py is not None and isinstance(filepath, h5py.File)) or str(",
            "        filepath",
            "    ).endswith((\".h5\", \".hdf5\")):",
            "        if save_format and save_format != \"h5\":",
            "            raise ValueError(",
            "                \"Provided `save_format` is inconsistent with `filepath`. \"",
            "                f\"Received: save_format='{save_format}', filepath='{filepath}'\"",
            "            )",
            "        save_format = \"h5\"",
            "",
            "    return save_format or default_format"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "155": [
                "load_model"
            ],
            "199": [
                "load_model"
            ]
        },
        "addLocation": []
    },
    "keras/saving/saving_lib.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 206,
                "PatchRowcode": "         _SAVING_V3_ENABLED.value = saving_v3_enabled_value"
            },
            "1": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 207,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 208,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def load_model(filepath, custom_objects=None, compile=True):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):"
            },
            "5": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": 210,
                "PatchRowcode": "     \"\"\"Load a zip archive representing a Keras model.\"\"\""
            },
            "6": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": 211,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 212,
                "PatchRowcode": "     filepath = str(filepath)"
            },
            "8": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 235,
                "PatchRowcode": "                 config_dict[\"compile_config\"] = None"
            },
            "9": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "             # Construct the model from the configuration file in the archive."
            },
            "10": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "             with ObjectSharingScope():"
            },
            "11": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                model = deserialize_keras_object(config_dict, custom_objects)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 238,
                "PatchRowcode": "+                model = deserialize_keras_object("
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+                    config_dict, custom_objects, safe_mode=safe_mode"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 240,
                "PatchRowcode": "+                )"
            },
            "15": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 241,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": 242,
                "PatchRowcode": "             all_filenames = zf.namelist()"
            },
            "17": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 243,
                "PatchRowcode": "             if _VARS_FNAME + \".h5\" in all_filenames:"
            }
        },
        "frontPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Python-based idempotent model-saving functionality.\"\"\"",
            "",
            "import datetime",
            "import io",
            "import json",
            "import os",
            "import re",
            "import tempfile",
            "import threading",
            "import warnings",
            "import zipfile",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "",
            "import keras",
            "from keras import losses",
            "from keras.engine import base_layer",
            "from keras.optimizers import optimizer",
            "from keras.saving.serialization_lib import ObjectSharingScope",
            "from keras.saving.serialization_lib import deserialize_keras_object",
            "from keras.saving.serialization_lib import serialize_keras_object",
            "from keras.utils import generic_utils",
            "from keras.utils import io_utils",
            "",
            "try:",
            "    import h5py",
            "except ImportError:",
            "    h5py = None",
            "",
            "# isort: off",
            "",
            "_CONFIG_FILENAME = \"config.json\"",
            "_METADATA_FILENAME = \"metadata.json\"",
            "_VARS_FNAME = \"model.weights\"  # Will become e.g. \"model.weights.h5\"",
            "_ASSETS_DIRNAME = \"assets\"",
            "",
            "# A temporary flag to enable the new idempotent saving framework.",
            "_SAVING_V3_ENABLED = threading.local()",
            "_SAVING_V3_ENABLED.value = False",
            "",
            "ATTR_SKIPLIST = frozenset(",
            "    {",
            "        \"_callable_losses\",",
            "        \"_captured_weight_regularizer\",",
            "        \"_checkpoint_dependencies\",",
            "        \"_deferred_dependencies\",",
            "        \"_eager_losses\",",
            "        \"_inbound_nodes\",",
            "        \"_inbound_nodes_value\",",
            "        \"_output_layers\",",
            "        \"_input_layers\",",
            "        \"_keras_api_names\",",
            "        \"_keras_api_names_v1\",",
            "        \"_name_based_restores\",",
            "        \"_non_trainable_weights\",",
            "        \"_outbound_nodes\",",
            "        \"_outbound_nodes_value\",",
            "        \"_saved_model_arg_spec\",",
            "        \"_self_name_based_restores\",",
            "        \"_self_saveable_object_factories\",",
            "        \"_self_tracked_trackables\",",
            "        \"_self_unconditional_checkpoint_dependencies\",",
            "        \"_self_unconditional_deferred_dependencies\",",
            "        \"_self_unconditional_dependency_names\",",
            "        \"_tf_api_names\",",
            "        \"_tf_api_names_v1\",",
            "        \"_trainable_weights\",",
            "        \"_non_trainable_weights\",",
            "        \"_unconditional_checkpoint_dependencies\",",
            "        \"_unconditional_dependency_names\",",
            "        \"_updates\",",
            "        \"_layer_call_argspecs\",",
            "        \"inbound_nodes\",",
            "        \"submodules\",",
            "        \"weights\",",
            "        \"non_trainable_weights\",",
            "        \"trainable_weights\",",
            "        \"variables\",",
            "        \"non_trainable_variables\",",
            "        \"trainable_variables\",",
            "        \"updates\",  # Would raise a warning if visited.",
            "        \"state_updates\",  # Would raise a warning if visited.",
            "    }",
            ")",
            "",
            "",
            "def save_model(model, filepath, weights_format=\"h5\"):",
            "    \"\"\"Save a zip-archive representing a Keras model to the given filepath.",
            "",
            "    The zip-based archive contains the following structure:",
            "",
            "    - JSON-based configuration file (config.json): Records of model, layer, and",
            "        other trackables' configuration.",
            "    - NPZ-based trackable state files, found in respective directories, such as",
            "        model/states.npz, model/dense_layer/states.npz, etc.",
            "    - Metadata file.",
            "",
            "    The states of Keras trackables (layers, optimizers, loss, and metrics) are",
            "    automatically saved as long as they can be discovered through the attributes",
            "    returned by `dir(Model)`. Typically, the state includes the variables",
            "    associated with the trackable, but some specially purposed layers may",
            "    contain more such as the vocabularies stored in the hashmaps. The trackables",
            "    define how their states are saved by exposing `save_state()` and",
            "    `load_state()` APIs.",
            "",
            "    For the case of layer states, the variables will be visited as long as",
            "    they are either 1) referenced via layer attributes, or 2) referenced via a",
            "    container (list, tuple, or dict), and the container is referenced via a",
            "    layer attribute.",
            "    \"\"\"",
            "    filepath = str(filepath)",
            "    if not filepath.endswith(\".keras\"):",
            "        raise ValueError(",
            "            \"Invalid `filepath` argument: expected a `.keras` extension. \"",
            "            f\"Received: filepath={filepath}\"",
            "        )",
            "    if weights_format == \"h5\" and h5py is None:",
            "        raise ImportError(\"h5py must be installed in order to save a model.\")",
            "",
            "    if not model.built:",
            "        warnings.warn(",
            "            \"You are saving a model that has not yet been built. \"",
            "            \"It might not contain any weights yet. \"",
            "            \"Consider building the model first by calling it \"",
            "            \"on some data.\",",
            "            stacklevel=2,",
            "        )",
            "    saving_v3_enabled_value = getattr(_SAVING_V3_ENABLED, \"value\", False)",
            "    _SAVING_V3_ENABLED.value = True",
            "",
            "    with ObjectSharingScope():",
            "        serialized_model_dict = serialize_keras_object(model)",
            "    config_json = json.dumps(serialized_model_dict)",
            "    metadata_json = json.dumps(",
            "        {",
            "            \"keras_version\": keras.__version__,",
            "            \"date_saved\": datetime.datetime.now().strftime(\"%Y-%m-%d@%H:%M:%S\"),",
            "        }",
            "    )",
            "    # TODO(rameshsampath): Need a better logic for local vs remote path",
            "    if re.match(r\"^(/cns|/cfs|.*://).*$\", filepath):",
            "        # Remote path. Zip to local drive and copy to remote",
            "        is_remote_path = True",
            "        zip_filepath = os.path.join(_get_temp_dir(), \"tmp_model.keras\")",
            "    else:",
            "        is_remote_path = False",
            "        zip_filepath = filepath",
            "    try:",
            "        with zipfile.ZipFile(zip_filepath, \"w\") as zf:",
            "",
            "            with zf.open(_METADATA_FILENAME, \"w\") as f:",
            "                f.write(metadata_json.encode())",
            "            with zf.open(_CONFIG_FILENAME, \"w\") as f:",
            "                f.write(config_json.encode())",
            "",
            "            if weights_format == \"h5\":",
            "                weights_store = H5IOStore(",
            "                    _VARS_FNAME + \".h5\", archive=zf, mode=\"w\"",
            "                )",
            "            elif weights_format == \"npz\":",
            "                weights_store = NpzIOStore(",
            "                    _VARS_FNAME + \".npz\", archive=zf, mode=\"w\"",
            "                )",
            "            else:",
            "                raise ValueError(",
            "                    \"Unknown `weights_format` argument. \"",
            "                    \"Expected 'h5' or 'npz'. \"",
            "                    f\"Received: weights_format={weights_format}\"",
            "                )",
            "",
            "            asset_store = DiskIOStore(_ASSETS_DIRNAME, archive=zf, mode=\"w\")",
            "",
            "            _save_state(",
            "                model,",
            "                weights_store=weights_store,",
            "                assets_store=asset_store,",
            "                inner_path=\"\",",
            "                visited_trackables=set(),",
            "            )",
            "            weights_store.close()",
            "            asset_store.close()",
            "",
            "        if is_remote_path:",
            "            # Using tf.io.gfile context manager doesn't close zip file when",
            "            # writing to GCS. Hence writing to local and copying to filepath.",
            "            tf.io.gfile.copy(zip_filepath, filepath, overwrite=True)",
            "            os.remove(zip_filepath)",
            "    except Exception as e:",
            "        raise e",
            "    finally:",
            "        _SAVING_V3_ENABLED.value = saving_v3_enabled_value",
            "",
            "",
            "def load_model(filepath, custom_objects=None, compile=True):",
            "    \"\"\"Load a zip archive representing a Keras model.\"\"\"",
            "",
            "    filepath = str(filepath)",
            "    if not filepath.endswith(\".keras\"):",
            "        raise ValueError(",
            "            \"Invalid filename: expected a `.keras` extension. \"",
            "            f\"Received: filepath={filepath}\"",
            "        )",
            "",
            "    saving_v3_enabled_value = getattr(_SAVING_V3_ENABLED, \"value\", False)",
            "    _SAVING_V3_ENABLED.value = True",
            "",
            "    try:",
            "        with tf.io.gfile.GFile(",
            "            filepath, mode=\"r+b\"",
            "        ) as gfile_handle, zipfile.ZipFile(gfile_handle, \"r\") as zf:",
            "",
            "            with zf.open(_CONFIG_FILENAME, \"r\") as f:",
            "                config_json = f.read()",
            "",
            "            # Note: we should NOT use a custom JSON decoder. Anything that",
            "            # needs custom decoding must be handled in deserialize_keras_object.",
            "            config_dict = json.loads(config_json)",
            "            if not compile:",
            "                # Disable compilation",
            "                config_dict[\"compile_config\"] = None",
            "            # Construct the model from the configuration file in the archive.",
            "            with ObjectSharingScope():",
            "                model = deserialize_keras_object(config_dict, custom_objects)",
            "",
            "            all_filenames = zf.namelist()",
            "            if _VARS_FNAME + \".h5\" in all_filenames:",
            "                weights_store = H5IOStore(",
            "                    _VARS_FNAME + \".h5\", archive=zf, mode=\"r\"",
            "                )",
            "            elif _VARS_FNAME + \".npz\" in all_filenames:",
            "                weights_store = NpzIOStore(",
            "                    _VARS_FNAME + \".npz\", archive=zf, mode=\"r\"",
            "                )",
            "            else:",
            "                raise ValueError(",
            "                    f\"Expected a {_VARS_FNAME}.h5 or {_VARS_FNAME}.npz file.\"",
            "                )",
            "",
            "            if len(all_filenames) > 3:",
            "                asset_store = DiskIOStore(_ASSETS_DIRNAME, archive=zf, mode=\"r\")",
            "            else:",
            "                asset_store = None",
            "",
            "            _load_state(",
            "                model,",
            "                weights_store=weights_store,",
            "                assets_store=asset_store,",
            "                inner_path=\"\",",
            "                visited_trackables=set(),",
            "            )",
            "            weights_store.close()",
            "            if asset_store:",
            "                asset_store.close()",
            "",
            "    except Exception as e:",
            "        raise e",
            "    else:",
            "        return model",
            "    finally:",
            "        _SAVING_V3_ENABLED.value = saving_v3_enabled_value",
            "",
            "",
            "def save_weights_only(model, filepath):",
            "    \"\"\"Save only the weights of a model to a target filepath (.weights.h5).",
            "",
            "    Note: only supports h5 for now.",
            "    \"\"\"",
            "    # TODO: if h5 filepath is remote, create the file in a temporary directory",
            "    # then upload it",
            "    filepath = str(filepath)",
            "    if not filepath.endswith(\".weights.h5\"):",
            "        raise ValueError(",
            "            \"Invalid `filepath` argument: expected a `.weights.h5` extension. \"",
            "            f\"Received: filepath={filepath}\"",
            "        )",
            "    weights_store = H5IOStore(filepath, mode=\"w\")",
            "    _save_state(",
            "        model,",
            "        weights_store=weights_store,",
            "        assets_store=None,",
            "        inner_path=\"\",",
            "        visited_trackables=set(),",
            "    )",
            "    weights_store.close()",
            "",
            "",
            "def load_weights_only(model, filepath, skip_mismatch=False):",
            "    \"\"\"Load the weights of a model from a filepath (.keras or .weights.h5).",
            "",
            "    Note: only supports h5 for now.",
            "    \"\"\"",
            "    temp_dir = None",
            "    archive = None",
            "    filepath = str(filepath)",
            "    if filepath.endswith(\".weights.h5\"):",
            "        # TODO: download file if h5 filepath is remote",
            "        weights_store = H5IOStore(filepath, mode=\"r\")",
            "    elif filepath.endswith(\".keras\"):",
            "        archive = zipfile.ZipFile(filepath, \"r\")",
            "        weights_store = H5IOStore(",
            "            _VARS_FNAME + \".h5\", archive=archive, mode=\"r\"",
            "        )",
            "",
            "    _load_state(",
            "        model,",
            "        weights_store=weights_store,",
            "        assets_store=None,",
            "        inner_path=\"\",",
            "        skip_mismatch=skip_mismatch,",
            "        visited_trackables=set(),",
            "    )",
            "    weights_store.close()",
            "    if temp_dir and tf.io.gfile.exists(temp_dir):",
            "        tf.io.gfile.rmtree(temp_dir)",
            "    if archive:",
            "        archive.close()",
            "",
            "",
            "def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):",
            "    if not tf.io.gfile.isdir(system_path):",
            "        zipfile_to_save.write(system_path, zip_path)",
            "    else:",
            "        for file_name in tf.io.gfile.listdir(system_path):",
            "            system_file_path = tf.io.gfile.join(system_path, file_name)",
            "            zip_file_path = tf.io.gfile.join(zip_path, file_name)",
            "            _write_to_zip_recursively(",
            "                zipfile_to_save, system_file_path, zip_file_path",
            "            )",
            "",
            "",
            "def _walk_trackable(trackable):",
            "    for child_attr in dir(trackable):",
            "        if child_attr.startswith(\"__\") or child_attr in ATTR_SKIPLIST:",
            "            continue",
            "        try:",
            "            child_obj = getattr(trackable, child_attr)",
            "        except Exception:",
            "            # Avoid raising the exception when visiting the attributes.",
            "            continue",
            "        yield child_attr, child_obj",
            "",
            "",
            "def _save_state(",
            "    trackable, weights_store, assets_store, inner_path, visited_trackables",
            "):",
            "    # If the trackable has already been saved, skip it.",
            "    if id(trackable) in visited_trackables:",
            "        return",
            "",
            "    # TODO(fchollet): better name?",
            "    if hasattr(trackable, \"_save_own_variables\") and weights_store:",
            "        trackable._save_own_variables(weights_store.make(inner_path))",
            "    if hasattr(trackable, \"_save_assets\") and assets_store:",
            "        trackable._save_assets(assets_store.make(inner_path))",
            "",
            "    visited_trackables.add(id(trackable))",
            "",
            "    # Recursively save state of children trackables (layers, optimizers, etc.)",
            "    for child_attr, child_obj in _walk_trackable(trackable):",
            "        if _is_keras_trackable(child_obj):",
            "            _save_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                visited_trackables=visited_trackables,",
            "            )",
            "        elif isinstance(child_obj, (list, dict, tuple, set)):",
            "            _save_container_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "def _load_state(",
            "    trackable,",
            "    weights_store,",
            "    assets_store,",
            "    inner_path,",
            "    skip_mismatch=False,",
            "    visited_trackables=None,",
            "):",
            "    if visited_trackables and id(trackable) in visited_trackables:",
            "        return",
            "",
            "    if hasattr(trackable, \"_load_own_variables\") and weights_store:",
            "        if skip_mismatch:",
            "            try:",
            "                trackable._load_own_variables(weights_store.get(inner_path))",
            "            except Exception as e:",
            "                warnings.warn(",
            "                    f\"Could not load weights in object {trackable}. \"",
            "                    \"Skipping object. \"",
            "                    f\"Exception encountered: {e}\",",
            "                    stacklevel=2,",
            "                )",
            "        else:",
            "            trackable._load_own_variables(weights_store.get(inner_path))",
            "",
            "    if hasattr(trackable, \"_load_assets\") and assets_store:",
            "        if skip_mismatch:",
            "            try:",
            "                trackable._load_assets(assets_store.get(inner_path))",
            "            except Exception as e:",
            "                warnings.warn(",
            "                    f\"Could not load assets in object {trackable}. \"",
            "                    \"Skipping object. \"",
            "                    f\"Exception encountered: {e}\",",
            "                    stacklevel=2,",
            "                )",
            "        else:",
            "            trackable._load_assets(assets_store.get(inner_path))",
            "",
            "    if visited_trackables is not None:",
            "        visited_trackables.add(id(trackable))",
            "",
            "    # Recursively load states for Keras trackables such as layers/optimizers.",
            "    for child_attr, child_obj in _walk_trackable(trackable):",
            "        if _is_keras_trackable(child_obj):",
            "            _load_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                skip_mismatch=skip_mismatch,",
            "                visited_trackables=visited_trackables,",
            "            )",
            "        elif isinstance(child_obj, (list, dict, tuple, set)):",
            "            _load_container_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                skip_mismatch=skip_mismatch,",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "def _save_container_state(",
            "    container, weights_store, assets_store, inner_path, visited_trackables",
            "):",
            "    used_names = {}",
            "    for trackable in container:",
            "        if _is_keras_trackable(trackable):",
            "            # Do NOT address the trackable via `trackable.name`, since",
            "            # names are usually autogenerated and thus not reproducible",
            "            # (i.e. they may vary across two instances of the same model).",
            "            name = generic_utils.to_snake_case(trackable.__class__.__name__)",
            "            if name in used_names:",
            "                used_names[name] += 1",
            "                name = f\"{name}_{used_names[name]}\"",
            "            else:",
            "                used_names[name] = 0",
            "            _save_state(",
            "                trackable,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, name),",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "def _load_container_state(",
            "    container,",
            "    weights_store,",
            "    assets_store,",
            "    inner_path,",
            "    skip_mismatch,",
            "    visited_trackables,",
            "):",
            "    used_names = {}",
            "    for trackable in container:",
            "        if _is_keras_trackable(trackable):",
            "            name = generic_utils.to_snake_case(trackable.__class__.__name__)",
            "            if name in used_names:",
            "                used_names[name] += 1",
            "                name = f\"{name}_{used_names[name]}\"",
            "            else:",
            "                used_names[name] = 0",
            "            _load_state(",
            "                trackable,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, name),",
            "                skip_mismatch=skip_mismatch,",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "class DiskIOStore:",
            "    \"\"\"Asset store backed by disk storage.",
            "",
            "    If `archive` is specified, then `root_path` refers to the filename",
            "    inside the archive.",
            "",
            "    If `archive` is not specified, then `root_path` refers to the full path of",
            "    the target directory.",
            "    \"\"\"",
            "",
            "    def __init__(self, root_path, archive=None, mode=None):",
            "        self.mode = mode",
            "        self.root_path = root_path",
            "        self.archive = archive",
            "        self.tmp_dir = None",
            "        if self.archive:",
            "            self.tmp_dir = _get_temp_dir()",
            "            if self.mode == \"r\":",
            "                self.archive.extractall(path=self.tmp_dir)",
            "            self.working_dir = tf.io.gfile.join(self.tmp_dir, self.root_path)",
            "            if self.mode == \"w\":",
            "                tf.io.gfile.makedirs(self.working_dir)",
            "        else:",
            "            if mode == \"r\":",
            "                self.working_dir = root_path",
            "            else:",
            "                self.tmp_dir = _get_temp_dir()",
            "                self.working_dir = tf.io.gfile.join(",
            "                    self.tmp_dir, self.root_path",
            "                )",
            "                tf.io.gfile.makedirs(self.working_dir)",
            "",
            "    def make(self, path):",
            "        if not path:",
            "            return self.working_dir",
            "        path = tf.io.gfile.join(self.working_dir, path)",
            "        if not tf.io.gfile.exists(path):",
            "            tf.io.gfile.makedirs(path)",
            "        return path",
            "",
            "    def get(self, path):",
            "        if not path:",
            "            return self.working_dir",
            "        path = tf.io.gfile.join(self.working_dir, path)",
            "        if tf.io.gfile.exists(path):",
            "            return path",
            "        return None",
            "",
            "    def close(self):",
            "        if self.mode == \"w\" and self.archive:",
            "            _write_to_zip_recursively(",
            "                self.archive, self.working_dir, self.root_path",
            "            )",
            "        if self.tmp_dir and tf.io.gfile.exists(self.tmp_dir):",
            "            tf.io.gfile.rmtree(self.tmp_dir)",
            "",
            "",
            "class H5IOStore:",
            "    def __init__(self, root_path, archive=None, mode=\"r\"):",
            "        \"\"\"Numerical variable store backed by HDF5.",
            "",
            "        If `archive` is specified, then `root_path` refers to the filename",
            "        inside the archive.",
            "",
            "        If `archive` is not specified, then `root_path` refers to the path of",
            "        the h5 file on disk.",
            "        \"\"\"",
            "        self.root_path = root_path",
            "        self.mode = mode",
            "        self.archive = archive",
            "        self.io_file = None",
            "",
            "        if self.archive:",
            "            if self.mode == \"w\":",
            "                self.io_file = io.BytesIO()",
            "            else:",
            "                self.io_file = self.archive.open(self.root_path, \"r\")",
            "            self.h5_file = h5py.File(self.io_file, mode=self.mode)",
            "        else:",
            "            self.h5_file = h5py.File(root_path, mode=self.mode)",
            "",
            "    def make(self, path):",
            "        if not path:",
            "            return self.h5_file.create_group(\"vars\")",
            "        return self.h5_file.create_group(path).create_group(\"vars\")",
            "",
            "    def get(self, path):",
            "        if not path:",
            "            return self.h5_file[\"vars\"]",
            "        if path in self.h5_file and \"vars\" in self.h5_file[path]:",
            "            return self.h5_file[path][\"vars\"]",
            "        return {}",
            "",
            "    def close(self):",
            "        self.h5_file.close()",
            "        if self.mode == \"w\" and self.archive:",
            "            self.archive.writestr(self.root_path, self.io_file.getvalue())",
            "        if self.io_file:",
            "            self.io_file.close()",
            "",
            "",
            "class NpzIOStore:",
            "    def __init__(self, root_path, archive=None, mode=\"r\"):",
            "        \"\"\"Numerical variable store backed by NumPy.savez/load.",
            "",
            "         If `archive` is specified, then `root_path` refers to the filename",
            "        inside the archive.",
            "",
            "        If `archive` is not specified, then `root_path` refers to the path of",
            "        the npz file on disk.",
            "        \"\"\"",
            "        self.root_path = root_path",
            "        self.mode = mode",
            "        self.archive = archive",
            "        if mode == \"w\":",
            "            self.contents = {}",
            "        else:",
            "            if self.archive:",
            "                self.f = archive.open(root_path, mode=\"r\")",
            "            else:",
            "                self.f = open(root_path, mode=\"rb\")",
            "            self.contents = np.load(self.f, allow_pickle=True)",
            "",
            "    def make(self, path):",
            "        if not path:",
            "            self.contents[\"__root__\"] = {}",
            "            return self.contents[\"__root__\"]",
            "        self.contents[path] = {}",
            "        return self.contents[path]",
            "",
            "    def get(self, path):",
            "        if not path:",
            "            if \"__root__\" in self.contents:",
            "                return dict(self.contents[\"__root__\"])",
            "            return {}",
            "        if path in self.contents:",
            "            return self.contents[path].tolist()",
            "        return {}",
            "",
            "    def close(self):",
            "        if self.mode == \"w\":",
            "            if self.archive:",
            "                self.f = self.archive.open(",
            "                    self.root_path, mode=\"w\", force_zip64=True",
            "                )",
            "            else:",
            "                self.f = open(self.root_path, mode=\"wb\")",
            "            np.savez(self.f, **self.contents)",
            "        self.f.close()",
            "",
            "",
            "def _get_temp_dir():",
            "    temp_dir = tempfile.mkdtemp()",
            "    testfile = tempfile.TemporaryFile(dir=temp_dir)",
            "    testfile.close()",
            "    return temp_dir",
            "",
            "",
            "def _is_keras_trackable(obj):",
            "    from keras.metrics import base_metric  # To avoid circular import",
            "",
            "    return isinstance(",
            "        obj,",
            "        (",
            "            base_layer.Layer,",
            "            optimizer.Optimizer,",
            "            base_metric.Metric,",
            "            losses.Loss,",
            "        ),",
            "    )",
            "",
            "",
            "def saving_v3_enabled():",
            "    return getattr(_SAVING_V3_ENABLED, \"value\", False)",
            "",
            "",
            "# Some debugging utilities.",
            "",
            "",
            "def _print_h5_file(h5_file, prefix=\"\", action=None):",
            "    if not prefix:",
            "        print(f\"Keras weights file ({h5_file}) {action}:\")",
            "    if not hasattr(h5_file, \"keys\"):",
            "        return",
            "    for key in h5_file.keys():",
            "        print(f\"...{prefix}{key}\")",
            "        _print_h5_file(h5_file[key], prefix=prefix + \"...\")",
            "",
            "",
            "def _print_zip_file(zipfile, action):",
            "    # TODO(fchollet): move to debugging logs.",
            "    io_utils.print_msg(f\"Keras model archive {action}:\")",
            "    # Same as `ZipFile.printdir()` except for using Keras' printing utility.",
            "    io_utils.print_msg(",
            "        \"%-46s %19s %12s\" % (\"File Name\", \"Modified    \", \"Size\")",
            "    )",
            "    for zinfo in zipfile.filelist:",
            "        date = \"%d-%02d-%02d %02d:%02d:%02d\" % zinfo.date_time[:6]",
            "        io_utils.print_msg(",
            "            \"%-46s %s %12d\" % (zinfo.filename, date, zinfo.file_size)",
            "        )"
        ],
        "afterPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Python-based idempotent model-saving functionality.\"\"\"",
            "",
            "import datetime",
            "import io",
            "import json",
            "import os",
            "import re",
            "import tempfile",
            "import threading",
            "import warnings",
            "import zipfile",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "",
            "import keras",
            "from keras import losses",
            "from keras.engine import base_layer",
            "from keras.optimizers import optimizer",
            "from keras.saving.serialization_lib import ObjectSharingScope",
            "from keras.saving.serialization_lib import deserialize_keras_object",
            "from keras.saving.serialization_lib import serialize_keras_object",
            "from keras.utils import generic_utils",
            "from keras.utils import io_utils",
            "",
            "try:",
            "    import h5py",
            "except ImportError:",
            "    h5py = None",
            "",
            "# isort: off",
            "",
            "_CONFIG_FILENAME = \"config.json\"",
            "_METADATA_FILENAME = \"metadata.json\"",
            "_VARS_FNAME = \"model.weights\"  # Will become e.g. \"model.weights.h5\"",
            "_ASSETS_DIRNAME = \"assets\"",
            "",
            "# A temporary flag to enable the new idempotent saving framework.",
            "_SAVING_V3_ENABLED = threading.local()",
            "_SAVING_V3_ENABLED.value = False",
            "",
            "ATTR_SKIPLIST = frozenset(",
            "    {",
            "        \"_callable_losses\",",
            "        \"_captured_weight_regularizer\",",
            "        \"_checkpoint_dependencies\",",
            "        \"_deferred_dependencies\",",
            "        \"_eager_losses\",",
            "        \"_inbound_nodes\",",
            "        \"_inbound_nodes_value\",",
            "        \"_output_layers\",",
            "        \"_input_layers\",",
            "        \"_keras_api_names\",",
            "        \"_keras_api_names_v1\",",
            "        \"_name_based_restores\",",
            "        \"_non_trainable_weights\",",
            "        \"_outbound_nodes\",",
            "        \"_outbound_nodes_value\",",
            "        \"_saved_model_arg_spec\",",
            "        \"_self_name_based_restores\",",
            "        \"_self_saveable_object_factories\",",
            "        \"_self_tracked_trackables\",",
            "        \"_self_unconditional_checkpoint_dependencies\",",
            "        \"_self_unconditional_deferred_dependencies\",",
            "        \"_self_unconditional_dependency_names\",",
            "        \"_tf_api_names\",",
            "        \"_tf_api_names_v1\",",
            "        \"_trainable_weights\",",
            "        \"_non_trainable_weights\",",
            "        \"_unconditional_checkpoint_dependencies\",",
            "        \"_unconditional_dependency_names\",",
            "        \"_updates\",",
            "        \"_layer_call_argspecs\",",
            "        \"inbound_nodes\",",
            "        \"submodules\",",
            "        \"weights\",",
            "        \"non_trainable_weights\",",
            "        \"trainable_weights\",",
            "        \"variables\",",
            "        \"non_trainable_variables\",",
            "        \"trainable_variables\",",
            "        \"updates\",  # Would raise a warning if visited.",
            "        \"state_updates\",  # Would raise a warning if visited.",
            "    }",
            ")",
            "",
            "",
            "def save_model(model, filepath, weights_format=\"h5\"):",
            "    \"\"\"Save a zip-archive representing a Keras model to the given filepath.",
            "",
            "    The zip-based archive contains the following structure:",
            "",
            "    - JSON-based configuration file (config.json): Records of model, layer, and",
            "        other trackables' configuration.",
            "    - NPZ-based trackable state files, found in respective directories, such as",
            "        model/states.npz, model/dense_layer/states.npz, etc.",
            "    - Metadata file.",
            "",
            "    The states of Keras trackables (layers, optimizers, loss, and metrics) are",
            "    automatically saved as long as they can be discovered through the attributes",
            "    returned by `dir(Model)`. Typically, the state includes the variables",
            "    associated with the trackable, but some specially purposed layers may",
            "    contain more such as the vocabularies stored in the hashmaps. The trackables",
            "    define how their states are saved by exposing `save_state()` and",
            "    `load_state()` APIs.",
            "",
            "    For the case of layer states, the variables will be visited as long as",
            "    they are either 1) referenced via layer attributes, or 2) referenced via a",
            "    container (list, tuple, or dict), and the container is referenced via a",
            "    layer attribute.",
            "    \"\"\"",
            "    filepath = str(filepath)",
            "    if not filepath.endswith(\".keras\"):",
            "        raise ValueError(",
            "            \"Invalid `filepath` argument: expected a `.keras` extension. \"",
            "            f\"Received: filepath={filepath}\"",
            "        )",
            "    if weights_format == \"h5\" and h5py is None:",
            "        raise ImportError(\"h5py must be installed in order to save a model.\")",
            "",
            "    if not model.built:",
            "        warnings.warn(",
            "            \"You are saving a model that has not yet been built. \"",
            "            \"It might not contain any weights yet. \"",
            "            \"Consider building the model first by calling it \"",
            "            \"on some data.\",",
            "            stacklevel=2,",
            "        )",
            "    saving_v3_enabled_value = getattr(_SAVING_V3_ENABLED, \"value\", False)",
            "    _SAVING_V3_ENABLED.value = True",
            "",
            "    with ObjectSharingScope():",
            "        serialized_model_dict = serialize_keras_object(model)",
            "    config_json = json.dumps(serialized_model_dict)",
            "    metadata_json = json.dumps(",
            "        {",
            "            \"keras_version\": keras.__version__,",
            "            \"date_saved\": datetime.datetime.now().strftime(\"%Y-%m-%d@%H:%M:%S\"),",
            "        }",
            "    )",
            "    # TODO(rameshsampath): Need a better logic for local vs remote path",
            "    if re.match(r\"^(/cns|/cfs|.*://).*$\", filepath):",
            "        # Remote path. Zip to local drive and copy to remote",
            "        is_remote_path = True",
            "        zip_filepath = os.path.join(_get_temp_dir(), \"tmp_model.keras\")",
            "    else:",
            "        is_remote_path = False",
            "        zip_filepath = filepath",
            "    try:",
            "        with zipfile.ZipFile(zip_filepath, \"w\") as zf:",
            "",
            "            with zf.open(_METADATA_FILENAME, \"w\") as f:",
            "                f.write(metadata_json.encode())",
            "            with zf.open(_CONFIG_FILENAME, \"w\") as f:",
            "                f.write(config_json.encode())",
            "",
            "            if weights_format == \"h5\":",
            "                weights_store = H5IOStore(",
            "                    _VARS_FNAME + \".h5\", archive=zf, mode=\"w\"",
            "                )",
            "            elif weights_format == \"npz\":",
            "                weights_store = NpzIOStore(",
            "                    _VARS_FNAME + \".npz\", archive=zf, mode=\"w\"",
            "                )",
            "            else:",
            "                raise ValueError(",
            "                    \"Unknown `weights_format` argument. \"",
            "                    \"Expected 'h5' or 'npz'. \"",
            "                    f\"Received: weights_format={weights_format}\"",
            "                )",
            "",
            "            asset_store = DiskIOStore(_ASSETS_DIRNAME, archive=zf, mode=\"w\")",
            "",
            "            _save_state(",
            "                model,",
            "                weights_store=weights_store,",
            "                assets_store=asset_store,",
            "                inner_path=\"\",",
            "                visited_trackables=set(),",
            "            )",
            "            weights_store.close()",
            "            asset_store.close()",
            "",
            "        if is_remote_path:",
            "            # Using tf.io.gfile context manager doesn't close zip file when",
            "            # writing to GCS. Hence writing to local and copying to filepath.",
            "            tf.io.gfile.copy(zip_filepath, filepath, overwrite=True)",
            "            os.remove(zip_filepath)",
            "    except Exception as e:",
            "        raise e",
            "    finally:",
            "        _SAVING_V3_ENABLED.value = saving_v3_enabled_value",
            "",
            "",
            "def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):",
            "    \"\"\"Load a zip archive representing a Keras model.\"\"\"",
            "",
            "    filepath = str(filepath)",
            "    if not filepath.endswith(\".keras\"):",
            "        raise ValueError(",
            "            \"Invalid filename: expected a `.keras` extension. \"",
            "            f\"Received: filepath={filepath}\"",
            "        )",
            "",
            "    saving_v3_enabled_value = getattr(_SAVING_V3_ENABLED, \"value\", False)",
            "    _SAVING_V3_ENABLED.value = True",
            "",
            "    try:",
            "        with tf.io.gfile.GFile(",
            "            filepath, mode=\"r+b\"",
            "        ) as gfile_handle, zipfile.ZipFile(gfile_handle, \"r\") as zf:",
            "",
            "            with zf.open(_CONFIG_FILENAME, \"r\") as f:",
            "                config_json = f.read()",
            "",
            "            # Note: we should NOT use a custom JSON decoder. Anything that",
            "            # needs custom decoding must be handled in deserialize_keras_object.",
            "            config_dict = json.loads(config_json)",
            "            if not compile:",
            "                # Disable compilation",
            "                config_dict[\"compile_config\"] = None",
            "            # Construct the model from the configuration file in the archive.",
            "            with ObjectSharingScope():",
            "                model = deserialize_keras_object(",
            "                    config_dict, custom_objects, safe_mode=safe_mode",
            "                )",
            "",
            "            all_filenames = zf.namelist()",
            "            if _VARS_FNAME + \".h5\" in all_filenames:",
            "                weights_store = H5IOStore(",
            "                    _VARS_FNAME + \".h5\", archive=zf, mode=\"r\"",
            "                )",
            "            elif _VARS_FNAME + \".npz\" in all_filenames:",
            "                weights_store = NpzIOStore(",
            "                    _VARS_FNAME + \".npz\", archive=zf, mode=\"r\"",
            "                )",
            "            else:",
            "                raise ValueError(",
            "                    f\"Expected a {_VARS_FNAME}.h5 or {_VARS_FNAME}.npz file.\"",
            "                )",
            "",
            "            if len(all_filenames) > 3:",
            "                asset_store = DiskIOStore(_ASSETS_DIRNAME, archive=zf, mode=\"r\")",
            "            else:",
            "                asset_store = None",
            "",
            "            _load_state(",
            "                model,",
            "                weights_store=weights_store,",
            "                assets_store=asset_store,",
            "                inner_path=\"\",",
            "                visited_trackables=set(),",
            "            )",
            "            weights_store.close()",
            "            if asset_store:",
            "                asset_store.close()",
            "",
            "    except Exception as e:",
            "        raise e",
            "    else:",
            "        return model",
            "    finally:",
            "        _SAVING_V3_ENABLED.value = saving_v3_enabled_value",
            "",
            "",
            "def save_weights_only(model, filepath):",
            "    \"\"\"Save only the weights of a model to a target filepath (.weights.h5).",
            "",
            "    Note: only supports h5 for now.",
            "    \"\"\"",
            "    # TODO: if h5 filepath is remote, create the file in a temporary directory",
            "    # then upload it",
            "    filepath = str(filepath)",
            "    if not filepath.endswith(\".weights.h5\"):",
            "        raise ValueError(",
            "            \"Invalid `filepath` argument: expected a `.weights.h5` extension. \"",
            "            f\"Received: filepath={filepath}\"",
            "        )",
            "    weights_store = H5IOStore(filepath, mode=\"w\")",
            "    _save_state(",
            "        model,",
            "        weights_store=weights_store,",
            "        assets_store=None,",
            "        inner_path=\"\",",
            "        visited_trackables=set(),",
            "    )",
            "    weights_store.close()",
            "",
            "",
            "def load_weights_only(model, filepath, skip_mismatch=False):",
            "    \"\"\"Load the weights of a model from a filepath (.keras or .weights.h5).",
            "",
            "    Note: only supports h5 for now.",
            "    \"\"\"",
            "    temp_dir = None",
            "    archive = None",
            "    filepath = str(filepath)",
            "    if filepath.endswith(\".weights.h5\"):",
            "        # TODO: download file if h5 filepath is remote",
            "        weights_store = H5IOStore(filepath, mode=\"r\")",
            "    elif filepath.endswith(\".keras\"):",
            "        archive = zipfile.ZipFile(filepath, \"r\")",
            "        weights_store = H5IOStore(",
            "            _VARS_FNAME + \".h5\", archive=archive, mode=\"r\"",
            "        )",
            "",
            "    _load_state(",
            "        model,",
            "        weights_store=weights_store,",
            "        assets_store=None,",
            "        inner_path=\"\",",
            "        skip_mismatch=skip_mismatch,",
            "        visited_trackables=set(),",
            "    )",
            "    weights_store.close()",
            "    if temp_dir and tf.io.gfile.exists(temp_dir):",
            "        tf.io.gfile.rmtree(temp_dir)",
            "    if archive:",
            "        archive.close()",
            "",
            "",
            "def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):",
            "    if not tf.io.gfile.isdir(system_path):",
            "        zipfile_to_save.write(system_path, zip_path)",
            "    else:",
            "        for file_name in tf.io.gfile.listdir(system_path):",
            "            system_file_path = tf.io.gfile.join(system_path, file_name)",
            "            zip_file_path = tf.io.gfile.join(zip_path, file_name)",
            "            _write_to_zip_recursively(",
            "                zipfile_to_save, system_file_path, zip_file_path",
            "            )",
            "",
            "",
            "def _walk_trackable(trackable):",
            "    for child_attr in dir(trackable):",
            "        if child_attr.startswith(\"__\") or child_attr in ATTR_SKIPLIST:",
            "            continue",
            "        try:",
            "            child_obj = getattr(trackable, child_attr)",
            "        except Exception:",
            "            # Avoid raising the exception when visiting the attributes.",
            "            continue",
            "        yield child_attr, child_obj",
            "",
            "",
            "def _save_state(",
            "    trackable, weights_store, assets_store, inner_path, visited_trackables",
            "):",
            "    # If the trackable has already been saved, skip it.",
            "    if id(trackable) in visited_trackables:",
            "        return",
            "",
            "    # TODO(fchollet): better name?",
            "    if hasattr(trackable, \"_save_own_variables\") and weights_store:",
            "        trackable._save_own_variables(weights_store.make(inner_path))",
            "    if hasattr(trackable, \"_save_assets\") and assets_store:",
            "        trackable._save_assets(assets_store.make(inner_path))",
            "",
            "    visited_trackables.add(id(trackable))",
            "",
            "    # Recursively save state of children trackables (layers, optimizers, etc.)",
            "    for child_attr, child_obj in _walk_trackable(trackable):",
            "        if _is_keras_trackable(child_obj):",
            "            _save_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                visited_trackables=visited_trackables,",
            "            )",
            "        elif isinstance(child_obj, (list, dict, tuple, set)):",
            "            _save_container_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "def _load_state(",
            "    trackable,",
            "    weights_store,",
            "    assets_store,",
            "    inner_path,",
            "    skip_mismatch=False,",
            "    visited_trackables=None,",
            "):",
            "    if visited_trackables and id(trackable) in visited_trackables:",
            "        return",
            "",
            "    if hasattr(trackable, \"_load_own_variables\") and weights_store:",
            "        if skip_mismatch:",
            "            try:",
            "                trackable._load_own_variables(weights_store.get(inner_path))",
            "            except Exception as e:",
            "                warnings.warn(",
            "                    f\"Could not load weights in object {trackable}. \"",
            "                    \"Skipping object. \"",
            "                    f\"Exception encountered: {e}\",",
            "                    stacklevel=2,",
            "                )",
            "        else:",
            "            trackable._load_own_variables(weights_store.get(inner_path))",
            "",
            "    if hasattr(trackable, \"_load_assets\") and assets_store:",
            "        if skip_mismatch:",
            "            try:",
            "                trackable._load_assets(assets_store.get(inner_path))",
            "            except Exception as e:",
            "                warnings.warn(",
            "                    f\"Could not load assets in object {trackable}. \"",
            "                    \"Skipping object. \"",
            "                    f\"Exception encountered: {e}\",",
            "                    stacklevel=2,",
            "                )",
            "        else:",
            "            trackable._load_assets(assets_store.get(inner_path))",
            "",
            "    if visited_trackables is not None:",
            "        visited_trackables.add(id(trackable))",
            "",
            "    # Recursively load states for Keras trackables such as layers/optimizers.",
            "    for child_attr, child_obj in _walk_trackable(trackable):",
            "        if _is_keras_trackable(child_obj):",
            "            _load_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                skip_mismatch=skip_mismatch,",
            "                visited_trackables=visited_trackables,",
            "            )",
            "        elif isinstance(child_obj, (list, dict, tuple, set)):",
            "            _load_container_state(",
            "                child_obj,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, child_attr),",
            "                skip_mismatch=skip_mismatch,",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "def _save_container_state(",
            "    container, weights_store, assets_store, inner_path, visited_trackables",
            "):",
            "    used_names = {}",
            "    for trackable in container:",
            "        if _is_keras_trackable(trackable):",
            "            # Do NOT address the trackable via `trackable.name`, since",
            "            # names are usually autogenerated and thus not reproducible",
            "            # (i.e. they may vary across two instances of the same model).",
            "            name = generic_utils.to_snake_case(trackable.__class__.__name__)",
            "            if name in used_names:",
            "                used_names[name] += 1",
            "                name = f\"{name}_{used_names[name]}\"",
            "            else:",
            "                used_names[name] = 0",
            "            _save_state(",
            "                trackable,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, name),",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "def _load_container_state(",
            "    container,",
            "    weights_store,",
            "    assets_store,",
            "    inner_path,",
            "    skip_mismatch,",
            "    visited_trackables,",
            "):",
            "    used_names = {}",
            "    for trackable in container:",
            "        if _is_keras_trackable(trackable):",
            "            name = generic_utils.to_snake_case(trackable.__class__.__name__)",
            "            if name in used_names:",
            "                used_names[name] += 1",
            "                name = f\"{name}_{used_names[name]}\"",
            "            else:",
            "                used_names[name] = 0",
            "            _load_state(",
            "                trackable,",
            "                weights_store,",
            "                assets_store,",
            "                inner_path=tf.io.gfile.join(inner_path, name),",
            "                skip_mismatch=skip_mismatch,",
            "                visited_trackables=visited_trackables,",
            "            )",
            "",
            "",
            "class DiskIOStore:",
            "    \"\"\"Asset store backed by disk storage.",
            "",
            "    If `archive` is specified, then `root_path` refers to the filename",
            "    inside the archive.",
            "",
            "    If `archive` is not specified, then `root_path` refers to the full path of",
            "    the target directory.",
            "    \"\"\"",
            "",
            "    def __init__(self, root_path, archive=None, mode=None):",
            "        self.mode = mode",
            "        self.root_path = root_path",
            "        self.archive = archive",
            "        self.tmp_dir = None",
            "        if self.archive:",
            "            self.tmp_dir = _get_temp_dir()",
            "            if self.mode == \"r\":",
            "                self.archive.extractall(path=self.tmp_dir)",
            "            self.working_dir = tf.io.gfile.join(self.tmp_dir, self.root_path)",
            "            if self.mode == \"w\":",
            "                tf.io.gfile.makedirs(self.working_dir)",
            "        else:",
            "            if mode == \"r\":",
            "                self.working_dir = root_path",
            "            else:",
            "                self.tmp_dir = _get_temp_dir()",
            "                self.working_dir = tf.io.gfile.join(",
            "                    self.tmp_dir, self.root_path",
            "                )",
            "                tf.io.gfile.makedirs(self.working_dir)",
            "",
            "    def make(self, path):",
            "        if not path:",
            "            return self.working_dir",
            "        path = tf.io.gfile.join(self.working_dir, path)",
            "        if not tf.io.gfile.exists(path):",
            "            tf.io.gfile.makedirs(path)",
            "        return path",
            "",
            "    def get(self, path):",
            "        if not path:",
            "            return self.working_dir",
            "        path = tf.io.gfile.join(self.working_dir, path)",
            "        if tf.io.gfile.exists(path):",
            "            return path",
            "        return None",
            "",
            "    def close(self):",
            "        if self.mode == \"w\" and self.archive:",
            "            _write_to_zip_recursively(",
            "                self.archive, self.working_dir, self.root_path",
            "            )",
            "        if self.tmp_dir and tf.io.gfile.exists(self.tmp_dir):",
            "            tf.io.gfile.rmtree(self.tmp_dir)",
            "",
            "",
            "class H5IOStore:",
            "    def __init__(self, root_path, archive=None, mode=\"r\"):",
            "        \"\"\"Numerical variable store backed by HDF5.",
            "",
            "        If `archive` is specified, then `root_path` refers to the filename",
            "        inside the archive.",
            "",
            "        If `archive` is not specified, then `root_path` refers to the path of",
            "        the h5 file on disk.",
            "        \"\"\"",
            "        self.root_path = root_path",
            "        self.mode = mode",
            "        self.archive = archive",
            "        self.io_file = None",
            "",
            "        if self.archive:",
            "            if self.mode == \"w\":",
            "                self.io_file = io.BytesIO()",
            "            else:",
            "                self.io_file = self.archive.open(self.root_path, \"r\")",
            "            self.h5_file = h5py.File(self.io_file, mode=self.mode)",
            "        else:",
            "            self.h5_file = h5py.File(root_path, mode=self.mode)",
            "",
            "    def make(self, path):",
            "        if not path:",
            "            return self.h5_file.create_group(\"vars\")",
            "        return self.h5_file.create_group(path).create_group(\"vars\")",
            "",
            "    def get(self, path):",
            "        if not path:",
            "            return self.h5_file[\"vars\"]",
            "        if path in self.h5_file and \"vars\" in self.h5_file[path]:",
            "            return self.h5_file[path][\"vars\"]",
            "        return {}",
            "",
            "    def close(self):",
            "        self.h5_file.close()",
            "        if self.mode == \"w\" and self.archive:",
            "            self.archive.writestr(self.root_path, self.io_file.getvalue())",
            "        if self.io_file:",
            "            self.io_file.close()",
            "",
            "",
            "class NpzIOStore:",
            "    def __init__(self, root_path, archive=None, mode=\"r\"):",
            "        \"\"\"Numerical variable store backed by NumPy.savez/load.",
            "",
            "         If `archive` is specified, then `root_path` refers to the filename",
            "        inside the archive.",
            "",
            "        If `archive` is not specified, then `root_path` refers to the path of",
            "        the npz file on disk.",
            "        \"\"\"",
            "        self.root_path = root_path",
            "        self.mode = mode",
            "        self.archive = archive",
            "        if mode == \"w\":",
            "            self.contents = {}",
            "        else:",
            "            if self.archive:",
            "                self.f = archive.open(root_path, mode=\"r\")",
            "            else:",
            "                self.f = open(root_path, mode=\"rb\")",
            "            self.contents = np.load(self.f, allow_pickle=True)",
            "",
            "    def make(self, path):",
            "        if not path:",
            "            self.contents[\"__root__\"] = {}",
            "            return self.contents[\"__root__\"]",
            "        self.contents[path] = {}",
            "        return self.contents[path]",
            "",
            "    def get(self, path):",
            "        if not path:",
            "            if \"__root__\" in self.contents:",
            "                return dict(self.contents[\"__root__\"])",
            "            return {}",
            "        if path in self.contents:",
            "            return self.contents[path].tolist()",
            "        return {}",
            "",
            "    def close(self):",
            "        if self.mode == \"w\":",
            "            if self.archive:",
            "                self.f = self.archive.open(",
            "                    self.root_path, mode=\"w\", force_zip64=True",
            "                )",
            "            else:",
            "                self.f = open(self.root_path, mode=\"wb\")",
            "            np.savez(self.f, **self.contents)",
            "        self.f.close()",
            "",
            "",
            "def _get_temp_dir():",
            "    temp_dir = tempfile.mkdtemp()",
            "    testfile = tempfile.TemporaryFile(dir=temp_dir)",
            "    testfile.close()",
            "    return temp_dir",
            "",
            "",
            "def _is_keras_trackable(obj):",
            "    from keras.metrics import base_metric  # To avoid circular import",
            "",
            "    return isinstance(",
            "        obj,",
            "        (",
            "            base_layer.Layer,",
            "            optimizer.Optimizer,",
            "            base_metric.Metric,",
            "            losses.Loss,",
            "        ),",
            "    )",
            "",
            "",
            "def saving_v3_enabled():",
            "    return getattr(_SAVING_V3_ENABLED, \"value\", False)",
            "",
            "",
            "# Some debugging utilities.",
            "",
            "",
            "def _print_h5_file(h5_file, prefix=\"\", action=None):",
            "    if not prefix:",
            "        print(f\"Keras weights file ({h5_file}) {action}:\")",
            "    if not hasattr(h5_file, \"keys\"):",
            "        return",
            "    for key in h5_file.keys():",
            "        print(f\"...{prefix}{key}\")",
            "        _print_h5_file(h5_file[key], prefix=prefix + \"...\")",
            "",
            "",
            "def _print_zip_file(zipfile, action):",
            "    # TODO(fchollet): move to debugging logs.",
            "    io_utils.print_msg(f\"Keras model archive {action}:\")",
            "    # Same as `ZipFile.printdir()` except for using Keras' printing utility.",
            "    io_utils.print_msg(",
            "        \"%-46s %19s %12s\" % (\"File Name\", \"Modified    \", \"Size\")",
            "    )",
            "    for zinfo in zipfile.filelist:",
            "        date = \"%d-%02d-%02d %02d:%02d:%02d\" % zinfo.date_time[:6]",
            "        io_utils.print_msg(",
            "            \"%-46s %s %12d\" % (zinfo.filename, date, zinfo.file_size)",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "209": [
                "load_model"
            ],
            "238": [
                "load_model"
            ]
        },
        "addLocation": []
    },
    "keras/saving/saving_lib_test.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 406,
                "afterPatchRowNumber": 406,
                "PatchRowcode": "         y = np.random.random((1000, 1))"
            },
            "1": {
                "beforePatchRowNumber": 407,
                "afterPatchRowNumber": 407,
                "PatchRowcode": "         functional_model.fit(x, y, epochs=3)"
            },
            "2": {
                "beforePatchRowNumber": 408,
                "afterPatchRowNumber": 408,
                "PatchRowcode": "         functional_model._save_experimental(temp_filepath)"
            },
            "3": {
                "beforePatchRowNumber": 409,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        loaded_model = saving_lib.load_model(temp_filepath)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 409,
                "PatchRowcode": "+        loaded_model = saving_lib.load_model(temp_filepath, safe_mode=False)"
            },
            "5": {
                "beforePatchRowNumber": 410,
                "afterPatchRowNumber": 410,
                "PatchRowcode": "         self.assertEqual("
            },
            "6": {
                "beforePatchRowNumber": 411,
                "afterPatchRowNumber": 411,
                "PatchRowcode": "             functional_model._is_compiled, loaded_model._is_compiled"
            },
            "7": {
                "beforePatchRowNumber": 412,
                "afterPatchRowNumber": 412,
                "PatchRowcode": "         )"
            },
            "8": {
                "beforePatchRowNumber": 689,
                "afterPatchRowNumber": 689,
                "PatchRowcode": "                 temp_filepath, include_optimizer=False, save_format=\"keras_v3\""
            },
            "9": {
                "beforePatchRowNumber": 690,
                "afterPatchRowNumber": 690,
                "PatchRowcode": "             )"
            },
            "10": {
                "beforePatchRowNumber": 691,
                "afterPatchRowNumber": 691,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 692,
                "PatchRowcode": "+    def test_safe_mode(self):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 693,
                "PatchRowcode": "+        temp_filepath = os.path.join(self.get_temp_dir(), \"unsafe_model.keras\")"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 694,
                "PatchRowcode": "+        model = keras.Sequential("
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 695,
                "PatchRowcode": "+            ["
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 696,
                "PatchRowcode": "+                keras.Input(shape=(3,)),"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 697,
                "PatchRowcode": "+                keras.layers.Lambda(lambda x: x * 2),"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 698,
                "PatchRowcode": "+            ]"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 699,
                "PatchRowcode": "+        )"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 700,
                "PatchRowcode": "+        model.save(temp_filepath, save_format=\"keras_v3\")"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 701,
                "PatchRowcode": "+        with self.assertRaisesRegex(ValueError, \"arbitrary code execution\"):"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 702,
                "PatchRowcode": "+            model = saving_lib.load_model(temp_filepath)"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 703,
                "PatchRowcode": "+        model = saving_lib.load_model(temp_filepath, safe_mode=False)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 704,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": 692,
                "afterPatchRowNumber": 705,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 693,
                "afterPatchRowNumber": 706,
                "PatchRowcode": " if __name__ == \"__main__\":"
            },
            "26": {
                "beforePatchRowNumber": 694,
                "afterPatchRowNumber": 707,
                "PatchRowcode": "     tf.test.main()"
            }
        },
        "frontPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Tests for Keras python-based idempotent saving functions (experimental).\"\"\"",
            "import os",
            "import sys",
            "import zipfile",
            "from pathlib import Path",
            "from unittest import mock",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "from absl.testing import parameterized",
            "from tensorflow.python.platform import tf_logging as logging",
            "",
            "import keras",
            "from keras import backend",
            "from keras.optimizers import adam",
            "from keras.saving import object_registration",
            "from keras.saving import saving_lib",
            "from keras.saving.legacy.saved_model import json_utils",
            "from keras.testing_infra import test_utils",
            "from keras.utils import io_utils",
            "",
            "train_step_message = \"This is my training step\"",
            "assets_data = \"These are my assets\"",
            "variables_data = np.random.random((10,))",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class MyDense(keras.layers.Dense):",
            "    def build(self, input_shape):",
            "        self.additional_weights = [",
            "            self.add_weight(",
            "                \"my_additional_weight\",",
            "                initializer=\"ones\",",
            "                trainable=True,",
            "            ),",
            "            self.add_weight(",
            "                \"my_additional_weight_2\",",
            "                initializer=\"ones\",",
            "                trainable=True,",
            "            ),",
            "        ]",
            "        self.weights_in_dict = {",
            "            \"my_weight\": self.add_weight(",
            "                \"my_dict_weight\",",
            "                initializer=\"ones\",",
            "                trainable=True,",
            "            ),",
            "        }",
            "        self.nested_layer = keras.layers.Dense(1)",
            "        return super().build(input_shape)",
            "",
            "    def call(self, inputs):",
            "        call_result = super().call(inputs)",
            "        return self.nested_layer(call_result)",
            "",
            "    def two(self):",
            "        return 2",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class LayerWithCustomSaving(MyDense):",
            "    def build(self, input_shape):",
            "        self.assets = assets_data",
            "        self.stored_variables = variables_data",
            "        return super().build(input_shape)",
            "",
            "    def _save_assets(self, inner_path):",
            "        with open(os.path.join(inner_path, \"assets.txt\"), \"w\") as f:",
            "            f.write(self.assets)",
            "",
            "    def _save_own_variables(self, store):",
            "        store[\"variables\"] = self.stored_variables",
            "",
            "    def _load_assets(self, inner_path):",
            "        with open(os.path.join(inner_path, \"assets.txt\"), \"r\") as f:",
            "            text = f.read()",
            "        self.assets = text",
            "",
            "    def _load_own_variables(self, store):",
            "        self.stored_variables = np.array(store[\"variables\"])",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class CustomModelX(keras.Model):",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.dense1 = MyDense(1)",
            "        self.dense2 = MyDense(1)",
            "",
            "    def call(self, inputs):",
            "        out = self.dense1(inputs)",
            "        return self.dense2(out)",
            "",
            "    def train_step(self, data):",
            "        tf.print(train_step_message)",
            "        x, y = data",
            "        with tf.GradientTape() as tape:",
            "            y_pred = self(x)",
            "            loss = self.compiled_loss(y, y_pred)",
            "",
            "        gradients = tape.gradient(loss, self.trainable_variables)",
            "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))",
            "        return {}",
            "",
            "    def one(self):",
            "        return 1",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class ModelWithCustomSaving(keras.Model):",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.custom_dense = LayerWithCustomSaving(1)",
            "",
            "    def call(self, inputs):",
            "        return self.custom_dense(inputs)",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class CompileOverridingModel(keras.Model):",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.dense1 = MyDense(1)",
            "",
            "    def compile(self, *args, **kwargs):",
            "        super().compile(*args, **kwargs)",
            "",
            "    def call(self, inputs):",
            "        return self.dense1(inputs)",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class CompileOverridingSequential(keras.Sequential):",
            "    def compile(self, *args, **kwargs):",
            "        super().compile(*args, **kwargs)",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "def my_mean_squared_error(y_true, y_pred):",
            "    \"\"\"Identical to built-in `mean_squared_error`, added here as a custom",
            "",
            "    func.",
            "    \"\"\"",
            "    return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)",
            "",
            "",
            "module_my_mean_squared_error = my_mean_squared_error",
            "",
            "",
            "@test_utils.run_v2_only",
            "class SavingV3Test(tf.test.TestCase, parameterized.TestCase):",
            "    def _get_subclassed_model(self):",
            "        subclassed_model = CustomModelX()",
            "        subclassed_model.compile(",
            "            optimizer=adam.Adam(),",
            "            loss=[",
            "                \"mse\",",
            "                keras.losses.mean_squared_error,",
            "                keras.losses.MeanSquaredError(),",
            "                my_mean_squared_error,",
            "            ],",
            "        )",
            "        return subclassed_model",
            "",
            "    def _get_sequential_model(self):",
            "        sequential_model = keras.Sequential([MyDense(1), MyDense(1)])",
            "        sequential_model.compile(",
            "            optimizer=\"adam\", loss=[\"mse\", keras.losses.mean_squared_error]",
            "        )",
            "        return sequential_model",
            "",
            "    def _get_functional_model(self):",
            "        inputs = keras.Input(shape=(32,))",
            "        x = MyDense(1, name=\"first_dense\")(inputs)",
            "        outputs = MyDense(1, name=\"second_dense\")(x)",
            "        functional_model = keras.Model(inputs, outputs)",
            "        functional_model.compile(",
            "            optimizer=\"adam\", loss=[\"mse\", keras.losses.mean_squared_error]",
            "        )",
            "        return functional_model",
            "",
            "    def test_saving_after_compile_but_before_fit(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = self._get_subclassed_model()",
            "        subclassed_model._save_experimental(temp_filepath)",
            "",
            "        # This is so that we can register another function with the same custom",
            "        # object key, and make sure the newly registered function is used while",
            "        # loading.",
            "        del object_registration._GLOBAL_CUSTOM_OBJECTS[",
            "            \"my_custom_package>my_mean_squared_error\"",
            "        ]",
            "",
            "        @keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "        def my_mean_squared_error(y_true, y_pred):",
            "            \"\"\"Function-local `mean_squared_error`.\"\"\"",
            "            return backend.mean(",
            "                tf.math.squared_difference(y_pred, y_true), axis=-1",
            "            )",
            "",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(",
            "            subclassed_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "",
            "        # Everything should be the same class or function for the original model",
            "        # and the loaded model.",
            "        for model in [subclassed_model, loaded_model]:",
            "            self.assertIs(",
            "                model.optimizer.__class__,",
            "                adam.Adam,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss.__class__,",
            "                keras.engine.compile_utils.LossesContainer,",
            "            )",
            "            self.assertEqual(model.compiled_loss._losses[0], \"mse\")",
            "            self.assertIs(",
            "                model.compiled_loss._losses[1], keras.losses.mean_squared_error",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[2].__class__,",
            "                keras.losses.MeanSquaredError,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._total_loss_mean.__class__,",
            "                keras.metrics.base_metric.Mean,",
            "            )",
            "",
            "        # Except for a custom function used because the loaded model is supposed",
            "        # to be using the newly registered custom function.",
            "        self.assertIs(",
            "            subclassed_model.compiled_loss._losses[3],",
            "            module_my_mean_squared_error,",
            "        )",
            "        self.assertIs(",
            "            loaded_model.compiled_loss._losses[3], my_mean_squared_error",
            "        )",
            "        self.assertIsNot(module_my_mean_squared_error, my_mean_squared_error)",
            "",
            "    def test_saving_after_fit(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = self._get_subclassed_model()",
            "",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        subclassed_model.fit(x, y, epochs=1)",
            "        subclassed_model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(",
            "            subclassed_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "",
            "        io_utils.enable_interactive_logging()",
            "        # `tf.print` writes to stderr. This is to make sure the custom training",
            "        # step is used.",
            "        with self.captureWritesToStream(sys.stderr) as printed:",
            "            loaded_model.fit(x, y, epochs=1)",
            "            self.assertRegex(printed.contents(), train_step_message)",
            "",
            "        # Check that the custom classes do get used.",
            "        self.assertIsInstance(loaded_model, CustomModelX)",
            "        self.assertIsInstance(loaded_model.dense1, MyDense)",
            "        # Check that the custom method is available.",
            "        self.assertEqual(loaded_model.one(), 1)",
            "        self.assertEqual(loaded_model.dense1.two(), 2)",
            "",
            "        # Everything should be the same class or function for the original model",
            "        # and the loaded model.",
            "        for model in [subclassed_model, loaded_model]:",
            "            self.assertIs(",
            "                model.optimizer.__class__,",
            "                adam.Adam,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss.__class__,",
            "                keras.engine.compile_utils.LossesContainer,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[0].__class__,",
            "                keras.losses.LossFunctionWrapper,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[1].__class__,",
            "                keras.losses.LossFunctionWrapper,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[2].__class__,",
            "                keras.losses.MeanSquaredError,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[3].__class__,",
            "                keras.losses.LossFunctionWrapper,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._total_loss_mean.__class__,",
            "                keras.metrics.base_metric.Mean,",
            "            )",
            "",
            "    def test_saving_preserve_unbuilt_state(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = CustomModelX()",
            "        subclassed_model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(",
            "            subclassed_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "        self.assertFalse(subclassed_model.built)",
            "        self.assertFalse(loaded_model.built)",
            "",
            "    def test_saving_preserve_built_state(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = self._get_subclassed_model()",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        model.fit(x, y, epochs=1)",
            "        model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(model._is_compiled, loaded_model._is_compiled)",
            "        self.assertTrue(model.built)",
            "        self.assertTrue(loaded_model.built)",
            "        self.assertEqual(",
            "            model._build_input_shape, loaded_model._build_input_shape",
            "        )",
            "        self.assertEqual(",
            "            tf.TensorShape([None, 32]), loaded_model._build_input_shape",
            "        )",
            "",
            "    def test_saved_module_paths_and_class_names(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = self._get_subclassed_model()",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        subclassed_model.fit(x, y, epochs=1)",
            "        subclassed_model._save_experimental(temp_filepath)",
            "",
            "        with zipfile.ZipFile(temp_filepath, \"r\") as z:",
            "            with z.open(saving_lib._CONFIG_FILENAME, \"r\") as c:",
            "                config_json = c.read()",
            "        config_dict = json_utils.decode(config_json)",
            "        self.assertEqual(",
            "            config_dict[\"registered_name\"], \"my_custom_package>CustomModelX\"",
            "        )",
            "        self.assertEqual(",
            "            config_dict[\"compile_config\"][\"optimizer\"][\"config\"][",
            "                \"is_legacy_optimizer\"",
            "            ],",
            "            False,",
            "        )",
            "        self.assertEqual(",
            "            config_dict[\"compile_config\"][\"optimizer\"][\"class_name\"],",
            "            \"Adam\",",
            "        )",
            "        self.assertLen(config_dict[\"compile_config\"][\"loss\"], 4)",
            "        self.assertEqual(",
            "            config_dict[\"compile_config\"][\"loss\"][0],",
            "            \"mse\",",
            "        )",
            "",
            "    @tf.__internal__.distribute.combinations.generate(",
            "        tf.__internal__.test.combinations.combine(",
            "            layer=[\"tf_op_lambda\", \"lambda\"],",
            "        )",
            "    )",
            "    def test_functional_model_with_tf_op_lambda_layer(self, layer):",
            "        class ToString:",
            "            def __init__(self):",
            "                self.contents = \"\"",
            "",
            "            def __call__(self, msg):",
            "                self.contents += msg + \"\\n\"",
            "",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "",
            "        if layer == \"lambda\":",
            "            func = tf.function(lambda x: tf.math.cos(x) + tf.math.sin(x))",
            "            inputs = keras.layers.Input(shape=(32,))",
            "            outputs = keras.layers.Dense(1)(inputs)",
            "            outputs = keras.layers.Lambda(func._python_function)(outputs)",
            "",
            "        elif layer == \"tf_op_lambda\":",
            "            inputs = keras.layers.Input(shape=(32,))",
            "            outputs = keras.layers.Dense(1)(inputs)",
            "            outputs = outputs + inputs",
            "",
            "        functional_model = keras.Model(inputs, outputs)",
            "        functional_to_string = ToString()",
            "        functional_model.summary(print_fn=functional_to_string)",
            "        functional_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])",
            "",
            "        x = np.random.random((1000, 32))",
            "        y = np.random.random((1000, 1))",
            "        functional_model.fit(x, y, epochs=3)",
            "        functional_model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(",
            "            functional_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "",
            "        loaded_model.fit(x, y, epochs=3)",
            "        loaded_to_string = ToString()",
            "        loaded_model.summary(print_fn=loaded_to_string)",
            "",
            "        # Confirming the original and saved/loaded model have same structure.",
            "        self.assertEqual(",
            "            functional_to_string.contents, loaded_to_string.contents",
            "        )",
            "",
            "    @tf.__internal__.distribute.combinations.generate(",
            "        tf.__internal__.test.combinations.combine(",
            "            model_type=[\"sequential\", \"functional\", \"subclassed\"],",
            "        )",
            "    )",
            "    def test_saving_model_state(self, model_type):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = getattr(self, f\"_get_{model_type}_model\")()",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        model.fit(x, y, epochs=1)",
            "",
            "        # Assert that the archive has not been saved.",
            "        self.assertFalse(os.path.exists(temp_filepath))",
            "",
            "        # Mutate the `Dense` layer custom weights to ensure that list and",
            "        # dict-contained weights get restored.",
            "        model.layers[1].additional_weights[0].assign(2)",
            "        model.layers[1].weights_in_dict[\"my_weight\"].assign(2)",
            "        model.layers[1].nested_layer.kernel.assign([[1]])",
            "",
            "        model._save_experimental(temp_filepath)",
            "",
            "        # Assert that the archive has been saved.",
            "        self.assertTrue(os.path.exists(temp_filepath))",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(model._is_compiled, loaded_model._is_compiled)",
            "",
            "        # The weights are supposed to be the same (between original and loaded",
            "        # models).",
            "        for original_weights, loaded_weights in zip(",
            "            model.get_weights(), loaded_model.get_weights()",
            "        ):",
            "            np.testing.assert_allclose(original_weights, loaded_weights)",
            "",
            "        # The optimizer variables are supposed to be the same (between original",
            "        # and loaded models).",
            "        for original_weights, loaded_weights in zip(",
            "            model.optimizer.variables, loaded_model.optimizer.variables",
            "        ):",
            "            np.testing.assert_allclose(original_weights, loaded_weights)",
            "",
            "    def test_saving_custom_assets_and_variables(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = ModelWithCustomSaving()",
            "        model.compile(",
            "            optimizer=adam.Adam(),",
            "            loss=[",
            "                \"mse\",",
            "                keras.losses.mean_squared_error,",
            "                keras.losses.MeanSquaredError(),",
            "                my_mean_squared_error,",
            "            ],",
            "        )",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        model.fit(x, y, epochs=1)",
            "",
            "        # Assert that the archive has not been saved.",
            "        self.assertFalse(os.path.exists(temp_filepath))",
            "",
            "        model._save_experimental(temp_filepath)",
            "",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(loaded_model.custom_dense.assets, assets_data)",
            "        self.assertEqual(",
            "            loaded_model.custom_dense.stored_variables.tolist(),",
            "            variables_data.tolist(),",
            "        )",
            "",
            "    @tf.__internal__.distribute.combinations.generate(",
            "        tf.__internal__.test.combinations.combine(",
            "            model_type=[\"subclassed\", \"sequential\"],",
            "        )",
            "    )",
            "    def test_compile_overridden_model_raises_if_no_from_config_overridden(",
            "        self, model_type",
            "    ):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = (",
            "            CompileOverridingModel()",
            "            if model_type == \"subclassed\"",
            "            else CompileOverridingSequential(",
            "                [keras.layers.Embedding(4, 1), MyDense(1), MyDense(1)]",
            "            )",
            "        )",
            "        model.compile(\"rmsprop\", \"mse\")",
            "        model._save_experimental(temp_filepath)",
            "",
            "        with mock.patch.object(logging, \"warning\") as mock_warn:",
            "            saving_lib.load_model(temp_filepath)",
            "        if not mock_warn.call_args_list:",
            "            raise AssertionError(\"Did not warn.\")",
            "        self.assertIn(",
            "            \"`compile()` was not called as part of model loading \"",
            "            \"because the model's `compile()` method is custom. \",",
            "            mock_warn.call_args_list[0][0][0],",
            "        )",
            "",
            "    def test_metadata(self):",
            "        temp_filepath = Path(",
            "            os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        )",
            "        model = CompileOverridingModel()",
            "        model._save_experimental(temp_filepath)",
            "        with zipfile.ZipFile(temp_filepath, \"r\") as z:",
            "            with z.open(saving_lib._METADATA_FILENAME, \"r\") as c:",
            "                metadata_json = c.read()",
            "        metadata = json_utils.decode(metadata_json)",
            "        self.assertIn(\"keras_version\", metadata)",
            "        self.assertIn(\"date_saved\", metadata)",
            "",
            "    def test_gfile_copy_local_called(self):",
            "        temp_filepath = Path(",
            "            os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        )",
            "        model = CompileOverridingModel()",
            "        with mock.patch(\"re.match\", autospec=True) as mock_re_match, mock.patch(",
            "            \"tensorflow.compat.v2.io.gfile.copy\", autospec=True",
            "        ) as mock_copy:",
            "            # Mock Remote Path check to true to test gfile copy logic",
            "            mock_re_match.return_value = True",
            "            model._save_experimental(temp_filepath)",
            "            mock_re_match.assert_called_once()",
            "            mock_copy.assert_called_once()",
            "            self.assertIn(str(temp_filepath), mock_re_match.call_args.args)",
            "            self.assertIn(str(temp_filepath), mock_copy.call_args.args)",
            "",
            "    def test_load_model_api_endpoint(self):",
            "        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"mymodel.keras\"))",
            "        model = self._get_functional_model()",
            "        ref_input = np.random.random((10, 32))",
            "        ref_output = model.predict(ref_input)",
            "        model.save(temp_filepath, save_format=\"keras_v3\")",
            "        model = keras.models.load_model(temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "",
            "    def test_save_load_weights_only(self):",
            "        temp_filepath = Path(",
            "            os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")",
            "        )",
            "        model = self._get_functional_model()",
            "        ref_input = np.random.random((10, 32))",
            "        ref_output = model.predict(ref_input)",
            "        saving_lib.save_weights_only(model, temp_filepath)",
            "        model = self._get_functional_model()",
            "        saving_lib.load_weights_only(model, temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "        # Test with Model method",
            "        model = self._get_functional_model()",
            "        model.load_weights(temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "",
            "    def test_load_weights_only_with_keras_file(self):",
            "        # Test loading weights from whole saved model",
            "        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"mymodel.keras\"))",
            "        model = self._get_functional_model()",
            "        ref_input = np.random.random((10, 32))",
            "        ref_output = model.predict(ref_input)",
            "        saving_lib.save_model(model, temp_filepath)",
            "        model = self._get_functional_model()",
            "        saving_lib.load_weights_only(model, temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "        # Test with Model method",
            "        model = self._get_functional_model()",
            "        model.load_weights(temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "",
            "    def test_compile_arg(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        model = self._get_functional_model()",
            "        model.compile(\"rmsprop\", \"mse\")",
            "        model.fit(np.random.random((10, 32)), np.random.random((10, 1)))",
            "        saving_lib.save_model(model, temp_filepath)",
            "",
            "        model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(model._is_compiled, True)",
            "        model = saving_lib.load_model(temp_filepath, compile=False)",
            "        self.assertEqual(model._is_compiled, False)",
            "",
            "    def test_overwrite(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        model = self._get_functional_model()",
            "        model.save(temp_filepath, save_format=\"keras_v3\")",
            "        model.save(temp_filepath, save_format=\"keras_v3\", overwrite=True)",
            "        with self.assertRaises(EOFError):",
            "            model.save(temp_filepath, save_format=\"keras_v3\", overwrite=False)",
            "",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")",
            "        model = self._get_functional_model()",
            "        model.save_weights(temp_filepath)",
            "        model.save_weights(temp_filepath, overwrite=True)",
            "        with self.assertRaises(EOFError):",
            "            model.save_weights(temp_filepath, overwrite=False)",
            "",
            "    def test_partial_load(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        original_model = keras.Sequential(",
            "            [",
            "                keras.Input(shape=(3,)),",
            "                keras.layers.Dense(4),",
            "                keras.layers.Dense(5),",
            "            ]",
            "        )",
            "        original_model.save(temp_filepath, save_format=\"keras_v3\")",
            "",
            "        # Test with a model that has a differently shaped layer",
            "        new_model = keras.Sequential(",
            "            [",
            "                keras.Input(shape=(3,)),",
            "                keras.layers.Dense(4),",
            "                keras.layers.Dense(6),",
            "            ]",
            "        )",
            "        new_layer_kernel_value = new_model.layers[1].kernel.numpy()",
            "        with self.assertRaisesRegex(ValueError, \"Shape mismatch\"):",
            "            # Doesn't work by default",
            "            new_model.load_weights(temp_filepath)",
            "        # Now it works",
            "        new_model.load_weights(temp_filepath, skip_mismatch=True)",
            "        self.assertAllClose(",
            "            original_model.layers[0].get_weights(),",
            "            new_model.layers[0].get_weights(),",
            "        )",
            "        self.assertAllClose(",
            "            new_model.layers[1].kernel.numpy(), new_layer_kernel_value",
            "        )",
            "",
            "        # Test with a model that has a new layer",
            "        new_model = keras.Sequential(",
            "            [",
            "                keras.Input(shape=(3,)),",
            "                keras.layers.Dense(4),",
            "                keras.layers.Dense(5),",
            "                keras.layers.Dense(5),",
            "            ]",
            "        )",
            "        new_layer_kernel_value = new_model.layers[2].kernel.numpy()",
            "        with self.assertRaisesRegex(ValueError, \"received 0 variables\"):",
            "            # Doesn't work by default",
            "            new_model.load_weights(temp_filepath)",
            "        # Now it works",
            "        new_model.load_weights(temp_filepath, skip_mismatch=True)",
            "        self.assertAllClose(",
            "            original_model.layers[0].get_weights(),",
            "            new_model.layers[0].get_weights(),",
            "        )",
            "        self.assertAllClose(",
            "            original_model.layers[1].get_weights(),",
            "            new_model.layers[1].get_weights(),",
            "        )",
            "        self.assertAllClose(",
            "            new_model.layers[2].kernel.numpy(), new_layer_kernel_value",
            "        )",
            "",
            "    def test_api_errors(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.notkeras\")",
            "        model = self._get_functional_model()",
            "        with self.assertRaisesRegex(ValueError, \"Unknown `save_format`\"):",
            "            model.save(temp_filepath, save_format=\"invalid\")",
            "        with self.assertRaisesRegex(ValueError, \"Invalid `filepath` argument\"):",
            "            model.save(temp_filepath, save_format=\"keras_v3\")",
            "",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        with self.assertRaisesRegex(ValueError, \"not supported\"):",
            "            model.save(",
            "                temp_filepath, include_optimizer=False, save_format=\"keras_v3\"",
            "            )",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    tf.test.main()"
        ],
        "afterPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Tests for Keras python-based idempotent saving functions (experimental).\"\"\"",
            "import os",
            "import sys",
            "import zipfile",
            "from pathlib import Path",
            "from unittest import mock",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "from absl.testing import parameterized",
            "from tensorflow.python.platform import tf_logging as logging",
            "",
            "import keras",
            "from keras import backend",
            "from keras.optimizers import adam",
            "from keras.saving import object_registration",
            "from keras.saving import saving_lib",
            "from keras.saving.legacy.saved_model import json_utils",
            "from keras.testing_infra import test_utils",
            "from keras.utils import io_utils",
            "",
            "train_step_message = \"This is my training step\"",
            "assets_data = \"These are my assets\"",
            "variables_data = np.random.random((10,))",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class MyDense(keras.layers.Dense):",
            "    def build(self, input_shape):",
            "        self.additional_weights = [",
            "            self.add_weight(",
            "                \"my_additional_weight\",",
            "                initializer=\"ones\",",
            "                trainable=True,",
            "            ),",
            "            self.add_weight(",
            "                \"my_additional_weight_2\",",
            "                initializer=\"ones\",",
            "                trainable=True,",
            "            ),",
            "        ]",
            "        self.weights_in_dict = {",
            "            \"my_weight\": self.add_weight(",
            "                \"my_dict_weight\",",
            "                initializer=\"ones\",",
            "                trainable=True,",
            "            ),",
            "        }",
            "        self.nested_layer = keras.layers.Dense(1)",
            "        return super().build(input_shape)",
            "",
            "    def call(self, inputs):",
            "        call_result = super().call(inputs)",
            "        return self.nested_layer(call_result)",
            "",
            "    def two(self):",
            "        return 2",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class LayerWithCustomSaving(MyDense):",
            "    def build(self, input_shape):",
            "        self.assets = assets_data",
            "        self.stored_variables = variables_data",
            "        return super().build(input_shape)",
            "",
            "    def _save_assets(self, inner_path):",
            "        with open(os.path.join(inner_path, \"assets.txt\"), \"w\") as f:",
            "            f.write(self.assets)",
            "",
            "    def _save_own_variables(self, store):",
            "        store[\"variables\"] = self.stored_variables",
            "",
            "    def _load_assets(self, inner_path):",
            "        with open(os.path.join(inner_path, \"assets.txt\"), \"r\") as f:",
            "            text = f.read()",
            "        self.assets = text",
            "",
            "    def _load_own_variables(self, store):",
            "        self.stored_variables = np.array(store[\"variables\"])",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class CustomModelX(keras.Model):",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.dense1 = MyDense(1)",
            "        self.dense2 = MyDense(1)",
            "",
            "    def call(self, inputs):",
            "        out = self.dense1(inputs)",
            "        return self.dense2(out)",
            "",
            "    def train_step(self, data):",
            "        tf.print(train_step_message)",
            "        x, y = data",
            "        with tf.GradientTape() as tape:",
            "            y_pred = self(x)",
            "            loss = self.compiled_loss(y, y_pred)",
            "",
            "        gradients = tape.gradient(loss, self.trainable_variables)",
            "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))",
            "        return {}",
            "",
            "    def one(self):",
            "        return 1",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class ModelWithCustomSaving(keras.Model):",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.custom_dense = LayerWithCustomSaving(1)",
            "",
            "    def call(self, inputs):",
            "        return self.custom_dense(inputs)",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class CompileOverridingModel(keras.Model):",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        self.dense1 = MyDense(1)",
            "",
            "    def compile(self, *args, **kwargs):",
            "        super().compile(*args, **kwargs)",
            "",
            "    def call(self, inputs):",
            "        return self.dense1(inputs)",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "class CompileOverridingSequential(keras.Sequential):",
            "    def compile(self, *args, **kwargs):",
            "        super().compile(*args, **kwargs)",
            "",
            "",
            "@keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "def my_mean_squared_error(y_true, y_pred):",
            "    \"\"\"Identical to built-in `mean_squared_error`, added here as a custom",
            "",
            "    func.",
            "    \"\"\"",
            "    return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)",
            "",
            "",
            "module_my_mean_squared_error = my_mean_squared_error",
            "",
            "",
            "@test_utils.run_v2_only",
            "class SavingV3Test(tf.test.TestCase, parameterized.TestCase):",
            "    def _get_subclassed_model(self):",
            "        subclassed_model = CustomModelX()",
            "        subclassed_model.compile(",
            "            optimizer=adam.Adam(),",
            "            loss=[",
            "                \"mse\",",
            "                keras.losses.mean_squared_error,",
            "                keras.losses.MeanSquaredError(),",
            "                my_mean_squared_error,",
            "            ],",
            "        )",
            "        return subclassed_model",
            "",
            "    def _get_sequential_model(self):",
            "        sequential_model = keras.Sequential([MyDense(1), MyDense(1)])",
            "        sequential_model.compile(",
            "            optimizer=\"adam\", loss=[\"mse\", keras.losses.mean_squared_error]",
            "        )",
            "        return sequential_model",
            "",
            "    def _get_functional_model(self):",
            "        inputs = keras.Input(shape=(32,))",
            "        x = MyDense(1, name=\"first_dense\")(inputs)",
            "        outputs = MyDense(1, name=\"second_dense\")(x)",
            "        functional_model = keras.Model(inputs, outputs)",
            "        functional_model.compile(",
            "            optimizer=\"adam\", loss=[\"mse\", keras.losses.mean_squared_error]",
            "        )",
            "        return functional_model",
            "",
            "    def test_saving_after_compile_but_before_fit(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = self._get_subclassed_model()",
            "        subclassed_model._save_experimental(temp_filepath)",
            "",
            "        # This is so that we can register another function with the same custom",
            "        # object key, and make sure the newly registered function is used while",
            "        # loading.",
            "        del object_registration._GLOBAL_CUSTOM_OBJECTS[",
            "            \"my_custom_package>my_mean_squared_error\"",
            "        ]",
            "",
            "        @keras.utils.register_keras_serializable(package=\"my_custom_package\")",
            "        def my_mean_squared_error(y_true, y_pred):",
            "            \"\"\"Function-local `mean_squared_error`.\"\"\"",
            "            return backend.mean(",
            "                tf.math.squared_difference(y_pred, y_true), axis=-1",
            "            )",
            "",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(",
            "            subclassed_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "",
            "        # Everything should be the same class or function for the original model",
            "        # and the loaded model.",
            "        for model in [subclassed_model, loaded_model]:",
            "            self.assertIs(",
            "                model.optimizer.__class__,",
            "                adam.Adam,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss.__class__,",
            "                keras.engine.compile_utils.LossesContainer,",
            "            )",
            "            self.assertEqual(model.compiled_loss._losses[0], \"mse\")",
            "            self.assertIs(",
            "                model.compiled_loss._losses[1], keras.losses.mean_squared_error",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[2].__class__,",
            "                keras.losses.MeanSquaredError,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._total_loss_mean.__class__,",
            "                keras.metrics.base_metric.Mean,",
            "            )",
            "",
            "        # Except for a custom function used because the loaded model is supposed",
            "        # to be using the newly registered custom function.",
            "        self.assertIs(",
            "            subclassed_model.compiled_loss._losses[3],",
            "            module_my_mean_squared_error,",
            "        )",
            "        self.assertIs(",
            "            loaded_model.compiled_loss._losses[3], my_mean_squared_error",
            "        )",
            "        self.assertIsNot(module_my_mean_squared_error, my_mean_squared_error)",
            "",
            "    def test_saving_after_fit(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = self._get_subclassed_model()",
            "",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        subclassed_model.fit(x, y, epochs=1)",
            "        subclassed_model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(",
            "            subclassed_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "",
            "        io_utils.enable_interactive_logging()",
            "        # `tf.print` writes to stderr. This is to make sure the custom training",
            "        # step is used.",
            "        with self.captureWritesToStream(sys.stderr) as printed:",
            "            loaded_model.fit(x, y, epochs=1)",
            "            self.assertRegex(printed.contents(), train_step_message)",
            "",
            "        # Check that the custom classes do get used.",
            "        self.assertIsInstance(loaded_model, CustomModelX)",
            "        self.assertIsInstance(loaded_model.dense1, MyDense)",
            "        # Check that the custom method is available.",
            "        self.assertEqual(loaded_model.one(), 1)",
            "        self.assertEqual(loaded_model.dense1.two(), 2)",
            "",
            "        # Everything should be the same class or function for the original model",
            "        # and the loaded model.",
            "        for model in [subclassed_model, loaded_model]:",
            "            self.assertIs(",
            "                model.optimizer.__class__,",
            "                adam.Adam,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss.__class__,",
            "                keras.engine.compile_utils.LossesContainer,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[0].__class__,",
            "                keras.losses.LossFunctionWrapper,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[1].__class__,",
            "                keras.losses.LossFunctionWrapper,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[2].__class__,",
            "                keras.losses.MeanSquaredError,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._losses[3].__class__,",
            "                keras.losses.LossFunctionWrapper,",
            "            )",
            "            self.assertIs(",
            "                model.compiled_loss._total_loss_mean.__class__,",
            "                keras.metrics.base_metric.Mean,",
            "            )",
            "",
            "    def test_saving_preserve_unbuilt_state(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = CustomModelX()",
            "        subclassed_model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(",
            "            subclassed_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "        self.assertFalse(subclassed_model.built)",
            "        self.assertFalse(loaded_model.built)",
            "",
            "    def test_saving_preserve_built_state(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = self._get_subclassed_model()",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        model.fit(x, y, epochs=1)",
            "        model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(model._is_compiled, loaded_model._is_compiled)",
            "        self.assertTrue(model.built)",
            "        self.assertTrue(loaded_model.built)",
            "        self.assertEqual(",
            "            model._build_input_shape, loaded_model._build_input_shape",
            "        )",
            "        self.assertEqual(",
            "            tf.TensorShape([None, 32]), loaded_model._build_input_shape",
            "        )",
            "",
            "    def test_saved_module_paths_and_class_names(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        subclassed_model = self._get_subclassed_model()",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        subclassed_model.fit(x, y, epochs=1)",
            "        subclassed_model._save_experimental(temp_filepath)",
            "",
            "        with zipfile.ZipFile(temp_filepath, \"r\") as z:",
            "            with z.open(saving_lib._CONFIG_FILENAME, \"r\") as c:",
            "                config_json = c.read()",
            "        config_dict = json_utils.decode(config_json)",
            "        self.assertEqual(",
            "            config_dict[\"registered_name\"], \"my_custom_package>CustomModelX\"",
            "        )",
            "        self.assertEqual(",
            "            config_dict[\"compile_config\"][\"optimizer\"][\"config\"][",
            "                \"is_legacy_optimizer\"",
            "            ],",
            "            False,",
            "        )",
            "        self.assertEqual(",
            "            config_dict[\"compile_config\"][\"optimizer\"][\"class_name\"],",
            "            \"Adam\",",
            "        )",
            "        self.assertLen(config_dict[\"compile_config\"][\"loss\"], 4)",
            "        self.assertEqual(",
            "            config_dict[\"compile_config\"][\"loss\"][0],",
            "            \"mse\",",
            "        )",
            "",
            "    @tf.__internal__.distribute.combinations.generate(",
            "        tf.__internal__.test.combinations.combine(",
            "            layer=[\"tf_op_lambda\", \"lambda\"],",
            "        )",
            "    )",
            "    def test_functional_model_with_tf_op_lambda_layer(self, layer):",
            "        class ToString:",
            "            def __init__(self):",
            "                self.contents = \"\"",
            "",
            "            def __call__(self, msg):",
            "                self.contents += msg + \"\\n\"",
            "",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "",
            "        if layer == \"lambda\":",
            "            func = tf.function(lambda x: tf.math.cos(x) + tf.math.sin(x))",
            "            inputs = keras.layers.Input(shape=(32,))",
            "            outputs = keras.layers.Dense(1)(inputs)",
            "            outputs = keras.layers.Lambda(func._python_function)(outputs)",
            "",
            "        elif layer == \"tf_op_lambda\":",
            "            inputs = keras.layers.Input(shape=(32,))",
            "            outputs = keras.layers.Dense(1)(inputs)",
            "            outputs = outputs + inputs",
            "",
            "        functional_model = keras.Model(inputs, outputs)",
            "        functional_to_string = ToString()",
            "        functional_model.summary(print_fn=functional_to_string)",
            "        functional_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])",
            "",
            "        x = np.random.random((1000, 32))",
            "        y = np.random.random((1000, 1))",
            "        functional_model.fit(x, y, epochs=3)",
            "        functional_model._save_experimental(temp_filepath)",
            "        loaded_model = saving_lib.load_model(temp_filepath, safe_mode=False)",
            "        self.assertEqual(",
            "            functional_model._is_compiled, loaded_model._is_compiled",
            "        )",
            "",
            "        loaded_model.fit(x, y, epochs=3)",
            "        loaded_to_string = ToString()",
            "        loaded_model.summary(print_fn=loaded_to_string)",
            "",
            "        # Confirming the original and saved/loaded model have same structure.",
            "        self.assertEqual(",
            "            functional_to_string.contents, loaded_to_string.contents",
            "        )",
            "",
            "    @tf.__internal__.distribute.combinations.generate(",
            "        tf.__internal__.test.combinations.combine(",
            "            model_type=[\"sequential\", \"functional\", \"subclassed\"],",
            "        )",
            "    )",
            "    def test_saving_model_state(self, model_type):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = getattr(self, f\"_get_{model_type}_model\")()",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        model.fit(x, y, epochs=1)",
            "",
            "        # Assert that the archive has not been saved.",
            "        self.assertFalse(os.path.exists(temp_filepath))",
            "",
            "        # Mutate the `Dense` layer custom weights to ensure that list and",
            "        # dict-contained weights get restored.",
            "        model.layers[1].additional_weights[0].assign(2)",
            "        model.layers[1].weights_in_dict[\"my_weight\"].assign(2)",
            "        model.layers[1].nested_layer.kernel.assign([[1]])",
            "",
            "        model._save_experimental(temp_filepath)",
            "",
            "        # Assert that the archive has been saved.",
            "        self.assertTrue(os.path.exists(temp_filepath))",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(model._is_compiled, loaded_model._is_compiled)",
            "",
            "        # The weights are supposed to be the same (between original and loaded",
            "        # models).",
            "        for original_weights, loaded_weights in zip(",
            "            model.get_weights(), loaded_model.get_weights()",
            "        ):",
            "            np.testing.assert_allclose(original_weights, loaded_weights)",
            "",
            "        # The optimizer variables are supposed to be the same (between original",
            "        # and loaded models).",
            "        for original_weights, loaded_weights in zip(",
            "            model.optimizer.variables, loaded_model.optimizer.variables",
            "        ):",
            "            np.testing.assert_allclose(original_weights, loaded_weights)",
            "",
            "    def test_saving_custom_assets_and_variables(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = ModelWithCustomSaving()",
            "        model.compile(",
            "            optimizer=adam.Adam(),",
            "            loss=[",
            "                \"mse\",",
            "                keras.losses.mean_squared_error,",
            "                keras.losses.MeanSquaredError(),",
            "                my_mean_squared_error,",
            "            ],",
            "        )",
            "        x = np.random.random((100, 32))",
            "        y = np.random.random((100, 1))",
            "        model.fit(x, y, epochs=1)",
            "",
            "        # Assert that the archive has not been saved.",
            "        self.assertFalse(os.path.exists(temp_filepath))",
            "",
            "        model._save_experimental(temp_filepath)",
            "",
            "        loaded_model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(loaded_model.custom_dense.assets, assets_data)",
            "        self.assertEqual(",
            "            loaded_model.custom_dense.stored_variables.tolist(),",
            "            variables_data.tolist(),",
            "        )",
            "",
            "    @tf.__internal__.distribute.combinations.generate(",
            "        tf.__internal__.test.combinations.combine(",
            "            model_type=[\"subclassed\", \"sequential\"],",
            "        )",
            "    )",
            "    def test_compile_overridden_model_raises_if_no_from_config_overridden(",
            "        self, model_type",
            "    ):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        model = (",
            "            CompileOverridingModel()",
            "            if model_type == \"subclassed\"",
            "            else CompileOverridingSequential(",
            "                [keras.layers.Embedding(4, 1), MyDense(1), MyDense(1)]",
            "            )",
            "        )",
            "        model.compile(\"rmsprop\", \"mse\")",
            "        model._save_experimental(temp_filepath)",
            "",
            "        with mock.patch.object(logging, \"warning\") as mock_warn:",
            "            saving_lib.load_model(temp_filepath)",
            "        if not mock_warn.call_args_list:",
            "            raise AssertionError(\"Did not warn.\")",
            "        self.assertIn(",
            "            \"`compile()` was not called as part of model loading \"",
            "            \"because the model's `compile()` method is custom. \",",
            "            mock_warn.call_args_list[0][0][0],",
            "        )",
            "",
            "    def test_metadata(self):",
            "        temp_filepath = Path(",
            "            os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        )",
            "        model = CompileOverridingModel()",
            "        model._save_experimental(temp_filepath)",
            "        with zipfile.ZipFile(temp_filepath, \"r\") as z:",
            "            with z.open(saving_lib._METADATA_FILENAME, \"r\") as c:",
            "                metadata_json = c.read()",
            "        metadata = json_utils.decode(metadata_json)",
            "        self.assertIn(\"keras_version\", metadata)",
            "        self.assertIn(\"date_saved\", metadata)",
            "",
            "    def test_gfile_copy_local_called(self):",
            "        temp_filepath = Path(",
            "            os.path.join(self.get_temp_dir(), \"my_model.keras\")",
            "        )",
            "        model = CompileOverridingModel()",
            "        with mock.patch(\"re.match\", autospec=True) as mock_re_match, mock.patch(",
            "            \"tensorflow.compat.v2.io.gfile.copy\", autospec=True",
            "        ) as mock_copy:",
            "            # Mock Remote Path check to true to test gfile copy logic",
            "            mock_re_match.return_value = True",
            "            model._save_experimental(temp_filepath)",
            "            mock_re_match.assert_called_once()",
            "            mock_copy.assert_called_once()",
            "            self.assertIn(str(temp_filepath), mock_re_match.call_args.args)",
            "            self.assertIn(str(temp_filepath), mock_copy.call_args.args)",
            "",
            "    def test_load_model_api_endpoint(self):",
            "        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"mymodel.keras\"))",
            "        model = self._get_functional_model()",
            "        ref_input = np.random.random((10, 32))",
            "        ref_output = model.predict(ref_input)",
            "        model.save(temp_filepath, save_format=\"keras_v3\")",
            "        model = keras.models.load_model(temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "",
            "    def test_save_load_weights_only(self):",
            "        temp_filepath = Path(",
            "            os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")",
            "        )",
            "        model = self._get_functional_model()",
            "        ref_input = np.random.random((10, 32))",
            "        ref_output = model.predict(ref_input)",
            "        saving_lib.save_weights_only(model, temp_filepath)",
            "        model = self._get_functional_model()",
            "        saving_lib.load_weights_only(model, temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "        # Test with Model method",
            "        model = self._get_functional_model()",
            "        model.load_weights(temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "",
            "    def test_load_weights_only_with_keras_file(self):",
            "        # Test loading weights from whole saved model",
            "        temp_filepath = Path(os.path.join(self.get_temp_dir(), \"mymodel.keras\"))",
            "        model = self._get_functional_model()",
            "        ref_input = np.random.random((10, 32))",
            "        ref_output = model.predict(ref_input)",
            "        saving_lib.save_model(model, temp_filepath)",
            "        model = self._get_functional_model()",
            "        saving_lib.load_weights_only(model, temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "        # Test with Model method",
            "        model = self._get_functional_model()",
            "        model.load_weights(temp_filepath)",
            "        self.assertAllClose(model.predict(ref_input), ref_output, atol=1e-6)",
            "",
            "    def test_compile_arg(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        model = self._get_functional_model()",
            "        model.compile(\"rmsprop\", \"mse\")",
            "        model.fit(np.random.random((10, 32)), np.random.random((10, 1)))",
            "        saving_lib.save_model(model, temp_filepath)",
            "",
            "        model = saving_lib.load_model(temp_filepath)",
            "        self.assertEqual(model._is_compiled, True)",
            "        model = saving_lib.load_model(temp_filepath, compile=False)",
            "        self.assertEqual(model._is_compiled, False)",
            "",
            "    def test_overwrite(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        model = self._get_functional_model()",
            "        model.save(temp_filepath, save_format=\"keras_v3\")",
            "        model.save(temp_filepath, save_format=\"keras_v3\", overwrite=True)",
            "        with self.assertRaises(EOFError):",
            "            model.save(temp_filepath, save_format=\"keras_v3\", overwrite=False)",
            "",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.weights.h5\")",
            "        model = self._get_functional_model()",
            "        model.save_weights(temp_filepath)",
            "        model.save_weights(temp_filepath, overwrite=True)",
            "        with self.assertRaises(EOFError):",
            "            model.save_weights(temp_filepath, overwrite=False)",
            "",
            "    def test_partial_load(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        original_model = keras.Sequential(",
            "            [",
            "                keras.Input(shape=(3,)),",
            "                keras.layers.Dense(4),",
            "                keras.layers.Dense(5),",
            "            ]",
            "        )",
            "        original_model.save(temp_filepath, save_format=\"keras_v3\")",
            "",
            "        # Test with a model that has a differently shaped layer",
            "        new_model = keras.Sequential(",
            "            [",
            "                keras.Input(shape=(3,)),",
            "                keras.layers.Dense(4),",
            "                keras.layers.Dense(6),",
            "            ]",
            "        )",
            "        new_layer_kernel_value = new_model.layers[1].kernel.numpy()",
            "        with self.assertRaisesRegex(ValueError, \"Shape mismatch\"):",
            "            # Doesn't work by default",
            "            new_model.load_weights(temp_filepath)",
            "        # Now it works",
            "        new_model.load_weights(temp_filepath, skip_mismatch=True)",
            "        self.assertAllClose(",
            "            original_model.layers[0].get_weights(),",
            "            new_model.layers[0].get_weights(),",
            "        )",
            "        self.assertAllClose(",
            "            new_model.layers[1].kernel.numpy(), new_layer_kernel_value",
            "        )",
            "",
            "        # Test with a model that has a new layer",
            "        new_model = keras.Sequential(",
            "            [",
            "                keras.Input(shape=(3,)),",
            "                keras.layers.Dense(4),",
            "                keras.layers.Dense(5),",
            "                keras.layers.Dense(5),",
            "            ]",
            "        )",
            "        new_layer_kernel_value = new_model.layers[2].kernel.numpy()",
            "        with self.assertRaisesRegex(ValueError, \"received 0 variables\"):",
            "            # Doesn't work by default",
            "            new_model.load_weights(temp_filepath)",
            "        # Now it works",
            "        new_model.load_weights(temp_filepath, skip_mismatch=True)",
            "        self.assertAllClose(",
            "            original_model.layers[0].get_weights(),",
            "            new_model.layers[0].get_weights(),",
            "        )",
            "        self.assertAllClose(",
            "            original_model.layers[1].get_weights(),",
            "            new_model.layers[1].get_weights(),",
            "        )",
            "        self.assertAllClose(",
            "            new_model.layers[2].kernel.numpy(), new_layer_kernel_value",
            "        )",
            "",
            "    def test_api_errors(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.notkeras\")",
            "        model = self._get_functional_model()",
            "        with self.assertRaisesRegex(ValueError, \"Unknown `save_format`\"):",
            "            model.save(temp_filepath, save_format=\"invalid\")",
            "        with self.assertRaisesRegex(ValueError, \"Invalid `filepath` argument\"):",
            "            model.save(temp_filepath, save_format=\"keras_v3\")",
            "",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"mymodel.keras\")",
            "        with self.assertRaisesRegex(ValueError, \"not supported\"):",
            "            model.save(",
            "                temp_filepath, include_optimizer=False, save_format=\"keras_v3\"",
            "            )",
            "",
            "    def test_safe_mode(self):",
            "        temp_filepath = os.path.join(self.get_temp_dir(), \"unsafe_model.keras\")",
            "        model = keras.Sequential(",
            "            [",
            "                keras.Input(shape=(3,)),",
            "                keras.layers.Lambda(lambda x: x * 2),",
            "            ]",
            "        )",
            "        model.save(temp_filepath, save_format=\"keras_v3\")",
            "        with self.assertRaisesRegex(ValueError, \"arbitrary code execution\"):",
            "            model = saving_lib.load_model(temp_filepath)",
            "        model = saving_lib.load_model(temp_filepath, safe_mode=False)",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    tf.test.main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "409": [
                "SavingV3Test",
                "test_functional_model_with_tf_op_lambda_layer"
            ]
        },
        "addLocation": []
    },
    "keras/saving/serialization_lib.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " \"\"\"Object config serialization and deserialization logic.\"\"\""
            },
            "1": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import importlib"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+import inspect"
            },
            "4": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import threading"
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " import types"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+import warnings"
            },
            "7": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " import numpy as np"
            },
            "9": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " import tensorflow.compat.v2 as tf"
            },
            "10": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " PLAIN_TYPES = (str, int, float, bool)"
            },
            "12": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " SHARED_OBJECTS = threading.local()"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+SAFE_MODE = threading.local()"
            },
            "14": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " class Config:"
            },
            "17": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "         return serialize_keras_object(self.config)"
            },
            "18": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 45,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+class SafeModeScope:"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+    \"\"\"Scope to propagate safe mode flag to nested deserialization calls.\"\"\""
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+    def __init__(self, safe_mode=True):"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+        self.safe_mode = safe_mode"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+    def __enter__(self):"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+        self.original_value = in_safe_mode()"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+        SAFE_MODE.safe_mode = self.safe_mode"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+    def __exit__(self, *args, **kwargs):"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+        SAFE_MODE.safe_mode = self.original_value"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+def in_safe_mode():"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+    return getattr(SAFE_MODE, \"safe_mode\", None)"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+"
            },
            "38": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 65,
                "PatchRowcode": " class ObjectSharingScope:"
            },
            "39": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 66,
                "PatchRowcode": "     \"\"\"Scope to enable detection and reuse of previously seen objects.\"\"\""
            },
            "40": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " "
            },
            "41": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "     if isinstance(obj, tf.DType):"
            },
            "42": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "         return obj.name"
            },
            "43": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 166,
                "PatchRowcode": "     if isinstance(obj, types.FunctionType) and obj.__name__ == \"<lambda>\":"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+        warnings.warn("
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 168,
                "PatchRowcode": "+            \"The object being serialized includes a `lambda`. This is unsafe. \""
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+            \"In order to reload the object, you will have to pass \""
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+            \"`safe_mode=False` to the loading function. \""
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+            \"Please avoid using `lambda` in the \""
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+            \"future, and use named Python functions instead. \""
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 173,
                "PatchRowcode": "+            f\"This is the `lambda` being serialized: {inspect.getsource(obj)}\","
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+            stacklevel=2,"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+        )"
            },
            "53": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "         return {"
            },
            "54": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "             \"class_name\": \"__lambda__\","
            },
            "55": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "             \"config\": {"
            },
            "56": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 268,
                "PatchRowcode": "     return {key: serialize_keras_object(value) for key, value in obj.items()}"
            },
            "57": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 269,
                "PatchRowcode": " "
            },
            "58": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": 270,
                "PatchRowcode": " "
            },
            "59": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def deserialize_keras_object(config, custom_objects=None, **kwargs):"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 271,
                "PatchRowcode": "+def deserialize_keras_object("
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+    config, custom_objects=None, safe_mode=True, **kwargs"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 273,
                "PatchRowcode": "+):"
            },
            "63": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 274,
                "PatchRowcode": "     \"\"\"Retrieve the object by deserializing the config dict."
            },
            "64": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 275,
                "PatchRowcode": " "
            },
            "65": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 276,
                "PatchRowcode": "     The config dict is a Python dictionary that consists of a set of key-value"
            },
            "66": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": 357,
                "PatchRowcode": "     ```"
            },
            "67": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": 358,
                "PatchRowcode": " "
            },
            "68": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": 359,
                "PatchRowcode": "     Args:"
            },
            "69": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-      config_dict: the python dict structure to deserialize the Keras object"
            },
            "70": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        from."
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+        config: Python dict describing the object."
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 361,
                "PatchRowcode": "+        custom_objects: Python dict containing a mapping between custom"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 362,
                "PatchRowcode": "+            object names the corresponding classes or functions."
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+        safe_mode: Boolean, whether to disallow unsafe `lambda` deserialization."
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+            When `safe_mode=False`, loading an object has the potential to"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+            trigger arbitrary code execution. This argument is only"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+            applicable to the Keras v3 model format. Defaults to True."
            },
            "78": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 367,
                "PatchRowcode": " "
            },
            "79": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 368,
                "PatchRowcode": "     Returns:"
            },
            "80": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 369,
                "PatchRowcode": "       The object described by the `config` dictionary."
            },
            "81": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 370,
                "PatchRowcode": " "
            },
            "82": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 371,
                "PatchRowcode": "     \"\"\""
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+    safe_mode = in_safe_mode() or safe_mode"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 373,
                "PatchRowcode": "+"
            },
            "85": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "     module_objects = kwargs.pop(\"module_objects\", None)"
            },
            "86": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "     custom_objects = custom_objects or {}"
            },
            "87": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 376,
                "PatchRowcode": " "
            },
            "88": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": 392,
                "PatchRowcode": "         return config"
            },
            "89": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": 393,
                "PatchRowcode": "     if isinstance(config, (list, tuple)):"
            },
            "90": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": 394,
                "PatchRowcode": "         return ["
            },
            "91": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            deserialize_keras_object(x, custom_objects=custom_objects)"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 395,
                "PatchRowcode": "+            deserialize_keras_object("
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+                x, custom_objects=custom_objects, safe_mode=safe_mode"
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+            )"
            },
            "95": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": 398,
                "PatchRowcode": "             for x in config"
            },
            "96": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": 399,
                "PatchRowcode": "         ]"
            },
            "97": {
                "beforePatchRowNumber": 359,
                "afterPatchRowNumber": 400,
                "PatchRowcode": "     if not isinstance(config, dict):"
            },
            "98": {
                "beforePatchRowNumber": 360,
                "afterPatchRowNumber": 401,
                "PatchRowcode": "         raise TypeError(f\"Could not parse config: {config}\")"
            },
            "99": {
                "beforePatchRowNumber": 361,
                "afterPatchRowNumber": 402,
                "PatchRowcode": " "
            },
            "100": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": 403,
                "PatchRowcode": "     if \"class_name\" not in config or \"config\" not in config:"
            },
            "101": {
                "beforePatchRowNumber": 363,
                "afterPatchRowNumber": 404,
                "PatchRowcode": "         return {"
            },
            "102": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            key: deserialize_keras_object(value, custom_objects=custom_objects)"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 405,
                "PatchRowcode": "+            key: deserialize_keras_object("
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 406,
                "PatchRowcode": "+                value, custom_objects=custom_objects, safe_mode=safe_mode"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 407,
                "PatchRowcode": "+            )"
            },
            "106": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 408,
                "PatchRowcode": "             for key, value in config.items()"
            },
            "107": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": 409,
                "PatchRowcode": "         }"
            },
            "108": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 410,
                "PatchRowcode": " "
            },
            "109": {
                "beforePatchRowNumber": 376,
                "afterPatchRowNumber": 419,
                "PatchRowcode": "     if config[\"class_name\"] == \"__bytes__\":"
            },
            "110": {
                "beforePatchRowNumber": 377,
                "afterPatchRowNumber": 420,
                "PatchRowcode": "         return inner_config[\"value\"].encode(\"utf-8\")"
            },
            "111": {
                "beforePatchRowNumber": 378,
                "afterPatchRowNumber": 421,
                "PatchRowcode": "     if config[\"class_name\"] == \"__lambda__\":"
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 422,
                "PatchRowcode": "+        if safe_mode:"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 423,
                "PatchRowcode": "+            raise ValueError("
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 424,
                "PatchRowcode": "+                \"Requested the deserialization of a `lambda` object. \""
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 425,
                "PatchRowcode": "+                \"This carries a potential risk of arbitrary code execution \""
            },
            "116": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 426,
                "PatchRowcode": "+                \"and thus it is disallowed by default. If you trust the \""
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 427,
                "PatchRowcode": "+                \"source of the saved model, you can pass `safe_mode=False` to \""
            },
            "118": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 428,
                "PatchRowcode": "+                \"the loading function in order to allow `lambda` loading.\""
            },
            "119": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 429,
                "PatchRowcode": "+            )"
            },
            "120": {
                "beforePatchRowNumber": 379,
                "afterPatchRowNumber": 430,
                "PatchRowcode": "         return generic_utils.func_load(inner_config[\"value\"])"
            },
            "121": {
                "beforePatchRowNumber": 380,
                "afterPatchRowNumber": 431,
                "PatchRowcode": "     if config[\"class_name\"] == \"__typespec__\":"
            },
            "122": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 432,
                "PatchRowcode": "         obj = _retrieve_class_or_fn("
            },
            "123": {
                "beforePatchRowNumber": 434,
                "afterPatchRowNumber": 485,
                "PatchRowcode": "             f\"the class is missing a `from_config()` method. \""
            },
            "124": {
                "beforePatchRowNumber": 435,
                "afterPatchRowNumber": 486,
                "PatchRowcode": "             f\"Full object config: {config}\""
            },
            "125": {
                "beforePatchRowNumber": 436,
                "afterPatchRowNumber": 487,
                "PatchRowcode": "         )"
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 488,
                "PatchRowcode": "+"
            },
            "127": {
                "beforePatchRowNumber": 437,
                "afterPatchRowNumber": 489,
                "PatchRowcode": "     # Instantiate the class from its config inside a custom object scope"
            },
            "128": {
                "beforePatchRowNumber": 438,
                "afterPatchRowNumber": 490,
                "PatchRowcode": "     # so that we can catch any custom objects that the config refers to."
            },
            "129": {
                "beforePatchRowNumber": 439,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with object_registration.custom_object_scope(custom_objects):"
            },
            "130": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 491,
                "PatchRowcode": "+    with ("
            },
            "131": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 492,
                "PatchRowcode": "+        object_registration.custom_object_scope(custom_objects),"
            },
            "132": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 493,
                "PatchRowcode": "+        SafeModeScope(safe_mode),"
            },
            "133": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 494,
                "PatchRowcode": "+    ):"
            },
            "134": {
                "beforePatchRowNumber": 440,
                "afterPatchRowNumber": 495,
                "PatchRowcode": "         instance = cls.from_config(inner_config)"
            },
            "135": {
                "beforePatchRowNumber": 441,
                "afterPatchRowNumber": 496,
                "PatchRowcode": "         build_config = config.get(\"build_config\", None)"
            },
            "136": {
                "beforePatchRowNumber": 442,
                "afterPatchRowNumber": 497,
                "PatchRowcode": "         if build_config:"
            }
        },
        "frontPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Object config serialization and deserialization logic.\"\"\"",
            "",
            "import importlib",
            "import threading",
            "import types",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "",
            "from keras.saving import object_registration",
            "from keras.saving.legacy import serialization as legacy_serialization",
            "from keras.saving.legacy.saved_model.utils import in_tf_saved_model_scope",
            "from keras.utils import generic_utils",
            "",
            "# isort: off",
            "from tensorflow.python.util import tf_export",
            "",
            "PLAIN_TYPES = (str, int, float, bool)",
            "SHARED_OBJECTS = threading.local()",
            "",
            "",
            "class Config:",
            "    def __init__(self, **config):",
            "        self.config = config",
            "",
            "    def serialize(self):",
            "        return serialize_keras_object(self.config)",
            "",
            "",
            "class ObjectSharingScope:",
            "    \"\"\"Scope to enable detection and reuse of previously seen objects.\"\"\"",
            "",
            "    def __enter__(self):",
            "        SHARED_OBJECTS.enabled = True",
            "        SHARED_OBJECTS.id_to_obj_map = {}",
            "        SHARED_OBJECTS.id_to_config_map = {}",
            "",
            "    def __exit__(self, *args, **kwargs):",
            "        SHARED_OBJECTS.enabled = False",
            "        SHARED_OBJECTS.id_to_obj_map = {}",
            "        SHARED_OBJECTS.id_to_config_map = {}",
            "",
            "",
            "def get_shared_object(obj_id):",
            "    \"\"\"Retrieve an object previously seen during deserialization.\"\"\"",
            "    if getattr(SHARED_OBJECTS, \"enabled\", False):",
            "        return SHARED_OBJECTS.id_to_obj_map.get(obj_id, None)",
            "",
            "",
            "def record_object_after_serialization(obj, config):",
            "    \"\"\"Call after serializing an object, to keep track of its config.\"\"\"",
            "    if not getattr(SHARED_OBJECTS, \"enabled\", False):",
            "        return  # Not in a sharing scope",
            "    obj_id = int(id(obj))",
            "    if obj_id not in SHARED_OBJECTS.id_to_config_map:",
            "        SHARED_OBJECTS.id_to_config_map[obj_id] = config",
            "    else:",
            "        config[\"shared_object_id\"] = obj_id",
            "        prev_config = SHARED_OBJECTS.id_to_config_map[obj_id]",
            "        prev_config[\"shared_object_id\"] = obj_id",
            "",
            "",
            "def record_object_after_deserialization(obj, obj_id):",
            "    \"\"\"Call after deserializing an object, to keep track of it in the future.\"\"\"",
            "    if not getattr(SHARED_OBJECTS, \"enabled\", False):",
            "        return  # Not in a sharing scope",
            "    SHARED_OBJECTS.id_to_obj_map[obj_id] = obj",
            "",
            "",
            "def serialize_keras_object(obj):",
            "    \"\"\"Retrieve the config dict by serializing the Keras object.",
            "",
            "    `serialize_keras_object()` serializes a Keras object to a python dictionary",
            "    that represents the object, and is a reciprocal function of",
            "    `deserialize_keras_object()`. See `deserialize_keras_object()` for more",
            "    information about the config format.",
            "",
            "    Args:",
            "      obj: the Keras object to serialize.",
            "",
            "    Returns:",
            "      A python dict that represents the object. The python dict can be",
            "      deserialized via `deserialize_keras_object()`.",
            "    \"\"\"",
            "    # Fall back to legacy serialization for all TF1 users or if",
            "    # wrapped by in_tf_saved_model_scope() to explicitly use legacy",
            "    # saved_model logic.",
            "    if not tf.__internal__.tf2.enabled() or in_tf_saved_model_scope():",
            "        return legacy_serialization.serialize_keras_object(obj)",
            "",
            "    if obj is None:",
            "        return obj",
            "    if isinstance(obj, PLAIN_TYPES):",
            "        return obj",
            "",
            "    if isinstance(obj, (list, tuple)):",
            "        return [serialize_keras_object(x) for x in obj]",
            "    if isinstance(obj, dict):",
            "        return serialize_dict(obj)",
            "",
            "    # Special cases:",
            "    if isinstance(obj, bytes):",
            "        return {",
            "            \"class_name\": \"__bytes__\",",
            "            \"config\": {\"value\": obj.decode(\"utf-8\")},",
            "        }",
            "    if isinstance(obj, tf.TensorShape):",
            "        return obj.as_list()",
            "    if isinstance(obj, tf.Tensor):",
            "        return {",
            "            \"class_name\": \"__tensor__\",",
            "            \"config\": {",
            "                \"value\": obj.numpy().tolist(),",
            "                \"dtype\": obj.dtype.name,",
            "            },",
            "        }",
            "    if type(obj).__module__ == np.__name__:",
            "        if isinstance(obj, np.ndarray):",
            "            return {",
            "                \"class_name\": \"__numpy__\",",
            "                \"config\": {",
            "                    \"value\": obj.tolist(),",
            "                    \"dtype\": obj.dtype.name,",
            "                },",
            "            }",
            "        else:",
            "            # Treat numpy floats / etc as plain types.",
            "            return obj.item()",
            "    if isinstance(obj, tf.DType):",
            "        return obj.name",
            "    if isinstance(obj, types.FunctionType) and obj.__name__ == \"<lambda>\":",
            "        return {",
            "            \"class_name\": \"__lambda__\",",
            "            \"config\": {",
            "                \"value\": generic_utils.func_dump(obj),",
            "            },",
            "        }",
            "    if isinstance(obj, tf.TypeSpec):",
            "        ts_config = obj._serialize()",
            "        # TensorShape and tf.DType conversion",
            "        ts_config = list(",
            "            map(",
            "                lambda x: x.as_list()",
            "                if isinstance(x, tf.TensorShape)",
            "                else (x.name if isinstance(x, tf.DType) else x),",
            "                ts_config,",
            "            )",
            "        )",
            "        return {",
            "            \"class_name\": \"__typespec__\",",
            "            \"spec_name\": obj.__class__.__name__,",
            "            \"module\": obj.__class__.__module__,",
            "            \"config\": ts_config,",
            "            \"registered_name\": None,",
            "        }",
            "",
            "    # This gets the `keras.*` exported name, such as \"keras.optimizers.Adam\".",
            "    keras_api_name = tf_export.get_canonical_name_for_symbol(",
            "        obj.__class__, api_name=\"keras\"",
            "    )",
            "    if keras_api_name is None:",
            "        # Any custom object or otherwise non-exported object",
            "        if isinstance(obj, types.FunctionType):",
            "            module = obj.__module__",
            "        else:",
            "            module = obj.__class__.__module__",
            "        class_name = obj.__class__.__name__",
            "        if module == \"builtins\":",
            "            registered_name = None",
            "        else:",
            "            if isinstance(obj, types.FunctionType):",
            "                registered_name = object_registration.get_registered_name(obj)",
            "            else:",
            "                registered_name = object_registration.get_registered_name(",
            "                    obj.__class__",
            "                )",
            "    else:",
            "        # A publicly-exported Keras object",
            "        parts = keras_api_name.split(\".\")",
            "        module = \".\".join(parts[:-1])",
            "        class_name = parts[-1]",
            "        registered_name = None",
            "    config = {",
            "        \"module\": module,",
            "        \"class_name\": class_name,",
            "        \"config\": _get_class_or_fn_config(obj),",
            "        \"registered_name\": registered_name,",
            "    }",
            "    if hasattr(obj, \"get_build_config\"):",
            "        build_config = obj.get_build_config()",
            "        if build_config is not None:",
            "            config[\"build_config\"] = serialize_dict(build_config)",
            "    if hasattr(obj, \"get_compile_config\"):",
            "        compile_config = obj.get_compile_config()",
            "        if compile_config is not None:",
            "            config[\"compile_config\"] = serialize_dict(compile_config)",
            "    record_object_after_serialization(obj, config)",
            "    return config",
            "",
            "",
            "def _get_class_or_fn_config(obj):",
            "    \"\"\"Return the object's config depending on its type.\"\"\"",
            "    # Functions / lambdas:",
            "    if isinstance(obj, types.FunctionType):",
            "        return obj.__name__",
            "    # All classes:",
            "    if hasattr(obj, \"get_config\"):",
            "        config = obj.get_config()",
            "        if not isinstance(config, dict):",
            "            raise TypeError(",
            "                f\"The `get_config()` method of {obj} should return \"",
            "                f\"a dict. It returned: {config}\"",
            "            )",
            "        return serialize_dict(config)",
            "    else:",
            "        raise TypeError(",
            "            f\"Cannot serialize object {obj} of type {type(obj)}. \"",
            "            \"To be serializable, \"",
            "            \"a class must implement the `get_config()` method.\"",
            "        )",
            "",
            "",
            "def serialize_dict(obj):",
            "    return {key: serialize_keras_object(value) for key, value in obj.items()}",
            "",
            "",
            "def deserialize_keras_object(config, custom_objects=None, **kwargs):",
            "    \"\"\"Retrieve the object by deserializing the config dict.",
            "",
            "    The config dict is a Python dictionary that consists of a set of key-value",
            "    pairs, and represents a Keras object, such as an `Optimizer`, `Layer`,",
            "    `Metrics`, etc. The saving and loading library uses the following keys to",
            "    record information of a Keras object:",
            "",
            "    - `class_name`: String. This is the name of the class,",
            "      as exactly defined in the source",
            "      code, such as \"LossesContainer\".",
            "    - `config`: Dict. Library-defined or user-defined key-value pairs that store",
            "      the configuration of the object, as obtained by `object.get_config()`.",
            "    - `module`: String. The path of the python module, such as",
            "      \"keras.engine.compile_utils\". Built-in Keras classes",
            "      expect to have prefix `keras`.",
            "    - `registered_name`: String. The key the class is registered under via",
            "      `keras.utils.register_keras_serializable(package, name)` API. The key has",
            "      the format of '{package}>{name}', where `package` and `name` are the",
            "      arguments passed to `register_keras_serializable()`. If `name` is not",
            "      provided, it defaults to the class name. If `registered_name` successfully",
            "      resolves to a class (that was registered), the `class_name` and `config`",
            "      values in the dict will not be used. `registered_name` is only used for",
            "      non-built-in classes.",
            "",
            "    For example, the following dictionary represents the built-in Adam optimizer",
            "    with the relevant config:",
            "",
            "    ```python",
            "    dict_structure = {",
            "        \"class_name\": \"Adam\",",
            "        \"config\": {",
            "            \"amsgrad\": false,",
            "            \"beta_1\": 0.8999999761581421,",
            "            \"beta_2\": 0.9990000128746033,",
            "            \"decay\": 0.0,",
            "            \"epsilon\": 1e-07,",
            "            \"learning_rate\": 0.0010000000474974513,",
            "            \"name\": \"Adam\"",
            "        },",
            "        \"module\": \"keras.optimizers\",",
            "        \"registered_name\": None",
            "    }",
            "    # Returns an `Adam` instance identical to the original one.",
            "    deserialize_keras_object(dict_structure)",
            "    ```",
            "",
            "    If the class does not have an exported Keras namespace, the library tracks",
            "    it by its `module` and `class_name`. For example:",
            "",
            "    ```python",
            "    dict_structure = {",
            "      \"class_name\": \"LossesContainer\",",
            "      \"config\": {",
            "          \"losses\": [...],",
            "          \"total_loss_mean\": {...},",
            "      },",
            "      \"module\": \"keras.engine.compile_utils\",",
            "      \"registered_name\": \"LossesContainer\"",
            "    }",
            "",
            "    # Returns a `LossesContainer` instance identical to the original one.",
            "    deserialize_keras_object(dict_structure)",
            "    ```",
            "",
            "    And the following dictionary represents a user-customized `MeanSquaredError`",
            "    loss:",
            "",
            "    ```python",
            "    @keras.utils.register_keras_serializable(package='my_package')",
            "    class ModifiedMeanSquaredError(keras.losses.MeanSquaredError):",
            "      ...",
            "",
            "    dict_structure = {",
            "        \"class_name\": \"ModifiedMeanSquaredError\",",
            "        \"config\": {",
            "            \"fn\": \"mean_squared_error\",",
            "            \"name\": \"mean_squared_error\",",
            "            \"reduction\": \"auto\"",
            "        },",
            "        \"registered_name\": \"my_package>ModifiedMeanSquaredError\"",
            "    }",
            "    # Returns the `ModifiedMeanSquaredError` object",
            "    deserialize_keras_object(dict_structure)",
            "    ```",
            "",
            "    Args:",
            "      config_dict: the python dict structure to deserialize the Keras object",
            "        from.",
            "",
            "    Returns:",
            "      The object described by the `config` dictionary.",
            "",
            "    \"\"\"",
            "    module_objects = kwargs.pop(\"module_objects\", None)",
            "    custom_objects = custom_objects or {}",
            "",
            "    # Fall back to legacy deserialization for all TF1 users or if",
            "    # wrapped by in_tf_saved_model_scope() to explicitly use legacy",
            "    # saved_model logic.",
            "    if not tf.__internal__.tf2.enabled() or in_tf_saved_model_scope():",
            "        return legacy_serialization.deserialize_keras_object(",
            "            config, module_objects, custom_objects",
            "        )",
            "",
            "    if config is None:",
            "        return None",
            "    if isinstance(config, PLAIN_TYPES):",
            "        if isinstance(config, str) and custom_objects.get(config) is not None:",
            "            # This is to deserialize plain functions which are serialized as",
            "            # string names by legacy saving formats.",
            "            return custom_objects[config]",
            "        return config",
            "    if isinstance(config, (list, tuple)):",
            "        return [",
            "            deserialize_keras_object(x, custom_objects=custom_objects)",
            "            for x in config",
            "        ]",
            "    if not isinstance(config, dict):",
            "        raise TypeError(f\"Could not parse config: {config}\")",
            "",
            "    if \"class_name\" not in config or \"config\" not in config:",
            "        return {",
            "            key: deserialize_keras_object(value, custom_objects=custom_objects)",
            "            for key, value in config.items()",
            "        }",
            "",
            "    class_name = config[\"class_name\"]",
            "    inner_config = config[\"config\"]",
            "",
            "    # Special cases:",
            "    if class_name == \"__tensor__\":",
            "        return tf.constant(inner_config[\"value\"], dtype=inner_config[\"dtype\"])",
            "    if class_name == \"__numpy__\":",
            "        return np.array(inner_config[\"value\"], dtype=inner_config[\"dtype\"])",
            "    if config[\"class_name\"] == \"__bytes__\":",
            "        return inner_config[\"value\"].encode(\"utf-8\")",
            "    if config[\"class_name\"] == \"__lambda__\":",
            "        return generic_utils.func_load(inner_config[\"value\"])",
            "    if config[\"class_name\"] == \"__typespec__\":",
            "        obj = _retrieve_class_or_fn(",
            "            config[\"spec_name\"],",
            "            config[\"registered_name\"],",
            "            config[\"module\"],",
            "            obj_type=\"class\",",
            "            full_config=config,",
            "            custom_objects=custom_objects,",
            "        )",
            "        # Conversion to TensorShape and tf.DType",
            "        inner_config = map(",
            "            lambda x: tf.TensorShape(x)",
            "            if isinstance(x, list)",
            "            else (getattr(tf, x) if hasattr(tf.dtypes, str(x)) else x),",
            "            inner_config,",
            "        )",
            "        return obj._deserialize(tuple(inner_config))",
            "    # TODO(fchollet): support for TypeSpec, CompositeTensor, tf.Dtype",
            "    # TODO(fchollet): consider special-casing tuples (which are currently",
            "    # deserialized as lists).",
            "",
            "    # Below: classes and functions.",
            "    module = config.get(\"module\", None)",
            "    registered_name = config.get(\"registered_name\", class_name)",
            "",
            "    if class_name == \"function\":",
            "        fn_name = inner_config",
            "        return _retrieve_class_or_fn(",
            "            fn_name,",
            "            registered_name,",
            "            module,",
            "            obj_type=\"function\",",
            "            full_config=config,",
            "            custom_objects=custom_objects,",
            "        )",
            "",
            "    # Below, handling of all classes.",
            "    # First, is it a shared object?",
            "    if \"shared_object_id\" in config:",
            "        obj = get_shared_object(config[\"shared_object_id\"])",
            "        if obj is not None:",
            "            return obj",
            "",
            "    cls = _retrieve_class_or_fn(",
            "        class_name,",
            "        registered_name,",
            "        module,",
            "        obj_type=\"class\",",
            "        full_config=config,",
            "        custom_objects=custom_objects,",
            "    )",
            "    if not hasattr(cls, \"from_config\"):",
            "        raise TypeError(",
            "            f\"Unable to reconstruct an instance of '{class_name}' because \"",
            "            f\"the class is missing a `from_config()` method. \"",
            "            f\"Full object config: {config}\"",
            "        )",
            "    # Instantiate the class from its config inside a custom object scope",
            "    # so that we can catch any custom objects that the config refers to.",
            "    with object_registration.custom_object_scope(custom_objects):",
            "        instance = cls.from_config(inner_config)",
            "        build_config = config.get(\"build_config\", None)",
            "        if build_config:",
            "            instance.build_from_config(build_config)",
            "        compile_config = config.get(\"compile_config\", None)",
            "        if compile_config:",
            "            instance.compile_from_config(compile_config)",
            "",
            "    if \"shared_object_id\" in config:",
            "        record_object_after_deserialization(",
            "            instance, config[\"shared_object_id\"]",
            "        )",
            "    return instance",
            "",
            "",
            "def _retrieve_class_or_fn(",
            "    name, registered_name, module, obj_type, full_config, custom_objects=None",
            "):",
            "    # If there is a custom object registered via",
            "    # `register_keras_serializable`, that takes precedence.",
            "    custom_obj = object_registration.get_registered_object(",
            "        registered_name, custom_objects=custom_objects",
            "    )",
            "    if custom_obj is not None:",
            "        return custom_obj",
            "",
            "    if module:",
            "        # If it's a Keras built-in object,",
            "        # we cannot always use direct import, because the exported",
            "        # module name might not match the package structure",
            "        # (e.g. experimental symbols).",
            "        if module == \"keras\" or module.startswith(\"keras.\"):",
            "            obj = tf_export.get_symbol_from_name(module + \".\" + name)",
            "            if obj is not None:",
            "                return obj",
            "",
            "        # Otherwise, attempt to retrieve the class object given the `module`",
            "        # and `class_name`. Import the module, find the class.",
            "        try:",
            "            mod = importlib.import_module(module)",
            "        except ModuleNotFoundError:",
            "            raise TypeError(",
            "                f\"Could not deserialize {obj_type} '{name}' because \"",
            "                f\"its parent module {module} cannot be imported. \"",
            "                f\"Full object config: {full_config}\"",
            "            )",
            "        obj = vars(mod).get(name, None)",
            "        if obj is not None:",
            "            return obj",
            "",
            "    raise TypeError(",
            "        f\"Could not locate {obj_type} '{name}'. \"",
            "        \"Make sure custom classes are decorated with \"",
            "        \"`@keras.utils.register_keras_serializable`. \"",
            "        f\"Full object config: {full_config}\"",
            "    )"
        ],
        "afterPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Object config serialization and deserialization logic.\"\"\"",
            "",
            "import importlib",
            "import inspect",
            "import threading",
            "import types",
            "import warnings",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "",
            "from keras.saving import object_registration",
            "from keras.saving.legacy import serialization as legacy_serialization",
            "from keras.saving.legacy.saved_model.utils import in_tf_saved_model_scope",
            "from keras.utils import generic_utils",
            "",
            "# isort: off",
            "from tensorflow.python.util import tf_export",
            "",
            "PLAIN_TYPES = (str, int, float, bool)",
            "SHARED_OBJECTS = threading.local()",
            "SAFE_MODE = threading.local()",
            "",
            "",
            "class Config:",
            "    def __init__(self, **config):",
            "        self.config = config",
            "",
            "    def serialize(self):",
            "        return serialize_keras_object(self.config)",
            "",
            "",
            "class SafeModeScope:",
            "    \"\"\"Scope to propagate safe mode flag to nested deserialization calls.\"\"\"",
            "",
            "    def __init__(self, safe_mode=True):",
            "        self.safe_mode = safe_mode",
            "",
            "    def __enter__(self):",
            "        self.original_value = in_safe_mode()",
            "        SAFE_MODE.safe_mode = self.safe_mode",
            "",
            "    def __exit__(self, *args, **kwargs):",
            "        SAFE_MODE.safe_mode = self.original_value",
            "",
            "",
            "def in_safe_mode():",
            "    return getattr(SAFE_MODE, \"safe_mode\", None)",
            "",
            "",
            "class ObjectSharingScope:",
            "    \"\"\"Scope to enable detection and reuse of previously seen objects.\"\"\"",
            "",
            "    def __enter__(self):",
            "        SHARED_OBJECTS.enabled = True",
            "        SHARED_OBJECTS.id_to_obj_map = {}",
            "        SHARED_OBJECTS.id_to_config_map = {}",
            "",
            "    def __exit__(self, *args, **kwargs):",
            "        SHARED_OBJECTS.enabled = False",
            "        SHARED_OBJECTS.id_to_obj_map = {}",
            "        SHARED_OBJECTS.id_to_config_map = {}",
            "",
            "",
            "def get_shared_object(obj_id):",
            "    \"\"\"Retrieve an object previously seen during deserialization.\"\"\"",
            "    if getattr(SHARED_OBJECTS, \"enabled\", False):",
            "        return SHARED_OBJECTS.id_to_obj_map.get(obj_id, None)",
            "",
            "",
            "def record_object_after_serialization(obj, config):",
            "    \"\"\"Call after serializing an object, to keep track of its config.\"\"\"",
            "    if not getattr(SHARED_OBJECTS, \"enabled\", False):",
            "        return  # Not in a sharing scope",
            "    obj_id = int(id(obj))",
            "    if obj_id not in SHARED_OBJECTS.id_to_config_map:",
            "        SHARED_OBJECTS.id_to_config_map[obj_id] = config",
            "    else:",
            "        config[\"shared_object_id\"] = obj_id",
            "        prev_config = SHARED_OBJECTS.id_to_config_map[obj_id]",
            "        prev_config[\"shared_object_id\"] = obj_id",
            "",
            "",
            "def record_object_after_deserialization(obj, obj_id):",
            "    \"\"\"Call after deserializing an object, to keep track of it in the future.\"\"\"",
            "    if not getattr(SHARED_OBJECTS, \"enabled\", False):",
            "        return  # Not in a sharing scope",
            "    SHARED_OBJECTS.id_to_obj_map[obj_id] = obj",
            "",
            "",
            "def serialize_keras_object(obj):",
            "    \"\"\"Retrieve the config dict by serializing the Keras object.",
            "",
            "    `serialize_keras_object()` serializes a Keras object to a python dictionary",
            "    that represents the object, and is a reciprocal function of",
            "    `deserialize_keras_object()`. See `deserialize_keras_object()` for more",
            "    information about the config format.",
            "",
            "    Args:",
            "      obj: the Keras object to serialize.",
            "",
            "    Returns:",
            "      A python dict that represents the object. The python dict can be",
            "      deserialized via `deserialize_keras_object()`.",
            "    \"\"\"",
            "    # Fall back to legacy serialization for all TF1 users or if",
            "    # wrapped by in_tf_saved_model_scope() to explicitly use legacy",
            "    # saved_model logic.",
            "    if not tf.__internal__.tf2.enabled() or in_tf_saved_model_scope():",
            "        return legacy_serialization.serialize_keras_object(obj)",
            "",
            "    if obj is None:",
            "        return obj",
            "    if isinstance(obj, PLAIN_TYPES):",
            "        return obj",
            "",
            "    if isinstance(obj, (list, tuple)):",
            "        return [serialize_keras_object(x) for x in obj]",
            "    if isinstance(obj, dict):",
            "        return serialize_dict(obj)",
            "",
            "    # Special cases:",
            "    if isinstance(obj, bytes):",
            "        return {",
            "            \"class_name\": \"__bytes__\",",
            "            \"config\": {\"value\": obj.decode(\"utf-8\")},",
            "        }",
            "    if isinstance(obj, tf.TensorShape):",
            "        return obj.as_list()",
            "    if isinstance(obj, tf.Tensor):",
            "        return {",
            "            \"class_name\": \"__tensor__\",",
            "            \"config\": {",
            "                \"value\": obj.numpy().tolist(),",
            "                \"dtype\": obj.dtype.name,",
            "            },",
            "        }",
            "    if type(obj).__module__ == np.__name__:",
            "        if isinstance(obj, np.ndarray):",
            "            return {",
            "                \"class_name\": \"__numpy__\",",
            "                \"config\": {",
            "                    \"value\": obj.tolist(),",
            "                    \"dtype\": obj.dtype.name,",
            "                },",
            "            }",
            "        else:",
            "            # Treat numpy floats / etc as plain types.",
            "            return obj.item()",
            "    if isinstance(obj, tf.DType):",
            "        return obj.name",
            "    if isinstance(obj, types.FunctionType) and obj.__name__ == \"<lambda>\":",
            "        warnings.warn(",
            "            \"The object being serialized includes a `lambda`. This is unsafe. \"",
            "            \"In order to reload the object, you will have to pass \"",
            "            \"`safe_mode=False` to the loading function. \"",
            "            \"Please avoid using `lambda` in the \"",
            "            \"future, and use named Python functions instead. \"",
            "            f\"This is the `lambda` being serialized: {inspect.getsource(obj)}\",",
            "            stacklevel=2,",
            "        )",
            "        return {",
            "            \"class_name\": \"__lambda__\",",
            "            \"config\": {",
            "                \"value\": generic_utils.func_dump(obj),",
            "            },",
            "        }",
            "    if isinstance(obj, tf.TypeSpec):",
            "        ts_config = obj._serialize()",
            "        # TensorShape and tf.DType conversion",
            "        ts_config = list(",
            "            map(",
            "                lambda x: x.as_list()",
            "                if isinstance(x, tf.TensorShape)",
            "                else (x.name if isinstance(x, tf.DType) else x),",
            "                ts_config,",
            "            )",
            "        )",
            "        return {",
            "            \"class_name\": \"__typespec__\",",
            "            \"spec_name\": obj.__class__.__name__,",
            "            \"module\": obj.__class__.__module__,",
            "            \"config\": ts_config,",
            "            \"registered_name\": None,",
            "        }",
            "",
            "    # This gets the `keras.*` exported name, such as \"keras.optimizers.Adam\".",
            "    keras_api_name = tf_export.get_canonical_name_for_symbol(",
            "        obj.__class__, api_name=\"keras\"",
            "    )",
            "    if keras_api_name is None:",
            "        # Any custom object or otherwise non-exported object",
            "        if isinstance(obj, types.FunctionType):",
            "            module = obj.__module__",
            "        else:",
            "            module = obj.__class__.__module__",
            "        class_name = obj.__class__.__name__",
            "        if module == \"builtins\":",
            "            registered_name = None",
            "        else:",
            "            if isinstance(obj, types.FunctionType):",
            "                registered_name = object_registration.get_registered_name(obj)",
            "            else:",
            "                registered_name = object_registration.get_registered_name(",
            "                    obj.__class__",
            "                )",
            "    else:",
            "        # A publicly-exported Keras object",
            "        parts = keras_api_name.split(\".\")",
            "        module = \".\".join(parts[:-1])",
            "        class_name = parts[-1]",
            "        registered_name = None",
            "    config = {",
            "        \"module\": module,",
            "        \"class_name\": class_name,",
            "        \"config\": _get_class_or_fn_config(obj),",
            "        \"registered_name\": registered_name,",
            "    }",
            "    if hasattr(obj, \"get_build_config\"):",
            "        build_config = obj.get_build_config()",
            "        if build_config is not None:",
            "            config[\"build_config\"] = serialize_dict(build_config)",
            "    if hasattr(obj, \"get_compile_config\"):",
            "        compile_config = obj.get_compile_config()",
            "        if compile_config is not None:",
            "            config[\"compile_config\"] = serialize_dict(compile_config)",
            "    record_object_after_serialization(obj, config)",
            "    return config",
            "",
            "",
            "def _get_class_or_fn_config(obj):",
            "    \"\"\"Return the object's config depending on its type.\"\"\"",
            "    # Functions / lambdas:",
            "    if isinstance(obj, types.FunctionType):",
            "        return obj.__name__",
            "    # All classes:",
            "    if hasattr(obj, \"get_config\"):",
            "        config = obj.get_config()",
            "        if not isinstance(config, dict):",
            "            raise TypeError(",
            "                f\"The `get_config()` method of {obj} should return \"",
            "                f\"a dict. It returned: {config}\"",
            "            )",
            "        return serialize_dict(config)",
            "    else:",
            "        raise TypeError(",
            "            f\"Cannot serialize object {obj} of type {type(obj)}. \"",
            "            \"To be serializable, \"",
            "            \"a class must implement the `get_config()` method.\"",
            "        )",
            "",
            "",
            "def serialize_dict(obj):",
            "    return {key: serialize_keras_object(value) for key, value in obj.items()}",
            "",
            "",
            "def deserialize_keras_object(",
            "    config, custom_objects=None, safe_mode=True, **kwargs",
            "):",
            "    \"\"\"Retrieve the object by deserializing the config dict.",
            "",
            "    The config dict is a Python dictionary that consists of a set of key-value",
            "    pairs, and represents a Keras object, such as an `Optimizer`, `Layer`,",
            "    `Metrics`, etc. The saving and loading library uses the following keys to",
            "    record information of a Keras object:",
            "",
            "    - `class_name`: String. This is the name of the class,",
            "      as exactly defined in the source",
            "      code, such as \"LossesContainer\".",
            "    - `config`: Dict. Library-defined or user-defined key-value pairs that store",
            "      the configuration of the object, as obtained by `object.get_config()`.",
            "    - `module`: String. The path of the python module, such as",
            "      \"keras.engine.compile_utils\". Built-in Keras classes",
            "      expect to have prefix `keras`.",
            "    - `registered_name`: String. The key the class is registered under via",
            "      `keras.utils.register_keras_serializable(package, name)` API. The key has",
            "      the format of '{package}>{name}', where `package` and `name` are the",
            "      arguments passed to `register_keras_serializable()`. If `name` is not",
            "      provided, it defaults to the class name. If `registered_name` successfully",
            "      resolves to a class (that was registered), the `class_name` and `config`",
            "      values in the dict will not be used. `registered_name` is only used for",
            "      non-built-in classes.",
            "",
            "    For example, the following dictionary represents the built-in Adam optimizer",
            "    with the relevant config:",
            "",
            "    ```python",
            "    dict_structure = {",
            "        \"class_name\": \"Adam\",",
            "        \"config\": {",
            "            \"amsgrad\": false,",
            "            \"beta_1\": 0.8999999761581421,",
            "            \"beta_2\": 0.9990000128746033,",
            "            \"decay\": 0.0,",
            "            \"epsilon\": 1e-07,",
            "            \"learning_rate\": 0.0010000000474974513,",
            "            \"name\": \"Adam\"",
            "        },",
            "        \"module\": \"keras.optimizers\",",
            "        \"registered_name\": None",
            "    }",
            "    # Returns an `Adam` instance identical to the original one.",
            "    deserialize_keras_object(dict_structure)",
            "    ```",
            "",
            "    If the class does not have an exported Keras namespace, the library tracks",
            "    it by its `module` and `class_name`. For example:",
            "",
            "    ```python",
            "    dict_structure = {",
            "      \"class_name\": \"LossesContainer\",",
            "      \"config\": {",
            "          \"losses\": [...],",
            "          \"total_loss_mean\": {...},",
            "      },",
            "      \"module\": \"keras.engine.compile_utils\",",
            "      \"registered_name\": \"LossesContainer\"",
            "    }",
            "",
            "    # Returns a `LossesContainer` instance identical to the original one.",
            "    deserialize_keras_object(dict_structure)",
            "    ```",
            "",
            "    And the following dictionary represents a user-customized `MeanSquaredError`",
            "    loss:",
            "",
            "    ```python",
            "    @keras.utils.register_keras_serializable(package='my_package')",
            "    class ModifiedMeanSquaredError(keras.losses.MeanSquaredError):",
            "      ...",
            "",
            "    dict_structure = {",
            "        \"class_name\": \"ModifiedMeanSquaredError\",",
            "        \"config\": {",
            "            \"fn\": \"mean_squared_error\",",
            "            \"name\": \"mean_squared_error\",",
            "            \"reduction\": \"auto\"",
            "        },",
            "        \"registered_name\": \"my_package>ModifiedMeanSquaredError\"",
            "    }",
            "    # Returns the `ModifiedMeanSquaredError` object",
            "    deserialize_keras_object(dict_structure)",
            "    ```",
            "",
            "    Args:",
            "        config: Python dict describing the object.",
            "        custom_objects: Python dict containing a mapping between custom",
            "            object names the corresponding classes or functions.",
            "        safe_mode: Boolean, whether to disallow unsafe `lambda` deserialization.",
            "            When `safe_mode=False`, loading an object has the potential to",
            "            trigger arbitrary code execution. This argument is only",
            "            applicable to the Keras v3 model format. Defaults to True.",
            "",
            "    Returns:",
            "      The object described by the `config` dictionary.",
            "",
            "    \"\"\"",
            "    safe_mode = in_safe_mode() or safe_mode",
            "",
            "    module_objects = kwargs.pop(\"module_objects\", None)",
            "    custom_objects = custom_objects or {}",
            "",
            "    # Fall back to legacy deserialization for all TF1 users or if",
            "    # wrapped by in_tf_saved_model_scope() to explicitly use legacy",
            "    # saved_model logic.",
            "    if not tf.__internal__.tf2.enabled() or in_tf_saved_model_scope():",
            "        return legacy_serialization.deserialize_keras_object(",
            "            config, module_objects, custom_objects",
            "        )",
            "",
            "    if config is None:",
            "        return None",
            "    if isinstance(config, PLAIN_TYPES):",
            "        if isinstance(config, str) and custom_objects.get(config) is not None:",
            "            # This is to deserialize plain functions which are serialized as",
            "            # string names by legacy saving formats.",
            "            return custom_objects[config]",
            "        return config",
            "    if isinstance(config, (list, tuple)):",
            "        return [",
            "            deserialize_keras_object(",
            "                x, custom_objects=custom_objects, safe_mode=safe_mode",
            "            )",
            "            for x in config",
            "        ]",
            "    if not isinstance(config, dict):",
            "        raise TypeError(f\"Could not parse config: {config}\")",
            "",
            "    if \"class_name\" not in config or \"config\" not in config:",
            "        return {",
            "            key: deserialize_keras_object(",
            "                value, custom_objects=custom_objects, safe_mode=safe_mode",
            "            )",
            "            for key, value in config.items()",
            "        }",
            "",
            "    class_name = config[\"class_name\"]",
            "    inner_config = config[\"config\"]",
            "",
            "    # Special cases:",
            "    if class_name == \"__tensor__\":",
            "        return tf.constant(inner_config[\"value\"], dtype=inner_config[\"dtype\"])",
            "    if class_name == \"__numpy__\":",
            "        return np.array(inner_config[\"value\"], dtype=inner_config[\"dtype\"])",
            "    if config[\"class_name\"] == \"__bytes__\":",
            "        return inner_config[\"value\"].encode(\"utf-8\")",
            "    if config[\"class_name\"] == \"__lambda__\":",
            "        if safe_mode:",
            "            raise ValueError(",
            "                \"Requested the deserialization of a `lambda` object. \"",
            "                \"This carries a potential risk of arbitrary code execution \"",
            "                \"and thus it is disallowed by default. If you trust the \"",
            "                \"source of the saved model, you can pass `safe_mode=False` to \"",
            "                \"the loading function in order to allow `lambda` loading.\"",
            "            )",
            "        return generic_utils.func_load(inner_config[\"value\"])",
            "    if config[\"class_name\"] == \"__typespec__\":",
            "        obj = _retrieve_class_or_fn(",
            "            config[\"spec_name\"],",
            "            config[\"registered_name\"],",
            "            config[\"module\"],",
            "            obj_type=\"class\",",
            "            full_config=config,",
            "            custom_objects=custom_objects,",
            "        )",
            "        # Conversion to TensorShape and tf.DType",
            "        inner_config = map(",
            "            lambda x: tf.TensorShape(x)",
            "            if isinstance(x, list)",
            "            else (getattr(tf, x) if hasattr(tf.dtypes, str(x)) else x),",
            "            inner_config,",
            "        )",
            "        return obj._deserialize(tuple(inner_config))",
            "    # TODO(fchollet): support for TypeSpec, CompositeTensor, tf.Dtype",
            "    # TODO(fchollet): consider special-casing tuples (which are currently",
            "    # deserialized as lists).",
            "",
            "    # Below: classes and functions.",
            "    module = config.get(\"module\", None)",
            "    registered_name = config.get(\"registered_name\", class_name)",
            "",
            "    if class_name == \"function\":",
            "        fn_name = inner_config",
            "        return _retrieve_class_or_fn(",
            "            fn_name,",
            "            registered_name,",
            "            module,",
            "            obj_type=\"function\",",
            "            full_config=config,",
            "            custom_objects=custom_objects,",
            "        )",
            "",
            "    # Below, handling of all classes.",
            "    # First, is it a shared object?",
            "    if \"shared_object_id\" in config:",
            "        obj = get_shared_object(config[\"shared_object_id\"])",
            "        if obj is not None:",
            "            return obj",
            "",
            "    cls = _retrieve_class_or_fn(",
            "        class_name,",
            "        registered_name,",
            "        module,",
            "        obj_type=\"class\",",
            "        full_config=config,",
            "        custom_objects=custom_objects,",
            "    )",
            "    if not hasattr(cls, \"from_config\"):",
            "        raise TypeError(",
            "            f\"Unable to reconstruct an instance of '{class_name}' because \"",
            "            f\"the class is missing a `from_config()` method. \"",
            "            f\"Full object config: {config}\"",
            "        )",
            "",
            "    # Instantiate the class from its config inside a custom object scope",
            "    # so that we can catch any custom objects that the config refers to.",
            "    with (",
            "        object_registration.custom_object_scope(custom_objects),",
            "        SafeModeScope(safe_mode),",
            "    ):",
            "        instance = cls.from_config(inner_config)",
            "        build_config = config.get(\"build_config\", None)",
            "        if build_config:",
            "            instance.build_from_config(build_config)",
            "        compile_config = config.get(\"compile_config\", None)",
            "        if compile_config:",
            "            instance.compile_from_config(compile_config)",
            "",
            "    if \"shared_object_id\" in config:",
            "        record_object_after_deserialization(",
            "            instance, config[\"shared_object_id\"]",
            "        )",
            "    return instance",
            "",
            "",
            "def _retrieve_class_or_fn(",
            "    name, registered_name, module, obj_type, full_config, custom_objects=None",
            "):",
            "    # If there is a custom object registered via",
            "    # `register_keras_serializable`, that takes precedence.",
            "    custom_obj = object_registration.get_registered_object(",
            "        registered_name, custom_objects=custom_objects",
            "    )",
            "    if custom_obj is not None:",
            "        return custom_obj",
            "",
            "    if module:",
            "        # If it's a Keras built-in object,",
            "        # we cannot always use direct import, because the exported",
            "        # module name might not match the package structure",
            "        # (e.g. experimental symbols).",
            "        if module == \"keras\" or module.startswith(\"keras.\"):",
            "            obj = tf_export.get_symbol_from_name(module + \".\" + name)",
            "            if obj is not None:",
            "                return obj",
            "",
            "        # Otherwise, attempt to retrieve the class object given the `module`",
            "        # and `class_name`. Import the module, find the class.",
            "        try:",
            "            mod = importlib.import_module(module)",
            "        except ModuleNotFoundError:",
            "            raise TypeError(",
            "                f\"Could not deserialize {obj_type} '{name}' because \"",
            "                f\"its parent module {module} cannot be imported. \"",
            "                f\"Full object config: {full_config}\"",
            "            )",
            "        obj = vars(mod).get(name, None)",
            "        if obj is not None:",
            "            return obj",
            "",
            "    raise TypeError(",
            "        f\"Could not locate {obj_type} '{name}'. \"",
            "        \"Make sure custom classes are decorated with \"",
            "        \"`@keras.utils.register_keras_serializable`. \"",
            "        f\"Full object config: {full_config}\"",
            "    )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "241": [
                "deserialize_keras_object"
            ],
            "328": [
                "deserialize_keras_object"
            ],
            "329": [
                "deserialize_keras_object"
            ],
            "356": [
                "deserialize_keras_object"
            ],
            "364": [
                "deserialize_keras_object"
            ],
            "439": [
                "deserialize_keras_object"
            ]
        },
        "addLocation": [
            "keras.saving.serialization_lib.deserialize_keras_object",
            "keras.saving.serialization_lib.Config.serialize",
            "keras.saving.serialization_lib.serialize_dict"
        ]
    },
    "keras/saving/serialization_lib_test.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 84,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 85,
                "PatchRowcode": " @test_utils.run_v2_only"
            },
            "2": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 86,
                "PatchRowcode": " class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):"
            },
            "3": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def roundtrip(self, obj, custom_objects=None):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+    def roundtrip(self, obj, custom_objects=None, safe_mode=True):"
            },
            "5": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "         serialized = serialization_lib.serialize_keras_object(obj)"
            },
            "6": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "         json_data = json.dumps(serialized)"
            },
            "7": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "         json_data = json.loads(json_data)"
            },
            "8": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 91,
                "PatchRowcode": "         deserialized = serialization_lib.deserialize_keras_object("
            },
            "9": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            json_data, custom_objects=custom_objects"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+            json_data, custom_objects=custom_objects, safe_mode=safe_mode"
            },
            "11": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "         )"
            },
            "12": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "         reserialized = serialization_lib.serialize_keras_object(deserialized)"
            },
            "13": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "         return serialized, deserialized, reserialized"
            },
            "14": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 169,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "     def test_lambda_fn(self):"
            },
            "16": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "         obj = {\"activation\": lambda x: x**2}"
            },
            "17": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        _, new_obj, _ = self.roundtrip(obj)"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+        with self.assertRaisesRegex(ValueError, \"arbitrary code execution\"):"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 173,
                "PatchRowcode": "+            self.roundtrip(obj, safe_mode=True)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+        _, new_obj, _ = self.roundtrip(obj, safe_mode=False)"
            },
            "22": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "         self.assertEqual(obj[\"activation\"](3), new_obj[\"activation\"](3))"
            },
            "23": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 177,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "     def test_lambda_layer(self):"
            },
            "25": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "         lmbda = keras.layers.Lambda(lambda x: x**2)"
            },
            "26": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        _, new_lmbda, _ = self.roundtrip(lmbda)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+        with self.assertRaisesRegex(ValueError, \"arbitrary code execution\"):"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+            self.roundtrip(lmbda, safe_mode=True)"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+        _, new_lmbda, _ = self.roundtrip(lmbda, safe_mode=False)"
            },
            "31": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "         x = tf.random.normal((2, 2))"
            },
            "32": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "         y1 = lmbda(x)"
            },
            "33": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "         y2 = new_lmbda(x)"
            }
        },
        "frontPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Tests for serialization_lib.\"\"\"",
            "",
            "import json",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "from absl.testing import parameterized",
            "",
            "import keras",
            "from keras.saving import serialization_lib",
            "from keras.saving.legacy import serialization as legacy_serialization",
            "from keras.testing_infra import test_utils",
            "",
            "",
            "def custom_fn(x):",
            "    return x**2",
            "",
            "",
            "class CustomLayer(keras.layers.Layer):",
            "    def __init__(self, factor):",
            "        super().__init__()",
            "        self.factor = factor",
            "",
            "    def call(self, x):",
            "        return x * self.factor",
            "",
            "    def get_config(self):",
            "        return {\"factor\": self.factor}",
            "",
            "",
            "class NestedCustomLayer(keras.layers.Layer):",
            "    def __init__(self, factor, dense=None, activation=None):",
            "        super().__init__()",
            "        self.factor = factor",
            "",
            "        if dense is None:",
            "            self.dense = keras.layers.Dense(1, activation=custom_fn)",
            "        else:",
            "            self.dense = serialization_lib.deserialize_keras_object(dense)",
            "        if activation is None:",
            "            self.activation = keras.layers.Activation(\"relu\")",
            "        else:",
            "            self.activation = serialization_lib.deserialize_keras_object(",
            "                activation",
            "            )",
            "",
            "    def call(self, x):",
            "        return self.dense(x * self.factor)",
            "",
            "    def get_config(self):",
            "        return {",
            "            \"factor\": self.factor,",
            "            \"dense\": self.dense,",
            "            \"activation\": self.activation,",
            "        }",
            "",
            "",
            "class WrapperLayer(keras.layers.Layer):",
            "    def __init__(self, layer, **kwargs):",
            "        super().__init__(**kwargs)",
            "        self.layer = layer",
            "",
            "    def call(self, x):",
            "        return self.layer(x)",
            "",
            "    def get_config(self):",
            "        config = super().get_config()",
            "        return {\"layer\": self.layer, **config}",
            "",
            "",
            "@test_utils.run_v2_only",
            "class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):",
            "    def roundtrip(self, obj, custom_objects=None):",
            "        serialized = serialization_lib.serialize_keras_object(obj)",
            "        json_data = json.dumps(serialized)",
            "        json_data = json.loads(json_data)",
            "        deserialized = serialization_lib.deserialize_keras_object(",
            "            json_data, custom_objects=custom_objects",
            "        )",
            "        reserialized = serialization_lib.serialize_keras_object(deserialized)",
            "        return serialized, deserialized, reserialized",
            "",
            "    @parameterized.named_parameters(",
            "        (\"str\", \"hello\"),",
            "        (\"bytes\", b\"hello\"),",
            "        (\"nparray_int\", np.array([0, 1])),",
            "        (\"nparray_float\", np.array([0.0, 1.0])),",
            "        (\"nparray_item\", np.float32(1.0)),",
            "        (\"plain_types_list\", [\"hello\", 0, \"world\", 1.0, True]),",
            "        (\"plain_types_dict\", {\"1\": \"hello\", \"2\": 0, \"3\": True}),",
            "        (\"plain_types_nested_dict\", {\"1\": \"hello\", \"2\": [True, False]}),",
            "    )",
            "    def test_simple_objects(self, obj):",
            "        serialized, _, reserialized = self.roundtrip(obj)",
            "        self.assertEqual(serialized, reserialized)",
            "",
            "    def test_builtin_layers(self):",
            "        serialized, _, reserialized = self.roundtrip(keras.layers.Dense(3))",
            "        self.assertEqual(serialized, reserialized)",
            "",
            "    def test_tensors_and_tensorshape(self):",
            "        x = tf.random.normal((2, 2), dtype=\"float64\")",
            "        obj = {\"x\": x}",
            "        _, new_obj, _ = self.roundtrip(obj)",
            "        self.assertAllClose(x, new_obj[\"x\"], atol=1e-5)",
            "",
            "        obj = {\"x.shape\": x.shape}",
            "        _, new_obj, _ = self.roundtrip(obj)",
            "        self.assertListEqual(x.shape.as_list(), new_obj[\"x.shape\"])",
            "",
            "    def test_custom_fn(self):",
            "        obj = {\"activation\": custom_fn}",
            "        serialized, _, reserialized = self.roundtrip(",
            "            obj, custom_objects={\"custom_fn\": custom_fn}",
            "        )",
            "        self.assertEqual(serialized, reserialized)",
            "",
            "        # Test inside layer",
            "        dense = keras.layers.Dense(1, activation=custom_fn)",
            "        dense.build((None, 2))",
            "        _, new_dense, _ = self.roundtrip(",
            "            dense, custom_objects={\"custom_fn\": custom_fn}",
            "        )",
            "        x = tf.random.normal((2, 2))",
            "        y1 = dense(x)",
            "        _ = new_dense(x)",
            "        new_dense.set_weights(dense.get_weights())",
            "        y2 = new_dense(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def test_custom_layer(self):",
            "        layer = CustomLayer(factor=2)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = layer(x)",
            "        _, new_layer, _ = self.roundtrip(",
            "            layer, custom_objects={\"CustomLayer\": CustomLayer}",
            "        )",
            "        y2 = new_layer(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "        layer = NestedCustomLayer(factor=2)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = layer(x)",
            "        _, new_layer, _ = self.roundtrip(",
            "            layer,",
            "            custom_objects={",
            "                \"NestedCustomLayer\": NestedCustomLayer,",
            "                \"custom_fn\": custom_fn,",
            "            },",
            "        )",
            "        _ = new_layer(x)",
            "        new_layer.set_weights(layer.get_weights())",
            "        y2 = new_layer(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def test_lambda_fn(self):",
            "        obj = {\"activation\": lambda x: x**2}",
            "        _, new_obj, _ = self.roundtrip(obj)",
            "        self.assertEqual(obj[\"activation\"](3), new_obj[\"activation\"](3))",
            "",
            "    def test_lambda_layer(self):",
            "        lmbda = keras.layers.Lambda(lambda x: x**2)",
            "        _, new_lmbda, _ = self.roundtrip(lmbda)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = lmbda(x)",
            "        y2 = new_lmbda(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def test_tensorspec(self):",
            "        inputs = keras.Input(type_spec=tf.TensorSpec((2, 2), tf.float32))",
            "        outputs = keras.layers.Dense(1)(inputs)",
            "        model = keras.Model(inputs, outputs)",
            "        _, new_model, _ = self.roundtrip(model)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = model(x)",
            "        new_model.set_weights(model.get_weights())",
            "        y2 = new_model(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def shared_inner_layer(self):",
            "        input_1 = keras.Input((2,))",
            "        input_2 = keras.Input((2,))",
            "        shared_layer = keras.layers.Dense(1)",
            "        output_1 = shared_layer(input_1)",
            "        wrapper_layer = WrapperLayer(shared_layer)",
            "        output_2 = wrapper_layer(input_2)",
            "        model = keras.Model([input_1, input_2], [output_1, output_2])",
            "        _, new_model, _ = self.roundtrip(",
            "            model, custom_objects={\"WrapperLayer\": WrapperLayer}",
            "        )",
            "",
            "        self.assertIs(model.layers[2], model.layers[3].layer)",
            "        self.assertIs(new_model.layers[2], new_model.layers[3].layer)",
            "",
            "    def test_functional_subclass(self):",
            "        class PlainFunctionalSubclass(keras.Model):",
            "            pass",
            "",
            "        inputs = keras.Input((2,))",
            "        outputs = keras.layers.Dense(1)(inputs)",
            "        model = PlainFunctionalSubclass(inputs, outputs)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = model(x)",
            "        _, new_model, _ = self.roundtrip(",
            "            model,",
            "            custom_objects={\"PlainFunctionalSubclass\": PlainFunctionalSubclass},",
            "        )",
            "        new_model.set_weights(model.get_weights())",
            "        y2 = new_model(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "        self.assertIsInstance(new_model, PlainFunctionalSubclass)",
            "",
            "        class FunctionalSubclassWCustomInit(keras.Model):",
            "            def __init__(self, num_units=1, **kwargs):",
            "                inputs = keras.Input((2,))",
            "                outputs = keras.layers.Dense(num_units)(inputs)",
            "                super().__init__(inputs, outputs)",
            "",
            "        model = FunctionalSubclassWCustomInit(num_units=2)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = model(x)",
            "        _, new_model, _ = self.roundtrip(",
            "            model,",
            "            custom_objects={",
            "                \"FunctionalSubclassWCustomInit\": FunctionalSubclassWCustomInit",
            "            },",
            "        )",
            "        new_model.set_weights(model.get_weights())",
            "        y2 = new_model(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "        self.assertIsInstance(new_model, FunctionalSubclassWCustomInit)",
            "",
            "    def test_shared_object(self):",
            "        class MyLayer(keras.layers.Layer):",
            "            def __init__(self, activation, **kwargs):",
            "                super().__init__(**kwargs)",
            "                if isinstance(activation, dict):",
            "                    self.activation = (",
            "                        serialization_lib.deserialize_keras_object(activation)",
            "                    )",
            "                else:",
            "                    self.activation = activation",
            "",
            "            def call(self, x):",
            "                return self.activation(x)",
            "",
            "            def get_config(self):",
            "                config = super().get_config()",
            "                config[\"activation\"] = self.activation",
            "                return config",
            "",
            "        class SharedActivation:",
            "            def __call__(self, x):",
            "                return x**2",
            "",
            "            def get_config(self):",
            "                return {}",
            "",
            "            @classmethod",
            "            def from_config(cls, config):",
            "                return cls()",
            "",
            "        shared_act = SharedActivation()",
            "        layer_1 = MyLayer(activation=shared_act)",
            "        layer_2 = MyLayer(activation=shared_act)",
            "        layers = [layer_1, layer_2]",
            "",
            "        with serialization_lib.ObjectSharingScope():",
            "            serialized, new_layers, reserialized = self.roundtrip(",
            "                layers,",
            "                custom_objects={",
            "                    \"MyLayer\": MyLayer,",
            "                    \"SharedActivation\": SharedActivation,",
            "                },",
            "            )",
            "        self.assertIn(\"shared_object_id\", serialized[0][\"config\"][\"activation\"])",
            "        obj_id = serialized[0][\"config\"][\"activation\"]",
            "        self.assertIn(\"shared_object_id\", serialized[1][\"config\"][\"activation\"])",
            "        self.assertEqual(obj_id, serialized[1][\"config\"][\"activation\"])",
            "        self.assertIs(layers[0].activation, layers[1].activation)",
            "        self.assertIs(new_layers[0].activation, new_layers[1].activation)",
            "",
            "",
            "@test_utils.run_v2_only",
            "class BackwardsCompatibilityTest(tf.test.TestCase, parameterized.TestCase):",
            "    def assert_old_format_can_be_deserialized(self, obj, custom_objects=None):",
            "        old_config = legacy_serialization.serialize_keras_object(obj)",
            "        revived = serialization_lib.deserialize_keras_object(",
            "            old_config, custom_objects=custom_objects",
            "        )",
            "        new_config_1 = serialization_lib.serialize_keras_object(obj)",
            "        new_config_2 = serialization_lib.serialize_keras_object(revived)",
            "        self.assertEqual(new_config_1, new_config_2)",
            "",
            "    def test_backwards_compatibility_with_old_serialized_format(self):",
            "        optimizer = keras.optimizers.Adam(learning_rate=0.1)",
            "        self.assert_old_format_can_be_deserialized(",
            "            optimizer, custom_objects=vars(keras.optimizers)",
            "        )",
            "        activation = keras.activations.relu",
            "        self.assert_old_format_can_be_deserialized(",
            "            activation, custom_objects=vars(keras.activations)",
            "        )",
            "        initializer = keras.initializers.VarianceScaling(scale=2.0)",
            "        self.assert_old_format_can_be_deserialized(",
            "            initializer, custom_objects=vars(keras.initializers)",
            "        )",
            "        regularizer = keras.regularizers.L2(0.3)",
            "        self.assert_old_format_can_be_deserialized(",
            "            regularizer, custom_objects=vars(keras.regularizers)",
            "        )",
            "        constraint = keras.constraints.UnitNorm()",
            "        self.assert_old_format_can_be_deserialized(",
            "            constraint, custom_objects=vars(keras.constraints)",
            "        )",
            "        layer = keras.layers.Dense(2)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects=vars(keras.layers)",
            "        )",
            "        layer = keras.layers.MultiHeadAttention(2, 4)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects=vars(keras.layers)",
            "        )",
            "",
            "        # Custom objects",
            "        layer = CustomLayer(2)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects={\"CustomLayer\": CustomLayer}",
            "        )",
            "        layer = keras.layers.Dense(1, activation=custom_fn)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects={**vars(keras.layers), \"custom_fn\": custom_fn}",
            "        )",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    tf.test.main()"
        ],
        "afterPatchFile": [
            "# Copyright 2022 The TensorFlow Authors. All Rights Reserved.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "# ==============================================================================",
            "\"\"\"Tests for serialization_lib.\"\"\"",
            "",
            "import json",
            "",
            "import numpy as np",
            "import tensorflow.compat.v2 as tf",
            "from absl.testing import parameterized",
            "",
            "import keras",
            "from keras.saving import serialization_lib",
            "from keras.saving.legacy import serialization as legacy_serialization",
            "from keras.testing_infra import test_utils",
            "",
            "",
            "def custom_fn(x):",
            "    return x**2",
            "",
            "",
            "class CustomLayer(keras.layers.Layer):",
            "    def __init__(self, factor):",
            "        super().__init__()",
            "        self.factor = factor",
            "",
            "    def call(self, x):",
            "        return x * self.factor",
            "",
            "    def get_config(self):",
            "        return {\"factor\": self.factor}",
            "",
            "",
            "class NestedCustomLayer(keras.layers.Layer):",
            "    def __init__(self, factor, dense=None, activation=None):",
            "        super().__init__()",
            "        self.factor = factor",
            "",
            "        if dense is None:",
            "            self.dense = keras.layers.Dense(1, activation=custom_fn)",
            "        else:",
            "            self.dense = serialization_lib.deserialize_keras_object(dense)",
            "        if activation is None:",
            "            self.activation = keras.layers.Activation(\"relu\")",
            "        else:",
            "            self.activation = serialization_lib.deserialize_keras_object(",
            "                activation",
            "            )",
            "",
            "    def call(self, x):",
            "        return self.dense(x * self.factor)",
            "",
            "    def get_config(self):",
            "        return {",
            "            \"factor\": self.factor,",
            "            \"dense\": self.dense,",
            "            \"activation\": self.activation,",
            "        }",
            "",
            "",
            "class WrapperLayer(keras.layers.Layer):",
            "    def __init__(self, layer, **kwargs):",
            "        super().__init__(**kwargs)",
            "        self.layer = layer",
            "",
            "    def call(self, x):",
            "        return self.layer(x)",
            "",
            "    def get_config(self):",
            "        config = super().get_config()",
            "        return {\"layer\": self.layer, **config}",
            "",
            "",
            "@test_utils.run_v2_only",
            "class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):",
            "    def roundtrip(self, obj, custom_objects=None, safe_mode=True):",
            "        serialized = serialization_lib.serialize_keras_object(obj)",
            "        json_data = json.dumps(serialized)",
            "        json_data = json.loads(json_data)",
            "        deserialized = serialization_lib.deserialize_keras_object(",
            "            json_data, custom_objects=custom_objects, safe_mode=safe_mode",
            "        )",
            "        reserialized = serialization_lib.serialize_keras_object(deserialized)",
            "        return serialized, deserialized, reserialized",
            "",
            "    @parameterized.named_parameters(",
            "        (\"str\", \"hello\"),",
            "        (\"bytes\", b\"hello\"),",
            "        (\"nparray_int\", np.array([0, 1])),",
            "        (\"nparray_float\", np.array([0.0, 1.0])),",
            "        (\"nparray_item\", np.float32(1.0)),",
            "        (\"plain_types_list\", [\"hello\", 0, \"world\", 1.0, True]),",
            "        (\"plain_types_dict\", {\"1\": \"hello\", \"2\": 0, \"3\": True}),",
            "        (\"plain_types_nested_dict\", {\"1\": \"hello\", \"2\": [True, False]}),",
            "    )",
            "    def test_simple_objects(self, obj):",
            "        serialized, _, reserialized = self.roundtrip(obj)",
            "        self.assertEqual(serialized, reserialized)",
            "",
            "    def test_builtin_layers(self):",
            "        serialized, _, reserialized = self.roundtrip(keras.layers.Dense(3))",
            "        self.assertEqual(serialized, reserialized)",
            "",
            "    def test_tensors_and_tensorshape(self):",
            "        x = tf.random.normal((2, 2), dtype=\"float64\")",
            "        obj = {\"x\": x}",
            "        _, new_obj, _ = self.roundtrip(obj)",
            "        self.assertAllClose(x, new_obj[\"x\"], atol=1e-5)",
            "",
            "        obj = {\"x.shape\": x.shape}",
            "        _, new_obj, _ = self.roundtrip(obj)",
            "        self.assertListEqual(x.shape.as_list(), new_obj[\"x.shape\"])",
            "",
            "    def test_custom_fn(self):",
            "        obj = {\"activation\": custom_fn}",
            "        serialized, _, reserialized = self.roundtrip(",
            "            obj, custom_objects={\"custom_fn\": custom_fn}",
            "        )",
            "        self.assertEqual(serialized, reserialized)",
            "",
            "        # Test inside layer",
            "        dense = keras.layers.Dense(1, activation=custom_fn)",
            "        dense.build((None, 2))",
            "        _, new_dense, _ = self.roundtrip(",
            "            dense, custom_objects={\"custom_fn\": custom_fn}",
            "        )",
            "        x = tf.random.normal((2, 2))",
            "        y1 = dense(x)",
            "        _ = new_dense(x)",
            "        new_dense.set_weights(dense.get_weights())",
            "        y2 = new_dense(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def test_custom_layer(self):",
            "        layer = CustomLayer(factor=2)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = layer(x)",
            "        _, new_layer, _ = self.roundtrip(",
            "            layer, custom_objects={\"CustomLayer\": CustomLayer}",
            "        )",
            "        y2 = new_layer(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "        layer = NestedCustomLayer(factor=2)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = layer(x)",
            "        _, new_layer, _ = self.roundtrip(",
            "            layer,",
            "            custom_objects={",
            "                \"NestedCustomLayer\": NestedCustomLayer,",
            "                \"custom_fn\": custom_fn,",
            "            },",
            "        )",
            "        _ = new_layer(x)",
            "        new_layer.set_weights(layer.get_weights())",
            "        y2 = new_layer(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def test_lambda_fn(self):",
            "        obj = {\"activation\": lambda x: x**2}",
            "        with self.assertRaisesRegex(ValueError, \"arbitrary code execution\"):",
            "            self.roundtrip(obj, safe_mode=True)",
            "",
            "        _, new_obj, _ = self.roundtrip(obj, safe_mode=False)",
            "        self.assertEqual(obj[\"activation\"](3), new_obj[\"activation\"](3))",
            "",
            "    def test_lambda_layer(self):",
            "        lmbda = keras.layers.Lambda(lambda x: x**2)",
            "        with self.assertRaisesRegex(ValueError, \"arbitrary code execution\"):",
            "            self.roundtrip(lmbda, safe_mode=True)",
            "",
            "        _, new_lmbda, _ = self.roundtrip(lmbda, safe_mode=False)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = lmbda(x)",
            "        y2 = new_lmbda(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def test_tensorspec(self):",
            "        inputs = keras.Input(type_spec=tf.TensorSpec((2, 2), tf.float32))",
            "        outputs = keras.layers.Dense(1)(inputs)",
            "        model = keras.Model(inputs, outputs)",
            "        _, new_model, _ = self.roundtrip(model)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = model(x)",
            "        new_model.set_weights(model.get_weights())",
            "        y2 = new_model(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "",
            "    def shared_inner_layer(self):",
            "        input_1 = keras.Input((2,))",
            "        input_2 = keras.Input((2,))",
            "        shared_layer = keras.layers.Dense(1)",
            "        output_1 = shared_layer(input_1)",
            "        wrapper_layer = WrapperLayer(shared_layer)",
            "        output_2 = wrapper_layer(input_2)",
            "        model = keras.Model([input_1, input_2], [output_1, output_2])",
            "        _, new_model, _ = self.roundtrip(",
            "            model, custom_objects={\"WrapperLayer\": WrapperLayer}",
            "        )",
            "",
            "        self.assertIs(model.layers[2], model.layers[3].layer)",
            "        self.assertIs(new_model.layers[2], new_model.layers[3].layer)",
            "",
            "    def test_functional_subclass(self):",
            "        class PlainFunctionalSubclass(keras.Model):",
            "            pass",
            "",
            "        inputs = keras.Input((2,))",
            "        outputs = keras.layers.Dense(1)(inputs)",
            "        model = PlainFunctionalSubclass(inputs, outputs)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = model(x)",
            "        _, new_model, _ = self.roundtrip(",
            "            model,",
            "            custom_objects={\"PlainFunctionalSubclass\": PlainFunctionalSubclass},",
            "        )",
            "        new_model.set_weights(model.get_weights())",
            "        y2 = new_model(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "        self.assertIsInstance(new_model, PlainFunctionalSubclass)",
            "",
            "        class FunctionalSubclassWCustomInit(keras.Model):",
            "            def __init__(self, num_units=1, **kwargs):",
            "                inputs = keras.Input((2,))",
            "                outputs = keras.layers.Dense(num_units)(inputs)",
            "                super().__init__(inputs, outputs)",
            "",
            "        model = FunctionalSubclassWCustomInit(num_units=2)",
            "        x = tf.random.normal((2, 2))",
            "        y1 = model(x)",
            "        _, new_model, _ = self.roundtrip(",
            "            model,",
            "            custom_objects={",
            "                \"FunctionalSubclassWCustomInit\": FunctionalSubclassWCustomInit",
            "            },",
            "        )",
            "        new_model.set_weights(model.get_weights())",
            "        y2 = new_model(x)",
            "        self.assertAllClose(y1, y2, atol=1e-5)",
            "        self.assertIsInstance(new_model, FunctionalSubclassWCustomInit)",
            "",
            "    def test_shared_object(self):",
            "        class MyLayer(keras.layers.Layer):",
            "            def __init__(self, activation, **kwargs):",
            "                super().__init__(**kwargs)",
            "                if isinstance(activation, dict):",
            "                    self.activation = (",
            "                        serialization_lib.deserialize_keras_object(activation)",
            "                    )",
            "                else:",
            "                    self.activation = activation",
            "",
            "            def call(self, x):",
            "                return self.activation(x)",
            "",
            "            def get_config(self):",
            "                config = super().get_config()",
            "                config[\"activation\"] = self.activation",
            "                return config",
            "",
            "        class SharedActivation:",
            "            def __call__(self, x):",
            "                return x**2",
            "",
            "            def get_config(self):",
            "                return {}",
            "",
            "            @classmethod",
            "            def from_config(cls, config):",
            "                return cls()",
            "",
            "        shared_act = SharedActivation()",
            "        layer_1 = MyLayer(activation=shared_act)",
            "        layer_2 = MyLayer(activation=shared_act)",
            "        layers = [layer_1, layer_2]",
            "",
            "        with serialization_lib.ObjectSharingScope():",
            "            serialized, new_layers, reserialized = self.roundtrip(",
            "                layers,",
            "                custom_objects={",
            "                    \"MyLayer\": MyLayer,",
            "                    \"SharedActivation\": SharedActivation,",
            "                },",
            "            )",
            "        self.assertIn(\"shared_object_id\", serialized[0][\"config\"][\"activation\"])",
            "        obj_id = serialized[0][\"config\"][\"activation\"]",
            "        self.assertIn(\"shared_object_id\", serialized[1][\"config\"][\"activation\"])",
            "        self.assertEqual(obj_id, serialized[1][\"config\"][\"activation\"])",
            "        self.assertIs(layers[0].activation, layers[1].activation)",
            "        self.assertIs(new_layers[0].activation, new_layers[1].activation)",
            "",
            "",
            "@test_utils.run_v2_only",
            "class BackwardsCompatibilityTest(tf.test.TestCase, parameterized.TestCase):",
            "    def assert_old_format_can_be_deserialized(self, obj, custom_objects=None):",
            "        old_config = legacy_serialization.serialize_keras_object(obj)",
            "        revived = serialization_lib.deserialize_keras_object(",
            "            old_config, custom_objects=custom_objects",
            "        )",
            "        new_config_1 = serialization_lib.serialize_keras_object(obj)",
            "        new_config_2 = serialization_lib.serialize_keras_object(revived)",
            "        self.assertEqual(new_config_1, new_config_2)",
            "",
            "    def test_backwards_compatibility_with_old_serialized_format(self):",
            "        optimizer = keras.optimizers.Adam(learning_rate=0.1)",
            "        self.assert_old_format_can_be_deserialized(",
            "            optimizer, custom_objects=vars(keras.optimizers)",
            "        )",
            "        activation = keras.activations.relu",
            "        self.assert_old_format_can_be_deserialized(",
            "            activation, custom_objects=vars(keras.activations)",
            "        )",
            "        initializer = keras.initializers.VarianceScaling(scale=2.0)",
            "        self.assert_old_format_can_be_deserialized(",
            "            initializer, custom_objects=vars(keras.initializers)",
            "        )",
            "        regularizer = keras.regularizers.L2(0.3)",
            "        self.assert_old_format_can_be_deserialized(",
            "            regularizer, custom_objects=vars(keras.regularizers)",
            "        )",
            "        constraint = keras.constraints.UnitNorm()",
            "        self.assert_old_format_can_be_deserialized(",
            "            constraint, custom_objects=vars(keras.constraints)",
            "        )",
            "        layer = keras.layers.Dense(2)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects=vars(keras.layers)",
            "        )",
            "        layer = keras.layers.MultiHeadAttention(2, 4)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects=vars(keras.layers)",
            "        )",
            "",
            "        # Custom objects",
            "        layer = CustomLayer(2)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects={\"CustomLayer\": CustomLayer}",
            "        )",
            "        layer = keras.layers.Dense(1, activation=custom_fn)",
            "        self.assert_old_format_can_be_deserialized(",
            "            layer, custom_objects={**vars(keras.layers), \"custom_fn\": custom_fn}",
            "        )",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    tf.test.main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "87": [
                "SerializationLibTest",
                "roundtrip"
            ],
            "92": [
                "SerializationLibTest",
                "roundtrip"
            ],
            "172": [
                "SerializationLibTest",
                "test_lambda_fn"
            ],
            "177": [
                "SerializationLibTest",
                "test_lambda_layer"
            ]
        },
        "addLocation": []
    }
}