{
    "superset/views/datasource/views.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from sqlalchemy.exc import NoSuchTableError"
            },
            "1": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " from sqlalchemy.orm.exc import NoResultFound"
            },
            "2": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from superset import app, db, event_logger"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+from superset import db, event_logger"
            },
            "5": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from superset.commands.utils import populate_owners"
            },
            "6": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " from superset.connectors.connector_registry import ConnectorRegistry"
            },
            "7": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " from superset.connectors.sqla.utils import get_physical_table_metadata"
            },
            "8": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 81,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "         if \"owners\" in datasource_dict and orm_datasource.owner_class is not None:"
            },
            "10": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "             # Check ownership"
            },
            "11": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if app.config.get(\"OLD_API_CHECK_DATASET_OWNERSHIP\"):"
            },
            "12": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # mimic the behavior of the new dataset command that"
            },
            "13": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # checks ownership and ensures that non-admins aren't locked out"
            },
            "14": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # of the object"
            },
            "15": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                try:"
            },
            "16": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    check_ownership(orm_datasource)"
            },
            "17": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                except SupersetSecurityException as ex:"
            },
            "18": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    raise DatasetForbiddenError() from ex"
            },
            "19": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                user = security_manager.get_user_by_id(g.user.id)"
            },
            "20": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                datasource_dict[\"owners\"] = populate_owners("
            },
            "21": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    user, datasource_dict[\"owners\"], default_to_user=False"
            },
            "22": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                )"
            },
            "23": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            else:"
            },
            "24": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                # legacy behavior"
            },
            "25": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                datasource_dict[\"owners\"] = ("
            },
            "26": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    db.session.query(orm_datasource.owner_class)"
            },
            "27": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    .filter("
            },
            "28": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        orm_datasource.owner_class.id.in_("
            },
            "29": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            datasource_dict[\"owners\"] or []"
            },
            "30": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        )"
            },
            "31": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    )"
            },
            "32": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    .all()"
            },
            "33": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                )"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+            try:"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+                check_ownership(orm_datasource)"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+            except SupersetSecurityException as ex:"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+                raise DatasetForbiddenError() from ex"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+        user = security_manager.get_user_by_id(g.user.id)"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+        datasource_dict[\"owners\"] = populate_owners("
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+            user, datasource_dict[\"owners\"], default_to_user=False"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+        )"
            },
            "43": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": 93,
                "PatchRowcode": " "
            },
            "44": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "         duplicates = ["
            },
            "45": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "             name"
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "from collections import Counter",
            "from typing import Any",
            "",
            "from flask import g, request",
            "from flask_appbuilder import expose",
            "from flask_appbuilder.api import rison",
            "from flask_appbuilder.security.decorators import has_access_api",
            "from flask_babel import _",
            "from marshmallow import ValidationError",
            "from sqlalchemy.exc import NoSuchTableError",
            "from sqlalchemy.orm.exc import NoResultFound",
            "",
            "from superset import app, db, event_logger",
            "from superset.commands.utils import populate_owners",
            "from superset.connectors.connector_registry import ConnectorRegistry",
            "from superset.connectors.sqla.utils import get_physical_table_metadata",
            "from superset.datasets.commands.exceptions import (",
            "    DatasetForbiddenError,",
            "    DatasetNotFoundError,",
            ")",
            "from superset.exceptions import SupersetException, SupersetSecurityException",
            "from superset.extensions import security_manager",
            "from superset.models.core import Database",
            "from superset.superset_typing import FlaskResponse",
            "from superset.views.base import (",
            "    api,",
            "    BaseSupersetView,",
            "    check_ownership,",
            "    handle_api_exception,",
            "    json_error_response,",
            ")",
            "from superset.views.datasource.schemas import (",
            "    ExternalMetadataParams,",
            "    ExternalMetadataSchema,",
            "    get_external_metadata_schema,",
            ")",
            "from superset.views.utils import sanitize_datasource_data",
            "",
            "",
            "class Datasource(BaseSupersetView):",
            "    \"\"\"Datasource-related views\"\"\"",
            "",
            "    @expose(\"/save/\", methods=[\"POST\"])",
            "    @event_logger.log_this_with_context(",
            "        action=lambda self, *args, **kwargs: f\"{self.__class__.__name__}.save\",",
            "        log_to_statsd=False,",
            "    )",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    def save(self) -> FlaskResponse:",
            "        data = request.form.get(\"data\")",
            "        if not isinstance(data, str):",
            "            return json_error_response(_(\"Request missing data field.\"), status=500)",
            "",
            "        datasource_dict = json.loads(data)",
            "        datasource_id = datasource_dict.get(\"id\")",
            "        datasource_type = datasource_dict.get(\"type\")",
            "        database_id = datasource_dict[\"database\"].get(\"id\")",
            "        orm_datasource = ConnectorRegistry.get_datasource(",
            "            datasource_type, datasource_id, db.session",
            "        )",
            "        orm_datasource.database_id = database_id",
            "",
            "        if \"owners\" in datasource_dict and orm_datasource.owner_class is not None:",
            "            # Check ownership",
            "            if app.config.get(\"OLD_API_CHECK_DATASET_OWNERSHIP\"):",
            "                # mimic the behavior of the new dataset command that",
            "                # checks ownership and ensures that non-admins aren't locked out",
            "                # of the object",
            "                try:",
            "                    check_ownership(orm_datasource)",
            "                except SupersetSecurityException as ex:",
            "                    raise DatasetForbiddenError() from ex",
            "                user = security_manager.get_user_by_id(g.user.id)",
            "                datasource_dict[\"owners\"] = populate_owners(",
            "                    user, datasource_dict[\"owners\"], default_to_user=False",
            "                )",
            "            else:",
            "                # legacy behavior",
            "                datasource_dict[\"owners\"] = (",
            "                    db.session.query(orm_datasource.owner_class)",
            "                    .filter(",
            "                        orm_datasource.owner_class.id.in_(",
            "                            datasource_dict[\"owners\"] or []",
            "                        )",
            "                    )",
            "                    .all()",
            "                )",
            "",
            "        duplicates = [",
            "            name",
            "            for name, count in Counter(",
            "                [col[\"column_name\"] for col in datasource_dict[\"columns\"]]",
            "            ).items()",
            "            if count > 1",
            "        ]",
            "        if duplicates:",
            "            return json_error_response(",
            "                _(",
            "                    \"Duplicate column name(s): %(columns)s\",",
            "                    columns=\",\".join(duplicates),",
            "                ),",
            "                status=409,",
            "            )",
            "        orm_datasource.update_from_object(datasource_dict)",
            "        data = orm_datasource.data",
            "        db.session.commit()",
            "",
            "        return self.json_response(sanitize_datasource_data(data))",
            "",
            "    @expose(\"/get/<datasource_type>/<datasource_id>/\")",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    def get(self, datasource_type: str, datasource_id: int) -> FlaskResponse:",
            "        datasource = ConnectorRegistry.get_datasource(",
            "            datasource_type, datasource_id, db.session",
            "        )",
            "        return self.json_response(sanitize_datasource_data(datasource.data))",
            "",
            "    @expose(\"/external_metadata/<datasource_type>/<datasource_id>/\")",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    def external_metadata(",
            "        self, datasource_type: str, datasource_id: int",
            "    ) -> FlaskResponse:",
            "        \"\"\"Gets column info from the source system\"\"\"",
            "        datasource = ConnectorRegistry.get_datasource(",
            "            datasource_type, datasource_id, db.session",
            "        )",
            "        try:",
            "            external_metadata = datasource.external_metadata()",
            "        except SupersetException as ex:",
            "            return json_error_response(str(ex), status=400)",
            "        return self.json_response(external_metadata)",
            "",
            "    @expose(\"/external_metadata_by_name/\")",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    @rison(get_external_metadata_schema)",
            "    def external_metadata_by_name(self, **kwargs: Any) -> FlaskResponse:",
            "        \"\"\"Gets table metadata from the source system and SQLAlchemy inspector\"\"\"",
            "        try:",
            "            params: ExternalMetadataParams = ExternalMetadataSchema().load(",
            "                kwargs.get(\"rison\")",
            "            )",
            "        except ValidationError as err:",
            "            return json_error_response(str(err), status=400)",
            "",
            "        datasource = ConnectorRegistry.get_datasource_by_name(",
            "            session=db.session,",
            "            datasource_type=params[\"datasource_type\"],",
            "            database_name=params[\"database_name\"],",
            "            schema=params[\"schema_name\"],",
            "            datasource_name=params[\"table_name\"],",
            "        )",
            "        try:",
            "            if datasource is not None:",
            "                # Get columns from Superset metadata",
            "                external_metadata = datasource.external_metadata()",
            "            else:",
            "                # Use the SQLAlchemy inspector to get columns",
            "                database = (",
            "                    db.session.query(Database)",
            "                    .filter_by(database_name=params[\"database_name\"])",
            "                    .one()",
            "                )",
            "                external_metadata = get_physical_table_metadata(",
            "                    database=database,",
            "                    table_name=params[\"table_name\"],",
            "                    schema_name=params[\"schema_name\"],",
            "                )",
            "        except (NoResultFound, NoSuchTableError) as ex:",
            "            raise DatasetNotFoundError() from ex",
            "        return self.json_response(external_metadata)"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "from collections import Counter",
            "from typing import Any",
            "",
            "from flask import g, request",
            "from flask_appbuilder import expose",
            "from flask_appbuilder.api import rison",
            "from flask_appbuilder.security.decorators import has_access_api",
            "from flask_babel import _",
            "from marshmallow import ValidationError",
            "from sqlalchemy.exc import NoSuchTableError",
            "from sqlalchemy.orm.exc import NoResultFound",
            "",
            "from superset import db, event_logger",
            "from superset.commands.utils import populate_owners",
            "from superset.connectors.connector_registry import ConnectorRegistry",
            "from superset.connectors.sqla.utils import get_physical_table_metadata",
            "from superset.datasets.commands.exceptions import (",
            "    DatasetForbiddenError,",
            "    DatasetNotFoundError,",
            ")",
            "from superset.exceptions import SupersetException, SupersetSecurityException",
            "from superset.extensions import security_manager",
            "from superset.models.core import Database",
            "from superset.superset_typing import FlaskResponse",
            "from superset.views.base import (",
            "    api,",
            "    BaseSupersetView,",
            "    check_ownership,",
            "    handle_api_exception,",
            "    json_error_response,",
            ")",
            "from superset.views.datasource.schemas import (",
            "    ExternalMetadataParams,",
            "    ExternalMetadataSchema,",
            "    get_external_metadata_schema,",
            ")",
            "from superset.views.utils import sanitize_datasource_data",
            "",
            "",
            "class Datasource(BaseSupersetView):",
            "    \"\"\"Datasource-related views\"\"\"",
            "",
            "    @expose(\"/save/\", methods=[\"POST\"])",
            "    @event_logger.log_this_with_context(",
            "        action=lambda self, *args, **kwargs: f\"{self.__class__.__name__}.save\",",
            "        log_to_statsd=False,",
            "    )",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    def save(self) -> FlaskResponse:",
            "        data = request.form.get(\"data\")",
            "        if not isinstance(data, str):",
            "            return json_error_response(_(\"Request missing data field.\"), status=500)",
            "",
            "        datasource_dict = json.loads(data)",
            "        datasource_id = datasource_dict.get(\"id\")",
            "        datasource_type = datasource_dict.get(\"type\")",
            "        database_id = datasource_dict[\"database\"].get(\"id\")",
            "        orm_datasource = ConnectorRegistry.get_datasource(",
            "            datasource_type, datasource_id, db.session",
            "        )",
            "        orm_datasource.database_id = database_id",
            "",
            "        if \"owners\" in datasource_dict and orm_datasource.owner_class is not None:",
            "            # Check ownership",
            "            try:",
            "                check_ownership(orm_datasource)",
            "            except SupersetSecurityException as ex:",
            "                raise DatasetForbiddenError() from ex",
            "",
            "        user = security_manager.get_user_by_id(g.user.id)",
            "        datasource_dict[\"owners\"] = populate_owners(",
            "            user, datasource_dict[\"owners\"], default_to_user=False",
            "        )",
            "",
            "        duplicates = [",
            "            name",
            "            for name, count in Counter(",
            "                [col[\"column_name\"] for col in datasource_dict[\"columns\"]]",
            "            ).items()",
            "            if count > 1",
            "        ]",
            "        if duplicates:",
            "            return json_error_response(",
            "                _(",
            "                    \"Duplicate column name(s): %(columns)s\",",
            "                    columns=\",\".join(duplicates),",
            "                ),",
            "                status=409,",
            "            )",
            "        orm_datasource.update_from_object(datasource_dict)",
            "        data = orm_datasource.data",
            "        db.session.commit()",
            "",
            "        return self.json_response(sanitize_datasource_data(data))",
            "",
            "    @expose(\"/get/<datasource_type>/<datasource_id>/\")",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    def get(self, datasource_type: str, datasource_id: int) -> FlaskResponse:",
            "        datasource = ConnectorRegistry.get_datasource(",
            "            datasource_type, datasource_id, db.session",
            "        )",
            "        return self.json_response(sanitize_datasource_data(datasource.data))",
            "",
            "    @expose(\"/external_metadata/<datasource_type>/<datasource_id>/\")",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    def external_metadata(",
            "        self, datasource_type: str, datasource_id: int",
            "    ) -> FlaskResponse:",
            "        \"\"\"Gets column info from the source system\"\"\"",
            "        datasource = ConnectorRegistry.get_datasource(",
            "            datasource_type, datasource_id, db.session",
            "        )",
            "        try:",
            "            external_metadata = datasource.external_metadata()",
            "        except SupersetException as ex:",
            "            return json_error_response(str(ex), status=400)",
            "        return self.json_response(external_metadata)",
            "",
            "    @expose(\"/external_metadata_by_name/\")",
            "    @has_access_api",
            "    @api",
            "    @handle_api_exception",
            "    @rison(get_external_metadata_schema)",
            "    def external_metadata_by_name(self, **kwargs: Any) -> FlaskResponse:",
            "        \"\"\"Gets table metadata from the source system and SQLAlchemy inspector\"\"\"",
            "        try:",
            "            params: ExternalMetadataParams = ExternalMetadataSchema().load(",
            "                kwargs.get(\"rison\")",
            "            )",
            "        except ValidationError as err:",
            "            return json_error_response(str(err), status=400)",
            "",
            "        datasource = ConnectorRegistry.get_datasource_by_name(",
            "            session=db.session,",
            "            datasource_type=params[\"datasource_type\"],",
            "            database_name=params[\"database_name\"],",
            "            schema=params[\"schema_name\"],",
            "            datasource_name=params[\"table_name\"],",
            "        )",
            "        try:",
            "            if datasource is not None:",
            "                # Get columns from Superset metadata",
            "                external_metadata = datasource.external_metadata()",
            "            else:",
            "                # Use the SQLAlchemy inspector to get columns",
            "                database = (",
            "                    db.session.query(Database)",
            "                    .filter_by(database_name=params[\"database_name\"])",
            "                    .one()",
            "                )",
            "                external_metadata = get_physical_table_metadata(",
            "                    database=database,",
            "                    table_name=params[\"table_name\"],",
            "                    schema_name=params[\"schema_name\"],",
            "                )",
            "        except (NoResultFound, NoSuchTableError) as ex:",
            "            raise DatasetNotFoundError() from ex",
            "        return self.json_response(external_metadata)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "30": [],
            "84": [
                "Datasource",
                "save"
            ],
            "85": [
                "Datasource",
                "save"
            ],
            "86": [
                "Datasource",
                "save"
            ],
            "87": [
                "Datasource",
                "save"
            ],
            "88": [
                "Datasource",
                "save"
            ],
            "89": [
                "Datasource",
                "save"
            ],
            "90": [
                "Datasource",
                "save"
            ],
            "91": [
                "Datasource",
                "save"
            ],
            "92": [
                "Datasource",
                "save"
            ],
            "93": [
                "Datasource",
                "save"
            ],
            "94": [
                "Datasource",
                "save"
            ],
            "95": [
                "Datasource",
                "save"
            ],
            "96": [
                "Datasource",
                "save"
            ],
            "97": [
                "Datasource",
                "save"
            ],
            "98": [
                "Datasource",
                "save"
            ],
            "99": [
                "Datasource",
                "save"
            ],
            "100": [
                "Datasource",
                "save"
            ],
            "101": [
                "Datasource",
                "save"
            ],
            "102": [
                "Datasource",
                "save"
            ],
            "103": [
                "Datasource",
                "save"
            ],
            "104": [
                "Datasource",
                "save"
            ],
            "105": [
                "Datasource",
                "save"
            ],
            "106": [
                "Datasource",
                "save"
            ]
        },
        "addLocation": []
    }
}