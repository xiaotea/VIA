{
    "git/cmd.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "     Iterator,"
            },
            "1": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 47,
                "PatchRowcode": "     List,"
            },
            "2": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 48,
                "PatchRowcode": "     Mapping,"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+    Optional,"
            },
            "4": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "     Sequence,"
            },
            "5": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 51,
                "PatchRowcode": "     TYPE_CHECKING,"
            },
            "6": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "     TextIO,"
            },
            "7": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "         Callable[[bytes, \"Repo\", \"DiffIndex\"], None],"
            },
            "8": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "     ],"
            },
            "9": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "     stderr_handler: Union[None, Callable[[AnyStr], None], Callable[[List[AnyStr]], None]],"
            },
            "10": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    finalizer: Union[None, Callable[[Union[subprocess.Popen, \"Git.AutoInterrupt\"]], None]] = None,"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+    finalizer: Union[None, Callable[[Union[Popen, \"Git.AutoInterrupt\"]], None]] = None,"
            },
            "12": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 107,
                "PatchRowcode": "     decode_streams: bool = True,"
            },
            "13": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": 108,
                "PatchRowcode": "     kill_after_timeout: Union[None, float] = None,"
            },
            "14": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 109,
                "PatchRowcode": " ) -> None:"
            },
            "15": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 208,
                "PatchRowcode": "         finalizer(process)"
            },
            "16": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 209,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 210,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+def _safer_popen_windows("
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+    command: Union[str, Sequence[Any]],"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+    *,"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+    shell: bool = False,"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 215,
                "PatchRowcode": "+    env: Optional[Mapping[str, str]] = None,"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 216,
                "PatchRowcode": "+    **kwargs: Any,"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 217,
                "PatchRowcode": "+) -> Popen:"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 218,
                "PatchRowcode": "+    \"\"\"Call :class:`subprocess.Popen` on Windows but don't include a CWD in the search."
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 220,
                "PatchRowcode": "+    This avoids an untrusted search path condition where a file like ``git.exe`` in a"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 221,
                "PatchRowcode": "+    malicious repository would be run when GitPython operates on the repository. The"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 222,
                "PatchRowcode": "+    process using GitPython may have an untrusted repository's working tree as its"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 223,
                "PatchRowcode": "+    current working directory. Some operations may temporarily change to that directory"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 224,
                "PatchRowcode": "+    before running a subprocess. In addition, while by default GitPython does not run"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 225,
                "PatchRowcode": "+    external commands with a shell, it can be made to do so, in which case the CWD of"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 226,
                "PatchRowcode": "+    the subprocess, which GitPython usually sets to a repository working tree, can"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 227,
                "PatchRowcode": "+    itself be searched automatically by the shell. This wrapper covers all those cases."
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 228,
                "PatchRowcode": "+"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 229,
                "PatchRowcode": "+    :note: This currently works by setting the ``NoDefaultCurrentDirectoryInExePath``"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 230,
                "PatchRowcode": "+        environment variable during subprocess creation. It also takes care of passing"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 231,
                "PatchRowcode": "+        Windows-specific process creation flags, but that is unrelated to path search."
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 232,
                "PatchRowcode": "+"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 233,
                "PatchRowcode": "+    :note: The current implementation contains a race condition on :attr:`os.environ`."
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 234,
                "PatchRowcode": "+        GitPython isn't thread-safe, but a program using it on one thread should ideally"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+        be able to mutate :attr:`os.environ` on another, without unpredictable results."
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 236,
                "PatchRowcode": "+        See comments in https://github.com/gitpython-developers/GitPython/pull/1650."
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+    \"\"\""
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 238,
                "PatchRowcode": "+    # CREATE_NEW_PROCESS_GROUP is needed for some ways of killing it afterwards. See:"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+    # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 240,
                "PatchRowcode": "+    # https://docs.python.org/3/library/subprocess.html#subprocess.CREATE_NEW_PROCESS_GROUP"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 241,
                "PatchRowcode": "+    creationflags = subprocess.CREATE_NO_WINDOW | subprocess.CREATE_NEW_PROCESS_GROUP"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 242,
                "PatchRowcode": "+"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 243,
                "PatchRowcode": "+    # When using a shell, the shell is the direct subprocess, so the variable must be"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 244,
                "PatchRowcode": "+    # set in its environment, to affect its search behavior. (The \"1\" can be any value.)"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 245,
                "PatchRowcode": "+    if shell:"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+        safer_env = {} if env is None else dict(env)"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 247,
                "PatchRowcode": "+        safer_env[\"NoDefaultCurrentDirectoryInExePath\"] = \"1\""
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+    else:"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+        safer_env = env"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+    # When not using a shell, the current process does the search in a CreateProcessW"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 252,
                "PatchRowcode": "+    # API call, so the variable must be set in our environment. With a shell, this is"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 253,
                "PatchRowcode": "+    # unnecessary, in versions where https://github.com/python/cpython/issues/101283 is"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 254,
                "PatchRowcode": "+    # patched. If not, in the rare case the ComSpec environment variable is unset, the"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 255,
                "PatchRowcode": "+    # shell is searched for unsafely. Setting NoDefaultCurrentDirectoryInExePath in all"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+    # cases, as here, is simpler and protects against that. (The \"1\" can be any value.)"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 257,
                "PatchRowcode": "+    with patch_env(\"NoDefaultCurrentDirectoryInExePath\", \"1\"):"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+        return Popen("
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+            command,"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+            shell=shell,"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+            env=safer_env,"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+            creationflags=creationflags,"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+            **kwargs,"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+        )"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 265,
                "PatchRowcode": "+"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 266,
                "PatchRowcode": "+"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 267,
                "PatchRowcode": "+if os.name == \"nt\":"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 268,
                "PatchRowcode": "+    safer_popen = _safer_popen_windows"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 269,
                "PatchRowcode": "+else:"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 270,
                "PatchRowcode": "+    safer_popen = Popen"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 271,
                "PatchRowcode": "+"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+"
            },
            "80": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": 273,
                "PatchRowcode": " def dashify(string: str) -> str:"
            },
            "81": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": 274,
                "PatchRowcode": "     return string.replace(\"_\", \"-\")"
            },
            "82": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 275,
                "PatchRowcode": " "
            },
            "83": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": 288,
                "PatchRowcode": " ## -- End Utilities -- @}"
            },
            "84": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 289,
                "PatchRowcode": " "
            },
            "85": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 290,
                "PatchRowcode": " "
            },
            "86": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-if os.name == \"nt\":"
            },
            "87": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # CREATE_NEW_PROCESS_GROUP is needed to allow killing it afterwards. See:"
            },
            "88": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal"
            },
            "89": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    PROC_CREATIONFLAGS = subprocess.CREATE_NO_WINDOW | subprocess.CREATE_NEW_PROCESS_GROUP"
            },
            "90": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-else:"
            },
            "91": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    PROC_CREATIONFLAGS = 0"
            },
            "92": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "93": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "94": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 291,
                "PatchRowcode": " class Git(LazyMixin):"
            },
            "95": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 292,
                "PatchRowcode": "     \"\"\"The Git class manages communication with the Git binary."
            },
            "96": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 293,
                "PatchRowcode": " "
            },
            "97": {
                "beforePatchRowNumber": 992,
                "afterPatchRowNumber": 1047,
                "PatchRowcode": "                     redacted_command,"
            },
            "98": {
                "beforePatchRowNumber": 993,
                "afterPatchRowNumber": 1048,
                "PatchRowcode": "                     '\"kill_after_timeout\" feature is not supported on Windows.',"
            },
            "99": {
                "beforePatchRowNumber": 994,
                "afterPatchRowNumber": 1049,
                "PatchRowcode": "                 )"
            },
            "100": {
                "beforePatchRowNumber": 995,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # Only search PATH, not CWD. This must be in the *caller* environment. The \"1\" can be any value."
            },
            "101": {
                "beforePatchRowNumber": 996,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            maybe_patch_caller_env = patch_env(\"NoDefaultCurrentDirectoryInExePath\", \"1\")"
            },
            "102": {
                "beforePatchRowNumber": 997,
                "afterPatchRowNumber": 1050,
                "PatchRowcode": "         else:"
            },
            "103": {
                "beforePatchRowNumber": 998,
                "afterPatchRowNumber": 1051,
                "PatchRowcode": "             cmd_not_found_exception = FileNotFoundError"
            },
            "104": {
                "beforePatchRowNumber": 999,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            maybe_patch_caller_env = contextlib.nullcontext()"
            },
            "105": {
                "beforePatchRowNumber": 1000,
                "afterPatchRowNumber": 1052,
                "PatchRowcode": "         # END handle"
            },
            "106": {
                "beforePatchRowNumber": 1001,
                "afterPatchRowNumber": 1053,
                "PatchRowcode": " "
            },
            "107": {
                "beforePatchRowNumber": 1002,
                "afterPatchRowNumber": 1054,
                "PatchRowcode": "         stdout_sink = PIPE if with_stdout else getattr(subprocess, \"DEVNULL\", None) or open(os.devnull, \"wb\")"
            },
            "108": {
                "beforePatchRowNumber": 1011,
                "afterPatchRowNumber": 1063,
                "PatchRowcode": "             universal_newlines,"
            },
            "109": {
                "beforePatchRowNumber": 1012,
                "afterPatchRowNumber": 1064,
                "PatchRowcode": "         )"
            },
            "110": {
                "beforePatchRowNumber": 1013,
                "afterPatchRowNumber": 1065,
                "PatchRowcode": "         try:"
            },
            "111": {
                "beforePatchRowNumber": 1014,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            with maybe_patch_caller_env:"
            },
            "112": {
                "beforePatchRowNumber": 1015,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                proc = Popen("
            },
            "113": {
                "beforePatchRowNumber": 1016,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    command,"
            },
            "114": {
                "beforePatchRowNumber": 1017,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    env=env,"
            },
            "115": {
                "beforePatchRowNumber": 1018,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    cwd=cwd,"
            },
            "116": {
                "beforePatchRowNumber": 1019,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    bufsize=-1,"
            },
            "117": {
                "beforePatchRowNumber": 1020,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    stdin=(istream or DEVNULL),"
            },
            "118": {
                "beforePatchRowNumber": 1021,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    stderr=PIPE,"
            },
            "119": {
                "beforePatchRowNumber": 1022,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    stdout=stdout_sink,"
            },
            "120": {
                "beforePatchRowNumber": 1023,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    shell=shell,"
            },
            "121": {
                "beforePatchRowNumber": 1024,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    universal_newlines=universal_newlines,"
            },
            "122": {
                "beforePatchRowNumber": 1025,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    creationflags=PROC_CREATIONFLAGS,"
            },
            "123": {
                "beforePatchRowNumber": 1026,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    **subprocess_kwargs,"
            },
            "124": {
                "beforePatchRowNumber": 1027,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                )"
            },
            "125": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1066,
                "PatchRowcode": "+            proc = safer_popen("
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1067,
                "PatchRowcode": "+                command,"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1068,
                "PatchRowcode": "+                env=env,"
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1069,
                "PatchRowcode": "+                cwd=cwd,"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1070,
                "PatchRowcode": "+                bufsize=-1,"
            },
            "130": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1071,
                "PatchRowcode": "+                stdin=(istream or DEVNULL),"
            },
            "131": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1072,
                "PatchRowcode": "+                stderr=PIPE,"
            },
            "132": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1073,
                "PatchRowcode": "+                stdout=stdout_sink,"
            },
            "133": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1074,
                "PatchRowcode": "+                shell=shell,"
            },
            "134": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1075,
                "PatchRowcode": "+                universal_newlines=universal_newlines,"
            },
            "135": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1076,
                "PatchRowcode": "+                **subprocess_kwargs,"
            },
            "136": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1077,
                "PatchRowcode": "+            )"
            },
            "137": {
                "beforePatchRowNumber": 1028,
                "afterPatchRowNumber": 1078,
                "PatchRowcode": "         except cmd_not_found_exception as err:"
            },
            "138": {
                "beforePatchRowNumber": 1029,
                "afterPatchRowNumber": 1079,
                "PatchRowcode": "             raise GitCommandNotFound(redacted_command, err) from err"
            },
            "139": {
                "beforePatchRowNumber": 1030,
                "afterPatchRowNumber": 1080,
                "PatchRowcode": "         else:"
            }
        },
        "frontPatchFile": [
            "# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors",
            "#",
            "# This module is part of GitPython and is released under the",
            "# 3-Clause BSD License: https://opensource.org/license/bsd-3-clause/",
            "",
            "from __future__ import annotations",
            "",
            "import re",
            "import contextlib",
            "import io",
            "import logging",
            "import os",
            "import signal",
            "from subprocess import Popen, PIPE, DEVNULL",
            "import subprocess",
            "import threading",
            "from textwrap import dedent",
            "",
            "from git.compat import defenc, force_bytes, safe_decode",
            "from git.exc import (",
            "    CommandError,",
            "    GitCommandError,",
            "    GitCommandNotFound,",
            "    UnsafeOptionError,",
            "    UnsafeProtocolError,",
            ")",
            "from git.util import (",
            "    LazyMixin,",
            "    cygpath,",
            "    expand_path,",
            "    is_cygwin_git,",
            "    patch_env,",
            "    remove_password_if_present,",
            "    stream_copy,",
            ")",
            "",
            "# typing ---------------------------------------------------------------------------",
            "",
            "from typing import (",
            "    Any,",
            "    AnyStr,",
            "    BinaryIO,",
            "    Callable,",
            "    Dict,",
            "    IO,",
            "    Iterator,",
            "    List,",
            "    Mapping,",
            "    Sequence,",
            "    TYPE_CHECKING,",
            "    TextIO,",
            "    Tuple,",
            "    Union,",
            "    cast,",
            "    overload,",
            ")",
            "",
            "from git.types import PathLike, Literal, TBD",
            "",
            "if TYPE_CHECKING:",
            "    from git.repo.base import Repo",
            "    from git.diff import DiffIndex",
            "",
            "",
            "# ---------------------------------------------------------------------------------",
            "",
            "execute_kwargs = {",
            "    \"istream\",",
            "    \"with_extended_output\",",
            "    \"with_exceptions\",",
            "    \"as_process\",",
            "    \"output_stream\",",
            "    \"stdout_as_string\",",
            "    \"kill_after_timeout\",",
            "    \"with_stdout\",",
            "    \"universal_newlines\",",
            "    \"shell\",",
            "    \"env\",",
            "    \"max_chunk_size\",",
            "    \"strip_newline_in_stdout\",",
            "}",
            "",
            "log = logging.getLogger(__name__)",
            "log.addHandler(logging.NullHandler())",
            "",
            "__all__ = (\"Git\",)",
            "",
            "",
            "# ==============================================================================",
            "## @name Utilities",
            "# ------------------------------------------------------------------------------",
            "# Documentation",
            "## @{",
            "",
            "",
            "def handle_process_output(",
            "    process: \"Git.AutoInterrupt\" | Popen,",
            "    stdout_handler: Union[",
            "        None,",
            "        Callable[[AnyStr], None],",
            "        Callable[[List[AnyStr]], None],",
            "        Callable[[bytes, \"Repo\", \"DiffIndex\"], None],",
            "    ],",
            "    stderr_handler: Union[None, Callable[[AnyStr], None], Callable[[List[AnyStr]], None]],",
            "    finalizer: Union[None, Callable[[Union[subprocess.Popen, \"Git.AutoInterrupt\"]], None]] = None,",
            "    decode_streams: bool = True,",
            "    kill_after_timeout: Union[None, float] = None,",
            ") -> None:",
            "    \"\"\"Register for notifications to learn that process output is ready to read, and",
            "    dispatch lines to the respective line handlers.",
            "",
            "    This function returns once the finalizer returns.",
            "",
            "    :param process: :class:`subprocess.Popen` instance",
            "    :param stdout_handler: f(stdout_line_string), or None",
            "    :param stderr_handler: f(stderr_line_string), or None",
            "    :param finalizer: f(proc) - wait for proc to finish",
            "    :param decode_streams:",
            "        Assume stdout/stderr streams are binary and decode them before pushing",
            "        their contents to handlers.",
            "        Set it to False if ``universal_newlines == True`` (then streams are in",
            "        text mode) or if decoding must happen later (i.e. for Diffs).",
            "    :param kill_after_timeout:",
            "        float or None, Default = None",
            "        To specify a timeout in seconds for the git command, after which the process",
            "        should be killed.",
            "    \"\"\"",
            "",
            "    # Use 2 \"pump\" threads and wait for both to finish.",
            "    def pump_stream(",
            "        cmdline: List[str],",
            "        name: str,",
            "        stream: Union[BinaryIO, TextIO],",
            "        is_decode: bool,",
            "        handler: Union[None, Callable[[Union[bytes, str]], None]],",
            "    ) -> None:",
            "        try:",
            "            for line in stream:",
            "                if handler:",
            "                    if is_decode:",
            "                        assert isinstance(line, bytes)",
            "                        line_str = line.decode(defenc)",
            "                        handler(line_str)",
            "                    else:",
            "                        handler(line)",
            "",
            "        except Exception as ex:",
            "            log.error(f\"Pumping {name!r} of cmd({remove_password_if_present(cmdline)}) failed due to: {ex!r}\")",
            "            if \"I/O operation on closed file\" not in str(ex):",
            "                # Only reraise if the error was not due to the stream closing",
            "                raise CommandError([f\"<{name}-pump>\"] + remove_password_if_present(cmdline), ex) from ex",
            "        finally:",
            "            stream.close()",
            "",
            "    if hasattr(process, \"proc\"):",
            "        process = cast(\"Git.AutoInterrupt\", process)",
            "        cmdline: str | Tuple[str, ...] | List[str] = getattr(process.proc, \"args\", \"\")",
            "        p_stdout = process.proc.stdout if process.proc else None",
            "        p_stderr = process.proc.stderr if process.proc else None",
            "    else:",
            "        process = cast(Popen, process)  # type: ignore [redundant-cast]",
            "        cmdline = getattr(process, \"args\", \"\")",
            "        p_stdout = process.stdout",
            "        p_stderr = process.stderr",
            "",
            "    if not isinstance(cmdline, (tuple, list)):",
            "        cmdline = cmdline.split()",
            "",
            "    pumps: List[Tuple[str, IO, Callable[..., None] | None]] = []",
            "    if p_stdout:",
            "        pumps.append((\"stdout\", p_stdout, stdout_handler))",
            "    if p_stderr:",
            "        pumps.append((\"stderr\", p_stderr, stderr_handler))",
            "",
            "    threads: List[threading.Thread] = []",
            "",
            "    for name, stream, handler in pumps:",
            "        t = threading.Thread(target=pump_stream, args=(cmdline, name, stream, decode_streams, handler))",
            "        t.daemon = True",
            "        t.start()",
            "        threads.append(t)",
            "",
            "    # FIXME: Why join? Will block if stdin needs feeding...",
            "    for t in threads:",
            "        t.join(timeout=kill_after_timeout)",
            "        if t.is_alive():",
            "            if isinstance(process, Git.AutoInterrupt):",
            "                process._terminate()",
            "            else:  # Don't want to deal with the other case.",
            "                raise RuntimeError(",
            "                    \"Thread join() timed out in cmd.handle_process_output().\"",
            "                    f\" kill_after_timeout={kill_after_timeout} seconds\"",
            "                )",
            "            if stderr_handler:",
            "                error_str: Union[str, bytes] = (",
            "                    \"error: process killed because it timed out.\" f\" kill_after_timeout={kill_after_timeout} seconds\"",
            "                )",
            "                if not decode_streams and isinstance(p_stderr, BinaryIO):",
            "                    #  Assume stderr_handler needs binary input.",
            "                    error_str = cast(str, error_str)",
            "                    error_str = error_str.encode()",
            "                # We ignore typing on the next line because mypy does not like",
            "                # the way we inferred that stderr takes str or bytes.",
            "                stderr_handler(error_str)  # type: ignore",
            "",
            "    if finalizer:",
            "        finalizer(process)",
            "",
            "",
            "def dashify(string: str) -> str:",
            "    return string.replace(\"_\", \"-\")",
            "",
            "",
            "def slots_to_dict(self: \"Git\", exclude: Sequence[str] = ()) -> Dict[str, Any]:",
            "    return {s: getattr(self, s) for s in self.__slots__ if s not in exclude}",
            "",
            "",
            "def dict_to_slots_and__excluded_are_none(self: object, d: Mapping[str, Any], excluded: Sequence[str] = ()) -> None:",
            "    for k, v in d.items():",
            "        setattr(self, k, v)",
            "    for k in excluded:",
            "        setattr(self, k, None)",
            "",
            "",
            "## -- End Utilities -- @}",
            "",
            "",
            "if os.name == \"nt\":",
            "    # CREATE_NEW_PROCESS_GROUP is needed to allow killing it afterwards. See:",
            "    # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal",
            "    PROC_CREATIONFLAGS = subprocess.CREATE_NO_WINDOW | subprocess.CREATE_NEW_PROCESS_GROUP",
            "else:",
            "    PROC_CREATIONFLAGS = 0",
            "",
            "",
            "class Git(LazyMixin):",
            "    \"\"\"The Git class manages communication with the Git binary.",
            "",
            "    It provides a convenient interface to calling the Git binary, such as in::",
            "",
            "     g = Git( git_dir )",
            "     g.init()                   # calls 'git init' program",
            "     rval = g.ls_files()        # calls 'git ls-files' program",
            "",
            "    ``Debugging``",
            "        Set the GIT_PYTHON_TRACE environment variable print each invocation",
            "        of the command to stdout.",
            "        Set its value to 'full' to see details about the returned values.",
            "    \"\"\"",
            "",
            "    __slots__ = (",
            "        \"_working_dir\",",
            "        \"cat_file_all\",",
            "        \"cat_file_header\",",
            "        \"_version_info\",",
            "        \"_git_options\",",
            "        \"_persistent_git_options\",",
            "        \"_environment\",",
            "    )",
            "",
            "    _excluded_ = (\"cat_file_all\", \"cat_file_header\", \"_version_info\")",
            "",
            "    re_unsafe_protocol = re.compile(r\"(.+)::.+\")",
            "",
            "    def __getstate__(self) -> Dict[str, Any]:",
            "        return slots_to_dict(self, exclude=self._excluded_)",
            "",
            "    def __setstate__(self, d: Dict[str, Any]) -> None:",
            "        dict_to_slots_and__excluded_are_none(self, d, excluded=self._excluded_)",
            "",
            "    # CONFIGURATION",
            "",
            "    git_exec_name = \"git\"",
            "    \"\"\"Default git command that should work on Linux, Windows, and other systems.\"\"\"",
            "",
            "    GIT_PYTHON_TRACE = os.environ.get(\"GIT_PYTHON_TRACE\", False)",
            "    \"\"\"Enables debugging of GitPython's git commands.\"\"\"",
            "",
            "    USE_SHELL = False",
            "    \"\"\"Deprecated. If set to True, a shell will be used when executing git commands.",
            "",
            "    Prior to GitPython 2.0.8, this had a narrow purpose in suppressing console windows",
            "    in graphical Windows applications. In 2.0.8 and higher, it provides no benefit, as",
            "    GitPython solves that problem more robustly and safely by using the",
            "    ``CREATE_NO_WINDOW`` process creation flag on Windows.",
            "",
            "    Code that uses ``USE_SHELL = True`` or that passes ``shell=True`` to any GitPython",
            "    functions should be updated to use the default value of ``False`` instead. ``True``",
            "    is unsafe unless the effect of shell expansions is fully considered and accounted",
            "    for, which is not possible under most circumstances.",
            "",
            "    See:",
            "    - :meth:`Git.execute` (on the ``shell`` parameter).",
            "    - https://github.com/gitpython-developers/GitPython/commit/0d9390866f9ce42870d3116094cd49e0019a970a",
            "    - https://learn.microsoft.com/en-us/windows/win32/procthread/process-creation-flags",
            "    \"\"\"",
            "",
            "    _git_exec_env_var = \"GIT_PYTHON_GIT_EXECUTABLE\"",
            "    _refresh_env_var = \"GIT_PYTHON_REFRESH\"",
            "",
            "    GIT_PYTHON_GIT_EXECUTABLE = None",
            "    \"\"\"Provide the full path to the git executable. Otherwise it assumes git is in the path.",
            "",
            "    Note that the git executable is actually found during the refresh step in",
            "    the top level ``__init__``.",
            "    \"\"\"",
            "",
            "    @classmethod",
            "    def refresh(cls, path: Union[None, PathLike] = None) -> bool:",
            "        \"\"\"This gets called by the refresh function (see the top level __init__).\"\"\"",
            "        # Discern which path to refresh with.",
            "        if path is not None:",
            "            new_git = os.path.expanduser(path)",
            "            new_git = os.path.abspath(new_git)",
            "        else:",
            "            new_git = os.environ.get(cls._git_exec_env_var, cls.git_exec_name)",
            "",
            "        # Keep track of the old and new git executable path.",
            "        old_git = cls.GIT_PYTHON_GIT_EXECUTABLE",
            "        cls.GIT_PYTHON_GIT_EXECUTABLE = new_git",
            "",
            "        # Test if the new git executable path is valid. A GitCommandNotFound error is",
            "        # spawned by us. A PermissionError is spawned if the git executable cannot be",
            "        # executed for whatever reason.",
            "        has_git = False",
            "        try:",
            "            cls().version()",
            "            has_git = True",
            "        except (GitCommandNotFound, PermissionError):",
            "            pass",
            "",
            "        # Warn or raise exception if test failed.",
            "        if not has_git:",
            "            err = (",
            "                dedent(",
            "                    \"\"\"\\",
            "                Bad git executable.",
            "                The git executable must be specified in one of the following ways:",
            "                    - be included in your $PATH",
            "                    - be set via $%s",
            "                    - explicitly set via git.refresh()",
            "                \"\"\"",
            "                )",
            "                % cls._git_exec_env_var",
            "            )",
            "",
            "            # Revert to whatever the old_git was.",
            "            cls.GIT_PYTHON_GIT_EXECUTABLE = old_git",
            "",
            "            if old_git is None:",
            "                # On the first refresh (when GIT_PYTHON_GIT_EXECUTABLE is None) we only",
            "                # are quiet, warn, or error depending on the GIT_PYTHON_REFRESH value.",
            "",
            "                # Determine what the user wants to happen during the initial refresh we",
            "                # expect GIT_PYTHON_REFRESH to either be unset or be one of the",
            "                # following values:",
            "                #",
            "                #   0|q|quiet|s|silence|n|none",
            "                #   1|w|warn|warning",
            "                #   2|r|raise|e|error",
            "",
            "                mode = os.environ.get(cls._refresh_env_var, \"raise\").lower()",
            "",
            "                quiet = [\"quiet\", \"q\", \"silence\", \"s\", \"none\", \"n\", \"0\"]",
            "                warn = [\"warn\", \"w\", \"warning\", \"1\"]",
            "                error = [\"error\", \"e\", \"raise\", \"r\", \"2\"]",
            "",
            "                if mode in quiet:",
            "                    pass",
            "                elif mode in warn or mode in error:",
            "                    err = (",
            "                        dedent(",
            "                            \"\"\"\\",
            "                        %s",
            "                        All git commands will error until this is rectified.",
            "",
            "                        This initial warning can be silenced or aggravated in the future by setting the",
            "                        $%s environment variable. Use one of the following values:",
            "                            - %s: for no warning or exception",
            "                            - %s: for a printed warning",
            "                            - %s: for a raised exception",
            "",
            "                        Example:",
            "                            export %s=%s",
            "                        \"\"\"",
            "                        )",
            "                        % (",
            "                            err,",
            "                            cls._refresh_env_var,",
            "                            \"|\".join(quiet),",
            "                            \"|\".join(warn),",
            "                            \"|\".join(error),",
            "                            cls._refresh_env_var,",
            "                            quiet[0],",
            "                        )",
            "                    )",
            "",
            "                    if mode in warn:",
            "                        print(\"WARNING: %s\" % err)",
            "                    else:",
            "                        raise ImportError(err)",
            "                else:",
            "                    err = (",
            "                        dedent(",
            "                            \"\"\"\\",
            "                        %s environment variable has been set but it has been set with an invalid value.",
            "",
            "                        Use only the following values:",
            "                            - %s: for no warning or exception",
            "                            - %s: for a printed warning",
            "                            - %s: for a raised exception",
            "                        \"\"\"",
            "                        )",
            "                        % (",
            "                            cls._refresh_env_var,",
            "                            \"|\".join(quiet),",
            "                            \"|\".join(warn),",
            "                            \"|\".join(error),",
            "                        )",
            "                    )",
            "                    raise ImportError(err)",
            "",
            "                # We get here if this was the init refresh and the refresh mode was not",
            "                # error. Go ahead and set the GIT_PYTHON_GIT_EXECUTABLE such that we",
            "                # discern the difference between a first import and a second import.",
            "                cls.GIT_PYTHON_GIT_EXECUTABLE = cls.git_exec_name",
            "            else:",
            "                # After the first refresh (when GIT_PYTHON_GIT_EXECUTABLE is no longer",
            "                # None) we raise an exception.",
            "                raise GitCommandNotFound(\"git\", err)",
            "",
            "        return has_git",
            "",
            "    @classmethod",
            "    def is_cygwin(cls) -> bool:",
            "        return is_cygwin_git(cls.GIT_PYTHON_GIT_EXECUTABLE)",
            "",
            "    @overload",
            "    @classmethod",
            "    def polish_url(cls, url: str, is_cygwin: Literal[False] = ...) -> str:",
            "        ...",
            "",
            "    @overload",
            "    @classmethod",
            "    def polish_url(cls, url: str, is_cygwin: Union[None, bool] = None) -> str:",
            "        ...",
            "",
            "    @classmethod",
            "    def polish_url(cls, url: str, is_cygwin: Union[None, bool] = None) -> PathLike:",
            "        \"\"\"Remove any backslashes from urls to be written in config files.",
            "",
            "        Windows might create config files containing paths with backslashes,",
            "        but git stops liking them as it will escape the backslashes. Hence we",
            "        undo the escaping just to be sure.",
            "        \"\"\"",
            "        if is_cygwin is None:",
            "            is_cygwin = cls.is_cygwin()",
            "",
            "        if is_cygwin:",
            "            url = cygpath(url)",
            "        else:",
            "            url = os.path.expandvars(url)",
            "            if url.startswith(\"~\"):",
            "                url = os.path.expanduser(url)",
            "            url = url.replace(\"\\\\\\\\\", \"\\\\\").replace(\"\\\\\", \"/\")",
            "        return url",
            "",
            "    @classmethod",
            "    def check_unsafe_protocols(cls, url: str) -> None:",
            "        \"\"\"Check for unsafe protocols.",
            "",
            "        Apart from the usual protocols (http, git, ssh),",
            "        Git allows \"remote helpers\" that have the form ``<transport>::<address>``.",
            "        One of these helpers (``ext::``) can be used to invoke any arbitrary command.",
            "",
            "        See:",
            "",
            "        - https://git-scm.com/docs/gitremote-helpers",
            "        - https://git-scm.com/docs/git-remote-ext",
            "        \"\"\"",
            "        match = cls.re_unsafe_protocol.match(url)",
            "        if match:",
            "            protocol = match.group(1)",
            "            raise UnsafeProtocolError(",
            "                f\"The `{protocol}::` protocol looks suspicious, use `allow_unsafe_protocols=True` to allow it.\"",
            "            )",
            "",
            "    @classmethod",
            "    def check_unsafe_options(cls, options: List[str], unsafe_options: List[str]) -> None:",
            "        \"\"\"Check for unsafe options.",
            "",
            "        Some options that are passed to `git <command>` can be used to execute",
            "        arbitrary commands, this are blocked by default.",
            "        \"\"\"",
            "        # Options can be of the form `foo` or `--foo bar` `--foo=bar`,",
            "        # so we need to check if they start with \"--foo\" or if they are equal to \"foo\".",
            "        bare_unsafe_options = [option.lstrip(\"-\") for option in unsafe_options]",
            "        for option in options:",
            "            for unsafe_option, bare_option in zip(unsafe_options, bare_unsafe_options):",
            "                if option.startswith(unsafe_option) or option == bare_option:",
            "                    raise UnsafeOptionError(",
            "                        f\"{unsafe_option} is not allowed, use `allow_unsafe_options=True` to allow it.\"",
            "                    )",
            "",
            "    class AutoInterrupt:",
            "        \"\"\"Process wrapper that terminates the wrapped process on finalization.",
            "",
            "        This kills/interrupts the stored process instance once this instance goes out of",
            "        scope. It is used to prevent processes piling up in case iterators stop reading.",
            "",
            "        All attributes are wired through to the contained process object.",
            "",
            "        The wait method is overridden to perform automatic status code checking and",
            "        possibly raise.",
            "        \"\"\"",
            "",
            "        __slots__ = (\"proc\", \"args\", \"status\")",
            "",
            "        # If this is non-zero it will override any status code during",
            "        # _terminate, used to prevent race conditions in testing.",
            "        _status_code_if_terminate: int = 0",
            "",
            "        def __init__(self, proc: Union[None, subprocess.Popen], args: Any) -> None:",
            "            self.proc = proc",
            "            self.args = args",
            "            self.status: Union[int, None] = None",
            "",
            "        def _terminate(self) -> None:",
            "            \"\"\"Terminate the underlying process.\"\"\"",
            "            if self.proc is None:",
            "                return",
            "",
            "            proc = self.proc",
            "            self.proc = None",
            "            if proc.stdin:",
            "                proc.stdin.close()",
            "            if proc.stdout:",
            "                proc.stdout.close()",
            "            if proc.stderr:",
            "                proc.stderr.close()",
            "            # Did the process finish already so we have a return code?",
            "            try:",
            "                if proc.poll() is not None:",
            "                    self.status = self._status_code_if_terminate or proc.poll()",
            "                    return",
            "            except OSError as ex:",
            "                log.info(\"Ignored error after process had died: %r\", ex)",
            "",
            "            # It can be that nothing really exists anymore...",
            "            if os is None or getattr(os, \"kill\", None) is None:",
            "                return",
            "",
            "            # Try to kill it.",
            "            try:",
            "                proc.terminate()",
            "                status = proc.wait()  # Ensure the process goes away.",
            "",
            "                self.status = self._status_code_if_terminate or status",
            "            except OSError as ex:",
            "                log.info(\"Ignored error after process had died: %r\", ex)",
            "            # END exception handling",
            "",
            "        def __del__(self) -> None:",
            "            self._terminate()",
            "",
            "        def __getattr__(self, attr: str) -> Any:",
            "            return getattr(self.proc, attr)",
            "",
            "        # TODO: Bad choice to mimic `proc.wait()` but with different args.",
            "        def wait(self, stderr: Union[None, str, bytes] = b\"\") -> int:",
            "            \"\"\"Wait for the process and return its status code.",
            "",
            "            :param stderr: Previously read value of stderr, in case stderr is already closed.",
            "            :warn: May deadlock if output or error pipes are used and not handled separately.",
            "            :raise GitCommandError: If the return status is not 0.",
            "            \"\"\"",
            "            if stderr is None:",
            "                stderr_b = b\"\"",
            "            stderr_b = force_bytes(data=stderr, encoding=\"utf-8\")",
            "            status: Union[int, None]",
            "            if self.proc is not None:",
            "                status = self.proc.wait()",
            "                p_stderr = self.proc.stderr",
            "            else:  # Assume the underlying proc was killed earlier or never existed.",
            "                status = self.status",
            "                p_stderr = None",
            "",
            "            def read_all_from_possibly_closed_stream(stream: Union[IO[bytes], None]) -> bytes:",
            "                if stream:",
            "                    try:",
            "                        return stderr_b + force_bytes(stream.read())",
            "                    except (OSError, ValueError):",
            "                        return stderr_b or b\"\"",
            "                else:",
            "                    return stderr_b or b\"\"",
            "",
            "            # END status handling",
            "",
            "            if status != 0:",
            "                errstr = read_all_from_possibly_closed_stream(p_stderr)",
            "                log.debug(\"AutoInterrupt wait stderr: %r\" % (errstr,))",
            "                raise GitCommandError(remove_password_if_present(self.args), status, errstr)",
            "            return status",
            "",
            "    # END auto interrupt",
            "",
            "    class CatFileContentStream:",
            "        \"\"\"Object representing a sized read-only stream returning the contents of",
            "        an object.",
            "",
            "        This behaves like a stream, but counts the data read and simulates an empty",
            "        stream once our sized content region is empty.",
            "",
            "        If not all data are read to the end of the object's lifetime, we read the",
            "        rest to ensure the underlying stream continues to work.",
            "        \"\"\"",
            "",
            "        __slots__: Tuple[str, ...] = (\"_stream\", \"_nbr\", \"_size\")",
            "",
            "        def __init__(self, size: int, stream: IO[bytes]) -> None:",
            "            self._stream = stream",
            "            self._size = size",
            "            self._nbr = 0  # Number of bytes read.",
            "",
            "            # Special case: If the object is empty, has null bytes, get the",
            "            # final newline right away.",
            "            if size == 0:",
            "                stream.read(1)",
            "            # END handle empty streams",
            "",
            "        def read(self, size: int = -1) -> bytes:",
            "            bytes_left = self._size - self._nbr",
            "            if bytes_left == 0:",
            "                return b\"\"",
            "            if size > -1:",
            "                # Ensure we don't try to read past our limit.",
            "                size = min(bytes_left, size)",
            "            else:",
            "                # They try to read all, make sure it's not more than what remains.",
            "                size = bytes_left",
            "            # END check early depletion",
            "            data = self._stream.read(size)",
            "            self._nbr += len(data)",
            "",
            "            # Check for depletion, read our final byte to make the stream usable by others.",
            "            if self._size - self._nbr == 0:",
            "                self._stream.read(1)  # final newline",
            "            # END finish reading",
            "            return data",
            "",
            "        def readline(self, size: int = -1) -> bytes:",
            "            if self._nbr == self._size:",
            "                return b\"\"",
            "",
            "            # Clamp size to lowest allowed value.",
            "            bytes_left = self._size - self._nbr",
            "            if size > -1:",
            "                size = min(bytes_left, size)",
            "            else:",
            "                size = bytes_left",
            "            # END handle size",
            "",
            "            data = self._stream.readline(size)",
            "            self._nbr += len(data)",
            "",
            "            # Handle final byte.",
            "            if self._size - self._nbr == 0:",
            "                self._stream.read(1)",
            "            # END finish reading",
            "",
            "            return data",
            "",
            "        def readlines(self, size: int = -1) -> List[bytes]:",
            "            if self._nbr == self._size:",
            "                return []",
            "",
            "            # Leave all additional logic to our readline method, we just check the size.",
            "            out = []",
            "            nbr = 0",
            "            while True:",
            "                line = self.readline()",
            "                if not line:",
            "                    break",
            "                out.append(line)",
            "                if size > -1:",
            "                    nbr += len(line)",
            "                    if nbr > size:",
            "                        break",
            "                # END handle size constraint",
            "            # END readline loop",
            "            return out",
            "",
            "        # skipcq: PYL-E0301",
            "        def __iter__(self) -> \"Git.CatFileContentStream\":",
            "            return self",
            "",
            "        def __next__(self) -> bytes:",
            "            line = self.readline()",
            "            if not line:",
            "                raise StopIteration",
            "",
            "            return line",
            "",
            "        next = __next__",
            "",
            "        def __del__(self) -> None:",
            "            bytes_left = self._size - self._nbr",
            "            if bytes_left:",
            "                # Read and discard - seeking is impossible within a stream.",
            "                # This includes any terminating newline.",
            "                self._stream.read(bytes_left + 1)",
            "            # END handle incomplete read",
            "",
            "    def __init__(self, working_dir: Union[None, PathLike] = None):",
            "        \"\"\"Initialize this instance with:",
            "",
            "        :param working_dir:",
            "           Git directory we should work in. If None, we always work in the current",
            "           directory as returned by :func:`os.getcwd`.",
            "           It is meant to be the working tree directory if available, or the",
            "           ``.git`` directory in case of bare repositories.",
            "        \"\"\"",
            "        super().__init__()",
            "        self._working_dir = expand_path(working_dir)",
            "        self._git_options: Union[List[str], Tuple[str, ...]] = ()",
            "        self._persistent_git_options: List[str] = []",
            "",
            "        # Extra environment variables to pass to git commands",
            "        self._environment: Dict[str, str] = {}",
            "",
            "        # Cached command slots",
            "        self.cat_file_header: Union[None, TBD] = None",
            "        self.cat_file_all: Union[None, TBD] = None",
            "",
            "    def __getattr__(self, name: str) -> Any:",
            "        \"\"\"A convenience method as it allows to call the command as if it was",
            "        an object.",
            "",
            "        :return:",
            "            Callable object that will execute call :meth:`_call_process` with",
            "            your arguments.",
            "        \"\"\"",
            "        if name[0] == \"_\":",
            "            return LazyMixin.__getattr__(self, name)",
            "        return lambda *args, **kwargs: self._call_process(name, *args, **kwargs)",
            "",
            "    def set_persistent_git_options(self, **kwargs: Any) -> None:",
            "        \"\"\"Specify command line options to the git executable for subsequent",
            "        subcommand calls.",
            "",
            "        :param kwargs:",
            "            A dict of keyword arguments.",
            "            These arguments are passed as in :meth:`_call_process`, but will be",
            "            passed to the git command rather than the subcommand.",
            "        \"\"\"",
            "",
            "        self._persistent_git_options = self.transform_kwargs(split_single_char_options=True, **kwargs)",
            "",
            "    def _set_cache_(self, attr: str) -> None:",
            "        if attr == \"_version_info\":",
            "            # We only use the first 4 numbers, as everything else could be strings in fact (on Windows).",
            "            process_version = self._call_process(\"version\")  # Should be as default *args and **kwargs used.",
            "            version_numbers = process_version.split(\" \")[2]",
            "",
            "            self._version_info = cast(",
            "                Tuple[int, int, int, int],",
            "                tuple(int(n) for n in version_numbers.split(\".\")[:4] if n.isdigit()),",
            "            )",
            "        else:",
            "            super()._set_cache_(attr)",
            "        # END handle version info",
            "",
            "    @property",
            "    def working_dir(self) -> Union[None, PathLike]:",
            "        \"\"\":return: Git directory we are working on\"\"\"",
            "        return self._working_dir",
            "",
            "    @property",
            "    def version_info(self) -> Tuple[int, int, int, int]:",
            "        \"\"\"",
            "        :return: tuple(int, int, int, int) tuple with integers representing the major, minor",
            "            and additional version numbers as parsed from git version.",
            "",
            "            This value is generated on demand and is cached.",
            "        \"\"\"",
            "        return self._version_info",
            "",
            "    @overload",
            "    def execute(self, command: Union[str, Sequence[Any]], *, as_process: Literal[True]) -> \"AutoInterrupt\":",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        as_process: Literal[False] = False,",
            "        stdout_as_string: Literal[True],",
            "    ) -> Union[str, Tuple[int, str, str]]:",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        as_process: Literal[False] = False,",
            "        stdout_as_string: Literal[False] = False,",
            "    ) -> Union[bytes, Tuple[int, bytes, str]]:",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        with_extended_output: Literal[False],",
            "        as_process: Literal[False],",
            "        stdout_as_string: Literal[True],",
            "    ) -> str:",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        with_extended_output: Literal[False],",
            "        as_process: Literal[False],",
            "        stdout_as_string: Literal[False],",
            "    ) -> bytes:",
            "        ...",
            "",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        istream: Union[None, BinaryIO] = None,",
            "        with_extended_output: bool = False,",
            "        with_exceptions: bool = True,",
            "        as_process: bool = False,",
            "        output_stream: Union[None, BinaryIO] = None,",
            "        stdout_as_string: bool = True,",
            "        kill_after_timeout: Union[None, float] = None,",
            "        with_stdout: bool = True,",
            "        universal_newlines: bool = False,",
            "        shell: Union[None, bool] = None,",
            "        env: Union[None, Mapping[str, str]] = None,",
            "        max_chunk_size: int = io.DEFAULT_BUFFER_SIZE,",
            "        strip_newline_in_stdout: bool = True,",
            "        **subprocess_kwargs: Any,",
            "    ) -> Union[str, bytes, Tuple[int, Union[str, bytes], str], AutoInterrupt]:",
            "        R\"\"\"Handle executing the command, and consume and return the returned",
            "        information (stdout).",
            "",
            "        :param command:",
            "            The command argument list to execute.",
            "            It should be a sequence of program arguments, or a string. The",
            "            program to execute is the first item in the args sequence or string.",
            "",
            "        :param istream:",
            "            Standard input filehandle passed to :class:`subprocess.Popen`.",
            "",
            "        :param with_extended_output:",
            "            Whether to return a (status, stdout, stderr) tuple.",
            "",
            "        :param with_exceptions:",
            "            Whether to raise an exception when git returns a non-zero status.",
            "",
            "        :param as_process:",
            "            Whether to return the created process instance directly from which",
            "            streams can be read on demand. This will render `with_extended_output`",
            "            and `with_exceptions` ineffective - the caller will have to deal with",
            "            the details. It is important to note that the process will be placed",
            "            into an :class:`AutoInterrupt` wrapper that will interrupt the process",
            "            once it goes out of scope. If you use the command in iterators, you",
            "            should pass the whole process instance instead of a single stream.",
            "",
            "        :param output_stream:",
            "            If set to a file-like object, data produced by the git command will be",
            "            output to the given stream directly.",
            "            This feature only has any effect if `as_process` is False. Processes will",
            "            always be created with a pipe due to issues with subprocess.",
            "            This merely is a workaround as data will be copied from the",
            "            output pipe to the given output stream directly.",
            "            Judging from the implementation, you shouldn't use this parameter!",
            "",
            "        :param stdout_as_string:",
            "            If False, the command's standard output will be bytes. Otherwise, it will be",
            "            decoded into a string using the default encoding (usually UTF-8).",
            "            The latter can fail, if the output contains binary data.",
            "",
            "        :param kill_after_timeout:",
            "            Specifies a timeout in seconds for the git command, after which the process",
            "            should be killed. This will have no effect if `as_process` is set to True.",
            "            It is set to None by default and will let the process run until the timeout",
            "            is explicitly specified. Uses of this feature should be carefully",
            "            considered, due to the following limitations:",
            "",
            "            1. This feature is not supported at all on Windows.",
            "            2. Effectiveness may vary by operating system. ``ps --ppid`` is used to",
            "               enumerate child processes, which is available on most GNU/Linux systems",
            "               but not most others.",
            "            3. Deeper descendants do not receive signals, though they may sometimes",
            "               terminate as a consequence of their parent processes being killed.",
            "            4. `kill_after_timeout` uses ``SIGKILL``, which can have negative side",
            "               effects on a repository. For example, stale locks in case of ``git gc``",
            "               could render the repository incapable of accepting changes until the lock",
            "               is manually removed.",
            "",
            "        :param with_stdout:",
            "            If True, default True, we open stdout on the created process.",
            "",
            "        :param universal_newlines:",
            "            if True, pipes will be opened as text, and lines are split at",
            "            all known line endings.",
            "",
            "        :param shell:",
            "            Whether to invoke commands through a shell (see `Popen(..., shell=True)`).",
            "            If this is not `None`, it overrides :attr:`USE_SHELL`.",
            "",
            "            Passing ``shell=True`` to this or any other GitPython function should be",
            "            avoided, as it is unsafe under most circumstances. This is because it is",
            "            typically not feasible to fully consider and account for the effect of shell",
            "            expansions, especially when passing ``shell=True`` to other methods that",
            "            forward it to :meth:`Git.execute`. Passing ``shell=True`` is also no longer",
            "            needed (nor useful) to work around any known operating system specific",
            "            issues.",
            "",
            "        :param env:",
            "            A dictionary of environment variables to be passed to :class:`subprocess.Popen`.",
            "",
            "        :param max_chunk_size:",
            "            Maximum number of bytes in one chunk of data passed to the output_stream in",
            "            one invocation of write() method. If the given number is not positive then",
            "            the default value is used.",
            "",
            "        :param strip_newline_in_stdout:",
            "            Whether to strip the trailing ``\\n`` of the command stdout.",
            "",
            "        :param subprocess_kwargs:",
            "            Keyword arguments to be passed to :class:`subprocess.Popen`. Please note",
            "            that some of the valid kwargs are already set by this method; the ones you",
            "            specify may not be the same ones.",
            "",
            "        :return:",
            "            * str(output) if extended_output = False (Default)",
            "            * tuple(int(status), str(stdout), str(stderr)) if extended_output = True",
            "",
            "            If output_stream is True, the stdout value will be your output stream:",
            "            * output_stream if extended_output = False",
            "            * tuple(int(status), output_stream, str(stderr)) if extended_output = True",
            "",
            "            Note that git is executed with ``LC_MESSAGES=\"C\"`` to ensure consistent",
            "            output regardless of system language.",
            "",
            "        :raise GitCommandError:",
            "",
            "        :note:",
            "           If you add additional keyword arguments to the signature of this method,",
            "           you must update the execute_kwargs tuple housed in this module.",
            "        \"\"\"",
            "        # Remove password for the command if present.",
            "        redacted_command = remove_password_if_present(command)",
            "        if self.GIT_PYTHON_TRACE and (self.GIT_PYTHON_TRACE != \"full\" or as_process):",
            "            log.info(\" \".join(redacted_command))",
            "",
            "        # Allow the user to have the command executed in their working dir.",
            "        try:",
            "            cwd = self._working_dir or os.getcwd()  # type: Union[None, str]",
            "            if not os.access(str(cwd), os.X_OK):",
            "                cwd = None",
            "        except FileNotFoundError:",
            "            cwd = None",
            "",
            "        # Start the process.",
            "        inline_env = env",
            "        env = os.environ.copy()",
            "        # Attempt to force all output to plain ASCII English, which is what some parsing",
            "        # code may expect.",
            "        # According to https://askubuntu.com/a/311796, we are setting LANGUAGE as well",
            "        # just to be sure.",
            "        env[\"LANGUAGE\"] = \"C\"",
            "        env[\"LC_ALL\"] = \"C\"",
            "        env.update(self._environment)",
            "        if inline_env is not None:",
            "            env.update(inline_env)",
            "",
            "        if os.name == \"nt\":",
            "            cmd_not_found_exception = OSError",
            "            if kill_after_timeout is not None:",
            "                raise GitCommandError(",
            "                    redacted_command,",
            "                    '\"kill_after_timeout\" feature is not supported on Windows.',",
            "                )",
            "            # Only search PATH, not CWD. This must be in the *caller* environment. The \"1\" can be any value.",
            "            maybe_patch_caller_env = patch_env(\"NoDefaultCurrentDirectoryInExePath\", \"1\")",
            "        else:",
            "            cmd_not_found_exception = FileNotFoundError",
            "            maybe_patch_caller_env = contextlib.nullcontext()",
            "        # END handle",
            "",
            "        stdout_sink = PIPE if with_stdout else getattr(subprocess, \"DEVNULL\", None) or open(os.devnull, \"wb\")",
            "        if shell is None:",
            "            shell = self.USE_SHELL",
            "        log.debug(",
            "            \"Popen(%s, cwd=%s, stdin=%s, shell=%s, universal_newlines=%s)\",",
            "            redacted_command,",
            "            cwd,",
            "            \"<valid stream>\" if istream else \"None\",",
            "            shell,",
            "            universal_newlines,",
            "        )",
            "        try:",
            "            with maybe_patch_caller_env:",
            "                proc = Popen(",
            "                    command,",
            "                    env=env,",
            "                    cwd=cwd,",
            "                    bufsize=-1,",
            "                    stdin=(istream or DEVNULL),",
            "                    stderr=PIPE,",
            "                    stdout=stdout_sink,",
            "                    shell=shell,",
            "                    universal_newlines=universal_newlines,",
            "                    creationflags=PROC_CREATIONFLAGS,",
            "                    **subprocess_kwargs,",
            "                )",
            "        except cmd_not_found_exception as err:",
            "            raise GitCommandNotFound(redacted_command, err) from err",
            "        else:",
            "            # Replace with a typeguard for Popen[bytes]?",
            "            proc.stdout = cast(BinaryIO, proc.stdout)",
            "            proc.stderr = cast(BinaryIO, proc.stderr)",
            "",
            "        if as_process:",
            "            return self.AutoInterrupt(proc, command)",
            "",
            "        def kill_process(pid: int) -> None:",
            "            \"\"\"Callback to kill a process.\"\"\"",
            "            if os.name == \"nt\":",
            "                raise AssertionError(\"Bug: This callback would be ineffective and unsafe on Windows, stopping.\")",
            "            p = Popen([\"ps\", \"--ppid\", str(pid)], stdout=PIPE)",
            "            child_pids = []",
            "            if p.stdout is not None:",
            "                for line in p.stdout:",
            "                    if len(line.split()) > 0:",
            "                        local_pid = (line.split())[0]",
            "                        if local_pid.isdigit():",
            "                            child_pids.append(int(local_pid))",
            "            try:",
            "                os.kill(pid, signal.SIGKILL)",
            "                for child_pid in child_pids:",
            "                    try:",
            "                        os.kill(child_pid, signal.SIGKILL)",
            "                    except OSError:",
            "                        pass",
            "                kill_check.set()  # Tell the main routine that the process was killed.",
            "            except OSError:",
            "                # It is possible that the process gets completed in the duration after",
            "                # timeout happens and before we try to kill the process.",
            "                pass",
            "            return",
            "",
            "        # END kill_process",
            "",
            "        if kill_after_timeout is not None:",
            "            kill_check = threading.Event()",
            "            watchdog = threading.Timer(kill_after_timeout, kill_process, args=(proc.pid,))",
            "",
            "        # Wait for the process to return.",
            "        status = 0",
            "        stdout_value: Union[str, bytes] = b\"\"",
            "        stderr_value: Union[str, bytes] = b\"\"",
            "        newline = \"\\n\" if universal_newlines else b\"\\n\"",
            "        try:",
            "            if output_stream is None:",
            "                if kill_after_timeout is not None:",
            "                    watchdog.start()",
            "                stdout_value, stderr_value = proc.communicate()",
            "                if kill_after_timeout is not None:",
            "                    watchdog.cancel()",
            "                    if kill_check.is_set():",
            "                        stderr_value = 'Timeout: the command \"%s\" did not complete in %d ' \"secs.\" % (",
            "                            \" \".join(redacted_command),",
            "                            kill_after_timeout,",
            "                        )",
            "                        if not universal_newlines:",
            "                            stderr_value = stderr_value.encode(defenc)",
            "                # Strip trailing \"\\n\".",
            "                if stdout_value.endswith(newline) and strip_newline_in_stdout:  # type: ignore",
            "                    stdout_value = stdout_value[:-1]",
            "                if stderr_value.endswith(newline):  # type: ignore",
            "                    stderr_value = stderr_value[:-1]",
            "",
            "                status = proc.returncode",
            "            else:",
            "                max_chunk_size = max_chunk_size if max_chunk_size and max_chunk_size > 0 else io.DEFAULT_BUFFER_SIZE",
            "                stream_copy(proc.stdout, output_stream, max_chunk_size)",
            "                stdout_value = proc.stdout.read()",
            "                stderr_value = proc.stderr.read()",
            "                # Strip trailing \"\\n\".",
            "                if stderr_value.endswith(newline):  # type: ignore",
            "                    stderr_value = stderr_value[:-1]",
            "                status = proc.wait()",
            "            # END stdout handling",
            "        finally:",
            "            proc.stdout.close()",
            "            proc.stderr.close()",
            "",
            "        if self.GIT_PYTHON_TRACE == \"full\":",
            "            cmdstr = \" \".join(redacted_command)",
            "",
            "            def as_text(stdout_value: Union[bytes, str]) -> str:",
            "                return not output_stream and safe_decode(stdout_value) or \"<OUTPUT_STREAM>\"",
            "",
            "            # END as_text",
            "",
            "            if stderr_value:",
            "                log.info(",
            "                    \"%s -> %d; stdout: '%s'; stderr: '%s'\",",
            "                    cmdstr,",
            "                    status,",
            "                    as_text(stdout_value),",
            "                    safe_decode(stderr_value),",
            "                )",
            "            elif stdout_value:",
            "                log.info(\"%s -> %d; stdout: '%s'\", cmdstr, status, as_text(stdout_value))",
            "            else:",
            "                log.info(\"%s -> %d\", cmdstr, status)",
            "        # END handle debug printing",
            "",
            "        if with_exceptions and status != 0:",
            "            raise GitCommandError(redacted_command, status, stderr_value, stdout_value)",
            "",
            "        if isinstance(stdout_value, bytes) and stdout_as_string:  # Could also be output_stream.",
            "            stdout_value = safe_decode(stdout_value)",
            "",
            "        # Allow access to the command's status code.",
            "        if with_extended_output:",
            "            return (status, stdout_value, safe_decode(stderr_value))",
            "        else:",
            "            return stdout_value",
            "",
            "    def environment(self) -> Dict[str, str]:",
            "        return self._environment",
            "",
            "    def update_environment(self, **kwargs: Any) -> Dict[str, Union[str, None]]:",
            "        \"\"\"Set environment variables for future git invocations. Return all changed",
            "        values in a format that can be passed back into this function to revert the",
            "        changes.",
            "",
            "        ``Examples``::",
            "",
            "            old_env = self.update_environment(PWD='/tmp')",
            "            self.update_environment(**old_env)",
            "",
            "        :param kwargs: Environment variables to use for git processes",
            "",
            "        :return: Dict that maps environment variables to their old values",
            "        \"\"\"",
            "        old_env = {}",
            "        for key, value in kwargs.items():",
            "            # Set value if it is None.",
            "            if value is not None:",
            "                old_env[key] = self._environment.get(key)",
            "                self._environment[key] = value",
            "            # Remove key from environment if its value is None.",
            "            elif key in self._environment:",
            "                old_env[key] = self._environment[key]",
            "                del self._environment[key]",
            "        return old_env",
            "",
            "    @contextlib.contextmanager",
            "    def custom_environment(self, **kwargs: Any) -> Iterator[None]:",
            "        \"\"\"A context manager around the above :meth:`update_environment` method to",
            "        restore the environment back to its previous state after operation.",
            "",
            "        ``Examples``::",
            "",
            "            with self.custom_environment(GIT_SSH='/bin/ssh_wrapper'):",
            "                repo.remotes.origin.fetch()",
            "",
            "        :param kwargs: See :meth:`update_environment`",
            "        \"\"\"",
            "        old_env = self.update_environment(**kwargs)",
            "        try:",
            "            yield",
            "        finally:",
            "            self.update_environment(**old_env)",
            "",
            "    def transform_kwarg(self, name: str, value: Any, split_single_char_options: bool) -> List[str]:",
            "        if len(name) == 1:",
            "            if value is True:",
            "                return [\"-%s\" % name]",
            "            elif value not in (False, None):",
            "                if split_single_char_options:",
            "                    return [\"-%s\" % name, \"%s\" % value]",
            "                else:",
            "                    return [\"-%s%s\" % (name, value)]",
            "        else:",
            "            if value is True:",
            "                return [\"--%s\" % dashify(name)]",
            "            elif value is not False and value is not None:",
            "                return [\"--%s=%s\" % (dashify(name), value)]",
            "        return []",
            "",
            "    def transform_kwargs(self, split_single_char_options: bool = True, **kwargs: Any) -> List[str]:",
            "        \"\"\"Transform Python style kwargs into git command line options.\"\"\"",
            "        args = []",
            "        for k, v in kwargs.items():",
            "            if isinstance(v, (list, tuple)):",
            "                for value in v:",
            "                    args += self.transform_kwarg(k, value, split_single_char_options)",
            "            else:",
            "                args += self.transform_kwarg(k, v, split_single_char_options)",
            "        return args",
            "",
            "    @classmethod",
            "    def _unpack_args(cls, arg_list: Sequence[str]) -> List[str]:",
            "        outlist = []",
            "        if isinstance(arg_list, (list, tuple)):",
            "            for arg in arg_list:",
            "                outlist.extend(cls._unpack_args(arg))",
            "        else:",
            "            outlist.append(str(arg_list))",
            "",
            "        return outlist",
            "",
            "    def __call__(self, **kwargs: Any) -> \"Git\":",
            "        \"\"\"Specify command line options to the git executable for a subcommand call.",
            "",
            "        :param kwargs:",
            "            A dict of keyword arguments.",
            "            These arguments are passed as in :meth:`_call_process`, but will be",
            "            passed to the git command rather than the subcommand.",
            "",
            "        ``Examples``::",
            "            git(work_tree='/tmp').difftool()",
            "        \"\"\"",
            "        self._git_options = self.transform_kwargs(split_single_char_options=True, **kwargs)",
            "        return self",
            "",
            "    @overload",
            "    def _call_process(self, method: str, *args: None, **kwargs: None) -> str:",
            "        ...  # If no args were given, execute the call with all defaults.",
            "",
            "    @overload",
            "    def _call_process(",
            "        self,",
            "        method: str,",
            "        istream: int,",
            "        as_process: Literal[True],",
            "        *args: Any,",
            "        **kwargs: Any,",
            "    ) -> \"Git.AutoInterrupt\":",
            "        ...",
            "",
            "    @overload",
            "    def _call_process(",
            "        self, method: str, *args: Any, **kwargs: Any",
            "    ) -> Union[str, bytes, Tuple[int, Union[str, bytes], str], \"Git.AutoInterrupt\"]:",
            "        ...",
            "",
            "    def _call_process(",
            "        self, method: str, *args: Any, **kwargs: Any",
            "    ) -> Union[str, bytes, Tuple[int, Union[str, bytes], str], \"Git.AutoInterrupt\"]:",
            "        \"\"\"Run the given git command with the specified arguments and return",
            "        the result as a string.",
            "",
            "        :param method:",
            "            The command. Contained ``_`` characters will be converted to dashes,",
            "            such as in ``ls_files`` to call ``ls-files``.",
            "",
            "        :param args:",
            "            The list of arguments. If None is included, it will be pruned.",
            "            This allows your commands to call git more conveniently as None",
            "            is realized as non-existent.",
            "",
            "        :param kwargs:",
            "            Contains key-values for the following:",
            "            - The :meth:`execute()` kwds, as listed in :var:`execute_kwargs`.",
            "            - \"Command options\" to be converted by :meth:`transform_kwargs`.",
            "            - The `'insert_kwargs_after'` key which its value must match one of ``*args``.",
            "            It also contains any command options, to be appended after the matched arg.",
            "",
            "        Examples::",
            "",
            "            git.rev_list('master', max_count=10, header=True)",
            "",
            "        turns into::",
            "",
            "           git rev-list max-count 10 --header master",
            "",
            "        :return: Same as :meth:`execute`.",
            "            If no args are given, used :meth:`execute`'s default (especially",
            "            ``as_process = False``, ``stdout_as_string = True``) and return str.",
            "        \"\"\"",
            "        # Handle optional arguments prior to calling transform_kwargs.",
            "        # Otherwise these'll end up in args, which is bad.",
            "        exec_kwargs = {k: v for k, v in kwargs.items() if k in execute_kwargs}",
            "        opts_kwargs = {k: v for k, v in kwargs.items() if k not in execute_kwargs}",
            "",
            "        insert_after_this_arg = opts_kwargs.pop(\"insert_kwargs_after\", None)",
            "",
            "        # Prepare the argument list.",
            "",
            "        opt_args = self.transform_kwargs(**opts_kwargs)",
            "        ext_args = self._unpack_args([a for a in args if a is not None])",
            "",
            "        if insert_after_this_arg is None:",
            "            args_list = opt_args + ext_args",
            "        else:",
            "            try:",
            "                index = ext_args.index(insert_after_this_arg)",
            "            except ValueError as err:",
            "                raise ValueError(",
            "                    \"Couldn't find argument '%s' in args %s to insert cmd options after\"",
            "                    % (insert_after_this_arg, str(ext_args))",
            "                ) from err",
            "            # END handle error",
            "            args_list = ext_args[: index + 1] + opt_args + ext_args[index + 1 :]",
            "        # END handle opts_kwargs",
            "",
            "        call = [self.GIT_PYTHON_GIT_EXECUTABLE]",
            "",
            "        # Add persistent git options.",
            "        call.extend(self._persistent_git_options)",
            "",
            "        # Add the git options, then reset to empty to avoid side effects.",
            "        call.extend(self._git_options)",
            "        self._git_options = ()",
            "",
            "        call.append(dashify(method))",
            "        call.extend(args_list)",
            "",
            "        return self.execute(call, **exec_kwargs)",
            "",
            "    def _parse_object_header(self, header_line: str) -> Tuple[str, str, int]:",
            "        \"\"\"",
            "        :param header_line:",
            "            <hex_sha> type_string size_as_int",
            "",
            "        :return: (hex_sha, type_string, size_as_int)",
            "",
            "        :raise ValueError: If the header contains indication for an error due to",
            "            incorrect input sha",
            "        \"\"\"",
            "        tokens = header_line.split()",
            "        if len(tokens) != 3:",
            "            if not tokens:",
            "                err_msg = (",
            "                    f\"SHA is empty, possible dubious ownership in the repository \"",
            "                    f\"\"\"at {self._working_dir}.\\n            If this is unintended run:\\n\\n         \"\"\"",
            "                    f\"\"\"             \"git config --global --add safe.directory {self._working_dir}\" \"\"\"",
            "                )",
            "                raise ValueError(err_msg)",
            "            else:",
            "                raise ValueError(\"SHA %s could not be resolved, git returned: %r\" % (tokens[0], header_line.strip()))",
            "            # END handle actual return value",
            "        # END error handling",
            "",
            "        if len(tokens[0]) != 40:",
            "            raise ValueError(\"Failed to parse header: %r\" % header_line)",
            "        return (tokens[0], tokens[1], int(tokens[2]))",
            "",
            "    def _prepare_ref(self, ref: AnyStr) -> bytes:",
            "        # Required for command to separate refs on stdin, as bytes.",
            "        if isinstance(ref, bytes):",
            "            # Assume 40 bytes hexsha - bin-to-ascii for some reason returns bytes, not text.",
            "            refstr: str = ref.decode(\"ascii\")",
            "        elif not isinstance(ref, str):",
            "            refstr = str(ref)  # Could be ref-object.",
            "        else:",
            "            refstr = ref",
            "",
            "        if not refstr.endswith(\"\\n\"):",
            "            refstr += \"\\n\"",
            "        return refstr.encode(defenc)",
            "",
            "    def _get_persistent_cmd(self, attr_name: str, cmd_name: str, *args: Any, **kwargs: Any) -> \"Git.AutoInterrupt\":",
            "        cur_val = getattr(self, attr_name)",
            "        if cur_val is not None:",
            "            return cur_val",
            "",
            "        options = {\"istream\": PIPE, \"as_process\": True}",
            "        options.update(kwargs)",
            "",
            "        cmd = self._call_process(cmd_name, *args, **options)",
            "        setattr(self, attr_name, cmd)",
            "        cmd = cast(\"Git.AutoInterrupt\", cmd)",
            "        return cmd",
            "",
            "    def __get_object_header(self, cmd: \"Git.AutoInterrupt\", ref: AnyStr) -> Tuple[str, str, int]:",
            "        if cmd.stdin and cmd.stdout:",
            "            cmd.stdin.write(self._prepare_ref(ref))",
            "            cmd.stdin.flush()",
            "            return self._parse_object_header(cmd.stdout.readline())",
            "        else:",
            "            raise ValueError(\"cmd stdin was empty\")",
            "",
            "    def get_object_header(self, ref: str) -> Tuple[str, str, int]:",
            "        \"\"\"Use this method to quickly examine the type and size of the object behind",
            "        the given ref.",
            "",
            "        :note: The method will only suffer from the costs of command invocation",
            "            once and reuses the command in subsequent calls.",
            "",
            "        :return: (hexsha, type_string, size_as_int)",
            "        \"\"\"",
            "        cmd = self._get_persistent_cmd(\"cat_file_header\", \"cat_file\", batch_check=True)",
            "        return self.__get_object_header(cmd, ref)",
            "",
            "    def get_object_data(self, ref: str) -> Tuple[str, str, int, bytes]:",
            "        \"\"\"As get_object_header, but returns object data as well.",
            "",
            "        :return: (hexsha, type_string, size_as_int, data_string)",
            "        :note: Not threadsafe.",
            "        \"\"\"",
            "        hexsha, typename, size, stream = self.stream_object_data(ref)",
            "        data = stream.read(size)",
            "        del stream",
            "        return (hexsha, typename, size, data)",
            "",
            "    def stream_object_data(self, ref: str) -> Tuple[str, str, int, \"Git.CatFileContentStream\"]:",
            "        \"\"\"As get_object_header, but returns the data as a stream.",
            "",
            "        :return: (hexsha, type_string, size_as_int, stream)",
            "        :note: This method is not threadsafe, you need one independent Command instance per thread to be safe!",
            "        \"\"\"",
            "        cmd = self._get_persistent_cmd(\"cat_file_all\", \"cat_file\", batch=True)",
            "        hexsha, typename, size = self.__get_object_header(cmd, ref)",
            "        cmd_stdout = cmd.stdout if cmd.stdout is not None else io.BytesIO()",
            "        return (hexsha, typename, size, self.CatFileContentStream(size, cmd_stdout))",
            "",
            "    def clear_cache(self) -> \"Git\":",
            "        \"\"\"Clear all kinds of internal caches to release resources.",
            "",
            "        Currently persistent commands will be interrupted.",
            "",
            "        :return: self",
            "        \"\"\"",
            "        for cmd in (self.cat_file_all, self.cat_file_header):",
            "            if cmd:",
            "                cmd.__del__()",
            "",
            "        self.cat_file_all = None",
            "        self.cat_file_header = None",
            "        return self"
        ],
        "afterPatchFile": [
            "# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors",
            "#",
            "# This module is part of GitPython and is released under the",
            "# 3-Clause BSD License: https://opensource.org/license/bsd-3-clause/",
            "",
            "from __future__ import annotations",
            "",
            "import re",
            "import contextlib",
            "import io",
            "import logging",
            "import os",
            "import signal",
            "from subprocess import Popen, PIPE, DEVNULL",
            "import subprocess",
            "import threading",
            "from textwrap import dedent",
            "",
            "from git.compat import defenc, force_bytes, safe_decode",
            "from git.exc import (",
            "    CommandError,",
            "    GitCommandError,",
            "    GitCommandNotFound,",
            "    UnsafeOptionError,",
            "    UnsafeProtocolError,",
            ")",
            "from git.util import (",
            "    LazyMixin,",
            "    cygpath,",
            "    expand_path,",
            "    is_cygwin_git,",
            "    patch_env,",
            "    remove_password_if_present,",
            "    stream_copy,",
            ")",
            "",
            "# typing ---------------------------------------------------------------------------",
            "",
            "from typing import (",
            "    Any,",
            "    AnyStr,",
            "    BinaryIO,",
            "    Callable,",
            "    Dict,",
            "    IO,",
            "    Iterator,",
            "    List,",
            "    Mapping,",
            "    Optional,",
            "    Sequence,",
            "    TYPE_CHECKING,",
            "    TextIO,",
            "    Tuple,",
            "    Union,",
            "    cast,",
            "    overload,",
            ")",
            "",
            "from git.types import PathLike, Literal, TBD",
            "",
            "if TYPE_CHECKING:",
            "    from git.repo.base import Repo",
            "    from git.diff import DiffIndex",
            "",
            "",
            "# ---------------------------------------------------------------------------------",
            "",
            "execute_kwargs = {",
            "    \"istream\",",
            "    \"with_extended_output\",",
            "    \"with_exceptions\",",
            "    \"as_process\",",
            "    \"output_stream\",",
            "    \"stdout_as_string\",",
            "    \"kill_after_timeout\",",
            "    \"with_stdout\",",
            "    \"universal_newlines\",",
            "    \"shell\",",
            "    \"env\",",
            "    \"max_chunk_size\",",
            "    \"strip_newline_in_stdout\",",
            "}",
            "",
            "log = logging.getLogger(__name__)",
            "log.addHandler(logging.NullHandler())",
            "",
            "__all__ = (\"Git\",)",
            "",
            "",
            "# ==============================================================================",
            "## @name Utilities",
            "# ------------------------------------------------------------------------------",
            "# Documentation",
            "## @{",
            "",
            "",
            "def handle_process_output(",
            "    process: \"Git.AutoInterrupt\" | Popen,",
            "    stdout_handler: Union[",
            "        None,",
            "        Callable[[AnyStr], None],",
            "        Callable[[List[AnyStr]], None],",
            "        Callable[[bytes, \"Repo\", \"DiffIndex\"], None],",
            "    ],",
            "    stderr_handler: Union[None, Callable[[AnyStr], None], Callable[[List[AnyStr]], None]],",
            "    finalizer: Union[None, Callable[[Union[Popen, \"Git.AutoInterrupt\"]], None]] = None,",
            "    decode_streams: bool = True,",
            "    kill_after_timeout: Union[None, float] = None,",
            ") -> None:",
            "    \"\"\"Register for notifications to learn that process output is ready to read, and",
            "    dispatch lines to the respective line handlers.",
            "",
            "    This function returns once the finalizer returns.",
            "",
            "    :param process: :class:`subprocess.Popen` instance",
            "    :param stdout_handler: f(stdout_line_string), or None",
            "    :param stderr_handler: f(stderr_line_string), or None",
            "    :param finalizer: f(proc) - wait for proc to finish",
            "    :param decode_streams:",
            "        Assume stdout/stderr streams are binary and decode them before pushing",
            "        their contents to handlers.",
            "        Set it to False if ``universal_newlines == True`` (then streams are in",
            "        text mode) or if decoding must happen later (i.e. for Diffs).",
            "    :param kill_after_timeout:",
            "        float or None, Default = None",
            "        To specify a timeout in seconds for the git command, after which the process",
            "        should be killed.",
            "    \"\"\"",
            "",
            "    # Use 2 \"pump\" threads and wait for both to finish.",
            "    def pump_stream(",
            "        cmdline: List[str],",
            "        name: str,",
            "        stream: Union[BinaryIO, TextIO],",
            "        is_decode: bool,",
            "        handler: Union[None, Callable[[Union[bytes, str]], None]],",
            "    ) -> None:",
            "        try:",
            "            for line in stream:",
            "                if handler:",
            "                    if is_decode:",
            "                        assert isinstance(line, bytes)",
            "                        line_str = line.decode(defenc)",
            "                        handler(line_str)",
            "                    else:",
            "                        handler(line)",
            "",
            "        except Exception as ex:",
            "            log.error(f\"Pumping {name!r} of cmd({remove_password_if_present(cmdline)}) failed due to: {ex!r}\")",
            "            if \"I/O operation on closed file\" not in str(ex):",
            "                # Only reraise if the error was not due to the stream closing",
            "                raise CommandError([f\"<{name}-pump>\"] + remove_password_if_present(cmdline), ex) from ex",
            "        finally:",
            "            stream.close()",
            "",
            "    if hasattr(process, \"proc\"):",
            "        process = cast(\"Git.AutoInterrupt\", process)",
            "        cmdline: str | Tuple[str, ...] | List[str] = getattr(process.proc, \"args\", \"\")",
            "        p_stdout = process.proc.stdout if process.proc else None",
            "        p_stderr = process.proc.stderr if process.proc else None",
            "    else:",
            "        process = cast(Popen, process)  # type: ignore [redundant-cast]",
            "        cmdline = getattr(process, \"args\", \"\")",
            "        p_stdout = process.stdout",
            "        p_stderr = process.stderr",
            "",
            "    if not isinstance(cmdline, (tuple, list)):",
            "        cmdline = cmdline.split()",
            "",
            "    pumps: List[Tuple[str, IO, Callable[..., None] | None]] = []",
            "    if p_stdout:",
            "        pumps.append((\"stdout\", p_stdout, stdout_handler))",
            "    if p_stderr:",
            "        pumps.append((\"stderr\", p_stderr, stderr_handler))",
            "",
            "    threads: List[threading.Thread] = []",
            "",
            "    for name, stream, handler in pumps:",
            "        t = threading.Thread(target=pump_stream, args=(cmdline, name, stream, decode_streams, handler))",
            "        t.daemon = True",
            "        t.start()",
            "        threads.append(t)",
            "",
            "    # FIXME: Why join? Will block if stdin needs feeding...",
            "    for t in threads:",
            "        t.join(timeout=kill_after_timeout)",
            "        if t.is_alive():",
            "            if isinstance(process, Git.AutoInterrupt):",
            "                process._terminate()",
            "            else:  # Don't want to deal with the other case.",
            "                raise RuntimeError(",
            "                    \"Thread join() timed out in cmd.handle_process_output().\"",
            "                    f\" kill_after_timeout={kill_after_timeout} seconds\"",
            "                )",
            "            if stderr_handler:",
            "                error_str: Union[str, bytes] = (",
            "                    \"error: process killed because it timed out.\" f\" kill_after_timeout={kill_after_timeout} seconds\"",
            "                )",
            "                if not decode_streams and isinstance(p_stderr, BinaryIO):",
            "                    #  Assume stderr_handler needs binary input.",
            "                    error_str = cast(str, error_str)",
            "                    error_str = error_str.encode()",
            "                # We ignore typing on the next line because mypy does not like",
            "                # the way we inferred that stderr takes str or bytes.",
            "                stderr_handler(error_str)  # type: ignore",
            "",
            "    if finalizer:",
            "        finalizer(process)",
            "",
            "",
            "def _safer_popen_windows(",
            "    command: Union[str, Sequence[Any]],",
            "    *,",
            "    shell: bool = False,",
            "    env: Optional[Mapping[str, str]] = None,",
            "    **kwargs: Any,",
            ") -> Popen:",
            "    \"\"\"Call :class:`subprocess.Popen` on Windows but don't include a CWD in the search.",
            "",
            "    This avoids an untrusted search path condition where a file like ``git.exe`` in a",
            "    malicious repository would be run when GitPython operates on the repository. The",
            "    process using GitPython may have an untrusted repository's working tree as its",
            "    current working directory. Some operations may temporarily change to that directory",
            "    before running a subprocess. In addition, while by default GitPython does not run",
            "    external commands with a shell, it can be made to do so, in which case the CWD of",
            "    the subprocess, which GitPython usually sets to a repository working tree, can",
            "    itself be searched automatically by the shell. This wrapper covers all those cases.",
            "",
            "    :note: This currently works by setting the ``NoDefaultCurrentDirectoryInExePath``",
            "        environment variable during subprocess creation. It also takes care of passing",
            "        Windows-specific process creation flags, but that is unrelated to path search.",
            "",
            "    :note: The current implementation contains a race condition on :attr:`os.environ`.",
            "        GitPython isn't thread-safe, but a program using it on one thread should ideally",
            "        be able to mutate :attr:`os.environ` on another, without unpredictable results.",
            "        See comments in https://github.com/gitpython-developers/GitPython/pull/1650.",
            "    \"\"\"",
            "    # CREATE_NEW_PROCESS_GROUP is needed for some ways of killing it afterwards. See:",
            "    # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal",
            "    # https://docs.python.org/3/library/subprocess.html#subprocess.CREATE_NEW_PROCESS_GROUP",
            "    creationflags = subprocess.CREATE_NO_WINDOW | subprocess.CREATE_NEW_PROCESS_GROUP",
            "",
            "    # When using a shell, the shell is the direct subprocess, so the variable must be",
            "    # set in its environment, to affect its search behavior. (The \"1\" can be any value.)",
            "    if shell:",
            "        safer_env = {} if env is None else dict(env)",
            "        safer_env[\"NoDefaultCurrentDirectoryInExePath\"] = \"1\"",
            "    else:",
            "        safer_env = env",
            "",
            "    # When not using a shell, the current process does the search in a CreateProcessW",
            "    # API call, so the variable must be set in our environment. With a shell, this is",
            "    # unnecessary, in versions where https://github.com/python/cpython/issues/101283 is",
            "    # patched. If not, in the rare case the ComSpec environment variable is unset, the",
            "    # shell is searched for unsafely. Setting NoDefaultCurrentDirectoryInExePath in all",
            "    # cases, as here, is simpler and protects against that. (The \"1\" can be any value.)",
            "    with patch_env(\"NoDefaultCurrentDirectoryInExePath\", \"1\"):",
            "        return Popen(",
            "            command,",
            "            shell=shell,",
            "            env=safer_env,",
            "            creationflags=creationflags,",
            "            **kwargs,",
            "        )",
            "",
            "",
            "if os.name == \"nt\":",
            "    safer_popen = _safer_popen_windows",
            "else:",
            "    safer_popen = Popen",
            "",
            "",
            "def dashify(string: str) -> str:",
            "    return string.replace(\"_\", \"-\")",
            "",
            "",
            "def slots_to_dict(self: \"Git\", exclude: Sequence[str] = ()) -> Dict[str, Any]:",
            "    return {s: getattr(self, s) for s in self.__slots__ if s not in exclude}",
            "",
            "",
            "def dict_to_slots_and__excluded_are_none(self: object, d: Mapping[str, Any], excluded: Sequence[str] = ()) -> None:",
            "    for k, v in d.items():",
            "        setattr(self, k, v)",
            "    for k in excluded:",
            "        setattr(self, k, None)",
            "",
            "",
            "## -- End Utilities -- @}",
            "",
            "",
            "class Git(LazyMixin):",
            "    \"\"\"The Git class manages communication with the Git binary.",
            "",
            "    It provides a convenient interface to calling the Git binary, such as in::",
            "",
            "     g = Git( git_dir )",
            "     g.init()                   # calls 'git init' program",
            "     rval = g.ls_files()        # calls 'git ls-files' program",
            "",
            "    ``Debugging``",
            "        Set the GIT_PYTHON_TRACE environment variable print each invocation",
            "        of the command to stdout.",
            "        Set its value to 'full' to see details about the returned values.",
            "    \"\"\"",
            "",
            "    __slots__ = (",
            "        \"_working_dir\",",
            "        \"cat_file_all\",",
            "        \"cat_file_header\",",
            "        \"_version_info\",",
            "        \"_git_options\",",
            "        \"_persistent_git_options\",",
            "        \"_environment\",",
            "    )",
            "",
            "    _excluded_ = (\"cat_file_all\", \"cat_file_header\", \"_version_info\")",
            "",
            "    re_unsafe_protocol = re.compile(r\"(.+)::.+\")",
            "",
            "    def __getstate__(self) -> Dict[str, Any]:",
            "        return slots_to_dict(self, exclude=self._excluded_)",
            "",
            "    def __setstate__(self, d: Dict[str, Any]) -> None:",
            "        dict_to_slots_and__excluded_are_none(self, d, excluded=self._excluded_)",
            "",
            "    # CONFIGURATION",
            "",
            "    git_exec_name = \"git\"",
            "    \"\"\"Default git command that should work on Linux, Windows, and other systems.\"\"\"",
            "",
            "    GIT_PYTHON_TRACE = os.environ.get(\"GIT_PYTHON_TRACE\", False)",
            "    \"\"\"Enables debugging of GitPython's git commands.\"\"\"",
            "",
            "    USE_SHELL = False",
            "    \"\"\"Deprecated. If set to True, a shell will be used when executing git commands.",
            "",
            "    Prior to GitPython 2.0.8, this had a narrow purpose in suppressing console windows",
            "    in graphical Windows applications. In 2.0.8 and higher, it provides no benefit, as",
            "    GitPython solves that problem more robustly and safely by using the",
            "    ``CREATE_NO_WINDOW`` process creation flag on Windows.",
            "",
            "    Code that uses ``USE_SHELL = True`` or that passes ``shell=True`` to any GitPython",
            "    functions should be updated to use the default value of ``False`` instead. ``True``",
            "    is unsafe unless the effect of shell expansions is fully considered and accounted",
            "    for, which is not possible under most circumstances.",
            "",
            "    See:",
            "    - :meth:`Git.execute` (on the ``shell`` parameter).",
            "    - https://github.com/gitpython-developers/GitPython/commit/0d9390866f9ce42870d3116094cd49e0019a970a",
            "    - https://learn.microsoft.com/en-us/windows/win32/procthread/process-creation-flags",
            "    \"\"\"",
            "",
            "    _git_exec_env_var = \"GIT_PYTHON_GIT_EXECUTABLE\"",
            "    _refresh_env_var = \"GIT_PYTHON_REFRESH\"",
            "",
            "    GIT_PYTHON_GIT_EXECUTABLE = None",
            "    \"\"\"Provide the full path to the git executable. Otherwise it assumes git is in the path.",
            "",
            "    Note that the git executable is actually found during the refresh step in",
            "    the top level ``__init__``.",
            "    \"\"\"",
            "",
            "    @classmethod",
            "    def refresh(cls, path: Union[None, PathLike] = None) -> bool:",
            "        \"\"\"This gets called by the refresh function (see the top level __init__).\"\"\"",
            "        # Discern which path to refresh with.",
            "        if path is not None:",
            "            new_git = os.path.expanduser(path)",
            "            new_git = os.path.abspath(new_git)",
            "        else:",
            "            new_git = os.environ.get(cls._git_exec_env_var, cls.git_exec_name)",
            "",
            "        # Keep track of the old and new git executable path.",
            "        old_git = cls.GIT_PYTHON_GIT_EXECUTABLE",
            "        cls.GIT_PYTHON_GIT_EXECUTABLE = new_git",
            "",
            "        # Test if the new git executable path is valid. A GitCommandNotFound error is",
            "        # spawned by us. A PermissionError is spawned if the git executable cannot be",
            "        # executed for whatever reason.",
            "        has_git = False",
            "        try:",
            "            cls().version()",
            "            has_git = True",
            "        except (GitCommandNotFound, PermissionError):",
            "            pass",
            "",
            "        # Warn or raise exception if test failed.",
            "        if not has_git:",
            "            err = (",
            "                dedent(",
            "                    \"\"\"\\",
            "                Bad git executable.",
            "                The git executable must be specified in one of the following ways:",
            "                    - be included in your $PATH",
            "                    - be set via $%s",
            "                    - explicitly set via git.refresh()",
            "                \"\"\"",
            "                )",
            "                % cls._git_exec_env_var",
            "            )",
            "",
            "            # Revert to whatever the old_git was.",
            "            cls.GIT_PYTHON_GIT_EXECUTABLE = old_git",
            "",
            "            if old_git is None:",
            "                # On the first refresh (when GIT_PYTHON_GIT_EXECUTABLE is None) we only",
            "                # are quiet, warn, or error depending on the GIT_PYTHON_REFRESH value.",
            "",
            "                # Determine what the user wants to happen during the initial refresh we",
            "                # expect GIT_PYTHON_REFRESH to either be unset or be one of the",
            "                # following values:",
            "                #",
            "                #   0|q|quiet|s|silence|n|none",
            "                #   1|w|warn|warning",
            "                #   2|r|raise|e|error",
            "",
            "                mode = os.environ.get(cls._refresh_env_var, \"raise\").lower()",
            "",
            "                quiet = [\"quiet\", \"q\", \"silence\", \"s\", \"none\", \"n\", \"0\"]",
            "                warn = [\"warn\", \"w\", \"warning\", \"1\"]",
            "                error = [\"error\", \"e\", \"raise\", \"r\", \"2\"]",
            "",
            "                if mode in quiet:",
            "                    pass",
            "                elif mode in warn or mode in error:",
            "                    err = (",
            "                        dedent(",
            "                            \"\"\"\\",
            "                        %s",
            "                        All git commands will error until this is rectified.",
            "",
            "                        This initial warning can be silenced or aggravated in the future by setting the",
            "                        $%s environment variable. Use one of the following values:",
            "                            - %s: for no warning or exception",
            "                            - %s: for a printed warning",
            "                            - %s: for a raised exception",
            "",
            "                        Example:",
            "                            export %s=%s",
            "                        \"\"\"",
            "                        )",
            "                        % (",
            "                            err,",
            "                            cls._refresh_env_var,",
            "                            \"|\".join(quiet),",
            "                            \"|\".join(warn),",
            "                            \"|\".join(error),",
            "                            cls._refresh_env_var,",
            "                            quiet[0],",
            "                        )",
            "                    )",
            "",
            "                    if mode in warn:",
            "                        print(\"WARNING: %s\" % err)",
            "                    else:",
            "                        raise ImportError(err)",
            "                else:",
            "                    err = (",
            "                        dedent(",
            "                            \"\"\"\\",
            "                        %s environment variable has been set but it has been set with an invalid value.",
            "",
            "                        Use only the following values:",
            "                            - %s: for no warning or exception",
            "                            - %s: for a printed warning",
            "                            - %s: for a raised exception",
            "                        \"\"\"",
            "                        )",
            "                        % (",
            "                            cls._refresh_env_var,",
            "                            \"|\".join(quiet),",
            "                            \"|\".join(warn),",
            "                            \"|\".join(error),",
            "                        )",
            "                    )",
            "                    raise ImportError(err)",
            "",
            "                # We get here if this was the init refresh and the refresh mode was not",
            "                # error. Go ahead and set the GIT_PYTHON_GIT_EXECUTABLE such that we",
            "                # discern the difference between a first import and a second import.",
            "                cls.GIT_PYTHON_GIT_EXECUTABLE = cls.git_exec_name",
            "            else:",
            "                # After the first refresh (when GIT_PYTHON_GIT_EXECUTABLE is no longer",
            "                # None) we raise an exception.",
            "                raise GitCommandNotFound(\"git\", err)",
            "",
            "        return has_git",
            "",
            "    @classmethod",
            "    def is_cygwin(cls) -> bool:",
            "        return is_cygwin_git(cls.GIT_PYTHON_GIT_EXECUTABLE)",
            "",
            "    @overload",
            "    @classmethod",
            "    def polish_url(cls, url: str, is_cygwin: Literal[False] = ...) -> str:",
            "        ...",
            "",
            "    @overload",
            "    @classmethod",
            "    def polish_url(cls, url: str, is_cygwin: Union[None, bool] = None) -> str:",
            "        ...",
            "",
            "    @classmethod",
            "    def polish_url(cls, url: str, is_cygwin: Union[None, bool] = None) -> PathLike:",
            "        \"\"\"Remove any backslashes from urls to be written in config files.",
            "",
            "        Windows might create config files containing paths with backslashes,",
            "        but git stops liking them as it will escape the backslashes. Hence we",
            "        undo the escaping just to be sure.",
            "        \"\"\"",
            "        if is_cygwin is None:",
            "            is_cygwin = cls.is_cygwin()",
            "",
            "        if is_cygwin:",
            "            url = cygpath(url)",
            "        else:",
            "            url = os.path.expandvars(url)",
            "            if url.startswith(\"~\"):",
            "                url = os.path.expanduser(url)",
            "            url = url.replace(\"\\\\\\\\\", \"\\\\\").replace(\"\\\\\", \"/\")",
            "        return url",
            "",
            "    @classmethod",
            "    def check_unsafe_protocols(cls, url: str) -> None:",
            "        \"\"\"Check for unsafe protocols.",
            "",
            "        Apart from the usual protocols (http, git, ssh),",
            "        Git allows \"remote helpers\" that have the form ``<transport>::<address>``.",
            "        One of these helpers (``ext::``) can be used to invoke any arbitrary command.",
            "",
            "        See:",
            "",
            "        - https://git-scm.com/docs/gitremote-helpers",
            "        - https://git-scm.com/docs/git-remote-ext",
            "        \"\"\"",
            "        match = cls.re_unsafe_protocol.match(url)",
            "        if match:",
            "            protocol = match.group(1)",
            "            raise UnsafeProtocolError(",
            "                f\"The `{protocol}::` protocol looks suspicious, use `allow_unsafe_protocols=True` to allow it.\"",
            "            )",
            "",
            "    @classmethod",
            "    def check_unsafe_options(cls, options: List[str], unsafe_options: List[str]) -> None:",
            "        \"\"\"Check for unsafe options.",
            "",
            "        Some options that are passed to `git <command>` can be used to execute",
            "        arbitrary commands, this are blocked by default.",
            "        \"\"\"",
            "        # Options can be of the form `foo` or `--foo bar` `--foo=bar`,",
            "        # so we need to check if they start with \"--foo\" or if they are equal to \"foo\".",
            "        bare_unsafe_options = [option.lstrip(\"-\") for option in unsafe_options]",
            "        for option in options:",
            "            for unsafe_option, bare_option in zip(unsafe_options, bare_unsafe_options):",
            "                if option.startswith(unsafe_option) or option == bare_option:",
            "                    raise UnsafeOptionError(",
            "                        f\"{unsafe_option} is not allowed, use `allow_unsafe_options=True` to allow it.\"",
            "                    )",
            "",
            "    class AutoInterrupt:",
            "        \"\"\"Process wrapper that terminates the wrapped process on finalization.",
            "",
            "        This kills/interrupts the stored process instance once this instance goes out of",
            "        scope. It is used to prevent processes piling up in case iterators stop reading.",
            "",
            "        All attributes are wired through to the contained process object.",
            "",
            "        The wait method is overridden to perform automatic status code checking and",
            "        possibly raise.",
            "        \"\"\"",
            "",
            "        __slots__ = (\"proc\", \"args\", \"status\")",
            "",
            "        # If this is non-zero it will override any status code during",
            "        # _terminate, used to prevent race conditions in testing.",
            "        _status_code_if_terminate: int = 0",
            "",
            "        def __init__(self, proc: Union[None, subprocess.Popen], args: Any) -> None:",
            "            self.proc = proc",
            "            self.args = args",
            "            self.status: Union[int, None] = None",
            "",
            "        def _terminate(self) -> None:",
            "            \"\"\"Terminate the underlying process.\"\"\"",
            "            if self.proc is None:",
            "                return",
            "",
            "            proc = self.proc",
            "            self.proc = None",
            "            if proc.stdin:",
            "                proc.stdin.close()",
            "            if proc.stdout:",
            "                proc.stdout.close()",
            "            if proc.stderr:",
            "                proc.stderr.close()",
            "            # Did the process finish already so we have a return code?",
            "            try:",
            "                if proc.poll() is not None:",
            "                    self.status = self._status_code_if_terminate or proc.poll()",
            "                    return",
            "            except OSError as ex:",
            "                log.info(\"Ignored error after process had died: %r\", ex)",
            "",
            "            # It can be that nothing really exists anymore...",
            "            if os is None or getattr(os, \"kill\", None) is None:",
            "                return",
            "",
            "            # Try to kill it.",
            "            try:",
            "                proc.terminate()",
            "                status = proc.wait()  # Ensure the process goes away.",
            "",
            "                self.status = self._status_code_if_terminate or status",
            "            except OSError as ex:",
            "                log.info(\"Ignored error after process had died: %r\", ex)",
            "            # END exception handling",
            "",
            "        def __del__(self) -> None:",
            "            self._terminate()",
            "",
            "        def __getattr__(self, attr: str) -> Any:",
            "            return getattr(self.proc, attr)",
            "",
            "        # TODO: Bad choice to mimic `proc.wait()` but with different args.",
            "        def wait(self, stderr: Union[None, str, bytes] = b\"\") -> int:",
            "            \"\"\"Wait for the process and return its status code.",
            "",
            "            :param stderr: Previously read value of stderr, in case stderr is already closed.",
            "            :warn: May deadlock if output or error pipes are used and not handled separately.",
            "            :raise GitCommandError: If the return status is not 0.",
            "            \"\"\"",
            "            if stderr is None:",
            "                stderr_b = b\"\"",
            "            stderr_b = force_bytes(data=stderr, encoding=\"utf-8\")",
            "            status: Union[int, None]",
            "            if self.proc is not None:",
            "                status = self.proc.wait()",
            "                p_stderr = self.proc.stderr",
            "            else:  # Assume the underlying proc was killed earlier or never existed.",
            "                status = self.status",
            "                p_stderr = None",
            "",
            "            def read_all_from_possibly_closed_stream(stream: Union[IO[bytes], None]) -> bytes:",
            "                if stream:",
            "                    try:",
            "                        return stderr_b + force_bytes(stream.read())",
            "                    except (OSError, ValueError):",
            "                        return stderr_b or b\"\"",
            "                else:",
            "                    return stderr_b or b\"\"",
            "",
            "            # END status handling",
            "",
            "            if status != 0:",
            "                errstr = read_all_from_possibly_closed_stream(p_stderr)",
            "                log.debug(\"AutoInterrupt wait stderr: %r\" % (errstr,))",
            "                raise GitCommandError(remove_password_if_present(self.args), status, errstr)",
            "            return status",
            "",
            "    # END auto interrupt",
            "",
            "    class CatFileContentStream:",
            "        \"\"\"Object representing a sized read-only stream returning the contents of",
            "        an object.",
            "",
            "        This behaves like a stream, but counts the data read and simulates an empty",
            "        stream once our sized content region is empty.",
            "",
            "        If not all data are read to the end of the object's lifetime, we read the",
            "        rest to ensure the underlying stream continues to work.",
            "        \"\"\"",
            "",
            "        __slots__: Tuple[str, ...] = (\"_stream\", \"_nbr\", \"_size\")",
            "",
            "        def __init__(self, size: int, stream: IO[bytes]) -> None:",
            "            self._stream = stream",
            "            self._size = size",
            "            self._nbr = 0  # Number of bytes read.",
            "",
            "            # Special case: If the object is empty, has null bytes, get the",
            "            # final newline right away.",
            "            if size == 0:",
            "                stream.read(1)",
            "            # END handle empty streams",
            "",
            "        def read(self, size: int = -1) -> bytes:",
            "            bytes_left = self._size - self._nbr",
            "            if bytes_left == 0:",
            "                return b\"\"",
            "            if size > -1:",
            "                # Ensure we don't try to read past our limit.",
            "                size = min(bytes_left, size)",
            "            else:",
            "                # They try to read all, make sure it's not more than what remains.",
            "                size = bytes_left",
            "            # END check early depletion",
            "            data = self._stream.read(size)",
            "            self._nbr += len(data)",
            "",
            "            # Check for depletion, read our final byte to make the stream usable by others.",
            "            if self._size - self._nbr == 0:",
            "                self._stream.read(1)  # final newline",
            "            # END finish reading",
            "            return data",
            "",
            "        def readline(self, size: int = -1) -> bytes:",
            "            if self._nbr == self._size:",
            "                return b\"\"",
            "",
            "            # Clamp size to lowest allowed value.",
            "            bytes_left = self._size - self._nbr",
            "            if size > -1:",
            "                size = min(bytes_left, size)",
            "            else:",
            "                size = bytes_left",
            "            # END handle size",
            "",
            "            data = self._stream.readline(size)",
            "            self._nbr += len(data)",
            "",
            "            # Handle final byte.",
            "            if self._size - self._nbr == 0:",
            "                self._stream.read(1)",
            "            # END finish reading",
            "",
            "            return data",
            "",
            "        def readlines(self, size: int = -1) -> List[bytes]:",
            "            if self._nbr == self._size:",
            "                return []",
            "",
            "            # Leave all additional logic to our readline method, we just check the size.",
            "            out = []",
            "            nbr = 0",
            "            while True:",
            "                line = self.readline()",
            "                if not line:",
            "                    break",
            "                out.append(line)",
            "                if size > -1:",
            "                    nbr += len(line)",
            "                    if nbr > size:",
            "                        break",
            "                # END handle size constraint",
            "            # END readline loop",
            "            return out",
            "",
            "        # skipcq: PYL-E0301",
            "        def __iter__(self) -> \"Git.CatFileContentStream\":",
            "            return self",
            "",
            "        def __next__(self) -> bytes:",
            "            line = self.readline()",
            "            if not line:",
            "                raise StopIteration",
            "",
            "            return line",
            "",
            "        next = __next__",
            "",
            "        def __del__(self) -> None:",
            "            bytes_left = self._size - self._nbr",
            "            if bytes_left:",
            "                # Read and discard - seeking is impossible within a stream.",
            "                # This includes any terminating newline.",
            "                self._stream.read(bytes_left + 1)",
            "            # END handle incomplete read",
            "",
            "    def __init__(self, working_dir: Union[None, PathLike] = None):",
            "        \"\"\"Initialize this instance with:",
            "",
            "        :param working_dir:",
            "           Git directory we should work in. If None, we always work in the current",
            "           directory as returned by :func:`os.getcwd`.",
            "           It is meant to be the working tree directory if available, or the",
            "           ``.git`` directory in case of bare repositories.",
            "        \"\"\"",
            "        super().__init__()",
            "        self._working_dir = expand_path(working_dir)",
            "        self._git_options: Union[List[str], Tuple[str, ...]] = ()",
            "        self._persistent_git_options: List[str] = []",
            "",
            "        # Extra environment variables to pass to git commands",
            "        self._environment: Dict[str, str] = {}",
            "",
            "        # Cached command slots",
            "        self.cat_file_header: Union[None, TBD] = None",
            "        self.cat_file_all: Union[None, TBD] = None",
            "",
            "    def __getattr__(self, name: str) -> Any:",
            "        \"\"\"A convenience method as it allows to call the command as if it was",
            "        an object.",
            "",
            "        :return:",
            "            Callable object that will execute call :meth:`_call_process` with",
            "            your arguments.",
            "        \"\"\"",
            "        if name[0] == \"_\":",
            "            return LazyMixin.__getattr__(self, name)",
            "        return lambda *args, **kwargs: self._call_process(name, *args, **kwargs)",
            "",
            "    def set_persistent_git_options(self, **kwargs: Any) -> None:",
            "        \"\"\"Specify command line options to the git executable for subsequent",
            "        subcommand calls.",
            "",
            "        :param kwargs:",
            "            A dict of keyword arguments.",
            "            These arguments are passed as in :meth:`_call_process`, but will be",
            "            passed to the git command rather than the subcommand.",
            "        \"\"\"",
            "",
            "        self._persistent_git_options = self.transform_kwargs(split_single_char_options=True, **kwargs)",
            "",
            "    def _set_cache_(self, attr: str) -> None:",
            "        if attr == \"_version_info\":",
            "            # We only use the first 4 numbers, as everything else could be strings in fact (on Windows).",
            "            process_version = self._call_process(\"version\")  # Should be as default *args and **kwargs used.",
            "            version_numbers = process_version.split(\" \")[2]",
            "",
            "            self._version_info = cast(",
            "                Tuple[int, int, int, int],",
            "                tuple(int(n) for n in version_numbers.split(\".\")[:4] if n.isdigit()),",
            "            )",
            "        else:",
            "            super()._set_cache_(attr)",
            "        # END handle version info",
            "",
            "    @property",
            "    def working_dir(self) -> Union[None, PathLike]:",
            "        \"\"\":return: Git directory we are working on\"\"\"",
            "        return self._working_dir",
            "",
            "    @property",
            "    def version_info(self) -> Tuple[int, int, int, int]:",
            "        \"\"\"",
            "        :return: tuple(int, int, int, int) tuple with integers representing the major, minor",
            "            and additional version numbers as parsed from git version.",
            "",
            "            This value is generated on demand and is cached.",
            "        \"\"\"",
            "        return self._version_info",
            "",
            "    @overload",
            "    def execute(self, command: Union[str, Sequence[Any]], *, as_process: Literal[True]) -> \"AutoInterrupt\":",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        as_process: Literal[False] = False,",
            "        stdout_as_string: Literal[True],",
            "    ) -> Union[str, Tuple[int, str, str]]:",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        as_process: Literal[False] = False,",
            "        stdout_as_string: Literal[False] = False,",
            "    ) -> Union[bytes, Tuple[int, bytes, str]]:",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        with_extended_output: Literal[False],",
            "        as_process: Literal[False],",
            "        stdout_as_string: Literal[True],",
            "    ) -> str:",
            "        ...",
            "",
            "    @overload",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        *,",
            "        with_extended_output: Literal[False],",
            "        as_process: Literal[False],",
            "        stdout_as_string: Literal[False],",
            "    ) -> bytes:",
            "        ...",
            "",
            "    def execute(",
            "        self,",
            "        command: Union[str, Sequence[Any]],",
            "        istream: Union[None, BinaryIO] = None,",
            "        with_extended_output: bool = False,",
            "        with_exceptions: bool = True,",
            "        as_process: bool = False,",
            "        output_stream: Union[None, BinaryIO] = None,",
            "        stdout_as_string: bool = True,",
            "        kill_after_timeout: Union[None, float] = None,",
            "        with_stdout: bool = True,",
            "        universal_newlines: bool = False,",
            "        shell: Union[None, bool] = None,",
            "        env: Union[None, Mapping[str, str]] = None,",
            "        max_chunk_size: int = io.DEFAULT_BUFFER_SIZE,",
            "        strip_newline_in_stdout: bool = True,",
            "        **subprocess_kwargs: Any,",
            "    ) -> Union[str, bytes, Tuple[int, Union[str, bytes], str], AutoInterrupt]:",
            "        R\"\"\"Handle executing the command, and consume and return the returned",
            "        information (stdout).",
            "",
            "        :param command:",
            "            The command argument list to execute.",
            "            It should be a sequence of program arguments, or a string. The",
            "            program to execute is the first item in the args sequence or string.",
            "",
            "        :param istream:",
            "            Standard input filehandle passed to :class:`subprocess.Popen`.",
            "",
            "        :param with_extended_output:",
            "            Whether to return a (status, stdout, stderr) tuple.",
            "",
            "        :param with_exceptions:",
            "            Whether to raise an exception when git returns a non-zero status.",
            "",
            "        :param as_process:",
            "            Whether to return the created process instance directly from which",
            "            streams can be read on demand. This will render `with_extended_output`",
            "            and `with_exceptions` ineffective - the caller will have to deal with",
            "            the details. It is important to note that the process will be placed",
            "            into an :class:`AutoInterrupt` wrapper that will interrupt the process",
            "            once it goes out of scope. If you use the command in iterators, you",
            "            should pass the whole process instance instead of a single stream.",
            "",
            "        :param output_stream:",
            "            If set to a file-like object, data produced by the git command will be",
            "            output to the given stream directly.",
            "            This feature only has any effect if `as_process` is False. Processes will",
            "            always be created with a pipe due to issues with subprocess.",
            "            This merely is a workaround as data will be copied from the",
            "            output pipe to the given output stream directly.",
            "            Judging from the implementation, you shouldn't use this parameter!",
            "",
            "        :param stdout_as_string:",
            "            If False, the command's standard output will be bytes. Otherwise, it will be",
            "            decoded into a string using the default encoding (usually UTF-8).",
            "            The latter can fail, if the output contains binary data.",
            "",
            "        :param kill_after_timeout:",
            "            Specifies a timeout in seconds for the git command, after which the process",
            "            should be killed. This will have no effect if `as_process` is set to True.",
            "            It is set to None by default and will let the process run until the timeout",
            "            is explicitly specified. Uses of this feature should be carefully",
            "            considered, due to the following limitations:",
            "",
            "            1. This feature is not supported at all on Windows.",
            "            2. Effectiveness may vary by operating system. ``ps --ppid`` is used to",
            "               enumerate child processes, which is available on most GNU/Linux systems",
            "               but not most others.",
            "            3. Deeper descendants do not receive signals, though they may sometimes",
            "               terminate as a consequence of their parent processes being killed.",
            "            4. `kill_after_timeout` uses ``SIGKILL``, which can have negative side",
            "               effects on a repository. For example, stale locks in case of ``git gc``",
            "               could render the repository incapable of accepting changes until the lock",
            "               is manually removed.",
            "",
            "        :param with_stdout:",
            "            If True, default True, we open stdout on the created process.",
            "",
            "        :param universal_newlines:",
            "            if True, pipes will be opened as text, and lines are split at",
            "            all known line endings.",
            "",
            "        :param shell:",
            "            Whether to invoke commands through a shell (see `Popen(..., shell=True)`).",
            "            If this is not `None`, it overrides :attr:`USE_SHELL`.",
            "",
            "            Passing ``shell=True`` to this or any other GitPython function should be",
            "            avoided, as it is unsafe under most circumstances. This is because it is",
            "            typically not feasible to fully consider and account for the effect of shell",
            "            expansions, especially when passing ``shell=True`` to other methods that",
            "            forward it to :meth:`Git.execute`. Passing ``shell=True`` is also no longer",
            "            needed (nor useful) to work around any known operating system specific",
            "            issues.",
            "",
            "        :param env:",
            "            A dictionary of environment variables to be passed to :class:`subprocess.Popen`.",
            "",
            "        :param max_chunk_size:",
            "            Maximum number of bytes in one chunk of data passed to the output_stream in",
            "            one invocation of write() method. If the given number is not positive then",
            "            the default value is used.",
            "",
            "        :param strip_newline_in_stdout:",
            "            Whether to strip the trailing ``\\n`` of the command stdout.",
            "",
            "        :param subprocess_kwargs:",
            "            Keyword arguments to be passed to :class:`subprocess.Popen`. Please note",
            "            that some of the valid kwargs are already set by this method; the ones you",
            "            specify may not be the same ones.",
            "",
            "        :return:",
            "            * str(output) if extended_output = False (Default)",
            "            * tuple(int(status), str(stdout), str(stderr)) if extended_output = True",
            "",
            "            If output_stream is True, the stdout value will be your output stream:",
            "            * output_stream if extended_output = False",
            "            * tuple(int(status), output_stream, str(stderr)) if extended_output = True",
            "",
            "            Note that git is executed with ``LC_MESSAGES=\"C\"`` to ensure consistent",
            "            output regardless of system language.",
            "",
            "        :raise GitCommandError:",
            "",
            "        :note:",
            "           If you add additional keyword arguments to the signature of this method,",
            "           you must update the execute_kwargs tuple housed in this module.",
            "        \"\"\"",
            "        # Remove password for the command if present.",
            "        redacted_command = remove_password_if_present(command)",
            "        if self.GIT_PYTHON_TRACE and (self.GIT_PYTHON_TRACE != \"full\" or as_process):",
            "            log.info(\" \".join(redacted_command))",
            "",
            "        # Allow the user to have the command executed in their working dir.",
            "        try:",
            "            cwd = self._working_dir or os.getcwd()  # type: Union[None, str]",
            "            if not os.access(str(cwd), os.X_OK):",
            "                cwd = None",
            "        except FileNotFoundError:",
            "            cwd = None",
            "",
            "        # Start the process.",
            "        inline_env = env",
            "        env = os.environ.copy()",
            "        # Attempt to force all output to plain ASCII English, which is what some parsing",
            "        # code may expect.",
            "        # According to https://askubuntu.com/a/311796, we are setting LANGUAGE as well",
            "        # just to be sure.",
            "        env[\"LANGUAGE\"] = \"C\"",
            "        env[\"LC_ALL\"] = \"C\"",
            "        env.update(self._environment)",
            "        if inline_env is not None:",
            "            env.update(inline_env)",
            "",
            "        if os.name == \"nt\":",
            "            cmd_not_found_exception = OSError",
            "            if kill_after_timeout is not None:",
            "                raise GitCommandError(",
            "                    redacted_command,",
            "                    '\"kill_after_timeout\" feature is not supported on Windows.',",
            "                )",
            "        else:",
            "            cmd_not_found_exception = FileNotFoundError",
            "        # END handle",
            "",
            "        stdout_sink = PIPE if with_stdout else getattr(subprocess, \"DEVNULL\", None) or open(os.devnull, \"wb\")",
            "        if shell is None:",
            "            shell = self.USE_SHELL",
            "        log.debug(",
            "            \"Popen(%s, cwd=%s, stdin=%s, shell=%s, universal_newlines=%s)\",",
            "            redacted_command,",
            "            cwd,",
            "            \"<valid stream>\" if istream else \"None\",",
            "            shell,",
            "            universal_newlines,",
            "        )",
            "        try:",
            "            proc = safer_popen(",
            "                command,",
            "                env=env,",
            "                cwd=cwd,",
            "                bufsize=-1,",
            "                stdin=(istream or DEVNULL),",
            "                stderr=PIPE,",
            "                stdout=stdout_sink,",
            "                shell=shell,",
            "                universal_newlines=universal_newlines,",
            "                **subprocess_kwargs,",
            "            )",
            "        except cmd_not_found_exception as err:",
            "            raise GitCommandNotFound(redacted_command, err) from err",
            "        else:",
            "            # Replace with a typeguard for Popen[bytes]?",
            "            proc.stdout = cast(BinaryIO, proc.stdout)",
            "            proc.stderr = cast(BinaryIO, proc.stderr)",
            "",
            "        if as_process:",
            "            return self.AutoInterrupt(proc, command)",
            "",
            "        def kill_process(pid: int) -> None:",
            "            \"\"\"Callback to kill a process.\"\"\"",
            "            if os.name == \"nt\":",
            "                raise AssertionError(\"Bug: This callback would be ineffective and unsafe on Windows, stopping.\")",
            "            p = Popen([\"ps\", \"--ppid\", str(pid)], stdout=PIPE)",
            "            child_pids = []",
            "            if p.stdout is not None:",
            "                for line in p.stdout:",
            "                    if len(line.split()) > 0:",
            "                        local_pid = (line.split())[0]",
            "                        if local_pid.isdigit():",
            "                            child_pids.append(int(local_pid))",
            "            try:",
            "                os.kill(pid, signal.SIGKILL)",
            "                for child_pid in child_pids:",
            "                    try:",
            "                        os.kill(child_pid, signal.SIGKILL)",
            "                    except OSError:",
            "                        pass",
            "                kill_check.set()  # Tell the main routine that the process was killed.",
            "            except OSError:",
            "                # It is possible that the process gets completed in the duration after",
            "                # timeout happens and before we try to kill the process.",
            "                pass",
            "            return",
            "",
            "        # END kill_process",
            "",
            "        if kill_after_timeout is not None:",
            "            kill_check = threading.Event()",
            "            watchdog = threading.Timer(kill_after_timeout, kill_process, args=(proc.pid,))",
            "",
            "        # Wait for the process to return.",
            "        status = 0",
            "        stdout_value: Union[str, bytes] = b\"\"",
            "        stderr_value: Union[str, bytes] = b\"\"",
            "        newline = \"\\n\" if universal_newlines else b\"\\n\"",
            "        try:",
            "            if output_stream is None:",
            "                if kill_after_timeout is not None:",
            "                    watchdog.start()",
            "                stdout_value, stderr_value = proc.communicate()",
            "                if kill_after_timeout is not None:",
            "                    watchdog.cancel()",
            "                    if kill_check.is_set():",
            "                        stderr_value = 'Timeout: the command \"%s\" did not complete in %d ' \"secs.\" % (",
            "                            \" \".join(redacted_command),",
            "                            kill_after_timeout,",
            "                        )",
            "                        if not universal_newlines:",
            "                            stderr_value = stderr_value.encode(defenc)",
            "                # Strip trailing \"\\n\".",
            "                if stdout_value.endswith(newline) and strip_newline_in_stdout:  # type: ignore",
            "                    stdout_value = stdout_value[:-1]",
            "                if stderr_value.endswith(newline):  # type: ignore",
            "                    stderr_value = stderr_value[:-1]",
            "",
            "                status = proc.returncode",
            "            else:",
            "                max_chunk_size = max_chunk_size if max_chunk_size and max_chunk_size > 0 else io.DEFAULT_BUFFER_SIZE",
            "                stream_copy(proc.stdout, output_stream, max_chunk_size)",
            "                stdout_value = proc.stdout.read()",
            "                stderr_value = proc.stderr.read()",
            "                # Strip trailing \"\\n\".",
            "                if stderr_value.endswith(newline):  # type: ignore",
            "                    stderr_value = stderr_value[:-1]",
            "                status = proc.wait()",
            "            # END stdout handling",
            "        finally:",
            "            proc.stdout.close()",
            "            proc.stderr.close()",
            "",
            "        if self.GIT_PYTHON_TRACE == \"full\":",
            "            cmdstr = \" \".join(redacted_command)",
            "",
            "            def as_text(stdout_value: Union[bytes, str]) -> str:",
            "                return not output_stream and safe_decode(stdout_value) or \"<OUTPUT_STREAM>\"",
            "",
            "            # END as_text",
            "",
            "            if stderr_value:",
            "                log.info(",
            "                    \"%s -> %d; stdout: '%s'; stderr: '%s'\",",
            "                    cmdstr,",
            "                    status,",
            "                    as_text(stdout_value),",
            "                    safe_decode(stderr_value),",
            "                )",
            "            elif stdout_value:",
            "                log.info(\"%s -> %d; stdout: '%s'\", cmdstr, status, as_text(stdout_value))",
            "            else:",
            "                log.info(\"%s -> %d\", cmdstr, status)",
            "        # END handle debug printing",
            "",
            "        if with_exceptions and status != 0:",
            "            raise GitCommandError(redacted_command, status, stderr_value, stdout_value)",
            "",
            "        if isinstance(stdout_value, bytes) and stdout_as_string:  # Could also be output_stream.",
            "            stdout_value = safe_decode(stdout_value)",
            "",
            "        # Allow access to the command's status code.",
            "        if with_extended_output:",
            "            return (status, stdout_value, safe_decode(stderr_value))",
            "        else:",
            "            return stdout_value",
            "",
            "    def environment(self) -> Dict[str, str]:",
            "        return self._environment",
            "",
            "    def update_environment(self, **kwargs: Any) -> Dict[str, Union[str, None]]:",
            "        \"\"\"Set environment variables for future git invocations. Return all changed",
            "        values in a format that can be passed back into this function to revert the",
            "        changes.",
            "",
            "        ``Examples``::",
            "",
            "            old_env = self.update_environment(PWD='/tmp')",
            "            self.update_environment(**old_env)",
            "",
            "        :param kwargs: Environment variables to use for git processes",
            "",
            "        :return: Dict that maps environment variables to their old values",
            "        \"\"\"",
            "        old_env = {}",
            "        for key, value in kwargs.items():",
            "            # Set value if it is None.",
            "            if value is not None:",
            "                old_env[key] = self._environment.get(key)",
            "                self._environment[key] = value",
            "            # Remove key from environment if its value is None.",
            "            elif key in self._environment:",
            "                old_env[key] = self._environment[key]",
            "                del self._environment[key]",
            "        return old_env",
            "",
            "    @contextlib.contextmanager",
            "    def custom_environment(self, **kwargs: Any) -> Iterator[None]:",
            "        \"\"\"A context manager around the above :meth:`update_environment` method to",
            "        restore the environment back to its previous state after operation.",
            "",
            "        ``Examples``::",
            "",
            "            with self.custom_environment(GIT_SSH='/bin/ssh_wrapper'):",
            "                repo.remotes.origin.fetch()",
            "",
            "        :param kwargs: See :meth:`update_environment`",
            "        \"\"\"",
            "        old_env = self.update_environment(**kwargs)",
            "        try:",
            "            yield",
            "        finally:",
            "            self.update_environment(**old_env)",
            "",
            "    def transform_kwarg(self, name: str, value: Any, split_single_char_options: bool) -> List[str]:",
            "        if len(name) == 1:",
            "            if value is True:",
            "                return [\"-%s\" % name]",
            "            elif value not in (False, None):",
            "                if split_single_char_options:",
            "                    return [\"-%s\" % name, \"%s\" % value]",
            "                else:",
            "                    return [\"-%s%s\" % (name, value)]",
            "        else:",
            "            if value is True:",
            "                return [\"--%s\" % dashify(name)]",
            "            elif value is not False and value is not None:",
            "                return [\"--%s=%s\" % (dashify(name), value)]",
            "        return []",
            "",
            "    def transform_kwargs(self, split_single_char_options: bool = True, **kwargs: Any) -> List[str]:",
            "        \"\"\"Transform Python style kwargs into git command line options.\"\"\"",
            "        args = []",
            "        for k, v in kwargs.items():",
            "            if isinstance(v, (list, tuple)):",
            "                for value in v:",
            "                    args += self.transform_kwarg(k, value, split_single_char_options)",
            "            else:",
            "                args += self.transform_kwarg(k, v, split_single_char_options)",
            "        return args",
            "",
            "    @classmethod",
            "    def _unpack_args(cls, arg_list: Sequence[str]) -> List[str]:",
            "        outlist = []",
            "        if isinstance(arg_list, (list, tuple)):",
            "            for arg in arg_list:",
            "                outlist.extend(cls._unpack_args(arg))",
            "        else:",
            "            outlist.append(str(arg_list))",
            "",
            "        return outlist",
            "",
            "    def __call__(self, **kwargs: Any) -> \"Git\":",
            "        \"\"\"Specify command line options to the git executable for a subcommand call.",
            "",
            "        :param kwargs:",
            "            A dict of keyword arguments.",
            "            These arguments are passed as in :meth:`_call_process`, but will be",
            "            passed to the git command rather than the subcommand.",
            "",
            "        ``Examples``::",
            "            git(work_tree='/tmp').difftool()",
            "        \"\"\"",
            "        self._git_options = self.transform_kwargs(split_single_char_options=True, **kwargs)",
            "        return self",
            "",
            "    @overload",
            "    def _call_process(self, method: str, *args: None, **kwargs: None) -> str:",
            "        ...  # If no args were given, execute the call with all defaults.",
            "",
            "    @overload",
            "    def _call_process(",
            "        self,",
            "        method: str,",
            "        istream: int,",
            "        as_process: Literal[True],",
            "        *args: Any,",
            "        **kwargs: Any,",
            "    ) -> \"Git.AutoInterrupt\":",
            "        ...",
            "",
            "    @overload",
            "    def _call_process(",
            "        self, method: str, *args: Any, **kwargs: Any",
            "    ) -> Union[str, bytes, Tuple[int, Union[str, bytes], str], \"Git.AutoInterrupt\"]:",
            "        ...",
            "",
            "    def _call_process(",
            "        self, method: str, *args: Any, **kwargs: Any",
            "    ) -> Union[str, bytes, Tuple[int, Union[str, bytes], str], \"Git.AutoInterrupt\"]:",
            "        \"\"\"Run the given git command with the specified arguments and return",
            "        the result as a string.",
            "",
            "        :param method:",
            "            The command. Contained ``_`` characters will be converted to dashes,",
            "            such as in ``ls_files`` to call ``ls-files``.",
            "",
            "        :param args:",
            "            The list of arguments. If None is included, it will be pruned.",
            "            This allows your commands to call git more conveniently as None",
            "            is realized as non-existent.",
            "",
            "        :param kwargs:",
            "            Contains key-values for the following:",
            "            - The :meth:`execute()` kwds, as listed in :var:`execute_kwargs`.",
            "            - \"Command options\" to be converted by :meth:`transform_kwargs`.",
            "            - The `'insert_kwargs_after'` key which its value must match one of ``*args``.",
            "            It also contains any command options, to be appended after the matched arg.",
            "",
            "        Examples::",
            "",
            "            git.rev_list('master', max_count=10, header=True)",
            "",
            "        turns into::",
            "",
            "           git rev-list max-count 10 --header master",
            "",
            "        :return: Same as :meth:`execute`.",
            "            If no args are given, used :meth:`execute`'s default (especially",
            "            ``as_process = False``, ``stdout_as_string = True``) and return str.",
            "        \"\"\"",
            "        # Handle optional arguments prior to calling transform_kwargs.",
            "        # Otherwise these'll end up in args, which is bad.",
            "        exec_kwargs = {k: v for k, v in kwargs.items() if k in execute_kwargs}",
            "        opts_kwargs = {k: v for k, v in kwargs.items() if k not in execute_kwargs}",
            "",
            "        insert_after_this_arg = opts_kwargs.pop(\"insert_kwargs_after\", None)",
            "",
            "        # Prepare the argument list.",
            "",
            "        opt_args = self.transform_kwargs(**opts_kwargs)",
            "        ext_args = self._unpack_args([a for a in args if a is not None])",
            "",
            "        if insert_after_this_arg is None:",
            "            args_list = opt_args + ext_args",
            "        else:",
            "            try:",
            "                index = ext_args.index(insert_after_this_arg)",
            "            except ValueError as err:",
            "                raise ValueError(",
            "                    \"Couldn't find argument '%s' in args %s to insert cmd options after\"",
            "                    % (insert_after_this_arg, str(ext_args))",
            "                ) from err",
            "            # END handle error",
            "            args_list = ext_args[: index + 1] + opt_args + ext_args[index + 1 :]",
            "        # END handle opts_kwargs",
            "",
            "        call = [self.GIT_PYTHON_GIT_EXECUTABLE]",
            "",
            "        # Add persistent git options.",
            "        call.extend(self._persistent_git_options)",
            "",
            "        # Add the git options, then reset to empty to avoid side effects.",
            "        call.extend(self._git_options)",
            "        self._git_options = ()",
            "",
            "        call.append(dashify(method))",
            "        call.extend(args_list)",
            "",
            "        return self.execute(call, **exec_kwargs)",
            "",
            "    def _parse_object_header(self, header_line: str) -> Tuple[str, str, int]:",
            "        \"\"\"",
            "        :param header_line:",
            "            <hex_sha> type_string size_as_int",
            "",
            "        :return: (hex_sha, type_string, size_as_int)",
            "",
            "        :raise ValueError: If the header contains indication for an error due to",
            "            incorrect input sha",
            "        \"\"\"",
            "        tokens = header_line.split()",
            "        if len(tokens) != 3:",
            "            if not tokens:",
            "                err_msg = (",
            "                    f\"SHA is empty, possible dubious ownership in the repository \"",
            "                    f\"\"\"at {self._working_dir}.\\n            If this is unintended run:\\n\\n         \"\"\"",
            "                    f\"\"\"             \"git config --global --add safe.directory {self._working_dir}\" \"\"\"",
            "                )",
            "                raise ValueError(err_msg)",
            "            else:",
            "                raise ValueError(\"SHA %s could not be resolved, git returned: %r\" % (tokens[0], header_line.strip()))",
            "            # END handle actual return value",
            "        # END error handling",
            "",
            "        if len(tokens[0]) != 40:",
            "            raise ValueError(\"Failed to parse header: %r\" % header_line)",
            "        return (tokens[0], tokens[1], int(tokens[2]))",
            "",
            "    def _prepare_ref(self, ref: AnyStr) -> bytes:",
            "        # Required for command to separate refs on stdin, as bytes.",
            "        if isinstance(ref, bytes):",
            "            # Assume 40 bytes hexsha - bin-to-ascii for some reason returns bytes, not text.",
            "            refstr: str = ref.decode(\"ascii\")",
            "        elif not isinstance(ref, str):",
            "            refstr = str(ref)  # Could be ref-object.",
            "        else:",
            "            refstr = ref",
            "",
            "        if not refstr.endswith(\"\\n\"):",
            "            refstr += \"\\n\"",
            "        return refstr.encode(defenc)",
            "",
            "    def _get_persistent_cmd(self, attr_name: str, cmd_name: str, *args: Any, **kwargs: Any) -> \"Git.AutoInterrupt\":",
            "        cur_val = getattr(self, attr_name)",
            "        if cur_val is not None:",
            "            return cur_val",
            "",
            "        options = {\"istream\": PIPE, \"as_process\": True}",
            "        options.update(kwargs)",
            "",
            "        cmd = self._call_process(cmd_name, *args, **options)",
            "        setattr(self, attr_name, cmd)",
            "        cmd = cast(\"Git.AutoInterrupt\", cmd)",
            "        return cmd",
            "",
            "    def __get_object_header(self, cmd: \"Git.AutoInterrupt\", ref: AnyStr) -> Tuple[str, str, int]:",
            "        if cmd.stdin and cmd.stdout:",
            "            cmd.stdin.write(self._prepare_ref(ref))",
            "            cmd.stdin.flush()",
            "            return self._parse_object_header(cmd.stdout.readline())",
            "        else:",
            "            raise ValueError(\"cmd stdin was empty\")",
            "",
            "    def get_object_header(self, ref: str) -> Tuple[str, str, int]:",
            "        \"\"\"Use this method to quickly examine the type and size of the object behind",
            "        the given ref.",
            "",
            "        :note: The method will only suffer from the costs of command invocation",
            "            once and reuses the command in subsequent calls.",
            "",
            "        :return: (hexsha, type_string, size_as_int)",
            "        \"\"\"",
            "        cmd = self._get_persistent_cmd(\"cat_file_header\", \"cat_file\", batch_check=True)",
            "        return self.__get_object_header(cmd, ref)",
            "",
            "    def get_object_data(self, ref: str) -> Tuple[str, str, int, bytes]:",
            "        \"\"\"As get_object_header, but returns object data as well.",
            "",
            "        :return: (hexsha, type_string, size_as_int, data_string)",
            "        :note: Not threadsafe.",
            "        \"\"\"",
            "        hexsha, typename, size, stream = self.stream_object_data(ref)",
            "        data = stream.read(size)",
            "        del stream",
            "        return (hexsha, typename, size, data)",
            "",
            "    def stream_object_data(self, ref: str) -> Tuple[str, str, int, \"Git.CatFileContentStream\"]:",
            "        \"\"\"As get_object_header, but returns the data as a stream.",
            "",
            "        :return: (hexsha, type_string, size_as_int, stream)",
            "        :note: This method is not threadsafe, you need one independent Command instance per thread to be safe!",
            "        \"\"\"",
            "        cmd = self._get_persistent_cmd(\"cat_file_all\", \"cat_file\", batch=True)",
            "        hexsha, typename, size = self.__get_object_header(cmd, ref)",
            "        cmd_stdout = cmd.stdout if cmd.stdout is not None else io.BytesIO()",
            "        return (hexsha, typename, size, self.CatFileContentStream(size, cmd_stdout))",
            "",
            "    def clear_cache(self) -> \"Git\":",
            "        \"\"\"Clear all kinds of internal caches to release resources.",
            "",
            "        Currently persistent commands will be interrupted.",
            "",
            "        :return: self",
            "        \"\"\"",
            "        for cmd in (self.cat_file_all, self.cat_file_header):",
            "            if cmd:",
            "                cmd.__del__()",
            "",
            "        self.cat_file_all = None",
            "        self.cat_file_header = None",
            "        return self"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "105": [
                "handle_process_output"
            ],
            "228": [],
            "229": [],
            "230": [],
            "231": [
                "PROC_CREATIONFLAGS"
            ],
            "232": [],
            "233": [
                "PROC_CREATIONFLAGS"
            ],
            "234": [],
            "235": [],
            "995": [
                "Git",
                "execute"
            ],
            "996": [
                "Git",
                "execute"
            ],
            "999": [
                "Git",
                "execute"
            ],
            "1014": [
                "Git",
                "execute"
            ],
            "1015": [
                "Git",
                "execute"
            ],
            "1016": [
                "Git",
                "execute"
            ],
            "1017": [
                "Git",
                "execute"
            ],
            "1018": [
                "Git",
                "execute"
            ],
            "1019": [
                "Git",
                "execute"
            ],
            "1020": [
                "Git",
                "execute"
            ],
            "1021": [
                "Git",
                "execute"
            ],
            "1022": [
                "Git",
                "execute"
            ],
            "1023": [
                "Git",
                "execute"
            ],
            "1024": [
                "Git",
                "execute"
            ],
            "1025": [
                "Git",
                "execute"
            ],
            "1026": [
                "Git",
                "execute"
            ],
            "1027": [
                "Git",
                "execute"
            ]
        },
        "addLocation": []
    },
    "git/index/fun.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " )"
            },
            "1": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import subprocess"
            },
            "2": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from git.cmd import PROC_CREATIONFLAGS, handle_process_output"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+from git.cmd import handle_process_output, safer_popen"
            },
            "5": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from git.compat import defenc, force_bytes, force_text, safe_decode"
            },
            "6": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from git.exc import HookExecutionError, UnmergedEntriesError"
            },
            "7": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from git.objects.fun import ("
            },
            "8": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "             relative_hp = Path(hp).relative_to(index.repo.working_dir).as_posix()"
            },
            "9": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 99,
                "PatchRowcode": "             cmd = [\"bash.exe\", relative_hp]"
            },
            "10": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 100,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        process = subprocess.Popen("
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+        process = safer_popen("
            },
            "13": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 102,
                "PatchRowcode": "             cmd + list(args),"
            },
            "14": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "             env=env,"
            },
            "15": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "             stdout=subprocess.PIPE,"
            },
            "16": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "             stderr=subprocess.PIPE,"
            },
            "17": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 106,
                "PatchRowcode": "             cwd=index.repo.working_dir,"
            },
            "18": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            creationflags=PROC_CREATIONFLAGS,"
            },
            "19": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 107,
                "PatchRowcode": "         )"
            },
            "20": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 108,
                "PatchRowcode": "     except Exception as ex:"
            },
            "21": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 109,
                "PatchRowcode": "         raise HookExecutionError(hp, ex) from ex"
            }
        },
        "frontPatchFile": [
            "# This module is part of GitPython and is released under the",
            "# 3-Clause BSD License: https://opensource.org/license/bsd-3-clause/",
            "",
            "\"\"\"Standalone functions to accompany the index implementation and make it more versatile.\"\"\"",
            "",
            "from io import BytesIO",
            "import os",
            "import os.path as osp",
            "from pathlib import Path",
            "from stat import (",
            "    S_IFDIR,",
            "    S_IFLNK,",
            "    S_ISLNK,",
            "    S_ISDIR,",
            "    S_IFMT,",
            "    S_IFREG,",
            "    S_IXUSR,",
            ")",
            "import subprocess",
            "",
            "from git.cmd import PROC_CREATIONFLAGS, handle_process_output",
            "from git.compat import defenc, force_bytes, force_text, safe_decode",
            "from git.exc import HookExecutionError, UnmergedEntriesError",
            "from git.objects.fun import (",
            "    traverse_tree_recursive,",
            "    traverse_trees_recursive,",
            "    tree_to_stream,",
            ")",
            "from git.util import IndexFileSHA1Writer, finalize_process",
            "from gitdb.base import IStream",
            "from gitdb.typ import str_tree_type",
            "",
            "from .typ import BaseIndexEntry, IndexEntry, CE_NAMEMASK, CE_STAGESHIFT",
            "from .util import pack, unpack",
            "",
            "# typing -----------------------------------------------------------------------------",
            "",
            "from typing import Dict, IO, List, Sequence, TYPE_CHECKING, Tuple, Type, Union, cast",
            "",
            "from git.types import PathLike",
            "",
            "if TYPE_CHECKING:",
            "    from .base import IndexFile",
            "    from git.db import GitCmdObjectDB",
            "    from git.objects.tree import TreeCacheTup",
            "",
            "    # from git.objects.fun import EntryTupOrNone",
            "",
            "# ------------------------------------------------------------------------------------",
            "",
            "",
            "S_IFGITLINK = S_IFLNK | S_IFDIR",
            "\"\"\"Flags for a submodule.\"\"\"",
            "",
            "CE_NAMEMASK_INV = ~CE_NAMEMASK",
            "",
            "__all__ = (",
            "    \"write_cache\",",
            "    \"read_cache\",",
            "    \"write_tree_from_cache\",",
            "    \"entry_key\",",
            "    \"stat_mode_to_index_mode\",",
            "    \"S_IFGITLINK\",",
            "    \"run_commit_hook\",",
            "    \"hook_path\",",
            ")",
            "",
            "",
            "def hook_path(name: str, git_dir: PathLike) -> str:",
            "    \"\"\":return: path to the given named hook in the given git repository directory\"\"\"",
            "    return osp.join(git_dir, \"hooks\", name)",
            "",
            "",
            "def _has_file_extension(path: str) -> str:",
            "    return osp.splitext(path)[1]",
            "",
            "",
            "def run_commit_hook(name: str, index: \"IndexFile\", *args: str) -> None:",
            "    \"\"\"Run the commit hook of the given name. Silently ignore hooks that do not exist.",
            "",
            "    :param name: name of hook, like 'pre-commit'",
            "    :param index: IndexFile instance",
            "    :param args: Arguments passed to hook file",
            "    :raises HookExecutionError:",
            "    \"\"\"",
            "    hp = hook_path(name, index.repo.git_dir)",
            "    if not os.access(hp, os.X_OK):",
            "        return",
            "",
            "    env = os.environ.copy()",
            "    env[\"GIT_INDEX_FILE\"] = safe_decode(str(index.path))",
            "    env[\"GIT_EDITOR\"] = \":\"",
            "    cmd = [hp]",
            "    try:",
            "        if os.name == \"nt\" and not _has_file_extension(hp):",
            "            # Windows only uses extensions to determine how to open files",
            "            # (doesn't understand shebangs). Try using bash to run the hook.",
            "            relative_hp = Path(hp).relative_to(index.repo.working_dir).as_posix()",
            "            cmd = [\"bash.exe\", relative_hp]",
            "",
            "        process = subprocess.Popen(",
            "            cmd + list(args),",
            "            env=env,",
            "            stdout=subprocess.PIPE,",
            "            stderr=subprocess.PIPE,",
            "            cwd=index.repo.working_dir,",
            "            creationflags=PROC_CREATIONFLAGS,",
            "        )",
            "    except Exception as ex:",
            "        raise HookExecutionError(hp, ex) from ex",
            "    else:",
            "        stdout_list: List[str] = []",
            "        stderr_list: List[str] = []",
            "        handle_process_output(process, stdout_list.append, stderr_list.append, finalize_process)",
            "        stdout = \"\".join(stdout_list)",
            "        stderr = \"\".join(stderr_list)",
            "        if process.returncode != 0:",
            "            stdout = force_text(stdout, defenc)",
            "            stderr = force_text(stderr, defenc)",
            "            raise HookExecutionError(hp, process.returncode, stderr, stdout)",
            "    # END handle return code",
            "",
            "",
            "def stat_mode_to_index_mode(mode: int) -> int:",
            "    \"\"\"Convert the given mode from a stat call to the corresponding index mode",
            "    and return it.\"\"\"",
            "    if S_ISLNK(mode):  # symlinks",
            "        return S_IFLNK",
            "    if S_ISDIR(mode) or S_IFMT(mode) == S_IFGITLINK:  # submodules",
            "        return S_IFGITLINK",
            "    return S_IFREG | (mode & S_IXUSR and 0o755 or 0o644)  # blobs with or without executable bit",
            "",
            "",
            "def write_cache(",
            "    entries: Sequence[Union[BaseIndexEntry, \"IndexEntry\"]],",
            "    stream: IO[bytes],",
            "    extension_data: Union[None, bytes] = None,",
            "    ShaStreamCls: Type[IndexFileSHA1Writer] = IndexFileSHA1Writer,",
            ") -> None:",
            "    \"\"\"Write the cache represented by entries to a stream.",
            "",
            "    :param entries: **sorted** list of entries",
            "",
            "    :param stream: stream to wrap into the AdapterStreamCls - it is used for",
            "        final output.",
            "",
            "    :param ShaStreamCls: Type to use when writing to the stream. It produces a sha",
            "        while writing to it, before the data is passed on to the wrapped stream",
            "",
            "    :param extension_data: any kind of data to write as a trailer, it must begin",
            "        a 4 byte identifier, followed by its size (4 bytes).",
            "    \"\"\"",
            "    # Wrap the stream into a compatible writer.",
            "    stream_sha = ShaStreamCls(stream)",
            "",
            "    tell = stream_sha.tell",
            "    write = stream_sha.write",
            "",
            "    # Header",
            "    version = 2",
            "    write(b\"DIRC\")",
            "    write(pack(\">LL\", version, len(entries)))",
            "",
            "    # Body",
            "    for entry in entries:",
            "        beginoffset = tell()",
            "        write(entry.ctime_bytes)  # ctime",
            "        write(entry.mtime_bytes)  # mtime",
            "        path_str = str(entry.path)",
            "        path: bytes = force_bytes(path_str, encoding=defenc)",
            "        plen = len(path) & CE_NAMEMASK  # Path length",
            "        assert plen == len(path), \"Path %s too long to fit into index\" % entry.path",
            "        flags = plen | (entry.flags & CE_NAMEMASK_INV)  # Clear possible previous values.",
            "        write(",
            "            pack(",
            "                \">LLLLLL20sH\",",
            "                entry.dev,",
            "                entry.inode,",
            "                entry.mode,",
            "                entry.uid,",
            "                entry.gid,",
            "                entry.size,",
            "                entry.binsha,",
            "                flags,",
            "            )",
            "        )",
            "        write(path)",
            "        real_size = (tell() - beginoffset + 8) & ~7",
            "        write(b\"\\0\" * ((beginoffset + real_size) - tell()))",
            "    # END for each entry",
            "",
            "    # Write previously cached extensions data.",
            "    if extension_data is not None:",
            "        stream_sha.write(extension_data)",
            "",
            "    # Write the sha over the content.",
            "    stream_sha.write_sha()",
            "",
            "",
            "def read_header(stream: IO[bytes]) -> Tuple[int, int]:",
            "    \"\"\"Return tuple(version_long, num_entries) from the given stream\"\"\"",
            "    type_id = stream.read(4)",
            "    if type_id != b\"DIRC\":",
            "        raise AssertionError(\"Invalid index file header: %r\" % type_id)",
            "    unpacked = cast(Tuple[int, int], unpack(\">LL\", stream.read(4 * 2)))",
            "    version, num_entries = unpacked",
            "",
            "    # TODO: Handle version 3: extended data, see read-cache.c.",
            "    assert version in (1, 2)",
            "    return version, num_entries",
            "",
            "",
            "def entry_key(*entry: Union[BaseIndexEntry, PathLike, int]) -> Tuple[PathLike, int]:",
            "    \"\"\":return: Key suitable to be used for the index.entries dictionary",
            "",
            "    :param entry: One instance of type BaseIndexEntry or the path and the stage",
            "    \"\"\"",
            "",
            "    # def is_entry_key_tup(entry_key: Tuple) -> TypeGuard[Tuple[PathLike, int]]:",
            "    #     return isinstance(entry_key, tuple) and len(entry_key) == 2",
            "",
            "    if len(entry) == 1:",
            "        entry_first = entry[0]",
            "        assert isinstance(entry_first, BaseIndexEntry)",
            "        return (entry_first.path, entry_first.stage)",
            "    else:",
            "        # assert is_entry_key_tup(entry)",
            "        entry = cast(Tuple[PathLike, int], entry)",
            "        return entry",
            "    # END handle entry",
            "",
            "",
            "def read_cache(",
            "    stream: IO[bytes],",
            ") -> Tuple[int, Dict[Tuple[PathLike, int], \"IndexEntry\"], bytes, bytes]:",
            "    \"\"\"Read a cache file from the given stream.",
            "",
            "    :return: tuple(version, entries_dict, extension_data, content_sha)",
            "",
            "      * version is the integer version number.",
            "      * entries dict is a dictionary which maps IndexEntry instances to a path at a stage.",
            "      * extension_data is '' or 4 bytes of type + 4 bytes of size + size bytes.",
            "      * content_sha is a 20 byte sha on all cache file contents.",
            "    \"\"\"",
            "    version, num_entries = read_header(stream)",
            "    count = 0",
            "    entries: Dict[Tuple[PathLike, int], \"IndexEntry\"] = {}",
            "",
            "    read = stream.read",
            "    tell = stream.tell",
            "    while count < num_entries:",
            "        beginoffset = tell()",
            "        ctime = unpack(\">8s\", read(8))[0]",
            "        mtime = unpack(\">8s\", read(8))[0]",
            "        (dev, ino, mode, uid, gid, size, sha, flags) = unpack(\">LLLLLL20sH\", read(20 + 4 * 6 + 2))",
            "        path_size = flags & CE_NAMEMASK",
            "        path = read(path_size).decode(defenc)",
            "",
            "        real_size = (tell() - beginoffset + 8) & ~7",
            "        read((beginoffset + real_size) - tell())",
            "        entry = IndexEntry((mode, sha, flags, path, ctime, mtime, dev, ino, uid, gid, size))",
            "        # entry_key would be the method to use, but we save the effort.",
            "        entries[(path, entry.stage)] = entry",
            "        count += 1",
            "    # END for each entry",
            "",
            "    # The footer contains extension data and a sha on the content so far.",
            "    # Keep the extension footer,and verify we have a sha in the end.",
            "    # Extension data format is:",
            "    #   4 bytes ID",
            "    #   4 bytes length of chunk",
            "    #   Repeated 0 - N times",
            "    extension_data = stream.read(~0)",
            "    assert (",
            "        len(extension_data) > 19",
            "    ), \"Index Footer was not at least a sha on content as it was only %i bytes in size\" % len(extension_data)",
            "",
            "    content_sha = extension_data[-20:]",
            "",
            "    # Truncate the sha in the end as we will dynamically create it anyway.",
            "    extension_data = extension_data[:-20]",
            "",
            "    return (version, entries, extension_data, content_sha)",
            "",
            "",
            "def write_tree_from_cache(",
            "    entries: List[IndexEntry], odb: \"GitCmdObjectDB\", sl: slice, si: int = 0",
            ") -> Tuple[bytes, List[\"TreeCacheTup\"]]:",
            "    \"\"\"Create a tree from the given sorted list of entries and put the respective",
            "    trees into the given object database.",
            "",
            "    :param entries: **Sorted** list of IndexEntries",
            "    :param odb: Object database to store the trees in",
            "    :param si: Start index at which we should start creating subtrees",
            "    :param sl: Slice indicating the range we should process on the entries list",
            "    :return: tuple(binsha, list(tree_entry, ...)) a tuple of a sha and a list of",
            "        tree entries being a tuple of hexsha, mode, name",
            "    \"\"\"",
            "    tree_items: List[\"TreeCacheTup\"] = []",
            "",
            "    ci = sl.start",
            "    end = sl.stop",
            "    while ci < end:",
            "        entry = entries[ci]",
            "        if entry.stage != 0:",
            "            raise UnmergedEntriesError(entry)",
            "        # END abort on unmerged",
            "        ci += 1",
            "        rbound = entry.path.find(\"/\", si)",
            "        if rbound == -1:",
            "            # It's not a tree.",
            "            tree_items.append((entry.binsha, entry.mode, entry.path[si:]))",
            "        else:",
            "            # Find common base range.",
            "            base = entry.path[si:rbound]",
            "            xi = ci",
            "            while xi < end:",
            "                oentry = entries[xi]",
            "                orbound = oentry.path.find(\"/\", si)",
            "                if orbound == -1 or oentry.path[si:orbound] != base:",
            "                    break",
            "                # END abort on base mismatch",
            "                xi += 1",
            "            # END find common base",
            "",
            "            # Enter recursion.",
            "            # ci - 1 as we want to count our current item as well.",
            "            sha, _tree_entry_list = write_tree_from_cache(entries, odb, slice(ci - 1, xi), rbound + 1)",
            "            tree_items.append((sha, S_IFDIR, base))",
            "",
            "            # Skip ahead.",
            "            ci = xi",
            "        # END handle bounds",
            "    # END for each entry",
            "",
            "    # Finally create the tree.",
            "    sio = BytesIO()",
            "    tree_to_stream(tree_items, sio.write)  # Writes to stream as bytes, but doesn't change tree_items.",
            "    sio.seek(0)",
            "",
            "    istream = odb.store(IStream(str_tree_type, len(sio.getvalue()), sio))",
            "    return (istream.binsha, tree_items)",
            "",
            "",
            "def _tree_entry_to_baseindexentry(tree_entry: \"TreeCacheTup\", stage: int) -> BaseIndexEntry:",
            "    return BaseIndexEntry((tree_entry[1], tree_entry[0], stage << CE_STAGESHIFT, tree_entry[2]))",
            "",
            "",
            "def aggressive_tree_merge(odb: \"GitCmdObjectDB\", tree_shas: Sequence[bytes]) -> List[BaseIndexEntry]:",
            "    \"\"\"",
            "    :return: List of BaseIndexEntries representing the aggressive merge of the given",
            "        trees. All valid entries are on stage 0, whereas the conflicting ones are left",
            "        on stage 1, 2 or 3, whereas stage 1 corresponds to the common ancestor tree,",
            "        2 to our tree and 3 to 'their' tree.",
            "",
            "    :param tree_shas: 1, 2 or 3 trees as identified by their binary 20 byte shas.",
            "        If 1 or two, the entries will effectively correspond to the last given tree.",
            "        If 3 are given, a 3 way merge is performed.",
            "    \"\"\"",
            "    out: List[BaseIndexEntry] = []",
            "",
            "    # One and two way is the same for us, as we don't have to handle an existing",
            "    # index, instrea",
            "    if len(tree_shas) in (1, 2):",
            "        for entry in traverse_tree_recursive(odb, tree_shas[-1], \"\"):",
            "            out.append(_tree_entry_to_baseindexentry(entry, 0))",
            "        # END for each entry",
            "        return out",
            "    # END handle single tree",
            "",
            "    if len(tree_shas) > 3:",
            "        raise ValueError(\"Cannot handle %i trees at once\" % len(tree_shas))",
            "",
            "    # Three trees.",
            "    for base, ours, theirs in traverse_trees_recursive(odb, tree_shas, \"\"):",
            "        if base is not None:",
            "            # Base version exists.",
            "            if ours is not None:",
            "                # Ours exists.",
            "                if theirs is not None:",
            "                    # It exists in all branches. Ff it was changed in both",
            "                    # its a conflict. Otherwise, we take the changed version.",
            "                    # This should be the most common branch, so it comes first.",
            "                    if (base[0] != ours[0] and base[0] != theirs[0] and ours[0] != theirs[0]) or (",
            "                        base[1] != ours[1] and base[1] != theirs[1] and ours[1] != theirs[1]",
            "                    ):",
            "                        # Changed by both.",
            "                        out.append(_tree_entry_to_baseindexentry(base, 1))",
            "                        out.append(_tree_entry_to_baseindexentry(ours, 2))",
            "                        out.append(_tree_entry_to_baseindexentry(theirs, 3))",
            "                    elif base[0] != ours[0] or base[1] != ours[1]:",
            "                        # Only we changed it.",
            "                        out.append(_tree_entry_to_baseindexentry(ours, 0))",
            "                    else:",
            "                        # Either nobody changed it, or they did. In either",
            "                        # case, use theirs.",
            "                        out.append(_tree_entry_to_baseindexentry(theirs, 0))",
            "                    # END handle modification",
            "                else:",
            "                    if ours[0] != base[0] or ours[1] != base[1]:",
            "                        # They deleted it, we changed it, conflict.",
            "                        out.append(_tree_entry_to_baseindexentry(base, 1))",
            "                        out.append(_tree_entry_to_baseindexentry(ours, 2))",
            "                    # else:",
            "                    #   # We didn't change it, ignore.",
            "                    #   pass",
            "                    # END handle our change",
            "                # END handle theirs",
            "            else:",
            "                if theirs is None:",
            "                    # Deleted in both, its fine - it's out.",
            "                    pass",
            "                else:",
            "                    if theirs[0] != base[0] or theirs[1] != base[1]:",
            "                        # Deleted in ours, changed theirs, conflict.",
            "                        out.append(_tree_entry_to_baseindexentry(base, 1))",
            "                        out.append(_tree_entry_to_baseindexentry(theirs, 3))",
            "                    # END theirs changed",
            "                    # else:",
            "                    #   # Theirs didn't change.",
            "                    #   pass",
            "                # END handle theirs",
            "            # END handle ours",
            "        else:",
            "            # All three can't be None.",
            "            if ours is None:",
            "                # Added in their branch.",
            "                assert theirs is not None",
            "                out.append(_tree_entry_to_baseindexentry(theirs, 0))",
            "            elif theirs is None:",
            "                # Added in our branch.",
            "                out.append(_tree_entry_to_baseindexentry(ours, 0))",
            "            else:",
            "                # Both have it, except for the base, see whether it changed.",
            "                if ours[0] != theirs[0] or ours[1] != theirs[1]:",
            "                    out.append(_tree_entry_to_baseindexentry(ours, 2))",
            "                    out.append(_tree_entry_to_baseindexentry(theirs, 3))",
            "                else:",
            "                    # It was added the same in both.",
            "                    out.append(_tree_entry_to_baseindexentry(ours, 0))",
            "                # END handle two items",
            "            # END handle heads",
            "        # END handle base exists",
            "    # END for each entries tuple",
            "",
            "    return out"
        ],
        "afterPatchFile": [
            "# This module is part of GitPython and is released under the",
            "# 3-Clause BSD License: https://opensource.org/license/bsd-3-clause/",
            "",
            "\"\"\"Standalone functions to accompany the index implementation and make it more versatile.\"\"\"",
            "",
            "from io import BytesIO",
            "import os",
            "import os.path as osp",
            "from pathlib import Path",
            "from stat import (",
            "    S_IFDIR,",
            "    S_IFLNK,",
            "    S_ISLNK,",
            "    S_ISDIR,",
            "    S_IFMT,",
            "    S_IFREG,",
            "    S_IXUSR,",
            ")",
            "import subprocess",
            "",
            "from git.cmd import handle_process_output, safer_popen",
            "from git.compat import defenc, force_bytes, force_text, safe_decode",
            "from git.exc import HookExecutionError, UnmergedEntriesError",
            "from git.objects.fun import (",
            "    traverse_tree_recursive,",
            "    traverse_trees_recursive,",
            "    tree_to_stream,",
            ")",
            "from git.util import IndexFileSHA1Writer, finalize_process",
            "from gitdb.base import IStream",
            "from gitdb.typ import str_tree_type",
            "",
            "from .typ import BaseIndexEntry, IndexEntry, CE_NAMEMASK, CE_STAGESHIFT",
            "from .util import pack, unpack",
            "",
            "# typing -----------------------------------------------------------------------------",
            "",
            "from typing import Dict, IO, List, Sequence, TYPE_CHECKING, Tuple, Type, Union, cast",
            "",
            "from git.types import PathLike",
            "",
            "if TYPE_CHECKING:",
            "    from .base import IndexFile",
            "    from git.db import GitCmdObjectDB",
            "    from git.objects.tree import TreeCacheTup",
            "",
            "    # from git.objects.fun import EntryTupOrNone",
            "",
            "# ------------------------------------------------------------------------------------",
            "",
            "",
            "S_IFGITLINK = S_IFLNK | S_IFDIR",
            "\"\"\"Flags for a submodule.\"\"\"",
            "",
            "CE_NAMEMASK_INV = ~CE_NAMEMASK",
            "",
            "__all__ = (",
            "    \"write_cache\",",
            "    \"read_cache\",",
            "    \"write_tree_from_cache\",",
            "    \"entry_key\",",
            "    \"stat_mode_to_index_mode\",",
            "    \"S_IFGITLINK\",",
            "    \"run_commit_hook\",",
            "    \"hook_path\",",
            ")",
            "",
            "",
            "def hook_path(name: str, git_dir: PathLike) -> str:",
            "    \"\"\":return: path to the given named hook in the given git repository directory\"\"\"",
            "    return osp.join(git_dir, \"hooks\", name)",
            "",
            "",
            "def _has_file_extension(path: str) -> str:",
            "    return osp.splitext(path)[1]",
            "",
            "",
            "def run_commit_hook(name: str, index: \"IndexFile\", *args: str) -> None:",
            "    \"\"\"Run the commit hook of the given name. Silently ignore hooks that do not exist.",
            "",
            "    :param name: name of hook, like 'pre-commit'",
            "    :param index: IndexFile instance",
            "    :param args: Arguments passed to hook file",
            "    :raises HookExecutionError:",
            "    \"\"\"",
            "    hp = hook_path(name, index.repo.git_dir)",
            "    if not os.access(hp, os.X_OK):",
            "        return",
            "",
            "    env = os.environ.copy()",
            "    env[\"GIT_INDEX_FILE\"] = safe_decode(str(index.path))",
            "    env[\"GIT_EDITOR\"] = \":\"",
            "    cmd = [hp]",
            "    try:",
            "        if os.name == \"nt\" and not _has_file_extension(hp):",
            "            # Windows only uses extensions to determine how to open files",
            "            # (doesn't understand shebangs). Try using bash to run the hook.",
            "            relative_hp = Path(hp).relative_to(index.repo.working_dir).as_posix()",
            "            cmd = [\"bash.exe\", relative_hp]",
            "",
            "        process = safer_popen(",
            "            cmd + list(args),",
            "            env=env,",
            "            stdout=subprocess.PIPE,",
            "            stderr=subprocess.PIPE,",
            "            cwd=index.repo.working_dir,",
            "        )",
            "    except Exception as ex:",
            "        raise HookExecutionError(hp, ex) from ex",
            "    else:",
            "        stdout_list: List[str] = []",
            "        stderr_list: List[str] = []",
            "        handle_process_output(process, stdout_list.append, stderr_list.append, finalize_process)",
            "        stdout = \"\".join(stdout_list)",
            "        stderr = \"\".join(stderr_list)",
            "        if process.returncode != 0:",
            "            stdout = force_text(stdout, defenc)",
            "            stderr = force_text(stderr, defenc)",
            "            raise HookExecutionError(hp, process.returncode, stderr, stdout)",
            "    # END handle return code",
            "",
            "",
            "def stat_mode_to_index_mode(mode: int) -> int:",
            "    \"\"\"Convert the given mode from a stat call to the corresponding index mode",
            "    and return it.\"\"\"",
            "    if S_ISLNK(mode):  # symlinks",
            "        return S_IFLNK",
            "    if S_ISDIR(mode) or S_IFMT(mode) == S_IFGITLINK:  # submodules",
            "        return S_IFGITLINK",
            "    return S_IFREG | (mode & S_IXUSR and 0o755 or 0o644)  # blobs with or without executable bit",
            "",
            "",
            "def write_cache(",
            "    entries: Sequence[Union[BaseIndexEntry, \"IndexEntry\"]],",
            "    stream: IO[bytes],",
            "    extension_data: Union[None, bytes] = None,",
            "    ShaStreamCls: Type[IndexFileSHA1Writer] = IndexFileSHA1Writer,",
            ") -> None:",
            "    \"\"\"Write the cache represented by entries to a stream.",
            "",
            "    :param entries: **sorted** list of entries",
            "",
            "    :param stream: stream to wrap into the AdapterStreamCls - it is used for",
            "        final output.",
            "",
            "    :param ShaStreamCls: Type to use when writing to the stream. It produces a sha",
            "        while writing to it, before the data is passed on to the wrapped stream",
            "",
            "    :param extension_data: any kind of data to write as a trailer, it must begin",
            "        a 4 byte identifier, followed by its size (4 bytes).",
            "    \"\"\"",
            "    # Wrap the stream into a compatible writer.",
            "    stream_sha = ShaStreamCls(stream)",
            "",
            "    tell = stream_sha.tell",
            "    write = stream_sha.write",
            "",
            "    # Header",
            "    version = 2",
            "    write(b\"DIRC\")",
            "    write(pack(\">LL\", version, len(entries)))",
            "",
            "    # Body",
            "    for entry in entries:",
            "        beginoffset = tell()",
            "        write(entry.ctime_bytes)  # ctime",
            "        write(entry.mtime_bytes)  # mtime",
            "        path_str = str(entry.path)",
            "        path: bytes = force_bytes(path_str, encoding=defenc)",
            "        plen = len(path) & CE_NAMEMASK  # Path length",
            "        assert plen == len(path), \"Path %s too long to fit into index\" % entry.path",
            "        flags = plen | (entry.flags & CE_NAMEMASK_INV)  # Clear possible previous values.",
            "        write(",
            "            pack(",
            "                \">LLLLLL20sH\",",
            "                entry.dev,",
            "                entry.inode,",
            "                entry.mode,",
            "                entry.uid,",
            "                entry.gid,",
            "                entry.size,",
            "                entry.binsha,",
            "                flags,",
            "            )",
            "        )",
            "        write(path)",
            "        real_size = (tell() - beginoffset + 8) & ~7",
            "        write(b\"\\0\" * ((beginoffset + real_size) - tell()))",
            "    # END for each entry",
            "",
            "    # Write previously cached extensions data.",
            "    if extension_data is not None:",
            "        stream_sha.write(extension_data)",
            "",
            "    # Write the sha over the content.",
            "    stream_sha.write_sha()",
            "",
            "",
            "def read_header(stream: IO[bytes]) -> Tuple[int, int]:",
            "    \"\"\"Return tuple(version_long, num_entries) from the given stream\"\"\"",
            "    type_id = stream.read(4)",
            "    if type_id != b\"DIRC\":",
            "        raise AssertionError(\"Invalid index file header: %r\" % type_id)",
            "    unpacked = cast(Tuple[int, int], unpack(\">LL\", stream.read(4 * 2)))",
            "    version, num_entries = unpacked",
            "",
            "    # TODO: Handle version 3: extended data, see read-cache.c.",
            "    assert version in (1, 2)",
            "    return version, num_entries",
            "",
            "",
            "def entry_key(*entry: Union[BaseIndexEntry, PathLike, int]) -> Tuple[PathLike, int]:",
            "    \"\"\":return: Key suitable to be used for the index.entries dictionary",
            "",
            "    :param entry: One instance of type BaseIndexEntry or the path and the stage",
            "    \"\"\"",
            "",
            "    # def is_entry_key_tup(entry_key: Tuple) -> TypeGuard[Tuple[PathLike, int]]:",
            "    #     return isinstance(entry_key, tuple) and len(entry_key) == 2",
            "",
            "    if len(entry) == 1:",
            "        entry_first = entry[0]",
            "        assert isinstance(entry_first, BaseIndexEntry)",
            "        return (entry_first.path, entry_first.stage)",
            "    else:",
            "        # assert is_entry_key_tup(entry)",
            "        entry = cast(Tuple[PathLike, int], entry)",
            "        return entry",
            "    # END handle entry",
            "",
            "",
            "def read_cache(",
            "    stream: IO[bytes],",
            ") -> Tuple[int, Dict[Tuple[PathLike, int], \"IndexEntry\"], bytes, bytes]:",
            "    \"\"\"Read a cache file from the given stream.",
            "",
            "    :return: tuple(version, entries_dict, extension_data, content_sha)",
            "",
            "      * version is the integer version number.",
            "      * entries dict is a dictionary which maps IndexEntry instances to a path at a stage.",
            "      * extension_data is '' or 4 bytes of type + 4 bytes of size + size bytes.",
            "      * content_sha is a 20 byte sha on all cache file contents.",
            "    \"\"\"",
            "    version, num_entries = read_header(stream)",
            "    count = 0",
            "    entries: Dict[Tuple[PathLike, int], \"IndexEntry\"] = {}",
            "",
            "    read = stream.read",
            "    tell = stream.tell",
            "    while count < num_entries:",
            "        beginoffset = tell()",
            "        ctime = unpack(\">8s\", read(8))[0]",
            "        mtime = unpack(\">8s\", read(8))[0]",
            "        (dev, ino, mode, uid, gid, size, sha, flags) = unpack(\">LLLLLL20sH\", read(20 + 4 * 6 + 2))",
            "        path_size = flags & CE_NAMEMASK",
            "        path = read(path_size).decode(defenc)",
            "",
            "        real_size = (tell() - beginoffset + 8) & ~7",
            "        read((beginoffset + real_size) - tell())",
            "        entry = IndexEntry((mode, sha, flags, path, ctime, mtime, dev, ino, uid, gid, size))",
            "        # entry_key would be the method to use, but we save the effort.",
            "        entries[(path, entry.stage)] = entry",
            "        count += 1",
            "    # END for each entry",
            "",
            "    # The footer contains extension data and a sha on the content so far.",
            "    # Keep the extension footer,and verify we have a sha in the end.",
            "    # Extension data format is:",
            "    #   4 bytes ID",
            "    #   4 bytes length of chunk",
            "    #   Repeated 0 - N times",
            "    extension_data = stream.read(~0)",
            "    assert (",
            "        len(extension_data) > 19",
            "    ), \"Index Footer was not at least a sha on content as it was only %i bytes in size\" % len(extension_data)",
            "",
            "    content_sha = extension_data[-20:]",
            "",
            "    # Truncate the sha in the end as we will dynamically create it anyway.",
            "    extension_data = extension_data[:-20]",
            "",
            "    return (version, entries, extension_data, content_sha)",
            "",
            "",
            "def write_tree_from_cache(",
            "    entries: List[IndexEntry], odb: \"GitCmdObjectDB\", sl: slice, si: int = 0",
            ") -> Tuple[bytes, List[\"TreeCacheTup\"]]:",
            "    \"\"\"Create a tree from the given sorted list of entries and put the respective",
            "    trees into the given object database.",
            "",
            "    :param entries: **Sorted** list of IndexEntries",
            "    :param odb: Object database to store the trees in",
            "    :param si: Start index at which we should start creating subtrees",
            "    :param sl: Slice indicating the range we should process on the entries list",
            "    :return: tuple(binsha, list(tree_entry, ...)) a tuple of a sha and a list of",
            "        tree entries being a tuple of hexsha, mode, name",
            "    \"\"\"",
            "    tree_items: List[\"TreeCacheTup\"] = []",
            "",
            "    ci = sl.start",
            "    end = sl.stop",
            "    while ci < end:",
            "        entry = entries[ci]",
            "        if entry.stage != 0:",
            "            raise UnmergedEntriesError(entry)",
            "        # END abort on unmerged",
            "        ci += 1",
            "        rbound = entry.path.find(\"/\", si)",
            "        if rbound == -1:",
            "            # It's not a tree.",
            "            tree_items.append((entry.binsha, entry.mode, entry.path[si:]))",
            "        else:",
            "            # Find common base range.",
            "            base = entry.path[si:rbound]",
            "            xi = ci",
            "            while xi < end:",
            "                oentry = entries[xi]",
            "                orbound = oentry.path.find(\"/\", si)",
            "                if orbound == -1 or oentry.path[si:orbound] != base:",
            "                    break",
            "                # END abort on base mismatch",
            "                xi += 1",
            "            # END find common base",
            "",
            "            # Enter recursion.",
            "            # ci - 1 as we want to count our current item as well.",
            "            sha, _tree_entry_list = write_tree_from_cache(entries, odb, slice(ci - 1, xi), rbound + 1)",
            "            tree_items.append((sha, S_IFDIR, base))",
            "",
            "            # Skip ahead.",
            "            ci = xi",
            "        # END handle bounds",
            "    # END for each entry",
            "",
            "    # Finally create the tree.",
            "    sio = BytesIO()",
            "    tree_to_stream(tree_items, sio.write)  # Writes to stream as bytes, but doesn't change tree_items.",
            "    sio.seek(0)",
            "",
            "    istream = odb.store(IStream(str_tree_type, len(sio.getvalue()), sio))",
            "    return (istream.binsha, tree_items)",
            "",
            "",
            "def _tree_entry_to_baseindexentry(tree_entry: \"TreeCacheTup\", stage: int) -> BaseIndexEntry:",
            "    return BaseIndexEntry((tree_entry[1], tree_entry[0], stage << CE_STAGESHIFT, tree_entry[2]))",
            "",
            "",
            "def aggressive_tree_merge(odb: \"GitCmdObjectDB\", tree_shas: Sequence[bytes]) -> List[BaseIndexEntry]:",
            "    \"\"\"",
            "    :return: List of BaseIndexEntries representing the aggressive merge of the given",
            "        trees. All valid entries are on stage 0, whereas the conflicting ones are left",
            "        on stage 1, 2 or 3, whereas stage 1 corresponds to the common ancestor tree,",
            "        2 to our tree and 3 to 'their' tree.",
            "",
            "    :param tree_shas: 1, 2 or 3 trees as identified by their binary 20 byte shas.",
            "        If 1 or two, the entries will effectively correspond to the last given tree.",
            "        If 3 are given, a 3 way merge is performed.",
            "    \"\"\"",
            "    out: List[BaseIndexEntry] = []",
            "",
            "    # One and two way is the same for us, as we don't have to handle an existing",
            "    # index, instrea",
            "    if len(tree_shas) in (1, 2):",
            "        for entry in traverse_tree_recursive(odb, tree_shas[-1], \"\"):",
            "            out.append(_tree_entry_to_baseindexentry(entry, 0))",
            "        # END for each entry",
            "        return out",
            "    # END handle single tree",
            "",
            "    if len(tree_shas) > 3:",
            "        raise ValueError(\"Cannot handle %i trees at once\" % len(tree_shas))",
            "",
            "    # Three trees.",
            "    for base, ours, theirs in traverse_trees_recursive(odb, tree_shas, \"\"):",
            "        if base is not None:",
            "            # Base version exists.",
            "            if ours is not None:",
            "                # Ours exists.",
            "                if theirs is not None:",
            "                    # It exists in all branches. Ff it was changed in both",
            "                    # its a conflict. Otherwise, we take the changed version.",
            "                    # This should be the most common branch, so it comes first.",
            "                    if (base[0] != ours[0] and base[0] != theirs[0] and ours[0] != theirs[0]) or (",
            "                        base[1] != ours[1] and base[1] != theirs[1] and ours[1] != theirs[1]",
            "                    ):",
            "                        # Changed by both.",
            "                        out.append(_tree_entry_to_baseindexentry(base, 1))",
            "                        out.append(_tree_entry_to_baseindexentry(ours, 2))",
            "                        out.append(_tree_entry_to_baseindexentry(theirs, 3))",
            "                    elif base[0] != ours[0] or base[1] != ours[1]:",
            "                        # Only we changed it.",
            "                        out.append(_tree_entry_to_baseindexentry(ours, 0))",
            "                    else:",
            "                        # Either nobody changed it, or they did. In either",
            "                        # case, use theirs.",
            "                        out.append(_tree_entry_to_baseindexentry(theirs, 0))",
            "                    # END handle modification",
            "                else:",
            "                    if ours[0] != base[0] or ours[1] != base[1]:",
            "                        # They deleted it, we changed it, conflict.",
            "                        out.append(_tree_entry_to_baseindexentry(base, 1))",
            "                        out.append(_tree_entry_to_baseindexentry(ours, 2))",
            "                    # else:",
            "                    #   # We didn't change it, ignore.",
            "                    #   pass",
            "                    # END handle our change",
            "                # END handle theirs",
            "            else:",
            "                if theirs is None:",
            "                    # Deleted in both, its fine - it's out.",
            "                    pass",
            "                else:",
            "                    if theirs[0] != base[0] or theirs[1] != base[1]:",
            "                        # Deleted in ours, changed theirs, conflict.",
            "                        out.append(_tree_entry_to_baseindexentry(base, 1))",
            "                        out.append(_tree_entry_to_baseindexentry(theirs, 3))",
            "                    # END theirs changed",
            "                    # else:",
            "                    #   # Theirs didn't change.",
            "                    #   pass",
            "                # END handle theirs",
            "            # END handle ours",
            "        else:",
            "            # All three can't be None.",
            "            if ours is None:",
            "                # Added in their branch.",
            "                assert theirs is not None",
            "                out.append(_tree_entry_to_baseindexentry(theirs, 0))",
            "            elif theirs is None:",
            "                # Added in our branch.",
            "                out.append(_tree_entry_to_baseindexentry(ours, 0))",
            "            else:",
            "                # Both have it, except for the base, see whether it changed.",
            "                if ours[0] != theirs[0] or ours[1] != theirs[1]:",
            "                    out.append(_tree_entry_to_baseindexentry(ours, 2))",
            "                    out.append(_tree_entry_to_baseindexentry(theirs, 3))",
            "                else:",
            "                    # It was added the same in both.",
            "                    out.append(_tree_entry_to_baseindexentry(ours, 0))",
            "                # END handle two items",
            "            # END handle heads",
            "        # END handle base exists",
            "    # END for each entries tuple",
            "",
            "    return out"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "21": [],
            "101": [
                "run_commit_hook"
            ],
            "107": [
                "run_commit_hook"
            ]
        },
        "addLocation": []
    },
    "git/util.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": 327,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 328,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": 329,
                "PatchRowcode": " def py_where(program: str, path: Optional[PathLike] = None) -> List[str]:"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 330,
                "PatchRowcode": "+    \"\"\"Perform a path search to assist :func:`is_cygwin_git`."
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 331,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 332,
                "PatchRowcode": "+    This is not robust for general use. It is an implementation detail of"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 333,
                "PatchRowcode": "+    :func:`is_cygwin_git`. When a search following all shell rules is needed,"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 334,
                "PatchRowcode": "+    :func:`shutil.which` can be used instead."
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 335,
                "PatchRowcode": "+"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 336,
                "PatchRowcode": "+    :note: Neither this function nor :func:`shutil.which` will predict the effect of an"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 337,
                "PatchRowcode": "+        executable search on a native Windows system due to a :class:`subprocess.Popen`"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 338,
                "PatchRowcode": "+        call without ``shell=True``, because shell and non-shell executable search on"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 339,
                "PatchRowcode": "+        Windows differ considerably."
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 340,
                "PatchRowcode": "+    \"\"\""
            },
            "14": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 341,
                "PatchRowcode": "     # From: http://stackoverflow.com/a/377028/548792"
            },
            "15": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 342,
                "PatchRowcode": "     winprog_exts = _get_exe_extensions()"
            },
            "16": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 343,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors",
            "#",
            "# This module is part of GitPython and is released under the",
            "# 3-Clause BSD License: https://opensource.org/license/bsd-3-clause/",
            "",
            "from abc import abstractmethod",
            "import contextlib",
            "from functools import wraps",
            "import getpass",
            "import logging",
            "import os",
            "import os.path as osp",
            "import pathlib",
            "import platform",
            "import re",
            "import shutil",
            "import stat",
            "import subprocess",
            "import sys",
            "import time",
            "from urllib.parse import urlsplit, urlunsplit",
            "import warnings",
            "",
            "# typing ---------------------------------------------------------",
            "",
            "from typing import (",
            "    Any,",
            "    AnyStr,",
            "    BinaryIO,",
            "    Callable,",
            "    Dict,",
            "    Generator,",
            "    IO,",
            "    Iterator,",
            "    List,",
            "    Optional,",
            "    Pattern,",
            "    Sequence,",
            "    Tuple,",
            "    TypeVar,",
            "    Union,",
            "    TYPE_CHECKING,",
            "    cast,",
            "    overload,",
            ")",
            "",
            "if TYPE_CHECKING:",
            "    from git.remote import Remote",
            "    from git.repo.base import Repo",
            "    from git.config import GitConfigParser, SectionConstraint",
            "    from git import Git",
            "",
            "from .types import (",
            "    Literal,",
            "    SupportsIndex,",
            "    Protocol,",
            "    runtime_checkable,  # because behind py version guards",
            "    PathLike,",
            "    HSH_TD,",
            "    Total_TD,",
            "    Files_TD,  # aliases",
            "    Has_id_attribute,",
            ")",
            "",
            "# ---------------------------------------------------------------------",
            "",
            "from gitdb.util import (  # noqa: F401  # @IgnorePep8",
            "    make_sha,",
            "    LockedFD,  # @UnusedImport",
            "    file_contents_ro,  # @UnusedImport",
            "    file_contents_ro_filepath,  # @UnusedImport",
            "    LazyMixin,  # @UnusedImport",
            "    to_hex_sha,  # @UnusedImport",
            "    to_bin_sha,  # @UnusedImport",
            "    bin_to_hex,  # @UnusedImport",
            "    hex_to_bin,  # @UnusedImport",
            ")",
            "",
            "T_IterableObj = TypeVar(\"T_IterableObj\", bound=Union[\"IterableObj\", \"Has_id_attribute\"], covariant=True)",
            "# So IterableList[Head] is subtype of IterableList[IterableObj].",
            "",
            "# NOTE:  Some of the unused imports might be used/imported by others.",
            "# Handle once test-cases are back up and running.",
            "# Most of these are unused here, but are for use by git-python modules so these",
            "# don't see gitdb all the time. Flake of course doesn't like it.",
            "__all__ = [",
            "    \"stream_copy\",",
            "    \"join_path\",",
            "    \"to_native_path_linux\",",
            "    \"join_path_native\",",
            "    \"Stats\",",
            "    \"IndexFileSHA1Writer\",",
            "    \"IterableObj\",",
            "    \"IterableList\",",
            "    \"BlockingLockFile\",",
            "    \"LockFile\",",
            "    \"Actor\",",
            "    \"get_user_id\",",
            "    \"assure_directory_exists\",",
            "    \"RemoteProgress\",",
            "    \"CallableRemoteProgress\",",
            "    \"rmtree\",",
            "    \"unbare_repo\",",
            "    \"HIDE_WINDOWS_KNOWN_ERRORS\",",
            "]",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def _read_win_env_flag(name: str, default: bool) -> bool:",
            "    \"\"\"Read a boolean flag from an environment variable on Windows.",
            "",
            "    :return:",
            "        On Windows, the flag, or the ``default`` value if absent or ambiguous.",
            "        On all other operating systems, ``False``.",
            "",
            "    :note: This only accesses the environment on Windows.",
            "    \"\"\"",
            "    if os.name != \"nt\":",
            "        return False",
            "",
            "    try:",
            "        value = os.environ[name]",
            "    except KeyError:",
            "        return default",
            "",
            "    log.warning(",
            "        \"The %s environment variable is deprecated. Its effect has never been documented and changes without warning.\",",
            "        name,",
            "    )",
            "",
            "    adjusted_value = value.strip().lower()",
            "",
            "    if adjusted_value in {\"\", \"0\", \"false\", \"no\"}:",
            "        return False",
            "    if adjusted_value in {\"1\", \"true\", \"yes\"}:",
            "        return True",
            "    log.warning(\"%s has unrecognized value %r, treating as %r.\", name, value, default)",
            "    return default",
            "",
            "",
            "#: We need an easy way to see if Appveyor TCs start failing,",
            "#: so the errors marked with this var are considered \"acknowledged\" ones, awaiting remedy,",
            "#: till then, we wish to hide them.",
            "HIDE_WINDOWS_KNOWN_ERRORS = _read_win_env_flag(\"HIDE_WINDOWS_KNOWN_ERRORS\", True)",
            "HIDE_WINDOWS_FREEZE_ERRORS = _read_win_env_flag(\"HIDE_WINDOWS_FREEZE_ERRORS\", True)",
            "",
            "# { Utility Methods",
            "",
            "T = TypeVar(\"T\")",
            "",
            "",
            "def unbare_repo(func: Callable[..., T]) -> Callable[..., T]:",
            "    \"\"\"Methods with this decorator raise :class:`.exc.InvalidGitRepositoryError` if they",
            "    encounter a bare repository.\"\"\"",
            "",
            "    from .exc import InvalidGitRepositoryError",
            "",
            "    @wraps(func)",
            "    def wrapper(self: \"Remote\", *args: Any, **kwargs: Any) -> T:",
            "        if self.repo.bare:",
            "            raise InvalidGitRepositoryError(\"Method '%s' cannot operate on bare repositories\" % func.__name__)",
            "        # END bare method",
            "        return func(self, *args, **kwargs)",
            "",
            "    # END wrapper",
            "",
            "    return wrapper",
            "",
            "",
            "@contextlib.contextmanager",
            "def cwd(new_dir: PathLike) -> Generator[PathLike, None, None]:",
            "    \"\"\"Context manager to temporarily change directory.",
            "",
            "    This is similar to :func:`contextlib.chdir` introduced in Python 3.11, but the",
            "    context manager object returned by a single call to this function is not reentrant.",
            "    \"\"\"",
            "    old_dir = os.getcwd()",
            "    os.chdir(new_dir)",
            "    try:",
            "        yield new_dir",
            "    finally:",
            "        os.chdir(old_dir)",
            "",
            "",
            "@contextlib.contextmanager",
            "def patch_env(name: str, value: str) -> Generator[None, None, None]:",
            "    \"\"\"Context manager to temporarily patch an environment variable.\"\"\"",
            "    old_value = os.getenv(name)",
            "    os.environ[name] = value",
            "    try:",
            "        yield",
            "    finally:",
            "        if old_value is None:",
            "            del os.environ[name]",
            "        else:",
            "            os.environ[name] = old_value",
            "",
            "",
            "def rmtree(path: PathLike) -> None:",
            "    \"\"\"Remove the given directory tree recursively.",
            "",
            "    :note: We use :func:`shutil.rmtree` but adjust its behaviour to see whether files",
            "        that couldn't be deleted are read-only. Windows will not remove them in that",
            "        case.",
            "    \"\"\"",
            "",
            "    def handler(function: Callable, path: PathLike, _excinfo: Any) -> None:",
            "        \"\"\"Callback for :func:`shutil.rmtree`. Works either as ``onexc`` or ``onerror``.\"\"\"",
            "        # Is the error an access error?",
            "        os.chmod(path, stat.S_IWUSR)",
            "",
            "        try:",
            "            function(path)",
            "        except PermissionError as ex:",
            "            if HIDE_WINDOWS_KNOWN_ERRORS:",
            "                from unittest import SkipTest",
            "",
            "                raise SkipTest(f\"FIXME: fails with: PermissionError\\n  {ex}\") from ex",
            "            raise",
            "",
            "    if os.name != \"nt\":",
            "        shutil.rmtree(path)",
            "    elif sys.version_info >= (3, 12):",
            "        shutil.rmtree(path, onexc=handler)",
            "    else:",
            "        shutil.rmtree(path, onerror=handler)",
            "",
            "",
            "def rmfile(path: PathLike) -> None:",
            "    \"\"\"Ensure file deleted also on *Windows* where read-only files need special treatment.\"\"\"",
            "    if osp.isfile(path):",
            "        if os.name == \"nt\":",
            "            os.chmod(path, 0o777)",
            "        os.remove(path)",
            "",
            "",
            "def stream_copy(source: BinaryIO, destination: BinaryIO, chunk_size: int = 512 * 1024) -> int:",
            "    \"\"\"Copy all data from the source stream into the destination stream in chunks",
            "    of size chunk_size.",
            "",
            "    :return: Number of bytes written",
            "    \"\"\"",
            "    br = 0",
            "    while True:",
            "        chunk = source.read(chunk_size)",
            "        destination.write(chunk)",
            "        br += len(chunk)",
            "        if len(chunk) < chunk_size:",
            "            break",
            "    # END reading output stream",
            "    return br",
            "",
            "",
            "def join_path(a: PathLike, *p: PathLike) -> PathLike:",
            "    R\"\"\"Join path tokens together similar to osp.join, but always use",
            "    '/' instead of possibly '\\' on Windows.\"\"\"",
            "    path = str(a)",
            "    for b in p:",
            "        b = str(b)",
            "        if not b:",
            "            continue",
            "        if b.startswith(\"/\"):",
            "            path += b[1:]",
            "        elif path == \"\" or path.endswith(\"/\"):",
            "            path += b",
            "        else:",
            "            path += \"/\" + b",
            "    # END for each path token to add",
            "    return path",
            "",
            "",
            "if os.name == \"nt\":",
            "",
            "    def to_native_path_windows(path: PathLike) -> PathLike:",
            "        path = str(path)",
            "        return path.replace(\"/\", \"\\\\\")",
            "",
            "    def to_native_path_linux(path: PathLike) -> str:",
            "        path = str(path)",
            "        return path.replace(\"\\\\\", \"/\")",
            "",
            "    __all__.append(\"to_native_path_windows\")",
            "    to_native_path = to_native_path_windows",
            "else:",
            "    # No need for any work on Linux.",
            "    def to_native_path_linux(path: PathLike) -> str:",
            "        return str(path)",
            "",
            "    to_native_path = to_native_path_linux",
            "",
            "",
            "def join_path_native(a: PathLike, *p: PathLike) -> PathLike:",
            "    R\"\"\"Like join_path, but makes sure an OS native path is returned.",
            "",
            "    This is only needed to play it safe on Windows and to ensure nice paths that only",
            "    use '\\'.",
            "    \"\"\"",
            "    return to_native_path(join_path(a, *p))",
            "",
            "",
            "def assure_directory_exists(path: PathLike, is_file: bool = False) -> bool:",
            "    \"\"\"Make sure that the directory pointed to by path exists.",
            "",
            "    :param is_file: If True, ``path`` is assumed to be a file and handled correctly.",
            "        Otherwise it must be a directory.",
            "",
            "    :return: True if the directory was created, False if it already existed.",
            "    \"\"\"",
            "    if is_file:",
            "        path = osp.dirname(path)",
            "    # END handle file",
            "    if not osp.isdir(path):",
            "        os.makedirs(path, exist_ok=True)",
            "        return True",
            "    return False",
            "",
            "",
            "def _get_exe_extensions() -> Sequence[str]:",
            "    PATHEXT = os.environ.get(\"PATHEXT\", None)",
            "    if PATHEXT:",
            "        return tuple(p.upper() for p in PATHEXT.split(os.pathsep))",
            "    elif os.name == \"nt\":",
            "        return (\".BAT\", \"COM\", \".EXE\")",
            "    else:",
            "        return ()",
            "",
            "",
            "def py_where(program: str, path: Optional[PathLike] = None) -> List[str]:",
            "    # From: http://stackoverflow.com/a/377028/548792",
            "    winprog_exts = _get_exe_extensions()",
            "",
            "    def is_exec(fpath: str) -> bool:",
            "        return (",
            "            osp.isfile(fpath)",
            "            and os.access(fpath, os.X_OK)",
            "            and (os.name != \"nt\" or not winprog_exts or any(fpath.upper().endswith(ext) for ext in winprog_exts))",
            "        )",
            "",
            "    progs = []",
            "    if not path:",
            "        path = os.environ[\"PATH\"]",
            "    for folder in str(path).split(os.pathsep):",
            "        folder = folder.strip('\"')",
            "        if folder:",
            "            exe_path = osp.join(folder, program)",
            "            for f in [exe_path] + [\"%s%s\" % (exe_path, e) for e in winprog_exts]:",
            "                if is_exec(f):",
            "                    progs.append(f)",
            "    return progs",
            "",
            "",
            "def _cygexpath(drive: Optional[str], path: str) -> str:",
            "    if osp.isabs(path) and not drive:",
            "        # Invoked from `cygpath()` directly with `D:Apps\\123`?",
            "        #  It's an error, leave it alone just slashes)",
            "        p = path  # convert to str if AnyPath given",
            "    else:",
            "        p = path and osp.normpath(osp.expandvars(osp.expanduser(path)))",
            "        if osp.isabs(p):",
            "            if drive:",
            "                # Confusing, maybe a remote system should expand vars.",
            "                p = path",
            "            else:",
            "                p = cygpath(p)",
            "        elif drive:",
            "            p = \"/proc/cygdrive/%s/%s\" % (drive.lower(), p)",
            "    p_str = str(p)  # ensure it is a str and not AnyPath",
            "    return p_str.replace(\"\\\\\", \"/\")",
            "",
            "",
            "_cygpath_parsers: Tuple[Tuple[Pattern[str], Callable, bool], ...] = (",
            "    # See: https://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx",
            "    # and: https://www.cygwin.com/cygwin-ug-net/using.html#unc-paths",
            "    (",
            "        re.compile(r\"\\\\\\\\\\?\\\\UNC\\\\([^\\\\]+)\\\\([^\\\\]+)(?:\\\\(.*))?\"),",
            "        (lambda server, share, rest_path: \"//%s/%s/%s\" % (server, share, rest_path.replace(\"\\\\\", \"/\"))),",
            "        False,",
            "    ),",
            "    (re.compile(r\"\\\\\\\\\\?\\\\(\\w):[/\\\\](.*)\"), (_cygexpath), False),",
            "    (re.compile(r\"(\\w):[/\\\\](.*)\"), (_cygexpath), False),",
            "    (re.compile(r\"file:(.*)\", re.I), (lambda rest_path: rest_path), True),",
            "    (re.compile(r\"(\\w{2,}:.*)\"), (lambda url: url), False),  # remote URL, do nothing",
            ")",
            "",
            "",
            "def cygpath(path: str) -> str:",
            "    \"\"\"Use :meth:`git.cmd.Git.polish_url` instead, that works on any environment.\"\"\"",
            "    path = str(path)  # Ensure is str and not AnyPath.",
            "    # Fix to use Paths when 3.5 dropped. Or to be just str if only for URLs?",
            "    if not path.startswith((\"/cygdrive\", \"//\", \"/proc/cygdrive\")):",
            "        for regex, parser, recurse in _cygpath_parsers:",
            "            match = regex.match(path)",
            "            if match:",
            "                path = parser(*match.groups())",
            "                if recurse:",
            "                    path = cygpath(path)",
            "                break",
            "        else:",
            "            path = _cygexpath(None, path)",
            "",
            "    return path",
            "",
            "",
            "_decygpath_regex = re.compile(r\"(?:/proc)?/cygdrive/(\\w)(/.*)?\")",
            "",
            "",
            "def decygpath(path: PathLike) -> str:",
            "    path = str(path)",
            "    m = _decygpath_regex.match(path)",
            "    if m:",
            "        drive, rest_path = m.groups()",
            "        path = \"%s:%s\" % (drive.upper(), rest_path or \"\")",
            "",
            "    return path.replace(\"/\", \"\\\\\")",
            "",
            "",
            "#: Store boolean flags denoting if a specific Git executable",
            "#: is from a Cygwin installation (since `cache_lru()` unsupported on PY2).",
            "_is_cygwin_cache: Dict[str, Optional[bool]] = {}",
            "",
            "",
            "@overload",
            "def is_cygwin_git(git_executable: None) -> Literal[False]:",
            "    ...",
            "",
            "",
            "@overload",
            "def is_cygwin_git(git_executable: PathLike) -> bool:",
            "    ...",
            "",
            "",
            "def is_cygwin_git(git_executable: Union[None, PathLike]) -> bool:",
            "    if os.name == \"nt\":",
            "        # This is Windows-native Python, since Cygwin has os.name == \"posix\".",
            "        return False",
            "",
            "    if git_executable is None:",
            "        return False",
            "",
            "    git_executable = str(git_executable)",
            "    is_cygwin = _is_cygwin_cache.get(git_executable)  # type: Optional[bool]",
            "    if is_cygwin is None:",
            "        is_cygwin = False",
            "        try:",
            "            git_dir = osp.dirname(git_executable)",
            "            if not git_dir:",
            "                res = py_where(git_executable)",
            "                git_dir = osp.dirname(res[0]) if res else \"\"",
            "",
            "            # Just a name given, not a real path.",
            "            uname_cmd = osp.join(git_dir, \"uname\")",
            "            process = subprocess.Popen([uname_cmd], stdout=subprocess.PIPE, universal_newlines=True)",
            "            uname_out, _ = process.communicate()",
            "            # retcode = process.poll()",
            "            is_cygwin = \"CYGWIN\" in uname_out",
            "        except Exception as ex:",
            "            log.debug(\"Failed checking if running in CYGWIN due to: %r\", ex)",
            "        _is_cygwin_cache[git_executable] = is_cygwin",
            "",
            "    return is_cygwin",
            "",
            "",
            "def get_user_id() -> str:",
            "    \"\"\":return: string identifying the currently active system user as name@node\"\"\"",
            "    return \"%s@%s\" % (getpass.getuser(), platform.node())",
            "",
            "",
            "def finalize_process(proc: Union[subprocess.Popen, \"Git.AutoInterrupt\"], **kwargs: Any) -> None:",
            "    \"\"\"Wait for the process (clone, fetch, pull or push) and handle its errors accordingly\"\"\"",
            "    # TODO: No close proc-streams??",
            "    proc.wait(**kwargs)",
            "",
            "",
            "@overload",
            "def expand_path(p: None, expand_vars: bool = ...) -> None:",
            "    ...",
            "",
            "",
            "@overload",
            "def expand_path(p: PathLike, expand_vars: bool = ...) -> str:",
            "    # improve these overloads when 3.5 dropped",
            "    ...",
            "",
            "",
            "def expand_path(p: Union[None, PathLike], expand_vars: bool = True) -> Optional[PathLike]:",
            "    if isinstance(p, pathlib.Path):",
            "        return p.resolve()",
            "    try:",
            "        p = osp.expanduser(p)  # type: ignore",
            "        if expand_vars:",
            "            p = osp.expandvars(p)  # type: ignore",
            "        return osp.normpath(osp.abspath(p))  # type: ignore",
            "    except Exception:",
            "        return None",
            "",
            "",
            "def remove_password_if_present(cmdline: Sequence[str]) -> List[str]:",
            "    \"\"\"Parse any command line argument and if one of the elements is an URL with a",
            "    username and/or password, replace them by stars (in-place).",
            "",
            "    If nothing is found, this just returns the command line as-is.",
            "",
            "    This should be used for every log line that print a command line, as well as",
            "    exception messages.",
            "    \"\"\"",
            "    new_cmdline = []",
            "    for index, to_parse in enumerate(cmdline):",
            "        new_cmdline.append(to_parse)",
            "        try:",
            "            url = urlsplit(to_parse)",
            "            # Remove password from the URL if present.",
            "            if url.password is None and url.username is None:",
            "                continue",
            "",
            "            if url.password is not None:",
            "                url = url._replace(netloc=url.netloc.replace(url.password, \"*****\"))",
            "            if url.username is not None:",
            "                url = url._replace(netloc=url.netloc.replace(url.username, \"*****\"))",
            "            new_cmdline[index] = urlunsplit(url)",
            "        except ValueError:",
            "            # This is not a valid URL.",
            "            continue",
            "    return new_cmdline",
            "",
            "",
            "# } END utilities",
            "",
            "# { Classes",
            "",
            "",
            "class RemoteProgress:",
            "    \"\"\"",
            "    Handler providing an interface to parse progress information emitted by git-push",
            "    and git-fetch and to dispatch callbacks allowing subclasses to react to the progress.",
            "    \"\"\"",
            "",
            "    _num_op_codes: int = 9",
            "    (",
            "        BEGIN,",
            "        END,",
            "        COUNTING,",
            "        COMPRESSING,",
            "        WRITING,",
            "        RECEIVING,",
            "        RESOLVING,",
            "        FINDING_SOURCES,",
            "        CHECKING_OUT,",
            "    ) = [1 << x for x in range(_num_op_codes)]",
            "    STAGE_MASK = BEGIN | END",
            "    OP_MASK = ~STAGE_MASK",
            "",
            "    DONE_TOKEN = \"done.\"",
            "    TOKEN_SEPARATOR = \", \"",
            "",
            "    __slots__ = (",
            "        \"_cur_line\",",
            "        \"_seen_ops\",",
            "        \"error_lines\",  # Lines that started with 'error:' or 'fatal:'.",
            "        \"other_lines\",  # Lines not denoting progress (i.e.g. push-infos).",
            "    )",
            "    re_op_absolute = re.compile(r\"(remote: )?([\\w\\s]+):\\s+()(\\d+)()(.*)\")",
            "    re_op_relative = re.compile(r\"(remote: )?([\\w\\s]+):\\s+(\\d+)% \\((\\d+)/(\\d+)\\)(.*)\")",
            "",
            "    def __init__(self) -> None:",
            "        self._seen_ops: List[int] = []",
            "        self._cur_line: Optional[str] = None",
            "        self.error_lines: List[str] = []",
            "        self.other_lines: List[str] = []",
            "",
            "    def _parse_progress_line(self, line: AnyStr) -> None:",
            "        \"\"\"Parse progress information from the given line as retrieved by git-push",
            "        or git-fetch.",
            "",
            "        - Lines that do not contain progress info are stored in :attr:`other_lines`.",
            "        - Lines that seem to contain an error (i.e. start with ``error:`` or ``fatal:``)",
            "          are stored in :attr:`error_lines`.",
            "        \"\"\"",
            "        # handle",
            "        # Counting objects: 4, done.",
            "        # Compressing objects:  50% (1/2)",
            "        # Compressing objects: 100% (2/2)",
            "        # Compressing objects: 100% (2/2), done.",
            "        if isinstance(line, bytes):  # mypy argues about ternary assignment.",
            "            line_str = line.decode(\"utf-8\")",
            "        else:",
            "            line_str = line",
            "        self._cur_line = line_str",
            "",
            "        if self._cur_line.startswith((\"error:\", \"fatal:\")):",
            "            self.error_lines.append(self._cur_line)",
            "            return",
            "",
            "        # Find escape characters and cut them away - regex will not work with",
            "        # them as they are non-ASCII. As git might expect a tty, it will send them.",
            "        last_valid_index = None",
            "        for i, c in enumerate(reversed(line_str)):",
            "            if ord(c) < 32:",
            "                # its a slice index",
            "                last_valid_index = -i - 1",
            "            # END character was non-ASCII",
            "        # END for each character in line",
            "        if last_valid_index is not None:",
            "            line_str = line_str[:last_valid_index]",
            "        # END cut away invalid part",
            "        line_str = line_str.rstrip()",
            "",
            "        cur_count, max_count = None, None",
            "        match = self.re_op_relative.match(line_str)",
            "        if match is None:",
            "            match = self.re_op_absolute.match(line_str)",
            "",
            "        if not match:",
            "            self.line_dropped(line_str)",
            "            self.other_lines.append(line_str)",
            "            return",
            "        # END could not get match",
            "",
            "        op_code = 0",
            "        _remote, op_name, _percent, cur_count, max_count, message = match.groups()",
            "",
            "        # Get operation ID.",
            "        if op_name == \"Counting objects\":",
            "            op_code |= self.COUNTING",
            "        elif op_name == \"Compressing objects\":",
            "            op_code |= self.COMPRESSING",
            "        elif op_name == \"Writing objects\":",
            "            op_code |= self.WRITING",
            "        elif op_name == \"Receiving objects\":",
            "            op_code |= self.RECEIVING",
            "        elif op_name == \"Resolving deltas\":",
            "            op_code |= self.RESOLVING",
            "        elif op_name == \"Finding sources\":",
            "            op_code |= self.FINDING_SOURCES",
            "        elif op_name == \"Checking out files\":",
            "            op_code |= self.CHECKING_OUT",
            "        else:",
            "            # Note: On Windows it can happen that partial lines are sent.",
            "            # Hence we get something like \"CompreReceiving objects\", which is",
            "            # a blend of \"Compressing objects\" and \"Receiving objects\".",
            "            # This can't really be prevented, so we drop the line verbosely",
            "            # to make sure we get informed in case the process spits out new",
            "            # commands at some point.",
            "            self.line_dropped(line_str)",
            "            # Note: Don't add this line to the other lines, as we have to silently",
            "            # drop it.",
            "            return",
            "        # END handle op code",
            "",
            "        # Figure out stage.",
            "        if op_code not in self._seen_ops:",
            "            self._seen_ops.append(op_code)",
            "            op_code |= self.BEGIN",
            "        # END begin opcode",
            "",
            "        if message is None:",
            "            message = \"\"",
            "        # END message handling",
            "",
            "        message = message.strip()",
            "        if message.endswith(self.DONE_TOKEN):",
            "            op_code |= self.END",
            "            message = message[: -len(self.DONE_TOKEN)]",
            "        # END end message handling",
            "        message = message.strip(self.TOKEN_SEPARATOR)",
            "",
            "        self.update(",
            "            op_code,",
            "            cur_count and float(cur_count),",
            "            max_count and float(max_count),",
            "            message,",
            "        )",
            "",
            "    def new_message_handler(self) -> Callable[[str], None]:",
            "        \"\"\"",
            "        :return:",
            "            A progress handler suitable for handle_process_output(), passing lines on to",
            "            this Progress handler in a suitable format",
            "        \"\"\"",
            "",
            "        def handler(line: AnyStr) -> None:",
            "            return self._parse_progress_line(line.rstrip())",
            "",
            "        # END handler",
            "",
            "        return handler",
            "",
            "    def line_dropped(self, line: str) -> None:",
            "        \"\"\"Called whenever a line could not be understood and was therefore dropped.\"\"\"",
            "        pass",
            "",
            "    def update(",
            "        self,",
            "        op_code: int,",
            "        cur_count: Union[str, float],",
            "        max_count: Union[str, float, None] = None,",
            "        message: str = \"\",",
            "    ) -> None:",
            "        \"\"\"Called whenever the progress changes.",
            "",
            "        :param op_code:",
            "            Integer allowing to be compared against Operation IDs and stage IDs.",
            "",
            "            Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation",
            "            ID as well as END. It may be that BEGIN and END are set at once in case only",
            "            one progress message was emitted due to the speed of the operation.",
            "            Between BEGIN and END, none of these flags will be set.",
            "",
            "            Operation IDs are all held within the OP_MASK. Only one Operation ID will",
            "            be active per call.",
            "",
            "        :param cur_count: Current absolute count of items.",
            "",
            "        :param max_count:",
            "            The maximum count of items we expect. It may be None in case there is",
            "            no maximum number of items or if it is (yet) unknown.",
            "",
            "        :param message:",
            "            In case of the 'WRITING' operation, it contains the amount of bytes",
            "            transferred. It may possibly be used for other purposes as well.",
            "",
            "        You may read the contents of the current line in ``self._cur_line``.",
            "        \"\"\"",
            "        pass",
            "",
            "",
            "class CallableRemoteProgress(RemoteProgress):",
            "    \"\"\"An implementation forwarding updates to any callable.\"\"\"",
            "",
            "    __slots__ = (\"_callable\",)",
            "",
            "    def __init__(self, fn: Callable) -> None:",
            "        self._callable = fn",
            "        super().__init__()",
            "",
            "    def update(self, *args: Any, **kwargs: Any) -> None:",
            "        self._callable(*args, **kwargs)",
            "",
            "",
            "class Actor:",
            "    \"\"\"Actors hold information about a person acting on the repository. They",
            "    can be committers and authors or anything with a name and an email as",
            "    mentioned in the git log entries.\"\"\"",
            "",
            "    # PRECOMPILED REGEX",
            "    name_only_regex = re.compile(r\"<(.*)>\")",
            "    name_email_regex = re.compile(r\"(.*) <(.*?)>\")",
            "",
            "    # ENVIRONMENT VARIABLES",
            "    # These are read when creating new commits.",
            "    env_author_name = \"GIT_AUTHOR_NAME\"",
            "    env_author_email = \"GIT_AUTHOR_EMAIL\"",
            "    env_committer_name = \"GIT_COMMITTER_NAME\"",
            "    env_committer_email = \"GIT_COMMITTER_EMAIL\"",
            "",
            "    # CONFIGURATION KEYS",
            "    conf_name = \"name\"",
            "    conf_email = \"email\"",
            "",
            "    __slots__ = (\"name\", \"email\")",
            "",
            "    def __init__(self, name: Optional[str], email: Optional[str]) -> None:",
            "        self.name = name",
            "        self.email = email",
            "",
            "    def __eq__(self, other: Any) -> bool:",
            "        return self.name == other.name and self.email == other.email",
            "",
            "    def __ne__(self, other: Any) -> bool:",
            "        return not (self == other)",
            "",
            "    def __hash__(self) -> int:",
            "        return hash((self.name, self.email))",
            "",
            "    def __str__(self) -> str:",
            "        return self.name if self.name else \"\"",
            "",
            "    def __repr__(self) -> str:",
            "        return '<git.Actor \"%s <%s>\">' % (self.name, self.email)",
            "",
            "    @classmethod",
            "    def _from_string(cls, string: str) -> \"Actor\":",
            "        \"\"\"Create an Actor from a string.",
            "",
            "        :param string: The string, which is expected to be in regular git format::",
            "",
            "            John Doe <jdoe@example.com>",
            "",
            "        :return: Actor",
            "        \"\"\"",
            "        m = cls.name_email_regex.search(string)",
            "        if m:",
            "            name, email = m.groups()",
            "            return Actor(name, email)",
            "        else:",
            "            m = cls.name_only_regex.search(string)",
            "            if m:",
            "                return Actor(m.group(1), None)",
            "            # Assume the best and use the whole string as name.",
            "            return Actor(string, None)",
            "            # END special case name",
            "        # END handle name/email matching",
            "",
            "    @classmethod",
            "    def _main_actor(",
            "        cls,",
            "        env_name: str,",
            "        env_email: str,",
            "        config_reader: Union[None, \"GitConfigParser\", \"SectionConstraint\"] = None,",
            "    ) -> \"Actor\":",
            "        actor = Actor(\"\", \"\")",
            "        user_id = None  # We use this to avoid multiple calls to getpass.getuser().",
            "",
            "        def default_email() -> str:",
            "            nonlocal user_id",
            "            if not user_id:",
            "                user_id = get_user_id()",
            "            return user_id",
            "",
            "        def default_name() -> str:",
            "            return default_email().split(\"@\")[0]",
            "",
            "        for attr, evar, cvar, default in (",
            "            (\"name\", env_name, cls.conf_name, default_name),",
            "            (\"email\", env_email, cls.conf_email, default_email),",
            "        ):",
            "            try:",
            "                val = os.environ[evar]",
            "                setattr(actor, attr, val)",
            "            except KeyError:",
            "                if config_reader is not None:",
            "                    try:",
            "                        val = config_reader.get(\"user\", cvar)",
            "                    except Exception:",
            "                        val = default()",
            "                    setattr(actor, attr, val)",
            "                # END config-reader handling",
            "                if not getattr(actor, attr):",
            "                    setattr(actor, attr, default())",
            "            # END handle name",
            "        # END for each item to retrieve",
            "        return actor",
            "",
            "    @classmethod",
            "    def committer(cls, config_reader: Union[None, \"GitConfigParser\", \"SectionConstraint\"] = None) -> \"Actor\":",
            "        \"\"\"",
            "        :return: Actor instance corresponding to the configured committer. It behaves",
            "            similar to the git implementation, such that the environment will override",
            "            configuration values of config_reader. If no value is set at all, it will be",
            "            generated.",
            "",
            "        :param config_reader: ConfigReader to use to retrieve the values from in case",
            "            they are not set in the environment.",
            "        \"\"\"",
            "        return cls._main_actor(cls.env_committer_name, cls.env_committer_email, config_reader)",
            "",
            "    @classmethod",
            "    def author(cls, config_reader: Union[None, \"GitConfigParser\", \"SectionConstraint\"] = None) -> \"Actor\":",
            "        \"\"\"Same as committer(), but defines the main author. It may be specified in the",
            "        environment, but defaults to the committer.\"\"\"",
            "        return cls._main_actor(cls.env_author_name, cls.env_author_email, config_reader)",
            "",
            "",
            "class Stats:",
            "    \"\"\"",
            "    Represents stat information as presented by git at the end of a merge. It is",
            "    created from the output of a diff operation.",
            "",
            "    ``Example``::",
            "",
            "     c = Commit( sha1 )",
            "     s = c.stats",
            "     s.total         # full-stat-dict",
            "     s.files         # dict( filepath : stat-dict )",
            "",
            "    ``stat-dict``",
            "",
            "    A dictionary with the following keys and values::",
            "",
            "      deletions = number of deleted lines as int",
            "      insertions = number of inserted lines as int",
            "      lines = total number of lines changed as int, or deletions + insertions",
            "",
            "    ``full-stat-dict``",
            "",
            "    In addition to the items in the stat-dict, it features additional information::",
            "",
            "     files = number of changed files as int",
            "    \"\"\"",
            "",
            "    __slots__ = (\"total\", \"files\")",
            "",
            "    def __init__(self, total: Total_TD, files: Dict[PathLike, Files_TD]):",
            "        self.total = total",
            "        self.files = files",
            "",
            "    @classmethod",
            "    def _list_from_string(cls, repo: \"Repo\", text: str) -> \"Stats\":",
            "        \"\"\"Create a Stat object from output retrieved by git-diff.",
            "",
            "        :return: git.Stat",
            "        \"\"\"",
            "",
            "        hsh: HSH_TD = {",
            "            \"total\": {\"insertions\": 0, \"deletions\": 0, \"lines\": 0, \"files\": 0},",
            "            \"files\": {},",
            "        }",
            "        for line in text.splitlines():",
            "            (raw_insertions, raw_deletions, filename) = line.split(\"\\t\")",
            "            insertions = raw_insertions != \"-\" and int(raw_insertions) or 0",
            "            deletions = raw_deletions != \"-\" and int(raw_deletions) or 0",
            "            hsh[\"total\"][\"insertions\"] += insertions",
            "            hsh[\"total\"][\"deletions\"] += deletions",
            "            hsh[\"total\"][\"lines\"] += insertions + deletions",
            "            hsh[\"total\"][\"files\"] += 1",
            "            files_dict: Files_TD = {",
            "                \"insertions\": insertions,",
            "                \"deletions\": deletions,",
            "                \"lines\": insertions + deletions,",
            "            }",
            "            hsh[\"files\"][filename.strip()] = files_dict",
            "        return Stats(hsh[\"total\"], hsh[\"files\"])",
            "",
            "",
            "class IndexFileSHA1Writer:",
            "    \"\"\"Wrapper around a file-like object that remembers the SHA1 of",
            "    the data written to it. It will write a sha when the stream is closed",
            "    or if the asked for explicitly using write_sha.",
            "",
            "    Only useful to the index file.",
            "",
            "    :note: Based on the dulwich project.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"f\", \"sha1\")",
            "",
            "    def __init__(self, f: IO) -> None:",
            "        self.f = f",
            "        self.sha1 = make_sha(b\"\")",
            "",
            "    def write(self, data: AnyStr) -> int:",
            "        self.sha1.update(data)",
            "        return self.f.write(data)",
            "",
            "    def write_sha(self) -> bytes:",
            "        sha = self.sha1.digest()",
            "        self.f.write(sha)",
            "        return sha",
            "",
            "    def close(self) -> bytes:",
            "        sha = self.write_sha()",
            "        self.f.close()",
            "        return sha",
            "",
            "    def tell(self) -> int:",
            "        return self.f.tell()",
            "",
            "",
            "class LockFile:",
            "    \"\"\"Provides methods to obtain, check for, and release a file based lock which",
            "    should be used to handle concurrent access to the same file.",
            "",
            "    As we are a utility class to be derived from, we only use protected methods.",
            "",
            "    Locks will automatically be released on destruction.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"_file_path\", \"_owns_lock\")",
            "",
            "    def __init__(self, file_path: PathLike) -> None:",
            "        self._file_path = file_path",
            "        self._owns_lock = False",
            "",
            "    def __del__(self) -> None:",
            "        self._release_lock()",
            "",
            "    def _lock_file_path(self) -> str:",
            "        \"\"\":return: Path to lockfile\"\"\"",
            "        return \"%s.lock\" % (self._file_path)",
            "",
            "    def _has_lock(self) -> bool:",
            "        \"\"\"",
            "        :return: True if we have a lock and if the lockfile still exists",
            "",
            "        :raise AssertionError: If our lock-file does not exist",
            "        \"\"\"",
            "        return self._owns_lock",
            "",
            "    def _obtain_lock_or_raise(self) -> None:",
            "        \"\"\"Create a lock file as flag for other instances, mark our instance as lock-holder.",
            "",
            "        :raise IOError: If a lock was already present or a lock file could not be written",
            "        \"\"\"",
            "        if self._has_lock():",
            "            return",
            "        lock_file = self._lock_file_path()",
            "        if osp.isfile(lock_file):",
            "            raise IOError(",
            "                \"Lock for file %r did already exist, delete %r in case the lock is illegal\"",
            "                % (self._file_path, lock_file)",
            "            )",
            "",
            "        try:",
            "            with open(lock_file, mode=\"w\"):",
            "                pass",
            "        except OSError as e:",
            "            raise IOError(str(e)) from e",
            "",
            "        self._owns_lock = True",
            "",
            "    def _obtain_lock(self) -> None:",
            "        \"\"\"The default implementation will raise if a lock cannot be obtained.",
            "        Subclasses may override this method to provide a different implementation.\"\"\"",
            "        return self._obtain_lock_or_raise()",
            "",
            "    def _release_lock(self) -> None:",
            "        \"\"\"Release our lock if we have one.\"\"\"",
            "        if not self._has_lock():",
            "            return",
            "",
            "        # If someone removed our file beforehand, lets just flag this issue",
            "        # instead of failing, to make it more usable.",
            "        lfp = self._lock_file_path()",
            "        try:",
            "            rmfile(lfp)",
            "        except OSError:",
            "            pass",
            "        self._owns_lock = False",
            "",
            "",
            "class BlockingLockFile(LockFile):",
            "    \"\"\"The lock file will block until a lock could be obtained, or fail after",
            "    a specified timeout.",
            "",
            "    :note: If the directory containing the lock was removed, an exception will",
            "        be raised during the blocking period, preventing hangs as the lock",
            "        can never be obtained.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"_check_interval\", \"_max_block_time\")",
            "",
            "    def __init__(",
            "        self,",
            "        file_path: PathLike,",
            "        check_interval_s: float = 0.3,",
            "        max_block_time_s: int = sys.maxsize,",
            "    ) -> None:",
            "        \"\"\"Configure the instance.",
            "",
            "        :param check_interval_s:",
            "            Period of time to sleep until the lock is checked the next time.",
            "            By default, it waits a nearly unlimited time.",
            "",
            "        :param max_block_time_s: Maximum amount of seconds we may lock.",
            "        \"\"\"",
            "        super().__init__(file_path)",
            "        self._check_interval = check_interval_s",
            "        self._max_block_time = max_block_time_s",
            "",
            "    def _obtain_lock(self) -> None:",
            "        \"\"\"This method blocks until it obtained the lock, or raises IOError if",
            "        it ran out of time or if the parent directory was not available anymore.",
            "",
            "        If this method returns, you are guaranteed to own the lock.",
            "        \"\"\"",
            "        starttime = time.time()",
            "        maxtime = starttime + float(self._max_block_time)",
            "        while True:",
            "            try:",
            "                super()._obtain_lock()",
            "            except IOError as e:",
            "                # synity check: if the directory leading to the lockfile is not",
            "                # readable anymore, raise an exception",
            "                curtime = time.time()",
            "                if not osp.isdir(osp.dirname(self._lock_file_path())):",
            "                    msg = \"Directory containing the lockfile %r was not readable anymore after waiting %g seconds\" % (",
            "                        self._lock_file_path(),",
            "                        curtime - starttime,",
            "                    )",
            "                    raise IOError(msg) from e",
            "                # END handle missing directory",
            "",
            "                if curtime >= maxtime:",
            "                    msg = \"Waited %g seconds for lock at %r\" % (",
            "                        maxtime - starttime,",
            "                        self._lock_file_path(),",
            "                    )",
            "                    raise IOError(msg) from e",
            "                # END abort if we wait too long",
            "                time.sleep(self._check_interval)",
            "            else:",
            "                break",
            "        # END endless loop",
            "",
            "",
            "class IterableList(List[T_IterableObj]):",
            "    \"\"\"",
            "    List of iterable objects allowing to query an object by id or by named index::",
            "",
            "     heads = repo.heads",
            "     heads.master",
            "     heads['master']",
            "     heads[0]",
            "",
            "    Iterable parent objects = [Commit, SubModule, Reference, FetchInfo, PushInfo]",
            "    Iterable via inheritance = [Head, TagReference, RemoteReference]",
            "",
            "    It requires an id_attribute name to be set which will be queried from its",
            "    contained items to have a means for comparison.",
            "",
            "    A prefix can be specified which is to be used in case the id returned by the",
            "    items always contains a prefix that does not matter to the user, so it",
            "    can be left out.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"_id_attr\", \"_prefix\")",
            "",
            "    def __new__(cls, id_attr: str, prefix: str = \"\") -> \"IterableList[T_IterableObj]\":",
            "        return super().__new__(cls)",
            "",
            "    def __init__(self, id_attr: str, prefix: str = \"\") -> None:",
            "        self._id_attr = id_attr",
            "        self._prefix = prefix",
            "",
            "    def __contains__(self, attr: object) -> bool:",
            "        # First try identity match for performance.",
            "        try:",
            "            rval = list.__contains__(self, attr)",
            "            if rval:",
            "                return rval",
            "        except (AttributeError, TypeError):",
            "            pass",
            "        # END handle match",
            "",
            "        # Otherwise make a full name search.",
            "        try:",
            "            getattr(self, cast(str, attr))  # Use cast to silence mypy.",
            "            return True",
            "        except (AttributeError, TypeError):",
            "            return False",
            "        # END handle membership",
            "",
            "    def __getattr__(self, attr: str) -> T_IterableObj:",
            "        attr = self._prefix + attr",
            "        for item in self:",
            "            if getattr(item, self._id_attr) == attr:",
            "                return item",
            "        # END for each item",
            "        return list.__getattribute__(self, attr)",
            "",
            "    def __getitem__(self, index: Union[SupportsIndex, int, slice, str]) -> T_IterableObj:  # type: ignore",
            "        assert isinstance(index, (int, str, slice)), \"Index of IterableList should be an int or str\"",
            "",
            "        if isinstance(index, int):",
            "            return list.__getitem__(self, index)",
            "        elif isinstance(index, slice):",
            "            raise ValueError(\"Index should be an int or str\")",
            "        else:",
            "            try:",
            "                return getattr(self, index)",
            "            except AttributeError as e:",
            "                raise IndexError(\"No item found with id %r\" % (self._prefix + index)) from e",
            "        # END handle getattr",
            "",
            "    def __delitem__(self, index: Union[SupportsIndex, int, slice, str]) -> None:",
            "        assert isinstance(index, (int, str)), \"Index of IterableList should be an int or str\"",
            "",
            "        delindex = cast(int, index)",
            "        if not isinstance(index, int):",
            "            delindex = -1",
            "            name = self._prefix + index",
            "            for i, item in enumerate(self):",
            "                if getattr(item, self._id_attr) == name:",
            "                    delindex = i",
            "                    break",
            "                # END search index",
            "            # END for each item",
            "            if delindex == -1:",
            "                raise IndexError(\"Item with name %s not found\" % name)",
            "            # END handle error",
            "        # END get index to delete",
            "        list.__delitem__(self, delindex)",
            "",
            "",
            "@runtime_checkable",
            "class IterableObj(Protocol):",
            "    \"\"\"Defines an interface for iterable items, so there is a uniform way to retrieve",
            "    and iterate items within the git repository.",
            "",
            "    Subclasses = [Submodule, Commit, Reference, PushInfo, FetchInfo, Remote]",
            "    \"\"\"",
            "",
            "    __slots__ = ()",
            "",
            "    _id_attribute_: str",
            "",
            "    @classmethod",
            "    @abstractmethod",
            "    def iter_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> Iterator[T_IterableObj]:",
            "        # Return-typed to be compatible with subtypes e.g. Remote.",
            "        \"\"\"Find (all) items of this type.",
            "",
            "        Subclasses can specify ``args`` and ``kwargs`` differently, and may use them for",
            "        filtering. However, when the method is called with no additional positional or",
            "        keyword arguments, subclasses are obliged to to yield all items.",
            "",
            "        :return: Iterator yielding Items",
            "        \"\"\"",
            "        raise NotImplementedError(\"To be implemented by Subclass\")",
            "",
            "    @classmethod",
            "    def list_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> IterableList[T_IterableObj]:",
            "        \"\"\"Find (all) items of this type and collect them into a list.",
            "",
            "        For more information about the arguments, see :meth:`iter_items`.",
            "",
            "        :note: Favor the :meth:`iter_items` method as it will avoid eagerly collecting",
            "            all items. When there are many items, that can slow performance and increase",
            "            memory usage.",
            "",
            "        :return: list(Item,...) list of item instances",
            "        \"\"\"",
            "        out_list: IterableList = IterableList(cls._id_attribute_)",
            "        out_list.extend(cls.iter_items(repo, *args, **kwargs))",
            "        return out_list",
            "",
            "",
            "class IterableClassWatcher(type):",
            "    \"\"\"Metaclass that issues :class:`DeprecationWarning` when :class:`git.util.Iterable`",
            "    is subclassed.\"\"\"",
            "",
            "    def __init__(cls, name: str, bases: Tuple, clsdict: Dict) -> None:",
            "        for base in bases:",
            "            if type(base) is IterableClassWatcher:",
            "                warnings.warn(",
            "                    f\"GitPython Iterable subclassed by {name}.\"",
            "                    \" Iterable is deprecated due to naming clash since v3.1.18\"",
            "                    \" and will be removed in 4.0.0.\"",
            "                    \" Use IterableObj instead.\",",
            "                    DeprecationWarning,",
            "                    stacklevel=2,",
            "                )",
            "",
            "",
            "class Iterable(metaclass=IterableClassWatcher):",
            "    \"\"\"Deprecated, use :class:`IterableObj` instead.",
            "",
            "    Defines an interface for iterable items, so there is a uniform way to retrieve",
            "    and iterate items within the git repository.",
            "    \"\"\"",
            "",
            "    __slots__ = ()",
            "",
            "    _id_attribute_ = \"attribute that most suitably identifies your instance\"",
            "",
            "    @classmethod",
            "    def iter_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> Any:",
            "        \"\"\"Deprecated, use :class:`IterableObj` instead.",
            "",
            "        Find (all) items of this type.",
            "",
            "        See :meth:`IterableObj.iter_items` for details on usage.",
            "",
            "        :return: Iterator yielding Items",
            "        \"\"\"",
            "        raise NotImplementedError(\"To be implemented by Subclass\")",
            "",
            "    @classmethod",
            "    def list_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> Any:",
            "        \"\"\"Deprecated, use :class:`IterableObj` instead.",
            "",
            "        Find (all) items of this type and collect them into a list.",
            "",
            "        See :meth:`IterableObj.list_items` for details on usage.",
            "",
            "        :return: list(Item,...) list of item instances",
            "        \"\"\"",
            "        out_list: Any = IterableList(cls._id_attribute_)",
            "        out_list.extend(cls.iter_items(repo, *args, **kwargs))",
            "        return out_list",
            "",
            "",
            "# } END classes",
            "",
            "",
            "class NullHandler(logging.Handler):",
            "    def emit(self, record: object) -> None:",
            "        pass"
        ],
        "afterPatchFile": [
            "# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors",
            "#",
            "# This module is part of GitPython and is released under the",
            "# 3-Clause BSD License: https://opensource.org/license/bsd-3-clause/",
            "",
            "from abc import abstractmethod",
            "import contextlib",
            "from functools import wraps",
            "import getpass",
            "import logging",
            "import os",
            "import os.path as osp",
            "import pathlib",
            "import platform",
            "import re",
            "import shutil",
            "import stat",
            "import subprocess",
            "import sys",
            "import time",
            "from urllib.parse import urlsplit, urlunsplit",
            "import warnings",
            "",
            "# typing ---------------------------------------------------------",
            "",
            "from typing import (",
            "    Any,",
            "    AnyStr,",
            "    BinaryIO,",
            "    Callable,",
            "    Dict,",
            "    Generator,",
            "    IO,",
            "    Iterator,",
            "    List,",
            "    Optional,",
            "    Pattern,",
            "    Sequence,",
            "    Tuple,",
            "    TypeVar,",
            "    Union,",
            "    TYPE_CHECKING,",
            "    cast,",
            "    overload,",
            ")",
            "",
            "if TYPE_CHECKING:",
            "    from git.remote import Remote",
            "    from git.repo.base import Repo",
            "    from git.config import GitConfigParser, SectionConstraint",
            "    from git import Git",
            "",
            "from .types import (",
            "    Literal,",
            "    SupportsIndex,",
            "    Protocol,",
            "    runtime_checkable,  # because behind py version guards",
            "    PathLike,",
            "    HSH_TD,",
            "    Total_TD,",
            "    Files_TD,  # aliases",
            "    Has_id_attribute,",
            ")",
            "",
            "# ---------------------------------------------------------------------",
            "",
            "from gitdb.util import (  # noqa: F401  # @IgnorePep8",
            "    make_sha,",
            "    LockedFD,  # @UnusedImport",
            "    file_contents_ro,  # @UnusedImport",
            "    file_contents_ro_filepath,  # @UnusedImport",
            "    LazyMixin,  # @UnusedImport",
            "    to_hex_sha,  # @UnusedImport",
            "    to_bin_sha,  # @UnusedImport",
            "    bin_to_hex,  # @UnusedImport",
            "    hex_to_bin,  # @UnusedImport",
            ")",
            "",
            "T_IterableObj = TypeVar(\"T_IterableObj\", bound=Union[\"IterableObj\", \"Has_id_attribute\"], covariant=True)",
            "# So IterableList[Head] is subtype of IterableList[IterableObj].",
            "",
            "# NOTE:  Some of the unused imports might be used/imported by others.",
            "# Handle once test-cases are back up and running.",
            "# Most of these are unused here, but are for use by git-python modules so these",
            "# don't see gitdb all the time. Flake of course doesn't like it.",
            "__all__ = [",
            "    \"stream_copy\",",
            "    \"join_path\",",
            "    \"to_native_path_linux\",",
            "    \"join_path_native\",",
            "    \"Stats\",",
            "    \"IndexFileSHA1Writer\",",
            "    \"IterableObj\",",
            "    \"IterableList\",",
            "    \"BlockingLockFile\",",
            "    \"LockFile\",",
            "    \"Actor\",",
            "    \"get_user_id\",",
            "    \"assure_directory_exists\",",
            "    \"RemoteProgress\",",
            "    \"CallableRemoteProgress\",",
            "    \"rmtree\",",
            "    \"unbare_repo\",",
            "    \"HIDE_WINDOWS_KNOWN_ERRORS\",",
            "]",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def _read_win_env_flag(name: str, default: bool) -> bool:",
            "    \"\"\"Read a boolean flag from an environment variable on Windows.",
            "",
            "    :return:",
            "        On Windows, the flag, or the ``default`` value if absent or ambiguous.",
            "        On all other operating systems, ``False``.",
            "",
            "    :note: This only accesses the environment on Windows.",
            "    \"\"\"",
            "    if os.name != \"nt\":",
            "        return False",
            "",
            "    try:",
            "        value = os.environ[name]",
            "    except KeyError:",
            "        return default",
            "",
            "    log.warning(",
            "        \"The %s environment variable is deprecated. Its effect has never been documented and changes without warning.\",",
            "        name,",
            "    )",
            "",
            "    adjusted_value = value.strip().lower()",
            "",
            "    if adjusted_value in {\"\", \"0\", \"false\", \"no\"}:",
            "        return False",
            "    if adjusted_value in {\"1\", \"true\", \"yes\"}:",
            "        return True",
            "    log.warning(\"%s has unrecognized value %r, treating as %r.\", name, value, default)",
            "    return default",
            "",
            "",
            "#: We need an easy way to see if Appveyor TCs start failing,",
            "#: so the errors marked with this var are considered \"acknowledged\" ones, awaiting remedy,",
            "#: till then, we wish to hide them.",
            "HIDE_WINDOWS_KNOWN_ERRORS = _read_win_env_flag(\"HIDE_WINDOWS_KNOWN_ERRORS\", True)",
            "HIDE_WINDOWS_FREEZE_ERRORS = _read_win_env_flag(\"HIDE_WINDOWS_FREEZE_ERRORS\", True)",
            "",
            "# { Utility Methods",
            "",
            "T = TypeVar(\"T\")",
            "",
            "",
            "def unbare_repo(func: Callable[..., T]) -> Callable[..., T]:",
            "    \"\"\"Methods with this decorator raise :class:`.exc.InvalidGitRepositoryError` if they",
            "    encounter a bare repository.\"\"\"",
            "",
            "    from .exc import InvalidGitRepositoryError",
            "",
            "    @wraps(func)",
            "    def wrapper(self: \"Remote\", *args: Any, **kwargs: Any) -> T:",
            "        if self.repo.bare:",
            "            raise InvalidGitRepositoryError(\"Method '%s' cannot operate on bare repositories\" % func.__name__)",
            "        # END bare method",
            "        return func(self, *args, **kwargs)",
            "",
            "    # END wrapper",
            "",
            "    return wrapper",
            "",
            "",
            "@contextlib.contextmanager",
            "def cwd(new_dir: PathLike) -> Generator[PathLike, None, None]:",
            "    \"\"\"Context manager to temporarily change directory.",
            "",
            "    This is similar to :func:`contextlib.chdir` introduced in Python 3.11, but the",
            "    context manager object returned by a single call to this function is not reentrant.",
            "    \"\"\"",
            "    old_dir = os.getcwd()",
            "    os.chdir(new_dir)",
            "    try:",
            "        yield new_dir",
            "    finally:",
            "        os.chdir(old_dir)",
            "",
            "",
            "@contextlib.contextmanager",
            "def patch_env(name: str, value: str) -> Generator[None, None, None]:",
            "    \"\"\"Context manager to temporarily patch an environment variable.\"\"\"",
            "    old_value = os.getenv(name)",
            "    os.environ[name] = value",
            "    try:",
            "        yield",
            "    finally:",
            "        if old_value is None:",
            "            del os.environ[name]",
            "        else:",
            "            os.environ[name] = old_value",
            "",
            "",
            "def rmtree(path: PathLike) -> None:",
            "    \"\"\"Remove the given directory tree recursively.",
            "",
            "    :note: We use :func:`shutil.rmtree` but adjust its behaviour to see whether files",
            "        that couldn't be deleted are read-only. Windows will not remove them in that",
            "        case.",
            "    \"\"\"",
            "",
            "    def handler(function: Callable, path: PathLike, _excinfo: Any) -> None:",
            "        \"\"\"Callback for :func:`shutil.rmtree`. Works either as ``onexc`` or ``onerror``.\"\"\"",
            "        # Is the error an access error?",
            "        os.chmod(path, stat.S_IWUSR)",
            "",
            "        try:",
            "            function(path)",
            "        except PermissionError as ex:",
            "            if HIDE_WINDOWS_KNOWN_ERRORS:",
            "                from unittest import SkipTest",
            "",
            "                raise SkipTest(f\"FIXME: fails with: PermissionError\\n  {ex}\") from ex",
            "            raise",
            "",
            "    if os.name != \"nt\":",
            "        shutil.rmtree(path)",
            "    elif sys.version_info >= (3, 12):",
            "        shutil.rmtree(path, onexc=handler)",
            "    else:",
            "        shutil.rmtree(path, onerror=handler)",
            "",
            "",
            "def rmfile(path: PathLike) -> None:",
            "    \"\"\"Ensure file deleted also on *Windows* where read-only files need special treatment.\"\"\"",
            "    if osp.isfile(path):",
            "        if os.name == \"nt\":",
            "            os.chmod(path, 0o777)",
            "        os.remove(path)",
            "",
            "",
            "def stream_copy(source: BinaryIO, destination: BinaryIO, chunk_size: int = 512 * 1024) -> int:",
            "    \"\"\"Copy all data from the source stream into the destination stream in chunks",
            "    of size chunk_size.",
            "",
            "    :return: Number of bytes written",
            "    \"\"\"",
            "    br = 0",
            "    while True:",
            "        chunk = source.read(chunk_size)",
            "        destination.write(chunk)",
            "        br += len(chunk)",
            "        if len(chunk) < chunk_size:",
            "            break",
            "    # END reading output stream",
            "    return br",
            "",
            "",
            "def join_path(a: PathLike, *p: PathLike) -> PathLike:",
            "    R\"\"\"Join path tokens together similar to osp.join, but always use",
            "    '/' instead of possibly '\\' on Windows.\"\"\"",
            "    path = str(a)",
            "    for b in p:",
            "        b = str(b)",
            "        if not b:",
            "            continue",
            "        if b.startswith(\"/\"):",
            "            path += b[1:]",
            "        elif path == \"\" or path.endswith(\"/\"):",
            "            path += b",
            "        else:",
            "            path += \"/\" + b",
            "    # END for each path token to add",
            "    return path",
            "",
            "",
            "if os.name == \"nt\":",
            "",
            "    def to_native_path_windows(path: PathLike) -> PathLike:",
            "        path = str(path)",
            "        return path.replace(\"/\", \"\\\\\")",
            "",
            "    def to_native_path_linux(path: PathLike) -> str:",
            "        path = str(path)",
            "        return path.replace(\"\\\\\", \"/\")",
            "",
            "    __all__.append(\"to_native_path_windows\")",
            "    to_native_path = to_native_path_windows",
            "else:",
            "    # No need for any work on Linux.",
            "    def to_native_path_linux(path: PathLike) -> str:",
            "        return str(path)",
            "",
            "    to_native_path = to_native_path_linux",
            "",
            "",
            "def join_path_native(a: PathLike, *p: PathLike) -> PathLike:",
            "    R\"\"\"Like join_path, but makes sure an OS native path is returned.",
            "",
            "    This is only needed to play it safe on Windows and to ensure nice paths that only",
            "    use '\\'.",
            "    \"\"\"",
            "    return to_native_path(join_path(a, *p))",
            "",
            "",
            "def assure_directory_exists(path: PathLike, is_file: bool = False) -> bool:",
            "    \"\"\"Make sure that the directory pointed to by path exists.",
            "",
            "    :param is_file: If True, ``path`` is assumed to be a file and handled correctly.",
            "        Otherwise it must be a directory.",
            "",
            "    :return: True if the directory was created, False if it already existed.",
            "    \"\"\"",
            "    if is_file:",
            "        path = osp.dirname(path)",
            "    # END handle file",
            "    if not osp.isdir(path):",
            "        os.makedirs(path, exist_ok=True)",
            "        return True",
            "    return False",
            "",
            "",
            "def _get_exe_extensions() -> Sequence[str]:",
            "    PATHEXT = os.environ.get(\"PATHEXT\", None)",
            "    if PATHEXT:",
            "        return tuple(p.upper() for p in PATHEXT.split(os.pathsep))",
            "    elif os.name == \"nt\":",
            "        return (\".BAT\", \"COM\", \".EXE\")",
            "    else:",
            "        return ()",
            "",
            "",
            "def py_where(program: str, path: Optional[PathLike] = None) -> List[str]:",
            "    \"\"\"Perform a path search to assist :func:`is_cygwin_git`.",
            "",
            "    This is not robust for general use. It is an implementation detail of",
            "    :func:`is_cygwin_git`. When a search following all shell rules is needed,",
            "    :func:`shutil.which` can be used instead.",
            "",
            "    :note: Neither this function nor :func:`shutil.which` will predict the effect of an",
            "        executable search on a native Windows system due to a :class:`subprocess.Popen`",
            "        call without ``shell=True``, because shell and non-shell executable search on",
            "        Windows differ considerably.",
            "    \"\"\"",
            "    # From: http://stackoverflow.com/a/377028/548792",
            "    winprog_exts = _get_exe_extensions()",
            "",
            "    def is_exec(fpath: str) -> bool:",
            "        return (",
            "            osp.isfile(fpath)",
            "            and os.access(fpath, os.X_OK)",
            "            and (os.name != \"nt\" or not winprog_exts or any(fpath.upper().endswith(ext) for ext in winprog_exts))",
            "        )",
            "",
            "    progs = []",
            "    if not path:",
            "        path = os.environ[\"PATH\"]",
            "    for folder in str(path).split(os.pathsep):",
            "        folder = folder.strip('\"')",
            "        if folder:",
            "            exe_path = osp.join(folder, program)",
            "            for f in [exe_path] + [\"%s%s\" % (exe_path, e) for e in winprog_exts]:",
            "                if is_exec(f):",
            "                    progs.append(f)",
            "    return progs",
            "",
            "",
            "def _cygexpath(drive: Optional[str], path: str) -> str:",
            "    if osp.isabs(path) and not drive:",
            "        # Invoked from `cygpath()` directly with `D:Apps\\123`?",
            "        #  It's an error, leave it alone just slashes)",
            "        p = path  # convert to str if AnyPath given",
            "    else:",
            "        p = path and osp.normpath(osp.expandvars(osp.expanduser(path)))",
            "        if osp.isabs(p):",
            "            if drive:",
            "                # Confusing, maybe a remote system should expand vars.",
            "                p = path",
            "            else:",
            "                p = cygpath(p)",
            "        elif drive:",
            "            p = \"/proc/cygdrive/%s/%s\" % (drive.lower(), p)",
            "    p_str = str(p)  # ensure it is a str and not AnyPath",
            "    return p_str.replace(\"\\\\\", \"/\")",
            "",
            "",
            "_cygpath_parsers: Tuple[Tuple[Pattern[str], Callable, bool], ...] = (",
            "    # See: https://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx",
            "    # and: https://www.cygwin.com/cygwin-ug-net/using.html#unc-paths",
            "    (",
            "        re.compile(r\"\\\\\\\\\\?\\\\UNC\\\\([^\\\\]+)\\\\([^\\\\]+)(?:\\\\(.*))?\"),",
            "        (lambda server, share, rest_path: \"//%s/%s/%s\" % (server, share, rest_path.replace(\"\\\\\", \"/\"))),",
            "        False,",
            "    ),",
            "    (re.compile(r\"\\\\\\\\\\?\\\\(\\w):[/\\\\](.*)\"), (_cygexpath), False),",
            "    (re.compile(r\"(\\w):[/\\\\](.*)\"), (_cygexpath), False),",
            "    (re.compile(r\"file:(.*)\", re.I), (lambda rest_path: rest_path), True),",
            "    (re.compile(r\"(\\w{2,}:.*)\"), (lambda url: url), False),  # remote URL, do nothing",
            ")",
            "",
            "",
            "def cygpath(path: str) -> str:",
            "    \"\"\"Use :meth:`git.cmd.Git.polish_url` instead, that works on any environment.\"\"\"",
            "    path = str(path)  # Ensure is str and not AnyPath.",
            "    # Fix to use Paths when 3.5 dropped. Or to be just str if only for URLs?",
            "    if not path.startswith((\"/cygdrive\", \"//\", \"/proc/cygdrive\")):",
            "        for regex, parser, recurse in _cygpath_parsers:",
            "            match = regex.match(path)",
            "            if match:",
            "                path = parser(*match.groups())",
            "                if recurse:",
            "                    path = cygpath(path)",
            "                break",
            "        else:",
            "            path = _cygexpath(None, path)",
            "",
            "    return path",
            "",
            "",
            "_decygpath_regex = re.compile(r\"(?:/proc)?/cygdrive/(\\w)(/.*)?\")",
            "",
            "",
            "def decygpath(path: PathLike) -> str:",
            "    path = str(path)",
            "    m = _decygpath_regex.match(path)",
            "    if m:",
            "        drive, rest_path = m.groups()",
            "        path = \"%s:%s\" % (drive.upper(), rest_path or \"\")",
            "",
            "    return path.replace(\"/\", \"\\\\\")",
            "",
            "",
            "#: Store boolean flags denoting if a specific Git executable",
            "#: is from a Cygwin installation (since `cache_lru()` unsupported on PY2).",
            "_is_cygwin_cache: Dict[str, Optional[bool]] = {}",
            "",
            "",
            "@overload",
            "def is_cygwin_git(git_executable: None) -> Literal[False]:",
            "    ...",
            "",
            "",
            "@overload",
            "def is_cygwin_git(git_executable: PathLike) -> bool:",
            "    ...",
            "",
            "",
            "def is_cygwin_git(git_executable: Union[None, PathLike]) -> bool:",
            "    if os.name == \"nt\":",
            "        # This is Windows-native Python, since Cygwin has os.name == \"posix\".",
            "        return False",
            "",
            "    if git_executable is None:",
            "        return False",
            "",
            "    git_executable = str(git_executable)",
            "    is_cygwin = _is_cygwin_cache.get(git_executable)  # type: Optional[bool]",
            "    if is_cygwin is None:",
            "        is_cygwin = False",
            "        try:",
            "            git_dir = osp.dirname(git_executable)",
            "            if not git_dir:",
            "                res = py_where(git_executable)",
            "                git_dir = osp.dirname(res[0]) if res else \"\"",
            "",
            "            # Just a name given, not a real path.",
            "            uname_cmd = osp.join(git_dir, \"uname\")",
            "            process = subprocess.Popen([uname_cmd], stdout=subprocess.PIPE, universal_newlines=True)",
            "            uname_out, _ = process.communicate()",
            "            # retcode = process.poll()",
            "            is_cygwin = \"CYGWIN\" in uname_out",
            "        except Exception as ex:",
            "            log.debug(\"Failed checking if running in CYGWIN due to: %r\", ex)",
            "        _is_cygwin_cache[git_executable] = is_cygwin",
            "",
            "    return is_cygwin",
            "",
            "",
            "def get_user_id() -> str:",
            "    \"\"\":return: string identifying the currently active system user as name@node\"\"\"",
            "    return \"%s@%s\" % (getpass.getuser(), platform.node())",
            "",
            "",
            "def finalize_process(proc: Union[subprocess.Popen, \"Git.AutoInterrupt\"], **kwargs: Any) -> None:",
            "    \"\"\"Wait for the process (clone, fetch, pull or push) and handle its errors accordingly\"\"\"",
            "    # TODO: No close proc-streams??",
            "    proc.wait(**kwargs)",
            "",
            "",
            "@overload",
            "def expand_path(p: None, expand_vars: bool = ...) -> None:",
            "    ...",
            "",
            "",
            "@overload",
            "def expand_path(p: PathLike, expand_vars: bool = ...) -> str:",
            "    # improve these overloads when 3.5 dropped",
            "    ...",
            "",
            "",
            "def expand_path(p: Union[None, PathLike], expand_vars: bool = True) -> Optional[PathLike]:",
            "    if isinstance(p, pathlib.Path):",
            "        return p.resolve()",
            "    try:",
            "        p = osp.expanduser(p)  # type: ignore",
            "        if expand_vars:",
            "            p = osp.expandvars(p)  # type: ignore",
            "        return osp.normpath(osp.abspath(p))  # type: ignore",
            "    except Exception:",
            "        return None",
            "",
            "",
            "def remove_password_if_present(cmdline: Sequence[str]) -> List[str]:",
            "    \"\"\"Parse any command line argument and if one of the elements is an URL with a",
            "    username and/or password, replace them by stars (in-place).",
            "",
            "    If nothing is found, this just returns the command line as-is.",
            "",
            "    This should be used for every log line that print a command line, as well as",
            "    exception messages.",
            "    \"\"\"",
            "    new_cmdline = []",
            "    for index, to_parse in enumerate(cmdline):",
            "        new_cmdline.append(to_parse)",
            "        try:",
            "            url = urlsplit(to_parse)",
            "            # Remove password from the URL if present.",
            "            if url.password is None and url.username is None:",
            "                continue",
            "",
            "            if url.password is not None:",
            "                url = url._replace(netloc=url.netloc.replace(url.password, \"*****\"))",
            "            if url.username is not None:",
            "                url = url._replace(netloc=url.netloc.replace(url.username, \"*****\"))",
            "            new_cmdline[index] = urlunsplit(url)",
            "        except ValueError:",
            "            # This is not a valid URL.",
            "            continue",
            "    return new_cmdline",
            "",
            "",
            "# } END utilities",
            "",
            "# { Classes",
            "",
            "",
            "class RemoteProgress:",
            "    \"\"\"",
            "    Handler providing an interface to parse progress information emitted by git-push",
            "    and git-fetch and to dispatch callbacks allowing subclasses to react to the progress.",
            "    \"\"\"",
            "",
            "    _num_op_codes: int = 9",
            "    (",
            "        BEGIN,",
            "        END,",
            "        COUNTING,",
            "        COMPRESSING,",
            "        WRITING,",
            "        RECEIVING,",
            "        RESOLVING,",
            "        FINDING_SOURCES,",
            "        CHECKING_OUT,",
            "    ) = [1 << x for x in range(_num_op_codes)]",
            "    STAGE_MASK = BEGIN | END",
            "    OP_MASK = ~STAGE_MASK",
            "",
            "    DONE_TOKEN = \"done.\"",
            "    TOKEN_SEPARATOR = \", \"",
            "",
            "    __slots__ = (",
            "        \"_cur_line\",",
            "        \"_seen_ops\",",
            "        \"error_lines\",  # Lines that started with 'error:' or 'fatal:'.",
            "        \"other_lines\",  # Lines not denoting progress (i.e.g. push-infos).",
            "    )",
            "    re_op_absolute = re.compile(r\"(remote: )?([\\w\\s]+):\\s+()(\\d+)()(.*)\")",
            "    re_op_relative = re.compile(r\"(remote: )?([\\w\\s]+):\\s+(\\d+)% \\((\\d+)/(\\d+)\\)(.*)\")",
            "",
            "    def __init__(self) -> None:",
            "        self._seen_ops: List[int] = []",
            "        self._cur_line: Optional[str] = None",
            "        self.error_lines: List[str] = []",
            "        self.other_lines: List[str] = []",
            "",
            "    def _parse_progress_line(self, line: AnyStr) -> None:",
            "        \"\"\"Parse progress information from the given line as retrieved by git-push",
            "        or git-fetch.",
            "",
            "        - Lines that do not contain progress info are stored in :attr:`other_lines`.",
            "        - Lines that seem to contain an error (i.e. start with ``error:`` or ``fatal:``)",
            "          are stored in :attr:`error_lines`.",
            "        \"\"\"",
            "        # handle",
            "        # Counting objects: 4, done.",
            "        # Compressing objects:  50% (1/2)",
            "        # Compressing objects: 100% (2/2)",
            "        # Compressing objects: 100% (2/2), done.",
            "        if isinstance(line, bytes):  # mypy argues about ternary assignment.",
            "            line_str = line.decode(\"utf-8\")",
            "        else:",
            "            line_str = line",
            "        self._cur_line = line_str",
            "",
            "        if self._cur_line.startswith((\"error:\", \"fatal:\")):",
            "            self.error_lines.append(self._cur_line)",
            "            return",
            "",
            "        # Find escape characters and cut them away - regex will not work with",
            "        # them as they are non-ASCII. As git might expect a tty, it will send them.",
            "        last_valid_index = None",
            "        for i, c in enumerate(reversed(line_str)):",
            "            if ord(c) < 32:",
            "                # its a slice index",
            "                last_valid_index = -i - 1",
            "            # END character was non-ASCII",
            "        # END for each character in line",
            "        if last_valid_index is not None:",
            "            line_str = line_str[:last_valid_index]",
            "        # END cut away invalid part",
            "        line_str = line_str.rstrip()",
            "",
            "        cur_count, max_count = None, None",
            "        match = self.re_op_relative.match(line_str)",
            "        if match is None:",
            "            match = self.re_op_absolute.match(line_str)",
            "",
            "        if not match:",
            "            self.line_dropped(line_str)",
            "            self.other_lines.append(line_str)",
            "            return",
            "        # END could not get match",
            "",
            "        op_code = 0",
            "        _remote, op_name, _percent, cur_count, max_count, message = match.groups()",
            "",
            "        # Get operation ID.",
            "        if op_name == \"Counting objects\":",
            "            op_code |= self.COUNTING",
            "        elif op_name == \"Compressing objects\":",
            "            op_code |= self.COMPRESSING",
            "        elif op_name == \"Writing objects\":",
            "            op_code |= self.WRITING",
            "        elif op_name == \"Receiving objects\":",
            "            op_code |= self.RECEIVING",
            "        elif op_name == \"Resolving deltas\":",
            "            op_code |= self.RESOLVING",
            "        elif op_name == \"Finding sources\":",
            "            op_code |= self.FINDING_SOURCES",
            "        elif op_name == \"Checking out files\":",
            "            op_code |= self.CHECKING_OUT",
            "        else:",
            "            # Note: On Windows it can happen that partial lines are sent.",
            "            # Hence we get something like \"CompreReceiving objects\", which is",
            "            # a blend of \"Compressing objects\" and \"Receiving objects\".",
            "            # This can't really be prevented, so we drop the line verbosely",
            "            # to make sure we get informed in case the process spits out new",
            "            # commands at some point.",
            "            self.line_dropped(line_str)",
            "            # Note: Don't add this line to the other lines, as we have to silently",
            "            # drop it.",
            "            return",
            "        # END handle op code",
            "",
            "        # Figure out stage.",
            "        if op_code not in self._seen_ops:",
            "            self._seen_ops.append(op_code)",
            "            op_code |= self.BEGIN",
            "        # END begin opcode",
            "",
            "        if message is None:",
            "            message = \"\"",
            "        # END message handling",
            "",
            "        message = message.strip()",
            "        if message.endswith(self.DONE_TOKEN):",
            "            op_code |= self.END",
            "            message = message[: -len(self.DONE_TOKEN)]",
            "        # END end message handling",
            "        message = message.strip(self.TOKEN_SEPARATOR)",
            "",
            "        self.update(",
            "            op_code,",
            "            cur_count and float(cur_count),",
            "            max_count and float(max_count),",
            "            message,",
            "        )",
            "",
            "    def new_message_handler(self) -> Callable[[str], None]:",
            "        \"\"\"",
            "        :return:",
            "            A progress handler suitable for handle_process_output(), passing lines on to",
            "            this Progress handler in a suitable format",
            "        \"\"\"",
            "",
            "        def handler(line: AnyStr) -> None:",
            "            return self._parse_progress_line(line.rstrip())",
            "",
            "        # END handler",
            "",
            "        return handler",
            "",
            "    def line_dropped(self, line: str) -> None:",
            "        \"\"\"Called whenever a line could not be understood and was therefore dropped.\"\"\"",
            "        pass",
            "",
            "    def update(",
            "        self,",
            "        op_code: int,",
            "        cur_count: Union[str, float],",
            "        max_count: Union[str, float, None] = None,",
            "        message: str = \"\",",
            "    ) -> None:",
            "        \"\"\"Called whenever the progress changes.",
            "",
            "        :param op_code:",
            "            Integer allowing to be compared against Operation IDs and stage IDs.",
            "",
            "            Stage IDs are BEGIN and END. BEGIN will only be set once for each Operation",
            "            ID as well as END. It may be that BEGIN and END are set at once in case only",
            "            one progress message was emitted due to the speed of the operation.",
            "            Between BEGIN and END, none of these flags will be set.",
            "",
            "            Operation IDs are all held within the OP_MASK. Only one Operation ID will",
            "            be active per call.",
            "",
            "        :param cur_count: Current absolute count of items.",
            "",
            "        :param max_count:",
            "            The maximum count of items we expect. It may be None in case there is",
            "            no maximum number of items or if it is (yet) unknown.",
            "",
            "        :param message:",
            "            In case of the 'WRITING' operation, it contains the amount of bytes",
            "            transferred. It may possibly be used for other purposes as well.",
            "",
            "        You may read the contents of the current line in ``self._cur_line``.",
            "        \"\"\"",
            "        pass",
            "",
            "",
            "class CallableRemoteProgress(RemoteProgress):",
            "    \"\"\"An implementation forwarding updates to any callable.\"\"\"",
            "",
            "    __slots__ = (\"_callable\",)",
            "",
            "    def __init__(self, fn: Callable) -> None:",
            "        self._callable = fn",
            "        super().__init__()",
            "",
            "    def update(self, *args: Any, **kwargs: Any) -> None:",
            "        self._callable(*args, **kwargs)",
            "",
            "",
            "class Actor:",
            "    \"\"\"Actors hold information about a person acting on the repository. They",
            "    can be committers and authors or anything with a name and an email as",
            "    mentioned in the git log entries.\"\"\"",
            "",
            "    # PRECOMPILED REGEX",
            "    name_only_regex = re.compile(r\"<(.*)>\")",
            "    name_email_regex = re.compile(r\"(.*) <(.*?)>\")",
            "",
            "    # ENVIRONMENT VARIABLES",
            "    # These are read when creating new commits.",
            "    env_author_name = \"GIT_AUTHOR_NAME\"",
            "    env_author_email = \"GIT_AUTHOR_EMAIL\"",
            "    env_committer_name = \"GIT_COMMITTER_NAME\"",
            "    env_committer_email = \"GIT_COMMITTER_EMAIL\"",
            "",
            "    # CONFIGURATION KEYS",
            "    conf_name = \"name\"",
            "    conf_email = \"email\"",
            "",
            "    __slots__ = (\"name\", \"email\")",
            "",
            "    def __init__(self, name: Optional[str], email: Optional[str]) -> None:",
            "        self.name = name",
            "        self.email = email",
            "",
            "    def __eq__(self, other: Any) -> bool:",
            "        return self.name == other.name and self.email == other.email",
            "",
            "    def __ne__(self, other: Any) -> bool:",
            "        return not (self == other)",
            "",
            "    def __hash__(self) -> int:",
            "        return hash((self.name, self.email))",
            "",
            "    def __str__(self) -> str:",
            "        return self.name if self.name else \"\"",
            "",
            "    def __repr__(self) -> str:",
            "        return '<git.Actor \"%s <%s>\">' % (self.name, self.email)",
            "",
            "    @classmethod",
            "    def _from_string(cls, string: str) -> \"Actor\":",
            "        \"\"\"Create an Actor from a string.",
            "",
            "        :param string: The string, which is expected to be in regular git format::",
            "",
            "            John Doe <jdoe@example.com>",
            "",
            "        :return: Actor",
            "        \"\"\"",
            "        m = cls.name_email_regex.search(string)",
            "        if m:",
            "            name, email = m.groups()",
            "            return Actor(name, email)",
            "        else:",
            "            m = cls.name_only_regex.search(string)",
            "            if m:",
            "                return Actor(m.group(1), None)",
            "            # Assume the best and use the whole string as name.",
            "            return Actor(string, None)",
            "            # END special case name",
            "        # END handle name/email matching",
            "",
            "    @classmethod",
            "    def _main_actor(",
            "        cls,",
            "        env_name: str,",
            "        env_email: str,",
            "        config_reader: Union[None, \"GitConfigParser\", \"SectionConstraint\"] = None,",
            "    ) -> \"Actor\":",
            "        actor = Actor(\"\", \"\")",
            "        user_id = None  # We use this to avoid multiple calls to getpass.getuser().",
            "",
            "        def default_email() -> str:",
            "            nonlocal user_id",
            "            if not user_id:",
            "                user_id = get_user_id()",
            "            return user_id",
            "",
            "        def default_name() -> str:",
            "            return default_email().split(\"@\")[0]",
            "",
            "        for attr, evar, cvar, default in (",
            "            (\"name\", env_name, cls.conf_name, default_name),",
            "            (\"email\", env_email, cls.conf_email, default_email),",
            "        ):",
            "            try:",
            "                val = os.environ[evar]",
            "                setattr(actor, attr, val)",
            "            except KeyError:",
            "                if config_reader is not None:",
            "                    try:",
            "                        val = config_reader.get(\"user\", cvar)",
            "                    except Exception:",
            "                        val = default()",
            "                    setattr(actor, attr, val)",
            "                # END config-reader handling",
            "                if not getattr(actor, attr):",
            "                    setattr(actor, attr, default())",
            "            # END handle name",
            "        # END for each item to retrieve",
            "        return actor",
            "",
            "    @classmethod",
            "    def committer(cls, config_reader: Union[None, \"GitConfigParser\", \"SectionConstraint\"] = None) -> \"Actor\":",
            "        \"\"\"",
            "        :return: Actor instance corresponding to the configured committer. It behaves",
            "            similar to the git implementation, such that the environment will override",
            "            configuration values of config_reader. If no value is set at all, it will be",
            "            generated.",
            "",
            "        :param config_reader: ConfigReader to use to retrieve the values from in case",
            "            they are not set in the environment.",
            "        \"\"\"",
            "        return cls._main_actor(cls.env_committer_name, cls.env_committer_email, config_reader)",
            "",
            "    @classmethod",
            "    def author(cls, config_reader: Union[None, \"GitConfigParser\", \"SectionConstraint\"] = None) -> \"Actor\":",
            "        \"\"\"Same as committer(), but defines the main author. It may be specified in the",
            "        environment, but defaults to the committer.\"\"\"",
            "        return cls._main_actor(cls.env_author_name, cls.env_author_email, config_reader)",
            "",
            "",
            "class Stats:",
            "    \"\"\"",
            "    Represents stat information as presented by git at the end of a merge. It is",
            "    created from the output of a diff operation.",
            "",
            "    ``Example``::",
            "",
            "     c = Commit( sha1 )",
            "     s = c.stats",
            "     s.total         # full-stat-dict",
            "     s.files         # dict( filepath : stat-dict )",
            "",
            "    ``stat-dict``",
            "",
            "    A dictionary with the following keys and values::",
            "",
            "      deletions = number of deleted lines as int",
            "      insertions = number of inserted lines as int",
            "      lines = total number of lines changed as int, or deletions + insertions",
            "",
            "    ``full-stat-dict``",
            "",
            "    In addition to the items in the stat-dict, it features additional information::",
            "",
            "     files = number of changed files as int",
            "    \"\"\"",
            "",
            "    __slots__ = (\"total\", \"files\")",
            "",
            "    def __init__(self, total: Total_TD, files: Dict[PathLike, Files_TD]):",
            "        self.total = total",
            "        self.files = files",
            "",
            "    @classmethod",
            "    def _list_from_string(cls, repo: \"Repo\", text: str) -> \"Stats\":",
            "        \"\"\"Create a Stat object from output retrieved by git-diff.",
            "",
            "        :return: git.Stat",
            "        \"\"\"",
            "",
            "        hsh: HSH_TD = {",
            "            \"total\": {\"insertions\": 0, \"deletions\": 0, \"lines\": 0, \"files\": 0},",
            "            \"files\": {},",
            "        }",
            "        for line in text.splitlines():",
            "            (raw_insertions, raw_deletions, filename) = line.split(\"\\t\")",
            "            insertions = raw_insertions != \"-\" and int(raw_insertions) or 0",
            "            deletions = raw_deletions != \"-\" and int(raw_deletions) or 0",
            "            hsh[\"total\"][\"insertions\"] += insertions",
            "            hsh[\"total\"][\"deletions\"] += deletions",
            "            hsh[\"total\"][\"lines\"] += insertions + deletions",
            "            hsh[\"total\"][\"files\"] += 1",
            "            files_dict: Files_TD = {",
            "                \"insertions\": insertions,",
            "                \"deletions\": deletions,",
            "                \"lines\": insertions + deletions,",
            "            }",
            "            hsh[\"files\"][filename.strip()] = files_dict",
            "        return Stats(hsh[\"total\"], hsh[\"files\"])",
            "",
            "",
            "class IndexFileSHA1Writer:",
            "    \"\"\"Wrapper around a file-like object that remembers the SHA1 of",
            "    the data written to it. It will write a sha when the stream is closed",
            "    or if the asked for explicitly using write_sha.",
            "",
            "    Only useful to the index file.",
            "",
            "    :note: Based on the dulwich project.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"f\", \"sha1\")",
            "",
            "    def __init__(self, f: IO) -> None:",
            "        self.f = f",
            "        self.sha1 = make_sha(b\"\")",
            "",
            "    def write(self, data: AnyStr) -> int:",
            "        self.sha1.update(data)",
            "        return self.f.write(data)",
            "",
            "    def write_sha(self) -> bytes:",
            "        sha = self.sha1.digest()",
            "        self.f.write(sha)",
            "        return sha",
            "",
            "    def close(self) -> bytes:",
            "        sha = self.write_sha()",
            "        self.f.close()",
            "        return sha",
            "",
            "    def tell(self) -> int:",
            "        return self.f.tell()",
            "",
            "",
            "class LockFile:",
            "    \"\"\"Provides methods to obtain, check for, and release a file based lock which",
            "    should be used to handle concurrent access to the same file.",
            "",
            "    As we are a utility class to be derived from, we only use protected methods.",
            "",
            "    Locks will automatically be released on destruction.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"_file_path\", \"_owns_lock\")",
            "",
            "    def __init__(self, file_path: PathLike) -> None:",
            "        self._file_path = file_path",
            "        self._owns_lock = False",
            "",
            "    def __del__(self) -> None:",
            "        self._release_lock()",
            "",
            "    def _lock_file_path(self) -> str:",
            "        \"\"\":return: Path to lockfile\"\"\"",
            "        return \"%s.lock\" % (self._file_path)",
            "",
            "    def _has_lock(self) -> bool:",
            "        \"\"\"",
            "        :return: True if we have a lock and if the lockfile still exists",
            "",
            "        :raise AssertionError: If our lock-file does not exist",
            "        \"\"\"",
            "        return self._owns_lock",
            "",
            "    def _obtain_lock_or_raise(self) -> None:",
            "        \"\"\"Create a lock file as flag for other instances, mark our instance as lock-holder.",
            "",
            "        :raise IOError: If a lock was already present or a lock file could not be written",
            "        \"\"\"",
            "        if self._has_lock():",
            "            return",
            "        lock_file = self._lock_file_path()",
            "        if osp.isfile(lock_file):",
            "            raise IOError(",
            "                \"Lock for file %r did already exist, delete %r in case the lock is illegal\"",
            "                % (self._file_path, lock_file)",
            "            )",
            "",
            "        try:",
            "            with open(lock_file, mode=\"w\"):",
            "                pass",
            "        except OSError as e:",
            "            raise IOError(str(e)) from e",
            "",
            "        self._owns_lock = True",
            "",
            "    def _obtain_lock(self) -> None:",
            "        \"\"\"The default implementation will raise if a lock cannot be obtained.",
            "        Subclasses may override this method to provide a different implementation.\"\"\"",
            "        return self._obtain_lock_or_raise()",
            "",
            "    def _release_lock(self) -> None:",
            "        \"\"\"Release our lock if we have one.\"\"\"",
            "        if not self._has_lock():",
            "            return",
            "",
            "        # If someone removed our file beforehand, lets just flag this issue",
            "        # instead of failing, to make it more usable.",
            "        lfp = self._lock_file_path()",
            "        try:",
            "            rmfile(lfp)",
            "        except OSError:",
            "            pass",
            "        self._owns_lock = False",
            "",
            "",
            "class BlockingLockFile(LockFile):",
            "    \"\"\"The lock file will block until a lock could be obtained, or fail after",
            "    a specified timeout.",
            "",
            "    :note: If the directory containing the lock was removed, an exception will",
            "        be raised during the blocking period, preventing hangs as the lock",
            "        can never be obtained.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"_check_interval\", \"_max_block_time\")",
            "",
            "    def __init__(",
            "        self,",
            "        file_path: PathLike,",
            "        check_interval_s: float = 0.3,",
            "        max_block_time_s: int = sys.maxsize,",
            "    ) -> None:",
            "        \"\"\"Configure the instance.",
            "",
            "        :param check_interval_s:",
            "            Period of time to sleep until the lock is checked the next time.",
            "            By default, it waits a nearly unlimited time.",
            "",
            "        :param max_block_time_s: Maximum amount of seconds we may lock.",
            "        \"\"\"",
            "        super().__init__(file_path)",
            "        self._check_interval = check_interval_s",
            "        self._max_block_time = max_block_time_s",
            "",
            "    def _obtain_lock(self) -> None:",
            "        \"\"\"This method blocks until it obtained the lock, or raises IOError if",
            "        it ran out of time or if the parent directory was not available anymore.",
            "",
            "        If this method returns, you are guaranteed to own the lock.",
            "        \"\"\"",
            "        starttime = time.time()",
            "        maxtime = starttime + float(self._max_block_time)",
            "        while True:",
            "            try:",
            "                super()._obtain_lock()",
            "            except IOError as e:",
            "                # synity check: if the directory leading to the lockfile is not",
            "                # readable anymore, raise an exception",
            "                curtime = time.time()",
            "                if not osp.isdir(osp.dirname(self._lock_file_path())):",
            "                    msg = \"Directory containing the lockfile %r was not readable anymore after waiting %g seconds\" % (",
            "                        self._lock_file_path(),",
            "                        curtime - starttime,",
            "                    )",
            "                    raise IOError(msg) from e",
            "                # END handle missing directory",
            "",
            "                if curtime >= maxtime:",
            "                    msg = \"Waited %g seconds for lock at %r\" % (",
            "                        maxtime - starttime,",
            "                        self._lock_file_path(),",
            "                    )",
            "                    raise IOError(msg) from e",
            "                # END abort if we wait too long",
            "                time.sleep(self._check_interval)",
            "            else:",
            "                break",
            "        # END endless loop",
            "",
            "",
            "class IterableList(List[T_IterableObj]):",
            "    \"\"\"",
            "    List of iterable objects allowing to query an object by id or by named index::",
            "",
            "     heads = repo.heads",
            "     heads.master",
            "     heads['master']",
            "     heads[0]",
            "",
            "    Iterable parent objects = [Commit, SubModule, Reference, FetchInfo, PushInfo]",
            "    Iterable via inheritance = [Head, TagReference, RemoteReference]",
            "",
            "    It requires an id_attribute name to be set which will be queried from its",
            "    contained items to have a means for comparison.",
            "",
            "    A prefix can be specified which is to be used in case the id returned by the",
            "    items always contains a prefix that does not matter to the user, so it",
            "    can be left out.",
            "    \"\"\"",
            "",
            "    __slots__ = (\"_id_attr\", \"_prefix\")",
            "",
            "    def __new__(cls, id_attr: str, prefix: str = \"\") -> \"IterableList[T_IterableObj]\":",
            "        return super().__new__(cls)",
            "",
            "    def __init__(self, id_attr: str, prefix: str = \"\") -> None:",
            "        self._id_attr = id_attr",
            "        self._prefix = prefix",
            "",
            "    def __contains__(self, attr: object) -> bool:",
            "        # First try identity match for performance.",
            "        try:",
            "            rval = list.__contains__(self, attr)",
            "            if rval:",
            "                return rval",
            "        except (AttributeError, TypeError):",
            "            pass",
            "        # END handle match",
            "",
            "        # Otherwise make a full name search.",
            "        try:",
            "            getattr(self, cast(str, attr))  # Use cast to silence mypy.",
            "            return True",
            "        except (AttributeError, TypeError):",
            "            return False",
            "        # END handle membership",
            "",
            "    def __getattr__(self, attr: str) -> T_IterableObj:",
            "        attr = self._prefix + attr",
            "        for item in self:",
            "            if getattr(item, self._id_attr) == attr:",
            "                return item",
            "        # END for each item",
            "        return list.__getattribute__(self, attr)",
            "",
            "    def __getitem__(self, index: Union[SupportsIndex, int, slice, str]) -> T_IterableObj:  # type: ignore",
            "        assert isinstance(index, (int, str, slice)), \"Index of IterableList should be an int or str\"",
            "",
            "        if isinstance(index, int):",
            "            return list.__getitem__(self, index)",
            "        elif isinstance(index, slice):",
            "            raise ValueError(\"Index should be an int or str\")",
            "        else:",
            "            try:",
            "                return getattr(self, index)",
            "            except AttributeError as e:",
            "                raise IndexError(\"No item found with id %r\" % (self._prefix + index)) from e",
            "        # END handle getattr",
            "",
            "    def __delitem__(self, index: Union[SupportsIndex, int, slice, str]) -> None:",
            "        assert isinstance(index, (int, str)), \"Index of IterableList should be an int or str\"",
            "",
            "        delindex = cast(int, index)",
            "        if not isinstance(index, int):",
            "            delindex = -1",
            "            name = self._prefix + index",
            "            for i, item in enumerate(self):",
            "                if getattr(item, self._id_attr) == name:",
            "                    delindex = i",
            "                    break",
            "                # END search index",
            "            # END for each item",
            "            if delindex == -1:",
            "                raise IndexError(\"Item with name %s not found\" % name)",
            "            # END handle error",
            "        # END get index to delete",
            "        list.__delitem__(self, delindex)",
            "",
            "",
            "@runtime_checkable",
            "class IterableObj(Protocol):",
            "    \"\"\"Defines an interface for iterable items, so there is a uniform way to retrieve",
            "    and iterate items within the git repository.",
            "",
            "    Subclasses = [Submodule, Commit, Reference, PushInfo, FetchInfo, Remote]",
            "    \"\"\"",
            "",
            "    __slots__ = ()",
            "",
            "    _id_attribute_: str",
            "",
            "    @classmethod",
            "    @abstractmethod",
            "    def iter_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> Iterator[T_IterableObj]:",
            "        # Return-typed to be compatible with subtypes e.g. Remote.",
            "        \"\"\"Find (all) items of this type.",
            "",
            "        Subclasses can specify ``args`` and ``kwargs`` differently, and may use them for",
            "        filtering. However, when the method is called with no additional positional or",
            "        keyword arguments, subclasses are obliged to to yield all items.",
            "",
            "        :return: Iterator yielding Items",
            "        \"\"\"",
            "        raise NotImplementedError(\"To be implemented by Subclass\")",
            "",
            "    @classmethod",
            "    def list_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> IterableList[T_IterableObj]:",
            "        \"\"\"Find (all) items of this type and collect them into a list.",
            "",
            "        For more information about the arguments, see :meth:`iter_items`.",
            "",
            "        :note: Favor the :meth:`iter_items` method as it will avoid eagerly collecting",
            "            all items. When there are many items, that can slow performance and increase",
            "            memory usage.",
            "",
            "        :return: list(Item,...) list of item instances",
            "        \"\"\"",
            "        out_list: IterableList = IterableList(cls._id_attribute_)",
            "        out_list.extend(cls.iter_items(repo, *args, **kwargs))",
            "        return out_list",
            "",
            "",
            "class IterableClassWatcher(type):",
            "    \"\"\"Metaclass that issues :class:`DeprecationWarning` when :class:`git.util.Iterable`",
            "    is subclassed.\"\"\"",
            "",
            "    def __init__(cls, name: str, bases: Tuple, clsdict: Dict) -> None:",
            "        for base in bases:",
            "            if type(base) is IterableClassWatcher:",
            "                warnings.warn(",
            "                    f\"GitPython Iterable subclassed by {name}.\"",
            "                    \" Iterable is deprecated due to naming clash since v3.1.18\"",
            "                    \" and will be removed in 4.0.0.\"",
            "                    \" Use IterableObj instead.\",",
            "                    DeprecationWarning,",
            "                    stacklevel=2,",
            "                )",
            "",
            "",
            "class Iterable(metaclass=IterableClassWatcher):",
            "    \"\"\"Deprecated, use :class:`IterableObj` instead.",
            "",
            "    Defines an interface for iterable items, so there is a uniform way to retrieve",
            "    and iterate items within the git repository.",
            "    \"\"\"",
            "",
            "    __slots__ = ()",
            "",
            "    _id_attribute_ = \"attribute that most suitably identifies your instance\"",
            "",
            "    @classmethod",
            "    def iter_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> Any:",
            "        \"\"\"Deprecated, use :class:`IterableObj` instead.",
            "",
            "        Find (all) items of this type.",
            "",
            "        See :meth:`IterableObj.iter_items` for details on usage.",
            "",
            "        :return: Iterator yielding Items",
            "        \"\"\"",
            "        raise NotImplementedError(\"To be implemented by Subclass\")",
            "",
            "    @classmethod",
            "    def list_items(cls, repo: \"Repo\", *args: Any, **kwargs: Any) -> Any:",
            "        \"\"\"Deprecated, use :class:`IterableObj` instead.",
            "",
            "        Find (all) items of this type and collect them into a list.",
            "",
            "        See :meth:`IterableObj.list_items` for details on usage.",
            "",
            "        :return: list(Item,...) list of item instances",
            "        \"\"\"",
            "        out_list: Any = IterableList(cls._id_attribute_)",
            "        out_list.extend(cls.iter_items(repo, *args, **kwargs))",
            "        return out_list",
            "",
            "",
            "# } END classes",
            "",
            "",
            "class NullHandler(logging.Handler):",
            "    def emit(self, record: object) -> None:",
            "        pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "git.util.py_where.progs"
        ]
    }
}