{
    "superset/dashboards/commands/create.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "     def run(self) -> Model:"
            },
            "1": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "         self.validate()"
            },
            "2": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "         try:"
            },
            "3": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dashboard = DashboardDAO.create(self._properties, commit=False)"
            },
            "4": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=True)"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+            dashboard = DashboardDAO.create(self._properties, commit=True)"
            },
            "6": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "         except DAOCreateFailedError as ex:"
            },
            "7": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "             logger.exception(ex.exception)"
            },
            "8": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "             raise DashboardCreateFailedError() from ex"
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import logging",
            "from typing import Any, Dict, List, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset.commands.base import BaseCommand, CreateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.dao.exceptions import DAOCreateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardCreateFailedError,",
            "    DashboardInvalidError,",
            "    DashboardSlugExistsValidationError,",
            ")",
            "from superset.dashboards.dao import DashboardDAO",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class CreateDashboardCommand(CreateMixin, BaseCommand):",
            "    def __init__(self, data: Dict[str, Any]):",
            "        self._properties = data.copy()",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        try:",
            "            dashboard = DashboardDAO.create(self._properties, commit=False)",
            "            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=True)",
            "        except DAOCreateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardCreateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: List[ValidationError] = []",
            "        owner_ids: Optional[List[int]] = self._properties.get(\"owners\")",
            "        role_ids: Optional[List[int]] = self._properties.get(\"roles\")",
            "        slug: str = self._properties.get(\"slug\", \"\")",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_slug_uniqueness(slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        try:",
            "            owners = self.populate_owners(owner_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception",
            "",
            "        try:",
            "            roles = populate_roles(role_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import logging",
            "from typing import Any, Dict, List, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset.commands.base import BaseCommand, CreateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.dao.exceptions import DAOCreateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardCreateFailedError,",
            "    DashboardInvalidError,",
            "    DashboardSlugExistsValidationError,",
            ")",
            "from superset.dashboards.dao import DashboardDAO",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class CreateDashboardCommand(CreateMixin, BaseCommand):",
            "    def __init__(self, data: Dict[str, Any]):",
            "        self._properties = data.copy()",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        try:",
            "            dashboard = DashboardDAO.create(self._properties, commit=True)",
            "        except DAOCreateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardCreateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: List[ValidationError] = []",
            "        owner_ids: Optional[List[int]] = self._properties.get(\"owners\")",
            "        role_ids: Optional[List[int]] = self._properties.get(\"roles\")",
            "        slug: str = self._properties.get(\"slug\", \"\")",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_slug_uniqueness(slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        try:",
            "            owners = self.populate_owners(owner_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception",
            "",
            "        try:",
            "            roles = populate_roles(role_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "43": [
                "CreateDashboardCommand",
                "run"
            ],
            "44": [
                "CreateDashboardCommand",
                "run"
            ]
        },
        "addLocation": []
    },
    "superset/dashboards/commands/update.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "                     data=json.loads(self._properties.get(\"json_metadata\", \"{}\")),"
            },
            "1": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "                     commit=False,"
            },
            "2": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "                 )"
            },
            "3": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=False)"
            },
            "4": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "             db.session.commit()"
            },
            "5": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "         except DAOUpdateFailedError as ex:"
            },
            "6": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "             logger.exception(ex.exception)"
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "import logging",
            "from typing import Any, Dict, List, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset import security_manager",
            "from superset.commands.base import BaseCommand, UpdateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.dao.exceptions import DAOUpdateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardForbiddenError,",
            "    DashboardInvalidError,",
            "    DashboardNotFoundError,",
            "    DashboardSlugExistsValidationError,",
            "    DashboardUpdateFailedError,",
            ")",
            "from superset.dashboards.dao import DashboardDAO",
            "from superset.exceptions import SupersetSecurityException",
            "from superset.extensions import db",
            "from superset.models.dashboard import Dashboard",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class UpdateDashboardCommand(UpdateMixin, BaseCommand):",
            "    def __init__(self, model_id: int, data: Dict[str, Any]):",
            "        self._model_id = model_id",
            "        self._properties = data.copy()",
            "        self._model: Optional[Dashboard] = None",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        try:",
            "            dashboard = DashboardDAO.update(self._model, self._properties, commit=False)",
            "            if self._properties.get(\"json_metadata\"):",
            "                dashboard = DashboardDAO.set_dash_metadata(",
            "                    dashboard,",
            "                    data=json.loads(self._properties.get(\"json_metadata\", \"{}\")),",
            "                    commit=False,",
            "                )",
            "            dashboard = DashboardDAO.update_charts_owners(dashboard, commit=False)",
            "            db.session.commit()",
            "        except DAOUpdateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardUpdateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: List[ValidationError] = []",
            "        owners_ids: Optional[List[int]] = self._properties.get(\"owners\")",
            "        roles_ids: Optional[List[int]] = self._properties.get(\"roles\")",
            "        slug: Optional[str] = self._properties.get(\"slug\")",
            "",
            "        # Validate/populate model exists",
            "        self._model = DashboardDAO.find_by_id(self._model_id)",
            "        if not self._model:",
            "            raise DashboardNotFoundError()",
            "        # Check ownership",
            "        try:",
            "            security_manager.raise_for_ownership(self._model)",
            "        except SupersetSecurityException as ex:",
            "            raise DashboardForbiddenError() from ex",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_update_slug_uniqueness(self._model_id, slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        # Validate/Populate owner",
            "        if owners_ids is None:",
            "            owners_ids = [owner.id for owner in self._model.owners]",
            "        try:",
            "            owners = self.populate_owners(owners_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception",
            "",
            "        # Validate/Populate role",
            "        if roles_ids is None:",
            "            roles_ids = [role.id for role in self._model.roles]",
            "        try:",
            "            roles = populate_roles(roles_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "import logging",
            "from typing import Any, Dict, List, Optional",
            "",
            "from flask_appbuilder.models.sqla import Model",
            "from marshmallow import ValidationError",
            "",
            "from superset import security_manager",
            "from superset.commands.base import BaseCommand, UpdateMixin",
            "from superset.commands.utils import populate_roles",
            "from superset.dao.exceptions import DAOUpdateFailedError",
            "from superset.dashboards.commands.exceptions import (",
            "    DashboardForbiddenError,",
            "    DashboardInvalidError,",
            "    DashboardNotFoundError,",
            "    DashboardSlugExistsValidationError,",
            "    DashboardUpdateFailedError,",
            ")",
            "from superset.dashboards.dao import DashboardDAO",
            "from superset.exceptions import SupersetSecurityException",
            "from superset.extensions import db",
            "from superset.models.dashboard import Dashboard",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class UpdateDashboardCommand(UpdateMixin, BaseCommand):",
            "    def __init__(self, model_id: int, data: Dict[str, Any]):",
            "        self._model_id = model_id",
            "        self._properties = data.copy()",
            "        self._model: Optional[Dashboard] = None",
            "",
            "    def run(self) -> Model:",
            "        self.validate()",
            "        try:",
            "            dashboard = DashboardDAO.update(self._model, self._properties, commit=False)",
            "            if self._properties.get(\"json_metadata\"):",
            "                dashboard = DashboardDAO.set_dash_metadata(",
            "                    dashboard,",
            "                    data=json.loads(self._properties.get(\"json_metadata\", \"{}\")),",
            "                    commit=False,",
            "                )",
            "            db.session.commit()",
            "        except DAOUpdateFailedError as ex:",
            "            logger.exception(ex.exception)",
            "            raise DashboardUpdateFailedError() from ex",
            "        return dashboard",
            "",
            "    def validate(self) -> None:",
            "        exceptions: List[ValidationError] = []",
            "        owners_ids: Optional[List[int]] = self._properties.get(\"owners\")",
            "        roles_ids: Optional[List[int]] = self._properties.get(\"roles\")",
            "        slug: Optional[str] = self._properties.get(\"slug\")",
            "",
            "        # Validate/populate model exists",
            "        self._model = DashboardDAO.find_by_id(self._model_id)",
            "        if not self._model:",
            "            raise DashboardNotFoundError()",
            "        # Check ownership",
            "        try:",
            "            security_manager.raise_for_ownership(self._model)",
            "        except SupersetSecurityException as ex:",
            "            raise DashboardForbiddenError() from ex",
            "",
            "        # Validate slug uniqueness",
            "        if not DashboardDAO.validate_update_slug_uniqueness(self._model_id, slug):",
            "            exceptions.append(DashboardSlugExistsValidationError())",
            "",
            "        # Validate/Populate owner",
            "        if owners_ids is None:",
            "            owners_ids = [owner.id for owner in self._model.owners]",
            "        try:",
            "            owners = self.populate_owners(owners_ids)",
            "            self._properties[\"owners\"] = owners",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception",
            "",
            "        # Validate/Populate role",
            "        if roles_ids is None:",
            "            roles_ids = [role.id for role in self._model.roles]",
            "        try:",
            "            roles = populate_roles(roles_ids)",
            "            self._properties[\"roles\"] = roles",
            "        except ValidationError as ex:",
            "            exceptions.append(ex)",
            "        if exceptions:",
            "            exception = DashboardInvalidError()",
            "            exception.add_list(exceptions)",
            "            raise exception"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "59": [
                "UpdateDashboardCommand",
                "run"
            ]
        },
        "addLocation": []
    },
    "superset/dashboards/dao.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "             return not db.session.query(dashboard_query.exists()).scalar()"
            },
            "1": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 155,
                "PatchRowcode": "         return True"
            },
            "2": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 156,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    @staticmethod"
            },
            "4": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def update_charts_owners(model: Dashboard, commit: bool = True) -> Dashboard:"
            },
            "5": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        owners = list(model.owners)"
            },
            "6": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for slc in model.slices:"
            },
            "7": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            slc.owners = list(set(owners) | set(slc.owners))"
            },
            "8": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if commit:"
            },
            "9": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            db.session.commit()"
            },
            "10": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return model"
            },
            "11": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "12": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "     @staticmethod"
            },
            "13": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "     def bulk_delete(models: Optional[List[Dashboard]], commit: bool = True) -> None:"
            },
            "14": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "         item_ids = [model.id for model in models] if models else []"
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "import logging",
            "from datetime import datetime",
            "from typing import Any, Dict, List, Optional, Union",
            "",
            "from flask_appbuilder.models.sqla.interface import SQLAInterface",
            "from sqlalchemy.exc import SQLAlchemyError",
            "",
            "from superset.dao.base import BaseDAO",
            "from superset.dashboards.commands.exceptions import DashboardNotFoundError",
            "from superset.dashboards.filters import DashboardAccessFilter",
            "from superset.extensions import db",
            "from superset.models.core import FavStar, FavStarClassName",
            "from superset.models.dashboard import Dashboard, id_or_slug_filter",
            "from superset.models.slice import Slice",
            "from superset.utils.core import get_user_id",
            "from superset.utils.dashboard_filter_scopes_converter import copy_filter_scopes",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class DashboardDAO(BaseDAO):",
            "    model_cls = Dashboard",
            "    base_filter = DashboardAccessFilter",
            "",
            "    @staticmethod",
            "    def get_by_id_or_slug(id_or_slug: Union[int, str]) -> Dashboard:",
            "        query = (",
            "            db.session.query(Dashboard)",
            "            .filter(id_or_slug_filter(id_or_slug))",
            "            .outerjoin(Slice, Dashboard.slices)",
            "            .outerjoin(Slice.table)",
            "            .outerjoin(Dashboard.owners)",
            "            .outerjoin(Dashboard.roles)",
            "        )",
            "        # Apply dashboard base filters",
            "        query = DashboardAccessFilter(\"id\", SQLAInterface(Dashboard, db.session)).apply(",
            "            query, None",
            "        )",
            "        dashboard = query.one_or_none()",
            "        if not dashboard:",
            "            raise DashboardNotFoundError()",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def get_datasets_for_dashboard(id_or_slug: str) -> List[Any]:",
            "        dashboard = DashboardDAO.get_by_id_or_slug(id_or_slug)",
            "        return dashboard.datasets_trimmed_for_slices()",
            "",
            "    @staticmethod",
            "    def get_charts_for_dashboard(id_or_slug: str) -> List[Slice]:",
            "        return DashboardDAO.get_by_id_or_slug(id_or_slug).slices",
            "",
            "    @staticmethod",
            "    def get_dashboard_changed_on(",
            "        id_or_slug_or_dashboard: Union[str, Dashboard]",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard: Dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return dashboard.changed_on.replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_slices_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: Union[str, Dashboard]",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, or a change to one of its dependent slices.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        slices = dashboard.slices",
            "        slices_changed_on = max(",
            "            [slc.changed_on for slc in slices]",
            "            + ([datetime.fromtimestamp(0)] if len(slices) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, slices_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_datasets_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: Union[str, Dashboard]",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, a change to one of its dependent datasets.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        datasources = dashboard.datasources",
            "        datasources_changed_on = max(",
            "            [datasource.changed_on for datasource in datasources]",
            "            + ([datetime.fromtimestamp(0)] if len(datasources) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, datasources_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def validate_slug_uniqueness(slug: str) -> bool:",
            "        if not slug:",
            "            return True",
            "        dashboard_query = db.session.query(Dashboard).filter(Dashboard.slug == slug)",
            "        return not db.session.query(dashboard_query.exists()).scalar()",
            "",
            "    @staticmethod",
            "    def validate_update_slug_uniqueness(dashboard_id: int, slug: Optional[str]) -> bool:",
            "        if slug is not None:",
            "            dashboard_query = db.session.query(Dashboard).filter(",
            "                Dashboard.slug == slug, Dashboard.id != dashboard_id",
            "            )",
            "            return not db.session.query(dashboard_query.exists()).scalar()",
            "        return True",
            "",
            "    @staticmethod",
            "    def update_charts_owners(model: Dashboard, commit: bool = True) -> Dashboard:",
            "        owners = list(model.owners)",
            "        for slc in model.slices:",
            "            slc.owners = list(set(owners) | set(slc.owners))",
            "        if commit:",
            "            db.session.commit()",
            "        return model",
            "",
            "    @staticmethod",
            "    def bulk_delete(models: Optional[List[Dashboard]], commit: bool = True) -> None:",
            "        item_ids = [model.id for model in models] if models else []",
            "        # bulk delete, first delete related data",
            "        if models:",
            "            for model in models:",
            "                model.slices = []",
            "                model.owners = []",
            "                model.embedded = []",
            "                db.session.merge(model)",
            "        # bulk delete itself",
            "        try:",
            "            db.session.query(Dashboard).filter(Dashboard.id.in_(item_ids)).delete(",
            "                synchronize_session=\"fetch\"",
            "            )",
            "            if commit:",
            "                db.session.commit()",
            "        except SQLAlchemyError as ex:",
            "            db.session.rollback()",
            "            raise ex",
            "",
            "    @staticmethod",
            "    def set_dash_metadata(  # pylint: disable=too-many-locals",
            "        dashboard: Dashboard,",
            "        data: Dict[Any, Any],",
            "        old_to_new_slice_ids: Optional[Dict[int, int]] = None,",
            "        commit: bool = False,",
            "    ) -> Dashboard:",
            "        positions = data.get(\"positions\")",
            "        new_filter_scopes = {}",
            "        md = dashboard.params_dict",
            "",
            "        if positions is not None:",
            "            # find slices in the position data",
            "            slice_ids = [",
            "                value.get(\"meta\", {}).get(\"chartId\")",
            "                for value in positions.values()",
            "                if isinstance(value, dict)",
            "            ]",
            "",
            "            session = db.session()",
            "            current_slices = session.query(Slice).filter(Slice.id.in_(slice_ids)).all()",
            "",
            "            dashboard.slices = current_slices",
            "",
            "            # add UUID to positions",
            "            uuid_map = {slice.id: str(slice.uuid) for slice in current_slices}",
            "            for obj in positions.values():",
            "                if (",
            "                    isinstance(obj, dict)",
            "                    and obj[\"type\"] == \"CHART\"",
            "                    and obj[\"meta\"][\"chartId\"]",
            "                ):",
            "                    chart_id = obj[\"meta\"][\"chartId\"]",
            "                    obj[\"meta\"][\"uuid\"] = uuid_map.get(chart_id)",
            "",
            "            # remove leading and trailing white spaces in the dumped json",
            "            dashboard.position_json = json.dumps(",
            "                positions, indent=None, separators=(\",\", \":\"), sort_keys=True",
            "            )",
            "",
            "            if \"filter_scopes\" in data:",
            "                # replace filter_id and immune ids from old slice id to new slice id:",
            "                # and remove slice ids that are not in dash anymore",
            "                slc_id_dict: Dict[int, int] = {}",
            "                if old_to_new_slice_ids:",
            "                    slc_id_dict = {",
            "                        old: new",
            "                        for old, new in old_to_new_slice_ids.items()",
            "                        if new in slice_ids",
            "                    }",
            "                else:",
            "                    slc_id_dict = {sid: sid for sid in slice_ids}",
            "                new_filter_scopes = copy_filter_scopes(",
            "                    old_to_new_slc_id_dict=slc_id_dict,",
            "                    old_filter_scopes=json.loads(data[\"filter_scopes\"] or \"{}\")",
            "                    if isinstance(data[\"filter_scopes\"], str)",
            "                    else data[\"filter_scopes\"],",
            "                )",
            "",
            "            default_filters_data = json.loads(data.get(\"default_filters\", \"{}\"))",
            "            applicable_filters = {",
            "                key: v",
            "                for key, v in default_filters_data.items()",
            "                if int(key) in slice_ids",
            "            }",
            "            md[\"default_filters\"] = json.dumps(applicable_filters)",
            "",
            "            # positions have its own column, no need to store it in metadata",
            "            md.pop(\"positions\", None)",
            "",
            "        # The css and dashboard_title properties are not part of the metadata",
            "        # TODO (geido): remove by refactoring/deprecating save_dash endpoint",
            "        if data.get(\"css\") is not None:",
            "            dashboard.css = data.get(\"css\")",
            "        if data.get(\"dashboard_title\") is not None:",
            "            dashboard.dashboard_title = data.get(\"dashboard_title\")",
            "",
            "        if new_filter_scopes:",
            "            md[\"filter_scopes\"] = new_filter_scopes",
            "        else:",
            "            md.pop(\"filter_scopes\", None)",
            "",
            "        md.setdefault(\"timed_refresh_immune_slices\", [])",
            "",
            "        if data.get(\"color_namespace\") is None:",
            "            md.pop(\"color_namespace\", None)",
            "        else:",
            "            md[\"color_namespace\"] = data.get(\"color_namespace\")",
            "",
            "        md[\"expanded_slices\"] = data.get(\"expanded_slices\", {})",
            "        md[\"refresh_frequency\"] = data.get(\"refresh_frequency\", 0)",
            "        md[\"color_scheme\"] = data.get(\"color_scheme\", \"\")",
            "        md[\"label_colors\"] = data.get(\"label_colors\", {})",
            "        md[\"shared_label_colors\"] = data.get(\"shared_label_colors\", {})",
            "        md[\"color_scheme_domain\"] = data.get(\"color_scheme_domain\", [])",
            "        md[\"cross_filters_enabled\"] = data.get(\"cross_filters_enabled\", True)",
            "        dashboard.json_metadata = json.dumps(md)",
            "",
            "        if commit:",
            "            db.session.commit()",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def favorited_ids(dashboards: List[Dashboard]) -> List[FavStar]:",
            "        ids = [dash.id for dash in dashboards]",
            "        return [",
            "            star.obj_id",
            "            for star in db.session.query(FavStar.obj_id)",
            "            .filter(",
            "                FavStar.class_name == FavStarClassName.DASHBOARD,",
            "                FavStar.obj_id.in_(ids),",
            "                FavStar.user_id == get_user_id(),",
            "            )",
            "            .all()",
            "        ]"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "import json",
            "import logging",
            "from datetime import datetime",
            "from typing import Any, Dict, List, Optional, Union",
            "",
            "from flask_appbuilder.models.sqla.interface import SQLAInterface",
            "from sqlalchemy.exc import SQLAlchemyError",
            "",
            "from superset.dao.base import BaseDAO",
            "from superset.dashboards.commands.exceptions import DashboardNotFoundError",
            "from superset.dashboards.filters import DashboardAccessFilter",
            "from superset.extensions import db",
            "from superset.models.core import FavStar, FavStarClassName",
            "from superset.models.dashboard import Dashboard, id_or_slug_filter",
            "from superset.models.slice import Slice",
            "from superset.utils.core import get_user_id",
            "from superset.utils.dashboard_filter_scopes_converter import copy_filter_scopes",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class DashboardDAO(BaseDAO):",
            "    model_cls = Dashboard",
            "    base_filter = DashboardAccessFilter",
            "",
            "    @staticmethod",
            "    def get_by_id_or_slug(id_or_slug: Union[int, str]) -> Dashboard:",
            "        query = (",
            "            db.session.query(Dashboard)",
            "            .filter(id_or_slug_filter(id_or_slug))",
            "            .outerjoin(Slice, Dashboard.slices)",
            "            .outerjoin(Slice.table)",
            "            .outerjoin(Dashboard.owners)",
            "            .outerjoin(Dashboard.roles)",
            "        )",
            "        # Apply dashboard base filters",
            "        query = DashboardAccessFilter(\"id\", SQLAInterface(Dashboard, db.session)).apply(",
            "            query, None",
            "        )",
            "        dashboard = query.one_or_none()",
            "        if not dashboard:",
            "            raise DashboardNotFoundError()",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def get_datasets_for_dashboard(id_or_slug: str) -> List[Any]:",
            "        dashboard = DashboardDAO.get_by_id_or_slug(id_or_slug)",
            "        return dashboard.datasets_trimmed_for_slices()",
            "",
            "    @staticmethod",
            "    def get_charts_for_dashboard(id_or_slug: str) -> List[Slice]:",
            "        return DashboardDAO.get_by_id_or_slug(id_or_slug).slices",
            "",
            "    @staticmethod",
            "    def get_dashboard_changed_on(",
            "        id_or_slug_or_dashboard: Union[str, Dashboard]",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard: Dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return dashboard.changed_on.replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_slices_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: Union[str, Dashboard]",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, or a change to one of its dependent slices.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        slices = dashboard.slices",
            "        slices_changed_on = max(",
            "            [slc.changed_on for slc in slices]",
            "            + ([datetime.fromtimestamp(0)] if len(slices) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, slices_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def get_dashboard_and_datasets_changed_on(  # pylint: disable=invalid-name",
            "        id_or_slug_or_dashboard: Union[str, Dashboard]",
            "    ) -> datetime:",
            "        \"\"\"",
            "        Get latest changed datetime for a dashboard. The change could be a dashboard",
            "        metadata change, a change to one of its dependent datasets.",
            "",
            "        :param id_or_slug_or_dashboard: A dashboard or the ID or slug of the dashboard.",
            "        :returns: The datetime the dashboard was last changed.",
            "        \"\"\"",
            "",
            "        dashboard = (",
            "            DashboardDAO.get_by_id_or_slug(id_or_slug_or_dashboard)",
            "            if isinstance(id_or_slug_or_dashboard, str)",
            "            else id_or_slug_or_dashboard",
            "        )",
            "        dashboard_changed_on = DashboardDAO.get_dashboard_changed_on(dashboard)",
            "        datasources = dashboard.datasources",
            "        datasources_changed_on = max(",
            "            [datasource.changed_on for datasource in datasources]",
            "            + ([datetime.fromtimestamp(0)] if len(datasources) == 0 else [])",
            "        )",
            "        # drop microseconds in datetime to match with last_modified header",
            "        return max(dashboard_changed_on, datasources_changed_on).replace(microsecond=0)",
            "",
            "    @staticmethod",
            "    def validate_slug_uniqueness(slug: str) -> bool:",
            "        if not slug:",
            "            return True",
            "        dashboard_query = db.session.query(Dashboard).filter(Dashboard.slug == slug)",
            "        return not db.session.query(dashboard_query.exists()).scalar()",
            "",
            "    @staticmethod",
            "    def validate_update_slug_uniqueness(dashboard_id: int, slug: Optional[str]) -> bool:",
            "        if slug is not None:",
            "            dashboard_query = db.session.query(Dashboard).filter(",
            "                Dashboard.slug == slug, Dashboard.id != dashboard_id",
            "            )",
            "            return not db.session.query(dashboard_query.exists()).scalar()",
            "        return True",
            "",
            "    @staticmethod",
            "    def bulk_delete(models: Optional[List[Dashboard]], commit: bool = True) -> None:",
            "        item_ids = [model.id for model in models] if models else []",
            "        # bulk delete, first delete related data",
            "        if models:",
            "            for model in models:",
            "                model.slices = []",
            "                model.owners = []",
            "                model.embedded = []",
            "                db.session.merge(model)",
            "        # bulk delete itself",
            "        try:",
            "            db.session.query(Dashboard).filter(Dashboard.id.in_(item_ids)).delete(",
            "                synchronize_session=\"fetch\"",
            "            )",
            "            if commit:",
            "                db.session.commit()",
            "        except SQLAlchemyError as ex:",
            "            db.session.rollback()",
            "            raise ex",
            "",
            "    @staticmethod",
            "    def set_dash_metadata(  # pylint: disable=too-many-locals",
            "        dashboard: Dashboard,",
            "        data: Dict[Any, Any],",
            "        old_to_new_slice_ids: Optional[Dict[int, int]] = None,",
            "        commit: bool = False,",
            "    ) -> Dashboard:",
            "        positions = data.get(\"positions\")",
            "        new_filter_scopes = {}",
            "        md = dashboard.params_dict",
            "",
            "        if positions is not None:",
            "            # find slices in the position data",
            "            slice_ids = [",
            "                value.get(\"meta\", {}).get(\"chartId\")",
            "                for value in positions.values()",
            "                if isinstance(value, dict)",
            "            ]",
            "",
            "            session = db.session()",
            "            current_slices = session.query(Slice).filter(Slice.id.in_(slice_ids)).all()",
            "",
            "            dashboard.slices = current_slices",
            "",
            "            # add UUID to positions",
            "            uuid_map = {slice.id: str(slice.uuid) for slice in current_slices}",
            "            for obj in positions.values():",
            "                if (",
            "                    isinstance(obj, dict)",
            "                    and obj[\"type\"] == \"CHART\"",
            "                    and obj[\"meta\"][\"chartId\"]",
            "                ):",
            "                    chart_id = obj[\"meta\"][\"chartId\"]",
            "                    obj[\"meta\"][\"uuid\"] = uuid_map.get(chart_id)",
            "",
            "            # remove leading and trailing white spaces in the dumped json",
            "            dashboard.position_json = json.dumps(",
            "                positions, indent=None, separators=(\",\", \":\"), sort_keys=True",
            "            )",
            "",
            "            if \"filter_scopes\" in data:",
            "                # replace filter_id and immune ids from old slice id to new slice id:",
            "                # and remove slice ids that are not in dash anymore",
            "                slc_id_dict: Dict[int, int] = {}",
            "                if old_to_new_slice_ids:",
            "                    slc_id_dict = {",
            "                        old: new",
            "                        for old, new in old_to_new_slice_ids.items()",
            "                        if new in slice_ids",
            "                    }",
            "                else:",
            "                    slc_id_dict = {sid: sid for sid in slice_ids}",
            "                new_filter_scopes = copy_filter_scopes(",
            "                    old_to_new_slc_id_dict=slc_id_dict,",
            "                    old_filter_scopes=json.loads(data[\"filter_scopes\"] or \"{}\")",
            "                    if isinstance(data[\"filter_scopes\"], str)",
            "                    else data[\"filter_scopes\"],",
            "                )",
            "",
            "            default_filters_data = json.loads(data.get(\"default_filters\", \"{}\"))",
            "            applicable_filters = {",
            "                key: v",
            "                for key, v in default_filters_data.items()",
            "                if int(key) in slice_ids",
            "            }",
            "            md[\"default_filters\"] = json.dumps(applicable_filters)",
            "",
            "            # positions have its own column, no need to store it in metadata",
            "            md.pop(\"positions\", None)",
            "",
            "        # The css and dashboard_title properties are not part of the metadata",
            "        # TODO (geido): remove by refactoring/deprecating save_dash endpoint",
            "        if data.get(\"css\") is not None:",
            "            dashboard.css = data.get(\"css\")",
            "        if data.get(\"dashboard_title\") is not None:",
            "            dashboard.dashboard_title = data.get(\"dashboard_title\")",
            "",
            "        if new_filter_scopes:",
            "            md[\"filter_scopes\"] = new_filter_scopes",
            "        else:",
            "            md.pop(\"filter_scopes\", None)",
            "",
            "        md.setdefault(\"timed_refresh_immune_slices\", [])",
            "",
            "        if data.get(\"color_namespace\") is None:",
            "            md.pop(\"color_namespace\", None)",
            "        else:",
            "            md[\"color_namespace\"] = data.get(\"color_namespace\")",
            "",
            "        md[\"expanded_slices\"] = data.get(\"expanded_slices\", {})",
            "        md[\"refresh_frequency\"] = data.get(\"refresh_frequency\", 0)",
            "        md[\"color_scheme\"] = data.get(\"color_scheme\", \"\")",
            "        md[\"label_colors\"] = data.get(\"label_colors\", {})",
            "        md[\"shared_label_colors\"] = data.get(\"shared_label_colors\", {})",
            "        md[\"color_scheme_domain\"] = data.get(\"color_scheme_domain\", [])",
            "        md[\"cross_filters_enabled\"] = data.get(\"cross_filters_enabled\", True)",
            "        dashboard.json_metadata = json.dumps(md)",
            "",
            "        if commit:",
            "            db.session.commit()",
            "        return dashboard",
            "",
            "    @staticmethod",
            "    def favorited_ids(dashboards: List[Dashboard]) -> List[FavStar]:",
            "        ids = [dash.id for dash in dashboards]",
            "        return [",
            "            star.obj_id",
            "            for star in db.session.query(FavStar.obj_id)",
            "            .filter(",
            "                FavStar.class_name == FavStarClassName.DASHBOARD,",
            "                FavStar.obj_id.in_(ids),",
            "                FavStar.user_id == get_user_id(),",
            "            )",
            "            .all()",
            "        ]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "157": [
                "DashboardDAO"
            ],
            "158": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "159": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "160": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "161": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "162": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "163": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "164": [
                "DashboardDAO",
                "update_charts_owners"
            ],
            "165": [
                "DashboardDAO"
            ]
        },
        "addLocation": []
    }
}