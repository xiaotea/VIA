{
    "dummyserver/server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "     'certfile': os.path.join(CERTS_PATH, 'server.ipv6addr.crt'),"
            },
            "1": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "     'keyfile': os.path.join(CERTS_PATH, 'server.ipv6addr.key'),"
            },
            "2": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": " }"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+IPV6_SAN_CERTS = {"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+    'certfile': os.path.join(CERTS_PATH, 'server.ipv6_san.crt'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+    'keyfile': DEFAULT_CERTS['keyfile']"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+}"
            },
            "7": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 65,
                "PatchRowcode": " DEFAULT_CA = os.path.join(CERTS_PATH, 'cacert.pem')"
            },
            "8": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " DEFAULT_CA_BAD = os.path.join(CERTS_PATH, 'client_bad.pem')"
            },
            "9": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " NO_SAN_CA = os.path.join(CERTS_PATH, 'cacert.no_san.pem')"
            },
            "10": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 68,
                "PatchRowcode": " DEFAULT_CA_DIR = os.path.join(CERTS_PATH, 'ca_path_test')"
            },
            "11": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " IPV6_ADDR_CA = os.path.join(CERTS_PATH, 'server.ipv6addr.crt')"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+IPV6_SAN_CA = os.path.join(CERTS_PATH, 'server.ipv6_san.crt')"
            },
            "13": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 71,
                "PatchRowcode": " COMBINED_CERT_AND_KEY = os.path.join(CERTS_PATH, 'server.combined.pem')"
            },
            "14": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 72,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 73,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/env python",
            "",
            "\"\"\"",
            "Dummy server used for unit testing.",
            "\"\"\"",
            "from __future__ import print_function",
            "",
            "import errno",
            "import logging",
            "import os",
            "import random",
            "import string",
            "import sys",
            "import threading",
            "import socket",
            "import warnings",
            "import ssl",
            "from datetime import datetime",
            "",
            "from urllib3.exceptions import HTTPWarning",
            "",
            "from tornado.platform.auto import set_close_exec",
            "import tornado.httpserver",
            "import tornado.ioloop",
            "import tornado.web",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "CERTS_PATH = os.path.join(os.path.dirname(__file__), 'certs')",
            "DEFAULT_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.crt'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'server.key'),",
            "    'cert_reqs': ssl.CERT_OPTIONAL,",
            "    'ca_certs': os.path.join(CERTS_PATH, 'cacert.pem'),",
            "}",
            "DEFAULT_CLIENT_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'client_intermediate.pem'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'client_intermediate.key'),",
            "    'subject': dict(countryName=u'FI', stateOrProvinceName=u'dummy',",
            "                    organizationName=u'dummy', organizationalUnitName=u'dummy',",
            "                    commonName=u'SnakeOilClient',",
            "                    emailAddress=u'dummy@test.local'),",
            "}",
            "DEFAULT_CLIENT_NO_INTERMEDIATE_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'client_no_intermediate.pem'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'client_intermediate.key'),",
            "}",
            "NO_SAN_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.no_san.crt'),",
            "    'keyfile': DEFAULT_CERTS['keyfile']",
            "}",
            "IP_SAN_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.ip_san.crt'),",
            "    'keyfile': DEFAULT_CERTS['keyfile']",
            "}",
            "IPV6_ADDR_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.ipv6addr.crt'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'server.ipv6addr.key'),",
            "}",
            "DEFAULT_CA = os.path.join(CERTS_PATH, 'cacert.pem')",
            "DEFAULT_CA_BAD = os.path.join(CERTS_PATH, 'client_bad.pem')",
            "NO_SAN_CA = os.path.join(CERTS_PATH, 'cacert.no_san.pem')",
            "DEFAULT_CA_DIR = os.path.join(CERTS_PATH, 'ca_path_test')",
            "IPV6_ADDR_CA = os.path.join(CERTS_PATH, 'server.ipv6addr.crt')",
            "COMBINED_CERT_AND_KEY = os.path.join(CERTS_PATH, 'server.combined.pem')",
            "",
            "",
            "def _has_ipv6(host):",
            "    \"\"\" Returns True if the system can bind an IPv6 address. \"\"\"",
            "    sock = None",
            "    has_ipv6 = False",
            "",
            "    if socket.has_ipv6:",
            "        # has_ipv6 returns true if cPython was compiled with IPv6 support.",
            "        # It does not tell us if the system has IPv6 support enabled. To",
            "        # determine that we must bind to an IPv6 address.",
            "        # https://github.com/shazow/urllib3/pull/611",
            "        # https://bugs.python.org/issue658327",
            "        try:",
            "            sock = socket.socket(socket.AF_INET6)",
            "            sock.bind((host, 0))",
            "            has_ipv6 = True",
            "        except Exception:",
            "            pass",
            "",
            "    if sock:",
            "        sock.close()",
            "    return has_ipv6",
            "",
            "",
            "# Some systems may have IPv6 support but DNS may not be configured",
            "# properly. We can not count that localhost will resolve to ::1 on all",
            "# systems. See https://github.com/shazow/urllib3/pull/611 and",
            "# https://bugs.python.org/issue18792",
            "HAS_IPV6_AND_DNS = _has_ipv6('localhost')",
            "HAS_IPV6 = _has_ipv6('::1')",
            "",
            "",
            "# Different types of servers we have:",
            "",
            "",
            "class NoIPv6Warning(HTTPWarning):",
            "    \"IPv6 is not available\"",
            "    pass",
            "",
            "",
            "class SocketServerThread(threading.Thread):",
            "    \"\"\"",
            "    :param socket_handler: Callable which receives a socket argument for one",
            "        request.",
            "    :param ready_event: Event which gets set when the socket handler is",
            "        ready to receive requests.",
            "    \"\"\"",
            "    USE_IPV6 = HAS_IPV6_AND_DNS",
            "",
            "    def __init__(self, socket_handler, host='localhost', port=8081,",
            "                 ready_event=None):",
            "        threading.Thread.__init__(self)",
            "        self.daemon = True",
            "",
            "        self.socket_handler = socket_handler",
            "        self.host = host",
            "        self.ready_event = ready_event",
            "",
            "    def _start_server(self):",
            "        if self.USE_IPV6:",
            "            sock = socket.socket(socket.AF_INET6)",
            "        else:",
            "            warnings.warn(\"No IPv6 support. Falling back to IPv4.\",",
            "                          NoIPv6Warning)",
            "            sock = socket.socket(socket.AF_INET)",
            "        if sys.platform != 'win32':",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "        sock.bind((self.host, 0))",
            "        self.port = sock.getsockname()[1]",
            "",
            "        # Once listen() returns, the server socket is ready",
            "        sock.listen(1)",
            "",
            "        if self.ready_event:",
            "            self.ready_event.set()",
            "",
            "        self.socket_handler(sock)",
            "        sock.close()",
            "",
            "    def run(self):",
            "        self.server = self._start_server()",
            "",
            "",
            "# FIXME: there is a pull request patching bind_sockets in Tornado directly.",
            "# If it gets merged and released we can drop this and use",
            "# `tornado.netutil.bind_sockets` again.",
            "# https://github.com/facebook/tornado/pull/977",
            "",
            "def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=128,",
            "                 flags=None):",
            "    \"\"\"Creates listening sockets bound to the given port and address.",
            "",
            "    Returns a list of socket objects (multiple sockets are returned if",
            "    the given address maps to multiple IP addresses, which is most common",
            "    for mixed IPv4 and IPv6 use).",
            "",
            "    Address may be either an IP address or hostname.  If it's a hostname,",
            "    the server will listen on all IP addresses associated with the",
            "    name.  Address may be an empty string or None to listen on all",
            "    available interfaces.  Family may be set to either `socket.AF_INET`",
            "    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise",
            "    both will be used if available.",
            "",
            "    The ``backlog`` argument has the same meaning as for",
            "    `socket.listen() <socket.socket.listen>`.",
            "",
            "    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like",
            "    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.",
            "    \"\"\"",
            "    sockets = []",
            "    if address == \"\":",
            "        address = None",
            "    if not HAS_IPV6 and family == socket.AF_UNSPEC:",
            "        # Python can be compiled with --disable-ipv6, which causes",
            "        # operations on AF_INET6 sockets to fail, but does not",
            "        # automatically exclude those results from getaddrinfo",
            "        # results.",
            "        # http://bugs.python.org/issue16208",
            "        family = socket.AF_INET",
            "    if flags is None:",
            "        flags = socket.AI_PASSIVE",
            "    binded_port = None",
            "    for res in set(socket.getaddrinfo(address, port, family,",
            "                                      socket.SOCK_STREAM, 0, flags)):",
            "        af, socktype, proto, canonname, sockaddr = res",
            "        try:",
            "            sock = socket.socket(af, socktype, proto)",
            "        except socket.error as e:",
            "            if e.args[0] == errno.EAFNOSUPPORT:",
            "                continue",
            "            raise",
            "        set_close_exec(sock.fileno())",
            "        if os.name != 'nt':",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "        if af == socket.AF_INET6:",
            "            # On linux, ipv6 sockets accept ipv4 too by default,",
            "            # but this makes it impossible to bind to both",
            "            # 0.0.0.0 in ipv4 and :: in ipv6.  On other systems,",
            "            # separate sockets *must* be used to listen for both ipv4",
            "            # and ipv6.  For consistency, always disable ipv4 on our",
            "            # ipv6 sockets and use a separate ipv4 socket when needed.",
            "            #",
            "            # Python 2.x on windows doesn't have IPPROTO_IPV6.",
            "            if hasattr(socket, \"IPPROTO_IPV6\"):",
            "                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)",
            "",
            "        # automatic port allocation with port=None",
            "        # should bind on the same port on IPv4 and IPv6",
            "        host, requested_port = sockaddr[:2]",
            "        if requested_port == 0 and binded_port is not None:",
            "            sockaddr = tuple([host, binded_port] + list(sockaddr[2:]))",
            "",
            "        sock.setblocking(0)",
            "        sock.bind(sockaddr)",
            "        binded_port = sock.getsockname()[1]",
            "        sock.listen(backlog)",
            "        sockets.append(sock)",
            "    return sockets",
            "",
            "",
            "def run_tornado_app(app, io_loop, certs, scheme, host):",
            "    assert io_loop == tornado.ioloop.IOLoop.current()",
            "",
            "    # We can't use fromtimestamp(0) because of CPython issue 29097, so we'll",
            "    # just construct the datetime object directly.",
            "    app.last_req = datetime(1970, 1, 1)",
            "",
            "    if scheme == 'https':",
            "        http_server = tornado.httpserver.HTTPServer(app, ssl_options=certs)",
            "    else:",
            "        http_server = tornado.httpserver.HTTPServer(app)",
            "",
            "    sockets = bind_sockets(None, address=host)",
            "    port = sockets[0].getsockname()[1]",
            "    http_server.add_sockets(sockets)",
            "    return http_server, port",
            "",
            "",
            "def run_loop_in_thread(io_loop):",
            "    t = threading.Thread(target=io_loop.start)",
            "    t.start()",
            "    return t",
            "",
            "",
            "def get_unreachable_address():",
            "    while True:",
            "        host = ''.join(random.choice(string.ascii_lowercase)",
            "                       for _ in range(60))",
            "        sockaddr = (host, 54321)",
            "",
            "        # check if we are really \"lucky\" and hit an actual server",
            "        try:",
            "            s = socket.create_connection(sockaddr)",
            "        except socket.error:",
            "            return sockaddr",
            "        else:",
            "            s.close()",
            "",
            "",
            "if __name__ == '__main__':",
            "    # For debugging dummyserver itself - python -m dummyserver.server",
            "    from .testcase import TestingApp",
            "    host = '127.0.0.1'",
            "",
            "    io_loop = tornado.ioloop.IOLoop.current()",
            "    app = tornado.web.Application([(r\".*\", TestingApp)])",
            "    server, port = run_tornado_app(app, io_loop, None,",
            "                                   'http', host)",
            "    server_thread = run_loop_in_thread(io_loop)",
            "",
            "    print(\"Listening on http://{host}:{port}\".format(host=host, port=port))"
        ],
        "afterPatchFile": [
            "#!/usr/bin/env python",
            "",
            "\"\"\"",
            "Dummy server used for unit testing.",
            "\"\"\"",
            "from __future__ import print_function",
            "",
            "import errno",
            "import logging",
            "import os",
            "import random",
            "import string",
            "import sys",
            "import threading",
            "import socket",
            "import warnings",
            "import ssl",
            "from datetime import datetime",
            "",
            "from urllib3.exceptions import HTTPWarning",
            "",
            "from tornado.platform.auto import set_close_exec",
            "import tornado.httpserver",
            "import tornado.ioloop",
            "import tornado.web",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "CERTS_PATH = os.path.join(os.path.dirname(__file__), 'certs')",
            "DEFAULT_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.crt'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'server.key'),",
            "    'cert_reqs': ssl.CERT_OPTIONAL,",
            "    'ca_certs': os.path.join(CERTS_PATH, 'cacert.pem'),",
            "}",
            "DEFAULT_CLIENT_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'client_intermediate.pem'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'client_intermediate.key'),",
            "    'subject': dict(countryName=u'FI', stateOrProvinceName=u'dummy',",
            "                    organizationName=u'dummy', organizationalUnitName=u'dummy',",
            "                    commonName=u'SnakeOilClient',",
            "                    emailAddress=u'dummy@test.local'),",
            "}",
            "DEFAULT_CLIENT_NO_INTERMEDIATE_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'client_no_intermediate.pem'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'client_intermediate.key'),",
            "}",
            "NO_SAN_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.no_san.crt'),",
            "    'keyfile': DEFAULT_CERTS['keyfile']",
            "}",
            "IP_SAN_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.ip_san.crt'),",
            "    'keyfile': DEFAULT_CERTS['keyfile']",
            "}",
            "IPV6_ADDR_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.ipv6addr.crt'),",
            "    'keyfile': os.path.join(CERTS_PATH, 'server.ipv6addr.key'),",
            "}",
            "IPV6_SAN_CERTS = {",
            "    'certfile': os.path.join(CERTS_PATH, 'server.ipv6_san.crt'),",
            "    'keyfile': DEFAULT_CERTS['keyfile']",
            "}",
            "DEFAULT_CA = os.path.join(CERTS_PATH, 'cacert.pem')",
            "DEFAULT_CA_BAD = os.path.join(CERTS_PATH, 'client_bad.pem')",
            "NO_SAN_CA = os.path.join(CERTS_PATH, 'cacert.no_san.pem')",
            "DEFAULT_CA_DIR = os.path.join(CERTS_PATH, 'ca_path_test')",
            "IPV6_ADDR_CA = os.path.join(CERTS_PATH, 'server.ipv6addr.crt')",
            "IPV6_SAN_CA = os.path.join(CERTS_PATH, 'server.ipv6_san.crt')",
            "COMBINED_CERT_AND_KEY = os.path.join(CERTS_PATH, 'server.combined.pem')",
            "",
            "",
            "def _has_ipv6(host):",
            "    \"\"\" Returns True if the system can bind an IPv6 address. \"\"\"",
            "    sock = None",
            "    has_ipv6 = False",
            "",
            "    if socket.has_ipv6:",
            "        # has_ipv6 returns true if cPython was compiled with IPv6 support.",
            "        # It does not tell us if the system has IPv6 support enabled. To",
            "        # determine that we must bind to an IPv6 address.",
            "        # https://github.com/shazow/urllib3/pull/611",
            "        # https://bugs.python.org/issue658327",
            "        try:",
            "            sock = socket.socket(socket.AF_INET6)",
            "            sock.bind((host, 0))",
            "            has_ipv6 = True",
            "        except Exception:",
            "            pass",
            "",
            "    if sock:",
            "        sock.close()",
            "    return has_ipv6",
            "",
            "",
            "# Some systems may have IPv6 support but DNS may not be configured",
            "# properly. We can not count that localhost will resolve to ::1 on all",
            "# systems. See https://github.com/shazow/urllib3/pull/611 and",
            "# https://bugs.python.org/issue18792",
            "HAS_IPV6_AND_DNS = _has_ipv6('localhost')",
            "HAS_IPV6 = _has_ipv6('::1')",
            "",
            "",
            "# Different types of servers we have:",
            "",
            "",
            "class NoIPv6Warning(HTTPWarning):",
            "    \"IPv6 is not available\"",
            "    pass",
            "",
            "",
            "class SocketServerThread(threading.Thread):",
            "    \"\"\"",
            "    :param socket_handler: Callable which receives a socket argument for one",
            "        request.",
            "    :param ready_event: Event which gets set when the socket handler is",
            "        ready to receive requests.",
            "    \"\"\"",
            "    USE_IPV6 = HAS_IPV6_AND_DNS",
            "",
            "    def __init__(self, socket_handler, host='localhost', port=8081,",
            "                 ready_event=None):",
            "        threading.Thread.__init__(self)",
            "        self.daemon = True",
            "",
            "        self.socket_handler = socket_handler",
            "        self.host = host",
            "        self.ready_event = ready_event",
            "",
            "    def _start_server(self):",
            "        if self.USE_IPV6:",
            "            sock = socket.socket(socket.AF_INET6)",
            "        else:",
            "            warnings.warn(\"No IPv6 support. Falling back to IPv4.\",",
            "                          NoIPv6Warning)",
            "            sock = socket.socket(socket.AF_INET)",
            "        if sys.platform != 'win32':",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "        sock.bind((self.host, 0))",
            "        self.port = sock.getsockname()[1]",
            "",
            "        # Once listen() returns, the server socket is ready",
            "        sock.listen(1)",
            "",
            "        if self.ready_event:",
            "            self.ready_event.set()",
            "",
            "        self.socket_handler(sock)",
            "        sock.close()",
            "",
            "    def run(self):",
            "        self.server = self._start_server()",
            "",
            "",
            "# FIXME: there is a pull request patching bind_sockets in Tornado directly.",
            "# If it gets merged and released we can drop this and use",
            "# `tornado.netutil.bind_sockets` again.",
            "# https://github.com/facebook/tornado/pull/977",
            "",
            "def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=128,",
            "                 flags=None):",
            "    \"\"\"Creates listening sockets bound to the given port and address.",
            "",
            "    Returns a list of socket objects (multiple sockets are returned if",
            "    the given address maps to multiple IP addresses, which is most common",
            "    for mixed IPv4 and IPv6 use).",
            "",
            "    Address may be either an IP address or hostname.  If it's a hostname,",
            "    the server will listen on all IP addresses associated with the",
            "    name.  Address may be an empty string or None to listen on all",
            "    available interfaces.  Family may be set to either `socket.AF_INET`",
            "    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise",
            "    both will be used if available.",
            "",
            "    The ``backlog`` argument has the same meaning as for",
            "    `socket.listen() <socket.socket.listen>`.",
            "",
            "    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like",
            "    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.",
            "    \"\"\"",
            "    sockets = []",
            "    if address == \"\":",
            "        address = None",
            "    if not HAS_IPV6 and family == socket.AF_UNSPEC:",
            "        # Python can be compiled with --disable-ipv6, which causes",
            "        # operations on AF_INET6 sockets to fail, but does not",
            "        # automatically exclude those results from getaddrinfo",
            "        # results.",
            "        # http://bugs.python.org/issue16208",
            "        family = socket.AF_INET",
            "    if flags is None:",
            "        flags = socket.AI_PASSIVE",
            "    binded_port = None",
            "    for res in set(socket.getaddrinfo(address, port, family,",
            "                                      socket.SOCK_STREAM, 0, flags)):",
            "        af, socktype, proto, canonname, sockaddr = res",
            "        try:",
            "            sock = socket.socket(af, socktype, proto)",
            "        except socket.error as e:",
            "            if e.args[0] == errno.EAFNOSUPPORT:",
            "                continue",
            "            raise",
            "        set_close_exec(sock.fileno())",
            "        if os.name != 'nt':",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "        if af == socket.AF_INET6:",
            "            # On linux, ipv6 sockets accept ipv4 too by default,",
            "            # but this makes it impossible to bind to both",
            "            # 0.0.0.0 in ipv4 and :: in ipv6.  On other systems,",
            "            # separate sockets *must* be used to listen for both ipv4",
            "            # and ipv6.  For consistency, always disable ipv4 on our",
            "            # ipv6 sockets and use a separate ipv4 socket when needed.",
            "            #",
            "            # Python 2.x on windows doesn't have IPPROTO_IPV6.",
            "            if hasattr(socket, \"IPPROTO_IPV6\"):",
            "                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)",
            "",
            "        # automatic port allocation with port=None",
            "        # should bind on the same port on IPv4 and IPv6",
            "        host, requested_port = sockaddr[:2]",
            "        if requested_port == 0 and binded_port is not None:",
            "            sockaddr = tuple([host, binded_port] + list(sockaddr[2:]))",
            "",
            "        sock.setblocking(0)",
            "        sock.bind(sockaddr)",
            "        binded_port = sock.getsockname()[1]",
            "        sock.listen(backlog)",
            "        sockets.append(sock)",
            "    return sockets",
            "",
            "",
            "def run_tornado_app(app, io_loop, certs, scheme, host):",
            "    assert io_loop == tornado.ioloop.IOLoop.current()",
            "",
            "    # We can't use fromtimestamp(0) because of CPython issue 29097, so we'll",
            "    # just construct the datetime object directly.",
            "    app.last_req = datetime(1970, 1, 1)",
            "",
            "    if scheme == 'https':",
            "        http_server = tornado.httpserver.HTTPServer(app, ssl_options=certs)",
            "    else:",
            "        http_server = tornado.httpserver.HTTPServer(app)",
            "",
            "    sockets = bind_sockets(None, address=host)",
            "    port = sockets[0].getsockname()[1]",
            "    http_server.add_sockets(sockets)",
            "    return http_server, port",
            "",
            "",
            "def run_loop_in_thread(io_loop):",
            "    t = threading.Thread(target=io_loop.start)",
            "    t.start()",
            "    return t",
            "",
            "",
            "def get_unreachable_address():",
            "    while True:",
            "        host = ''.join(random.choice(string.ascii_lowercase)",
            "                       for _ in range(60))",
            "        sockaddr = (host, 54321)",
            "",
            "        # check if we are really \"lucky\" and hit an actual server",
            "        try:",
            "            s = socket.create_connection(sockaddr)",
            "        except socket.error:",
            "            return sockaddr",
            "        else:",
            "            s.close()",
            "",
            "",
            "if __name__ == '__main__':",
            "    # For debugging dummyserver itself - python -m dummyserver.server",
            "    from .testcase import TestingApp",
            "    host = '127.0.0.1'",
            "",
            "    io_loop = tornado.ioloop.IOLoop.current()",
            "    app = tornado.web.Application([(r\".*\", TestingApp)])",
            "    server, port = run_tornado_app(app, io_loop, None,",
            "                                   'http', host)",
            "    server_thread = run_loop_in_thread(io_loop)",
            "",
            "    print(\"Listening on http://{host}:{port}\".format(host=host, port=port))"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    },
    "src/urllib3/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " __author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'"
            },
            "2": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " __license__ = 'MIT'"
            },
            "3": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-__version__ = '1.24.1'"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+__version__ = '1.24.2'"
            },
            "5": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " __all__ = ("
            },
            "7": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "     'HTTPConnectionPool',"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "urllib3 - Thread-safe connection pooling and re-using.",
            "\"\"\"",
            "",
            "from __future__ import absolute_import",
            "import warnings",
            "",
            "from .connectionpool import (",
            "    HTTPConnectionPool,",
            "    HTTPSConnectionPool,",
            "    connection_from_url",
            ")",
            "",
            "from . import exceptions",
            "from .filepost import encode_multipart_formdata",
            "from .poolmanager import PoolManager, ProxyManager, proxy_from_url",
            "from .response import HTTPResponse",
            "from .util.request import make_headers",
            "from .util.url import get_host",
            "from .util.timeout import Timeout",
            "from .util.retry import Retry",
            "",
            "",
            "# Set default logging handler to avoid \"No handler found\" warnings.",
            "import logging",
            "from logging import NullHandler",
            "",
            "__author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'",
            "__license__ = 'MIT'",
            "__version__ = '1.24.1'",
            "",
            "__all__ = (",
            "    'HTTPConnectionPool',",
            "    'HTTPSConnectionPool',",
            "    'PoolManager',",
            "    'ProxyManager',",
            "    'HTTPResponse',",
            "    'Retry',",
            "    'Timeout',",
            "    'add_stderr_logger',",
            "    'connection_from_url',",
            "    'disable_warnings',",
            "    'encode_multipart_formdata',",
            "    'get_host',",
            "    'make_headers',",
            "    'proxy_from_url',",
            ")",
            "",
            "logging.getLogger(__name__).addHandler(NullHandler())",
            "",
            "",
            "def add_stderr_logger(level=logging.DEBUG):",
            "    \"\"\"",
            "    Helper for quickly adding a StreamHandler to the logger. Useful for",
            "    debugging.",
            "",
            "    Returns the handler after adding it.",
            "    \"\"\"",
            "    # This method needs to be in this __init__.py to get the __name__ correct",
            "    # even if urllib3 is vendored within another package.",
            "    logger = logging.getLogger(__name__)",
            "    handler = logging.StreamHandler()",
            "    handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))",
            "    logger.addHandler(handler)",
            "    logger.setLevel(level)",
            "    logger.debug('Added a stderr logging handler to logger: %s', __name__)",
            "    return handler",
            "",
            "",
            "# ... Clean up.",
            "del NullHandler",
            "",
            "",
            "# All warning filters *must* be appended unless you're really certain that they",
            "# shouldn't be: otherwise, it's very hard for users to use most Python",
            "# mechanisms to silence them.",
            "# SecurityWarning's always go off by default.",
            "warnings.simplefilter('always', exceptions.SecurityWarning, append=True)",
            "# SubjectAltNameWarning's should go off once per host",
            "warnings.simplefilter('default', exceptions.SubjectAltNameWarning, append=True)",
            "# InsecurePlatformWarning's don't vary between requests, so we keep it default.",
            "warnings.simplefilter('default', exceptions.InsecurePlatformWarning,",
            "                      append=True)",
            "# SNIMissingWarnings should go off only once.",
            "warnings.simplefilter('default', exceptions.SNIMissingWarning, append=True)",
            "",
            "",
            "def disable_warnings(category=exceptions.HTTPWarning):",
            "    \"\"\"",
            "    Helper for quickly disabling all urllib3 warnings.",
            "    \"\"\"",
            "    warnings.simplefilter('ignore', category)"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "urllib3 - Thread-safe connection pooling and re-using.",
            "\"\"\"",
            "",
            "from __future__ import absolute_import",
            "import warnings",
            "",
            "from .connectionpool import (",
            "    HTTPConnectionPool,",
            "    HTTPSConnectionPool,",
            "    connection_from_url",
            ")",
            "",
            "from . import exceptions",
            "from .filepost import encode_multipart_formdata",
            "from .poolmanager import PoolManager, ProxyManager, proxy_from_url",
            "from .response import HTTPResponse",
            "from .util.request import make_headers",
            "from .util.url import get_host",
            "from .util.timeout import Timeout",
            "from .util.retry import Retry",
            "",
            "",
            "# Set default logging handler to avoid \"No handler found\" warnings.",
            "import logging",
            "from logging import NullHandler",
            "",
            "__author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'",
            "__license__ = 'MIT'",
            "__version__ = '1.24.2'",
            "",
            "__all__ = (",
            "    'HTTPConnectionPool',",
            "    'HTTPSConnectionPool',",
            "    'PoolManager',",
            "    'ProxyManager',",
            "    'HTTPResponse',",
            "    'Retry',",
            "    'Timeout',",
            "    'add_stderr_logger',",
            "    'connection_from_url',",
            "    'disable_warnings',",
            "    'encode_multipart_formdata',",
            "    'get_host',",
            "    'make_headers',",
            "    'proxy_from_url',",
            ")",
            "",
            "logging.getLogger(__name__).addHandler(NullHandler())",
            "",
            "",
            "def add_stderr_logger(level=logging.DEBUG):",
            "    \"\"\"",
            "    Helper for quickly adding a StreamHandler to the logger. Useful for",
            "    debugging.",
            "",
            "    Returns the handler after adding it.",
            "    \"\"\"",
            "    # This method needs to be in this __init__.py to get the __name__ correct",
            "    # even if urllib3 is vendored within another package.",
            "    logger = logging.getLogger(__name__)",
            "    handler = logging.StreamHandler()",
            "    handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))",
            "    logger.addHandler(handler)",
            "    logger.setLevel(level)",
            "    logger.debug('Added a stderr logging handler to logger: %s', __name__)",
            "    return handler",
            "",
            "",
            "# ... Clean up.",
            "del NullHandler",
            "",
            "",
            "# All warning filters *must* be appended unless you're really certain that they",
            "# shouldn't be: otherwise, it's very hard for users to use most Python",
            "# mechanisms to silence them.",
            "# SecurityWarning's always go off by default.",
            "warnings.simplefilter('always', exceptions.SecurityWarning, append=True)",
            "# SubjectAltNameWarning's should go off once per host",
            "warnings.simplefilter('default', exceptions.SubjectAltNameWarning, append=True)",
            "# InsecurePlatformWarning's don't vary between requests, so we keep it default.",
            "warnings.simplefilter('default', exceptions.InsecurePlatformWarning,",
            "                      append=True)",
            "# SNIMissingWarnings should go off only once.",
            "warnings.simplefilter('default', exceptions.SNIMissingWarning, append=True)",
            "",
            "",
            "def disable_warnings(category=exceptions.HTTPWarning):",
            "    \"\"\"",
            "    Helper for quickly disabling all urllib3 warnings.",
            "    \"\"\"",
            "    warnings.simplefilter('ignore', category)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "30": [
                "__version__"
            ]
        },
        "addLocation": []
    },
    "src/urllib3/contrib/pyopenssl.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "         except idna.core.IDNAError:"
            },
            "1": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "             return None"
            },
            "2": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 186,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 187,
                "PatchRowcode": "+    if ':' in name:"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 188,
                "PatchRowcode": "+        return name"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 190,
                "PatchRowcode": "     name = idna_encode(name)"
            },
            "7": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "     if name is None:"
            },
            "8": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "         return None"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "SSL with SNI_-support for Python 2. Follow these instructions if you would",
            "like to verify SSL certificates in Python 2. Note, the default libraries do",
            "*not* do certificate checking; you need to do additional work to validate",
            "certificates yourself.",
            "",
            "This needs the following packages installed:",
            "",
            "* pyOpenSSL (tested with 16.0.0)",
            "* cryptography (minimum 1.3.4, from pyopenssl)",
            "* idna (minimum 2.0, from cryptography)",
            "",
            "However, pyopenssl depends on cryptography, which depends on idna, so while we",
            "use all three directly here we end up having relatively few packages required.",
            "",
            "You can install them with the following command:",
            "",
            "    pip install pyopenssl cryptography idna",
            "",
            "To activate certificate checking, call",
            ":func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code",
            "before you begin making HTTP requests. This can be done in a ``sitecustomize``",
            "module, or at any other time before your application begins using ``urllib3``,",
            "like this::",
            "",
            "    try:",
            "        import urllib3.contrib.pyopenssl",
            "        urllib3.contrib.pyopenssl.inject_into_urllib3()",
            "    except ImportError:",
            "        pass",
            "",
            "Now you can use :mod:`urllib3` as you normally would, and it will support SNI",
            "when the required modules are installed.",
            "",
            "Activating this module also has the positive side effect of disabling SSL/TLS",
            "compression in Python 2 (see `CRIME attack`_).",
            "",
            "If you want to configure the default list of supported cipher suites, you can",
            "set the ``urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST`` variable.",
            "",
            ".. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication",
            ".. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)",
            "\"\"\"",
            "from __future__ import absolute_import",
            "",
            "import OpenSSL.SSL",
            "from cryptography import x509",
            "from cryptography.hazmat.backends.openssl import backend as openssl_backend",
            "from cryptography.hazmat.backends.openssl.x509 import _Certificate",
            "try:",
            "    from cryptography.x509 import UnsupportedExtension",
            "except ImportError:",
            "    # UnsupportedExtension is gone in cryptography >= 2.1.0",
            "    class UnsupportedExtension(Exception):",
            "        pass",
            "",
            "from socket import timeout, error as SocketError",
            "from io import BytesIO",
            "",
            "try:  # Platform-specific: Python 2",
            "    from socket import _fileobject",
            "except ImportError:  # Platform-specific: Python 3",
            "    _fileobject = None",
            "    from ..packages.backports.makefile import backport_makefile",
            "",
            "import logging",
            "import ssl",
            "from ..packages import six",
            "import sys",
            "",
            "from .. import util",
            "",
            "__all__ = ['inject_into_urllib3', 'extract_from_urllib3']",
            "",
            "# SNI always works.",
            "HAS_SNI = True",
            "",
            "# Map from urllib3 to PyOpenSSL compatible parameter-values.",
            "_openssl_versions = {",
            "    ssl.PROTOCOL_SSLv23: OpenSSL.SSL.SSLv23_METHOD,",
            "    ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,",
            "}",
            "",
            "if hasattr(ssl, 'PROTOCOL_TLSv1_1') and hasattr(OpenSSL.SSL, 'TLSv1_1_METHOD'):",
            "    _openssl_versions[ssl.PROTOCOL_TLSv1_1] = OpenSSL.SSL.TLSv1_1_METHOD",
            "",
            "if hasattr(ssl, 'PROTOCOL_TLSv1_2') and hasattr(OpenSSL.SSL, 'TLSv1_2_METHOD'):",
            "    _openssl_versions[ssl.PROTOCOL_TLSv1_2] = OpenSSL.SSL.TLSv1_2_METHOD",
            "",
            "try:",
            "    _openssl_versions.update({ssl.PROTOCOL_SSLv3: OpenSSL.SSL.SSLv3_METHOD})",
            "except AttributeError:",
            "    pass",
            "",
            "_stdlib_to_openssl_verify = {",
            "    ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,",
            "    ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,",
            "    ssl.CERT_REQUIRED:",
            "        OpenSSL.SSL.VERIFY_PEER + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,",
            "}",
            "_openssl_to_stdlib_verify = dict(",
            "    (v, k) for k, v in _stdlib_to_openssl_verify.items()",
            ")",
            "",
            "# OpenSSL will only write 16K at a time",
            "SSL_WRITE_BLOCKSIZE = 16384",
            "",
            "orig_util_HAS_SNI = util.HAS_SNI",
            "orig_util_SSLContext = util.ssl_.SSLContext",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def inject_into_urllib3():",
            "    'Monkey-patch urllib3 with PyOpenSSL-backed SSL-support.'",
            "",
            "    _validate_dependencies_met()",
            "",
            "    util.ssl_.SSLContext = PyOpenSSLContext",
            "    util.HAS_SNI = HAS_SNI",
            "    util.ssl_.HAS_SNI = HAS_SNI",
            "    util.IS_PYOPENSSL = True",
            "    util.ssl_.IS_PYOPENSSL = True",
            "",
            "",
            "def extract_from_urllib3():",
            "    'Undo monkey-patching by :func:`inject_into_urllib3`.'",
            "",
            "    util.ssl_.SSLContext = orig_util_SSLContext",
            "    util.HAS_SNI = orig_util_HAS_SNI",
            "    util.ssl_.HAS_SNI = orig_util_HAS_SNI",
            "    util.IS_PYOPENSSL = False",
            "    util.ssl_.IS_PYOPENSSL = False",
            "",
            "",
            "def _validate_dependencies_met():",
            "    \"\"\"",
            "    Verifies that PyOpenSSL's package-level dependencies have been met.",
            "    Throws `ImportError` if they are not met.",
            "    \"\"\"",
            "    # Method added in `cryptography==1.1`; not available in older versions",
            "    from cryptography.x509.extensions import Extensions",
            "    if getattr(Extensions, \"get_extension_for_class\", None) is None:",
            "        raise ImportError(\"'cryptography' module missing required functionality.  \"",
            "                          \"Try upgrading to v1.3.4 or newer.\")",
            "",
            "    # pyOpenSSL 0.14 and above use cryptography for OpenSSL bindings. The _x509",
            "    # attribute is only present on those versions.",
            "    from OpenSSL.crypto import X509",
            "    x509 = X509()",
            "    if getattr(x509, \"_x509\", None) is None:",
            "        raise ImportError(\"'pyOpenSSL' module missing required functionality. \"",
            "                          \"Try upgrading to v0.14 or newer.\")",
            "",
            "",
            "def _dnsname_to_stdlib(name):",
            "    \"\"\"",
            "    Converts a dNSName SubjectAlternativeName field to the form used by the",
            "    standard library on the given Python version.",
            "",
            "    Cryptography produces a dNSName as a unicode string that was idna-decoded",
            "    from ASCII bytes. We need to idna-encode that string to get it back, and",
            "    then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib",
            "    uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).",
            "",
            "    If the name cannot be idna-encoded then we return None signalling that",
            "    the name given should be skipped.",
            "    \"\"\"",
            "    def idna_encode(name):",
            "        \"\"\"",
            "        Borrowed wholesale from the Python Cryptography Project. It turns out",
            "        that we can't just safely call `idna.encode`: it can explode for",
            "        wildcard names. This avoids that problem.",
            "        \"\"\"",
            "        import idna",
            "",
            "        try:",
            "            for prefix in [u'*.', u'.']:",
            "                if name.startswith(prefix):",
            "                    name = name[len(prefix):]",
            "                    return prefix.encode('ascii') + idna.encode(name)",
            "            return idna.encode(name)",
            "        except idna.core.IDNAError:",
            "            return None",
            "",
            "    name = idna_encode(name)",
            "    if name is None:",
            "        return None",
            "    elif sys.version_info >= (3, 0):",
            "        name = name.decode('utf-8')",
            "    return name",
            "",
            "",
            "def get_subj_alt_name(peer_cert):",
            "    \"\"\"",
            "    Given an PyOpenSSL certificate, provides all the subject alternative names.",
            "    \"\"\"",
            "    # Pass the cert to cryptography, which has much better APIs for this.",
            "    if hasattr(peer_cert, \"to_cryptography\"):",
            "        cert = peer_cert.to_cryptography()",
            "    else:",
            "        # This is technically using private APIs, but should work across all",
            "        # relevant versions before PyOpenSSL got a proper API for this.",
            "        cert = _Certificate(openssl_backend, peer_cert._x509)",
            "",
            "    # We want to find the SAN extension. Ask Cryptography to locate it (it's",
            "    # faster than looping in Python)",
            "    try:",
            "        ext = cert.extensions.get_extension_for_class(",
            "            x509.SubjectAlternativeName",
            "        ).value",
            "    except x509.ExtensionNotFound:",
            "        # No such extension, return the empty list.",
            "        return []",
            "    except (x509.DuplicateExtension, UnsupportedExtension,",
            "            x509.UnsupportedGeneralNameType, UnicodeError) as e:",
            "        # A problem has been found with the quality of the certificate. Assume",
            "        # no SAN field is present.",
            "        log.warning(",
            "            \"A problem was encountered with the certificate that prevented \"",
            "            \"urllib3 from finding the SubjectAlternativeName field. This can \"",
            "            \"affect certificate validation. The error was %s\",",
            "            e,",
            "        )",
            "        return []",
            "",
            "    # We want to return dNSName and iPAddress fields. We need to cast the IPs",
            "    # back to strings because the match_hostname function wants them as",
            "    # strings.",
            "    # Sadly the DNS names need to be idna encoded and then, on Python 3, UTF-8",
            "    # decoded. This is pretty frustrating, but that's what the standard library",
            "    # does with certificates, and so we need to attempt to do the same.",
            "    # We also want to skip over names which cannot be idna encoded.",
            "    names = [",
            "        ('DNS', name) for name in map(_dnsname_to_stdlib, ext.get_values_for_type(x509.DNSName))",
            "        if name is not None",
            "    ]",
            "    names.extend(",
            "        ('IP Address', str(name))",
            "        for name in ext.get_values_for_type(x509.IPAddress)",
            "    )",
            "",
            "    return names",
            "",
            "",
            "class WrappedSocket(object):",
            "    '''API-compatibility wrapper for Python OpenSSL's Connection-class.",
            "",
            "    Note: _makefile_refs, _drop() and _reuse() are needed for the garbage",
            "    collector of pypy.",
            "    '''",
            "",
            "    def __init__(self, connection, socket, suppress_ragged_eofs=True):",
            "        self.connection = connection",
            "        self.socket = socket",
            "        self.suppress_ragged_eofs = suppress_ragged_eofs",
            "        self._makefile_refs = 0",
            "        self._closed = False",
            "",
            "    def fileno(self):",
            "        return self.socket.fileno()",
            "",
            "    # Copy-pasted from Python 3.5 source code",
            "    def _decref_socketios(self):",
            "        if self._makefile_refs > 0:",
            "            self._makefile_refs -= 1",
            "        if self._closed:",
            "            self.close()",
            "",
            "    def recv(self, *args, **kwargs):",
            "        try:",
            "            data = self.connection.recv(*args, **kwargs)",
            "        except OpenSSL.SSL.SysCallError as e:",
            "            if self.suppress_ragged_eofs and e.args == (-1, 'Unexpected EOF'):",
            "                return b''",
            "            else:",
            "                raise SocketError(str(e))",
            "        except OpenSSL.SSL.ZeroReturnError as e:",
            "            if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:",
            "                return b''",
            "            else:",
            "                raise",
            "        except OpenSSL.SSL.WantReadError:",
            "            if not util.wait_for_read(self.socket, self.socket.gettimeout()):",
            "                raise timeout('The read operation timed out')",
            "            else:",
            "                return self.recv(*args, **kwargs)",
            "        else:",
            "            return data",
            "",
            "    def recv_into(self, *args, **kwargs):",
            "        try:",
            "            return self.connection.recv_into(*args, **kwargs)",
            "        except OpenSSL.SSL.SysCallError as e:",
            "            if self.suppress_ragged_eofs and e.args == (-1, 'Unexpected EOF'):",
            "                return 0",
            "            else:",
            "                raise SocketError(str(e))",
            "        except OpenSSL.SSL.ZeroReturnError as e:",
            "            if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:",
            "                return 0",
            "            else:",
            "                raise",
            "        except OpenSSL.SSL.WantReadError:",
            "            if not util.wait_for_read(self.socket, self.socket.gettimeout()):",
            "                raise timeout('The read operation timed out')",
            "            else:",
            "                return self.recv_into(*args, **kwargs)",
            "",
            "    def settimeout(self, timeout):",
            "        return self.socket.settimeout(timeout)",
            "",
            "    def _send_until_done(self, data):",
            "        while True:",
            "            try:",
            "                return self.connection.send(data)",
            "            except OpenSSL.SSL.WantWriteError:",
            "                if not util.wait_for_write(self.socket, self.socket.gettimeout()):",
            "                    raise timeout()",
            "                continue",
            "            except OpenSSL.SSL.SysCallError as e:",
            "                raise SocketError(str(e))",
            "",
            "    def sendall(self, data):",
            "        total_sent = 0",
            "        while total_sent < len(data):",
            "            sent = self._send_until_done(data[total_sent:total_sent + SSL_WRITE_BLOCKSIZE])",
            "            total_sent += sent",
            "",
            "    def shutdown(self):",
            "        # FIXME rethrow compatible exceptions should we ever use this",
            "        self.connection.shutdown()",
            "",
            "    def close(self):",
            "        if self._makefile_refs < 1:",
            "            try:",
            "                self._closed = True",
            "                return self.connection.close()",
            "            except OpenSSL.SSL.Error:",
            "                return",
            "        else:",
            "            self._makefile_refs -= 1",
            "",
            "    def getpeercert(self, binary_form=False):",
            "        x509 = self.connection.get_peer_certificate()",
            "",
            "        if not x509:",
            "            return x509",
            "",
            "        if binary_form:",
            "            return OpenSSL.crypto.dump_certificate(",
            "                OpenSSL.crypto.FILETYPE_ASN1,",
            "                x509)",
            "",
            "        return {",
            "            'subject': (",
            "                (('commonName', x509.get_subject().CN),),",
            "            ),",
            "            'subjectAltName': get_subj_alt_name(x509)",
            "        }",
            "",
            "    def _reuse(self):",
            "        self._makefile_refs += 1",
            "",
            "    def _drop(self):",
            "        if self._makefile_refs < 1:",
            "            self.close()",
            "        else:",
            "            self._makefile_refs -= 1",
            "",
            "",
            "if _fileobject:  # Platform-specific: Python 2",
            "    def makefile(self, mode, bufsize=-1):",
            "        self._makefile_refs += 1",
            "        return _fileobject(self, mode, bufsize, close=True)",
            "else:  # Platform-specific: Python 3",
            "    makefile = backport_makefile",
            "",
            "WrappedSocket.makefile = makefile",
            "",
            "",
            "class PyOpenSSLContext(object):",
            "    \"\"\"",
            "    I am a wrapper class for the PyOpenSSL ``Context`` object. I am responsible",
            "    for translating the interface of the standard library ``SSLContext`` object",
            "    to calls into PyOpenSSL.",
            "    \"\"\"",
            "    def __init__(self, protocol):",
            "        self.protocol = _openssl_versions[protocol]",
            "        self._ctx = OpenSSL.SSL.Context(self.protocol)",
            "        self._options = 0",
            "        self.check_hostname = False",
            "",
            "    @property",
            "    def options(self):",
            "        return self._options",
            "",
            "    @options.setter",
            "    def options(self, value):",
            "        self._options = value",
            "        self._ctx.set_options(value)",
            "",
            "    @property",
            "    def verify_mode(self):",
            "        return _openssl_to_stdlib_verify[self._ctx.get_verify_mode()]",
            "",
            "    @verify_mode.setter",
            "    def verify_mode(self, value):",
            "        self._ctx.set_verify(",
            "            _stdlib_to_openssl_verify[value],",
            "            _verify_callback",
            "        )",
            "",
            "    def set_default_verify_paths(self):",
            "        self._ctx.set_default_verify_paths()",
            "",
            "    def set_ciphers(self, ciphers):",
            "        if isinstance(ciphers, six.text_type):",
            "            ciphers = ciphers.encode('utf-8')",
            "        self._ctx.set_cipher_list(ciphers)",
            "",
            "    def load_verify_locations(self, cafile=None, capath=None, cadata=None):",
            "        if cafile is not None:",
            "            cafile = cafile.encode('utf-8')",
            "        if capath is not None:",
            "            capath = capath.encode('utf-8')",
            "        self._ctx.load_verify_locations(cafile, capath)",
            "        if cadata is not None:",
            "            self._ctx.load_verify_locations(BytesIO(cadata))",
            "",
            "    def load_cert_chain(self, certfile, keyfile=None, password=None):",
            "        self._ctx.use_certificate_chain_file(certfile)",
            "        if password is not None:",
            "            self._ctx.set_passwd_cb(lambda max_length, prompt_twice, userdata: password)",
            "        self._ctx.use_privatekey_file(keyfile or certfile)",
            "",
            "    def wrap_socket(self, sock, server_side=False,",
            "                    do_handshake_on_connect=True, suppress_ragged_eofs=True,",
            "                    server_hostname=None):",
            "        cnx = OpenSSL.SSL.Connection(self._ctx, sock)",
            "",
            "        if isinstance(server_hostname, six.text_type):  # Platform-specific: Python 3",
            "            server_hostname = server_hostname.encode('utf-8')",
            "",
            "        if server_hostname is not None:",
            "            cnx.set_tlsext_host_name(server_hostname)",
            "",
            "        cnx.set_connect_state()",
            "",
            "        while True:",
            "            try:",
            "                cnx.do_handshake()",
            "            except OpenSSL.SSL.WantReadError:",
            "                if not util.wait_for_read(sock, sock.gettimeout()):",
            "                    raise timeout('select timed out')",
            "                continue",
            "            except OpenSSL.SSL.Error as e:",
            "                raise ssl.SSLError('bad handshake: %r' % e)",
            "            break",
            "",
            "        return WrappedSocket(cnx, sock)",
            "",
            "",
            "def _verify_callback(cnx, x509, err_no, err_depth, return_code):",
            "    return err_no == 0"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "SSL with SNI_-support for Python 2. Follow these instructions if you would",
            "like to verify SSL certificates in Python 2. Note, the default libraries do",
            "*not* do certificate checking; you need to do additional work to validate",
            "certificates yourself.",
            "",
            "This needs the following packages installed:",
            "",
            "* pyOpenSSL (tested with 16.0.0)",
            "* cryptography (minimum 1.3.4, from pyopenssl)",
            "* idna (minimum 2.0, from cryptography)",
            "",
            "However, pyopenssl depends on cryptography, which depends on idna, so while we",
            "use all three directly here we end up having relatively few packages required.",
            "",
            "You can install them with the following command:",
            "",
            "    pip install pyopenssl cryptography idna",
            "",
            "To activate certificate checking, call",
            ":func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code",
            "before you begin making HTTP requests. This can be done in a ``sitecustomize``",
            "module, or at any other time before your application begins using ``urllib3``,",
            "like this::",
            "",
            "    try:",
            "        import urllib3.contrib.pyopenssl",
            "        urllib3.contrib.pyopenssl.inject_into_urllib3()",
            "    except ImportError:",
            "        pass",
            "",
            "Now you can use :mod:`urllib3` as you normally would, and it will support SNI",
            "when the required modules are installed.",
            "",
            "Activating this module also has the positive side effect of disabling SSL/TLS",
            "compression in Python 2 (see `CRIME attack`_).",
            "",
            "If you want to configure the default list of supported cipher suites, you can",
            "set the ``urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST`` variable.",
            "",
            ".. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication",
            ".. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)",
            "\"\"\"",
            "from __future__ import absolute_import",
            "",
            "import OpenSSL.SSL",
            "from cryptography import x509",
            "from cryptography.hazmat.backends.openssl import backend as openssl_backend",
            "from cryptography.hazmat.backends.openssl.x509 import _Certificate",
            "try:",
            "    from cryptography.x509 import UnsupportedExtension",
            "except ImportError:",
            "    # UnsupportedExtension is gone in cryptography >= 2.1.0",
            "    class UnsupportedExtension(Exception):",
            "        pass",
            "",
            "from socket import timeout, error as SocketError",
            "from io import BytesIO",
            "",
            "try:  # Platform-specific: Python 2",
            "    from socket import _fileobject",
            "except ImportError:  # Platform-specific: Python 3",
            "    _fileobject = None",
            "    from ..packages.backports.makefile import backport_makefile",
            "",
            "import logging",
            "import ssl",
            "from ..packages import six",
            "import sys",
            "",
            "from .. import util",
            "",
            "__all__ = ['inject_into_urllib3', 'extract_from_urllib3']",
            "",
            "# SNI always works.",
            "HAS_SNI = True",
            "",
            "# Map from urllib3 to PyOpenSSL compatible parameter-values.",
            "_openssl_versions = {",
            "    ssl.PROTOCOL_SSLv23: OpenSSL.SSL.SSLv23_METHOD,",
            "    ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,",
            "}",
            "",
            "if hasattr(ssl, 'PROTOCOL_TLSv1_1') and hasattr(OpenSSL.SSL, 'TLSv1_1_METHOD'):",
            "    _openssl_versions[ssl.PROTOCOL_TLSv1_1] = OpenSSL.SSL.TLSv1_1_METHOD",
            "",
            "if hasattr(ssl, 'PROTOCOL_TLSv1_2') and hasattr(OpenSSL.SSL, 'TLSv1_2_METHOD'):",
            "    _openssl_versions[ssl.PROTOCOL_TLSv1_2] = OpenSSL.SSL.TLSv1_2_METHOD",
            "",
            "try:",
            "    _openssl_versions.update({ssl.PROTOCOL_SSLv3: OpenSSL.SSL.SSLv3_METHOD})",
            "except AttributeError:",
            "    pass",
            "",
            "_stdlib_to_openssl_verify = {",
            "    ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,",
            "    ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,",
            "    ssl.CERT_REQUIRED:",
            "        OpenSSL.SSL.VERIFY_PEER + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,",
            "}",
            "_openssl_to_stdlib_verify = dict(",
            "    (v, k) for k, v in _stdlib_to_openssl_verify.items()",
            ")",
            "",
            "# OpenSSL will only write 16K at a time",
            "SSL_WRITE_BLOCKSIZE = 16384",
            "",
            "orig_util_HAS_SNI = util.HAS_SNI",
            "orig_util_SSLContext = util.ssl_.SSLContext",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def inject_into_urllib3():",
            "    'Monkey-patch urllib3 with PyOpenSSL-backed SSL-support.'",
            "",
            "    _validate_dependencies_met()",
            "",
            "    util.ssl_.SSLContext = PyOpenSSLContext",
            "    util.HAS_SNI = HAS_SNI",
            "    util.ssl_.HAS_SNI = HAS_SNI",
            "    util.IS_PYOPENSSL = True",
            "    util.ssl_.IS_PYOPENSSL = True",
            "",
            "",
            "def extract_from_urllib3():",
            "    'Undo monkey-patching by :func:`inject_into_urllib3`.'",
            "",
            "    util.ssl_.SSLContext = orig_util_SSLContext",
            "    util.HAS_SNI = orig_util_HAS_SNI",
            "    util.ssl_.HAS_SNI = orig_util_HAS_SNI",
            "    util.IS_PYOPENSSL = False",
            "    util.ssl_.IS_PYOPENSSL = False",
            "",
            "",
            "def _validate_dependencies_met():",
            "    \"\"\"",
            "    Verifies that PyOpenSSL's package-level dependencies have been met.",
            "    Throws `ImportError` if they are not met.",
            "    \"\"\"",
            "    # Method added in `cryptography==1.1`; not available in older versions",
            "    from cryptography.x509.extensions import Extensions",
            "    if getattr(Extensions, \"get_extension_for_class\", None) is None:",
            "        raise ImportError(\"'cryptography' module missing required functionality.  \"",
            "                          \"Try upgrading to v1.3.4 or newer.\")",
            "",
            "    # pyOpenSSL 0.14 and above use cryptography for OpenSSL bindings. The _x509",
            "    # attribute is only present on those versions.",
            "    from OpenSSL.crypto import X509",
            "    x509 = X509()",
            "    if getattr(x509, \"_x509\", None) is None:",
            "        raise ImportError(\"'pyOpenSSL' module missing required functionality. \"",
            "                          \"Try upgrading to v0.14 or newer.\")",
            "",
            "",
            "def _dnsname_to_stdlib(name):",
            "    \"\"\"",
            "    Converts a dNSName SubjectAlternativeName field to the form used by the",
            "    standard library on the given Python version.",
            "",
            "    Cryptography produces a dNSName as a unicode string that was idna-decoded",
            "    from ASCII bytes. We need to idna-encode that string to get it back, and",
            "    then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib",
            "    uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).",
            "",
            "    If the name cannot be idna-encoded then we return None signalling that",
            "    the name given should be skipped.",
            "    \"\"\"",
            "    def idna_encode(name):",
            "        \"\"\"",
            "        Borrowed wholesale from the Python Cryptography Project. It turns out",
            "        that we can't just safely call `idna.encode`: it can explode for",
            "        wildcard names. This avoids that problem.",
            "        \"\"\"",
            "        import idna",
            "",
            "        try:",
            "            for prefix in [u'*.', u'.']:",
            "                if name.startswith(prefix):",
            "                    name = name[len(prefix):]",
            "                    return prefix.encode('ascii') + idna.encode(name)",
            "            return idna.encode(name)",
            "        except idna.core.IDNAError:",
            "            return None",
            "",
            "    if ':' in name:",
            "        return name",
            "",
            "    name = idna_encode(name)",
            "    if name is None:",
            "        return None",
            "    elif sys.version_info >= (3, 0):",
            "        name = name.decode('utf-8')",
            "    return name",
            "",
            "",
            "def get_subj_alt_name(peer_cert):",
            "    \"\"\"",
            "    Given an PyOpenSSL certificate, provides all the subject alternative names.",
            "    \"\"\"",
            "    # Pass the cert to cryptography, which has much better APIs for this.",
            "    if hasattr(peer_cert, \"to_cryptography\"):",
            "        cert = peer_cert.to_cryptography()",
            "    else:",
            "        # This is technically using private APIs, but should work across all",
            "        # relevant versions before PyOpenSSL got a proper API for this.",
            "        cert = _Certificate(openssl_backend, peer_cert._x509)",
            "",
            "    # We want to find the SAN extension. Ask Cryptography to locate it (it's",
            "    # faster than looping in Python)",
            "    try:",
            "        ext = cert.extensions.get_extension_for_class(",
            "            x509.SubjectAlternativeName",
            "        ).value",
            "    except x509.ExtensionNotFound:",
            "        # No such extension, return the empty list.",
            "        return []",
            "    except (x509.DuplicateExtension, UnsupportedExtension,",
            "            x509.UnsupportedGeneralNameType, UnicodeError) as e:",
            "        # A problem has been found with the quality of the certificate. Assume",
            "        # no SAN field is present.",
            "        log.warning(",
            "            \"A problem was encountered with the certificate that prevented \"",
            "            \"urllib3 from finding the SubjectAlternativeName field. This can \"",
            "            \"affect certificate validation. The error was %s\",",
            "            e,",
            "        )",
            "        return []",
            "",
            "    # We want to return dNSName and iPAddress fields. We need to cast the IPs",
            "    # back to strings because the match_hostname function wants them as",
            "    # strings.",
            "    # Sadly the DNS names need to be idna encoded and then, on Python 3, UTF-8",
            "    # decoded. This is pretty frustrating, but that's what the standard library",
            "    # does with certificates, and so we need to attempt to do the same.",
            "    # We also want to skip over names which cannot be idna encoded.",
            "    names = [",
            "        ('DNS', name) for name in map(_dnsname_to_stdlib, ext.get_values_for_type(x509.DNSName))",
            "        if name is not None",
            "    ]",
            "    names.extend(",
            "        ('IP Address', str(name))",
            "        for name in ext.get_values_for_type(x509.IPAddress)",
            "    )",
            "",
            "    return names",
            "",
            "",
            "class WrappedSocket(object):",
            "    '''API-compatibility wrapper for Python OpenSSL's Connection-class.",
            "",
            "    Note: _makefile_refs, _drop() and _reuse() are needed for the garbage",
            "    collector of pypy.",
            "    '''",
            "",
            "    def __init__(self, connection, socket, suppress_ragged_eofs=True):",
            "        self.connection = connection",
            "        self.socket = socket",
            "        self.suppress_ragged_eofs = suppress_ragged_eofs",
            "        self._makefile_refs = 0",
            "        self._closed = False",
            "",
            "    def fileno(self):",
            "        return self.socket.fileno()",
            "",
            "    # Copy-pasted from Python 3.5 source code",
            "    def _decref_socketios(self):",
            "        if self._makefile_refs > 0:",
            "            self._makefile_refs -= 1",
            "        if self._closed:",
            "            self.close()",
            "",
            "    def recv(self, *args, **kwargs):",
            "        try:",
            "            data = self.connection.recv(*args, **kwargs)",
            "        except OpenSSL.SSL.SysCallError as e:",
            "            if self.suppress_ragged_eofs and e.args == (-1, 'Unexpected EOF'):",
            "                return b''",
            "            else:",
            "                raise SocketError(str(e))",
            "        except OpenSSL.SSL.ZeroReturnError as e:",
            "            if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:",
            "                return b''",
            "            else:",
            "                raise",
            "        except OpenSSL.SSL.WantReadError:",
            "            if not util.wait_for_read(self.socket, self.socket.gettimeout()):",
            "                raise timeout('The read operation timed out')",
            "            else:",
            "                return self.recv(*args, **kwargs)",
            "        else:",
            "            return data",
            "",
            "    def recv_into(self, *args, **kwargs):",
            "        try:",
            "            return self.connection.recv_into(*args, **kwargs)",
            "        except OpenSSL.SSL.SysCallError as e:",
            "            if self.suppress_ragged_eofs and e.args == (-1, 'Unexpected EOF'):",
            "                return 0",
            "            else:",
            "                raise SocketError(str(e))",
            "        except OpenSSL.SSL.ZeroReturnError as e:",
            "            if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:",
            "                return 0",
            "            else:",
            "                raise",
            "        except OpenSSL.SSL.WantReadError:",
            "            if not util.wait_for_read(self.socket, self.socket.gettimeout()):",
            "                raise timeout('The read operation timed out')",
            "            else:",
            "                return self.recv_into(*args, **kwargs)",
            "",
            "    def settimeout(self, timeout):",
            "        return self.socket.settimeout(timeout)",
            "",
            "    def _send_until_done(self, data):",
            "        while True:",
            "            try:",
            "                return self.connection.send(data)",
            "            except OpenSSL.SSL.WantWriteError:",
            "                if not util.wait_for_write(self.socket, self.socket.gettimeout()):",
            "                    raise timeout()",
            "                continue",
            "            except OpenSSL.SSL.SysCallError as e:",
            "                raise SocketError(str(e))",
            "",
            "    def sendall(self, data):",
            "        total_sent = 0",
            "        while total_sent < len(data):",
            "            sent = self._send_until_done(data[total_sent:total_sent + SSL_WRITE_BLOCKSIZE])",
            "            total_sent += sent",
            "",
            "    def shutdown(self):",
            "        # FIXME rethrow compatible exceptions should we ever use this",
            "        self.connection.shutdown()",
            "",
            "    def close(self):",
            "        if self._makefile_refs < 1:",
            "            try:",
            "                self._closed = True",
            "                return self.connection.close()",
            "            except OpenSSL.SSL.Error:",
            "                return",
            "        else:",
            "            self._makefile_refs -= 1",
            "",
            "    def getpeercert(self, binary_form=False):",
            "        x509 = self.connection.get_peer_certificate()",
            "",
            "        if not x509:",
            "            return x509",
            "",
            "        if binary_form:",
            "            return OpenSSL.crypto.dump_certificate(",
            "                OpenSSL.crypto.FILETYPE_ASN1,",
            "                x509)",
            "",
            "        return {",
            "            'subject': (",
            "                (('commonName', x509.get_subject().CN),),",
            "            ),",
            "            'subjectAltName': get_subj_alt_name(x509)",
            "        }",
            "",
            "    def _reuse(self):",
            "        self._makefile_refs += 1",
            "",
            "    def _drop(self):",
            "        if self._makefile_refs < 1:",
            "            self.close()",
            "        else:",
            "            self._makefile_refs -= 1",
            "",
            "",
            "if _fileobject:  # Platform-specific: Python 2",
            "    def makefile(self, mode, bufsize=-1):",
            "        self._makefile_refs += 1",
            "        return _fileobject(self, mode, bufsize, close=True)",
            "else:  # Platform-specific: Python 3",
            "    makefile = backport_makefile",
            "",
            "WrappedSocket.makefile = makefile",
            "",
            "",
            "class PyOpenSSLContext(object):",
            "    \"\"\"",
            "    I am a wrapper class for the PyOpenSSL ``Context`` object. I am responsible",
            "    for translating the interface of the standard library ``SSLContext`` object",
            "    to calls into PyOpenSSL.",
            "    \"\"\"",
            "    def __init__(self, protocol):",
            "        self.protocol = _openssl_versions[protocol]",
            "        self._ctx = OpenSSL.SSL.Context(self.protocol)",
            "        self._options = 0",
            "        self.check_hostname = False",
            "",
            "    @property",
            "    def options(self):",
            "        return self._options",
            "",
            "    @options.setter",
            "    def options(self, value):",
            "        self._options = value",
            "        self._ctx.set_options(value)",
            "",
            "    @property",
            "    def verify_mode(self):",
            "        return _openssl_to_stdlib_verify[self._ctx.get_verify_mode()]",
            "",
            "    @verify_mode.setter",
            "    def verify_mode(self, value):",
            "        self._ctx.set_verify(",
            "            _stdlib_to_openssl_verify[value],",
            "            _verify_callback",
            "        )",
            "",
            "    def set_default_verify_paths(self):",
            "        self._ctx.set_default_verify_paths()",
            "",
            "    def set_ciphers(self, ciphers):",
            "        if isinstance(ciphers, six.text_type):",
            "            ciphers = ciphers.encode('utf-8')",
            "        self._ctx.set_cipher_list(ciphers)",
            "",
            "    def load_verify_locations(self, cafile=None, capath=None, cadata=None):",
            "        if cafile is not None:",
            "            cafile = cafile.encode('utf-8')",
            "        if capath is not None:",
            "            capath = capath.encode('utf-8')",
            "        self._ctx.load_verify_locations(cafile, capath)",
            "        if cadata is not None:",
            "            self._ctx.load_verify_locations(BytesIO(cadata))",
            "",
            "    def load_cert_chain(self, certfile, keyfile=None, password=None):",
            "        self._ctx.use_certificate_chain_file(certfile)",
            "        if password is not None:",
            "            self._ctx.set_passwd_cb(lambda max_length, prompt_twice, userdata: password)",
            "        self._ctx.use_privatekey_file(keyfile or certfile)",
            "",
            "    def wrap_socket(self, sock, server_side=False,",
            "                    do_handshake_on_connect=True, suppress_ragged_eofs=True,",
            "                    server_hostname=None):",
            "        cnx = OpenSSL.SSL.Connection(self._ctx, sock)",
            "",
            "        if isinstance(server_hostname, six.text_type):  # Platform-specific: Python 3",
            "            server_hostname = server_hostname.encode('utf-8')",
            "",
            "        if server_hostname is not None:",
            "            cnx.set_tlsext_host_name(server_hostname)",
            "",
            "        cnx.set_connect_state()",
            "",
            "        while True:",
            "            try:",
            "                cnx.do_handshake()",
            "            except OpenSSL.SSL.WantReadError:",
            "                if not util.wait_for_read(sock, sock.gettimeout()):",
            "                    raise timeout('select timed out')",
            "                continue",
            "            except OpenSSL.SSL.Error as e:",
            "                raise ssl.SSLError('bad handshake: %r' % e)",
            "            break",
            "",
            "        return WrappedSocket(cnx, sock)",
            "",
            "",
            "def _verify_callback(cnx, x509, err_no, err_depth, return_code):",
            "    return err_no == 0"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "asyncua.server.uaprocessor.UaProcessor._process_message"
        ]
    },
    "src/urllib3/poolmanager.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool"
            },
            "1": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from .connectionpool import port_by_scheme"
            },
            "2": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from .exceptions import LocationValueError, MaxRetryError, ProxySchemeUnknown"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+from .packages import six"
            },
            "4": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from .packages.six.moves.urllib.parse import urljoin"
            },
            "5": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from .request import RequestMethods"
            },
            "6": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " from .util.url import parse_url"
            },
            "7": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": 343,
                "PatchRowcode": "         # conn.is_same_host() which may use socket.gethostbyname() in the future."
            },
            "8": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": 344,
                "PatchRowcode": "         if (retries.remove_headers_on_redirect"
            },
            "9": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": 345,
                "PatchRowcode": "                 and not conn.is_same_host(redirect_location)):"
            },
            "10": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            for header in retries.remove_headers_on_redirect:"
            },
            "11": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                kw['headers'].pop(header, None)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 346,
                "PatchRowcode": "+            headers = list(six.iterkeys(kw['headers']))"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 347,
                "PatchRowcode": "+            for header in headers:"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+                if header.lower() in retries.remove_headers_on_redirect:"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 349,
                "PatchRowcode": "+                    kw['headers'].pop(header, None)"
            },
            "16": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": 350,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 351,
                "PatchRowcode": "         try:"
            },
            "18": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 352,
                "PatchRowcode": "             retries = retries.increment(method, url, response=response, _pool=conn)"
            }
        },
        "frontPatchFile": [
            "from __future__ import absolute_import",
            "import collections",
            "import functools",
            "import logging",
            "",
            "from ._collections import RecentlyUsedContainer",
            "from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool",
            "from .connectionpool import port_by_scheme",
            "from .exceptions import LocationValueError, MaxRetryError, ProxySchemeUnknown",
            "from .packages.six.moves.urllib.parse import urljoin",
            "from .request import RequestMethods",
            "from .util.url import parse_url",
            "from .util.retry import Retry",
            "",
            "",
            "__all__ = ['PoolManager', 'ProxyManager', 'proxy_from_url']",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "SSL_KEYWORDS = ('key_file', 'cert_file', 'cert_reqs', 'ca_certs',",
            "                'ssl_version', 'ca_cert_dir', 'ssl_context')",
            "",
            "# All known keyword arguments that could be provided to the pool manager, its",
            "# pools, or the underlying connections. This is used to construct a pool key.",
            "_key_fields = (",
            "    'key_scheme',  # str",
            "    'key_host',  # str",
            "    'key_port',  # int",
            "    'key_timeout',  # int or float or Timeout",
            "    'key_retries',  # int or Retry",
            "    'key_strict',  # bool",
            "    'key_block',  # bool",
            "    'key_source_address',  # str",
            "    'key_key_file',  # str",
            "    'key_cert_file',  # str",
            "    'key_cert_reqs',  # str",
            "    'key_ca_certs',  # str",
            "    'key_ssl_version',  # str",
            "    'key_ca_cert_dir',  # str",
            "    'key_ssl_context',  # instance of ssl.SSLContext or urllib3.util.ssl_.SSLContext",
            "    'key_maxsize',  # int",
            "    'key_headers',  # dict",
            "    'key__proxy',  # parsed proxy url",
            "    'key__proxy_headers',  # dict",
            "    'key_socket_options',  # list of (level (int), optname (int), value (int or str)) tuples",
            "    'key__socks_options',  # dict",
            "    'key_assert_hostname',  # bool or string",
            "    'key_assert_fingerprint',  # str",
            "    'key_server_hostname', #str",
            ")",
            "",
            "#: The namedtuple class used to construct keys for the connection pool.",
            "#: All custom key schemes should include the fields in this key at a minimum.",
            "PoolKey = collections.namedtuple('PoolKey', _key_fields)",
            "",
            "",
            "def _default_key_normalizer(key_class, request_context):",
            "    \"\"\"",
            "    Create a pool key out of a request context dictionary.",
            "",
            "    According to RFC 3986, both the scheme and host are case-insensitive.",
            "    Therefore, this function normalizes both before constructing the pool",
            "    key for an HTTPS request. If you wish to change this behaviour, provide",
            "    alternate callables to ``key_fn_by_scheme``.",
            "",
            "    :param key_class:",
            "        The class to use when constructing the key. This should be a namedtuple",
            "        with the ``scheme`` and ``host`` keys at a minimum.",
            "    :type  key_class: namedtuple",
            "    :param request_context:",
            "        A dictionary-like object that contain the context for a request.",
            "    :type  request_context: dict",
            "",
            "    :return: A namedtuple that can be used as a connection pool key.",
            "    :rtype:  PoolKey",
            "    \"\"\"",
            "    # Since we mutate the dictionary, make a copy first",
            "    context = request_context.copy()",
            "    context['scheme'] = context['scheme'].lower()",
            "    context['host'] = context['host'].lower()",
            "",
            "    # These are both dictionaries and need to be transformed into frozensets",
            "    for key in ('headers', '_proxy_headers', '_socks_options'):",
            "        if key in context and context[key] is not None:",
            "            context[key] = frozenset(context[key].items())",
            "",
            "    # The socket_options key may be a list and needs to be transformed into a",
            "    # tuple.",
            "    socket_opts = context.get('socket_options')",
            "    if socket_opts is not None:",
            "        context['socket_options'] = tuple(socket_opts)",
            "",
            "    # Map the kwargs to the names in the namedtuple - this is necessary since",
            "    # namedtuples can't have fields starting with '_'.",
            "    for key in list(context.keys()):",
            "        context['key_' + key] = context.pop(key)",
            "",
            "    # Default to ``None`` for keys missing from the context",
            "    for field in key_class._fields:",
            "        if field not in context:",
            "            context[field] = None",
            "",
            "    return key_class(**context)",
            "",
            "",
            "#: A dictionary that maps a scheme to a callable that creates a pool key.",
            "#: This can be used to alter the way pool keys are constructed, if desired.",
            "#: Each PoolManager makes a copy of this dictionary so they can be configured",
            "#: globally here, or individually on the instance.",
            "key_fn_by_scheme = {",
            "    'http': functools.partial(_default_key_normalizer, PoolKey),",
            "    'https': functools.partial(_default_key_normalizer, PoolKey),",
            "}",
            "",
            "pool_classes_by_scheme = {",
            "    'http': HTTPConnectionPool,",
            "    'https': HTTPSConnectionPool,",
            "}",
            "",
            "",
            "class PoolManager(RequestMethods):",
            "    \"\"\"",
            "    Allows for arbitrary requests while transparently keeping track of",
            "    necessary connection pools for you.",
            "",
            "    :param num_pools:",
            "        Number of connection pools to cache before discarding the least",
            "        recently used pool.",
            "",
            "    :param headers:",
            "        Headers to include with all requests, unless other headers are given",
            "        explicitly.",
            "",
            "    :param \\\\**connection_pool_kw:",
            "        Additional parameters are used to create fresh",
            "        :class:`urllib3.connectionpool.ConnectionPool` instances.",
            "",
            "    Example::",
            "",
            "        >>> manager = PoolManager(num_pools=2)",
            "        >>> r = manager.request('GET', 'http://google.com/')",
            "        >>> r = manager.request('GET', 'http://google.com/mail')",
            "        >>> r = manager.request('GET', 'http://yahoo.com/')",
            "        >>> len(manager.pools)",
            "        2",
            "",
            "    \"\"\"",
            "",
            "    proxy = None",
            "",
            "    def __init__(self, num_pools=10, headers=None, **connection_pool_kw):",
            "        RequestMethods.__init__(self, headers)",
            "        self.connection_pool_kw = connection_pool_kw",
            "        self.pools = RecentlyUsedContainer(num_pools,",
            "                                           dispose_func=lambda p: p.close())",
            "",
            "        # Locally set the pool classes and keys so other PoolManagers can",
            "        # override them.",
            "        self.pool_classes_by_scheme = pool_classes_by_scheme",
            "        self.key_fn_by_scheme = key_fn_by_scheme.copy()",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, exc_type, exc_val, exc_tb):",
            "        self.clear()",
            "        # Return False to re-raise any potential exceptions",
            "        return False",
            "",
            "    def _new_pool(self, scheme, host, port, request_context=None):",
            "        \"\"\"",
            "        Create a new :class:`ConnectionPool` based on host, port, scheme, and",
            "        any additional pool keyword arguments.",
            "",
            "        If ``request_context`` is provided, it is provided as keyword arguments",
            "        to the pool class used. This method is used to actually create the",
            "        connection pools handed out by :meth:`connection_from_url` and",
            "        companion methods. It is intended to be overridden for customization.",
            "        \"\"\"",
            "        pool_cls = self.pool_classes_by_scheme[scheme]",
            "        if request_context is None:",
            "            request_context = self.connection_pool_kw.copy()",
            "",
            "        # Although the context has everything necessary to create the pool,",
            "        # this function has historically only used the scheme, host, and port",
            "        # in the positional args. When an API change is acceptable these can",
            "        # be removed.",
            "        for key in ('scheme', 'host', 'port'):",
            "            request_context.pop(key, None)",
            "",
            "        if scheme == 'http':",
            "            for kw in SSL_KEYWORDS:",
            "                request_context.pop(kw, None)",
            "",
            "        return pool_cls(host, port, **request_context)",
            "",
            "    def clear(self):",
            "        \"\"\"",
            "        Empty our store of pools and direct them all to close.",
            "",
            "        This will not affect in-flight connections, but they will not be",
            "        re-used after completion.",
            "        \"\"\"",
            "        self.pools.clear()",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the host, port, and scheme.",
            "",
            "        If ``port`` isn't given, it will be derived from the ``scheme`` using",
            "        ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is",
            "        provided, it is merged with the instance's ``connection_pool_kw``",
            "        variable and used to create the new connection pool, if one is",
            "        needed.",
            "        \"\"\"",
            "",
            "        if not host:",
            "            raise LocationValueError(\"No host specified.\")",
            "",
            "        request_context = self._merge_pool_kwargs(pool_kwargs)",
            "        request_context['scheme'] = scheme or 'http'",
            "        if not port:",
            "            port = port_by_scheme.get(request_context['scheme'].lower(), 80)",
            "        request_context['port'] = port",
            "        request_context['host'] = host",
            "",
            "        return self.connection_from_context(request_context)",
            "",
            "    def connection_from_context(self, request_context):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the request context.",
            "",
            "        ``request_context`` must at least contain the ``scheme`` key and its",
            "        value must be a key in ``key_fn_by_scheme`` instance variable.",
            "        \"\"\"",
            "        scheme = request_context['scheme'].lower()",
            "        pool_key_constructor = self.key_fn_by_scheme[scheme]",
            "        pool_key = pool_key_constructor(request_context)",
            "",
            "        return self.connection_from_pool_key(pool_key, request_context=request_context)",
            "",
            "    def connection_from_pool_key(self, pool_key, request_context=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the provided pool key.",
            "",
            "        ``pool_key`` should be a namedtuple that only contains immutable",
            "        objects. At a minimum it must have the ``scheme``, ``host``, and",
            "        ``port`` fields.",
            "        \"\"\"",
            "        with self.pools.lock:",
            "            # If the scheme, host, or port doesn't match existing open",
            "            # connections, open a new ConnectionPool.",
            "            pool = self.pools.get(pool_key)",
            "            if pool:",
            "                return pool",
            "",
            "            # Make a fresh ConnectionPool of the desired type",
            "            scheme = request_context['scheme']",
            "            host = request_context['host']",
            "            port = request_context['port']",
            "            pool = self._new_pool(scheme, host, port, request_context=request_context)",
            "            self.pools[pool_key] = pool",
            "",
            "        return pool",
            "",
            "    def connection_from_url(self, url, pool_kwargs=None):",
            "        \"\"\"",
            "        Similar to :func:`urllib3.connectionpool.connection_from_url`.",
            "",
            "        If ``pool_kwargs`` is not provided and a new pool needs to be",
            "        constructed, ``self.connection_pool_kw`` is used to initialize",
            "        the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``",
            "        is provided, it is used instead. Note that if a new pool does not",
            "        need to be created for the request, the provided ``pool_kwargs`` are",
            "        not used.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        return self.connection_from_host(u.host, port=u.port, scheme=u.scheme,",
            "                                         pool_kwargs=pool_kwargs)",
            "",
            "    def _merge_pool_kwargs(self, override):",
            "        \"\"\"",
            "        Merge a dictionary of override values for self.connection_pool_kw.",
            "",
            "        This does not modify self.connection_pool_kw and returns a new dict.",
            "        Any keys in the override dictionary with a value of ``None`` are",
            "        removed from the merged dictionary.",
            "        \"\"\"",
            "        base_pool_kwargs = self.connection_pool_kw.copy()",
            "        if override:",
            "            for key, value in override.items():",
            "                if value is None:",
            "                    try:",
            "                        del base_pool_kwargs[key]",
            "                    except KeyError:",
            "                        pass",
            "                else:",
            "                    base_pool_kwargs[key] = value",
            "        return base_pool_kwargs",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"\"\"",
            "        Same as :meth:`urllib3.connectionpool.HTTPConnectionPool.urlopen`",
            "        with custom cross-host redirect logic and only sends the request-uri",
            "        portion of the ``url``.",
            "",
            "        The given ``url`` parameter must be absolute, such that an appropriate",
            "        :class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)",
            "",
            "        kw['assert_same_host'] = False",
            "        kw['redirect'] = False",
            "",
            "        if 'headers' not in kw:",
            "            kw['headers'] = self.headers.copy()",
            "",
            "        if self.proxy is not None and u.scheme == \"http\":",
            "            response = conn.urlopen(method, url, **kw)",
            "        else:",
            "            response = conn.urlopen(method, u.request_uri, **kw)",
            "",
            "        redirect_location = redirect and response.get_redirect_location()",
            "        if not redirect_location:",
            "            return response",
            "",
            "        # Support relative URLs for redirecting.",
            "        redirect_location = urljoin(url, redirect_location)",
            "",
            "        # RFC 7231, Section 6.4.4",
            "        if response.status == 303:",
            "            method = 'GET'",
            "",
            "        retries = kw.get('retries')",
            "        if not isinstance(retries, Retry):",
            "            retries = Retry.from_int(retries, redirect=redirect)",
            "",
            "        # Strip headers marked as unsafe to forward to the redirected location.",
            "        # Check remove_headers_on_redirect to avoid a potential network call within",
            "        # conn.is_same_host() which may use socket.gethostbyname() in the future.",
            "        if (retries.remove_headers_on_redirect",
            "                and not conn.is_same_host(redirect_location)):",
            "            for header in retries.remove_headers_on_redirect:",
            "                kw['headers'].pop(header, None)",
            "",
            "        try:",
            "            retries = retries.increment(method, url, response=response, _pool=conn)",
            "        except MaxRetryError:",
            "            if retries.raise_on_redirect:",
            "                raise",
            "            return response",
            "",
            "        kw['retries'] = retries",
            "        kw['redirect'] = redirect",
            "",
            "        log.info(\"Redirecting %s -> %s\", url, redirect_location)",
            "        return self.urlopen(method, redirect_location, **kw)",
            "",
            "",
            "class ProxyManager(PoolManager):",
            "    \"\"\"",
            "    Behaves just like :class:`PoolManager`, but sends all requests through",
            "    the defined proxy, using the CONNECT method for HTTPS URLs.",
            "",
            "    :param proxy_url:",
            "        The URL of the proxy to be used.",
            "",
            "    :param proxy_headers:",
            "        A dictionary containing headers that will be sent to the proxy. In case",
            "        of HTTP they are being sent with each request, while in the",
            "        HTTPS/CONNECT case they are sent only once. Could be used for proxy",
            "        authentication.",
            "",
            "    Example:",
            "        >>> proxy = urllib3.ProxyManager('http://localhost:3128/')",
            "        >>> r1 = proxy.request('GET', 'http://google.com/')",
            "        >>> r2 = proxy.request('GET', 'http://httpbin.org/')",
            "        >>> len(proxy.pools)",
            "        1",
            "        >>> r3 = proxy.request('GET', 'https://httpbin.org/')",
            "        >>> r4 = proxy.request('GET', 'https://twitter.com/')",
            "        >>> len(proxy.pools)",
            "        3",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, proxy_url, num_pools=10, headers=None,",
            "                 proxy_headers=None, **connection_pool_kw):",
            "",
            "        if isinstance(proxy_url, HTTPConnectionPool):",
            "            proxy_url = '%s://%s:%i' % (proxy_url.scheme, proxy_url.host,",
            "                                        proxy_url.port)",
            "        proxy = parse_url(proxy_url)",
            "        if not proxy.port:",
            "            port = port_by_scheme.get(proxy.scheme, 80)",
            "            proxy = proxy._replace(port=port)",
            "",
            "        if proxy.scheme not in (\"http\", \"https\"):",
            "            raise ProxySchemeUnknown(proxy.scheme)",
            "",
            "        self.proxy = proxy",
            "        self.proxy_headers = proxy_headers or {}",
            "",
            "        connection_pool_kw['_proxy'] = self.proxy",
            "        connection_pool_kw['_proxy_headers'] = self.proxy_headers",
            "",
            "        super(ProxyManager, self).__init__(",
            "            num_pools, headers, **connection_pool_kw)",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        if scheme == \"https\":",
            "            return super(ProxyManager, self).connection_from_host(",
            "                host, port, scheme, pool_kwargs=pool_kwargs)",
            "",
            "        return super(ProxyManager, self).connection_from_host(",
            "            self.proxy.host, self.proxy.port, self.proxy.scheme, pool_kwargs=pool_kwargs)",
            "",
            "    def _set_proxy_headers(self, url, headers=None):",
            "        \"\"\"",
            "        Sets headers needed by proxies: specifically, the Accept and Host",
            "        headers. Only sets headers not provided by the user.",
            "        \"\"\"",
            "        headers_ = {'Accept': '*/*'}",
            "",
            "        netloc = parse_url(url).netloc",
            "        if netloc:",
            "            headers_['Host'] = netloc",
            "",
            "        if headers:",
            "            headers_.update(headers)",
            "        return headers_",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"",
            "        u = parse_url(url)",
            "",
            "        if u.scheme == \"http\":",
            "            # For proxied HTTPS requests, httplib sets the necessary headers",
            "            # on the CONNECT to the proxy. For HTTP, we'll definitely",
            "            # need to set 'Host' at the very least.",
            "            headers = kw.get('headers', self.headers)",
            "            kw['headers'] = self._set_proxy_headers(url, headers)",
            "",
            "        return super(ProxyManager, self).urlopen(method, url, redirect=redirect, **kw)",
            "",
            "",
            "def proxy_from_url(url, **kw):",
            "    return ProxyManager(proxy_url=url, **kw)"
        ],
        "afterPatchFile": [
            "from __future__ import absolute_import",
            "import collections",
            "import functools",
            "import logging",
            "",
            "from ._collections import RecentlyUsedContainer",
            "from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool",
            "from .connectionpool import port_by_scheme",
            "from .exceptions import LocationValueError, MaxRetryError, ProxySchemeUnknown",
            "from .packages import six",
            "from .packages.six.moves.urllib.parse import urljoin",
            "from .request import RequestMethods",
            "from .util.url import parse_url",
            "from .util.retry import Retry",
            "",
            "",
            "__all__ = ['PoolManager', 'ProxyManager', 'proxy_from_url']",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "SSL_KEYWORDS = ('key_file', 'cert_file', 'cert_reqs', 'ca_certs',",
            "                'ssl_version', 'ca_cert_dir', 'ssl_context')",
            "",
            "# All known keyword arguments that could be provided to the pool manager, its",
            "# pools, or the underlying connections. This is used to construct a pool key.",
            "_key_fields = (",
            "    'key_scheme',  # str",
            "    'key_host',  # str",
            "    'key_port',  # int",
            "    'key_timeout',  # int or float or Timeout",
            "    'key_retries',  # int or Retry",
            "    'key_strict',  # bool",
            "    'key_block',  # bool",
            "    'key_source_address',  # str",
            "    'key_key_file',  # str",
            "    'key_cert_file',  # str",
            "    'key_cert_reqs',  # str",
            "    'key_ca_certs',  # str",
            "    'key_ssl_version',  # str",
            "    'key_ca_cert_dir',  # str",
            "    'key_ssl_context',  # instance of ssl.SSLContext or urllib3.util.ssl_.SSLContext",
            "    'key_maxsize',  # int",
            "    'key_headers',  # dict",
            "    'key__proxy',  # parsed proxy url",
            "    'key__proxy_headers',  # dict",
            "    'key_socket_options',  # list of (level (int), optname (int), value (int or str)) tuples",
            "    'key__socks_options',  # dict",
            "    'key_assert_hostname',  # bool or string",
            "    'key_assert_fingerprint',  # str",
            "    'key_server_hostname', #str",
            ")",
            "",
            "#: The namedtuple class used to construct keys for the connection pool.",
            "#: All custom key schemes should include the fields in this key at a minimum.",
            "PoolKey = collections.namedtuple('PoolKey', _key_fields)",
            "",
            "",
            "def _default_key_normalizer(key_class, request_context):",
            "    \"\"\"",
            "    Create a pool key out of a request context dictionary.",
            "",
            "    According to RFC 3986, both the scheme and host are case-insensitive.",
            "    Therefore, this function normalizes both before constructing the pool",
            "    key for an HTTPS request. If you wish to change this behaviour, provide",
            "    alternate callables to ``key_fn_by_scheme``.",
            "",
            "    :param key_class:",
            "        The class to use when constructing the key. This should be a namedtuple",
            "        with the ``scheme`` and ``host`` keys at a minimum.",
            "    :type  key_class: namedtuple",
            "    :param request_context:",
            "        A dictionary-like object that contain the context for a request.",
            "    :type  request_context: dict",
            "",
            "    :return: A namedtuple that can be used as a connection pool key.",
            "    :rtype:  PoolKey",
            "    \"\"\"",
            "    # Since we mutate the dictionary, make a copy first",
            "    context = request_context.copy()",
            "    context['scheme'] = context['scheme'].lower()",
            "    context['host'] = context['host'].lower()",
            "",
            "    # These are both dictionaries and need to be transformed into frozensets",
            "    for key in ('headers', '_proxy_headers', '_socks_options'):",
            "        if key in context and context[key] is not None:",
            "            context[key] = frozenset(context[key].items())",
            "",
            "    # The socket_options key may be a list and needs to be transformed into a",
            "    # tuple.",
            "    socket_opts = context.get('socket_options')",
            "    if socket_opts is not None:",
            "        context['socket_options'] = tuple(socket_opts)",
            "",
            "    # Map the kwargs to the names in the namedtuple - this is necessary since",
            "    # namedtuples can't have fields starting with '_'.",
            "    for key in list(context.keys()):",
            "        context['key_' + key] = context.pop(key)",
            "",
            "    # Default to ``None`` for keys missing from the context",
            "    for field in key_class._fields:",
            "        if field not in context:",
            "            context[field] = None",
            "",
            "    return key_class(**context)",
            "",
            "",
            "#: A dictionary that maps a scheme to a callable that creates a pool key.",
            "#: This can be used to alter the way pool keys are constructed, if desired.",
            "#: Each PoolManager makes a copy of this dictionary so they can be configured",
            "#: globally here, or individually on the instance.",
            "key_fn_by_scheme = {",
            "    'http': functools.partial(_default_key_normalizer, PoolKey),",
            "    'https': functools.partial(_default_key_normalizer, PoolKey),",
            "}",
            "",
            "pool_classes_by_scheme = {",
            "    'http': HTTPConnectionPool,",
            "    'https': HTTPSConnectionPool,",
            "}",
            "",
            "",
            "class PoolManager(RequestMethods):",
            "    \"\"\"",
            "    Allows for arbitrary requests while transparently keeping track of",
            "    necessary connection pools for you.",
            "",
            "    :param num_pools:",
            "        Number of connection pools to cache before discarding the least",
            "        recently used pool.",
            "",
            "    :param headers:",
            "        Headers to include with all requests, unless other headers are given",
            "        explicitly.",
            "",
            "    :param \\\\**connection_pool_kw:",
            "        Additional parameters are used to create fresh",
            "        :class:`urllib3.connectionpool.ConnectionPool` instances.",
            "",
            "    Example::",
            "",
            "        >>> manager = PoolManager(num_pools=2)",
            "        >>> r = manager.request('GET', 'http://google.com/')",
            "        >>> r = manager.request('GET', 'http://google.com/mail')",
            "        >>> r = manager.request('GET', 'http://yahoo.com/')",
            "        >>> len(manager.pools)",
            "        2",
            "",
            "    \"\"\"",
            "",
            "    proxy = None",
            "",
            "    def __init__(self, num_pools=10, headers=None, **connection_pool_kw):",
            "        RequestMethods.__init__(self, headers)",
            "        self.connection_pool_kw = connection_pool_kw",
            "        self.pools = RecentlyUsedContainer(num_pools,",
            "                                           dispose_func=lambda p: p.close())",
            "",
            "        # Locally set the pool classes and keys so other PoolManagers can",
            "        # override them.",
            "        self.pool_classes_by_scheme = pool_classes_by_scheme",
            "        self.key_fn_by_scheme = key_fn_by_scheme.copy()",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, exc_type, exc_val, exc_tb):",
            "        self.clear()",
            "        # Return False to re-raise any potential exceptions",
            "        return False",
            "",
            "    def _new_pool(self, scheme, host, port, request_context=None):",
            "        \"\"\"",
            "        Create a new :class:`ConnectionPool` based on host, port, scheme, and",
            "        any additional pool keyword arguments.",
            "",
            "        If ``request_context`` is provided, it is provided as keyword arguments",
            "        to the pool class used. This method is used to actually create the",
            "        connection pools handed out by :meth:`connection_from_url` and",
            "        companion methods. It is intended to be overridden for customization.",
            "        \"\"\"",
            "        pool_cls = self.pool_classes_by_scheme[scheme]",
            "        if request_context is None:",
            "            request_context = self.connection_pool_kw.copy()",
            "",
            "        # Although the context has everything necessary to create the pool,",
            "        # this function has historically only used the scheme, host, and port",
            "        # in the positional args. When an API change is acceptable these can",
            "        # be removed.",
            "        for key in ('scheme', 'host', 'port'):",
            "            request_context.pop(key, None)",
            "",
            "        if scheme == 'http':",
            "            for kw in SSL_KEYWORDS:",
            "                request_context.pop(kw, None)",
            "",
            "        return pool_cls(host, port, **request_context)",
            "",
            "    def clear(self):",
            "        \"\"\"",
            "        Empty our store of pools and direct them all to close.",
            "",
            "        This will not affect in-flight connections, but they will not be",
            "        re-used after completion.",
            "        \"\"\"",
            "        self.pools.clear()",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the host, port, and scheme.",
            "",
            "        If ``port`` isn't given, it will be derived from the ``scheme`` using",
            "        ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is",
            "        provided, it is merged with the instance's ``connection_pool_kw``",
            "        variable and used to create the new connection pool, if one is",
            "        needed.",
            "        \"\"\"",
            "",
            "        if not host:",
            "            raise LocationValueError(\"No host specified.\")",
            "",
            "        request_context = self._merge_pool_kwargs(pool_kwargs)",
            "        request_context['scheme'] = scheme or 'http'",
            "        if not port:",
            "            port = port_by_scheme.get(request_context['scheme'].lower(), 80)",
            "        request_context['port'] = port",
            "        request_context['host'] = host",
            "",
            "        return self.connection_from_context(request_context)",
            "",
            "    def connection_from_context(self, request_context):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the request context.",
            "",
            "        ``request_context`` must at least contain the ``scheme`` key and its",
            "        value must be a key in ``key_fn_by_scheme`` instance variable.",
            "        \"\"\"",
            "        scheme = request_context['scheme'].lower()",
            "        pool_key_constructor = self.key_fn_by_scheme[scheme]",
            "        pool_key = pool_key_constructor(request_context)",
            "",
            "        return self.connection_from_pool_key(pool_key, request_context=request_context)",
            "",
            "    def connection_from_pool_key(self, pool_key, request_context=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the provided pool key.",
            "",
            "        ``pool_key`` should be a namedtuple that only contains immutable",
            "        objects. At a minimum it must have the ``scheme``, ``host``, and",
            "        ``port`` fields.",
            "        \"\"\"",
            "        with self.pools.lock:",
            "            # If the scheme, host, or port doesn't match existing open",
            "            # connections, open a new ConnectionPool.",
            "            pool = self.pools.get(pool_key)",
            "            if pool:",
            "                return pool",
            "",
            "            # Make a fresh ConnectionPool of the desired type",
            "            scheme = request_context['scheme']",
            "            host = request_context['host']",
            "            port = request_context['port']",
            "            pool = self._new_pool(scheme, host, port, request_context=request_context)",
            "            self.pools[pool_key] = pool",
            "",
            "        return pool",
            "",
            "    def connection_from_url(self, url, pool_kwargs=None):",
            "        \"\"\"",
            "        Similar to :func:`urllib3.connectionpool.connection_from_url`.",
            "",
            "        If ``pool_kwargs`` is not provided and a new pool needs to be",
            "        constructed, ``self.connection_pool_kw`` is used to initialize",
            "        the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``",
            "        is provided, it is used instead. Note that if a new pool does not",
            "        need to be created for the request, the provided ``pool_kwargs`` are",
            "        not used.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        return self.connection_from_host(u.host, port=u.port, scheme=u.scheme,",
            "                                         pool_kwargs=pool_kwargs)",
            "",
            "    def _merge_pool_kwargs(self, override):",
            "        \"\"\"",
            "        Merge a dictionary of override values for self.connection_pool_kw.",
            "",
            "        This does not modify self.connection_pool_kw and returns a new dict.",
            "        Any keys in the override dictionary with a value of ``None`` are",
            "        removed from the merged dictionary.",
            "        \"\"\"",
            "        base_pool_kwargs = self.connection_pool_kw.copy()",
            "        if override:",
            "            for key, value in override.items():",
            "                if value is None:",
            "                    try:",
            "                        del base_pool_kwargs[key]",
            "                    except KeyError:",
            "                        pass",
            "                else:",
            "                    base_pool_kwargs[key] = value",
            "        return base_pool_kwargs",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"\"\"",
            "        Same as :meth:`urllib3.connectionpool.HTTPConnectionPool.urlopen`",
            "        with custom cross-host redirect logic and only sends the request-uri",
            "        portion of the ``url``.",
            "",
            "        The given ``url`` parameter must be absolute, such that an appropriate",
            "        :class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)",
            "",
            "        kw['assert_same_host'] = False",
            "        kw['redirect'] = False",
            "",
            "        if 'headers' not in kw:",
            "            kw['headers'] = self.headers.copy()",
            "",
            "        if self.proxy is not None and u.scheme == \"http\":",
            "            response = conn.urlopen(method, url, **kw)",
            "        else:",
            "            response = conn.urlopen(method, u.request_uri, **kw)",
            "",
            "        redirect_location = redirect and response.get_redirect_location()",
            "        if not redirect_location:",
            "            return response",
            "",
            "        # Support relative URLs for redirecting.",
            "        redirect_location = urljoin(url, redirect_location)",
            "",
            "        # RFC 7231, Section 6.4.4",
            "        if response.status == 303:",
            "            method = 'GET'",
            "",
            "        retries = kw.get('retries')",
            "        if not isinstance(retries, Retry):",
            "            retries = Retry.from_int(retries, redirect=redirect)",
            "",
            "        # Strip headers marked as unsafe to forward to the redirected location.",
            "        # Check remove_headers_on_redirect to avoid a potential network call within",
            "        # conn.is_same_host() which may use socket.gethostbyname() in the future.",
            "        if (retries.remove_headers_on_redirect",
            "                and not conn.is_same_host(redirect_location)):",
            "            headers = list(six.iterkeys(kw['headers']))",
            "            for header in headers:",
            "                if header.lower() in retries.remove_headers_on_redirect:",
            "                    kw['headers'].pop(header, None)",
            "",
            "        try:",
            "            retries = retries.increment(method, url, response=response, _pool=conn)",
            "        except MaxRetryError:",
            "            if retries.raise_on_redirect:",
            "                raise",
            "            return response",
            "",
            "        kw['retries'] = retries",
            "        kw['redirect'] = redirect",
            "",
            "        log.info(\"Redirecting %s -> %s\", url, redirect_location)",
            "        return self.urlopen(method, redirect_location, **kw)",
            "",
            "",
            "class ProxyManager(PoolManager):",
            "    \"\"\"",
            "    Behaves just like :class:`PoolManager`, but sends all requests through",
            "    the defined proxy, using the CONNECT method for HTTPS URLs.",
            "",
            "    :param proxy_url:",
            "        The URL of the proxy to be used.",
            "",
            "    :param proxy_headers:",
            "        A dictionary containing headers that will be sent to the proxy. In case",
            "        of HTTP they are being sent with each request, while in the",
            "        HTTPS/CONNECT case they are sent only once. Could be used for proxy",
            "        authentication.",
            "",
            "    Example:",
            "        >>> proxy = urllib3.ProxyManager('http://localhost:3128/')",
            "        >>> r1 = proxy.request('GET', 'http://google.com/')",
            "        >>> r2 = proxy.request('GET', 'http://httpbin.org/')",
            "        >>> len(proxy.pools)",
            "        1",
            "        >>> r3 = proxy.request('GET', 'https://httpbin.org/')",
            "        >>> r4 = proxy.request('GET', 'https://twitter.com/')",
            "        >>> len(proxy.pools)",
            "        3",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, proxy_url, num_pools=10, headers=None,",
            "                 proxy_headers=None, **connection_pool_kw):",
            "",
            "        if isinstance(proxy_url, HTTPConnectionPool):",
            "            proxy_url = '%s://%s:%i' % (proxy_url.scheme, proxy_url.host,",
            "                                        proxy_url.port)",
            "        proxy = parse_url(proxy_url)",
            "        if not proxy.port:",
            "            port = port_by_scheme.get(proxy.scheme, 80)",
            "            proxy = proxy._replace(port=port)",
            "",
            "        if proxy.scheme not in (\"http\", \"https\"):",
            "            raise ProxySchemeUnknown(proxy.scheme)",
            "",
            "        self.proxy = proxy",
            "        self.proxy_headers = proxy_headers or {}",
            "",
            "        connection_pool_kw['_proxy'] = self.proxy",
            "        connection_pool_kw['_proxy_headers'] = self.proxy_headers",
            "",
            "        super(ProxyManager, self).__init__(",
            "            num_pools, headers, **connection_pool_kw)",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        if scheme == \"https\":",
            "            return super(ProxyManager, self).connection_from_host(",
            "                host, port, scheme, pool_kwargs=pool_kwargs)",
            "",
            "        return super(ProxyManager, self).connection_from_host(",
            "            self.proxy.host, self.proxy.port, self.proxy.scheme, pool_kwargs=pool_kwargs)",
            "",
            "    def _set_proxy_headers(self, url, headers=None):",
            "        \"\"\"",
            "        Sets headers needed by proxies: specifically, the Accept and Host",
            "        headers. Only sets headers not provided by the user.",
            "        \"\"\"",
            "        headers_ = {'Accept': '*/*'}",
            "",
            "        netloc = parse_url(url).netloc",
            "        if netloc:",
            "            headers_['Host'] = netloc",
            "",
            "        if headers:",
            "            headers_.update(headers)",
            "        return headers_",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"",
            "        u = parse_url(url)",
            "",
            "        if u.scheme == \"http\":",
            "            # For proxied HTTPS requests, httplib sets the necessary headers",
            "            # on the CONNECT to the proxy. For HTTP, we'll definitely",
            "            # need to set 'Host' at the very least.",
            "            headers = kw.get('headers', self.headers)",
            "            kw['headers'] = self._set_proxy_headers(url, headers)",
            "",
            "        return super(ProxyManager, self).urlopen(method, url, redirect=redirect, **kw)",
            "",
            "",
            "def proxy_from_url(url, **kw):",
            "    return ProxyManager(proxy_url=url, **kw)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "345": [
                "PoolManager",
                "urlopen"
            ],
            "346": [
                "PoolManager",
                "urlopen"
            ]
        },
        "addLocation": []
    },
    "src/urllib3/util/retry.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "         self.raise_on_status = raise_on_status"
            },
            "1": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 180,
                "PatchRowcode": "         self.history = history or tuple()"
            },
            "2": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "         self.respect_retry_after_header = respect_retry_after_header"
            },
            "3": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.remove_headers_on_redirect = remove_headers_on_redirect"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+        self.remove_headers_on_redirect = frozenset(["
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+            h.lower() for h in remove_headers_on_redirect])"
            },
            "6": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 184,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "     def new(self, **kw):"
            },
            "8": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "         params = dict("
            }
        },
        "frontPatchFile": [
            "from __future__ import absolute_import",
            "import time",
            "import logging",
            "from collections import namedtuple",
            "from itertools import takewhile",
            "import email",
            "import re",
            "",
            "from ..exceptions import (",
            "    ConnectTimeoutError,",
            "    MaxRetryError,",
            "    ProtocolError,",
            "    ReadTimeoutError,",
            "    ResponseError,",
            "    InvalidHeader,",
            ")",
            "from ..packages import six",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "# Data structure for representing the metadata of requests that result in a retry.",
            "RequestHistory = namedtuple('RequestHistory', [\"method\", \"url\", \"error\",",
            "                                               \"status\", \"redirect_location\"])",
            "",
            "",
            "class Retry(object):",
            "    \"\"\" Retry configuration.",
            "",
            "    Each retry attempt will create a new Retry object with updated values, so",
            "    they can be safely reused.",
            "",
            "    Retries can be defined as a default for a pool::",
            "",
            "        retries = Retry(connect=5, read=2, redirect=5)",
            "        http = PoolManager(retries=retries)",
            "        response = http.request('GET', 'http://example.com/')",
            "",
            "    Or per-request (which overrides the default for the pool)::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=Retry(10))",
            "",
            "    Retries can be disabled by passing ``False``::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=False)",
            "",
            "    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless",
            "    retries are disabled, in which case the causing exception will be raised.",
            "",
            "    :param int total:",
            "        Total number of retries to allow. Takes precedence over other counts.",
            "",
            "        Set to ``None`` to remove this constraint and fall back on other",
            "        counts. It's a good idea to set this to some sensibly-high value to",
            "        account for unexpected edge cases and avoid infinite retry loops.",
            "",
            "        Set to ``0`` to fail on the first retry.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int connect:",
            "        How many connection-related errors to retry on.",
            "",
            "        These are errors raised before the request is sent to the remote server,",
            "        which we assume has not triggered the server to process the request.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int read:",
            "        How many times to retry on read errors.",
            "",
            "        These errors are raised after the request was sent to the server, so the",
            "        request may have side-effects.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int redirect:",
            "        How many redirects to perform. Limit this to avoid infinite redirect",
            "        loops.",
            "",
            "        A redirect is a HTTP response with a status code 301, 302, 303, 307 or",
            "        308.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int status:",
            "        How many times to retry on bad status codes.",
            "",
            "        These are retries made on responses, where status code matches",
            "        ``status_forcelist``.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param iterable method_whitelist:",
            "        Set of uppercased HTTP method verbs that we should retry on.",
            "",
            "        By default, we only retry on methods which are considered to be",
            "        idempotent (multiple requests with the same parameters end with the",
            "        same state). See :attr:`Retry.DEFAULT_METHOD_WHITELIST`.",
            "",
            "        Set to a ``False`` value to retry on any verb.",
            "",
            "    :param iterable status_forcelist:",
            "        A set of integer HTTP status codes that we should force a retry on.",
            "        A retry is initiated if the request method is in ``method_whitelist``",
            "        and the response status code is in ``status_forcelist``.",
            "",
            "        By default, this is disabled with ``None``.",
            "",
            "    :param float backoff_factor:",
            "        A backoff factor to apply between attempts after the second try",
            "        (most errors are resolved immediately by a second try without a",
            "        delay). urllib3 will sleep for::",
            "",
            "            {backoff factor} * (2 ** ({number of total retries} - 1))",
            "",
            "        seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep",
            "        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer",
            "        than :attr:`Retry.BACKOFF_MAX`.",
            "",
            "        By default, backoff is disabled (set to 0).",
            "",
            "    :param bool raise_on_redirect: Whether, if the number of redirects is",
            "        exhausted, to raise a MaxRetryError, or to return a response with a",
            "        response code in the 3xx range.",
            "",
            "    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:",
            "        whether we should raise an exception, or return a response,",
            "        if status falls in ``status_forcelist`` range and retries have",
            "        been exhausted.",
            "",
            "    :param tuple history: The history of the request encountered during",
            "        each call to :meth:`~Retry.increment`. The list is in the order",
            "        the requests occurred. Each list item is of class :class:`RequestHistory`.",
            "",
            "    :param bool respect_retry_after_header:",
            "        Whether to respect Retry-After header on status codes defined as",
            "        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.",
            "",
            "    :param iterable remove_headers_on_redirect:",
            "        Sequence of headers to remove from the request when a response",
            "        indicating a redirect is returned before firing off the redirected",
            "        request.",
            "    \"\"\"",
            "",
            "    DEFAULT_METHOD_WHITELIST = frozenset([",
            "        'HEAD', 'GET', 'PUT', 'DELETE', 'OPTIONS', 'TRACE'])",
            "",
            "    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])",
            "",
            "    DEFAULT_REDIRECT_HEADERS_BLACKLIST = frozenset(['Authorization'])",
            "",
            "    #: Maximum backoff time.",
            "    BACKOFF_MAX = 120",
            "",
            "    def __init__(self, total=10, connect=None, read=None, redirect=None, status=None,",
            "                 method_whitelist=DEFAULT_METHOD_WHITELIST, status_forcelist=None,",
            "                 backoff_factor=0, raise_on_redirect=True, raise_on_status=True,",
            "                 history=None, respect_retry_after_header=True,",
            "                 remove_headers_on_redirect=DEFAULT_REDIRECT_HEADERS_BLACKLIST):",
            "",
            "        self.total = total",
            "        self.connect = connect",
            "        self.read = read",
            "        self.status = status",
            "",
            "        if redirect is False or total is False:",
            "            redirect = 0",
            "            raise_on_redirect = False",
            "",
            "        self.redirect = redirect",
            "        self.status_forcelist = status_forcelist or set()",
            "        self.method_whitelist = method_whitelist",
            "        self.backoff_factor = backoff_factor",
            "        self.raise_on_redirect = raise_on_redirect",
            "        self.raise_on_status = raise_on_status",
            "        self.history = history or tuple()",
            "        self.respect_retry_after_header = respect_retry_after_header",
            "        self.remove_headers_on_redirect = remove_headers_on_redirect",
            "",
            "    def new(self, **kw):",
            "        params = dict(",
            "            total=self.total,",
            "            connect=self.connect, read=self.read, redirect=self.redirect, status=self.status,",
            "            method_whitelist=self.method_whitelist,",
            "            status_forcelist=self.status_forcelist,",
            "            backoff_factor=self.backoff_factor,",
            "            raise_on_redirect=self.raise_on_redirect,",
            "            raise_on_status=self.raise_on_status,",
            "            history=self.history,",
            "            remove_headers_on_redirect=self.remove_headers_on_redirect",
            "        )",
            "        params.update(kw)",
            "        return type(self)(**params)",
            "",
            "    @classmethod",
            "    def from_int(cls, retries, redirect=True, default=None):",
            "        \"\"\" Backwards-compatibility for the old retries format.\"\"\"",
            "        if retries is None:",
            "            retries = default if default is not None else cls.DEFAULT",
            "",
            "        if isinstance(retries, Retry):",
            "            return retries",
            "",
            "        redirect = bool(redirect) and None",
            "        new_retries = cls(retries, redirect=redirect)",
            "        log.debug(\"Converted retries value: %r -> %r\", retries, new_retries)",
            "        return new_retries",
            "",
            "    def get_backoff_time(self):",
            "        \"\"\" Formula for computing the current backoff",
            "",
            "        :rtype: float",
            "        \"\"\"",
            "        # We want to consider only the last consecutive errors sequence (Ignore redirects).",
            "        consecutive_errors_len = len(list(takewhile(lambda x: x.redirect_location is None,",
            "                                                    reversed(self.history))))",
            "        if consecutive_errors_len <= 1:",
            "            return 0",
            "",
            "        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))",
            "        return min(self.BACKOFF_MAX, backoff_value)",
            "",
            "    def parse_retry_after(self, retry_after):",
            "        # Whitespace: https://tools.ietf.org/html/rfc7230#section-3.2.4",
            "        if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):",
            "            seconds = int(retry_after)",
            "        else:",
            "            retry_date_tuple = email.utils.parsedate(retry_after)",
            "            if retry_date_tuple is None:",
            "                raise InvalidHeader(\"Invalid Retry-After header: %s\" % retry_after)",
            "            retry_date = time.mktime(retry_date_tuple)",
            "            seconds = retry_date - time.time()",
            "",
            "        if seconds < 0:",
            "            seconds = 0",
            "",
            "        return seconds",
            "",
            "    def get_retry_after(self, response):",
            "        \"\"\" Get the value of Retry-After in seconds. \"\"\"",
            "",
            "        retry_after = response.getheader(\"Retry-After\")",
            "",
            "        if retry_after is None:",
            "            return None",
            "",
            "        return self.parse_retry_after(retry_after)",
            "",
            "    def sleep_for_retry(self, response=None):",
            "        retry_after = self.get_retry_after(response)",
            "        if retry_after:",
            "            time.sleep(retry_after)",
            "            return True",
            "",
            "        return False",
            "",
            "    def _sleep_backoff(self):",
            "        backoff = self.get_backoff_time()",
            "        if backoff <= 0:",
            "            return",
            "        time.sleep(backoff)",
            "",
            "    def sleep(self, response=None):",
            "        \"\"\" Sleep between retry attempts.",
            "",
            "        This method will respect a server's ``Retry-After`` response header",
            "        and sleep the duration of the time requested. If that is not present, it",
            "        will use an exponential backoff. By default, the backoff factor is 0 and",
            "        this method will return immediately.",
            "        \"\"\"",
            "",
            "        if response:",
            "            slept = self.sleep_for_retry(response)",
            "            if slept:",
            "                return",
            "",
            "        self._sleep_backoff()",
            "",
            "    def _is_connection_error(self, err):",
            "        \"\"\" Errors when we're fairly sure that the server did not receive the",
            "        request, so it should be safe to retry.",
            "        \"\"\"",
            "        return isinstance(err, ConnectTimeoutError)",
            "",
            "    def _is_read_error(self, err):",
            "        \"\"\" Errors that occur after the request has been started, so we should",
            "        assume that the server began processing it.",
            "        \"\"\"",
            "        return isinstance(err, (ReadTimeoutError, ProtocolError))",
            "",
            "    def _is_method_retryable(self, method):",
            "        \"\"\" Checks if a given HTTP method should be retried upon, depending if",
            "        it is included on the method whitelist.",
            "        \"\"\"",
            "        if self.method_whitelist and method.upper() not in self.method_whitelist:",
            "            return False",
            "",
            "        return True",
            "",
            "    def is_retry(self, method, status_code, has_retry_after=False):",
            "        \"\"\" Is this method/status code retryable? (Based on whitelists and control",
            "        variables such as the number of total retries to allow, whether to",
            "        respect the Retry-After header, whether this header is present, and",
            "        whether the returned status code is on the list of status codes to",
            "        be retried upon on the presence of the aforementioned header)",
            "        \"\"\"",
            "        if not self._is_method_retryable(method):",
            "            return False",
            "",
            "        if self.status_forcelist and status_code in self.status_forcelist:",
            "            return True",
            "",
            "        return (self.total and self.respect_retry_after_header and",
            "                has_retry_after and (status_code in self.RETRY_AFTER_STATUS_CODES))",
            "",
            "    def is_exhausted(self):",
            "        \"\"\" Are we out of retries? \"\"\"",
            "        retry_counts = (self.total, self.connect, self.read, self.redirect, self.status)",
            "        retry_counts = list(filter(None, retry_counts))",
            "        if not retry_counts:",
            "            return False",
            "",
            "        return min(retry_counts) < 0",
            "",
            "    def increment(self, method=None, url=None, response=None, error=None,",
            "                  _pool=None, _stacktrace=None):",
            "        \"\"\" Return a new Retry object with incremented retry counters.",
            "",
            "        :param response: A response object, or None, if the server did not",
            "            return a response.",
            "        :type response: :class:`~urllib3.response.HTTPResponse`",
            "        :param Exception error: An error encountered during the request, or",
            "            None if the response was received successfully.",
            "",
            "        :return: A new ``Retry`` object.",
            "        \"\"\"",
            "        if self.total is False and error:",
            "            # Disabled, indicate to re-raise the error.",
            "            raise six.reraise(type(error), error, _stacktrace)",
            "",
            "        total = self.total",
            "        if total is not None:",
            "            total -= 1",
            "",
            "        connect = self.connect",
            "        read = self.read",
            "        redirect = self.redirect",
            "        status_count = self.status",
            "        cause = 'unknown'",
            "        status = None",
            "        redirect_location = None",
            "",
            "        if error and self._is_connection_error(error):",
            "            # Connect retry?",
            "            if connect is False:",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif connect is not None:",
            "                connect -= 1",
            "",
            "        elif error and self._is_read_error(error):",
            "            # Read retry?",
            "            if read is False or not self._is_method_retryable(method):",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif read is not None:",
            "                read -= 1",
            "",
            "        elif response and response.get_redirect_location():",
            "            # Redirect retry?",
            "            if redirect is not None:",
            "                redirect -= 1",
            "            cause = 'too many redirects'",
            "            redirect_location = response.get_redirect_location()",
            "            status = response.status",
            "",
            "        else:",
            "            # Incrementing because of a server error like a 500 in",
            "            # status_forcelist and a the given method is in the whitelist",
            "            cause = ResponseError.GENERIC_ERROR",
            "            if response and response.status:",
            "                if status_count is not None:",
            "                    status_count -= 1",
            "                cause = ResponseError.SPECIFIC_ERROR.format(",
            "                    status_code=response.status)",
            "                status = response.status",
            "",
            "        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)",
            "",
            "        new_retry = self.new(",
            "            total=total,",
            "            connect=connect, read=read, redirect=redirect, status=status_count,",
            "            history=history)",
            "",
            "        if new_retry.is_exhausted():",
            "            raise MaxRetryError(_pool, url, error or ResponseError(cause))",
            "",
            "        log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)",
            "",
            "        return new_retry",
            "",
            "    def __repr__(self):",
            "        return ('{cls.__name__}(total={self.total}, connect={self.connect}, '",
            "                'read={self.read}, redirect={self.redirect}, status={self.status})').format(",
            "                    cls=type(self), self=self)",
            "",
            "",
            "# For backwards compatibility (equivalent to pre-v1.9):",
            "Retry.DEFAULT = Retry(3)"
        ],
        "afterPatchFile": [
            "from __future__ import absolute_import",
            "import time",
            "import logging",
            "from collections import namedtuple",
            "from itertools import takewhile",
            "import email",
            "import re",
            "",
            "from ..exceptions import (",
            "    ConnectTimeoutError,",
            "    MaxRetryError,",
            "    ProtocolError,",
            "    ReadTimeoutError,",
            "    ResponseError,",
            "    InvalidHeader,",
            ")",
            "from ..packages import six",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "# Data structure for representing the metadata of requests that result in a retry.",
            "RequestHistory = namedtuple('RequestHistory', [\"method\", \"url\", \"error\",",
            "                                               \"status\", \"redirect_location\"])",
            "",
            "",
            "class Retry(object):",
            "    \"\"\" Retry configuration.",
            "",
            "    Each retry attempt will create a new Retry object with updated values, so",
            "    they can be safely reused.",
            "",
            "    Retries can be defined as a default for a pool::",
            "",
            "        retries = Retry(connect=5, read=2, redirect=5)",
            "        http = PoolManager(retries=retries)",
            "        response = http.request('GET', 'http://example.com/')",
            "",
            "    Or per-request (which overrides the default for the pool)::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=Retry(10))",
            "",
            "    Retries can be disabled by passing ``False``::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=False)",
            "",
            "    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless",
            "    retries are disabled, in which case the causing exception will be raised.",
            "",
            "    :param int total:",
            "        Total number of retries to allow. Takes precedence over other counts.",
            "",
            "        Set to ``None`` to remove this constraint and fall back on other",
            "        counts. It's a good idea to set this to some sensibly-high value to",
            "        account for unexpected edge cases and avoid infinite retry loops.",
            "",
            "        Set to ``0`` to fail on the first retry.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int connect:",
            "        How many connection-related errors to retry on.",
            "",
            "        These are errors raised before the request is sent to the remote server,",
            "        which we assume has not triggered the server to process the request.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int read:",
            "        How many times to retry on read errors.",
            "",
            "        These errors are raised after the request was sent to the server, so the",
            "        request may have side-effects.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int redirect:",
            "        How many redirects to perform. Limit this to avoid infinite redirect",
            "        loops.",
            "",
            "        A redirect is a HTTP response with a status code 301, 302, 303, 307 or",
            "        308.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int status:",
            "        How many times to retry on bad status codes.",
            "",
            "        These are retries made on responses, where status code matches",
            "        ``status_forcelist``.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param iterable method_whitelist:",
            "        Set of uppercased HTTP method verbs that we should retry on.",
            "",
            "        By default, we only retry on methods which are considered to be",
            "        idempotent (multiple requests with the same parameters end with the",
            "        same state). See :attr:`Retry.DEFAULT_METHOD_WHITELIST`.",
            "",
            "        Set to a ``False`` value to retry on any verb.",
            "",
            "    :param iterable status_forcelist:",
            "        A set of integer HTTP status codes that we should force a retry on.",
            "        A retry is initiated if the request method is in ``method_whitelist``",
            "        and the response status code is in ``status_forcelist``.",
            "",
            "        By default, this is disabled with ``None``.",
            "",
            "    :param float backoff_factor:",
            "        A backoff factor to apply between attempts after the second try",
            "        (most errors are resolved immediately by a second try without a",
            "        delay). urllib3 will sleep for::",
            "",
            "            {backoff factor} * (2 ** ({number of total retries} - 1))",
            "",
            "        seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep",
            "        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer",
            "        than :attr:`Retry.BACKOFF_MAX`.",
            "",
            "        By default, backoff is disabled (set to 0).",
            "",
            "    :param bool raise_on_redirect: Whether, if the number of redirects is",
            "        exhausted, to raise a MaxRetryError, or to return a response with a",
            "        response code in the 3xx range.",
            "",
            "    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:",
            "        whether we should raise an exception, or return a response,",
            "        if status falls in ``status_forcelist`` range and retries have",
            "        been exhausted.",
            "",
            "    :param tuple history: The history of the request encountered during",
            "        each call to :meth:`~Retry.increment`. The list is in the order",
            "        the requests occurred. Each list item is of class :class:`RequestHistory`.",
            "",
            "    :param bool respect_retry_after_header:",
            "        Whether to respect Retry-After header on status codes defined as",
            "        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.",
            "",
            "    :param iterable remove_headers_on_redirect:",
            "        Sequence of headers to remove from the request when a response",
            "        indicating a redirect is returned before firing off the redirected",
            "        request.",
            "    \"\"\"",
            "",
            "    DEFAULT_METHOD_WHITELIST = frozenset([",
            "        'HEAD', 'GET', 'PUT', 'DELETE', 'OPTIONS', 'TRACE'])",
            "",
            "    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])",
            "",
            "    DEFAULT_REDIRECT_HEADERS_BLACKLIST = frozenset(['Authorization'])",
            "",
            "    #: Maximum backoff time.",
            "    BACKOFF_MAX = 120",
            "",
            "    def __init__(self, total=10, connect=None, read=None, redirect=None, status=None,",
            "                 method_whitelist=DEFAULT_METHOD_WHITELIST, status_forcelist=None,",
            "                 backoff_factor=0, raise_on_redirect=True, raise_on_status=True,",
            "                 history=None, respect_retry_after_header=True,",
            "                 remove_headers_on_redirect=DEFAULT_REDIRECT_HEADERS_BLACKLIST):",
            "",
            "        self.total = total",
            "        self.connect = connect",
            "        self.read = read",
            "        self.status = status",
            "",
            "        if redirect is False or total is False:",
            "            redirect = 0",
            "            raise_on_redirect = False",
            "",
            "        self.redirect = redirect",
            "        self.status_forcelist = status_forcelist or set()",
            "        self.method_whitelist = method_whitelist",
            "        self.backoff_factor = backoff_factor",
            "        self.raise_on_redirect = raise_on_redirect",
            "        self.raise_on_status = raise_on_status",
            "        self.history = history or tuple()",
            "        self.respect_retry_after_header = respect_retry_after_header",
            "        self.remove_headers_on_redirect = frozenset([",
            "            h.lower() for h in remove_headers_on_redirect])",
            "",
            "    def new(self, **kw):",
            "        params = dict(",
            "            total=self.total,",
            "            connect=self.connect, read=self.read, redirect=self.redirect, status=self.status,",
            "            method_whitelist=self.method_whitelist,",
            "            status_forcelist=self.status_forcelist,",
            "            backoff_factor=self.backoff_factor,",
            "            raise_on_redirect=self.raise_on_redirect,",
            "            raise_on_status=self.raise_on_status,",
            "            history=self.history,",
            "            remove_headers_on_redirect=self.remove_headers_on_redirect",
            "        )",
            "        params.update(kw)",
            "        return type(self)(**params)",
            "",
            "    @classmethod",
            "    def from_int(cls, retries, redirect=True, default=None):",
            "        \"\"\" Backwards-compatibility for the old retries format.\"\"\"",
            "        if retries is None:",
            "            retries = default if default is not None else cls.DEFAULT",
            "",
            "        if isinstance(retries, Retry):",
            "            return retries",
            "",
            "        redirect = bool(redirect) and None",
            "        new_retries = cls(retries, redirect=redirect)",
            "        log.debug(\"Converted retries value: %r -> %r\", retries, new_retries)",
            "        return new_retries",
            "",
            "    def get_backoff_time(self):",
            "        \"\"\" Formula for computing the current backoff",
            "",
            "        :rtype: float",
            "        \"\"\"",
            "        # We want to consider only the last consecutive errors sequence (Ignore redirects).",
            "        consecutive_errors_len = len(list(takewhile(lambda x: x.redirect_location is None,",
            "                                                    reversed(self.history))))",
            "        if consecutive_errors_len <= 1:",
            "            return 0",
            "",
            "        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))",
            "        return min(self.BACKOFF_MAX, backoff_value)",
            "",
            "    def parse_retry_after(self, retry_after):",
            "        # Whitespace: https://tools.ietf.org/html/rfc7230#section-3.2.4",
            "        if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):",
            "            seconds = int(retry_after)",
            "        else:",
            "            retry_date_tuple = email.utils.parsedate(retry_after)",
            "            if retry_date_tuple is None:",
            "                raise InvalidHeader(\"Invalid Retry-After header: %s\" % retry_after)",
            "            retry_date = time.mktime(retry_date_tuple)",
            "            seconds = retry_date - time.time()",
            "",
            "        if seconds < 0:",
            "            seconds = 0",
            "",
            "        return seconds",
            "",
            "    def get_retry_after(self, response):",
            "        \"\"\" Get the value of Retry-After in seconds. \"\"\"",
            "",
            "        retry_after = response.getheader(\"Retry-After\")",
            "",
            "        if retry_after is None:",
            "            return None",
            "",
            "        return self.parse_retry_after(retry_after)",
            "",
            "    def sleep_for_retry(self, response=None):",
            "        retry_after = self.get_retry_after(response)",
            "        if retry_after:",
            "            time.sleep(retry_after)",
            "            return True",
            "",
            "        return False",
            "",
            "    def _sleep_backoff(self):",
            "        backoff = self.get_backoff_time()",
            "        if backoff <= 0:",
            "            return",
            "        time.sleep(backoff)",
            "",
            "    def sleep(self, response=None):",
            "        \"\"\" Sleep between retry attempts.",
            "",
            "        This method will respect a server's ``Retry-After`` response header",
            "        and sleep the duration of the time requested. If that is not present, it",
            "        will use an exponential backoff. By default, the backoff factor is 0 and",
            "        this method will return immediately.",
            "        \"\"\"",
            "",
            "        if response:",
            "            slept = self.sleep_for_retry(response)",
            "            if slept:",
            "                return",
            "",
            "        self._sleep_backoff()",
            "",
            "    def _is_connection_error(self, err):",
            "        \"\"\" Errors when we're fairly sure that the server did not receive the",
            "        request, so it should be safe to retry.",
            "        \"\"\"",
            "        return isinstance(err, ConnectTimeoutError)",
            "",
            "    def _is_read_error(self, err):",
            "        \"\"\" Errors that occur after the request has been started, so we should",
            "        assume that the server began processing it.",
            "        \"\"\"",
            "        return isinstance(err, (ReadTimeoutError, ProtocolError))",
            "",
            "    def _is_method_retryable(self, method):",
            "        \"\"\" Checks if a given HTTP method should be retried upon, depending if",
            "        it is included on the method whitelist.",
            "        \"\"\"",
            "        if self.method_whitelist and method.upper() not in self.method_whitelist:",
            "            return False",
            "",
            "        return True",
            "",
            "    def is_retry(self, method, status_code, has_retry_after=False):",
            "        \"\"\" Is this method/status code retryable? (Based on whitelists and control",
            "        variables such as the number of total retries to allow, whether to",
            "        respect the Retry-After header, whether this header is present, and",
            "        whether the returned status code is on the list of status codes to",
            "        be retried upon on the presence of the aforementioned header)",
            "        \"\"\"",
            "        if not self._is_method_retryable(method):",
            "            return False",
            "",
            "        if self.status_forcelist and status_code in self.status_forcelist:",
            "            return True",
            "",
            "        return (self.total and self.respect_retry_after_header and",
            "                has_retry_after and (status_code in self.RETRY_AFTER_STATUS_CODES))",
            "",
            "    def is_exhausted(self):",
            "        \"\"\" Are we out of retries? \"\"\"",
            "        retry_counts = (self.total, self.connect, self.read, self.redirect, self.status)",
            "        retry_counts = list(filter(None, retry_counts))",
            "        if not retry_counts:",
            "            return False",
            "",
            "        return min(retry_counts) < 0",
            "",
            "    def increment(self, method=None, url=None, response=None, error=None,",
            "                  _pool=None, _stacktrace=None):",
            "        \"\"\" Return a new Retry object with incremented retry counters.",
            "",
            "        :param response: A response object, or None, if the server did not",
            "            return a response.",
            "        :type response: :class:`~urllib3.response.HTTPResponse`",
            "        :param Exception error: An error encountered during the request, or",
            "            None if the response was received successfully.",
            "",
            "        :return: A new ``Retry`` object.",
            "        \"\"\"",
            "        if self.total is False and error:",
            "            # Disabled, indicate to re-raise the error.",
            "            raise six.reraise(type(error), error, _stacktrace)",
            "",
            "        total = self.total",
            "        if total is not None:",
            "            total -= 1",
            "",
            "        connect = self.connect",
            "        read = self.read",
            "        redirect = self.redirect",
            "        status_count = self.status",
            "        cause = 'unknown'",
            "        status = None",
            "        redirect_location = None",
            "",
            "        if error and self._is_connection_error(error):",
            "            # Connect retry?",
            "            if connect is False:",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif connect is not None:",
            "                connect -= 1",
            "",
            "        elif error and self._is_read_error(error):",
            "            # Read retry?",
            "            if read is False or not self._is_method_retryable(method):",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif read is not None:",
            "                read -= 1",
            "",
            "        elif response and response.get_redirect_location():",
            "            # Redirect retry?",
            "            if redirect is not None:",
            "                redirect -= 1",
            "            cause = 'too many redirects'",
            "            redirect_location = response.get_redirect_location()",
            "            status = response.status",
            "",
            "        else:",
            "            # Incrementing because of a server error like a 500 in",
            "            # status_forcelist and a the given method is in the whitelist",
            "            cause = ResponseError.GENERIC_ERROR",
            "            if response and response.status:",
            "                if status_count is not None:",
            "                    status_count -= 1",
            "                cause = ResponseError.SPECIFIC_ERROR.format(",
            "                    status_code=response.status)",
            "                status = response.status",
            "",
            "        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)",
            "",
            "        new_retry = self.new(",
            "            total=total,",
            "            connect=connect, read=read, redirect=redirect, status=status_count,",
            "            history=history)",
            "",
            "        if new_retry.is_exhausted():",
            "            raise MaxRetryError(_pool, url, error or ResponseError(cause))",
            "",
            "        log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)",
            "",
            "        return new_retry",
            "",
            "    def __repr__(self):",
            "        return ('{cls.__name__}(total={self.total}, connect={self.connect}, '",
            "                'read={self.read}, redirect={self.redirect}, status={self.status})').format(",
            "                    cls=type(self), self=self)",
            "",
            "",
            "# For backwards compatibility (equivalent to pre-v1.9):",
            "Retry.DEFAULT = Retry(3)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "182": [
                "Retry",
                "__init__"
            ]
        },
        "addLocation": []
    },
    "src/urllib3/util/ssl_.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": 327,
                "PatchRowcode": "             if e.errno == errno.ENOENT:"
            },
            "1": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 328,
                "PatchRowcode": "                 raise SSLError(e)"
            },
            "2": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": 329,
                "PatchRowcode": "             raise"
            },
            "3": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    elif getattr(context, 'load_default_certs', None) is not None:"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 330,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 331,
                "PatchRowcode": "+    # Don't load system certs unless there were no CA certs or"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 332,
                "PatchRowcode": "+    # SSLContext object specified manually."
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 333,
                "PatchRowcode": "+    elif ssl_context is None and hasattr(context, 'load_default_certs'):"
            },
            "8": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 334,
                "PatchRowcode": "         # try to load OS default certs; works well on Windows (require Python3.4+)"
            },
            "9": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 335,
                "PatchRowcode": "         context.load_default_certs()"
            },
            "10": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 336,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "from __future__ import absolute_import",
            "import errno",
            "import warnings",
            "import hmac",
            "import socket",
            "",
            "from binascii import hexlify, unhexlify",
            "from hashlib import md5, sha1, sha256",
            "",
            "from ..exceptions import SSLError, InsecurePlatformWarning, SNIMissingWarning",
            "from ..packages import six",
            "",
            "",
            "SSLContext = None",
            "HAS_SNI = False",
            "IS_PYOPENSSL = False",
            "IS_SECURETRANSPORT = False",
            "",
            "# Maps the length of a digest to a possible hash function producing this digest",
            "HASHFUNC_MAP = {",
            "    32: md5,",
            "    40: sha1,",
            "    64: sha256,",
            "}",
            "",
            "",
            "def _const_compare_digest_backport(a, b):",
            "    \"\"\"",
            "    Compare two digests of equal length in constant time.",
            "",
            "    The digests must be of type str/bytes.",
            "    Returns True if the digests match, and False otherwise.",
            "    \"\"\"",
            "    result = abs(len(a) - len(b))",
            "    for l, r in zip(bytearray(a), bytearray(b)):",
            "        result |= l ^ r",
            "    return result == 0",
            "",
            "",
            "_const_compare_digest = getattr(hmac, 'compare_digest',",
            "                                _const_compare_digest_backport)",
            "",
            "",
            "try:  # Test for SSL features",
            "    import ssl",
            "    from ssl import wrap_socket, CERT_NONE, PROTOCOL_SSLv23",
            "    from ssl import HAS_SNI  # Has SNI?",
            "except ImportError:",
            "    pass",
            "",
            "",
            "try:",
            "    from ssl import OP_NO_SSLv2, OP_NO_SSLv3, OP_NO_COMPRESSION",
            "except ImportError:",
            "    OP_NO_SSLv2, OP_NO_SSLv3 = 0x1000000, 0x2000000",
            "    OP_NO_COMPRESSION = 0x20000",
            "",
            "",
            "# Python 2.7 doesn't have inet_pton on non-Linux so we fallback on inet_aton in",
            "# those cases. This means that we can only detect IPv4 addresses in this case.",
            "if hasattr(socket, 'inet_pton'):",
            "    inet_pton = socket.inet_pton",
            "else:",
            "    # Maybe we can use ipaddress if the user has urllib3[secure]?",
            "    try:",
            "        import ipaddress",
            "",
            "        def inet_pton(_, host):",
            "            if isinstance(host, bytes):",
            "                host = host.decode('ascii')",
            "            return ipaddress.ip_address(host)",
            "",
            "    except ImportError:  # Platform-specific: Non-Linux",
            "        def inet_pton(_, host):",
            "            return socket.inet_aton(host)",
            "",
            "",
            "# A secure default.",
            "# Sources for more information on TLS ciphers:",
            "#",
            "# - https://wiki.mozilla.org/Security/Server_Side_TLS",
            "# - https://www.ssllabs.com/projects/best-practices/index.html",
            "# - https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/",
            "#",
            "# The general intent is:",
            "# - Prefer TLS 1.3 cipher suites",
            "# - prefer cipher suites that offer perfect forward secrecy (DHE/ECDHE),",
            "# - prefer ECDHE over DHE for better performance,",
            "# - prefer any AES-GCM and ChaCha20 over any AES-CBC for better performance and",
            "#   security,",
            "# - prefer AES-GCM over ChaCha20 because hardware-accelerated AES is common,",
            "# - disable NULL authentication, MD5 MACs and DSS for security reasons.",
            "DEFAULT_CIPHERS = ':'.join([",
            "    'TLS13-AES-256-GCM-SHA384',",
            "    'TLS13-CHACHA20-POLY1305-SHA256',",
            "    'TLS13-AES-128-GCM-SHA256',",
            "    'ECDH+AESGCM',",
            "    'ECDH+CHACHA20',",
            "    'DH+AESGCM',",
            "    'DH+CHACHA20',",
            "    'ECDH+AES256',",
            "    'DH+AES256',",
            "    'ECDH+AES128',",
            "    'DH+AES',",
            "    'RSA+AESGCM',",
            "    'RSA+AES',",
            "    '!aNULL',",
            "    '!eNULL',",
            "    '!MD5',",
            "])",
            "",
            "try:",
            "    from ssl import SSLContext  # Modern SSL?",
            "except ImportError:",
            "    import sys",
            "",
            "    class SSLContext(object):  # Platform-specific: Python 2",
            "        def __init__(self, protocol_version):",
            "            self.protocol = protocol_version",
            "            # Use default values from a real SSLContext",
            "            self.check_hostname = False",
            "            self.verify_mode = ssl.CERT_NONE",
            "            self.ca_certs = None",
            "            self.options = 0",
            "            self.certfile = None",
            "            self.keyfile = None",
            "            self.ciphers = None",
            "",
            "        def load_cert_chain(self, certfile, keyfile):",
            "            self.certfile = certfile",
            "            self.keyfile = keyfile",
            "",
            "        def load_verify_locations(self, cafile=None, capath=None):",
            "            self.ca_certs = cafile",
            "",
            "            if capath is not None:",
            "                raise SSLError(\"CA directories not supported in older Pythons\")",
            "",
            "        def set_ciphers(self, cipher_suite):",
            "            self.ciphers = cipher_suite",
            "",
            "        def wrap_socket(self, socket, server_hostname=None, server_side=False):",
            "            warnings.warn(",
            "                'A true SSLContext object is not available. This prevents '",
            "                'urllib3 from configuring SSL appropriately and may cause '",
            "                'certain SSL connections to fail. You can upgrade to a newer '",
            "                'version of Python to solve this. For more information, see '",
            "                'https://urllib3.readthedocs.io/en/latest/advanced-usage.html'",
            "                '#ssl-warnings',",
            "                InsecurePlatformWarning",
            "            )",
            "            kwargs = {",
            "                'keyfile': self.keyfile,",
            "                'certfile': self.certfile,",
            "                'ca_certs': self.ca_certs,",
            "                'cert_reqs': self.verify_mode,",
            "                'ssl_version': self.protocol,",
            "                'server_side': server_side,",
            "            }",
            "            return wrap_socket(socket, ciphers=self.ciphers, **kwargs)",
            "",
            "",
            "def assert_fingerprint(cert, fingerprint):",
            "    \"\"\"",
            "    Checks if given fingerprint matches the supplied certificate.",
            "",
            "    :param cert:",
            "        Certificate as bytes object.",
            "    :param fingerprint:",
            "        Fingerprint as string of hexdigits, can be interspersed by colons.",
            "    \"\"\"",
            "",
            "    fingerprint = fingerprint.replace(':', '').lower()",
            "    digest_length = len(fingerprint)",
            "    hashfunc = HASHFUNC_MAP.get(digest_length)",
            "    if not hashfunc:",
            "        raise SSLError(",
            "            'Fingerprint of invalid length: {0}'.format(fingerprint))",
            "",
            "    # We need encode() here for py32; works on py2 and p33.",
            "    fingerprint_bytes = unhexlify(fingerprint.encode())",
            "",
            "    cert_digest = hashfunc(cert).digest()",
            "",
            "    if not _const_compare_digest(cert_digest, fingerprint_bytes):",
            "        raise SSLError('Fingerprints did not match. Expected \"{0}\", got \"{1}\".'",
            "                       .format(fingerprint, hexlify(cert_digest)))",
            "",
            "",
            "def resolve_cert_reqs(candidate):",
            "    \"\"\"",
            "    Resolves the argument to a numeric constant, which can be passed to",
            "    the wrap_socket function/method from the ssl module.",
            "    Defaults to :data:`ssl.CERT_NONE`.",
            "    If given a string it is assumed to be the name of the constant in the",
            "    :mod:`ssl` module or its abbreviation.",
            "    (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.",
            "    If it's neither `None` nor a string we assume it is already the numeric",
            "    constant which can directly be passed to wrap_socket.",
            "    \"\"\"",
            "    if candidate is None:",
            "        return CERT_NONE",
            "",
            "    if isinstance(candidate, str):",
            "        res = getattr(ssl, candidate, None)",
            "        if res is None:",
            "            res = getattr(ssl, 'CERT_' + candidate)",
            "        return res",
            "",
            "    return candidate",
            "",
            "",
            "def resolve_ssl_version(candidate):",
            "    \"\"\"",
            "    like resolve_cert_reqs",
            "    \"\"\"",
            "    if candidate is None:",
            "        return PROTOCOL_SSLv23",
            "",
            "    if isinstance(candidate, str):",
            "        res = getattr(ssl, candidate, None)",
            "        if res is None:",
            "            res = getattr(ssl, 'PROTOCOL_' + candidate)",
            "        return res",
            "",
            "    return candidate",
            "",
            "",
            "def create_urllib3_context(ssl_version=None, cert_reqs=None,",
            "                           options=None, ciphers=None):",
            "    \"\"\"All arguments have the same meaning as ``ssl_wrap_socket``.",
            "",
            "    By default, this function does a lot of the same work that",
            "    ``ssl.create_default_context`` does on Python 3.4+. It:",
            "",
            "    - Disables SSLv2, SSLv3, and compression",
            "    - Sets a restricted set of server ciphers",
            "",
            "    If you wish to enable SSLv3, you can do::",
            "",
            "        from urllib3.util import ssl_",
            "        context = ssl_.create_urllib3_context()",
            "        context.options &= ~ssl_.OP_NO_SSLv3",
            "",
            "    You can do the same to enable compression (substituting ``COMPRESSION``",
            "    for ``SSLv3`` in the last line above).",
            "",
            "    :param ssl_version:",
            "        The desired protocol version to use. This will default to",
            "        PROTOCOL_SSLv23 which will negotiate the highest protocol that both",
            "        the server and your installation of OpenSSL support.",
            "    :param cert_reqs:",
            "        Whether to require the certificate verification. This defaults to",
            "        ``ssl.CERT_REQUIRED``.",
            "    :param options:",
            "        Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,",
            "        ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``.",
            "    :param ciphers:",
            "        Which cipher suites to allow the server to select.",
            "    :returns:",
            "        Constructed SSLContext object with specified options",
            "    :rtype: SSLContext",
            "    \"\"\"",
            "    context = SSLContext(ssl_version or ssl.PROTOCOL_SSLv23)",
            "",
            "    context.set_ciphers(ciphers or DEFAULT_CIPHERS)",
            "",
            "    # Setting the default here, as we may have no ssl module on import",
            "    cert_reqs = ssl.CERT_REQUIRED if cert_reqs is None else cert_reqs",
            "",
            "    if options is None:",
            "        options = 0",
            "        # SSLv2 is easily broken and is considered harmful and dangerous",
            "        options |= OP_NO_SSLv2",
            "        # SSLv3 has several problems and is now dangerous",
            "        options |= OP_NO_SSLv3",
            "        # Disable compression to prevent CRIME attacks for OpenSSL 1.0+",
            "        # (issue #309)",
            "        options |= OP_NO_COMPRESSION",
            "",
            "    context.options |= options",
            "",
            "    context.verify_mode = cert_reqs",
            "    if getattr(context, 'check_hostname', None) is not None:  # Platform-specific: Python 3.2",
            "        # We do our own verification, including fingerprints and alternative",
            "        # hostnames. So disable it here",
            "        context.check_hostname = False",
            "    return context",
            "",
            "",
            "def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,",
            "                    ca_certs=None, server_hostname=None,",
            "                    ssl_version=None, ciphers=None, ssl_context=None,",
            "                    ca_cert_dir=None):",
            "    \"\"\"",
            "    All arguments except for server_hostname, ssl_context, and ca_cert_dir have",
            "    the same meaning as they do when using :func:`ssl.wrap_socket`.",
            "",
            "    :param server_hostname:",
            "        When SNI is supported, the expected hostname of the certificate",
            "    :param ssl_context:",
            "        A pre-made :class:`SSLContext` object. If none is provided, one will",
            "        be created using :func:`create_urllib3_context`.",
            "    :param ciphers:",
            "        A string of ciphers we wish the client to support.",
            "    :param ca_cert_dir:",
            "        A directory containing CA certificates in multiple separate files, as",
            "        supported by OpenSSL's -CApath flag or the capath argument to",
            "        SSLContext.load_verify_locations().",
            "    \"\"\"",
            "    context = ssl_context",
            "    if context is None:",
            "        # Note: This branch of code and all the variables in it are no longer",
            "        # used by urllib3 itself. We should consider deprecating and removing",
            "        # this code.",
            "        context = create_urllib3_context(ssl_version, cert_reqs,",
            "                                         ciphers=ciphers)",
            "",
            "    if ca_certs or ca_cert_dir:",
            "        try:",
            "            context.load_verify_locations(ca_certs, ca_cert_dir)",
            "        except IOError as e:  # Platform-specific: Python 2.7",
            "            raise SSLError(e)",
            "        # Py33 raises FileNotFoundError which subclasses OSError",
            "        # These are not equivalent unless we check the errno attribute",
            "        except OSError as e:  # Platform-specific: Python 3.3 and beyond",
            "            if e.errno == errno.ENOENT:",
            "                raise SSLError(e)",
            "            raise",
            "    elif getattr(context, 'load_default_certs', None) is not None:",
            "        # try to load OS default certs; works well on Windows (require Python3.4+)",
            "        context.load_default_certs()",
            "",
            "    if certfile:",
            "        context.load_cert_chain(certfile, keyfile)",
            "",
            "    # If we detect server_hostname is an IP address then the SNI",
            "    # extension should not be used according to RFC3546 Section 3.1",
            "    # We shouldn't warn the user if SNI isn't available but we would",
            "    # not be using SNI anyways due to IP address for server_hostname.",
            "    if ((server_hostname is not None and not is_ipaddress(server_hostname))",
            "            or IS_SECURETRANSPORT):",
            "        if HAS_SNI and server_hostname is not None:",
            "            return context.wrap_socket(sock, server_hostname=server_hostname)",
            "",
            "        warnings.warn(",
            "            'An HTTPS request has been made, but the SNI (Server Name '",
            "            'Indication) extension to TLS is not available on this platform. '",
            "            'This may cause the server to present an incorrect TLS '",
            "            'certificate, which can cause validation failures. You can upgrade to '",
            "            'a newer version of Python to solve this. For more information, see '",
            "            'https://urllib3.readthedocs.io/en/latest/advanced-usage.html'",
            "            '#ssl-warnings',",
            "            SNIMissingWarning",
            "        )",
            "",
            "    return context.wrap_socket(sock)",
            "",
            "",
            "def is_ipaddress(hostname):",
            "    \"\"\"Detects whether the hostname given is an IP address.",
            "",
            "    :param str hostname: Hostname to examine.",
            "    :return: True if the hostname is an IP address, False otherwise.",
            "    \"\"\"",
            "    if six.PY3 and isinstance(hostname, bytes):",
            "        # IDN A-label bytes are ASCII compatible.",
            "        hostname = hostname.decode('ascii')",
            "",
            "    families = [socket.AF_INET]",
            "    if hasattr(socket, 'AF_INET6'):",
            "        families.append(socket.AF_INET6)",
            "",
            "    for af in families:",
            "        try:",
            "            inet_pton(af, hostname)",
            "        except (socket.error, ValueError, OSError):",
            "            pass",
            "        else:",
            "            return True",
            "    return False"
        ],
        "afterPatchFile": [
            "from __future__ import absolute_import",
            "import errno",
            "import warnings",
            "import hmac",
            "import socket",
            "",
            "from binascii import hexlify, unhexlify",
            "from hashlib import md5, sha1, sha256",
            "",
            "from ..exceptions import SSLError, InsecurePlatformWarning, SNIMissingWarning",
            "from ..packages import six",
            "",
            "",
            "SSLContext = None",
            "HAS_SNI = False",
            "IS_PYOPENSSL = False",
            "IS_SECURETRANSPORT = False",
            "",
            "# Maps the length of a digest to a possible hash function producing this digest",
            "HASHFUNC_MAP = {",
            "    32: md5,",
            "    40: sha1,",
            "    64: sha256,",
            "}",
            "",
            "",
            "def _const_compare_digest_backport(a, b):",
            "    \"\"\"",
            "    Compare two digests of equal length in constant time.",
            "",
            "    The digests must be of type str/bytes.",
            "    Returns True if the digests match, and False otherwise.",
            "    \"\"\"",
            "    result = abs(len(a) - len(b))",
            "    for l, r in zip(bytearray(a), bytearray(b)):",
            "        result |= l ^ r",
            "    return result == 0",
            "",
            "",
            "_const_compare_digest = getattr(hmac, 'compare_digest',",
            "                                _const_compare_digest_backport)",
            "",
            "",
            "try:  # Test for SSL features",
            "    import ssl",
            "    from ssl import wrap_socket, CERT_NONE, PROTOCOL_SSLv23",
            "    from ssl import HAS_SNI  # Has SNI?",
            "except ImportError:",
            "    pass",
            "",
            "",
            "try:",
            "    from ssl import OP_NO_SSLv2, OP_NO_SSLv3, OP_NO_COMPRESSION",
            "except ImportError:",
            "    OP_NO_SSLv2, OP_NO_SSLv3 = 0x1000000, 0x2000000",
            "    OP_NO_COMPRESSION = 0x20000",
            "",
            "",
            "# Python 2.7 doesn't have inet_pton on non-Linux so we fallback on inet_aton in",
            "# those cases. This means that we can only detect IPv4 addresses in this case.",
            "if hasattr(socket, 'inet_pton'):",
            "    inet_pton = socket.inet_pton",
            "else:",
            "    # Maybe we can use ipaddress if the user has urllib3[secure]?",
            "    try:",
            "        import ipaddress",
            "",
            "        def inet_pton(_, host):",
            "            if isinstance(host, bytes):",
            "                host = host.decode('ascii')",
            "            return ipaddress.ip_address(host)",
            "",
            "    except ImportError:  # Platform-specific: Non-Linux",
            "        def inet_pton(_, host):",
            "            return socket.inet_aton(host)",
            "",
            "",
            "# A secure default.",
            "# Sources for more information on TLS ciphers:",
            "#",
            "# - https://wiki.mozilla.org/Security/Server_Side_TLS",
            "# - https://www.ssllabs.com/projects/best-practices/index.html",
            "# - https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/",
            "#",
            "# The general intent is:",
            "# - Prefer TLS 1.3 cipher suites",
            "# - prefer cipher suites that offer perfect forward secrecy (DHE/ECDHE),",
            "# - prefer ECDHE over DHE for better performance,",
            "# - prefer any AES-GCM and ChaCha20 over any AES-CBC for better performance and",
            "#   security,",
            "# - prefer AES-GCM over ChaCha20 because hardware-accelerated AES is common,",
            "# - disable NULL authentication, MD5 MACs and DSS for security reasons.",
            "DEFAULT_CIPHERS = ':'.join([",
            "    'TLS13-AES-256-GCM-SHA384',",
            "    'TLS13-CHACHA20-POLY1305-SHA256',",
            "    'TLS13-AES-128-GCM-SHA256',",
            "    'ECDH+AESGCM',",
            "    'ECDH+CHACHA20',",
            "    'DH+AESGCM',",
            "    'DH+CHACHA20',",
            "    'ECDH+AES256',",
            "    'DH+AES256',",
            "    'ECDH+AES128',",
            "    'DH+AES',",
            "    'RSA+AESGCM',",
            "    'RSA+AES',",
            "    '!aNULL',",
            "    '!eNULL',",
            "    '!MD5',",
            "])",
            "",
            "try:",
            "    from ssl import SSLContext  # Modern SSL?",
            "except ImportError:",
            "    import sys",
            "",
            "    class SSLContext(object):  # Platform-specific: Python 2",
            "        def __init__(self, protocol_version):",
            "            self.protocol = protocol_version",
            "            # Use default values from a real SSLContext",
            "            self.check_hostname = False",
            "            self.verify_mode = ssl.CERT_NONE",
            "            self.ca_certs = None",
            "            self.options = 0",
            "            self.certfile = None",
            "            self.keyfile = None",
            "            self.ciphers = None",
            "",
            "        def load_cert_chain(self, certfile, keyfile):",
            "            self.certfile = certfile",
            "            self.keyfile = keyfile",
            "",
            "        def load_verify_locations(self, cafile=None, capath=None):",
            "            self.ca_certs = cafile",
            "",
            "            if capath is not None:",
            "                raise SSLError(\"CA directories not supported in older Pythons\")",
            "",
            "        def set_ciphers(self, cipher_suite):",
            "            self.ciphers = cipher_suite",
            "",
            "        def wrap_socket(self, socket, server_hostname=None, server_side=False):",
            "            warnings.warn(",
            "                'A true SSLContext object is not available. This prevents '",
            "                'urllib3 from configuring SSL appropriately and may cause '",
            "                'certain SSL connections to fail. You can upgrade to a newer '",
            "                'version of Python to solve this. For more information, see '",
            "                'https://urllib3.readthedocs.io/en/latest/advanced-usage.html'",
            "                '#ssl-warnings',",
            "                InsecurePlatformWarning",
            "            )",
            "            kwargs = {",
            "                'keyfile': self.keyfile,",
            "                'certfile': self.certfile,",
            "                'ca_certs': self.ca_certs,",
            "                'cert_reqs': self.verify_mode,",
            "                'ssl_version': self.protocol,",
            "                'server_side': server_side,",
            "            }",
            "            return wrap_socket(socket, ciphers=self.ciphers, **kwargs)",
            "",
            "",
            "def assert_fingerprint(cert, fingerprint):",
            "    \"\"\"",
            "    Checks if given fingerprint matches the supplied certificate.",
            "",
            "    :param cert:",
            "        Certificate as bytes object.",
            "    :param fingerprint:",
            "        Fingerprint as string of hexdigits, can be interspersed by colons.",
            "    \"\"\"",
            "",
            "    fingerprint = fingerprint.replace(':', '').lower()",
            "    digest_length = len(fingerprint)",
            "    hashfunc = HASHFUNC_MAP.get(digest_length)",
            "    if not hashfunc:",
            "        raise SSLError(",
            "            'Fingerprint of invalid length: {0}'.format(fingerprint))",
            "",
            "    # We need encode() here for py32; works on py2 and p33.",
            "    fingerprint_bytes = unhexlify(fingerprint.encode())",
            "",
            "    cert_digest = hashfunc(cert).digest()",
            "",
            "    if not _const_compare_digest(cert_digest, fingerprint_bytes):",
            "        raise SSLError('Fingerprints did not match. Expected \"{0}\", got \"{1}\".'",
            "                       .format(fingerprint, hexlify(cert_digest)))",
            "",
            "",
            "def resolve_cert_reqs(candidate):",
            "    \"\"\"",
            "    Resolves the argument to a numeric constant, which can be passed to",
            "    the wrap_socket function/method from the ssl module.",
            "    Defaults to :data:`ssl.CERT_NONE`.",
            "    If given a string it is assumed to be the name of the constant in the",
            "    :mod:`ssl` module or its abbreviation.",
            "    (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.",
            "    If it's neither `None` nor a string we assume it is already the numeric",
            "    constant which can directly be passed to wrap_socket.",
            "    \"\"\"",
            "    if candidate is None:",
            "        return CERT_NONE",
            "",
            "    if isinstance(candidate, str):",
            "        res = getattr(ssl, candidate, None)",
            "        if res is None:",
            "            res = getattr(ssl, 'CERT_' + candidate)",
            "        return res",
            "",
            "    return candidate",
            "",
            "",
            "def resolve_ssl_version(candidate):",
            "    \"\"\"",
            "    like resolve_cert_reqs",
            "    \"\"\"",
            "    if candidate is None:",
            "        return PROTOCOL_SSLv23",
            "",
            "    if isinstance(candidate, str):",
            "        res = getattr(ssl, candidate, None)",
            "        if res is None:",
            "            res = getattr(ssl, 'PROTOCOL_' + candidate)",
            "        return res",
            "",
            "    return candidate",
            "",
            "",
            "def create_urllib3_context(ssl_version=None, cert_reqs=None,",
            "                           options=None, ciphers=None):",
            "    \"\"\"All arguments have the same meaning as ``ssl_wrap_socket``.",
            "",
            "    By default, this function does a lot of the same work that",
            "    ``ssl.create_default_context`` does on Python 3.4+. It:",
            "",
            "    - Disables SSLv2, SSLv3, and compression",
            "    - Sets a restricted set of server ciphers",
            "",
            "    If you wish to enable SSLv3, you can do::",
            "",
            "        from urllib3.util import ssl_",
            "        context = ssl_.create_urllib3_context()",
            "        context.options &= ~ssl_.OP_NO_SSLv3",
            "",
            "    You can do the same to enable compression (substituting ``COMPRESSION``",
            "    for ``SSLv3`` in the last line above).",
            "",
            "    :param ssl_version:",
            "        The desired protocol version to use. This will default to",
            "        PROTOCOL_SSLv23 which will negotiate the highest protocol that both",
            "        the server and your installation of OpenSSL support.",
            "    :param cert_reqs:",
            "        Whether to require the certificate verification. This defaults to",
            "        ``ssl.CERT_REQUIRED``.",
            "    :param options:",
            "        Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,",
            "        ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``.",
            "    :param ciphers:",
            "        Which cipher suites to allow the server to select.",
            "    :returns:",
            "        Constructed SSLContext object with specified options",
            "    :rtype: SSLContext",
            "    \"\"\"",
            "    context = SSLContext(ssl_version or ssl.PROTOCOL_SSLv23)",
            "",
            "    context.set_ciphers(ciphers or DEFAULT_CIPHERS)",
            "",
            "    # Setting the default here, as we may have no ssl module on import",
            "    cert_reqs = ssl.CERT_REQUIRED if cert_reqs is None else cert_reqs",
            "",
            "    if options is None:",
            "        options = 0",
            "        # SSLv2 is easily broken and is considered harmful and dangerous",
            "        options |= OP_NO_SSLv2",
            "        # SSLv3 has several problems and is now dangerous",
            "        options |= OP_NO_SSLv3",
            "        # Disable compression to prevent CRIME attacks for OpenSSL 1.0+",
            "        # (issue #309)",
            "        options |= OP_NO_COMPRESSION",
            "",
            "    context.options |= options",
            "",
            "    context.verify_mode = cert_reqs",
            "    if getattr(context, 'check_hostname', None) is not None:  # Platform-specific: Python 3.2",
            "        # We do our own verification, including fingerprints and alternative",
            "        # hostnames. So disable it here",
            "        context.check_hostname = False",
            "    return context",
            "",
            "",
            "def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,",
            "                    ca_certs=None, server_hostname=None,",
            "                    ssl_version=None, ciphers=None, ssl_context=None,",
            "                    ca_cert_dir=None):",
            "    \"\"\"",
            "    All arguments except for server_hostname, ssl_context, and ca_cert_dir have",
            "    the same meaning as they do when using :func:`ssl.wrap_socket`.",
            "",
            "    :param server_hostname:",
            "        When SNI is supported, the expected hostname of the certificate",
            "    :param ssl_context:",
            "        A pre-made :class:`SSLContext` object. If none is provided, one will",
            "        be created using :func:`create_urllib3_context`.",
            "    :param ciphers:",
            "        A string of ciphers we wish the client to support.",
            "    :param ca_cert_dir:",
            "        A directory containing CA certificates in multiple separate files, as",
            "        supported by OpenSSL's -CApath flag or the capath argument to",
            "        SSLContext.load_verify_locations().",
            "    \"\"\"",
            "    context = ssl_context",
            "    if context is None:",
            "        # Note: This branch of code and all the variables in it are no longer",
            "        # used by urllib3 itself. We should consider deprecating and removing",
            "        # this code.",
            "        context = create_urllib3_context(ssl_version, cert_reqs,",
            "                                         ciphers=ciphers)",
            "",
            "    if ca_certs or ca_cert_dir:",
            "        try:",
            "            context.load_verify_locations(ca_certs, ca_cert_dir)",
            "        except IOError as e:  # Platform-specific: Python 2.7",
            "            raise SSLError(e)",
            "        # Py33 raises FileNotFoundError which subclasses OSError",
            "        # These are not equivalent unless we check the errno attribute",
            "        except OSError as e:  # Platform-specific: Python 3.3 and beyond",
            "            if e.errno == errno.ENOENT:",
            "                raise SSLError(e)",
            "            raise",
            "",
            "    # Don't load system certs unless there were no CA certs or",
            "    # SSLContext object specified manually.",
            "    elif ssl_context is None and hasattr(context, 'load_default_certs'):",
            "        # try to load OS default certs; works well on Windows (require Python3.4+)",
            "        context.load_default_certs()",
            "",
            "    if certfile:",
            "        context.load_cert_chain(certfile, keyfile)",
            "",
            "    # If we detect server_hostname is an IP address then the SNI",
            "    # extension should not be used according to RFC3546 Section 3.1",
            "    # We shouldn't warn the user if SNI isn't available but we would",
            "    # not be using SNI anyways due to IP address for server_hostname.",
            "    if ((server_hostname is not None and not is_ipaddress(server_hostname))",
            "            or IS_SECURETRANSPORT):",
            "        if HAS_SNI and server_hostname is not None:",
            "            return context.wrap_socket(sock, server_hostname=server_hostname)",
            "",
            "        warnings.warn(",
            "            'An HTTPS request has been made, but the SNI (Server Name '",
            "            'Indication) extension to TLS is not available on this platform. '",
            "            'This may cause the server to present an incorrect TLS '",
            "            'certificate, which can cause validation failures. You can upgrade to '",
            "            'a newer version of Python to solve this. For more information, see '",
            "            'https://urllib3.readthedocs.io/en/latest/advanced-usage.html'",
            "            '#ssl-warnings',",
            "            SNIMissingWarning",
            "        )",
            "",
            "    return context.wrap_socket(sock)",
            "",
            "",
            "def is_ipaddress(hostname):",
            "    \"\"\"Detects whether the hostname given is an IP address.",
            "",
            "    :param str hostname: Hostname to examine.",
            "    :return: True if the hostname is an IP address, False otherwise.",
            "    \"\"\"",
            "    if six.PY3 and isinstance(hostname, bytes):",
            "        # IDN A-label bytes are ASCII compatible.",
            "        hostname = hostname.decode('ascii')",
            "",
            "    families = [socket.AF_INET]",
            "    if hasattr(socket, 'AF_INET6'):",
            "        families.append(socket.AF_INET6)",
            "",
            "    for af in families:",
            "        try:",
            "            inet_pton(af, hostname)",
            "        except (socket.error, ValueError, OSError):",
            "            pass",
            "        else:",
            "            return True",
            "    return False"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "330": [
                "ssl_wrap_socket"
            ]
        },
        "addLocation": []
    }
}