{
    "src/sentry/api/serializers/models/group.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 72,
                "PatchRowcode": "         dict1.setdefault(key, []).extend(val)"
            },
            "1": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 73,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 74,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+class GroupAnnotation(TypedDict):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+    displayName: str"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+    url: str"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 80,
                "PatchRowcode": " class GroupStatusDetailsResponseOptional(TypedDict, total=False):"
            },
            "9": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "     autoResolved: bool"
            },
            "10": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "     ignoreCount: int"
            },
            "11": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "     isSubscribed: bool"
            },
            "12": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "     subscriptionDetails: GroupSubscriptionResponseOptional | None"
            },
            "13": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "     hasSeen: bool"
            },
            "14": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    annotations: Sequence[str]"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+    annotations: Sequence[GroupAnnotation]"
            },
            "16": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 154,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 155,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 156,
                "PatchRowcode": " class SeenStats(TypedDict):"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "import itertools",
            "import logging",
            "from abc import ABC, abstractmethod",
            "from collections import defaultdict",
            "from collections.abc import Callable, Iterable, Mapping, MutableMapping, Sequence",
            "from datetime import datetime, timedelta, timezone",
            "from typing import Any, Protocol, TypedDict",
            "",
            "import sentry_sdk",
            "from django.conf import settings",
            "from django.db.models import Min, prefetch_related_objects",
            "",
            "from sentry import features, tagstore",
            "from sentry.api.serializers import Serializer, register, serialize",
            "from sentry.api.serializers.models.actor import ActorSerializer",
            "from sentry.api.serializers.models.plugin import is_plugin_deprecated",
            "from sentry.api.serializers.models.user import UserSerializerResponse",
            "from sentry.app import env",
            "from sentry.auth.services.auth import AuthenticatedToken",
            "from sentry.auth.superuser import is_active_superuser",
            "from sentry.constants import LOG_LEVELS",
            "from sentry.integrations.services.integration import integration_service",
            "from sentry.issues.grouptype import GroupCategory",
            "from sentry.models.apitoken import is_api_token_auth",
            "from sentry.models.commit import Commit",
            "from sentry.models.environment import Environment",
            "from sentry.models.group import Group, GroupStatus",
            "from sentry.models.groupassignee import GroupAssignee",
            "from sentry.models.groupbookmark import GroupBookmark",
            "from sentry.models.groupenvironment import GroupEnvironment",
            "from sentry.models.grouplink import GroupLink",
            "from sentry.models.groupmeta import GroupMeta",
            "from sentry.models.groupresolution import GroupResolution",
            "from sentry.models.groupseen import GroupSeen",
            "from sentry.models.groupshare import GroupShare",
            "from sentry.models.groupsnooze import GroupSnooze",
            "from sentry.models.groupsubscription import GroupSubscription",
            "from sentry.models.organizationmember import OrganizationMember",
            "from sentry.models.orgauthtoken import is_org_auth_token_auth",
            "from sentry.models.team import Team",
            "from sentry.models.user import User",
            "from sentry.notifications.helpers import collect_groups_by_project, get_subscription_from_attributes",
            "from sentry.notifications.services import notifications_service",
            "from sentry.notifications.types import NotificationSettingEnum",
            "from sentry.reprocessing2 import get_progress",
            "from sentry.search.events.constants import RELEASE_STAGE_ALIAS",
            "from sentry.search.events.filter import convert_search_filter_to_snuba_query, format_search_filter",
            "from sentry.snuba.dataset import Dataset",
            "from sentry.tagstore.snuba.backend import fix_tag_value_data",
            "from sentry.tagstore.types import GroupTagValue",
            "from sentry.tsdb.snuba import SnubaTSDB",
            "from sentry.types.group import SUBSTATUS_TO_STR, PriorityLevel",
            "from sentry.users.services.user.serial import serialize_generic_user",
            "from sentry.users.services.user.service import user_service",
            "from sentry.utils.cache import cache",
            "from sentry.utils.safe import safe_execute",
            "from sentry.utils.snuba import aliased_query, raw_query",
            "",
            "# TODO(jess): remove when snuba is primary backend",
            "snuba_tsdb = SnubaTSDB(**settings.SENTRY_TSDB_OPTIONS)",
            "",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def merge_list_dictionaries(",
            "    dict1: MutableMapping[Any, list[Any]], dict2: Mapping[Any, Sequence[Any]]",
            "):",
            "    for key, val in dict2.items():",
            "        dict1.setdefault(key, []).extend(val)",
            "",
            "",
            "class GroupStatusDetailsResponseOptional(TypedDict, total=False):",
            "    autoResolved: bool",
            "    ignoreCount: int",
            "    ignoreUntil: datetime",
            "    ignoreUserCount: int",
            "    ignoreUserWindow: int",
            "    ignoreWindow: int",
            "    actor: UserSerializerResponse",
            "    inNextRelease: bool",
            "    inRelease: str",
            "    inCommit: str",
            "    pendingEvents: int",
            "    info: Any",
            "",
            "",
            "class GroupStatusDetailsResponse(GroupStatusDetailsResponseOptional):",
            "    pass",
            "",
            "",
            "class GroupProjectResponse(TypedDict):",
            "    id: str",
            "    name: str",
            "    slug: str",
            "    platform: str",
            "",
            "",
            "class GroupMetadataResponseOptional(TypedDict, total=False):",
            "    type: str",
            "    filename: str",
            "    function: str",
            "",
            "",
            "class GroupMetadataResponse(GroupMetadataResponseOptional):",
            "    value: str",
            "    display_title_with_tree_label: bool",
            "",
            "",
            "class GroupSubscriptionResponseOptional(TypedDict, total=False):",
            "    disabled: bool",
            "    reason: str",
            "",
            "",
            "class BaseGroupResponseOptional(TypedDict, total=False):",
            "    isUnhandled: bool",
            "    count: int",
            "    userCount: int",
            "    firstSeen: datetime",
            "    lastSeen: datetime",
            "",
            "",
            "class BaseGroupSerializerResponse(BaseGroupResponseOptional):",
            "    id: str",
            "    shareId: str",
            "    shortId: str",
            "    title: str",
            "    culprit: str",
            "    permalink: str",
            "    logger: str | None",
            "    level: str",
            "    status: str",
            "    statusDetails: GroupStatusDetailsResponseOptional",
            "    isPublic: bool",
            "    platform: str",
            "    priority: str",
            "    project: GroupProjectResponse",
            "    type: str",
            "    metadata: GroupMetadataResponse",
            "    numComments: int",
            "    assignedTo: UserSerializerResponse",
            "    isBookmarked: bool",
            "    isSubscribed: bool",
            "    subscriptionDetails: GroupSubscriptionResponseOptional | None",
            "    hasSeen: bool",
            "    annotations: Sequence[str]",
            "",
            "",
            "class SeenStats(TypedDict):",
            "    times_seen: int",
            "    first_seen: datetime | None",
            "    last_seen: datetime | None",
            "    user_count: int",
            "",
            "",
            "class GroupSerializerBase(Serializer, ABC):",
            "    def __init__(",
            "        self,",
            "        collapse=None,",
            "        expand=None,",
            "    ):",
            "        self.collapse = collapse",
            "        self.expand = expand",
            "",
            "    def _serialize_assignees(self, item_list: Sequence[Group]) -> Mapping[int, Team | Any]:",
            "        gas = GroupAssignee.objects.filter(group__in=item_list)",
            "        result: MutableMapping[int, Team | Any] = {}",
            "        all_team_ids: MutableMapping[int, set[int]] = defaultdict(set)",
            "        all_user_ids: MutableMapping[int, set[int]] = defaultdict(set)",
            "",
            "        for g in gas:",
            "            if g.team_id:",
            "                all_team_ids[g.team_id].add(g.group_id)",
            "            if g.user_id:",
            "                all_user_ids[g.user_id].add(g.group_id)",
            "",
            "        for team in Team.objects.filter(id__in=all_team_ids.keys()):",
            "            for group_id in all_team_ids[team.id]:",
            "                result[group_id] = team",
            "        for user in user_service.get_many_by_id(ids=list(all_user_ids.keys())):",
            "            for group_id in all_user_ids[user.id]:",
            "                result[group_id] = user",
            "",
            "        return result",
            "",
            "    def get_attrs(",
            "        self, item_list: Sequence[Group], user: Any, **kwargs: Any",
            "    ) -> MutableMapping[Group, MutableMapping[str, Any]]:",
            "        GroupMeta.objects.populate_cache(item_list)",
            "",
            "        # Note that organization is necessary here for use in `_get_permalink` to avoid",
            "        # making unnecessary queries.",
            "        prefetch_related_objects(item_list, \"project__organization\")",
            "",
            "        if user.is_authenticated and item_list:",
            "            bookmarks = set(",
            "                GroupBookmark.objects.filter(user_id=user.id, group__in=item_list).values_list(",
            "                    \"group_id\", flat=True",
            "                )",
            "            )",
            "            seen_groups = dict(",
            "                GroupSeen.objects.filter(user_id=user.id, group__in=item_list).values_list(",
            "                    \"group_id\", \"last_seen\"",
            "                )",
            "            )",
            "            subscriptions = self._get_subscriptions(item_list, user)",
            "        else:",
            "            bookmarks = set()",
            "            seen_groups = {}",
            "            subscriptions = defaultdict(lambda: (False, False, None))",
            "",
            "        resolved_assignees = self._serialize_assignees(item_list)",
            "",
            "        ignore_items = {g.group_id: g for g in GroupSnooze.objects.filter(group__in=item_list)}",
            "",
            "        release_resolutions, commit_resolutions = self._resolve_resolutions(item_list, user)",
            "",
            "        user_ids = {",
            "            user_id",
            "            for user_id in itertools.chain(",
            "                (r[-1] for r in release_resolutions.values()),",
            "                (r.actor_id for r in ignore_items.values()),",
            "            )",
            "            if user_id is not None",
            "        }",
            "        if user_ids:",
            "            serialized_users = user_service.serialize_many(",
            "                filter={\"user_ids\": user_ids, \"is_active\": True},",
            "                as_user=serialize_generic_user(user),",
            "            )",
            "            actors = {id: u for id, u in zip(user_ids, serialized_users)}",
            "        else:",
            "            actors = {}",
            "",
            "        share_ids = dict(",
            "            GroupShare.objects.filter(group__in=item_list).values_list(\"group_id\", \"uuid\")",
            "        )",
            "",
            "        seen_stats = self._get_seen_stats(item_list, user)",
            "",
            "        organization_id_list = list({item.project.organization_id for item in item_list})",
            "        # if no groups, then we can't proceed but this seems to be a valid use case",
            "        if not item_list:",
            "            return {}",
            "        if len(organization_id_list) > 1:",
            "            # this should never happen but if it does we should know about it",
            "            logger.warning(",
            "                \"Found multiple organizations for groups: %s, with orgs: %s\",",
            "                [item.id for item in item_list],",
            "                organization_id_list,",
            "            )",
            "",
            "        # should only have 1 org at this point",
            "        organization_id = organization_id_list[0]",
            "",
            "        authorized = self._is_authorized(user, organization_id)",
            "",
            "        annotations_by_group_id: MutableMapping[int, list[Any]] = defaultdict(list)",
            "        for annotations_by_group in itertools.chain.from_iterable(",
            "            [",
            "                self._resolve_integration_annotations(organization_id, item_list),",
            "                [self._resolve_external_issue_annotations(item_list)],",
            "            ]",
            "        ):",
            "            merge_list_dictionaries(annotations_by_group_id, annotations_by_group)",
            "",
            "        snuba_stats = self._get_group_snuba_stats(item_list, seen_stats)",
            "",
            "        result = {}",
            "        for item in item_list:",
            "            active_date = item.active_at or item.first_seen",
            "",
            "            resolution_actor = None",
            "            resolution_type = None",
            "            resolution = release_resolutions.get(item.id)",
            "            if resolution:",
            "                resolution_type = \"release\"",
            "                resolution_actor = actors.get(resolution[-1])",
            "            if not resolution:",
            "                resolution = commit_resolutions.get(item.id)",
            "                if resolution:",
            "                    resolution_type = \"commit\"",
            "",
            "            ignore_item = ignore_items.get(item.id)",
            "",
            "            result[item] = {",
            "                \"id\": item.id,",
            "                \"assigned_to\": resolved_assignees.get(item.id),",
            "                \"is_bookmarked\": item.id in bookmarks,",
            "                \"subscription\": subscriptions[item.id],",
            "                \"has_seen\": seen_groups.get(item.id, active_date) > active_date,",
            "                \"annotations\": self._resolve_and_extend_plugin_annotation(",
            "                    item, annotations_by_group_id[item.id]",
            "                ),",
            "                \"ignore_until\": ignore_item,",
            "                \"ignore_actor\": actors.get(ignore_item.actor_id) if ignore_item else None,",
            "                \"resolution\": resolution,",
            "                \"resolution_type\": resolution_type,",
            "                \"resolution_actor\": resolution_actor,",
            "                \"share_id\": share_ids.get(item.id),",
            "                \"authorized\": authorized,",
            "            }",
            "            if snuba_stats is not None:",
            "                result[item][\"is_unhandled\"] = bool(snuba_stats.get(item.id, {}).get(\"unhandled\"))",
            "",
            "            if seen_stats:",
            "                result[item].update(seen_stats.get(item, {}))",
            "        return result",
            "",
            "    def serialize(",
            "        self, obj: Group, attrs: MutableMapping[str, Any], user: Any, **kwargs: Any",
            "    ) -> BaseGroupSerializerResponse:",
            "        status_details, status_label = self._get_status(attrs, obj)",
            "        permalink = self._get_permalink(attrs, obj)",
            "        is_subscribed, subscription_details = get_subscription_from_attributes(attrs)",
            "        share_id = attrs[\"share_id\"]",
            "        group_dict = {",
            "            \"id\": str(obj.id),",
            "            \"shareId\": share_id,",
            "            \"shortId\": obj.qualified_short_id,",
            "            \"title\": obj.title,",
            "            \"culprit\": obj.culprit,",
            "            \"permalink\": permalink,",
            "            \"logger\": obj.logger or None,",
            "            \"level\": LOG_LEVELS.get(obj.level, \"unknown\"),",
            "            \"status\": status_label,",
            "            \"statusDetails\": status_details,",
            "            \"substatus\": SUBSTATUS_TO_STR[obj.substatus] if obj.substatus else None,",
            "            \"isPublic\": share_id is not None,",
            "            \"platform\": obj.platform,",
            "            \"project\": {",
            "                \"id\": str(obj.project.id),",
            "                \"name\": obj.project.name,",
            "                \"slug\": obj.project.slug,",
            "                \"platform\": obj.project.platform,",
            "            },",
            "            \"type\": obj.get_event_type(),",
            "            \"metadata\": obj.get_event_metadata(),",
            "            \"numComments\": obj.num_comments,",
            "            \"assignedTo\": serialize(attrs[\"assigned_to\"], user, ActorSerializer()),",
            "            \"isBookmarked\": attrs[\"is_bookmarked\"],",
            "            \"isSubscribed\": is_subscribed,",
            "            \"subscriptionDetails\": subscription_details,",
            "            \"hasSeen\": attrs[\"has_seen\"],",
            "            \"annotations\": attrs[\"annotations\"],",
            "            \"issueType\": obj.issue_type.slug,",
            "            \"issueCategory\": obj.issue_category.name.lower(),",
            "        }",
            "",
            "        priority_label = PriorityLevel(obj.priority).to_str() if obj.priority else None",
            "        group_dict[\"priority\"] = priority_label",
            "        group_dict[\"priorityLockedAt\"] = obj.priority_locked_at",
            "",
            "        # This attribute is currently feature gated",
            "        if \"is_unhandled\" in attrs:",
            "            group_dict[\"isUnhandled\"] = attrs[\"is_unhandled\"]",
            "        if \"times_seen\" in attrs:",
            "            group_dict.update(self._convert_seen_stats(attrs))",
            "        return group_dict",
            "",
            "    @abstractmethod",
            "    def _seen_stats_error(",
            "        self, error_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        pass",
            "",
            "    @abstractmethod",
            "    def _seen_stats_generic(",
            "        self, generic_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        pass",
            "",
            "    def _expand(self, key) -> bool:",
            "        if self.expand is None:",
            "            return False",
            "",
            "        return key in self.expand",
            "",
            "    def _collapse(self, key) -> bool:",
            "        if self.collapse is None:",
            "            return False",
            "        return key in self.collapse",
            "",
            "    def _get_status(self, attrs: MutableMapping[str, Any], obj: Group):",
            "        status = obj.status",
            "        status_details = {}",
            "        if attrs[\"ignore_until\"]:",
            "            snooze = attrs[\"ignore_until\"]",
            "            if snooze.is_valid(group=obj):",
            "                # counts return the delta remaining when window is not set",
            "                status_details.update(",
            "                    {",
            "                        \"ignoreCount\": (",
            "                            snooze.count - (obj.times_seen - snooze.state[\"times_seen\"])",
            "                            if snooze.count and not snooze.window",
            "                            else snooze.count",
            "                        ),",
            "                        \"ignoreUntil\": snooze.until,",
            "                        \"ignoreUserCount\": (",
            "                            snooze.user_count - (attrs[\"user_count\"] - snooze.state[\"users_seen\"])",
            "                            if snooze.user_count",
            "                            and not snooze.user_window",
            "                            and not self._collapse(\"stats\")",
            "                            else snooze.user_count",
            "                        ),",
            "                        \"ignoreUserWindow\": snooze.user_window,",
            "                        \"ignoreWindow\": snooze.window,",
            "                        \"actor\": attrs[\"ignore_actor\"],",
            "                    }",
            "                )",
            "            else:",
            "                status = GroupStatus.UNRESOLVED",
            "        if status == GroupStatus.UNRESOLVED and obj.is_over_resolve_age():",
            "            # When an issue is over the auto-resolve age but the task has not yet run",
            "            status = GroupStatus.RESOLVED",
            "            status_details[\"autoResolved\"] = True",
            "        if status == GroupStatus.RESOLVED:",
            "            status_label = \"resolved\"",
            "            if attrs[\"resolution_type\"] == \"release\":",
            "                res_type, res_version, _ = attrs[\"resolution\"]",
            "                if res_type in (GroupResolution.Type.in_next_release, None):",
            "                    status_details[\"inNextRelease\"] = True",
            "                elif res_type == GroupResolution.Type.in_release:",
            "                    status_details[\"inRelease\"] = res_version",
            "                status_details[\"actor\"] = attrs[\"resolution_actor\"]",
            "            elif attrs[\"resolution_type\"] == \"commit\":",
            "                status_details[\"inCommit\"] = attrs[\"resolution\"]",
            "        elif status == GroupStatus.IGNORED:",
            "            status_label = \"ignored\"",
            "        elif status in [GroupStatus.PENDING_DELETION, GroupStatus.DELETION_IN_PROGRESS]:",
            "            status_label = \"pending_deletion\"",
            "        elif status == GroupStatus.PENDING_MERGE:",
            "            status_label = \"pending_merge\"",
            "        elif status == GroupStatus.REPROCESSING:",
            "            status_label = \"reprocessing\"",
            "            status_details[\"pendingEvents\"], status_details[\"info\"] = get_progress(",
            "                attrs[\"id\"], obj.project.id",
            "            )",
            "        else:",
            "            status_label = \"unresolved\"",
            "        return status_details, status_label",
            "",
            "    def _get_seen_stats(self, item_list: Sequence[Group], user) -> Mapping[Group, SeenStats] | None:",
            "        \"\"\"",
            "        Returns a dictionary keyed by item that includes:",
            "            - times_seen",
            "            - first_seen",
            "            - last_seen",
            "            - user_count",
            "        \"\"\"",
            "        if self._collapse(\"stats\"):",
            "            return None",
            "",
            "        if not item_list:",
            "            return None",
            "",
            "        # partition the item_list by type",
            "        error_issues = [group for group in item_list if GroupCategory.ERROR == group.issue_category]",
            "        generic_issues = [",
            "            group for group in item_list if group.issue_category != GroupCategory.ERROR",
            "        ]",
            "",
            "        # bulk query for the seen_stats by type",
            "        error_stats = (self._seen_stats_error(error_issues, user) if error_issues else {}) or {}",
            "        generic_stats = (",
            "            self._seen_stats_generic(generic_issues, user) if generic_issues else {}",
            "        ) or {}",
            "        agg_stats = {**error_stats, **generic_stats}",
            "        # combine results back",
            "        return {group: agg_stats.get(group, {}) for group in item_list}",
            "",
            "    def _get_group_snuba_stats(",
            "        self, item_list: Sequence[Group], seen_stats: Mapping[Group, SeenStats] | None",
            "    ):",
            "        if (",
            "            self._collapse(\"unhandled\")",
            "            and len(item_list) > 0",
            "            and features.has(",
            "                \"organizations:issue-stream-performance\", item_list[0].project.organization",
            "            )",
            "        ):",
            "            return None",
            "        start = self._get_start_from_seen_stats(seen_stats)",
            "        unhandled = {}",
            "",
            "        cache_keys = []",
            "        for item in item_list:",
            "            cache_keys.append(f\"group-mechanism-handled:{item.id}\")",
            "",
            "        cache_data = cache.get_many(cache_keys)",
            "        for item, cache_key in zip(item_list, cache_keys):",
            "            unhandled[item.id] = cache_data.get(cache_key)",
            "",
            "        filter_keys = {}",
            "        for item in item_list:",
            "            if unhandled.get(item.id) is not None:",
            "                continue",
            "            filter_keys.setdefault(\"project_id\", []).append(item.project_id)",
            "            filter_keys.setdefault(\"group_id\", []).append(item.id)",
            "",
            "        if filter_keys:",
            "            rv = raw_query(",
            "                dataset=Dataset.Events,",
            "                selected_columns=[",
            "                    \"group_id\",",
            "                    [",
            "                        \"argMax\",",
            "                        [[\"has\", [\"exception_stacks.mechanism_handled\", 0]], \"timestamp\"],",
            "                        \"unhandled\",",
            "                    ],",
            "                ],",
            "                groupby=[\"group_id\"],",
            "                filter_keys=filter_keys,",
            "                start=start,",
            "                orderby=\"group_id\",",
            "                referrer=\"group.unhandled-flag\",",
            "                tenant_ids=(",
            "                    {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "                ),",
            "            )",
            "            for x in rv[\"data\"]:",
            "                unhandled[x[\"group_id\"]] = x[\"unhandled\"]",
            "",
            "                # cache the handled flag for 60 seconds.  This is broadly in line with",
            "                # the time we give for buffer flushes so the user experience is somewhat",
            "                # consistent here.",
            "                cache.set(\"group-mechanism-handled:%d\" % x[\"group_id\"], x[\"unhandled\"], 60)",
            "",
            "        return {group_id: {\"unhandled\": unhandled} for group_id, unhandled in unhandled.items()}",
            "",
            "    @staticmethod",
            "    def _get_start_from_seen_stats(seen_stats: Mapping[Group, SeenStats] | None):",
            "        # Try to figure out what is a reasonable time frame to look into stats,",
            "        # based on a given \"seen stats\".  We try to pick a day prior to the earliest last seen,",
            "        # but it has to be at least 14 days, and not more than 90 days ago.",
            "        # Fallback to the 30 days ago if we are not able to calculate the value.",
            "        last_seen = None",
            "        if seen_stats:",
            "            for item in seen_stats.values():",
            "                if last_seen is None or (item[\"last_seen\"] and last_seen > item[\"last_seen\"]):",
            "                    last_seen = item[\"last_seen\"]",
            "",
            "        if last_seen is None:",
            "            return datetime.now(timezone.utc) - timedelta(days=30)",
            "",
            "        return max(",
            "            min(last_seen - timedelta(days=1), datetime.now(timezone.utc) - timedelta(days=14)),",
            "            datetime.now(timezone.utc) - timedelta(days=90),",
            "        )",
            "",
            "    @staticmethod",
            "    def _get_subscriptions(",
            "        groups: Iterable[Group], user: User",
            "    ) -> Mapping[int, tuple[bool, bool, GroupSubscription | None]]:",
            "        \"\"\"",
            "        Returns a mapping of group IDs to a two-tuple of (is_disabled: bool,",
            "        subscribed: bool, subscription: Optional[GroupSubscription]) for the",
            "        provided user and groups.",
            "",
            "        Returns:",
            "            Mapping[int, Tuple[bool, bool, Optional[GroupSubscription]]]: A mapping of group IDs to",
            "            a tuple of (is_disabled: bool, subscribed: bool, subscription: Optional[GroupSubscription])",
            "        \"\"\"",
            "        if not groups:",
            "            return {}",
            "",
            "        groups_by_project = collect_groups_by_project(groups)",
            "        project_ids = list(groups_by_project.keys())",
            "        enabled_settings = notifications_service.subscriptions_for_projects(",
            "            user_id=user.id, project_ids=project_ids, type=NotificationSettingEnum.WORKFLOW",
            "        )",
            "        query_groups = {",
            "            group",
            "            for group in groups",
            "            if (not enabled_settings[group.project_id].has_only_inactive_subscriptions)",
            "        }",
            "        subscriptions_by_group_id: dict[int, GroupSubscription] = {",
            "            subscription.group_id: subscription",
            "            for subscription in GroupSubscription.objects.filter(",
            "                group__in=query_groups, user_id=user.id",
            "            )",
            "        }",
            "        groups_by_project = collect_groups_by_project(groups)",
            "",
            "        results = {}",
            "        for project_id, group_set in groups_by_project.items():",
            "            subscription_status = enabled_settings[project_id]",
            "            for group in group_set:",
            "                subscription = subscriptions_by_group_id.get(group.id)",
            "                if subscription:",
            "                    # Having a GroupSubscription overrides NotificationSettings.",
            "                    results[group.id] = (False, subscription.is_active, subscription)",
            "                elif subscription_status.is_disabled:",
            "                    # The user has disabled notifications in all cases.",
            "                    results[group.id] = (True, False, None)",
            "                else:",
            "                    # Since there is no subscription, it is only active if the value is ALWAYS.",
            "                    results[group.id] = (False, subscription_status.is_active, None)",
            "",
            "        return results",
            "",
            "    @staticmethod",
            "    def _resolve_resolutions(",
            "        groups: Sequence[Group], user",
            "    ) -> tuple[Mapping[int, Sequence[Any]], Mapping[int, Any]]:",
            "        resolved_groups = [i for i in groups if i.status == GroupStatus.RESOLVED]",
            "        if not resolved_groups:",
            "            return {}, {}",
            "",
            "        _release_resolutions = {",
            "            i[0]: i[1:]",
            "            for i in GroupResolution.objects.filter(group__in=resolved_groups).values_list(",
            "                \"group\", \"type\", \"release__version\", \"actor_id\"",
            "            )",
            "        }",
            "",
            "        # due to our laziness, and django's inability to do a reasonable join here",
            "        # we end up with two queries",
            "        commit_results = list(",
            "            Commit.objects.extra(",
            "                select={\"group_id\": \"sentry_grouplink.group_id\"},",
            "                tables=[\"sentry_grouplink\"],",
            "                where=[",
            "                    \"sentry_grouplink.linked_id = sentry_commit.id\",",
            "                    \"sentry_grouplink.group_id IN ({})\".format(",
            "                        \", \".join(str(i.id) for i in resolved_groups)",
            "                    ),",
            "                    \"sentry_grouplink.linked_type = %s\",",
            "                    \"sentry_grouplink.relationship = %s\",",
            "                ],",
            "                params=[int(GroupLink.LinkedType.commit), int(GroupLink.Relationship.resolves)],",
            "            )",
            "        )",
            "        _commit_resolutions = {",
            "            i.group_id: d for i, d in zip(commit_results, serialize(commit_results, user))",
            "        }",
            "",
            "        return _release_resolutions, _commit_resolutions",
            "",
            "    @staticmethod",
            "    def _resolve_external_issue_annotations(groups: Sequence[Group]) -> Mapping[int, Sequence[Any]]:",
            "        from sentry.models.platformexternalissue import PlatformExternalIssue",
            "",
            "        # find the external issues for sentry apps and add them in",
            "        return (",
            "            safe_execute(PlatformExternalIssue.get_annotations_for_group_list, group_list=groups)",
            "            or {}",
            "        )",
            "",
            "    @staticmethod",
            "    def _resolve_integration_annotations(",
            "        org_id: int, groups: Sequence[Group]",
            "    ) -> Sequence[Mapping[int, Sequence[Any]]]:",
            "        from sentry.integrations.base import IntegrationFeatures",
            "",
            "        integration_annotations = []",
            "        # find all the integration installs that have issue tracking",
            "        integrations = integration_service.get_integrations(organization_id=org_id)",
            "        for integration in integrations:",
            "            if not (",
            "                integration.has_feature(feature=IntegrationFeatures.ISSUE_BASIC)",
            "                or integration.has_feature(feature=IntegrationFeatures.ISSUE_SYNC)",
            "            ):",
            "                continue",
            "",
            "            install = integration.get_installation(organization_id=org_id)",
            "            local_annotations_by_group_id = (",
            "                safe_execute(install.get_annotations_for_group_list, group_list=groups) or {}",
            "            )",
            "            integration_annotations.append(local_annotations_by_group_id)",
            "",
            "        return integration_annotations",
            "",
            "    @staticmethod",
            "    def _resolve_and_extend_plugin_annotation(",
            "        item: Group, current_annotations: list[Any]",
            "    ) -> Sequence[Any]:",
            "        from sentry.plugins.base import plugins",
            "",
            "        annotations_for_group = []",
            "        annotations_for_group.extend(current_annotations)",
            "",
            "        # add the annotations for plugins",
            "        # note that the model GroupMeta(where all the information is stored) is already cached at the start of",
            "        # `get_attrs`, so these for loops doesn't make a bunch of queries",
            "        for plugin in plugins.for_project(project=item.project, version=1):",
            "            if is_plugin_deprecated(plugin, item.project):",
            "                continue",
            "            safe_execute(plugin.tags, None, item, annotations_for_group)",
            "        for plugin in plugins.for_project(project=item.project, version=2):",
            "            annotations_for_group.extend(safe_execute(plugin.get_annotations, group=item) or ())",
            "",
            "        return annotations_for_group",
            "",
            "    @staticmethod",
            "    def _is_authorized(user, organization_id: int):",
            "        # If user is not logged in and member of the organization,",
            "        # do not return the permalink which contains private information i.e. org name.",
            "        request = env.request",
            "        if request and is_active_superuser(request) and request.user.id == user.id:",
            "            return True",
            "",
            "        # If user is a sentry_app then it's a proxy user meaning we can't do a org lookup via `get_orgs()`",
            "        # because the user isn't an org member. Instead we can use the auth token and the installation",
            "        # it's associated with to find out what organization the token has access to.",
            "        if (",
            "            request",
            "            and getattr(request.user, \"is_sentry_app\", False)",
            "            and is_api_token_auth(request.auth)",
            "        ):",
            "            if AuthenticatedToken.from_token(request.auth).token_has_org_access(organization_id):",
            "                return True",
            "",
            "        if (",
            "            request",
            "            and user.is_anonymous",
            "            and hasattr(request, \"auth\")",
            "            and is_org_auth_token_auth(request.auth)",
            "        ):",
            "            return request.auth.organization_id == organization_id",
            "",
            "        return (",
            "            user.is_authenticated",
            "            and OrganizationMember.objects.filter(",
            "                user_id=user.id, organization_id=organization_id",
            "            ).exists()",
            "        )",
            "",
            "    @staticmethod",
            "    def _get_permalink(attrs, obj: Group):",
            "        if attrs[\"authorized\"]:",
            "            with sentry_sdk.start_span(op=\"GroupSerializerBase.serialize.permalink.build\"):",
            "                return obj.get_absolute_url()",
            "        else:",
            "            return None",
            "",
            "    @staticmethod",
            "    def _convert_seen_stats(attrs: SeenStats):",
            "        return {",
            "            \"count\": str(attrs[\"times_seen\"]),",
            "            \"userCount\": attrs[\"user_count\"],",
            "            \"firstSeen\": attrs[\"first_seen\"],",
            "            \"lastSeen\": attrs[\"last_seen\"],",
            "        }",
            "",
            "",
            "@register(Group)",
            "class GroupSerializer(GroupSerializerBase):",
            "    class GroupUserCountsFunc(Protocol):",
            "        def __call__(",
            "            self,",
            "            project_ids: Sequence[int],",
            "            item_ids: Sequence[int],",
            "            environment_ids: Sequence[int] | None,",
            "        ) -> Mapping[int, int]:",
            "            pass",
            "",
            "    def __init__(self, environment_func: Callable[[], Environment] | None = None):",
            "        GroupSerializerBase.__init__(self)",
            "        self.environment_func = environment_func if environment_func is not None else lambda: None",
            "",
            "    def _seen_stats_error(self, item_list, user) -> Mapping[Group, SeenStats]:",
            "        return self.__seen_stats_impl(",
            "            item_list,",
            "            tagstore.backend.get_groups_user_counts,",
            "            tagstore.backend.get_group_list_tag_value,",
            "        )",
            "",
            "    def _seen_stats_generic(",
            "        self, generic_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        return self.__seen_stats_impl(",
            "            generic_issue_list,",
            "            tagstore.backend.get_generic_groups_user_counts,",
            "            tagstore.backend.get_generic_group_list_tag_value,",
            "        )",
            "",
            "    def __seen_stats_impl(",
            "        self,",
            "        issue_list: Sequence[Group],",
            "        user_counts_func: GroupUserCountsFunc,",
            "        environment_seen_stats_func: Callable[",
            "            [Sequence[int], Sequence[int], Sequence[int], str, str], Mapping[int, GroupTagValue]",
            "        ],",
            "    ) -> Mapping[Group, SeenStats]:",
            "        if not issue_list:",
            "            return {}",
            "        try:",
            "            environment = self.environment_func()",
            "        except Environment.DoesNotExist:",
            "            return {",
            "                item: {\"times_seen\": 0, \"first_seen\": None, \"last_seen\": None, \"user_count\": 0}",
            "                for item in issue_list",
            "            }",
            "",
            "        project_id = issue_list[0].project_id",
            "        item_ids = [g.id for g in issue_list]",
            "        tenant_ids = {\"organization_id\": issue_list[0].project.organization_id}",
            "        user_counts: Mapping[int, int] = user_counts_func(",
            "            [project_id],",
            "            item_ids,",
            "            environment_ids=environment and [environment.id],",
            "            tenant_ids=tenant_ids,",
            "        )",
            "        first_seen: MutableMapping[int, datetime] = {}",
            "        last_seen: MutableMapping[int, datetime] = {}",
            "        times_seen: MutableMapping[int, int] = {}",
            "",
            "        if environment is not None:",
            "            environment_seen_stats = environment_seen_stats_func(",
            "                [project_id],",
            "                item_ids,",
            "                [environment.id],",
            "                \"environment\",",
            "                environment.name,",
            "                tenant_ids=tenant_ids,",
            "            )",
            "            for item_id, value in environment_seen_stats.items():",
            "                first_seen[item_id] = value.first_seen",
            "                last_seen[item_id] = value.last_seen",
            "                times_seen[item_id] = value.times_seen",
            "        else:",
            "            # fallback to the model data since we can't query tagstore",
            "            for item in issue_list:",
            "                first_seen[item.id] = item.first_seen",
            "                last_seen[item.id] = item.last_seen",
            "                times_seen[item.id] = item.times_seen",
            "",
            "        return {",
            "            item: {",
            "                \"times_seen\": times_seen.get(item.id, 0),",
            "                \"first_seen\": first_seen.get(item.id),",
            "                \"last_seen\": last_seen.get(item.id),",
            "                \"user_count\": user_counts.get(item.id, 0),",
            "            }",
            "            for item in issue_list",
            "        }",
            "",
            "",
            "class SharedGroupSerializer(GroupSerializer):",
            "    def serialize(",
            "        self, obj: Group, attrs: MutableMapping[str, Any], user: Any, **kwargs: Any",
            "    ) -> BaseGroupSerializerResponse:",
            "        result = super().serialize(obj, attrs, user)",
            "",
            "        ALLOWED_FIELDS = [",
            "            \"culprit\",",
            "            \"id\",",
            "            \"isUnhandled\",",
            "            \"issueCategory\",",
            "            \"permalink\",",
            "            \"shortId\",",
            "            \"title\",",
            "        ]",
            "        result = {k: v for (k, v) in result.items() if k in ALLOWED_FIELDS}",
            "",
            "        # avoids a circular import",
            "        from sentry.api.serializers.models import SharedEventSerializer, SharedProjectSerializer",
            "",
            "        event = obj.get_latest_event()",
            "        result[\"latestEvent\"] = serialize(event, user, SharedEventSerializer())",
            "",
            "        result[\"project\"] = serialize(obj.project, user, SharedProjectSerializer())",
            "",
            "        return result",
            "",
            "",
            "SKIP_SNUBA_FIELDS = frozenset(",
            "    (",
            "        \"status\",",
            "        \"substatus\",",
            "        \"bookmarked_by\",",
            "        \"assigned_to\",",
            "        \"for_review\",",
            "        \"assigned_or_suggested\",",
            "        \"unassigned\",",
            "        \"linked\",",
            "        \"subscribed_by\",",
            "        \"first_release\",",
            "        \"first_seen\",",
            "        \"issue.category\",",
            "        \"issue.priority\",",
            "        \"issue.type\",",
            "    )",
            ")",
            "",
            "",
            "class GroupSerializerSnuba(GroupSerializerBase):",
            "    skip_snuba_fields = {",
            "        *SKIP_SNUBA_FIELDS,",
            "        \"last_seen\",",
            "        \"times_seen\",",
            "        \"date\",",
            "        \"timestamp\",  # We merge this with start/end, so don't want to include it as its own",
            "        # condition",
            "        # We don't need to filter by release stage again here since we're",
            "        # filtering to specific groups. Saves us making a second query to",
            "        # postgres for no reason",
            "        RELEASE_STAGE_ALIAS,",
            "    }",
            "",
            "    def __init__(",
            "        self,",
            "        environment_ids=None,",
            "        start: datetime | None = None,",
            "        end: datetime | None = None,",
            "        search_filters=None,",
            "        collapse=None,",
            "        expand=None,",
            "        organization_id=None,",
            "        project_ids=None,",
            "    ):",
            "        super().__init__(collapse=collapse, expand=expand)",
            "        from sentry.search.snuba.executors import get_search_filter",
            "",
            "        self.environment_ids = environment_ids",
            "        self.organization_id = organization_id",
            "        # XXX: We copy this logic from `PostgresSnubaQueryExecutor.query`. Ideally we",
            "        # should try and encapsulate this logic, but if you're changing this, change it",
            "        # there as well.",
            "        self.start = None",
            "        start_params = [",
            "            _f",
            "            for _f in [",
            "                start,",
            "                get_search_filter(search_filters, \"date\", \">\"),",
            "                get_search_filter(search_filters, \"timestamp\", \">\"),",
            "            ]",
            "            if _f",
            "        ]",
            "        if start_params:",
            "            self.start = max(_f for _f in start_params if _f)",
            "",
            "        self.end = None",
            "        end_params = [",
            "            _f",
            "            for _f in [",
            "                end,",
            "                get_search_filter(search_filters, \"date\", \"<\"),",
            "                get_search_filter(search_filters, \"timestamp\", \"<\"),",
            "            ]",
            "            if _f",
            "        ]",
            "        if end_params:",
            "            self.end = min(end_params)",
            "",
            "        conditions = []",
            "        if search_filters is not None:",
            "            for search_filter in search_filters:",
            "                if search_filter.key.name not in self.skip_snuba_fields:",
            "                    formatted_conditions, projects_to_filter, group_ids = format_search_filter(",
            "                        search_filter,",
            "                        params={",
            "                            \"organization_id\": organization_id,",
            "                            \"project_id\": project_ids,",
            "                            \"environment_id\": environment_ids,",
            "                        },",
            "                    )",
            "",
            "                    # if no re-formatted conditions, use fallback method",
            "                    new_condition = None",
            "                    if formatted_conditions:",
            "                        new_condition = formatted_conditions[0]",
            "                    elif group_ids:",
            "                        new_condition = convert_search_filter_to_snuba_query(",
            "                            search_filter,",
            "                            params={",
            "                                \"organization_id\": organization_id,",
            "                                \"project_id\": project_ids,",
            "                                \"environment_id\": environment_ids,",
            "                            },",
            "                        )",
            "",
            "                    if new_condition:",
            "                        conditions.append(new_condition)",
            "        self.conditions = conditions",
            "",
            "    def _seen_stats_error(",
            "        self, error_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        return self._parse_seen_stats_results(",
            "            self._execute_error_seen_stats_query(",
            "                item_list=error_issue_list,",
            "                start=self.start,",
            "                end=self.end,",
            "                conditions=self.conditions,",
            "                environment_ids=self.environment_ids,",
            "            ),",
            "            error_issue_list,",
            "            bool(self.start or self.end or self.conditions),",
            "            self.environment_ids,",
            "        )",
            "",
            "    def _seen_stats_generic(",
            "        self, generic_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        return self._parse_seen_stats_results(",
            "            self._execute_generic_seen_stats_query(",
            "                item_list=generic_issue_list,",
            "                start=self.start,",
            "                end=self.end,",
            "                conditions=self.conditions,",
            "                environment_ids=self.environment_ids,",
            "            ),",
            "            generic_issue_list,",
            "            bool(self.start or self.end or self.conditions),",
            "            self.environment_ids,",
            "        )",
            "",
            "    @staticmethod",
            "    def _execute_error_seen_stats_query(",
            "        item_list, start=None, end=None, conditions=None, environment_ids=None",
            "    ):",
            "        project_ids = list({item.project_id for item in item_list})",
            "        group_ids = [item.id for item in item_list]",
            "        aggregations = [",
            "            [\"count()\", \"\", \"times_seen\"],",
            "            [\"min\", \"timestamp\", \"first_seen\"],",
            "            [\"max\", \"timestamp\", \"last_seen\"],",
            "            [\"uniq\", \"tags[sentry:user]\", \"count\"],",
            "        ]",
            "        filters = {\"project_id\": project_ids, \"group_id\": group_ids}",
            "        if environment_ids:",
            "            filters[\"environment\"] = environment_ids",
            "",
            "        return aliased_query(",
            "            dataset=Dataset.Events,",
            "            start=start,",
            "            end=end,",
            "            groupby=[\"group_id\"],",
            "            conditions=conditions,",
            "            filter_keys=filters,",
            "            aggregations=aggregations,",
            "            referrer=\"serializers.GroupSerializerSnuba._execute_error_seen_stats_query\",",
            "            tenant_ids=(",
            "                {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "            ),",
            "        )",
            "",
            "    @staticmethod",
            "    def _execute_perf_seen_stats_query(",
            "        item_list, start=None, end=None, conditions=None, environment_ids=None",
            "    ):",
            "        project_ids = list({item.project_id for item in item_list})",
            "        group_ids = [item.id for item in item_list]",
            "        aggregations = [",
            "            [\"arrayJoin\", [\"group_ids\"], \"group_id\"],",
            "            [\"count()\", \"\", \"times_seen\"],",
            "            [\"min\", \"timestamp\", \"first_seen\"],",
            "            [\"max\", \"timestamp\", \"last_seen\"],",
            "            [\"uniq\", \"tags[sentry:user]\", \"count\"],",
            "        ]",
            "        filters = {\"project_id\": project_ids}",
            "        if environment_ids:",
            "            filters[\"environment\"] = environment_ids",
            "        return aliased_query(",
            "            dataset=Dataset.Transactions,",
            "            start=start,",
            "            end=end,",
            "            groupby=[\"group_id\"],",
            "            conditions=[",
            "                [[\"hasAny\", [\"group_ids\", [\"array\", group_ids]]], \"=\", 1],",
            "            ]",
            "            + (conditions or []),",
            "            filter_keys=filters,",
            "            aggregations=aggregations,",
            "            referrer=\"serializers.GroupSerializerSnuba._execute_perf_seen_stats_query\",",
            "            tenant_ids=(",
            "                {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "            ),",
            "        )",
            "",
            "    @staticmethod",
            "    def _execute_generic_seen_stats_query(",
            "        item_list, start=None, end=None, conditions=None, environment_ids=None",
            "    ):",
            "        project_ids = list({item.project_id for item in item_list})",
            "        group_ids = [item.id for item in item_list]",
            "        aggregations = [",
            "            [\"count()\", \"\", \"times_seen\"],",
            "            [\"min\", \"timestamp\", \"first_seen\"],",
            "            [\"max\", \"timestamp\", \"last_seen\"],",
            "            [\"uniq\", \"tags[sentry:user]\", \"count\"],",
            "        ]",
            "        filters = {\"project_id\": project_ids, \"group_id\": group_ids}",
            "        if environment_ids:",
            "            filters[\"environment\"] = environment_ids",
            "        return aliased_query(",
            "            dataset=Dataset.IssuePlatform,",
            "            start=start,",
            "            end=end,",
            "            groupby=[\"group_id\"],",
            "            conditions=conditions,",
            "            filter_keys=filters,",
            "            aggregations=aggregations,",
            "            referrer=\"serializers.GroupSerializerSnuba._execute_generic_seen_stats_query\",",
            "            tenant_ids=(",
            "                {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "            ),",
            "        )",
            "",
            "    @staticmethod",
            "    def _parse_seen_stats_results(",
            "        result, item_list, use_result_first_seen_times_seen, environment_ids=None",
            "    ):",
            "        seen_data = {",
            "            issue[\"group_id\"]: fix_tag_value_data(",
            "                dict(filter(lambda key: key[0] != \"group_id\", issue.items()))",
            "            )",
            "            for issue in result[\"data\"]",
            "        }",
            "        user_counts = {item_id: value[\"count\"] for item_id, value in seen_data.items()}",
            "        last_seen = {item_id: value[\"last_seen\"] for item_id, value in seen_data.items()}",
            "        if use_result_first_seen_times_seen:",
            "            first_seen = {item_id: value[\"first_seen\"] for item_id, value in seen_data.items()}",
            "            times_seen = {item_id: value[\"times_seen\"] for item_id, value in seen_data.items()}",
            "        else:",
            "            if environment_ids:",
            "                first_seen = {",
            "                    ge[\"group_id\"]: ge[\"first_seen__min\"]",
            "                    for ge in GroupEnvironment.objects.filter(",
            "                        group_id__in=[item.id for item in item_list],",
            "                        environment_id__in=environment_ids,",
            "                    )",
            "                    .values(\"group_id\")",
            "                    .annotate(Min(\"first_seen\"))",
            "                }",
            "            else:",
            "                first_seen = {item.id: item.first_seen for item in item_list}",
            "            times_seen = {item.id: item.times_seen for item in item_list}",
            "",
            "        return {",
            "            item: {",
            "                \"times_seen\": times_seen.get(item.id, 0),",
            "                \"first_seen\": first_seen.get(item.id),",
            "                \"last_seen\": last_seen.get(item.id),",
            "                \"user_count\": user_counts.get(item.id, 0),",
            "            }",
            "            for item in item_list",
            "        }"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "import itertools",
            "import logging",
            "from abc import ABC, abstractmethod",
            "from collections import defaultdict",
            "from collections.abc import Callable, Iterable, Mapping, MutableMapping, Sequence",
            "from datetime import datetime, timedelta, timezone",
            "from typing import Any, Protocol, TypedDict",
            "",
            "import sentry_sdk",
            "from django.conf import settings",
            "from django.db.models import Min, prefetch_related_objects",
            "",
            "from sentry import features, tagstore",
            "from sentry.api.serializers import Serializer, register, serialize",
            "from sentry.api.serializers.models.actor import ActorSerializer",
            "from sentry.api.serializers.models.plugin import is_plugin_deprecated",
            "from sentry.api.serializers.models.user import UserSerializerResponse",
            "from sentry.app import env",
            "from sentry.auth.services.auth import AuthenticatedToken",
            "from sentry.auth.superuser import is_active_superuser",
            "from sentry.constants import LOG_LEVELS",
            "from sentry.integrations.services.integration import integration_service",
            "from sentry.issues.grouptype import GroupCategory",
            "from sentry.models.apitoken import is_api_token_auth",
            "from sentry.models.commit import Commit",
            "from sentry.models.environment import Environment",
            "from sentry.models.group import Group, GroupStatus",
            "from sentry.models.groupassignee import GroupAssignee",
            "from sentry.models.groupbookmark import GroupBookmark",
            "from sentry.models.groupenvironment import GroupEnvironment",
            "from sentry.models.grouplink import GroupLink",
            "from sentry.models.groupmeta import GroupMeta",
            "from sentry.models.groupresolution import GroupResolution",
            "from sentry.models.groupseen import GroupSeen",
            "from sentry.models.groupshare import GroupShare",
            "from sentry.models.groupsnooze import GroupSnooze",
            "from sentry.models.groupsubscription import GroupSubscription",
            "from sentry.models.organizationmember import OrganizationMember",
            "from sentry.models.orgauthtoken import is_org_auth_token_auth",
            "from sentry.models.team import Team",
            "from sentry.models.user import User",
            "from sentry.notifications.helpers import collect_groups_by_project, get_subscription_from_attributes",
            "from sentry.notifications.services import notifications_service",
            "from sentry.notifications.types import NotificationSettingEnum",
            "from sentry.reprocessing2 import get_progress",
            "from sentry.search.events.constants import RELEASE_STAGE_ALIAS",
            "from sentry.search.events.filter import convert_search_filter_to_snuba_query, format_search_filter",
            "from sentry.snuba.dataset import Dataset",
            "from sentry.tagstore.snuba.backend import fix_tag_value_data",
            "from sentry.tagstore.types import GroupTagValue",
            "from sentry.tsdb.snuba import SnubaTSDB",
            "from sentry.types.group import SUBSTATUS_TO_STR, PriorityLevel",
            "from sentry.users.services.user.serial import serialize_generic_user",
            "from sentry.users.services.user.service import user_service",
            "from sentry.utils.cache import cache",
            "from sentry.utils.safe import safe_execute",
            "from sentry.utils.snuba import aliased_query, raw_query",
            "",
            "# TODO(jess): remove when snuba is primary backend",
            "snuba_tsdb = SnubaTSDB(**settings.SENTRY_TSDB_OPTIONS)",
            "",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def merge_list_dictionaries(",
            "    dict1: MutableMapping[Any, list[Any]], dict2: Mapping[Any, Sequence[Any]]",
            "):",
            "    for key, val in dict2.items():",
            "        dict1.setdefault(key, []).extend(val)",
            "",
            "",
            "class GroupAnnotation(TypedDict):",
            "    displayName: str",
            "    url: str",
            "",
            "",
            "class GroupStatusDetailsResponseOptional(TypedDict, total=False):",
            "    autoResolved: bool",
            "    ignoreCount: int",
            "    ignoreUntil: datetime",
            "    ignoreUserCount: int",
            "    ignoreUserWindow: int",
            "    ignoreWindow: int",
            "    actor: UserSerializerResponse",
            "    inNextRelease: bool",
            "    inRelease: str",
            "    inCommit: str",
            "    pendingEvents: int",
            "    info: Any",
            "",
            "",
            "class GroupStatusDetailsResponse(GroupStatusDetailsResponseOptional):",
            "    pass",
            "",
            "",
            "class GroupProjectResponse(TypedDict):",
            "    id: str",
            "    name: str",
            "    slug: str",
            "    platform: str",
            "",
            "",
            "class GroupMetadataResponseOptional(TypedDict, total=False):",
            "    type: str",
            "    filename: str",
            "    function: str",
            "",
            "",
            "class GroupMetadataResponse(GroupMetadataResponseOptional):",
            "    value: str",
            "    display_title_with_tree_label: bool",
            "",
            "",
            "class GroupSubscriptionResponseOptional(TypedDict, total=False):",
            "    disabled: bool",
            "    reason: str",
            "",
            "",
            "class BaseGroupResponseOptional(TypedDict, total=False):",
            "    isUnhandled: bool",
            "    count: int",
            "    userCount: int",
            "    firstSeen: datetime",
            "    lastSeen: datetime",
            "",
            "",
            "class BaseGroupSerializerResponse(BaseGroupResponseOptional):",
            "    id: str",
            "    shareId: str",
            "    shortId: str",
            "    title: str",
            "    culprit: str",
            "    permalink: str",
            "    logger: str | None",
            "    level: str",
            "    status: str",
            "    statusDetails: GroupStatusDetailsResponseOptional",
            "    isPublic: bool",
            "    platform: str",
            "    priority: str",
            "    project: GroupProjectResponse",
            "    type: str",
            "    metadata: GroupMetadataResponse",
            "    numComments: int",
            "    assignedTo: UserSerializerResponse",
            "    isBookmarked: bool",
            "    isSubscribed: bool",
            "    subscriptionDetails: GroupSubscriptionResponseOptional | None",
            "    hasSeen: bool",
            "    annotations: Sequence[GroupAnnotation]",
            "",
            "",
            "class SeenStats(TypedDict):",
            "    times_seen: int",
            "    first_seen: datetime | None",
            "    last_seen: datetime | None",
            "    user_count: int",
            "",
            "",
            "class GroupSerializerBase(Serializer, ABC):",
            "    def __init__(",
            "        self,",
            "        collapse=None,",
            "        expand=None,",
            "    ):",
            "        self.collapse = collapse",
            "        self.expand = expand",
            "",
            "    def _serialize_assignees(self, item_list: Sequence[Group]) -> Mapping[int, Team | Any]:",
            "        gas = GroupAssignee.objects.filter(group__in=item_list)",
            "        result: MutableMapping[int, Team | Any] = {}",
            "        all_team_ids: MutableMapping[int, set[int]] = defaultdict(set)",
            "        all_user_ids: MutableMapping[int, set[int]] = defaultdict(set)",
            "",
            "        for g in gas:",
            "            if g.team_id:",
            "                all_team_ids[g.team_id].add(g.group_id)",
            "            if g.user_id:",
            "                all_user_ids[g.user_id].add(g.group_id)",
            "",
            "        for team in Team.objects.filter(id__in=all_team_ids.keys()):",
            "            for group_id in all_team_ids[team.id]:",
            "                result[group_id] = team",
            "        for user in user_service.get_many_by_id(ids=list(all_user_ids.keys())):",
            "            for group_id in all_user_ids[user.id]:",
            "                result[group_id] = user",
            "",
            "        return result",
            "",
            "    def get_attrs(",
            "        self, item_list: Sequence[Group], user: Any, **kwargs: Any",
            "    ) -> MutableMapping[Group, MutableMapping[str, Any]]:",
            "        GroupMeta.objects.populate_cache(item_list)",
            "",
            "        # Note that organization is necessary here for use in `_get_permalink` to avoid",
            "        # making unnecessary queries.",
            "        prefetch_related_objects(item_list, \"project__organization\")",
            "",
            "        if user.is_authenticated and item_list:",
            "            bookmarks = set(",
            "                GroupBookmark.objects.filter(user_id=user.id, group__in=item_list).values_list(",
            "                    \"group_id\", flat=True",
            "                )",
            "            )",
            "            seen_groups = dict(",
            "                GroupSeen.objects.filter(user_id=user.id, group__in=item_list).values_list(",
            "                    \"group_id\", \"last_seen\"",
            "                )",
            "            )",
            "            subscriptions = self._get_subscriptions(item_list, user)",
            "        else:",
            "            bookmarks = set()",
            "            seen_groups = {}",
            "            subscriptions = defaultdict(lambda: (False, False, None))",
            "",
            "        resolved_assignees = self._serialize_assignees(item_list)",
            "",
            "        ignore_items = {g.group_id: g for g in GroupSnooze.objects.filter(group__in=item_list)}",
            "",
            "        release_resolutions, commit_resolutions = self._resolve_resolutions(item_list, user)",
            "",
            "        user_ids = {",
            "            user_id",
            "            for user_id in itertools.chain(",
            "                (r[-1] for r in release_resolutions.values()),",
            "                (r.actor_id for r in ignore_items.values()),",
            "            )",
            "            if user_id is not None",
            "        }",
            "        if user_ids:",
            "            serialized_users = user_service.serialize_many(",
            "                filter={\"user_ids\": user_ids, \"is_active\": True},",
            "                as_user=serialize_generic_user(user),",
            "            )",
            "            actors = {id: u for id, u in zip(user_ids, serialized_users)}",
            "        else:",
            "            actors = {}",
            "",
            "        share_ids = dict(",
            "            GroupShare.objects.filter(group__in=item_list).values_list(\"group_id\", \"uuid\")",
            "        )",
            "",
            "        seen_stats = self._get_seen_stats(item_list, user)",
            "",
            "        organization_id_list = list({item.project.organization_id for item in item_list})",
            "        # if no groups, then we can't proceed but this seems to be a valid use case",
            "        if not item_list:",
            "            return {}",
            "        if len(organization_id_list) > 1:",
            "            # this should never happen but if it does we should know about it",
            "            logger.warning(",
            "                \"Found multiple organizations for groups: %s, with orgs: %s\",",
            "                [item.id for item in item_list],",
            "                organization_id_list,",
            "            )",
            "",
            "        # should only have 1 org at this point",
            "        organization_id = organization_id_list[0]",
            "",
            "        authorized = self._is_authorized(user, organization_id)",
            "",
            "        annotations_by_group_id: MutableMapping[int, list[Any]] = defaultdict(list)",
            "        for annotations_by_group in itertools.chain.from_iterable(",
            "            [",
            "                self._resolve_integration_annotations(organization_id, item_list),",
            "                [self._resolve_external_issue_annotations(item_list)],",
            "            ]",
            "        ):",
            "            merge_list_dictionaries(annotations_by_group_id, annotations_by_group)",
            "",
            "        snuba_stats = self._get_group_snuba_stats(item_list, seen_stats)",
            "",
            "        result = {}",
            "        for item in item_list:",
            "            active_date = item.active_at or item.first_seen",
            "",
            "            resolution_actor = None",
            "            resolution_type = None",
            "            resolution = release_resolutions.get(item.id)",
            "            if resolution:",
            "                resolution_type = \"release\"",
            "                resolution_actor = actors.get(resolution[-1])",
            "            if not resolution:",
            "                resolution = commit_resolutions.get(item.id)",
            "                if resolution:",
            "                    resolution_type = \"commit\"",
            "",
            "            ignore_item = ignore_items.get(item.id)",
            "",
            "            result[item] = {",
            "                \"id\": item.id,",
            "                \"assigned_to\": resolved_assignees.get(item.id),",
            "                \"is_bookmarked\": item.id in bookmarks,",
            "                \"subscription\": subscriptions[item.id],",
            "                \"has_seen\": seen_groups.get(item.id, active_date) > active_date,",
            "                \"annotations\": self._resolve_and_extend_plugin_annotation(",
            "                    item, annotations_by_group_id[item.id]",
            "                ),",
            "                \"ignore_until\": ignore_item,",
            "                \"ignore_actor\": actors.get(ignore_item.actor_id) if ignore_item else None,",
            "                \"resolution\": resolution,",
            "                \"resolution_type\": resolution_type,",
            "                \"resolution_actor\": resolution_actor,",
            "                \"share_id\": share_ids.get(item.id),",
            "                \"authorized\": authorized,",
            "            }",
            "            if snuba_stats is not None:",
            "                result[item][\"is_unhandled\"] = bool(snuba_stats.get(item.id, {}).get(\"unhandled\"))",
            "",
            "            if seen_stats:",
            "                result[item].update(seen_stats.get(item, {}))",
            "        return result",
            "",
            "    def serialize(",
            "        self, obj: Group, attrs: MutableMapping[str, Any], user: Any, **kwargs: Any",
            "    ) -> BaseGroupSerializerResponse:",
            "        status_details, status_label = self._get_status(attrs, obj)",
            "        permalink = self._get_permalink(attrs, obj)",
            "        is_subscribed, subscription_details = get_subscription_from_attributes(attrs)",
            "        share_id = attrs[\"share_id\"]",
            "        group_dict = {",
            "            \"id\": str(obj.id),",
            "            \"shareId\": share_id,",
            "            \"shortId\": obj.qualified_short_id,",
            "            \"title\": obj.title,",
            "            \"culprit\": obj.culprit,",
            "            \"permalink\": permalink,",
            "            \"logger\": obj.logger or None,",
            "            \"level\": LOG_LEVELS.get(obj.level, \"unknown\"),",
            "            \"status\": status_label,",
            "            \"statusDetails\": status_details,",
            "            \"substatus\": SUBSTATUS_TO_STR[obj.substatus] if obj.substatus else None,",
            "            \"isPublic\": share_id is not None,",
            "            \"platform\": obj.platform,",
            "            \"project\": {",
            "                \"id\": str(obj.project.id),",
            "                \"name\": obj.project.name,",
            "                \"slug\": obj.project.slug,",
            "                \"platform\": obj.project.platform,",
            "            },",
            "            \"type\": obj.get_event_type(),",
            "            \"metadata\": obj.get_event_metadata(),",
            "            \"numComments\": obj.num_comments,",
            "            \"assignedTo\": serialize(attrs[\"assigned_to\"], user, ActorSerializer()),",
            "            \"isBookmarked\": attrs[\"is_bookmarked\"],",
            "            \"isSubscribed\": is_subscribed,",
            "            \"subscriptionDetails\": subscription_details,",
            "            \"hasSeen\": attrs[\"has_seen\"],",
            "            \"annotations\": attrs[\"annotations\"],",
            "            \"issueType\": obj.issue_type.slug,",
            "            \"issueCategory\": obj.issue_category.name.lower(),",
            "        }",
            "",
            "        priority_label = PriorityLevel(obj.priority).to_str() if obj.priority else None",
            "        group_dict[\"priority\"] = priority_label",
            "        group_dict[\"priorityLockedAt\"] = obj.priority_locked_at",
            "",
            "        # This attribute is currently feature gated",
            "        if \"is_unhandled\" in attrs:",
            "            group_dict[\"isUnhandled\"] = attrs[\"is_unhandled\"]",
            "        if \"times_seen\" in attrs:",
            "            group_dict.update(self._convert_seen_stats(attrs))",
            "        return group_dict",
            "",
            "    @abstractmethod",
            "    def _seen_stats_error(",
            "        self, error_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        pass",
            "",
            "    @abstractmethod",
            "    def _seen_stats_generic(",
            "        self, generic_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        pass",
            "",
            "    def _expand(self, key) -> bool:",
            "        if self.expand is None:",
            "            return False",
            "",
            "        return key in self.expand",
            "",
            "    def _collapse(self, key) -> bool:",
            "        if self.collapse is None:",
            "            return False",
            "        return key in self.collapse",
            "",
            "    def _get_status(self, attrs: MutableMapping[str, Any], obj: Group):",
            "        status = obj.status",
            "        status_details = {}",
            "        if attrs[\"ignore_until\"]:",
            "            snooze = attrs[\"ignore_until\"]",
            "            if snooze.is_valid(group=obj):",
            "                # counts return the delta remaining when window is not set",
            "                status_details.update(",
            "                    {",
            "                        \"ignoreCount\": (",
            "                            snooze.count - (obj.times_seen - snooze.state[\"times_seen\"])",
            "                            if snooze.count and not snooze.window",
            "                            else snooze.count",
            "                        ),",
            "                        \"ignoreUntil\": snooze.until,",
            "                        \"ignoreUserCount\": (",
            "                            snooze.user_count - (attrs[\"user_count\"] - snooze.state[\"users_seen\"])",
            "                            if snooze.user_count",
            "                            and not snooze.user_window",
            "                            and not self._collapse(\"stats\")",
            "                            else snooze.user_count",
            "                        ),",
            "                        \"ignoreUserWindow\": snooze.user_window,",
            "                        \"ignoreWindow\": snooze.window,",
            "                        \"actor\": attrs[\"ignore_actor\"],",
            "                    }",
            "                )",
            "            else:",
            "                status = GroupStatus.UNRESOLVED",
            "        if status == GroupStatus.UNRESOLVED and obj.is_over_resolve_age():",
            "            # When an issue is over the auto-resolve age but the task has not yet run",
            "            status = GroupStatus.RESOLVED",
            "            status_details[\"autoResolved\"] = True",
            "        if status == GroupStatus.RESOLVED:",
            "            status_label = \"resolved\"",
            "            if attrs[\"resolution_type\"] == \"release\":",
            "                res_type, res_version, _ = attrs[\"resolution\"]",
            "                if res_type in (GroupResolution.Type.in_next_release, None):",
            "                    status_details[\"inNextRelease\"] = True",
            "                elif res_type == GroupResolution.Type.in_release:",
            "                    status_details[\"inRelease\"] = res_version",
            "                status_details[\"actor\"] = attrs[\"resolution_actor\"]",
            "            elif attrs[\"resolution_type\"] == \"commit\":",
            "                status_details[\"inCommit\"] = attrs[\"resolution\"]",
            "        elif status == GroupStatus.IGNORED:",
            "            status_label = \"ignored\"",
            "        elif status in [GroupStatus.PENDING_DELETION, GroupStatus.DELETION_IN_PROGRESS]:",
            "            status_label = \"pending_deletion\"",
            "        elif status == GroupStatus.PENDING_MERGE:",
            "            status_label = \"pending_merge\"",
            "        elif status == GroupStatus.REPROCESSING:",
            "            status_label = \"reprocessing\"",
            "            status_details[\"pendingEvents\"], status_details[\"info\"] = get_progress(",
            "                attrs[\"id\"], obj.project.id",
            "            )",
            "        else:",
            "            status_label = \"unresolved\"",
            "        return status_details, status_label",
            "",
            "    def _get_seen_stats(self, item_list: Sequence[Group], user) -> Mapping[Group, SeenStats] | None:",
            "        \"\"\"",
            "        Returns a dictionary keyed by item that includes:",
            "            - times_seen",
            "            - first_seen",
            "            - last_seen",
            "            - user_count",
            "        \"\"\"",
            "        if self._collapse(\"stats\"):",
            "            return None",
            "",
            "        if not item_list:",
            "            return None",
            "",
            "        # partition the item_list by type",
            "        error_issues = [group for group in item_list if GroupCategory.ERROR == group.issue_category]",
            "        generic_issues = [",
            "            group for group in item_list if group.issue_category != GroupCategory.ERROR",
            "        ]",
            "",
            "        # bulk query for the seen_stats by type",
            "        error_stats = (self._seen_stats_error(error_issues, user) if error_issues else {}) or {}",
            "        generic_stats = (",
            "            self._seen_stats_generic(generic_issues, user) if generic_issues else {}",
            "        ) or {}",
            "        agg_stats = {**error_stats, **generic_stats}",
            "        # combine results back",
            "        return {group: agg_stats.get(group, {}) for group in item_list}",
            "",
            "    def _get_group_snuba_stats(",
            "        self, item_list: Sequence[Group], seen_stats: Mapping[Group, SeenStats] | None",
            "    ):",
            "        if (",
            "            self._collapse(\"unhandled\")",
            "            and len(item_list) > 0",
            "            and features.has(",
            "                \"organizations:issue-stream-performance\", item_list[0].project.organization",
            "            )",
            "        ):",
            "            return None",
            "        start = self._get_start_from_seen_stats(seen_stats)",
            "        unhandled = {}",
            "",
            "        cache_keys = []",
            "        for item in item_list:",
            "            cache_keys.append(f\"group-mechanism-handled:{item.id}\")",
            "",
            "        cache_data = cache.get_many(cache_keys)",
            "        for item, cache_key in zip(item_list, cache_keys):",
            "            unhandled[item.id] = cache_data.get(cache_key)",
            "",
            "        filter_keys = {}",
            "        for item in item_list:",
            "            if unhandled.get(item.id) is not None:",
            "                continue",
            "            filter_keys.setdefault(\"project_id\", []).append(item.project_id)",
            "            filter_keys.setdefault(\"group_id\", []).append(item.id)",
            "",
            "        if filter_keys:",
            "            rv = raw_query(",
            "                dataset=Dataset.Events,",
            "                selected_columns=[",
            "                    \"group_id\",",
            "                    [",
            "                        \"argMax\",",
            "                        [[\"has\", [\"exception_stacks.mechanism_handled\", 0]], \"timestamp\"],",
            "                        \"unhandled\",",
            "                    ],",
            "                ],",
            "                groupby=[\"group_id\"],",
            "                filter_keys=filter_keys,",
            "                start=start,",
            "                orderby=\"group_id\",",
            "                referrer=\"group.unhandled-flag\",",
            "                tenant_ids=(",
            "                    {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "                ),",
            "            )",
            "            for x in rv[\"data\"]:",
            "                unhandled[x[\"group_id\"]] = x[\"unhandled\"]",
            "",
            "                # cache the handled flag for 60 seconds.  This is broadly in line with",
            "                # the time we give for buffer flushes so the user experience is somewhat",
            "                # consistent here.",
            "                cache.set(\"group-mechanism-handled:%d\" % x[\"group_id\"], x[\"unhandled\"], 60)",
            "",
            "        return {group_id: {\"unhandled\": unhandled} for group_id, unhandled in unhandled.items()}",
            "",
            "    @staticmethod",
            "    def _get_start_from_seen_stats(seen_stats: Mapping[Group, SeenStats] | None):",
            "        # Try to figure out what is a reasonable time frame to look into stats,",
            "        # based on a given \"seen stats\".  We try to pick a day prior to the earliest last seen,",
            "        # but it has to be at least 14 days, and not more than 90 days ago.",
            "        # Fallback to the 30 days ago if we are not able to calculate the value.",
            "        last_seen = None",
            "        if seen_stats:",
            "            for item in seen_stats.values():",
            "                if last_seen is None or (item[\"last_seen\"] and last_seen > item[\"last_seen\"]):",
            "                    last_seen = item[\"last_seen\"]",
            "",
            "        if last_seen is None:",
            "            return datetime.now(timezone.utc) - timedelta(days=30)",
            "",
            "        return max(",
            "            min(last_seen - timedelta(days=1), datetime.now(timezone.utc) - timedelta(days=14)),",
            "            datetime.now(timezone.utc) - timedelta(days=90),",
            "        )",
            "",
            "    @staticmethod",
            "    def _get_subscriptions(",
            "        groups: Iterable[Group], user: User",
            "    ) -> Mapping[int, tuple[bool, bool, GroupSubscription | None]]:",
            "        \"\"\"",
            "        Returns a mapping of group IDs to a two-tuple of (is_disabled: bool,",
            "        subscribed: bool, subscription: Optional[GroupSubscription]) for the",
            "        provided user and groups.",
            "",
            "        Returns:",
            "            Mapping[int, Tuple[bool, bool, Optional[GroupSubscription]]]: A mapping of group IDs to",
            "            a tuple of (is_disabled: bool, subscribed: bool, subscription: Optional[GroupSubscription])",
            "        \"\"\"",
            "        if not groups:",
            "            return {}",
            "",
            "        groups_by_project = collect_groups_by_project(groups)",
            "        project_ids = list(groups_by_project.keys())",
            "        enabled_settings = notifications_service.subscriptions_for_projects(",
            "            user_id=user.id, project_ids=project_ids, type=NotificationSettingEnum.WORKFLOW",
            "        )",
            "        query_groups = {",
            "            group",
            "            for group in groups",
            "            if (not enabled_settings[group.project_id].has_only_inactive_subscriptions)",
            "        }",
            "        subscriptions_by_group_id: dict[int, GroupSubscription] = {",
            "            subscription.group_id: subscription",
            "            for subscription in GroupSubscription.objects.filter(",
            "                group__in=query_groups, user_id=user.id",
            "            )",
            "        }",
            "        groups_by_project = collect_groups_by_project(groups)",
            "",
            "        results = {}",
            "        for project_id, group_set in groups_by_project.items():",
            "            subscription_status = enabled_settings[project_id]",
            "            for group in group_set:",
            "                subscription = subscriptions_by_group_id.get(group.id)",
            "                if subscription:",
            "                    # Having a GroupSubscription overrides NotificationSettings.",
            "                    results[group.id] = (False, subscription.is_active, subscription)",
            "                elif subscription_status.is_disabled:",
            "                    # The user has disabled notifications in all cases.",
            "                    results[group.id] = (True, False, None)",
            "                else:",
            "                    # Since there is no subscription, it is only active if the value is ALWAYS.",
            "                    results[group.id] = (False, subscription_status.is_active, None)",
            "",
            "        return results",
            "",
            "    @staticmethod",
            "    def _resolve_resolutions(",
            "        groups: Sequence[Group], user",
            "    ) -> tuple[Mapping[int, Sequence[Any]], Mapping[int, Any]]:",
            "        resolved_groups = [i for i in groups if i.status == GroupStatus.RESOLVED]",
            "        if not resolved_groups:",
            "            return {}, {}",
            "",
            "        _release_resolutions = {",
            "            i[0]: i[1:]",
            "            for i in GroupResolution.objects.filter(group__in=resolved_groups).values_list(",
            "                \"group\", \"type\", \"release__version\", \"actor_id\"",
            "            )",
            "        }",
            "",
            "        # due to our laziness, and django's inability to do a reasonable join here",
            "        # we end up with two queries",
            "        commit_results = list(",
            "            Commit.objects.extra(",
            "                select={\"group_id\": \"sentry_grouplink.group_id\"},",
            "                tables=[\"sentry_grouplink\"],",
            "                where=[",
            "                    \"sentry_grouplink.linked_id = sentry_commit.id\",",
            "                    \"sentry_grouplink.group_id IN ({})\".format(",
            "                        \", \".join(str(i.id) for i in resolved_groups)",
            "                    ),",
            "                    \"sentry_grouplink.linked_type = %s\",",
            "                    \"sentry_grouplink.relationship = %s\",",
            "                ],",
            "                params=[int(GroupLink.LinkedType.commit), int(GroupLink.Relationship.resolves)],",
            "            )",
            "        )",
            "        _commit_resolutions = {",
            "            i.group_id: d for i, d in zip(commit_results, serialize(commit_results, user))",
            "        }",
            "",
            "        return _release_resolutions, _commit_resolutions",
            "",
            "    @staticmethod",
            "    def _resolve_external_issue_annotations(groups: Sequence[Group]) -> Mapping[int, Sequence[Any]]:",
            "        from sentry.models.platformexternalissue import PlatformExternalIssue",
            "",
            "        # find the external issues for sentry apps and add them in",
            "        return (",
            "            safe_execute(PlatformExternalIssue.get_annotations_for_group_list, group_list=groups)",
            "            or {}",
            "        )",
            "",
            "    @staticmethod",
            "    def _resolve_integration_annotations(",
            "        org_id: int, groups: Sequence[Group]",
            "    ) -> Sequence[Mapping[int, Sequence[Any]]]:",
            "        from sentry.integrations.base import IntegrationFeatures",
            "",
            "        integration_annotations = []",
            "        # find all the integration installs that have issue tracking",
            "        integrations = integration_service.get_integrations(organization_id=org_id)",
            "        for integration in integrations:",
            "            if not (",
            "                integration.has_feature(feature=IntegrationFeatures.ISSUE_BASIC)",
            "                or integration.has_feature(feature=IntegrationFeatures.ISSUE_SYNC)",
            "            ):",
            "                continue",
            "",
            "            install = integration.get_installation(organization_id=org_id)",
            "            local_annotations_by_group_id = (",
            "                safe_execute(install.get_annotations_for_group_list, group_list=groups) or {}",
            "            )",
            "            integration_annotations.append(local_annotations_by_group_id)",
            "",
            "        return integration_annotations",
            "",
            "    @staticmethod",
            "    def _resolve_and_extend_plugin_annotation(",
            "        item: Group, current_annotations: list[Any]",
            "    ) -> Sequence[Any]:",
            "        from sentry.plugins.base import plugins",
            "",
            "        annotations_for_group = []",
            "        annotations_for_group.extend(current_annotations)",
            "",
            "        # add the annotations for plugins",
            "        # note that the model GroupMeta(where all the information is stored) is already cached at the start of",
            "        # `get_attrs`, so these for loops doesn't make a bunch of queries",
            "        for plugin in plugins.for_project(project=item.project, version=1):",
            "            if is_plugin_deprecated(plugin, item.project):",
            "                continue",
            "            safe_execute(plugin.tags, None, item, annotations_for_group)",
            "        for plugin in plugins.for_project(project=item.project, version=2):",
            "            annotations_for_group.extend(safe_execute(plugin.get_annotations, group=item) or ())",
            "",
            "        return annotations_for_group",
            "",
            "    @staticmethod",
            "    def _is_authorized(user, organization_id: int):",
            "        # If user is not logged in and member of the organization,",
            "        # do not return the permalink which contains private information i.e. org name.",
            "        request = env.request",
            "        if request and is_active_superuser(request) and request.user.id == user.id:",
            "            return True",
            "",
            "        # If user is a sentry_app then it's a proxy user meaning we can't do a org lookup via `get_orgs()`",
            "        # because the user isn't an org member. Instead we can use the auth token and the installation",
            "        # it's associated with to find out what organization the token has access to.",
            "        if (",
            "            request",
            "            and getattr(request.user, \"is_sentry_app\", False)",
            "            and is_api_token_auth(request.auth)",
            "        ):",
            "            if AuthenticatedToken.from_token(request.auth).token_has_org_access(organization_id):",
            "                return True",
            "",
            "        if (",
            "            request",
            "            and user.is_anonymous",
            "            and hasattr(request, \"auth\")",
            "            and is_org_auth_token_auth(request.auth)",
            "        ):",
            "            return request.auth.organization_id == organization_id",
            "",
            "        return (",
            "            user.is_authenticated",
            "            and OrganizationMember.objects.filter(",
            "                user_id=user.id, organization_id=organization_id",
            "            ).exists()",
            "        )",
            "",
            "    @staticmethod",
            "    def _get_permalink(attrs, obj: Group):",
            "        if attrs[\"authorized\"]:",
            "            with sentry_sdk.start_span(op=\"GroupSerializerBase.serialize.permalink.build\"):",
            "                return obj.get_absolute_url()",
            "        else:",
            "            return None",
            "",
            "    @staticmethod",
            "    def _convert_seen_stats(attrs: SeenStats):",
            "        return {",
            "            \"count\": str(attrs[\"times_seen\"]),",
            "            \"userCount\": attrs[\"user_count\"],",
            "            \"firstSeen\": attrs[\"first_seen\"],",
            "            \"lastSeen\": attrs[\"last_seen\"],",
            "        }",
            "",
            "",
            "@register(Group)",
            "class GroupSerializer(GroupSerializerBase):",
            "    class GroupUserCountsFunc(Protocol):",
            "        def __call__(",
            "            self,",
            "            project_ids: Sequence[int],",
            "            item_ids: Sequence[int],",
            "            environment_ids: Sequence[int] | None,",
            "        ) -> Mapping[int, int]:",
            "            pass",
            "",
            "    def __init__(self, environment_func: Callable[[], Environment] | None = None):",
            "        GroupSerializerBase.__init__(self)",
            "        self.environment_func = environment_func if environment_func is not None else lambda: None",
            "",
            "    def _seen_stats_error(self, item_list, user) -> Mapping[Group, SeenStats]:",
            "        return self.__seen_stats_impl(",
            "            item_list,",
            "            tagstore.backend.get_groups_user_counts,",
            "            tagstore.backend.get_group_list_tag_value,",
            "        )",
            "",
            "    def _seen_stats_generic(",
            "        self, generic_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        return self.__seen_stats_impl(",
            "            generic_issue_list,",
            "            tagstore.backend.get_generic_groups_user_counts,",
            "            tagstore.backend.get_generic_group_list_tag_value,",
            "        )",
            "",
            "    def __seen_stats_impl(",
            "        self,",
            "        issue_list: Sequence[Group],",
            "        user_counts_func: GroupUserCountsFunc,",
            "        environment_seen_stats_func: Callable[",
            "            [Sequence[int], Sequence[int], Sequence[int], str, str], Mapping[int, GroupTagValue]",
            "        ],",
            "    ) -> Mapping[Group, SeenStats]:",
            "        if not issue_list:",
            "            return {}",
            "        try:",
            "            environment = self.environment_func()",
            "        except Environment.DoesNotExist:",
            "            return {",
            "                item: {\"times_seen\": 0, \"first_seen\": None, \"last_seen\": None, \"user_count\": 0}",
            "                for item in issue_list",
            "            }",
            "",
            "        project_id = issue_list[0].project_id",
            "        item_ids = [g.id for g in issue_list]",
            "        tenant_ids = {\"organization_id\": issue_list[0].project.organization_id}",
            "        user_counts: Mapping[int, int] = user_counts_func(",
            "            [project_id],",
            "            item_ids,",
            "            environment_ids=environment and [environment.id],",
            "            tenant_ids=tenant_ids,",
            "        )",
            "        first_seen: MutableMapping[int, datetime] = {}",
            "        last_seen: MutableMapping[int, datetime] = {}",
            "        times_seen: MutableMapping[int, int] = {}",
            "",
            "        if environment is not None:",
            "            environment_seen_stats = environment_seen_stats_func(",
            "                [project_id],",
            "                item_ids,",
            "                [environment.id],",
            "                \"environment\",",
            "                environment.name,",
            "                tenant_ids=tenant_ids,",
            "            )",
            "            for item_id, value in environment_seen_stats.items():",
            "                first_seen[item_id] = value.first_seen",
            "                last_seen[item_id] = value.last_seen",
            "                times_seen[item_id] = value.times_seen",
            "        else:",
            "            # fallback to the model data since we can't query tagstore",
            "            for item in issue_list:",
            "                first_seen[item.id] = item.first_seen",
            "                last_seen[item.id] = item.last_seen",
            "                times_seen[item.id] = item.times_seen",
            "",
            "        return {",
            "            item: {",
            "                \"times_seen\": times_seen.get(item.id, 0),",
            "                \"first_seen\": first_seen.get(item.id),",
            "                \"last_seen\": last_seen.get(item.id),",
            "                \"user_count\": user_counts.get(item.id, 0),",
            "            }",
            "            for item in issue_list",
            "        }",
            "",
            "",
            "class SharedGroupSerializer(GroupSerializer):",
            "    def serialize(",
            "        self, obj: Group, attrs: MutableMapping[str, Any], user: Any, **kwargs: Any",
            "    ) -> BaseGroupSerializerResponse:",
            "        result = super().serialize(obj, attrs, user)",
            "",
            "        ALLOWED_FIELDS = [",
            "            \"culprit\",",
            "            \"id\",",
            "            \"isUnhandled\",",
            "            \"issueCategory\",",
            "            \"permalink\",",
            "            \"shortId\",",
            "            \"title\",",
            "        ]",
            "        result = {k: v for (k, v) in result.items() if k in ALLOWED_FIELDS}",
            "",
            "        # avoids a circular import",
            "        from sentry.api.serializers.models import SharedEventSerializer, SharedProjectSerializer",
            "",
            "        event = obj.get_latest_event()",
            "        result[\"latestEvent\"] = serialize(event, user, SharedEventSerializer())",
            "",
            "        result[\"project\"] = serialize(obj.project, user, SharedProjectSerializer())",
            "",
            "        return result",
            "",
            "",
            "SKIP_SNUBA_FIELDS = frozenset(",
            "    (",
            "        \"status\",",
            "        \"substatus\",",
            "        \"bookmarked_by\",",
            "        \"assigned_to\",",
            "        \"for_review\",",
            "        \"assigned_or_suggested\",",
            "        \"unassigned\",",
            "        \"linked\",",
            "        \"subscribed_by\",",
            "        \"first_release\",",
            "        \"first_seen\",",
            "        \"issue.category\",",
            "        \"issue.priority\",",
            "        \"issue.type\",",
            "    )",
            ")",
            "",
            "",
            "class GroupSerializerSnuba(GroupSerializerBase):",
            "    skip_snuba_fields = {",
            "        *SKIP_SNUBA_FIELDS,",
            "        \"last_seen\",",
            "        \"times_seen\",",
            "        \"date\",",
            "        \"timestamp\",  # We merge this with start/end, so don't want to include it as its own",
            "        # condition",
            "        # We don't need to filter by release stage again here since we're",
            "        # filtering to specific groups. Saves us making a second query to",
            "        # postgres for no reason",
            "        RELEASE_STAGE_ALIAS,",
            "    }",
            "",
            "    def __init__(",
            "        self,",
            "        environment_ids=None,",
            "        start: datetime | None = None,",
            "        end: datetime | None = None,",
            "        search_filters=None,",
            "        collapse=None,",
            "        expand=None,",
            "        organization_id=None,",
            "        project_ids=None,",
            "    ):",
            "        super().__init__(collapse=collapse, expand=expand)",
            "        from sentry.search.snuba.executors import get_search_filter",
            "",
            "        self.environment_ids = environment_ids",
            "        self.organization_id = organization_id",
            "        # XXX: We copy this logic from `PostgresSnubaQueryExecutor.query`. Ideally we",
            "        # should try and encapsulate this logic, but if you're changing this, change it",
            "        # there as well.",
            "        self.start = None",
            "        start_params = [",
            "            _f",
            "            for _f in [",
            "                start,",
            "                get_search_filter(search_filters, \"date\", \">\"),",
            "                get_search_filter(search_filters, \"timestamp\", \">\"),",
            "            ]",
            "            if _f",
            "        ]",
            "        if start_params:",
            "            self.start = max(_f for _f in start_params if _f)",
            "",
            "        self.end = None",
            "        end_params = [",
            "            _f",
            "            for _f in [",
            "                end,",
            "                get_search_filter(search_filters, \"date\", \"<\"),",
            "                get_search_filter(search_filters, \"timestamp\", \"<\"),",
            "            ]",
            "            if _f",
            "        ]",
            "        if end_params:",
            "            self.end = min(end_params)",
            "",
            "        conditions = []",
            "        if search_filters is not None:",
            "            for search_filter in search_filters:",
            "                if search_filter.key.name not in self.skip_snuba_fields:",
            "                    formatted_conditions, projects_to_filter, group_ids = format_search_filter(",
            "                        search_filter,",
            "                        params={",
            "                            \"organization_id\": organization_id,",
            "                            \"project_id\": project_ids,",
            "                            \"environment_id\": environment_ids,",
            "                        },",
            "                    )",
            "",
            "                    # if no re-formatted conditions, use fallback method",
            "                    new_condition = None",
            "                    if formatted_conditions:",
            "                        new_condition = formatted_conditions[0]",
            "                    elif group_ids:",
            "                        new_condition = convert_search_filter_to_snuba_query(",
            "                            search_filter,",
            "                            params={",
            "                                \"organization_id\": organization_id,",
            "                                \"project_id\": project_ids,",
            "                                \"environment_id\": environment_ids,",
            "                            },",
            "                        )",
            "",
            "                    if new_condition:",
            "                        conditions.append(new_condition)",
            "        self.conditions = conditions",
            "",
            "    def _seen_stats_error(",
            "        self, error_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        return self._parse_seen_stats_results(",
            "            self._execute_error_seen_stats_query(",
            "                item_list=error_issue_list,",
            "                start=self.start,",
            "                end=self.end,",
            "                conditions=self.conditions,",
            "                environment_ids=self.environment_ids,",
            "            ),",
            "            error_issue_list,",
            "            bool(self.start or self.end or self.conditions),",
            "            self.environment_ids,",
            "        )",
            "",
            "    def _seen_stats_generic(",
            "        self, generic_issue_list: Sequence[Group], user",
            "    ) -> Mapping[Group, SeenStats]:",
            "        return self._parse_seen_stats_results(",
            "            self._execute_generic_seen_stats_query(",
            "                item_list=generic_issue_list,",
            "                start=self.start,",
            "                end=self.end,",
            "                conditions=self.conditions,",
            "                environment_ids=self.environment_ids,",
            "            ),",
            "            generic_issue_list,",
            "            bool(self.start or self.end or self.conditions),",
            "            self.environment_ids,",
            "        )",
            "",
            "    @staticmethod",
            "    def _execute_error_seen_stats_query(",
            "        item_list, start=None, end=None, conditions=None, environment_ids=None",
            "    ):",
            "        project_ids = list({item.project_id for item in item_list})",
            "        group_ids = [item.id for item in item_list]",
            "        aggregations = [",
            "            [\"count()\", \"\", \"times_seen\"],",
            "            [\"min\", \"timestamp\", \"first_seen\"],",
            "            [\"max\", \"timestamp\", \"last_seen\"],",
            "            [\"uniq\", \"tags[sentry:user]\", \"count\"],",
            "        ]",
            "        filters = {\"project_id\": project_ids, \"group_id\": group_ids}",
            "        if environment_ids:",
            "            filters[\"environment\"] = environment_ids",
            "",
            "        return aliased_query(",
            "            dataset=Dataset.Events,",
            "            start=start,",
            "            end=end,",
            "            groupby=[\"group_id\"],",
            "            conditions=conditions,",
            "            filter_keys=filters,",
            "            aggregations=aggregations,",
            "            referrer=\"serializers.GroupSerializerSnuba._execute_error_seen_stats_query\",",
            "            tenant_ids=(",
            "                {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "            ),",
            "        )",
            "",
            "    @staticmethod",
            "    def _execute_perf_seen_stats_query(",
            "        item_list, start=None, end=None, conditions=None, environment_ids=None",
            "    ):",
            "        project_ids = list({item.project_id for item in item_list})",
            "        group_ids = [item.id for item in item_list]",
            "        aggregations = [",
            "            [\"arrayJoin\", [\"group_ids\"], \"group_id\"],",
            "            [\"count()\", \"\", \"times_seen\"],",
            "            [\"min\", \"timestamp\", \"first_seen\"],",
            "            [\"max\", \"timestamp\", \"last_seen\"],",
            "            [\"uniq\", \"tags[sentry:user]\", \"count\"],",
            "        ]",
            "        filters = {\"project_id\": project_ids}",
            "        if environment_ids:",
            "            filters[\"environment\"] = environment_ids",
            "        return aliased_query(",
            "            dataset=Dataset.Transactions,",
            "            start=start,",
            "            end=end,",
            "            groupby=[\"group_id\"],",
            "            conditions=[",
            "                [[\"hasAny\", [\"group_ids\", [\"array\", group_ids]]], \"=\", 1],",
            "            ]",
            "            + (conditions or []),",
            "            filter_keys=filters,",
            "            aggregations=aggregations,",
            "            referrer=\"serializers.GroupSerializerSnuba._execute_perf_seen_stats_query\",",
            "            tenant_ids=(",
            "                {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "            ),",
            "        )",
            "",
            "    @staticmethod",
            "    def _execute_generic_seen_stats_query(",
            "        item_list, start=None, end=None, conditions=None, environment_ids=None",
            "    ):",
            "        project_ids = list({item.project_id for item in item_list})",
            "        group_ids = [item.id for item in item_list]",
            "        aggregations = [",
            "            [\"count()\", \"\", \"times_seen\"],",
            "            [\"min\", \"timestamp\", \"first_seen\"],",
            "            [\"max\", \"timestamp\", \"last_seen\"],",
            "            [\"uniq\", \"tags[sentry:user]\", \"count\"],",
            "        ]",
            "        filters = {\"project_id\": project_ids, \"group_id\": group_ids}",
            "        if environment_ids:",
            "            filters[\"environment\"] = environment_ids",
            "        return aliased_query(",
            "            dataset=Dataset.IssuePlatform,",
            "            start=start,",
            "            end=end,",
            "            groupby=[\"group_id\"],",
            "            conditions=conditions,",
            "            filter_keys=filters,",
            "            aggregations=aggregations,",
            "            referrer=\"serializers.GroupSerializerSnuba._execute_generic_seen_stats_query\",",
            "            tenant_ids=(",
            "                {\"organization_id\": item_list[0].project.organization_id} if item_list else None",
            "            ),",
            "        )",
            "",
            "    @staticmethod",
            "    def _parse_seen_stats_results(",
            "        result, item_list, use_result_first_seen_times_seen, environment_ids=None",
            "    ):",
            "        seen_data = {",
            "            issue[\"group_id\"]: fix_tag_value_data(",
            "                dict(filter(lambda key: key[0] != \"group_id\", issue.items()))",
            "            )",
            "            for issue in result[\"data\"]",
            "        }",
            "        user_counts = {item_id: value[\"count\"] for item_id, value in seen_data.items()}",
            "        last_seen = {item_id: value[\"last_seen\"] for item_id, value in seen_data.items()}",
            "        if use_result_first_seen_times_seen:",
            "            first_seen = {item_id: value[\"first_seen\"] for item_id, value in seen_data.items()}",
            "            times_seen = {item_id: value[\"times_seen\"] for item_id, value in seen_data.items()}",
            "        else:",
            "            if environment_ids:",
            "                first_seen = {",
            "                    ge[\"group_id\"]: ge[\"first_seen__min\"]",
            "                    for ge in GroupEnvironment.objects.filter(",
            "                        group_id__in=[item.id for item in item_list],",
            "                        environment_id__in=environment_ids,",
            "                    )",
            "                    .values(\"group_id\")",
            "                    .annotate(Min(\"first_seen\"))",
            "                }",
            "            else:",
            "                first_seen = {item.id: item.first_seen for item in item_list}",
            "            times_seen = {item.id: item.times_seen for item in item_list}",
            "",
            "        return {",
            "            item: {",
            "                \"times_seen\": times_seen.get(item.id, 0),",
            "                \"first_seen\": first_seen.get(item.id),",
            "                \"last_seen\": last_seen.get(item.id),",
            "                \"user_count\": user_counts.get(item.id, 0),",
            "            }",
            "            for item in item_list",
            "        }"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "148": [
                "BaseGroupSerializerResponse"
            ]
        },
        "addLocation": []
    },
    "src/sentry/integrations/mixins/issues.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 348,
                "PatchRowcode": "         for ei in external_issues:"
            },
            "1": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 349,
                "PatchRowcode": "             link = self.get_issue_url(ei.key)"
            },
            "2": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": 350,
                "PatchRowcode": "             label = self.get_issue_display_name(ei) or ei.key"
            },
            "3": {
                "beforePatchRowNumber": 351,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            annotations.append(f'<a href=\"{link}\">{label}</a>')"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 351,
                "PatchRowcode": "+            annotations.append({\"url\": link, \"displayName\": label})"
            },
            "5": {
                "beforePatchRowNumber": 352,
                "afterPatchRowNumber": 352,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": 353,
                "PatchRowcode": "         return annotations"
            },
            "7": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": 354,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "import enum",
            "import logging",
            "from collections import defaultdict",
            "from collections.abc import Mapping, Sequence",
            "from copy import deepcopy",
            "from typing import Any, ClassVar",
            "",
            "from sentry.integrations.services.integration import integration_service",
            "from sentry.integrations.utils import where_should_sync",
            "from sentry.issues.grouptype import GroupCategory",
            "from sentry.models.group import Group",
            "from sentry.models.grouplink import GroupLink",
            "from sentry.models.integrations.external_issue import ExternalIssue",
            "from sentry.models.project import Project",
            "from sentry.models.user import User",
            "from sentry.notifications.utils import get_notification_group_title",
            "from sentry.shared_integrations.exceptions import ApiError, IntegrationError",
            "from sentry.silo.base import all_silo_function",
            "from sentry.tasks.integrations import sync_status_inbound as sync_status_inbound_task",
            "from sentry.users.services.user import RpcUser",
            "from sentry.users.services.user_option import get_option_from_list, user_option_service",
            "from sentry.utils.http import absolute_uri",
            "from sentry.utils.safe import safe_execute",
            "",
            "logger = logging.getLogger(\"sentry.integrations.issues\")",
            "MAX_CHAR = 50",
            "",
            "",
            "class ResolveSyncAction(enum.Enum):",
            "    \"\"\"",
            "    When an issue's state changes, we may have to sync the state based on the",
            "    \"done\" states we get from the API. This enum encapsulates the three options",
            "    we have: \"resolve\", \"unresolve\", or \"do nothing\".",
            "    \"\"\"",
            "",
            "    NOOP = 0",
            "    RESOLVE = 1",
            "    UNRESOLVE = 2",
            "",
            "    @classmethod",
            "    def from_resolve_unresolve(",
            "        cls, should_resolve: bool, should_unresolve: bool",
            "    ) -> ResolveSyncAction:",
            "        if should_resolve and should_unresolve:",
            "            logger.warning(\"sync-config-conflict\")",
            "            return ResolveSyncAction.NOOP",
            "",
            "        if should_resolve:",
            "            return ResolveSyncAction.RESOLVE",
            "",
            "        if should_unresolve:",
            "            return ResolveSyncAction.UNRESOLVE",
            "",
            "        return ResolveSyncAction.NOOP",
            "",
            "",
            "class IssueBasicMixin:",
            "    def should_sync(self, attribute):",
            "        return False",
            "",
            "    def get_group_title(self, group, event, **kwargs):",
            "        return get_notification_group_title(group, event, **kwargs)",
            "",
            "    def get_issue_url(self, key):",
            "        \"\"\"",
            "        Given the key of the external_issue return the external issue link.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_group_body(self, group, event, **kwargs):",
            "        result = []",
            "        for interface in event.interfaces.values():",
            "            output = safe_execute(interface.to_string, event)",
            "            if output:",
            "                result.append(output)",
            "        return \"\\n\\n\".join(result)",
            "",
            "    def get_group_link(self, group, **kwargs):",
            "        params = {}",
            "        if kwargs.get(\"link_referrer\"):",
            "            params[\"referrer\"] = kwargs.get(\"link_referrer\")",
            "",
            "        if group.issue_category == GroupCategory.FEEDBACK:",
            "            return [",
            "                \"Sentry Feedback: [{}]({})\\n\".format(",
            "                    group.qualified_short_id, absolute_uri(group.get_absolute_url(params=params))",
            "                )",
            "            ]",
            "",
            "        return [",
            "            \"Sentry Issue: [{}]({})\".format(",
            "                group.qualified_short_id, absolute_uri(group.get_absolute_url(params=params))",
            "            )",
            "        ]",
            "",
            "    def get_group_description(self, group, event, **kwargs):",
            "        output = self.get_group_link(group, **kwargs)",
            "        body = self.get_group_body(group, event)",
            "        if body:",
            "            output.extend([\"\", \"```\", body, \"```\"])",
            "        return \"\\n\".join(output)",
            "",
            "    @all_silo_function",
            "    def get_create_issue_config(",
            "        self, group: Group | None, user: User, **kwargs",
            "    ) -> list[dict[str, Any]]:",
            "        \"\"\"",
            "        These fields are used to render a form for the user,",
            "        and are then passed in the format of:",
            "",
            "        >>>{'title': 'TypeError: Object [object Object] has no method \"updateFrom\"'}",
            "",
            "        to `create_issue`, which handles creation of the issue",
            "        in Jira, VSTS, GitHub, etc",
            "        \"\"\"",
            "        if not group:",
            "            return []",
            "",
            "        event = group.get_latest_event()",
            "",
            "        return [",
            "            {",
            "                \"name\": \"title\",",
            "                \"label\": \"Title\",",
            "                \"default\": self.get_group_title(group, event, **kwargs),",
            "                \"type\": \"string\",",
            "                \"required\": True,",
            "            },",
            "            {",
            "                \"name\": \"description\",",
            "                \"label\": \"Description\",",
            "                \"default\": self.get_group_description(group, event, **kwargs),",
            "                \"type\": \"textarea\",",
            "                \"autosize\": True,",
            "                \"maxRows\": 10,",
            "            },",
            "        ]",
            "",
            "    def get_link_issue_config(self, group, **kwargs):",
            "        \"\"\"",
            "        Used by the `GroupIntegrationDetailsEndpoint` to create an",
            "        `ExternalIssue` using title/description obtained from calling",
            "        `get_issue` described below.",
            "        \"\"\"",
            "        return [{\"name\": \"externalIssue\", \"label\": \"Issue\", \"default\": \"\", \"type\": \"string\"}]",
            "",
            "    def get_persisted_default_config_fields(self) -> Sequence[str]:",
            "        \"\"\"",
            "        Returns a list of field names that should have their last used values",
            "        persisted on a per-project basis.",
            "        \"\"\"",
            "        return []",
            "",
            "    def get_persisted_user_default_config_fields(self):",
            "        \"\"\"",
            "        Returns a list of field names that should have their last used values",
            "        persisted on a per-project, per-user basis.",
            "        \"\"\"",
            "        return []",
            "",
            "    def store_issue_last_defaults(self, project: Project, user: RpcUser, data):",
            "        \"\"\"",
            "        Stores the last used field defaults on a per-project basis. This",
            "        accepts a dict of values that will be filtered to keys returned by",
            "        ``get_persisted_default_config_fields`` which will automatically be",
            "        merged into the associated field config object as the default.",
            "",
            "        >>> integ.store_issue_last_defaults(project, user, {'externalProject': 2})",
            "",
            "        When the integration is serialized these values will automatically be",
            "        merged into the field configuration objects.",
            "",
            "        NOTE: These are currently stored for both link and create issue, no",
            "              differentiation is made between the two field configs.",
            "        \"\"\"",
            "        persisted_fields = self.get_persisted_default_config_fields()",
            "        if persisted_fields:",
            "            project_defaults = {k: v for k, v in data.items() if k in persisted_fields}",
            "            new_config = deepcopy(self.org_integration.config)",
            "            new_config.setdefault(\"project_issue_defaults\", {}).setdefault(",
            "                str(project.id), {}",
            "            ).update(project_defaults)",
            "            self.org_integration = integration_service.update_organization_integration(",
            "                org_integration_id=self.org_integration.id,",
            "                config=new_config,",
            "            )",
            "",
            "        user_persisted_fields = self.get_persisted_user_default_config_fields()",
            "        if user_persisted_fields:",
            "            user_defaults = {k: v for k, v in data.items() if k in user_persisted_fields}",
            "            user_option_key = dict(key=\"issue:defaults\", project_id=project.id)",
            "            options = user_option_service.get_many(",
            "                filter={\"user_ids\": [user.id], **user_option_key}",
            "            )",
            "            new_user_defaults = get_option_from_list(options, default={}, key=\"issue:defaults\")",
            "            new_user_defaults.setdefault(self.model.provider, {}).update(user_defaults)",
            "            if user_defaults != new_user_defaults:",
            "                user_option_service.set_option(",
            "                    user_id=user.id, value=new_user_defaults, **user_option_key",
            "                )",
            "",
            "    def get_defaults(self, project: Project, user: User):",
            "        project_defaults = self.get_project_defaults(project.id)",
            "",
            "        user_option_value = get_option_from_list(",
            "            user_option_service.get_many(",
            "                filter={\"user_ids\": [user.id], \"keys\": [\"issue:defaults\"], \"project_id\": project.id}",
            "            ),",
            "            key=\"issue:defaults\",",
            "            default={},",
            "        )",
            "",
            "        user_defaults = user_option_value.get(self.model.provider, {})",
            "",
            "        defaults = {}",
            "        defaults.update(project_defaults)",
            "        defaults.update(user_defaults)",
            "",
            "        return defaults",
            "",
            "    # TODO(saif): Make private and move all usages over to `get_defaults`",
            "    def get_project_defaults(self, project_id):",
            "        return self.org_integration.config.get(\"project_issue_defaults\", {}).get(",
            "            str(project_id), {}",
            "        )",
            "",
            "    def create_issue(self, data, **kwargs):",
            "        \"\"\"",
            "        Create an issue via the provider's API and return the issue key,",
            "        title and description.",
            "",
            "        Should also handle API client exceptions and reraise as an",
            "        IntegrationError (using the `message_from_error` helper).",
            "",
            "        >>> def create_issue(self, data, **kwargs):",
            "        >>>     resp = self.get_client().create_issue(data)",
            "        >>>     return {",
            "        >>>         'key': resp['id'],",
            "        >>>         'title': resp['title'],",
            "        >>>         'description': resp['description'],",
            "        >>>     }",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue(self, issue_id, **kwargs):",
            "        \"\"\"",
            "        Get an issue via the provider's API and return the issue key,",
            "        title and description.",
            "",
            "        Should also handle API client exceptions and reraise as an",
            "        IntegrationError (using the `message_from_error` helper).",
            "",
            "        >>> def get_issue(self, data, **kwargs):",
            "        >>>     resp = self.get_client().get_issue(issue_id)",
            "        >>>     return {",
            "        >>>         'key': resp['id'],",
            "        >>>         'title': resp['title'],",
            "        >>>         'description': resp['description'],",
            "        >>>     }",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def after_link_issue(self, external_issue, **kwargs):",
            "        \"\"\"",
            "        Takes the external issue that has been linked via `get_issue`.",
            "",
            "        Does anything needed after an issue has been linked, i.e. creating",
            "        a comment for a linked issue.",
            "        \"\"\"",
            "",
            "    def make_external_key(self, data):",
            "        \"\"\"",
            "        Takes result of `get_issue` or `create_issue` and returns the formatted key",
            "        \"\"\"",
            "        return data[\"key\"]",
            "",
            "    def get_issue_display_name(self, external_issue):",
            "        \"\"\"",
            "        Returns the display name of the issue.",
            "",
            "        This is not required but helpful for integrations whose external issue key",
            "        does not match the desired display name.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def get_repository_choices(self, group: Group | None, params: Mapping[str, Any], **kwargs):",
            "        \"\"\"",
            "        Returns the default repository and a set/subset of repositories of associated with the installation",
            "        \"\"\"",
            "        try:",
            "            repos = self.get_repositories()",
            "        except ApiError:",
            "            raise IntegrationError(\"Unable to retrieve repositories. Please try again later.\")",
            "        else:",
            "            repo_choices = [(repo[\"identifier\"], repo[\"name\"]) for repo in repos]",
            "",
            "        defaults = self.get_project_defaults(group.project_id) if group else {}",
            "        repo = params.get(\"repo\") or defaults.get(\"repo\")",
            "",
            "        try:",
            "            default_repo = repo or repo_choices[0][0]",
            "        except IndexError:",
            "            return \"\", repo_choices",
            "",
            "        # If a repo has been selected outside of the default list of",
            "        # repos, stick it onto the front of the list so that it can be",
            "        # selected.",
            "        try:",
            "            next(True for r in repo_choices if r[0] == default_repo)",
            "        except StopIteration:",
            "            repo_choices.insert(0, self.create_default_repo_choice(default_repo))",
            "",
            "        return default_repo, repo_choices",
            "",
            "    def create_default_repo_choice(self, default_repo):",
            "        \"\"\"",
            "        Helper method for get_repository_choices",
            "        Returns the choice for the default repo in a tuple to be added to the list of repository choices",
            "        \"\"\"",
            "        return (default_repo, default_repo)",
            "",
            "    def get_annotations_for_group_list(self, group_list):",
            "        group_links = GroupLink.objects.filter(",
            "            group_id__in=[group.id for group in group_list],",
            "            project_id__in=list({group.project.id for group in group_list}),",
            "            linked_type=GroupLink.LinkedType.issue,",
            "            relationship=GroupLink.Relationship.references,",
            "        )",
            "",
            "        external_issues = ExternalIssue.objects.filter(",
            "            id__in=[group_link.linked_id for group_link in group_links],",
            "            integration_id=self.model.id,",
            "        )",
            "",
            "        # group annotations by group id",
            "        annotations_by_group_id = defaultdict(list)",
            "        for group_link in group_links:",
            "            issues_for_group = filter(lambda x: x.id == group_link.linked_id, external_issues)",
            "            annotations = self.map_external_issues_to_annotations(issues_for_group)",
            "            annotations_by_group_id[group_link.group_id].extend(annotations)",
            "",
            "        return annotations_by_group_id",
            "",
            "    def map_external_issues_to_annotations(self, external_issues):",
            "        annotations = []",
            "        for ei in external_issues:",
            "            link = self.get_issue_url(ei.key)",
            "            label = self.get_issue_display_name(ei) or ei.key",
            "            annotations.append(f'<a href=\"{link}\">{label}</a>')",
            "",
            "        return annotations",
            "",
            "    def get_comment_id(self, comment):",
            "        return comment[\"id\"]",
            "",
            "    def create_comment(self, issue_id, user_id, group_note):",
            "        pass",
            "",
            "    def update_comment(self, issue_id, user_id, group_note):",
            "        pass",
            "",
            "",
            "class IssueSyncMixin(IssueBasicMixin):",
            "    comment_key: ClassVar[str | None] = None",
            "    outbound_status_key: ClassVar[str | None] = None",
            "    inbound_status_key: ClassVar[str | None] = None",
            "    outbound_assignee_key: ClassVar[str | None] = None",
            "    inbound_assignee_key: ClassVar[str | None] = None",
            "",
            "    def should_sync(self, attribute: str) -> bool:",
            "        key = getattr(self, f\"{attribute}_key\", None)",
            "        if key is None or self.org_integration is None:",
            "            return False",
            "        value: bool = self.org_integration.config.get(key, False)",
            "        return value",
            "",
            "    def sync_assignee_outbound(",
            "        self,",
            "        external_issue: ExternalIssue,",
            "        user: RpcUser | None,",
            "        assign: bool = True,",
            "        **kwargs: Any,",
            "    ) -> None:",
            "        \"\"\"",
            "        Propagate a sentry issue's assignee to a linked issue's assignee.",
            "        If assign=True, we're assigning the issue. Otherwise, deassign.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def sync_status_outbound(self, external_issue, is_resolved, project_id, **kwargs):",
            "        \"\"\"",
            "        Propagate a sentry issue's status to a linked issue's status.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_resolve_sync_action(self, data: Mapping[str, Any]) -> ResolveSyncAction:",
            "        \"\"\"",
            "        Given webhook data, check whether the status category changed FROM",
            "        \"done\" to something else, meaning the Sentry issue should be marked as",
            "        unresolved or if the status category changed TO \"done\" from something",
            "        else, meaning the sentry issue should be marked as resolved.",
            "",
            "        Because checking the \"done\" states can rely on an API call, this function",
            "        should calculate both \"resolve\" and \"unresolve\" to save a round trip.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def sync_status_inbound(self, issue_key: str, data: Mapping[str, Any]) -> None:",
            "        if not where_should_sync(self.model, \"inbound_status\", self.organization_id):",
            "            return None",
            "",
            "        sync_status_inbound_task.apply_async(",
            "            kwargs={",
            "                \"integration_id\": self.model.id,",
            "                \"organization_id\": self.organization_id,",
            "                \"issue_key\": issue_key,",
            "                \"data\": data,",
            "            }",
            "        )",
            "",
            "    def migrate_issues(self):",
            "        \"\"\"",
            "        Migrate the corresponding plugin's issues to the integration and disable the plugins.",
            "        \"\"\""
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "import enum",
            "import logging",
            "from collections import defaultdict",
            "from collections.abc import Mapping, Sequence",
            "from copy import deepcopy",
            "from typing import Any, ClassVar",
            "",
            "from sentry.integrations.services.integration import integration_service",
            "from sentry.integrations.utils import where_should_sync",
            "from sentry.issues.grouptype import GroupCategory",
            "from sentry.models.group import Group",
            "from sentry.models.grouplink import GroupLink",
            "from sentry.models.integrations.external_issue import ExternalIssue",
            "from sentry.models.project import Project",
            "from sentry.models.user import User",
            "from sentry.notifications.utils import get_notification_group_title",
            "from sentry.shared_integrations.exceptions import ApiError, IntegrationError",
            "from sentry.silo.base import all_silo_function",
            "from sentry.tasks.integrations import sync_status_inbound as sync_status_inbound_task",
            "from sentry.users.services.user import RpcUser",
            "from sentry.users.services.user_option import get_option_from_list, user_option_service",
            "from sentry.utils.http import absolute_uri",
            "from sentry.utils.safe import safe_execute",
            "",
            "logger = logging.getLogger(\"sentry.integrations.issues\")",
            "MAX_CHAR = 50",
            "",
            "",
            "class ResolveSyncAction(enum.Enum):",
            "    \"\"\"",
            "    When an issue's state changes, we may have to sync the state based on the",
            "    \"done\" states we get from the API. This enum encapsulates the three options",
            "    we have: \"resolve\", \"unresolve\", or \"do nothing\".",
            "    \"\"\"",
            "",
            "    NOOP = 0",
            "    RESOLVE = 1",
            "    UNRESOLVE = 2",
            "",
            "    @classmethod",
            "    def from_resolve_unresolve(",
            "        cls, should_resolve: bool, should_unresolve: bool",
            "    ) -> ResolveSyncAction:",
            "        if should_resolve and should_unresolve:",
            "            logger.warning(\"sync-config-conflict\")",
            "            return ResolveSyncAction.NOOP",
            "",
            "        if should_resolve:",
            "            return ResolveSyncAction.RESOLVE",
            "",
            "        if should_unresolve:",
            "            return ResolveSyncAction.UNRESOLVE",
            "",
            "        return ResolveSyncAction.NOOP",
            "",
            "",
            "class IssueBasicMixin:",
            "    def should_sync(self, attribute):",
            "        return False",
            "",
            "    def get_group_title(self, group, event, **kwargs):",
            "        return get_notification_group_title(group, event, **kwargs)",
            "",
            "    def get_issue_url(self, key):",
            "        \"\"\"",
            "        Given the key of the external_issue return the external issue link.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_group_body(self, group, event, **kwargs):",
            "        result = []",
            "        for interface in event.interfaces.values():",
            "            output = safe_execute(interface.to_string, event)",
            "            if output:",
            "                result.append(output)",
            "        return \"\\n\\n\".join(result)",
            "",
            "    def get_group_link(self, group, **kwargs):",
            "        params = {}",
            "        if kwargs.get(\"link_referrer\"):",
            "            params[\"referrer\"] = kwargs.get(\"link_referrer\")",
            "",
            "        if group.issue_category == GroupCategory.FEEDBACK:",
            "            return [",
            "                \"Sentry Feedback: [{}]({})\\n\".format(",
            "                    group.qualified_short_id, absolute_uri(group.get_absolute_url(params=params))",
            "                )",
            "            ]",
            "",
            "        return [",
            "            \"Sentry Issue: [{}]({})\".format(",
            "                group.qualified_short_id, absolute_uri(group.get_absolute_url(params=params))",
            "            )",
            "        ]",
            "",
            "    def get_group_description(self, group, event, **kwargs):",
            "        output = self.get_group_link(group, **kwargs)",
            "        body = self.get_group_body(group, event)",
            "        if body:",
            "            output.extend([\"\", \"```\", body, \"```\"])",
            "        return \"\\n\".join(output)",
            "",
            "    @all_silo_function",
            "    def get_create_issue_config(",
            "        self, group: Group | None, user: User, **kwargs",
            "    ) -> list[dict[str, Any]]:",
            "        \"\"\"",
            "        These fields are used to render a form for the user,",
            "        and are then passed in the format of:",
            "",
            "        >>>{'title': 'TypeError: Object [object Object] has no method \"updateFrom\"'}",
            "",
            "        to `create_issue`, which handles creation of the issue",
            "        in Jira, VSTS, GitHub, etc",
            "        \"\"\"",
            "        if not group:",
            "            return []",
            "",
            "        event = group.get_latest_event()",
            "",
            "        return [",
            "            {",
            "                \"name\": \"title\",",
            "                \"label\": \"Title\",",
            "                \"default\": self.get_group_title(group, event, **kwargs),",
            "                \"type\": \"string\",",
            "                \"required\": True,",
            "            },",
            "            {",
            "                \"name\": \"description\",",
            "                \"label\": \"Description\",",
            "                \"default\": self.get_group_description(group, event, **kwargs),",
            "                \"type\": \"textarea\",",
            "                \"autosize\": True,",
            "                \"maxRows\": 10,",
            "            },",
            "        ]",
            "",
            "    def get_link_issue_config(self, group, **kwargs):",
            "        \"\"\"",
            "        Used by the `GroupIntegrationDetailsEndpoint` to create an",
            "        `ExternalIssue` using title/description obtained from calling",
            "        `get_issue` described below.",
            "        \"\"\"",
            "        return [{\"name\": \"externalIssue\", \"label\": \"Issue\", \"default\": \"\", \"type\": \"string\"}]",
            "",
            "    def get_persisted_default_config_fields(self) -> Sequence[str]:",
            "        \"\"\"",
            "        Returns a list of field names that should have their last used values",
            "        persisted on a per-project basis.",
            "        \"\"\"",
            "        return []",
            "",
            "    def get_persisted_user_default_config_fields(self):",
            "        \"\"\"",
            "        Returns a list of field names that should have their last used values",
            "        persisted on a per-project, per-user basis.",
            "        \"\"\"",
            "        return []",
            "",
            "    def store_issue_last_defaults(self, project: Project, user: RpcUser, data):",
            "        \"\"\"",
            "        Stores the last used field defaults on a per-project basis. This",
            "        accepts a dict of values that will be filtered to keys returned by",
            "        ``get_persisted_default_config_fields`` which will automatically be",
            "        merged into the associated field config object as the default.",
            "",
            "        >>> integ.store_issue_last_defaults(project, user, {'externalProject': 2})",
            "",
            "        When the integration is serialized these values will automatically be",
            "        merged into the field configuration objects.",
            "",
            "        NOTE: These are currently stored for both link and create issue, no",
            "              differentiation is made between the two field configs.",
            "        \"\"\"",
            "        persisted_fields = self.get_persisted_default_config_fields()",
            "        if persisted_fields:",
            "            project_defaults = {k: v for k, v in data.items() if k in persisted_fields}",
            "            new_config = deepcopy(self.org_integration.config)",
            "            new_config.setdefault(\"project_issue_defaults\", {}).setdefault(",
            "                str(project.id), {}",
            "            ).update(project_defaults)",
            "            self.org_integration = integration_service.update_organization_integration(",
            "                org_integration_id=self.org_integration.id,",
            "                config=new_config,",
            "            )",
            "",
            "        user_persisted_fields = self.get_persisted_user_default_config_fields()",
            "        if user_persisted_fields:",
            "            user_defaults = {k: v for k, v in data.items() if k in user_persisted_fields}",
            "            user_option_key = dict(key=\"issue:defaults\", project_id=project.id)",
            "            options = user_option_service.get_many(",
            "                filter={\"user_ids\": [user.id], **user_option_key}",
            "            )",
            "            new_user_defaults = get_option_from_list(options, default={}, key=\"issue:defaults\")",
            "            new_user_defaults.setdefault(self.model.provider, {}).update(user_defaults)",
            "            if user_defaults != new_user_defaults:",
            "                user_option_service.set_option(",
            "                    user_id=user.id, value=new_user_defaults, **user_option_key",
            "                )",
            "",
            "    def get_defaults(self, project: Project, user: User):",
            "        project_defaults = self.get_project_defaults(project.id)",
            "",
            "        user_option_value = get_option_from_list(",
            "            user_option_service.get_many(",
            "                filter={\"user_ids\": [user.id], \"keys\": [\"issue:defaults\"], \"project_id\": project.id}",
            "            ),",
            "            key=\"issue:defaults\",",
            "            default={},",
            "        )",
            "",
            "        user_defaults = user_option_value.get(self.model.provider, {})",
            "",
            "        defaults = {}",
            "        defaults.update(project_defaults)",
            "        defaults.update(user_defaults)",
            "",
            "        return defaults",
            "",
            "    # TODO(saif): Make private and move all usages over to `get_defaults`",
            "    def get_project_defaults(self, project_id):",
            "        return self.org_integration.config.get(\"project_issue_defaults\", {}).get(",
            "            str(project_id), {}",
            "        )",
            "",
            "    def create_issue(self, data, **kwargs):",
            "        \"\"\"",
            "        Create an issue via the provider's API and return the issue key,",
            "        title and description.",
            "",
            "        Should also handle API client exceptions and reraise as an",
            "        IntegrationError (using the `message_from_error` helper).",
            "",
            "        >>> def create_issue(self, data, **kwargs):",
            "        >>>     resp = self.get_client().create_issue(data)",
            "        >>>     return {",
            "        >>>         'key': resp['id'],",
            "        >>>         'title': resp['title'],",
            "        >>>         'description': resp['description'],",
            "        >>>     }",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue(self, issue_id, **kwargs):",
            "        \"\"\"",
            "        Get an issue via the provider's API and return the issue key,",
            "        title and description.",
            "",
            "        Should also handle API client exceptions and reraise as an",
            "        IntegrationError (using the `message_from_error` helper).",
            "",
            "        >>> def get_issue(self, data, **kwargs):",
            "        >>>     resp = self.get_client().get_issue(issue_id)",
            "        >>>     return {",
            "        >>>         'key': resp['id'],",
            "        >>>         'title': resp['title'],",
            "        >>>         'description': resp['description'],",
            "        >>>     }",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def after_link_issue(self, external_issue, **kwargs):",
            "        \"\"\"",
            "        Takes the external issue that has been linked via `get_issue`.",
            "",
            "        Does anything needed after an issue has been linked, i.e. creating",
            "        a comment for a linked issue.",
            "        \"\"\"",
            "",
            "    def make_external_key(self, data):",
            "        \"\"\"",
            "        Takes result of `get_issue` or `create_issue` and returns the formatted key",
            "        \"\"\"",
            "        return data[\"key\"]",
            "",
            "    def get_issue_display_name(self, external_issue):",
            "        \"\"\"",
            "        Returns the display name of the issue.",
            "",
            "        This is not required but helpful for integrations whose external issue key",
            "        does not match the desired display name.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def get_repository_choices(self, group: Group | None, params: Mapping[str, Any], **kwargs):",
            "        \"\"\"",
            "        Returns the default repository and a set/subset of repositories of associated with the installation",
            "        \"\"\"",
            "        try:",
            "            repos = self.get_repositories()",
            "        except ApiError:",
            "            raise IntegrationError(\"Unable to retrieve repositories. Please try again later.\")",
            "        else:",
            "            repo_choices = [(repo[\"identifier\"], repo[\"name\"]) for repo in repos]",
            "",
            "        defaults = self.get_project_defaults(group.project_id) if group else {}",
            "        repo = params.get(\"repo\") or defaults.get(\"repo\")",
            "",
            "        try:",
            "            default_repo = repo or repo_choices[0][0]",
            "        except IndexError:",
            "            return \"\", repo_choices",
            "",
            "        # If a repo has been selected outside of the default list of",
            "        # repos, stick it onto the front of the list so that it can be",
            "        # selected.",
            "        try:",
            "            next(True for r in repo_choices if r[0] == default_repo)",
            "        except StopIteration:",
            "            repo_choices.insert(0, self.create_default_repo_choice(default_repo))",
            "",
            "        return default_repo, repo_choices",
            "",
            "    def create_default_repo_choice(self, default_repo):",
            "        \"\"\"",
            "        Helper method for get_repository_choices",
            "        Returns the choice for the default repo in a tuple to be added to the list of repository choices",
            "        \"\"\"",
            "        return (default_repo, default_repo)",
            "",
            "    def get_annotations_for_group_list(self, group_list):",
            "        group_links = GroupLink.objects.filter(",
            "            group_id__in=[group.id for group in group_list],",
            "            project_id__in=list({group.project.id for group in group_list}),",
            "            linked_type=GroupLink.LinkedType.issue,",
            "            relationship=GroupLink.Relationship.references,",
            "        )",
            "",
            "        external_issues = ExternalIssue.objects.filter(",
            "            id__in=[group_link.linked_id for group_link in group_links],",
            "            integration_id=self.model.id,",
            "        )",
            "",
            "        # group annotations by group id",
            "        annotations_by_group_id = defaultdict(list)",
            "        for group_link in group_links:",
            "            issues_for_group = filter(lambda x: x.id == group_link.linked_id, external_issues)",
            "            annotations = self.map_external_issues_to_annotations(issues_for_group)",
            "            annotations_by_group_id[group_link.group_id].extend(annotations)",
            "",
            "        return annotations_by_group_id",
            "",
            "    def map_external_issues_to_annotations(self, external_issues):",
            "        annotations = []",
            "        for ei in external_issues:",
            "            link = self.get_issue_url(ei.key)",
            "            label = self.get_issue_display_name(ei) or ei.key",
            "            annotations.append({\"url\": link, \"displayName\": label})",
            "",
            "        return annotations",
            "",
            "    def get_comment_id(self, comment):",
            "        return comment[\"id\"]",
            "",
            "    def create_comment(self, issue_id, user_id, group_note):",
            "        pass",
            "",
            "    def update_comment(self, issue_id, user_id, group_note):",
            "        pass",
            "",
            "",
            "class IssueSyncMixin(IssueBasicMixin):",
            "    comment_key: ClassVar[str | None] = None",
            "    outbound_status_key: ClassVar[str | None] = None",
            "    inbound_status_key: ClassVar[str | None] = None",
            "    outbound_assignee_key: ClassVar[str | None] = None",
            "    inbound_assignee_key: ClassVar[str | None] = None",
            "",
            "    def should_sync(self, attribute: str) -> bool:",
            "        key = getattr(self, f\"{attribute}_key\", None)",
            "        if key is None or self.org_integration is None:",
            "            return False",
            "        value: bool = self.org_integration.config.get(key, False)",
            "        return value",
            "",
            "    def sync_assignee_outbound(",
            "        self,",
            "        external_issue: ExternalIssue,",
            "        user: RpcUser | None,",
            "        assign: bool = True,",
            "        **kwargs: Any,",
            "    ) -> None:",
            "        \"\"\"",
            "        Propagate a sentry issue's assignee to a linked issue's assignee.",
            "        If assign=True, we're assigning the issue. Otherwise, deassign.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def sync_status_outbound(self, external_issue, is_resolved, project_id, **kwargs):",
            "        \"\"\"",
            "        Propagate a sentry issue's status to a linked issue's status.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_resolve_sync_action(self, data: Mapping[str, Any]) -> ResolveSyncAction:",
            "        \"\"\"",
            "        Given webhook data, check whether the status category changed FROM",
            "        \"done\" to something else, meaning the Sentry issue should be marked as",
            "        unresolved or if the status category changed TO \"done\" from something",
            "        else, meaning the sentry issue should be marked as resolved.",
            "",
            "        Because checking the \"done\" states can rely on an API call, this function",
            "        should calculate both \"resolve\" and \"unresolve\" to save a round trip.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def sync_status_inbound(self, issue_key: str, data: Mapping[str, Any]) -> None:",
            "        if not where_should_sync(self.model, \"inbound_status\", self.organization_id):",
            "            return None",
            "",
            "        sync_status_inbound_task.apply_async(",
            "            kwargs={",
            "                \"integration_id\": self.model.id,",
            "                \"organization_id\": self.organization_id,",
            "                \"issue_key\": issue_key,",
            "                \"data\": data,",
            "            }",
            "        )",
            "",
            "    def migrate_issues(self):",
            "        \"\"\"",
            "        Migrate the corresponding plugin's issues to the integration and disable the plugins.",
            "        \"\"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "351": [
                "IssueBasicMixin",
                "map_external_issues_to_annotations"
            ]
        },
        "addLocation": []
    },
    "src/sentry/models/platformexternalissue.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "         # group annotations by group id"
            },
            "1": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 36,
                "PatchRowcode": "         annotations_by_group_id = defaultdict(list)"
            },
            "2": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "         for ei in external_issues:"
            },
            "3": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            annotation = f'<a href=\"{ei.web_url}\">{ei.display_name}</a>'"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+            annotation = {\"url\": ei.web_url, \"displayName\": ei.display_name}"
            },
            "5": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "             annotations_by_group_id[ei.group_id].append(annotation)"
            },
            "6": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "         return annotations_by_group_id"
            }
        },
        "frontPatchFile": [
            "from collections import defaultdict",
            "",
            "from django.db import models",
            "from django.utils import timezone",
            "",
            "from sentry.backup.scopes import RelocationScope",
            "from sentry.db.models import Model, region_silo_model, sane_repr",
            "from sentry.db.models.fields.foreignkey import FlexibleForeignKey",
            "",
            "",
            "@region_silo_model",
            "class PlatformExternalIssue(Model):",
            "    __relocation_scope__ = RelocationScope.Excluded",
            "",
            "    group = FlexibleForeignKey(\"sentry.Group\", db_constraint=False, db_index=False)",
            "    project = FlexibleForeignKey(\"sentry.Project\", null=True, db_constraint=False)",
            "",
            "    # external service that's linked to the sentry issue",
            "    service_type = models.CharField(max_length=64)",
            "    display_name = models.TextField()",
            "    web_url = models.URLField()",
            "    date_added = models.DateTimeField(default=timezone.now)",
            "",
            "    class Meta:",
            "        app_label = \"sentry\"",
            "        db_table = \"sentry_platformexternalissue\"",
            "        unique_together = ((\"group\", \"service_type\"),)",
            "",
            "    __repr__ = sane_repr(\"group_id\", \"service_type\", \"display_name\", \"web_url\")",
            "",
            "    @classmethod",
            "    def get_annotations_for_group_list(cls, group_list):",
            "        external_issues = cls.objects.filter(group_id__in=[group.id for group in group_list])",
            "",
            "        # group annotations by group id",
            "        annotations_by_group_id = defaultdict(list)",
            "        for ei in external_issues:",
            "            annotation = f'<a href=\"{ei.web_url}\">{ei.display_name}</a>'",
            "            annotations_by_group_id[ei.group_id].append(annotation)",
            "",
            "        return annotations_by_group_id"
        ],
        "afterPatchFile": [
            "from collections import defaultdict",
            "",
            "from django.db import models",
            "from django.utils import timezone",
            "",
            "from sentry.backup.scopes import RelocationScope",
            "from sentry.db.models import Model, region_silo_model, sane_repr",
            "from sentry.db.models.fields.foreignkey import FlexibleForeignKey",
            "",
            "",
            "@region_silo_model",
            "class PlatformExternalIssue(Model):",
            "    __relocation_scope__ = RelocationScope.Excluded",
            "",
            "    group = FlexibleForeignKey(\"sentry.Group\", db_constraint=False, db_index=False)",
            "    project = FlexibleForeignKey(\"sentry.Project\", null=True, db_constraint=False)",
            "",
            "    # external service that's linked to the sentry issue",
            "    service_type = models.CharField(max_length=64)",
            "    display_name = models.TextField()",
            "    web_url = models.URLField()",
            "    date_added = models.DateTimeField(default=timezone.now)",
            "",
            "    class Meta:",
            "        app_label = \"sentry\"",
            "        db_table = \"sentry_platformexternalissue\"",
            "        unique_together = ((\"group\", \"service_type\"),)",
            "",
            "    __repr__ = sane_repr(\"group_id\", \"service_type\", \"display_name\", \"web_url\")",
            "",
            "    @classmethod",
            "    def get_annotations_for_group_list(cls, group_list):",
            "        external_issues = cls.objects.filter(group_id__in=[group.id for group in group_list])",
            "",
            "        # group annotations by group id",
            "        annotations_by_group_id = defaultdict(list)",
            "        for ei in external_issues:",
            "            annotation = {\"url\": ei.web_url, \"displayName\": ei.display_name}",
            "            annotations_by_group_id[ei.group_id].append(annotation)",
            "",
            "        return annotations_by_group_id"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "38": [
                "PlatformExternalIssue",
                "get_annotations_for_group_list"
            ]
        },
        "addLocation": []
    },
    "src/sentry/plugins/bases/issue.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from django import forms"
            },
            "2": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from django.conf import settings"
            },
            "3": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from django.utils.html import format_html"
            },
            "4": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from rest_framework.request import Request"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from sentry.models.activity import Activity"
            },
            "7": {
                "beforePatchRowNumber": 312,
                "afterPatchRowNumber": 311,
                "PatchRowcode": "             return tag_list"
            },
            "8": {
                "beforePatchRowNumber": 313,
                "afterPatchRowNumber": 312,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": 313,
                "PatchRowcode": "         tag_list.append("
            },
            "10": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            format_html("
            },
            "11": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                '<a href=\"{}\" rel=\"noreferrer\">{}</a>',"
            },
            "12": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                self.get_issue_url(group=group, issue_id=issue_id),"
            },
            "13": {
                "beforePatchRowNumber": 318,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                self.get_issue_label(group=group, issue_id=issue_id),"
            },
            "14": {
                "beforePatchRowNumber": 319,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            )"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 314,
                "PatchRowcode": "+            {"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 315,
                "PatchRowcode": "+                \"url\": self.get_issue_url(group=group, issue_id=issue_id),"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 316,
                "PatchRowcode": "+                \"displayName\": self.get_issue_label(group=group, issue_id=issue_id),"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 317,
                "PatchRowcode": "+            }"
            },
            "19": {
                "beforePatchRowNumber": 320,
                "afterPatchRowNumber": 318,
                "PatchRowcode": "         )"
            },
            "20": {
                "beforePatchRowNumber": 321,
                "afterPatchRowNumber": 319,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 322,
                "afterPatchRowNumber": 320,
                "PatchRowcode": "         return tag_list"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "from django import forms",
            "from django.conf import settings",
            "from django.utils.html import format_html",
            "from rest_framework.request import Request",
            "",
            "from sentry.models.activity import Activity",
            "from sentry.models.groupmeta import GroupMeta",
            "from sentry.plugins.base.v1 import Plugin",
            "from sentry.signals import issue_tracker_used",
            "from sentry.types.activity import ActivityType",
            "from sentry.users.services.usersocialauth.model import RpcUserSocialAuth",
            "from sentry.users.services.usersocialauth.service import usersocialauth_service",
            "from sentry.utils.auth import get_auth_providers",
            "from sentry.utils.http import absolute_uri",
            "from sentry.utils.safe import safe_execute",
            "",
            "",
            "class NewIssueForm(forms.Form):",
            "    title = forms.CharField(max_length=200, widget=forms.TextInput(attrs={\"class\": \"span9\"}))",
            "    description = forms.CharField(widget=forms.Textarea(attrs={\"class\": \"span9\"}))",
            "",
            "",
            "class IssueTrackingPlugin(Plugin):",
            "    # project_conf_form = BaseIssueOptionsForm",
            "    new_issue_form: type[forms.Form] = NewIssueForm",
            "    link_issue_form = None",
            "",
            "    create_issue_template = \"sentry/plugins/bases/issue/create_issue.html\"",
            "    not_configured_template = \"sentry/plugins/bases/issue/not_configured.html\"",
            "    needs_auth_template = \"sentry/plugins/bases/issue/needs_auth.html\"",
            "    auth_provider: str | None = None",
            "    can_unlink_issues = False",
            "    can_link_existing_issues = False",
            "",
            "    def get_plugin_type(self):",
            "        return \"issue-tracking\"",
            "",
            "    def _get_group_body(self, request: Request, group, event, **kwargs):",
            "        result = []",
            "        for interface in event.interfaces.values():",
            "            output = safe_execute(interface.to_string, event)",
            "            if output:",
            "                result.append(output)",
            "        return \"\\n\\n\".join(result)",
            "",
            "    def _get_group_description(self, request: Request, group, event):",
            "        referrer = self.get_conf_key() + \"_plugin\"",
            "        output = [absolute_uri(group.get_absolute_url(params={\"referrer\": referrer}))]",
            "        body = self._get_group_body(request, group, event)",
            "        if body:",
            "            output.extend([\"\", \"```\", body, \"```\"])",
            "        return \"\\n\".join(output)",
            "",
            "    def _get_group_title(self, request: Request, group, event):",
            "        return event.title",
            "",
            "    def is_configured(self, request: Request, project, **kwargs):",
            "        raise NotImplementedError",
            "",
            "    def get_auth_for_user(self, user, **kwargs) -> RpcUserSocialAuth:",
            "        \"\"\"",
            "        Return a ``RpcUserSocialAuth`` object for the given user based on this plugins ``auth_provider``.",
            "        \"\"\"",
            "        assert self.auth_provider, \"There is no auth provider configured for this plugin.\"",
            "",
            "        if not user.is_authenticated:",
            "            return None",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return auth",
            "",
            "    def needs_auth(self, request: Request, project, **kwargs):",
            "        \"\"\"",
            "        Return ``True`` if the authenticated user needs to associate an auth service before",
            "        performing actions with this plugin.",
            "        \"\"\"",
            "        if self.auth_provider is None:",
            "            return False",
            "",
            "        if not request.user.is_authenticated:",
            "            return True",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": request.user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return bool(auth)",
            "",
            "    def get_new_issue_title(self, **kwargs):",
            "        \"\"\"",
            "        Return a string for the \"Create new issue\" action label.",
            "        \"\"\"",
            "        return \"Create %s Issue\" % self.get_title()",
            "",
            "    def get_unlink_issue_title(self, **kwargs):",
            "        \"\"\"",
            "        Return a string for the \"Unlink plugin issue\" action label.",
            "        \"\"\"",
            "        return \"Unlink %s Issue\" % self.get_title()",
            "",
            "    def get_new_issue_form(self, request: Request, group, event, **kwargs):",
            "        \"\"\"",
            "        Return a Form for the \"Create new issue\" page.",
            "        \"\"\"",
            "        return self.new_issue_form(",
            "            request.POST or None, initial=self.get_initial_form_data(request, group, event)",
            "        )",
            "",
            "    def get_new_issue_read_only_fields(self, *args, **kwargs):",
            "        \"\"\"",
            "        Return a list of additional read only fields that are helpful to",
            "        know when filing the issue.",
            "        \"\"\"",
            "        return []",
            "",
            "    def get_link_existing_issue_form(self, request: Request, group, event, **kwargs):",
            "        if not self.link_issue_form:",
            "            return None",
            "        return self.link_issue_form(",
            "            request.POST or None, initial=self.get_initial_link_form_data(request, group, event)",
            "        )",
            "",
            "    def get_issue_url(self, group, issue_id, **kwargs):",
            "        \"\"\"",
            "        Given an issue_id (string) return an absolute URL to the issue's details",
            "        page.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue_title_by_id(self, request: Request, group, issue_id):",
            "        \"\"\"",
            "        Given an issue_id return the issue's title.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue_label(self, group, issue_id, **kwargs):",
            "        \"\"\"",
            "        Given an issue_id (string) return a string representing the issue.",
            "",
            "        e.g. GitHub represents issues as GH-XXX",
            "        \"\"\"",
            "        return \"#%s\" % issue_id",
            "",
            "    def create_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Creates the issue on the remote service and returns an issue ID.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def link_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Can be overridden for any actions needed when linking issues",
            "        (like adding a comment to an existing issue).",
            "        \"\"\"",
            "",
            "    def get_initial_form_data(self, request: Request, group, event, **kwargs):",
            "        return {",
            "            \"description\": self._get_group_description(request, group, event),",
            "            \"title\": self._get_group_title(request, group, event),",
            "        }",
            "",
            "    def get_initial_link_form_data(self, request: Request, group, event, **kwargs):",
            "        return {}",
            "",
            "    def has_auth_configured(self, **kwargs):",
            "        if not self.auth_provider:",
            "            return True",
            "",
            "        return self.auth_provider in get_auth_providers()",
            "",
            "    def handle_unlink_issue(self, request: Request, group, **kwargs):",
            "        GroupMeta.objects.unset_value(group, \"%s:tid\" % self.get_conf_key())",
            "        return self.redirect(group.get_absolute_url())",
            "",
            "    def view(self, request: Request, group, **kwargs):",
            "        has_auth_configured = self.has_auth_configured()",
            "        if not (has_auth_configured and self.is_configured(project=group.project, request=request)):",
            "            if self.auth_provider:",
            "                required_auth_settings = settings.AUTH_PROVIDERS[self.auth_provider]",
            "            else:",
            "                required_auth_settings = None",
            "",
            "            project = group.project",
            "",
            "            return self.render(",
            "                self.not_configured_template,",
            "                {",
            "                    \"title\": self.get_title(),",
            "                    \"project\": group.project,",
            "                    \"has_auth_configured\": has_auth_configured,",
            "                    \"required_auth_settings\": required_auth_settings,",
            "                    \"plugin_link\": f\"/settings/{project.organization.slug}/projects/{project.slug}/plugins/{self.slug}/\",",
            "                },",
            "            )",
            "",
            "        if self.needs_auth(project=group.project, request=request):",
            "            return self.render(",
            "                self.needs_auth_template, {\"title\": self.get_title(), \"project\": group.project}",
            "            )",
            "",
            "        if GroupMeta.objects.get_value(group, \"%s:tid\" % self.get_conf_key(), None):",
            "            if self.can_unlink_issues and request.GET.get(\"unlink\"):",
            "                return self.handle_unlink_issue(request, group, **kwargs)",
            "            return None",
            "",
            "        prefix = self.get_conf_key()",
            "        event = group.get_latest_event()",
            "",
            "        op = request.POST.get(\"op\", \"create\")",
            "",
            "        create_form = self.get_new_issue_form(request, group, event)",
            "        link_form = None",
            "        if self.can_link_existing_issues:",
            "            link_form = self.get_link_existing_issue_form(request, group, event)",
            "",
            "        if op == \"create\":",
            "            issue_id = None",
            "            if create_form.is_valid():",
            "                try:",
            "                    issue_id = self.create_issue(",
            "                        group=group, form_data=create_form.cleaned_data, request=request",
            "                    )",
            "                except forms.ValidationError as e:",
            "                    create_form.errors[\"__all__\"] = [\"Error creating issue: %s\" % e]",
            "",
            "            if create_form.is_valid():",
            "                GroupMeta.objects.set_value(group, \"%s:tid\" % prefix, issue_id)",
            "",
            "                issue_information = {",
            "                    \"title\": create_form.cleaned_data[\"title\"],",
            "                    \"provider\": self.get_title(),",
            "                    \"location\": self.get_issue_url(group, issue_id),",
            "                    \"label\": self.get_issue_label(group=group, issue_id=issue_id),",
            "                }",
            "                Activity.objects.create(",
            "                    project=group.project,",
            "                    group=group,",
            "                    type=ActivityType.CREATE_ISSUE.value,",
            "                    user_id=request.user.id,",
            "                    data=issue_information,",
            "                )",
            "",
            "                issue_tracker_used.send_robust(",
            "                    plugin=self,",
            "                    project=group.project,",
            "                    user=request.user,",
            "                    sender=IssueTrackingPlugin,",
            "                )",
            "                return self.redirect(group.get_absolute_url())",
            "",
            "        elif op == \"link\":",
            "            if link_form.is_valid():",
            "                try:",
            "                    self.link_issue(group=group, form_data=link_form.cleaned_data, request=request)",
            "                except forms.ValidationError as e:",
            "                    link_form.errors[\"__all__\"] = [\"Error creating issue: %s\" % e]",
            "",
            "            if link_form.is_valid():",
            "                issue_id = int(link_form.cleaned_data[\"issue_id\"])",
            "                GroupMeta.objects.set_value(group, \"%s:tid\" % prefix, issue_id)",
            "                issue_information = {",
            "                    \"title\": self.get_issue_title_by_id(request, group, issue_id),",
            "                    \"provider\": self.get_title(),",
            "                    \"location\": self.get_issue_url(group, issue_id),",
            "                    \"label\": self.get_issue_label(group=group, issue_id=issue_id),",
            "                }",
            "                Activity.objects.create(",
            "                    project=group.project,",
            "                    group=group,",
            "                    type=ActivityType.CREATE_ISSUE.value,",
            "                    user_id=request.user.id,",
            "                    data=issue_information,",
            "                )",
            "",
            "                return self.redirect(group.get_absolute_url())",
            "",
            "        context = {",
            "            \"create_form\": create_form,",
            "            # pass in 'form' for legacy compat",
            "            \"form\": create_form,",
            "            \"title\": self.get_new_issue_title(),",
            "            \"read_only_fields\": self.get_new_issue_read_only_fields(group=group),",
            "            \"can_link_existing_issues\": self.can_link_existing_issues,",
            "            \"link_form\": link_form,",
            "            \"op\": op,",
            "        }",
            "",
            "        return self.render(self.create_issue_template, context)",
            "",
            "    def actions(self, request: Request, group, action_list, **kwargs):",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return action_list",
            "        prefix = self.get_conf_key()",
            "        if not GroupMeta.objects.get_value(group, \"%s:tid\" % prefix, None):",
            "            action_list.append((self.get_new_issue_title(), self.get_url(group)))",
            "        elif self.can_unlink_issues:",
            "            action_list.append(",
            "                (self.get_unlink_issue_title(), \"%s?unlink=1\" % self.get_url(group).rstrip(\"/\"))",
            "            )",
            "        return action_list",
            "",
            "    def tags(self, request: Request, group, tag_list, **kwargs):",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return tag_list",
            "",
            "        prefix = self.get_conf_key()",
            "        issue_id = GroupMeta.objects.get_value(group, \"%s:tid\" % prefix)",
            "        if not issue_id:",
            "            return tag_list",
            "",
            "        tag_list.append(",
            "            format_html(",
            "                '<a href=\"{}\" rel=\"noreferrer\">{}</a>',",
            "                self.get_issue_url(group=group, issue_id=issue_id),",
            "                self.get_issue_label(group=group, issue_id=issue_id),",
            "            )",
            "        )",
            "",
            "        return tag_list",
            "",
            "    def get_issue_doc_html(self, **kwargs):",
            "        return \"\"",
            "",
            "",
            "IssuePlugin = IssueTrackingPlugin"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "from django import forms",
            "from django.conf import settings",
            "from rest_framework.request import Request",
            "",
            "from sentry.models.activity import Activity",
            "from sentry.models.groupmeta import GroupMeta",
            "from sentry.plugins.base.v1 import Plugin",
            "from sentry.signals import issue_tracker_used",
            "from sentry.types.activity import ActivityType",
            "from sentry.users.services.usersocialauth.model import RpcUserSocialAuth",
            "from sentry.users.services.usersocialauth.service import usersocialauth_service",
            "from sentry.utils.auth import get_auth_providers",
            "from sentry.utils.http import absolute_uri",
            "from sentry.utils.safe import safe_execute",
            "",
            "",
            "class NewIssueForm(forms.Form):",
            "    title = forms.CharField(max_length=200, widget=forms.TextInput(attrs={\"class\": \"span9\"}))",
            "    description = forms.CharField(widget=forms.Textarea(attrs={\"class\": \"span9\"}))",
            "",
            "",
            "class IssueTrackingPlugin(Plugin):",
            "    # project_conf_form = BaseIssueOptionsForm",
            "    new_issue_form: type[forms.Form] = NewIssueForm",
            "    link_issue_form = None",
            "",
            "    create_issue_template = \"sentry/plugins/bases/issue/create_issue.html\"",
            "    not_configured_template = \"sentry/plugins/bases/issue/not_configured.html\"",
            "    needs_auth_template = \"sentry/plugins/bases/issue/needs_auth.html\"",
            "    auth_provider: str | None = None",
            "    can_unlink_issues = False",
            "    can_link_existing_issues = False",
            "",
            "    def get_plugin_type(self):",
            "        return \"issue-tracking\"",
            "",
            "    def _get_group_body(self, request: Request, group, event, **kwargs):",
            "        result = []",
            "        for interface in event.interfaces.values():",
            "            output = safe_execute(interface.to_string, event)",
            "            if output:",
            "                result.append(output)",
            "        return \"\\n\\n\".join(result)",
            "",
            "    def _get_group_description(self, request: Request, group, event):",
            "        referrer = self.get_conf_key() + \"_plugin\"",
            "        output = [absolute_uri(group.get_absolute_url(params={\"referrer\": referrer}))]",
            "        body = self._get_group_body(request, group, event)",
            "        if body:",
            "            output.extend([\"\", \"```\", body, \"```\"])",
            "        return \"\\n\".join(output)",
            "",
            "    def _get_group_title(self, request: Request, group, event):",
            "        return event.title",
            "",
            "    def is_configured(self, request: Request, project, **kwargs):",
            "        raise NotImplementedError",
            "",
            "    def get_auth_for_user(self, user, **kwargs) -> RpcUserSocialAuth:",
            "        \"\"\"",
            "        Return a ``RpcUserSocialAuth`` object for the given user based on this plugins ``auth_provider``.",
            "        \"\"\"",
            "        assert self.auth_provider, \"There is no auth provider configured for this plugin.\"",
            "",
            "        if not user.is_authenticated:",
            "            return None",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return auth",
            "",
            "    def needs_auth(self, request: Request, project, **kwargs):",
            "        \"\"\"",
            "        Return ``True`` if the authenticated user needs to associate an auth service before",
            "        performing actions with this plugin.",
            "        \"\"\"",
            "        if self.auth_provider is None:",
            "            return False",
            "",
            "        if not request.user.is_authenticated:",
            "            return True",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": request.user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return bool(auth)",
            "",
            "    def get_new_issue_title(self, **kwargs):",
            "        \"\"\"",
            "        Return a string for the \"Create new issue\" action label.",
            "        \"\"\"",
            "        return \"Create %s Issue\" % self.get_title()",
            "",
            "    def get_unlink_issue_title(self, **kwargs):",
            "        \"\"\"",
            "        Return a string for the \"Unlink plugin issue\" action label.",
            "        \"\"\"",
            "        return \"Unlink %s Issue\" % self.get_title()",
            "",
            "    def get_new_issue_form(self, request: Request, group, event, **kwargs):",
            "        \"\"\"",
            "        Return a Form for the \"Create new issue\" page.",
            "        \"\"\"",
            "        return self.new_issue_form(",
            "            request.POST or None, initial=self.get_initial_form_data(request, group, event)",
            "        )",
            "",
            "    def get_new_issue_read_only_fields(self, *args, **kwargs):",
            "        \"\"\"",
            "        Return a list of additional read only fields that are helpful to",
            "        know when filing the issue.",
            "        \"\"\"",
            "        return []",
            "",
            "    def get_link_existing_issue_form(self, request: Request, group, event, **kwargs):",
            "        if not self.link_issue_form:",
            "            return None",
            "        return self.link_issue_form(",
            "            request.POST or None, initial=self.get_initial_link_form_data(request, group, event)",
            "        )",
            "",
            "    def get_issue_url(self, group, issue_id, **kwargs):",
            "        \"\"\"",
            "        Given an issue_id (string) return an absolute URL to the issue's details",
            "        page.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue_title_by_id(self, request: Request, group, issue_id):",
            "        \"\"\"",
            "        Given an issue_id return the issue's title.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue_label(self, group, issue_id, **kwargs):",
            "        \"\"\"",
            "        Given an issue_id (string) return a string representing the issue.",
            "",
            "        e.g. GitHub represents issues as GH-XXX",
            "        \"\"\"",
            "        return \"#%s\" % issue_id",
            "",
            "    def create_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Creates the issue on the remote service and returns an issue ID.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def link_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Can be overridden for any actions needed when linking issues",
            "        (like adding a comment to an existing issue).",
            "        \"\"\"",
            "",
            "    def get_initial_form_data(self, request: Request, group, event, **kwargs):",
            "        return {",
            "            \"description\": self._get_group_description(request, group, event),",
            "            \"title\": self._get_group_title(request, group, event),",
            "        }",
            "",
            "    def get_initial_link_form_data(self, request: Request, group, event, **kwargs):",
            "        return {}",
            "",
            "    def has_auth_configured(self, **kwargs):",
            "        if not self.auth_provider:",
            "            return True",
            "",
            "        return self.auth_provider in get_auth_providers()",
            "",
            "    def handle_unlink_issue(self, request: Request, group, **kwargs):",
            "        GroupMeta.objects.unset_value(group, \"%s:tid\" % self.get_conf_key())",
            "        return self.redirect(group.get_absolute_url())",
            "",
            "    def view(self, request: Request, group, **kwargs):",
            "        has_auth_configured = self.has_auth_configured()",
            "        if not (has_auth_configured and self.is_configured(project=group.project, request=request)):",
            "            if self.auth_provider:",
            "                required_auth_settings = settings.AUTH_PROVIDERS[self.auth_provider]",
            "            else:",
            "                required_auth_settings = None",
            "",
            "            project = group.project",
            "",
            "            return self.render(",
            "                self.not_configured_template,",
            "                {",
            "                    \"title\": self.get_title(),",
            "                    \"project\": group.project,",
            "                    \"has_auth_configured\": has_auth_configured,",
            "                    \"required_auth_settings\": required_auth_settings,",
            "                    \"plugin_link\": f\"/settings/{project.organization.slug}/projects/{project.slug}/plugins/{self.slug}/\",",
            "                },",
            "            )",
            "",
            "        if self.needs_auth(project=group.project, request=request):",
            "            return self.render(",
            "                self.needs_auth_template, {\"title\": self.get_title(), \"project\": group.project}",
            "            )",
            "",
            "        if GroupMeta.objects.get_value(group, \"%s:tid\" % self.get_conf_key(), None):",
            "            if self.can_unlink_issues and request.GET.get(\"unlink\"):",
            "                return self.handle_unlink_issue(request, group, **kwargs)",
            "            return None",
            "",
            "        prefix = self.get_conf_key()",
            "        event = group.get_latest_event()",
            "",
            "        op = request.POST.get(\"op\", \"create\")",
            "",
            "        create_form = self.get_new_issue_form(request, group, event)",
            "        link_form = None",
            "        if self.can_link_existing_issues:",
            "            link_form = self.get_link_existing_issue_form(request, group, event)",
            "",
            "        if op == \"create\":",
            "            issue_id = None",
            "            if create_form.is_valid():",
            "                try:",
            "                    issue_id = self.create_issue(",
            "                        group=group, form_data=create_form.cleaned_data, request=request",
            "                    )",
            "                except forms.ValidationError as e:",
            "                    create_form.errors[\"__all__\"] = [\"Error creating issue: %s\" % e]",
            "",
            "            if create_form.is_valid():",
            "                GroupMeta.objects.set_value(group, \"%s:tid\" % prefix, issue_id)",
            "",
            "                issue_information = {",
            "                    \"title\": create_form.cleaned_data[\"title\"],",
            "                    \"provider\": self.get_title(),",
            "                    \"location\": self.get_issue_url(group, issue_id),",
            "                    \"label\": self.get_issue_label(group=group, issue_id=issue_id),",
            "                }",
            "                Activity.objects.create(",
            "                    project=group.project,",
            "                    group=group,",
            "                    type=ActivityType.CREATE_ISSUE.value,",
            "                    user_id=request.user.id,",
            "                    data=issue_information,",
            "                )",
            "",
            "                issue_tracker_used.send_robust(",
            "                    plugin=self,",
            "                    project=group.project,",
            "                    user=request.user,",
            "                    sender=IssueTrackingPlugin,",
            "                )",
            "                return self.redirect(group.get_absolute_url())",
            "",
            "        elif op == \"link\":",
            "            if link_form.is_valid():",
            "                try:",
            "                    self.link_issue(group=group, form_data=link_form.cleaned_data, request=request)",
            "                except forms.ValidationError as e:",
            "                    link_form.errors[\"__all__\"] = [\"Error creating issue: %s\" % e]",
            "",
            "            if link_form.is_valid():",
            "                issue_id = int(link_form.cleaned_data[\"issue_id\"])",
            "                GroupMeta.objects.set_value(group, \"%s:tid\" % prefix, issue_id)",
            "                issue_information = {",
            "                    \"title\": self.get_issue_title_by_id(request, group, issue_id),",
            "                    \"provider\": self.get_title(),",
            "                    \"location\": self.get_issue_url(group, issue_id),",
            "                    \"label\": self.get_issue_label(group=group, issue_id=issue_id),",
            "                }",
            "                Activity.objects.create(",
            "                    project=group.project,",
            "                    group=group,",
            "                    type=ActivityType.CREATE_ISSUE.value,",
            "                    user_id=request.user.id,",
            "                    data=issue_information,",
            "                )",
            "",
            "                return self.redirect(group.get_absolute_url())",
            "",
            "        context = {",
            "            \"create_form\": create_form,",
            "            # pass in 'form' for legacy compat",
            "            \"form\": create_form,",
            "            \"title\": self.get_new_issue_title(),",
            "            \"read_only_fields\": self.get_new_issue_read_only_fields(group=group),",
            "            \"can_link_existing_issues\": self.can_link_existing_issues,",
            "            \"link_form\": link_form,",
            "            \"op\": op,",
            "        }",
            "",
            "        return self.render(self.create_issue_template, context)",
            "",
            "    def actions(self, request: Request, group, action_list, **kwargs):",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return action_list",
            "        prefix = self.get_conf_key()",
            "        if not GroupMeta.objects.get_value(group, \"%s:tid\" % prefix, None):",
            "            action_list.append((self.get_new_issue_title(), self.get_url(group)))",
            "        elif self.can_unlink_issues:",
            "            action_list.append(",
            "                (self.get_unlink_issue_title(), \"%s?unlink=1\" % self.get_url(group).rstrip(\"/\"))",
            "            )",
            "        return action_list",
            "",
            "    def tags(self, request: Request, group, tag_list, **kwargs):",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return tag_list",
            "",
            "        prefix = self.get_conf_key()",
            "        issue_id = GroupMeta.objects.get_value(group, \"%s:tid\" % prefix)",
            "        if not issue_id:",
            "            return tag_list",
            "",
            "        tag_list.append(",
            "            {",
            "                \"url\": self.get_issue_url(group=group, issue_id=issue_id),",
            "                \"displayName\": self.get_issue_label(group=group, issue_id=issue_id),",
            "            }",
            "        )",
            "",
            "        return tag_list",
            "",
            "    def get_issue_doc_html(self, **kwargs):",
            "        return \"\"",
            "",
            "",
            "IssuePlugin = IssueTrackingPlugin"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "5": [],
            "315": [
                "IssueTrackingPlugin",
                "tags"
            ],
            "316": [
                "IssueTrackingPlugin",
                "tags"
            ],
            "317": [
                "IssueTrackingPlugin",
                "tags"
            ],
            "318": [
                "IssueTrackingPlugin",
                "tags"
            ],
            "319": [
                "IssueTrackingPlugin",
                "tags"
            ]
        },
        "addLocation": []
    },
    "src/sentry/plugins/bases/issue2.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from django.conf import settings"
            },
            "2": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from django.urls import re_path, reverse"
            },
            "3": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from django.utils.html import format_html"
            },
            "4": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from rest_framework.request import Request"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from rest_framework.response import Response"
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 431,
                "afterPatchRowNumber": 430,
                "PatchRowcode": "             return tag_list"
            },
            "8": {
                "beforePatchRowNumber": 432,
                "afterPatchRowNumber": 431,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 433,
                "afterPatchRowNumber": 432,
                "PatchRowcode": "         tag_list.append("
            },
            "10": {
                "beforePatchRowNumber": 434,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            format_html("
            },
            "11": {
                "beforePatchRowNumber": 435,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                '<a href=\"{}\">{}</a>',"
            },
            "12": {
                "beforePatchRowNumber": 436,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                self._get_issue_url_compat(group, issue),"
            },
            "13": {
                "beforePatchRowNumber": 437,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                self._get_issue_label_compat(group, issue),"
            },
            "14": {
                "beforePatchRowNumber": 438,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            )"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 433,
                "PatchRowcode": "+            {"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 434,
                "PatchRowcode": "+                \"url\": self._get_issue_url_compat(group, issue),"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 435,
                "PatchRowcode": "+                \"displayName\": self._get_issue_label_compat(group, issue),"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 436,
                "PatchRowcode": "+            }"
            },
            "19": {
                "beforePatchRowNumber": 439,
                "afterPatchRowNumber": 437,
                "PatchRowcode": "         )"
            },
            "20": {
                "beforePatchRowNumber": 440,
                "afterPatchRowNumber": 438,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 441,
                "afterPatchRowNumber": 439,
                "PatchRowcode": "         return tag_list"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "from django.conf import settings",
            "from django.urls import re_path, reverse",
            "from django.utils.html import format_html",
            "from rest_framework.request import Request",
            "from rest_framework.response import Response",
            "",
            "from sentry.api.api_publish_status import ApiPublishStatus",
            "from sentry.api.base import region_silo_endpoint",
            "from sentry.api.serializers.models.plugin import PluginSerializer",
            "",
            "# api compat",
            "from sentry.exceptions import PluginError  # NOQA",
            "from sentry.models.activity import Activity",
            "from sentry.models.groupmeta import GroupMeta",
            "from sentry.plugins.base.configuration import react_plugin_config",
            "from sentry.plugins.base.v1 import Plugin",
            "from sentry.plugins.endpoints import PluginGroupEndpoint",
            "from sentry.signals import issue_tracker_used",
            "from sentry.types.activity import ActivityType",
            "from sentry.users.services.usersocialauth.model import RpcUserSocialAuth",
            "from sentry.users.services.usersocialauth.service import usersocialauth_service",
            "from sentry.utils.auth import get_auth_providers",
            "from sentry.utils.http import absolute_uri",
            "from sentry.utils.safe import safe_execute",
            "",
            "",
            "# TODO(dcramer): remove this in favor of GroupEndpoint",
            "@region_silo_endpoint",
            "class IssueGroupActionEndpoint(PluginGroupEndpoint):",
            "    publish_status = {",
            "        \"GET\": ApiPublishStatus.PRIVATE,",
            "        \"POST\": ApiPublishStatus.PRIVATE,",
            "    }",
            "    view_method_name = None",
            "    plugin = None",
            "",
            "    def _handle(self, request: Request, group, *args, **kwargs):",
            "        GroupMeta.objects.populate_cache([group])",
            "",
            "        return getattr(self.plugin, self.view_method_name)(request, group, *args, **kwargs)",
            "",
            "",
            "class IssueTrackingPlugin2(Plugin):",
            "    auth_provider: str | None = None",
            "",
            "    allowed_actions = (\"create\", \"link\", \"unlink\")",
            "",
            "    # we default this to None to support legacy integrations, but newer style",
            "    # should explicitly call out what is stored",
            "    issue_fields: frozenset[str] | None = None",
            "    # issue_fields = frozenset(['id', 'title', 'url'])",
            "",
            "    def configure(self, project, request):",
            "        return react_plugin_config(self, project, request)",
            "",
            "    def get_plugin_type(self):",
            "        return \"issue-tracking\"",
            "",
            "    def has_project_conf(self):",
            "        return True",
            "",
            "    def get_group_body(self, request: Request, group, event, **kwargs):",
            "        result = []",
            "        for interface in event.interfaces.values():",
            "            output = safe_execute(interface.to_string, event)",
            "            if output:",
            "                result.append(output)",
            "        return \"\\n\\n\".join(result)",
            "",
            "    def get_group_description(self, request: Request, group, event):",
            "        referrer = self.get_conf_key() + \"_plugin\"",
            "        output = [absolute_uri(group.get_absolute_url(params={\"referrer\": referrer}))]",
            "        body = self.get_group_body(request, group, event)",
            "        if body:",
            "            output.extend([\"\", \"```\", body, \"```\"])",
            "        return \"\\n\".join(output)",
            "",
            "    def get_group_title(self, request: Request, group, event):",
            "        return event.title",
            "",
            "    def is_configured(self, request: Request, project, **kwargs):",
            "        raise NotImplementedError",
            "",
            "    def get_group_urls(self):",
            "        _urls = []",
            "        for action in self.allowed_actions:",
            "            view_method_name = \"view_%s\" % action",
            "            _urls.append(",
            "                re_path(",
            "                    r\"^%s/\" % action,",
            "                    PluginGroupEndpoint.as_view(view=getattr(self, view_method_name)),",
            "                )",
            "            )",
            "        return _urls",
            "",
            "    def get_auth_for_user(self, user, **kwargs) -> RpcUserSocialAuth:",
            "        \"\"\"",
            "        Return a ``RpcUserSocialAuth`` object for the given user based on this plugins ``auth_provider``.",
            "        \"\"\"",
            "        assert self.auth_provider, \"There is no auth provider configured for this plugin.\"",
            "",
            "        if not user.is_authenticated:",
            "            return None",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return auth",
            "",
            "    def needs_auth(self, request: Request, project, **kwargs):",
            "        \"\"\"",
            "        Return ``True`` if the authenticated user needs to associate an auth service before",
            "        performing actions with this plugin.",
            "        \"\"\"",
            "        if self.auth_provider is None:",
            "            return False",
            "",
            "        if not request.user.is_authenticated:",
            "            return True",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": request.user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return not bool(auth)",
            "",
            "    def get_new_issue_fields(self, request: Request, group, event, **kwargs):",
            "        \"\"\"",
            "        If overriding, supported properties include 'readonly': true",
            "        \"\"\"",
            "        return [",
            "            {",
            "                \"name\": \"title\",",
            "                \"label\": \"Title\",",
            "                \"default\": self.get_group_title(request, group, event),",
            "                \"type\": \"text\",",
            "            },",
            "            {",
            "                \"name\": \"description\",",
            "                \"label\": \"Description\",",
            "                \"default\": self.get_group_description(request, group, event),",
            "                \"type\": \"textarea\",",
            "            },",
            "        ]",
            "",
            "    def get_link_existing_issue_fields(self, request: Request, group, event, **kwargs):",
            "        return []",
            "",
            "    def _get_issue_url_compat(self, group, issue, **kwargs):",
            "        if self.issue_fields is None:",
            "            return self.get_issue_url(group, issue[\"id\"])",
            "        return self.get_issue_url(group, issue)",
            "",
            "    def _get_issue_label_compat(self, group, issue, **kwargs):",
            "        if self.issue_fields is None:",
            "            return self.get_issue_label(group, issue[\"id\"])",
            "        return self.get_issue_label(group, issue)",
            "",
            "    def get_issue_url(self, group, issue, **kwargs):",
            "        \"\"\"",
            "        Given an issue context (issue_id string or issue dict) return an absolute URL to the issue's details",
            "        page.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue_label(self, group, issue, **kwargs):",
            "        \"\"\"",
            "        Given an issue context (issue_id string or issue dict) return a string representing the issue.",
            "",
            "        e.g. GitHub represents issues as GH-XXX",
            "        \"\"\"",
            "        if isinstance(issue, dict):",
            "            return \"#{}\".format(issue[\"id\"])",
            "        return f\"#{issue}\"",
            "",
            "    def create_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Creates the issue on the remote service and returns an issue ID.",
            "",
            "        Returns ``{'id': '1', 'title': issue_title}``",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def link_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Can be overridden for any actions needed when linking issues",
            "        (like adding a comment to an existing issue).",
            "",
            "        Returns ``{'id': '1', 'title': issue_title}``",
            "        \"\"\"",
            "",
            "    def has_auth_configured(self, **kwargs):",
            "        if not self.auth_provider:",
            "            return True",
            "",
            "        return self.auth_provider in get_auth_providers()",
            "",
            "    def validate_form(self, fields, form_data):",
            "        errors = {}",
            "        for field in fields:",
            "            if field.get(\"required\", True) and not field.get(\"readonly\"):",
            "                value = form_data.get(field[\"name\"])",
            "                if value is None or value == \"\":",
            "                    errors[field[\"name\"]] = \"%s is a required field.\" % field[\"label\"]",
            "        return errors",
            "",
            "    def get_issue_field_map(self):",
            "        # XXX(dcramer): legacy support",
            "        conf_key = self.get_conf_key()",
            "        if self.issue_fields is None:",
            "            return {\"id\": f\"{conf_key}:tid\"}",
            "        return {key: f\"{conf_key}:issue_{key}\" for key in self.issue_fields}",
            "",
            "    def build_issue(self, group):",
            "        issue_field_map = self.get_issue_field_map()",
            "        issue = {}",
            "        for key, meta_name in issue_field_map.items():",
            "            issue[key] = GroupMeta.objects.get_value(group, meta_name, None)",
            "        if not any(issue.values()):",
            "            return None",
            "        return issue",
            "",
            "    def has_linked_issue(self, group):",
            "        return bool(self.build_issue(group))",
            "",
            "    def unlink_issue(self, request: Request, group, issue, **kwargs):",
            "        issue_field_map = self.get_issue_field_map()",
            "        for meta_name in issue_field_map.values():",
            "            GroupMeta.objects.unset_value(group, meta_name)",
            "        return self.redirect(group.get_absolute_url())",
            "",
            "    def view_create(self, request: Request, group, **kwargs):",
            "        auth_errors = self.check_config_and_auth(request, group)",
            "        if auth_errors:",
            "            return Response(auth_errors, status=400)",
            "",
            "        event = group.get_latest_event()",
            "        if event is None:",
            "            return Response(",
            "                {",
            "                    \"message\": \"Unable to create issues: there are \"",
            "                    \"no events associated with this group\"",
            "                },",
            "                status=400,",
            "            )",
            "        try:",
            "            fields = self.get_new_issue_fields(request, group, event, **kwargs)",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "        if request.method == \"GET\":",
            "            return Response(fields)",
            "",
            "        errors = self.validate_form(fields, request.data)",
            "        if errors:",
            "            return Response({\"error_type\": \"validation\", \"errors\": errors}, status=400)",
            "",
            "        try:",
            "            issue = self.create_issue(group=group, form_data=request.data, request=request)",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "",
            "        if not isinstance(issue, dict):",
            "            issue = {\"id\": issue}",
            "",
            "        issue_field_map = self.get_issue_field_map()",
            "        for key, meta_name in issue_field_map.items():",
            "            if key in issue:",
            "                GroupMeta.objects.set_value(group, meta_name, issue[key])",
            "            else:",
            "                GroupMeta.objects.unset_value(group, meta_name)",
            "",
            "        issue_information = {",
            "            \"title\": issue.get(\"title\")",
            "            or request.data.get(\"title\")",
            "            or self._get_issue_label_compat(group, issue),",
            "            \"provider\": self.get_title(),",
            "            \"location\": self._get_issue_url_compat(group, issue),",
            "            \"label\": self._get_issue_label_compat(group, issue),",
            "        }",
            "        Activity.objects.create(",
            "            project=group.project,",
            "            group=group,",
            "            type=ActivityType.CREATE_ISSUE.value,",
            "            user_id=request.user.id,",
            "            data=issue_information,",
            "        )",
            "",
            "        issue_tracker_used.send_robust(",
            "            plugin=self, project=group.project, user=request.user, sender=type(self)",
            "        )",
            "        return Response(",
            "            {",
            "                \"issue_url\": self.get_issue_url(group, issue),",
            "                \"link\": self._get_issue_url_compat(group, issue),",
            "                \"label\": self._get_issue_label_compat(group, issue),",
            "                \"id\": issue[\"id\"],",
            "            }",
            "        )",
            "",
            "    def view_link(self, request: Request, group, **kwargs):",
            "        auth_errors = self.check_config_and_auth(request, group)",
            "        if auth_errors:",
            "            return Response(auth_errors, status=400)",
            "",
            "        event = group.get_latest_event()",
            "        if event is None:",
            "            return Response(",
            "                {",
            "                    \"message\": \"Unable to create issues: there are \"",
            "                    \"no events associated with this group\"",
            "                },",
            "                status=400,",
            "            )",
            "",
            "        try:",
            "            fields = self.get_link_existing_issue_fields(request, group, event, **kwargs)",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "        if request.method == \"GET\":",
            "            return Response(fields)",
            "        errors = self.validate_form(fields, request.data)",
            "        if errors:",
            "            return Response({\"error_type\": \"validation\", \"errors\": errors}, status=400)",
            "",
            "        try:",
            "            issue = self.link_issue(group=group, form_data=request.data, request=request) or {}",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "",
            "        # HACK(dcramer): maintain data for legacy issues",
            "        if \"id\" not in issue and \"issue_id\" in request.data:",
            "            issue[\"id\"] = request.data[\"issue_id\"]",
            "",
            "        issue_field_map = self.get_issue_field_map()",
            "        for key, meta_name in issue_field_map.items():",
            "            if key in issue:",
            "                GroupMeta.objects.set_value(group, meta_name, issue[key])",
            "            else:",
            "                GroupMeta.objects.unset_value(group, meta_name)",
            "",
            "        issue_information = {",
            "            \"title\": issue.get(\"title\") or self._get_issue_label_compat(group, issue),",
            "            \"provider\": self.get_title(),",
            "            \"location\": self._get_issue_url_compat(group, issue),",
            "            \"label\": self._get_issue_label_compat(group, issue),",
            "        }",
            "        Activity.objects.create(",
            "            project=group.project,",
            "            group=group,",
            "            type=ActivityType.CREATE_ISSUE.value,",
            "            user_id=request.user.id,",
            "            data=issue_information,",
            "        )",
            "        return Response(",
            "            {",
            "                \"message\": \"Successfully linked issue.\",",
            "                \"link\": self._get_issue_url_compat(group, issue),",
            "                \"label\": self._get_issue_label_compat(group, issue),",
            "                \"id\": issue[\"id\"],",
            "            }",
            "        )",
            "",
            "    def view_unlink(self, request: Request, group, **kwargs):",
            "        auth_errors = self.check_config_and_auth(request, group)",
            "        if auth_errors:",
            "            return Response(auth_errors, status=400)",
            "        issue = self.build_issue(group)",
            "        if issue and \"unlink\" in self.allowed_actions:",
            "            self.unlink_issue(request, group, issue)",
            "            return Response({\"message\": \"Successfully unlinked issue.\"})",
            "        return Response({\"message\": \"No issues to unlink.\"}, status=400)",
            "",
            "    def plugin_issues(self, request: Request, group, plugin_issues, **kwargs) -> None:",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return",
            "",
            "        item = {",
            "            \"slug\": self.slug,",
            "            \"allowed_actions\": self.allowed_actions,",
            "            \"title\": self.get_title(),",
            "        }",
            "        issue = self.build_issue(group)",
            "        if issue:",
            "            item[\"issue\"] = {",
            "                \"issue_id\": issue.get(\"id\"),",
            "                \"url\": self._get_issue_url_compat(group, issue),",
            "                \"label\": self._get_issue_label_compat(group, issue),",
            "            }",
            "",
            "        item.update(PluginSerializer(group.project).serialize(self, None, request.user))",
            "        plugin_issues.append(item)",
            "",
            "    def get_config(self, *args, **kwargs):",
            "        # TODO(dcramer): update existing plugins to just use get_config",
            "        # TODO(dcramer): remove request kwarg after sentry-plugins has been",
            "        # updated",
            "        kwargs.setdefault(\"request\", None)",
            "        return self.get_configure_plugin_fields(*args, **kwargs)",
            "",
            "    def check_config_and_auth(self, request: Request, group):",
            "        has_auth_configured = self.has_auth_configured()",
            "        if not (has_auth_configured and self.is_configured(project=group.project, request=request)):",
            "            if self.auth_provider:",
            "                required_auth_settings = settings.AUTH_PROVIDERS[self.auth_provider]",
            "            else:",
            "                required_auth_settings = None",
            "",
            "            return {",
            "                \"error_type\": \"config\",",
            "                \"has_auth_configured\": has_auth_configured,",
            "                \"auth_provider\": self.auth_provider,",
            "                \"required_auth_settings\": required_auth_settings,",
            "            }",
            "",
            "        if self.needs_auth(project=group.project, request=request):",
            "            return {",
            "                \"error_type\": \"auth\",",
            "                \"auth_url\": absolute_uri(",
            "                    reverse(\"socialauth_associate\", args=[self.auth_provider])",
            "                ),",
            "            }",
            "",
            "    # TODO: should we get rid of this (move it to react?)",
            "    def tags(self, request: Request, group, tag_list, **kwargs):",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return tag_list",
            "",
            "        issue = self.build_issue(group)",
            "        if not issue:",
            "            return tag_list",
            "",
            "        tag_list.append(",
            "            format_html(",
            "                '<a href=\"{}\">{}</a>',",
            "                self._get_issue_url_compat(group, issue),",
            "                self._get_issue_label_compat(group, issue),",
            "            )",
            "        )",
            "",
            "        return tag_list",
            "",
            "",
            "IssuePlugin2 = IssueTrackingPlugin2"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "from django.conf import settings",
            "from django.urls import re_path, reverse",
            "from rest_framework.request import Request",
            "from rest_framework.response import Response",
            "",
            "from sentry.api.api_publish_status import ApiPublishStatus",
            "from sentry.api.base import region_silo_endpoint",
            "from sentry.api.serializers.models.plugin import PluginSerializer",
            "",
            "# api compat",
            "from sentry.exceptions import PluginError  # NOQA",
            "from sentry.models.activity import Activity",
            "from sentry.models.groupmeta import GroupMeta",
            "from sentry.plugins.base.configuration import react_plugin_config",
            "from sentry.plugins.base.v1 import Plugin",
            "from sentry.plugins.endpoints import PluginGroupEndpoint",
            "from sentry.signals import issue_tracker_used",
            "from sentry.types.activity import ActivityType",
            "from sentry.users.services.usersocialauth.model import RpcUserSocialAuth",
            "from sentry.users.services.usersocialauth.service import usersocialauth_service",
            "from sentry.utils.auth import get_auth_providers",
            "from sentry.utils.http import absolute_uri",
            "from sentry.utils.safe import safe_execute",
            "",
            "",
            "# TODO(dcramer): remove this in favor of GroupEndpoint",
            "@region_silo_endpoint",
            "class IssueGroupActionEndpoint(PluginGroupEndpoint):",
            "    publish_status = {",
            "        \"GET\": ApiPublishStatus.PRIVATE,",
            "        \"POST\": ApiPublishStatus.PRIVATE,",
            "    }",
            "    view_method_name = None",
            "    plugin = None",
            "",
            "    def _handle(self, request: Request, group, *args, **kwargs):",
            "        GroupMeta.objects.populate_cache([group])",
            "",
            "        return getattr(self.plugin, self.view_method_name)(request, group, *args, **kwargs)",
            "",
            "",
            "class IssueTrackingPlugin2(Plugin):",
            "    auth_provider: str | None = None",
            "",
            "    allowed_actions = (\"create\", \"link\", \"unlink\")",
            "",
            "    # we default this to None to support legacy integrations, but newer style",
            "    # should explicitly call out what is stored",
            "    issue_fields: frozenset[str] | None = None",
            "    # issue_fields = frozenset(['id', 'title', 'url'])",
            "",
            "    def configure(self, project, request):",
            "        return react_plugin_config(self, project, request)",
            "",
            "    def get_plugin_type(self):",
            "        return \"issue-tracking\"",
            "",
            "    def has_project_conf(self):",
            "        return True",
            "",
            "    def get_group_body(self, request: Request, group, event, **kwargs):",
            "        result = []",
            "        for interface in event.interfaces.values():",
            "            output = safe_execute(interface.to_string, event)",
            "            if output:",
            "                result.append(output)",
            "        return \"\\n\\n\".join(result)",
            "",
            "    def get_group_description(self, request: Request, group, event):",
            "        referrer = self.get_conf_key() + \"_plugin\"",
            "        output = [absolute_uri(group.get_absolute_url(params={\"referrer\": referrer}))]",
            "        body = self.get_group_body(request, group, event)",
            "        if body:",
            "            output.extend([\"\", \"```\", body, \"```\"])",
            "        return \"\\n\".join(output)",
            "",
            "    def get_group_title(self, request: Request, group, event):",
            "        return event.title",
            "",
            "    def is_configured(self, request: Request, project, **kwargs):",
            "        raise NotImplementedError",
            "",
            "    def get_group_urls(self):",
            "        _urls = []",
            "        for action in self.allowed_actions:",
            "            view_method_name = \"view_%s\" % action",
            "            _urls.append(",
            "                re_path(",
            "                    r\"^%s/\" % action,",
            "                    PluginGroupEndpoint.as_view(view=getattr(self, view_method_name)),",
            "                )",
            "            )",
            "        return _urls",
            "",
            "    def get_auth_for_user(self, user, **kwargs) -> RpcUserSocialAuth:",
            "        \"\"\"",
            "        Return a ``RpcUserSocialAuth`` object for the given user based on this plugins ``auth_provider``.",
            "        \"\"\"",
            "        assert self.auth_provider, \"There is no auth provider configured for this plugin.\"",
            "",
            "        if not user.is_authenticated:",
            "            return None",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return auth",
            "",
            "    def needs_auth(self, request: Request, project, **kwargs):",
            "        \"\"\"",
            "        Return ``True`` if the authenticated user needs to associate an auth service before",
            "        performing actions with this plugin.",
            "        \"\"\"",
            "        if self.auth_provider is None:",
            "            return False",
            "",
            "        if not request.user.is_authenticated:",
            "            return True",
            "",
            "        auth = usersocialauth_service.get_one_or_none(",
            "            filter={\"user_id\": request.user.id, \"provider\": self.auth_provider}",
            "        )",
            "        return not bool(auth)",
            "",
            "    def get_new_issue_fields(self, request: Request, group, event, **kwargs):",
            "        \"\"\"",
            "        If overriding, supported properties include 'readonly': true",
            "        \"\"\"",
            "        return [",
            "            {",
            "                \"name\": \"title\",",
            "                \"label\": \"Title\",",
            "                \"default\": self.get_group_title(request, group, event),",
            "                \"type\": \"text\",",
            "            },",
            "            {",
            "                \"name\": \"description\",",
            "                \"label\": \"Description\",",
            "                \"default\": self.get_group_description(request, group, event),",
            "                \"type\": \"textarea\",",
            "            },",
            "        ]",
            "",
            "    def get_link_existing_issue_fields(self, request: Request, group, event, **kwargs):",
            "        return []",
            "",
            "    def _get_issue_url_compat(self, group, issue, **kwargs):",
            "        if self.issue_fields is None:",
            "            return self.get_issue_url(group, issue[\"id\"])",
            "        return self.get_issue_url(group, issue)",
            "",
            "    def _get_issue_label_compat(self, group, issue, **kwargs):",
            "        if self.issue_fields is None:",
            "            return self.get_issue_label(group, issue[\"id\"])",
            "        return self.get_issue_label(group, issue)",
            "",
            "    def get_issue_url(self, group, issue, **kwargs):",
            "        \"\"\"",
            "        Given an issue context (issue_id string or issue dict) return an absolute URL to the issue's details",
            "        page.",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def get_issue_label(self, group, issue, **kwargs):",
            "        \"\"\"",
            "        Given an issue context (issue_id string or issue dict) return a string representing the issue.",
            "",
            "        e.g. GitHub represents issues as GH-XXX",
            "        \"\"\"",
            "        if isinstance(issue, dict):",
            "            return \"#{}\".format(issue[\"id\"])",
            "        return f\"#{issue}\"",
            "",
            "    def create_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Creates the issue on the remote service and returns an issue ID.",
            "",
            "        Returns ``{'id': '1', 'title': issue_title}``",
            "        \"\"\"",
            "        raise NotImplementedError",
            "",
            "    def link_issue(self, request: Request, group, form_data, **kwargs):",
            "        \"\"\"",
            "        Can be overridden for any actions needed when linking issues",
            "        (like adding a comment to an existing issue).",
            "",
            "        Returns ``{'id': '1', 'title': issue_title}``",
            "        \"\"\"",
            "",
            "    def has_auth_configured(self, **kwargs):",
            "        if not self.auth_provider:",
            "            return True",
            "",
            "        return self.auth_provider in get_auth_providers()",
            "",
            "    def validate_form(self, fields, form_data):",
            "        errors = {}",
            "        for field in fields:",
            "            if field.get(\"required\", True) and not field.get(\"readonly\"):",
            "                value = form_data.get(field[\"name\"])",
            "                if value is None or value == \"\":",
            "                    errors[field[\"name\"]] = \"%s is a required field.\" % field[\"label\"]",
            "        return errors",
            "",
            "    def get_issue_field_map(self):",
            "        # XXX(dcramer): legacy support",
            "        conf_key = self.get_conf_key()",
            "        if self.issue_fields is None:",
            "            return {\"id\": f\"{conf_key}:tid\"}",
            "        return {key: f\"{conf_key}:issue_{key}\" for key in self.issue_fields}",
            "",
            "    def build_issue(self, group):",
            "        issue_field_map = self.get_issue_field_map()",
            "        issue = {}",
            "        for key, meta_name in issue_field_map.items():",
            "            issue[key] = GroupMeta.objects.get_value(group, meta_name, None)",
            "        if not any(issue.values()):",
            "            return None",
            "        return issue",
            "",
            "    def has_linked_issue(self, group):",
            "        return bool(self.build_issue(group))",
            "",
            "    def unlink_issue(self, request: Request, group, issue, **kwargs):",
            "        issue_field_map = self.get_issue_field_map()",
            "        for meta_name in issue_field_map.values():",
            "            GroupMeta.objects.unset_value(group, meta_name)",
            "        return self.redirect(group.get_absolute_url())",
            "",
            "    def view_create(self, request: Request, group, **kwargs):",
            "        auth_errors = self.check_config_and_auth(request, group)",
            "        if auth_errors:",
            "            return Response(auth_errors, status=400)",
            "",
            "        event = group.get_latest_event()",
            "        if event is None:",
            "            return Response(",
            "                {",
            "                    \"message\": \"Unable to create issues: there are \"",
            "                    \"no events associated with this group\"",
            "                },",
            "                status=400,",
            "            )",
            "        try:",
            "            fields = self.get_new_issue_fields(request, group, event, **kwargs)",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "        if request.method == \"GET\":",
            "            return Response(fields)",
            "",
            "        errors = self.validate_form(fields, request.data)",
            "        if errors:",
            "            return Response({\"error_type\": \"validation\", \"errors\": errors}, status=400)",
            "",
            "        try:",
            "            issue = self.create_issue(group=group, form_data=request.data, request=request)",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "",
            "        if not isinstance(issue, dict):",
            "            issue = {\"id\": issue}",
            "",
            "        issue_field_map = self.get_issue_field_map()",
            "        for key, meta_name in issue_field_map.items():",
            "            if key in issue:",
            "                GroupMeta.objects.set_value(group, meta_name, issue[key])",
            "            else:",
            "                GroupMeta.objects.unset_value(group, meta_name)",
            "",
            "        issue_information = {",
            "            \"title\": issue.get(\"title\")",
            "            or request.data.get(\"title\")",
            "            or self._get_issue_label_compat(group, issue),",
            "            \"provider\": self.get_title(),",
            "            \"location\": self._get_issue_url_compat(group, issue),",
            "            \"label\": self._get_issue_label_compat(group, issue),",
            "        }",
            "        Activity.objects.create(",
            "            project=group.project,",
            "            group=group,",
            "            type=ActivityType.CREATE_ISSUE.value,",
            "            user_id=request.user.id,",
            "            data=issue_information,",
            "        )",
            "",
            "        issue_tracker_used.send_robust(",
            "            plugin=self, project=group.project, user=request.user, sender=type(self)",
            "        )",
            "        return Response(",
            "            {",
            "                \"issue_url\": self.get_issue_url(group, issue),",
            "                \"link\": self._get_issue_url_compat(group, issue),",
            "                \"label\": self._get_issue_label_compat(group, issue),",
            "                \"id\": issue[\"id\"],",
            "            }",
            "        )",
            "",
            "    def view_link(self, request: Request, group, **kwargs):",
            "        auth_errors = self.check_config_and_auth(request, group)",
            "        if auth_errors:",
            "            return Response(auth_errors, status=400)",
            "",
            "        event = group.get_latest_event()",
            "        if event is None:",
            "            return Response(",
            "                {",
            "                    \"message\": \"Unable to create issues: there are \"",
            "                    \"no events associated with this group\"",
            "                },",
            "                status=400,",
            "            )",
            "",
            "        try:",
            "            fields = self.get_link_existing_issue_fields(request, group, event, **kwargs)",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "        if request.method == \"GET\":",
            "            return Response(fields)",
            "        errors = self.validate_form(fields, request.data)",
            "        if errors:",
            "            return Response({\"error_type\": \"validation\", \"errors\": errors}, status=400)",
            "",
            "        try:",
            "            issue = self.link_issue(group=group, form_data=request.data, request=request) or {}",
            "        except Exception as e:",
            "            return self.handle_api_error(e)",
            "",
            "        # HACK(dcramer): maintain data for legacy issues",
            "        if \"id\" not in issue and \"issue_id\" in request.data:",
            "            issue[\"id\"] = request.data[\"issue_id\"]",
            "",
            "        issue_field_map = self.get_issue_field_map()",
            "        for key, meta_name in issue_field_map.items():",
            "            if key in issue:",
            "                GroupMeta.objects.set_value(group, meta_name, issue[key])",
            "            else:",
            "                GroupMeta.objects.unset_value(group, meta_name)",
            "",
            "        issue_information = {",
            "            \"title\": issue.get(\"title\") or self._get_issue_label_compat(group, issue),",
            "            \"provider\": self.get_title(),",
            "            \"location\": self._get_issue_url_compat(group, issue),",
            "            \"label\": self._get_issue_label_compat(group, issue),",
            "        }",
            "        Activity.objects.create(",
            "            project=group.project,",
            "            group=group,",
            "            type=ActivityType.CREATE_ISSUE.value,",
            "            user_id=request.user.id,",
            "            data=issue_information,",
            "        )",
            "        return Response(",
            "            {",
            "                \"message\": \"Successfully linked issue.\",",
            "                \"link\": self._get_issue_url_compat(group, issue),",
            "                \"label\": self._get_issue_label_compat(group, issue),",
            "                \"id\": issue[\"id\"],",
            "            }",
            "        )",
            "",
            "    def view_unlink(self, request: Request, group, **kwargs):",
            "        auth_errors = self.check_config_and_auth(request, group)",
            "        if auth_errors:",
            "            return Response(auth_errors, status=400)",
            "        issue = self.build_issue(group)",
            "        if issue and \"unlink\" in self.allowed_actions:",
            "            self.unlink_issue(request, group, issue)",
            "            return Response({\"message\": \"Successfully unlinked issue.\"})",
            "        return Response({\"message\": \"No issues to unlink.\"}, status=400)",
            "",
            "    def plugin_issues(self, request: Request, group, plugin_issues, **kwargs) -> None:",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return",
            "",
            "        item = {",
            "            \"slug\": self.slug,",
            "            \"allowed_actions\": self.allowed_actions,",
            "            \"title\": self.get_title(),",
            "        }",
            "        issue = self.build_issue(group)",
            "        if issue:",
            "            item[\"issue\"] = {",
            "                \"issue_id\": issue.get(\"id\"),",
            "                \"url\": self._get_issue_url_compat(group, issue),",
            "                \"label\": self._get_issue_label_compat(group, issue),",
            "            }",
            "",
            "        item.update(PluginSerializer(group.project).serialize(self, None, request.user))",
            "        plugin_issues.append(item)",
            "",
            "    def get_config(self, *args, **kwargs):",
            "        # TODO(dcramer): update existing plugins to just use get_config",
            "        # TODO(dcramer): remove request kwarg after sentry-plugins has been",
            "        # updated",
            "        kwargs.setdefault(\"request\", None)",
            "        return self.get_configure_plugin_fields(*args, **kwargs)",
            "",
            "    def check_config_and_auth(self, request: Request, group):",
            "        has_auth_configured = self.has_auth_configured()",
            "        if not (has_auth_configured and self.is_configured(project=group.project, request=request)):",
            "            if self.auth_provider:",
            "                required_auth_settings = settings.AUTH_PROVIDERS[self.auth_provider]",
            "            else:",
            "                required_auth_settings = None",
            "",
            "            return {",
            "                \"error_type\": \"config\",",
            "                \"has_auth_configured\": has_auth_configured,",
            "                \"auth_provider\": self.auth_provider,",
            "                \"required_auth_settings\": required_auth_settings,",
            "            }",
            "",
            "        if self.needs_auth(project=group.project, request=request):",
            "            return {",
            "                \"error_type\": \"auth\",",
            "                \"auth_url\": absolute_uri(",
            "                    reverse(\"socialauth_associate\", args=[self.auth_provider])",
            "                ),",
            "            }",
            "",
            "    # TODO: should we get rid of this (move it to react?)",
            "    def tags(self, request: Request, group, tag_list, **kwargs):",
            "        if not self.is_configured(request=request, project=group.project):",
            "            return tag_list",
            "",
            "        issue = self.build_issue(group)",
            "        if not issue:",
            "            return tag_list",
            "",
            "        tag_list.append(",
            "            {",
            "                \"url\": self._get_issue_url_compat(group, issue),",
            "                \"displayName\": self._get_issue_label_compat(group, issue),",
            "            }",
            "        )",
            "",
            "        return tag_list",
            "",
            "",
            "IssuePlugin2 = IssueTrackingPlugin2"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "5": [],
            "434": [
                "IssueTrackingPlugin2",
                "tags"
            ],
            "435": [
                "IssueTrackingPlugin2",
                "tags"
            ],
            "436": [
                "IssueTrackingPlugin2",
                "tags"
            ],
            "437": [
                "IssueTrackingPlugin2",
                "tags"
            ],
            "438": [
                "IssueTrackingPlugin2",
                "tags"
            ]
        },
        "addLocation": []
    }
}