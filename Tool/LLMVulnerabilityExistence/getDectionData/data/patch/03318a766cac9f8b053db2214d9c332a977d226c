{
    "synapse/config/tls.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import warnings"
            },
            "1": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " from datetime import datetime"
            },
            "2": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from hashlib import sha256"
            },
            "3": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from typing import List, Optional"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+from typing import List, Optional, Pattern"
            },
            "5": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from unpaddedbase64 import encode_base64"
            },
            "7": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "             fed_whitelist_entries = []"
            },
            "9": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 125,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "         # Support globs (*) in whitelist values"
            },
            "11": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.federation_certificate_verification_whitelist = []  # type: List[str]"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+        self.federation_certificate_verification_whitelist = []  # type: List[Pattern]"
            },
            "13": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "         for entry in fed_whitelist_entries:"
            },
            "14": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "             try:"
            },
            "15": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "                 entry_regex = glob_to_regex(entry.encode(\"ascii\").decode(\"ascii\"))"
            }
        },
        "frontPatchFile": [
            "# Copyright 2014-2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import logging",
            "import os",
            "import warnings",
            "from datetime import datetime",
            "from hashlib import sha256",
            "from typing import List, Optional",
            "",
            "from unpaddedbase64 import encode_base64",
            "",
            "from OpenSSL import SSL, crypto",
            "from twisted.internet._sslverify import Certificate, trustRootFromCertificates",
            "",
            "from synapse.config._base import Config, ConfigError",
            "from synapse.util import glob_to_regex",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "ACME_SUPPORT_ENABLED_WARN = \"\"\"\\",
            "This server uses Synapse's built-in ACME support. Note that ACME v1 has been",
            "deprecated by Let's Encrypt, and that Synapse doesn't currently support ACME v2,",
            "which means that this feature will not work with Synapse installs set up after",
            "November 2019, and that it may stop working on June 2020 for installs set up",
            "before that date.",
            "",
            "For more info and alternative solutions, see",
            "https://github.com/matrix-org/synapse/blob/master/docs/ACME.md#deprecation-of-acme-v1",
            "--------------------------------------------------------------------------------\"\"\"",
            "",
            "",
            "class TlsConfig(Config):",
            "    section = \"tls\"",
            "",
            "    def read_config(self, config: dict, config_dir_path: str, **kwargs):",
            "",
            "        acme_config = config.get(\"acme\", None)",
            "        if acme_config is None:",
            "            acme_config = {}",
            "",
            "        self.acme_enabled = acme_config.get(\"enabled\", False)",
            "",
            "        if self.acme_enabled:",
            "            logger.warning(ACME_SUPPORT_ENABLED_WARN)",
            "",
            "        # hyperlink complains on py2 if this is not a Unicode",
            "        self.acme_url = str(",
            "            acme_config.get(\"url\", \"https://acme-v01.api.letsencrypt.org/directory\")",
            "        )",
            "        self.acme_port = acme_config.get(\"port\", 80)",
            "        self.acme_bind_addresses = acme_config.get(\"bind_addresses\", [\"::\", \"0.0.0.0\"])",
            "        self.acme_reprovision_threshold = acme_config.get(\"reprovision_threshold\", 30)",
            "        self.acme_domain = acme_config.get(\"domain\", config.get(\"server_name\"))",
            "",
            "        self.acme_account_key_file = self.abspath(",
            "            acme_config.get(\"account_key_file\", config_dir_path + \"/client.key\")",
            "        )",
            "",
            "        self.tls_certificate_file = self.abspath(config.get(\"tls_certificate_path\"))",
            "        self.tls_private_key_file = self.abspath(config.get(\"tls_private_key_path\"))",
            "",
            "        if self.root.server.has_tls_listener():",
            "            if not self.tls_certificate_file:",
            "                raise ConfigError(",
            "                    \"tls_certificate_path must be specified if TLS-enabled listeners are \"",
            "                    \"configured.\"",
            "                )",
            "            if not self.tls_private_key_file:",
            "                raise ConfigError(",
            "                    \"tls_private_key_path must be specified if TLS-enabled listeners are \"",
            "                    \"configured.\"",
            "                )",
            "",
            "        self._original_tls_fingerprints = config.get(\"tls_fingerprints\", [])",
            "",
            "        if self._original_tls_fingerprints is None:",
            "            self._original_tls_fingerprints = []",
            "",
            "        self.tls_fingerprints = list(self._original_tls_fingerprints)",
            "",
            "        # Whether to verify certificates on outbound federation traffic",
            "        self.federation_verify_certificates = config.get(",
            "            \"federation_verify_certificates\", True",
            "        )",
            "",
            "        # Minimum TLS version to use for outbound federation traffic",
            "        self.federation_client_minimum_tls_version = str(",
            "            config.get(\"federation_client_minimum_tls_version\", 1)",
            "        )",
            "",
            "        if self.federation_client_minimum_tls_version not in [\"1\", \"1.1\", \"1.2\", \"1.3\"]:",
            "            raise ConfigError(",
            "                \"federation_client_minimum_tls_version must be one of: 1, 1.1, 1.2, 1.3\"",
            "            )",
            "",
            "        # Prevent people shooting themselves in the foot here by setting it to",
            "        # the biggest number blindly",
            "        if self.federation_client_minimum_tls_version == \"1.3\":",
            "            if getattr(SSL, \"OP_NO_TLSv1_3\", None) is None:",
            "                raise ConfigError(",
            "                    (",
            "                        \"federation_client_minimum_tls_version cannot be 1.3, \"",
            "                        \"your OpenSSL does not support it\"",
            "                    )",
            "                )",
            "",
            "        # Whitelist of domains to not verify certificates for",
            "        fed_whitelist_entries = config.get(",
            "            \"federation_certificate_verification_whitelist\", []",
            "        )",
            "        if fed_whitelist_entries is None:",
            "            fed_whitelist_entries = []",
            "",
            "        # Support globs (*) in whitelist values",
            "        self.federation_certificate_verification_whitelist = []  # type: List[str]",
            "        for entry in fed_whitelist_entries:",
            "            try:",
            "                entry_regex = glob_to_regex(entry.encode(\"ascii\").decode(\"ascii\"))",
            "            except UnicodeEncodeError:",
            "                raise ConfigError(",
            "                    \"IDNA domain names are not allowed in the \"",
            "                    \"federation_certificate_verification_whitelist: %s\" % (entry,)",
            "                )",
            "",
            "            # Convert globs to regex",
            "            self.federation_certificate_verification_whitelist.append(entry_regex)",
            "",
            "        # List of custom certificate authorities for federation traffic validation",
            "        custom_ca_list = config.get(\"federation_custom_ca_list\", None)",
            "",
            "        # Read in and parse custom CA certificates",
            "        self.federation_ca_trust_root = None",
            "        if custom_ca_list is not None:",
            "            if len(custom_ca_list) == 0:",
            "                # A trustroot cannot be generated without any CA certificates.",
            "                # Raise an error if this option has been specified without any",
            "                # corresponding certificates.",
            "                raise ConfigError(",
            "                    \"federation_custom_ca_list specified without \"",
            "                    \"any certificate files\"",
            "                )",
            "",
            "            certs = []",
            "            for ca_file in custom_ca_list:",
            "                logger.debug(\"Reading custom CA certificate file: %s\", ca_file)",
            "                content = self.read_file(ca_file, \"federation_custom_ca_list\")",
            "",
            "                # Parse the CA certificates",
            "                try:",
            "                    cert_base = Certificate.loadPEM(content)",
            "                    certs.append(cert_base)",
            "                except Exception as e:",
            "                    raise ConfigError(",
            "                        \"Error parsing custom CA certificate file %s: %s\" % (ca_file, e)",
            "                    )",
            "",
            "            self.federation_ca_trust_root = trustRootFromCertificates(certs)",
            "",
            "        # This config option applies to non-federation HTTP clients",
            "        # (e.g. for talking to recaptcha, identity servers, and such)",
            "        # It should never be used in production, and is intended for",
            "        # use only when running tests.",
            "        self.use_insecure_ssl_client_just_for_testing_do_not_use = config.get(",
            "            \"use_insecure_ssl_client_just_for_testing_do_not_use\"",
            "        )",
            "",
            "        self.tls_certificate = None  # type: Optional[crypto.X509]",
            "        self.tls_private_key = None  # type: Optional[crypto.PKey]",
            "",
            "    def is_disk_cert_valid(self, allow_self_signed=True):",
            "        \"\"\"",
            "        Is the certificate we have on disk valid, and if so, for how long?",
            "",
            "        Args:",
            "            allow_self_signed (bool): Should we allow the certificate we",
            "                read to be self signed?",
            "",
            "        Returns:",
            "            int: Days remaining of certificate validity.",
            "            None: No certificate exists.",
            "        \"\"\"",
            "        if not os.path.exists(self.tls_certificate_file):",
            "            return None",
            "",
            "        try:",
            "            with open(self.tls_certificate_file, \"rb\") as f:",
            "                cert_pem = f.read()",
            "        except Exception as e:",
            "            raise ConfigError(",
            "                \"Failed to read existing certificate file %s: %s\"",
            "                % (self.tls_certificate_file, e)",
            "            )",
            "",
            "        try:",
            "            tls_certificate = crypto.load_certificate(crypto.FILETYPE_PEM, cert_pem)",
            "        except Exception as e:",
            "            raise ConfigError(",
            "                \"Failed to parse existing certificate file %s: %s\"",
            "                % (self.tls_certificate_file, e)",
            "            )",
            "",
            "        if not allow_self_signed:",
            "            if tls_certificate.get_subject() == tls_certificate.get_issuer():",
            "                raise ValueError(",
            "                    \"TLS Certificate is self signed, and this is not permitted\"",
            "                )",
            "",
            "        # YYYYMMDDhhmmssZ -- in UTC",
            "        expires_on = datetime.strptime(",
            "            tls_certificate.get_notAfter().decode(\"ascii\"), \"%Y%m%d%H%M%SZ\"",
            "        )",
            "        now = datetime.utcnow()",
            "        days_remaining = (expires_on - now).days",
            "        return days_remaining",
            "",
            "    def read_certificate_from_disk(self, require_cert_and_key: bool):",
            "        \"\"\"",
            "        Read the certificates and private key from disk.",
            "",
            "        Args:",
            "            require_cert_and_key: set to True to throw an error if the certificate",
            "                and key file are not given",
            "        \"\"\"",
            "        if require_cert_and_key:",
            "            self.tls_private_key = self.read_tls_private_key()",
            "            self.tls_certificate = self.read_tls_certificate()",
            "        elif self.tls_certificate_file:",
            "            # we only need the certificate for the tls_fingerprints. Reload it if we",
            "            # can, but it's not a fatal error if we can't.",
            "            try:",
            "                self.tls_certificate = self.read_tls_certificate()",
            "            except Exception as e:",
            "                logger.info(",
            "                    \"Unable to read TLS certificate (%s). Ignoring as no \"",
            "                    \"tls listeners enabled.\",",
            "                    e,",
            "                )",
            "",
            "        self.tls_fingerprints = list(self._original_tls_fingerprints)",
            "",
            "        if self.tls_certificate:",
            "            # Check that our own certificate is included in the list of fingerprints",
            "            # and include it if it is not.",
            "            x509_certificate_bytes = crypto.dump_certificate(",
            "                crypto.FILETYPE_ASN1, self.tls_certificate",
            "            )",
            "            sha256_fingerprint = encode_base64(sha256(x509_certificate_bytes).digest())",
            "            sha256_fingerprints = {f[\"sha256\"] for f in self.tls_fingerprints}",
            "            if sha256_fingerprint not in sha256_fingerprints:",
            "                self.tls_fingerprints.append({\"sha256\": sha256_fingerprint})",
            "",
            "    def generate_config_section(",
            "        self,",
            "        config_dir_path,",
            "        server_name,",
            "        data_dir_path,",
            "        tls_certificate_path,",
            "        tls_private_key_path,",
            "        acme_domain,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"If the acme_domain is specified acme will be enabled.",
            "        If the TLS paths are not specified the default will be certs in the",
            "        config directory\"\"\"",
            "",
            "        base_key_name = os.path.join(config_dir_path, server_name)",
            "",
            "        if bool(tls_certificate_path) != bool(tls_private_key_path):",
            "            raise ConfigError(",
            "                \"Please specify both a cert path and a key path or neither.\"",
            "            )",
            "",
            "        tls_enabled = (",
            "            \"\" if tls_certificate_path and tls_private_key_path or acme_domain else \"#\"",
            "        )",
            "",
            "        if not tls_certificate_path:",
            "            tls_certificate_path = base_key_name + \".tls.crt\"",
            "        if not tls_private_key_path:",
            "            tls_private_key_path = base_key_name + \".tls.key\"",
            "",
            "        acme_enabled = bool(acme_domain)",
            "        acme_domain = \"matrix.example.com\"",
            "",
            "        default_acme_account_file = os.path.join(data_dir_path, \"acme_account.key\")",
            "",
            "        # this is to avoid the max line length. Sorrynotsorry",
            "        proxypassline = (",
            "            \"ProxyPass /.well-known/acme-challenge \"",
            "            \"http://localhost:8009/.well-known/acme-challenge\"",
            "        )",
            "",
            "        # flake8 doesn't recognise that variables are used in the below string",
            "        _ = tls_enabled, proxypassline, acme_enabled, default_acme_account_file",
            "",
            "        return (",
            "            \"\"\"\\",
            "        ## TLS ##",
            "",
            "        # PEM-encoded X509 certificate for TLS.",
            "        # This certificate, as of Synapse 1.0, will need to be a valid and verifiable",
            "        # certificate, signed by a recognised Certificate Authority.",
            "        #",
            "        # See 'ACME support' below to enable auto-provisioning this certificate via",
            "        # Let's Encrypt.",
            "        #",
            "        # If supplying your own, be sure to use a `.pem` file that includes the",
            "        # full certificate chain including any intermediate certificates (for",
            "        # instance, if using certbot, use `fullchain.pem` as your certificate,",
            "        # not `cert.pem`).",
            "        #",
            "        %(tls_enabled)stls_certificate_path: \"%(tls_certificate_path)s\"",
            "",
            "        # PEM-encoded private key for TLS",
            "        #",
            "        %(tls_enabled)stls_private_key_path: \"%(tls_private_key_path)s\"",
            "",
            "        # Whether to verify TLS server certificates for outbound federation requests.",
            "        #",
            "        # Defaults to `true`. To disable certificate verification, uncomment the",
            "        # following line.",
            "        #",
            "        #federation_verify_certificates: false",
            "",
            "        # The minimum TLS version that will be used for outbound federation requests.",
            "        #",
            "        # Defaults to `1`. Configurable to `1`, `1.1`, `1.2`, or `1.3`. Note",
            "        # that setting this value higher than `1.2` will prevent federation to most",
            "        # of the public Matrix network: only configure it to `1.3` if you have an",
            "        # entirely private federation setup and you can ensure TLS 1.3 support.",
            "        #",
            "        #federation_client_minimum_tls_version: 1.2",
            "",
            "        # Skip federation certificate verification on the following whitelist",
            "        # of domains.",
            "        #",
            "        # This setting should only be used in very specific cases, such as",
            "        # federation over Tor hidden services and similar. For private networks",
            "        # of homeservers, you likely want to use a private CA instead.",
            "        #",
            "        # Only effective if federation_verify_certicates is `true`.",
            "        #",
            "        #federation_certificate_verification_whitelist:",
            "        #  - lon.example.com",
            "        #  - *.domain.com",
            "        #  - *.onion",
            "",
            "        # List of custom certificate authorities for federation traffic.",
            "        #",
            "        # This setting should only normally be used within a private network of",
            "        # homeservers.",
            "        #",
            "        # Note that this list will replace those that are provided by your",
            "        # operating environment. Certificates must be in PEM format.",
            "        #",
            "        #federation_custom_ca_list:",
            "        #  - myCA1.pem",
            "        #  - myCA2.pem",
            "        #  - myCA3.pem",
            "",
            "        # ACME support: This will configure Synapse to request a valid TLS certificate",
            "        # for your configured `server_name` via Let's Encrypt.",
            "        #",
            "        # Note that ACME v1 is now deprecated, and Synapse currently doesn't support",
            "        # ACME v2. This means that this feature currently won't work with installs set",
            "        # up after November 2019. For more info, and alternative solutions, see",
            "        # https://github.com/matrix-org/synapse/blob/master/docs/ACME.md#deprecation-of-acme-v1",
            "        #",
            "        # Note that provisioning a certificate in this way requires port 80 to be",
            "        # routed to Synapse so that it can complete the http-01 ACME challenge.",
            "        # By default, if you enable ACME support, Synapse will attempt to listen on",
            "        # port 80 for incoming http-01 challenges - however, this will likely fail",
            "        # with 'Permission denied' or a similar error.",
            "        #",
            "        # There are a couple of potential solutions to this:",
            "        #",
            "        #  * If you already have an Apache, Nginx, or similar listening on port 80,",
            "        #    you can configure Synapse to use an alternate port, and have your web",
            "        #    server forward the requests. For example, assuming you set 'port: 8009'",
            "        #    below, on Apache, you would write:",
            "        #",
            "        #    %(proxypassline)s",
            "        #",
            "        #  * Alternatively, you can use something like `authbind` to give Synapse",
            "        #    permission to listen on port 80.",
            "        #",
            "        acme:",
            "            # ACME support is disabled by default. Set this to `true` and uncomment",
            "            # tls_certificate_path and tls_private_key_path above to enable it.",
            "            #",
            "            enabled: %(acme_enabled)s",
            "",
            "            # Endpoint to use to request certificates. If you only want to test,",
            "            # use Let's Encrypt's staging url:",
            "            #     https://acme-staging.api.letsencrypt.org/directory",
            "            #",
            "            #url: https://acme-v01.api.letsencrypt.org/directory",
            "",
            "            # Port number to listen on for the HTTP-01 challenge. Change this if",
            "            # you are forwarding connections through Apache/Nginx/etc.",
            "            #",
            "            port: 80",
            "",
            "            # Local addresses to listen on for incoming connections.",
            "            # Again, you may want to change this if you are forwarding connections",
            "            # through Apache/Nginx/etc.",
            "            #",
            "            bind_addresses: ['::', '0.0.0.0']",
            "",
            "            # How many days remaining on a certificate before it is renewed.",
            "            #",
            "            reprovision_threshold: 30",
            "",
            "            # The domain that the certificate should be for. Normally this",
            "            # should be the same as your Matrix domain (i.e., 'server_name'), but,",
            "            # by putting a file at 'https://<server_name>/.well-known/matrix/server',",
            "            # you can delegate incoming traffic to another server. If you do that,",
            "            # you should give the target of the delegation here.",
            "            #",
            "            # For example: if your 'server_name' is 'example.com', but",
            "            # 'https://example.com/.well-known/matrix/server' delegates to",
            "            # 'matrix.example.com', you should put 'matrix.example.com' here.",
            "            #",
            "            # If not set, defaults to your 'server_name'.",
            "            #",
            "            domain: %(acme_domain)s",
            "",
            "            # file to use for the account key. This will be generated if it doesn't",
            "            # exist.",
            "            #",
            "            # If unspecified, we will use CONFDIR/client.key.",
            "            #",
            "            account_key_file: %(default_acme_account_file)s",
            "",
            "        # List of allowed TLS fingerprints for this server to publish along",
            "        # with the signing keys for this server. Other matrix servers that",
            "        # make HTTPS requests to this server will check that the TLS",
            "        # certificates returned by this server match one of the fingerprints.",
            "        #",
            "        # Synapse automatically adds the fingerprint of its own certificate",
            "        # to the list. So if federation traffic is handled directly by synapse",
            "        # then no modification to the list is required.",
            "        #",
            "        # If synapse is run behind a load balancer that handles the TLS then it",
            "        # will be necessary to add the fingerprints of the certificates used by",
            "        # the loadbalancers to this list if they are different to the one",
            "        # synapse is using.",
            "        #",
            "        # Homeservers are permitted to cache the list of TLS fingerprints",
            "        # returned in the key responses up to the \"valid_until_ts\" returned in",
            "        # key. It may be necessary to publish the fingerprints of a new",
            "        # certificate and wait until the \"valid_until_ts\" of the previous key",
            "        # responses have passed before deploying it.",
            "        #",
            "        # You can calculate a fingerprint from a given TLS listener via:",
            "        # openssl s_client -connect $host:$port < /dev/null 2> /dev/null |",
            "        #   openssl x509 -outform DER | openssl sha256 -binary | base64 | tr -d '='",
            "        # or by checking matrix.org/federationtester/api/report?server_name=$host",
            "        #",
            "        #tls_fingerprints: [{\"sha256\": \"<base64_encoded_sha256_fingerprint>\"}]",
            "        \"\"\"",
            "            # Lowercase the string representation of boolean values",
            "            % {",
            "                x[0]: str(x[1]).lower() if isinstance(x[1], bool) else x[1]",
            "                for x in locals().items()",
            "            }",
            "        )",
            "",
            "    def read_tls_certificate(self) -> crypto.X509:",
            "        \"\"\"Reads the TLS certificate from the configured file, and returns it",
            "",
            "        Also checks if it is self-signed, and warns if so",
            "",
            "        Returns:",
            "            The certificate",
            "        \"\"\"",
            "        cert_path = self.tls_certificate_file",
            "        logger.info(\"Loading TLS certificate from %s\", cert_path)",
            "        cert_pem = self.read_file(cert_path, \"tls_certificate_path\")",
            "        cert = crypto.load_certificate(crypto.FILETYPE_PEM, cert_pem)",
            "",
            "        # Check if it is self-signed, and issue a warning if so.",
            "        if cert.get_issuer() == cert.get_subject():",
            "            warnings.warn(",
            "                (",
            "                    \"Self-signed TLS certificates will not be accepted by Synapse 1.0. \"",
            "                    \"Please either provide a valid certificate, or use Synapse's ACME \"",
            "                    \"support to provision one.\"",
            "                )",
            "            )",
            "",
            "        return cert",
            "",
            "    def read_tls_private_key(self) -> crypto.PKey:",
            "        \"\"\"Reads the TLS private key from the configured file, and returns it",
            "",
            "        Returns:",
            "            The private key",
            "        \"\"\"",
            "        private_key_path = self.tls_private_key_file",
            "        logger.info(\"Loading TLS key from %s\", private_key_path)",
            "        private_key_pem = self.read_file(private_key_path, \"tls_private_key_path\")",
            "        return crypto.load_privatekey(crypto.FILETYPE_PEM, private_key_pem)"
        ],
        "afterPatchFile": [
            "# Copyright 2014-2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import logging",
            "import os",
            "import warnings",
            "from datetime import datetime",
            "from hashlib import sha256",
            "from typing import List, Optional, Pattern",
            "",
            "from unpaddedbase64 import encode_base64",
            "",
            "from OpenSSL import SSL, crypto",
            "from twisted.internet._sslverify import Certificate, trustRootFromCertificates",
            "",
            "from synapse.config._base import Config, ConfigError",
            "from synapse.util import glob_to_regex",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "ACME_SUPPORT_ENABLED_WARN = \"\"\"\\",
            "This server uses Synapse's built-in ACME support. Note that ACME v1 has been",
            "deprecated by Let's Encrypt, and that Synapse doesn't currently support ACME v2,",
            "which means that this feature will not work with Synapse installs set up after",
            "November 2019, and that it may stop working on June 2020 for installs set up",
            "before that date.",
            "",
            "For more info and alternative solutions, see",
            "https://github.com/matrix-org/synapse/blob/master/docs/ACME.md#deprecation-of-acme-v1",
            "--------------------------------------------------------------------------------\"\"\"",
            "",
            "",
            "class TlsConfig(Config):",
            "    section = \"tls\"",
            "",
            "    def read_config(self, config: dict, config_dir_path: str, **kwargs):",
            "",
            "        acme_config = config.get(\"acme\", None)",
            "        if acme_config is None:",
            "            acme_config = {}",
            "",
            "        self.acme_enabled = acme_config.get(\"enabled\", False)",
            "",
            "        if self.acme_enabled:",
            "            logger.warning(ACME_SUPPORT_ENABLED_WARN)",
            "",
            "        # hyperlink complains on py2 if this is not a Unicode",
            "        self.acme_url = str(",
            "            acme_config.get(\"url\", \"https://acme-v01.api.letsencrypt.org/directory\")",
            "        )",
            "        self.acme_port = acme_config.get(\"port\", 80)",
            "        self.acme_bind_addresses = acme_config.get(\"bind_addresses\", [\"::\", \"0.0.0.0\"])",
            "        self.acme_reprovision_threshold = acme_config.get(\"reprovision_threshold\", 30)",
            "        self.acme_domain = acme_config.get(\"domain\", config.get(\"server_name\"))",
            "",
            "        self.acme_account_key_file = self.abspath(",
            "            acme_config.get(\"account_key_file\", config_dir_path + \"/client.key\")",
            "        )",
            "",
            "        self.tls_certificate_file = self.abspath(config.get(\"tls_certificate_path\"))",
            "        self.tls_private_key_file = self.abspath(config.get(\"tls_private_key_path\"))",
            "",
            "        if self.root.server.has_tls_listener():",
            "            if not self.tls_certificate_file:",
            "                raise ConfigError(",
            "                    \"tls_certificate_path must be specified if TLS-enabled listeners are \"",
            "                    \"configured.\"",
            "                )",
            "            if not self.tls_private_key_file:",
            "                raise ConfigError(",
            "                    \"tls_private_key_path must be specified if TLS-enabled listeners are \"",
            "                    \"configured.\"",
            "                )",
            "",
            "        self._original_tls_fingerprints = config.get(\"tls_fingerprints\", [])",
            "",
            "        if self._original_tls_fingerprints is None:",
            "            self._original_tls_fingerprints = []",
            "",
            "        self.tls_fingerprints = list(self._original_tls_fingerprints)",
            "",
            "        # Whether to verify certificates on outbound federation traffic",
            "        self.federation_verify_certificates = config.get(",
            "            \"federation_verify_certificates\", True",
            "        )",
            "",
            "        # Minimum TLS version to use for outbound federation traffic",
            "        self.federation_client_minimum_tls_version = str(",
            "            config.get(\"federation_client_minimum_tls_version\", 1)",
            "        )",
            "",
            "        if self.federation_client_minimum_tls_version not in [\"1\", \"1.1\", \"1.2\", \"1.3\"]:",
            "            raise ConfigError(",
            "                \"federation_client_minimum_tls_version must be one of: 1, 1.1, 1.2, 1.3\"",
            "            )",
            "",
            "        # Prevent people shooting themselves in the foot here by setting it to",
            "        # the biggest number blindly",
            "        if self.federation_client_minimum_tls_version == \"1.3\":",
            "            if getattr(SSL, \"OP_NO_TLSv1_3\", None) is None:",
            "                raise ConfigError(",
            "                    (",
            "                        \"federation_client_minimum_tls_version cannot be 1.3, \"",
            "                        \"your OpenSSL does not support it\"",
            "                    )",
            "                )",
            "",
            "        # Whitelist of domains to not verify certificates for",
            "        fed_whitelist_entries = config.get(",
            "            \"federation_certificate_verification_whitelist\", []",
            "        )",
            "        if fed_whitelist_entries is None:",
            "            fed_whitelist_entries = []",
            "",
            "        # Support globs (*) in whitelist values",
            "        self.federation_certificate_verification_whitelist = []  # type: List[Pattern]",
            "        for entry in fed_whitelist_entries:",
            "            try:",
            "                entry_regex = glob_to_regex(entry.encode(\"ascii\").decode(\"ascii\"))",
            "            except UnicodeEncodeError:",
            "                raise ConfigError(",
            "                    \"IDNA domain names are not allowed in the \"",
            "                    \"federation_certificate_verification_whitelist: %s\" % (entry,)",
            "                )",
            "",
            "            # Convert globs to regex",
            "            self.federation_certificate_verification_whitelist.append(entry_regex)",
            "",
            "        # List of custom certificate authorities for federation traffic validation",
            "        custom_ca_list = config.get(\"federation_custom_ca_list\", None)",
            "",
            "        # Read in and parse custom CA certificates",
            "        self.federation_ca_trust_root = None",
            "        if custom_ca_list is not None:",
            "            if len(custom_ca_list) == 0:",
            "                # A trustroot cannot be generated without any CA certificates.",
            "                # Raise an error if this option has been specified without any",
            "                # corresponding certificates.",
            "                raise ConfigError(",
            "                    \"federation_custom_ca_list specified without \"",
            "                    \"any certificate files\"",
            "                )",
            "",
            "            certs = []",
            "            for ca_file in custom_ca_list:",
            "                logger.debug(\"Reading custom CA certificate file: %s\", ca_file)",
            "                content = self.read_file(ca_file, \"federation_custom_ca_list\")",
            "",
            "                # Parse the CA certificates",
            "                try:",
            "                    cert_base = Certificate.loadPEM(content)",
            "                    certs.append(cert_base)",
            "                except Exception as e:",
            "                    raise ConfigError(",
            "                        \"Error parsing custom CA certificate file %s: %s\" % (ca_file, e)",
            "                    )",
            "",
            "            self.federation_ca_trust_root = trustRootFromCertificates(certs)",
            "",
            "        # This config option applies to non-federation HTTP clients",
            "        # (e.g. for talking to recaptcha, identity servers, and such)",
            "        # It should never be used in production, and is intended for",
            "        # use only when running tests.",
            "        self.use_insecure_ssl_client_just_for_testing_do_not_use = config.get(",
            "            \"use_insecure_ssl_client_just_for_testing_do_not_use\"",
            "        )",
            "",
            "        self.tls_certificate = None  # type: Optional[crypto.X509]",
            "        self.tls_private_key = None  # type: Optional[crypto.PKey]",
            "",
            "    def is_disk_cert_valid(self, allow_self_signed=True):",
            "        \"\"\"",
            "        Is the certificate we have on disk valid, and if so, for how long?",
            "",
            "        Args:",
            "            allow_self_signed (bool): Should we allow the certificate we",
            "                read to be self signed?",
            "",
            "        Returns:",
            "            int: Days remaining of certificate validity.",
            "            None: No certificate exists.",
            "        \"\"\"",
            "        if not os.path.exists(self.tls_certificate_file):",
            "            return None",
            "",
            "        try:",
            "            with open(self.tls_certificate_file, \"rb\") as f:",
            "                cert_pem = f.read()",
            "        except Exception as e:",
            "            raise ConfigError(",
            "                \"Failed to read existing certificate file %s: %s\"",
            "                % (self.tls_certificate_file, e)",
            "            )",
            "",
            "        try:",
            "            tls_certificate = crypto.load_certificate(crypto.FILETYPE_PEM, cert_pem)",
            "        except Exception as e:",
            "            raise ConfigError(",
            "                \"Failed to parse existing certificate file %s: %s\"",
            "                % (self.tls_certificate_file, e)",
            "            )",
            "",
            "        if not allow_self_signed:",
            "            if tls_certificate.get_subject() == tls_certificate.get_issuer():",
            "                raise ValueError(",
            "                    \"TLS Certificate is self signed, and this is not permitted\"",
            "                )",
            "",
            "        # YYYYMMDDhhmmssZ -- in UTC",
            "        expires_on = datetime.strptime(",
            "            tls_certificate.get_notAfter().decode(\"ascii\"), \"%Y%m%d%H%M%SZ\"",
            "        )",
            "        now = datetime.utcnow()",
            "        days_remaining = (expires_on - now).days",
            "        return days_remaining",
            "",
            "    def read_certificate_from_disk(self, require_cert_and_key: bool):",
            "        \"\"\"",
            "        Read the certificates and private key from disk.",
            "",
            "        Args:",
            "            require_cert_and_key: set to True to throw an error if the certificate",
            "                and key file are not given",
            "        \"\"\"",
            "        if require_cert_and_key:",
            "            self.tls_private_key = self.read_tls_private_key()",
            "            self.tls_certificate = self.read_tls_certificate()",
            "        elif self.tls_certificate_file:",
            "            # we only need the certificate for the tls_fingerprints. Reload it if we",
            "            # can, but it's not a fatal error if we can't.",
            "            try:",
            "                self.tls_certificate = self.read_tls_certificate()",
            "            except Exception as e:",
            "                logger.info(",
            "                    \"Unable to read TLS certificate (%s). Ignoring as no \"",
            "                    \"tls listeners enabled.\",",
            "                    e,",
            "                )",
            "",
            "        self.tls_fingerprints = list(self._original_tls_fingerprints)",
            "",
            "        if self.tls_certificate:",
            "            # Check that our own certificate is included in the list of fingerprints",
            "            # and include it if it is not.",
            "            x509_certificate_bytes = crypto.dump_certificate(",
            "                crypto.FILETYPE_ASN1, self.tls_certificate",
            "            )",
            "            sha256_fingerprint = encode_base64(sha256(x509_certificate_bytes).digest())",
            "            sha256_fingerprints = {f[\"sha256\"] for f in self.tls_fingerprints}",
            "            if sha256_fingerprint not in sha256_fingerprints:",
            "                self.tls_fingerprints.append({\"sha256\": sha256_fingerprint})",
            "",
            "    def generate_config_section(",
            "        self,",
            "        config_dir_path,",
            "        server_name,",
            "        data_dir_path,",
            "        tls_certificate_path,",
            "        tls_private_key_path,",
            "        acme_domain,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"If the acme_domain is specified acme will be enabled.",
            "        If the TLS paths are not specified the default will be certs in the",
            "        config directory\"\"\"",
            "",
            "        base_key_name = os.path.join(config_dir_path, server_name)",
            "",
            "        if bool(tls_certificate_path) != bool(tls_private_key_path):",
            "            raise ConfigError(",
            "                \"Please specify both a cert path and a key path or neither.\"",
            "            )",
            "",
            "        tls_enabled = (",
            "            \"\" if tls_certificate_path and tls_private_key_path or acme_domain else \"#\"",
            "        )",
            "",
            "        if not tls_certificate_path:",
            "            tls_certificate_path = base_key_name + \".tls.crt\"",
            "        if not tls_private_key_path:",
            "            tls_private_key_path = base_key_name + \".tls.key\"",
            "",
            "        acme_enabled = bool(acme_domain)",
            "        acme_domain = \"matrix.example.com\"",
            "",
            "        default_acme_account_file = os.path.join(data_dir_path, \"acme_account.key\")",
            "",
            "        # this is to avoid the max line length. Sorrynotsorry",
            "        proxypassline = (",
            "            \"ProxyPass /.well-known/acme-challenge \"",
            "            \"http://localhost:8009/.well-known/acme-challenge\"",
            "        )",
            "",
            "        # flake8 doesn't recognise that variables are used in the below string",
            "        _ = tls_enabled, proxypassline, acme_enabled, default_acme_account_file",
            "",
            "        return (",
            "            \"\"\"\\",
            "        ## TLS ##",
            "",
            "        # PEM-encoded X509 certificate for TLS.",
            "        # This certificate, as of Synapse 1.0, will need to be a valid and verifiable",
            "        # certificate, signed by a recognised Certificate Authority.",
            "        #",
            "        # See 'ACME support' below to enable auto-provisioning this certificate via",
            "        # Let's Encrypt.",
            "        #",
            "        # If supplying your own, be sure to use a `.pem` file that includes the",
            "        # full certificate chain including any intermediate certificates (for",
            "        # instance, if using certbot, use `fullchain.pem` as your certificate,",
            "        # not `cert.pem`).",
            "        #",
            "        %(tls_enabled)stls_certificate_path: \"%(tls_certificate_path)s\"",
            "",
            "        # PEM-encoded private key for TLS",
            "        #",
            "        %(tls_enabled)stls_private_key_path: \"%(tls_private_key_path)s\"",
            "",
            "        # Whether to verify TLS server certificates for outbound federation requests.",
            "        #",
            "        # Defaults to `true`. To disable certificate verification, uncomment the",
            "        # following line.",
            "        #",
            "        #federation_verify_certificates: false",
            "",
            "        # The minimum TLS version that will be used for outbound federation requests.",
            "        #",
            "        # Defaults to `1`. Configurable to `1`, `1.1`, `1.2`, or `1.3`. Note",
            "        # that setting this value higher than `1.2` will prevent federation to most",
            "        # of the public Matrix network: only configure it to `1.3` if you have an",
            "        # entirely private federation setup and you can ensure TLS 1.3 support.",
            "        #",
            "        #federation_client_minimum_tls_version: 1.2",
            "",
            "        # Skip federation certificate verification on the following whitelist",
            "        # of domains.",
            "        #",
            "        # This setting should only be used in very specific cases, such as",
            "        # federation over Tor hidden services and similar. For private networks",
            "        # of homeservers, you likely want to use a private CA instead.",
            "        #",
            "        # Only effective if federation_verify_certicates is `true`.",
            "        #",
            "        #federation_certificate_verification_whitelist:",
            "        #  - lon.example.com",
            "        #  - *.domain.com",
            "        #  - *.onion",
            "",
            "        # List of custom certificate authorities for federation traffic.",
            "        #",
            "        # This setting should only normally be used within a private network of",
            "        # homeservers.",
            "        #",
            "        # Note that this list will replace those that are provided by your",
            "        # operating environment. Certificates must be in PEM format.",
            "        #",
            "        #federation_custom_ca_list:",
            "        #  - myCA1.pem",
            "        #  - myCA2.pem",
            "        #  - myCA3.pem",
            "",
            "        # ACME support: This will configure Synapse to request a valid TLS certificate",
            "        # for your configured `server_name` via Let's Encrypt.",
            "        #",
            "        # Note that ACME v1 is now deprecated, and Synapse currently doesn't support",
            "        # ACME v2. This means that this feature currently won't work with installs set",
            "        # up after November 2019. For more info, and alternative solutions, see",
            "        # https://github.com/matrix-org/synapse/blob/master/docs/ACME.md#deprecation-of-acme-v1",
            "        #",
            "        # Note that provisioning a certificate in this way requires port 80 to be",
            "        # routed to Synapse so that it can complete the http-01 ACME challenge.",
            "        # By default, if you enable ACME support, Synapse will attempt to listen on",
            "        # port 80 for incoming http-01 challenges - however, this will likely fail",
            "        # with 'Permission denied' or a similar error.",
            "        #",
            "        # There are a couple of potential solutions to this:",
            "        #",
            "        #  * If you already have an Apache, Nginx, or similar listening on port 80,",
            "        #    you can configure Synapse to use an alternate port, and have your web",
            "        #    server forward the requests. For example, assuming you set 'port: 8009'",
            "        #    below, on Apache, you would write:",
            "        #",
            "        #    %(proxypassline)s",
            "        #",
            "        #  * Alternatively, you can use something like `authbind` to give Synapse",
            "        #    permission to listen on port 80.",
            "        #",
            "        acme:",
            "            # ACME support is disabled by default. Set this to `true` and uncomment",
            "            # tls_certificate_path and tls_private_key_path above to enable it.",
            "            #",
            "            enabled: %(acme_enabled)s",
            "",
            "            # Endpoint to use to request certificates. If you only want to test,",
            "            # use Let's Encrypt's staging url:",
            "            #     https://acme-staging.api.letsencrypt.org/directory",
            "            #",
            "            #url: https://acme-v01.api.letsencrypt.org/directory",
            "",
            "            # Port number to listen on for the HTTP-01 challenge. Change this if",
            "            # you are forwarding connections through Apache/Nginx/etc.",
            "            #",
            "            port: 80",
            "",
            "            # Local addresses to listen on for incoming connections.",
            "            # Again, you may want to change this if you are forwarding connections",
            "            # through Apache/Nginx/etc.",
            "            #",
            "            bind_addresses: ['::', '0.0.0.0']",
            "",
            "            # How many days remaining on a certificate before it is renewed.",
            "            #",
            "            reprovision_threshold: 30",
            "",
            "            # The domain that the certificate should be for. Normally this",
            "            # should be the same as your Matrix domain (i.e., 'server_name'), but,",
            "            # by putting a file at 'https://<server_name>/.well-known/matrix/server',",
            "            # you can delegate incoming traffic to another server. If you do that,",
            "            # you should give the target of the delegation here.",
            "            #",
            "            # For example: if your 'server_name' is 'example.com', but",
            "            # 'https://example.com/.well-known/matrix/server' delegates to",
            "            # 'matrix.example.com', you should put 'matrix.example.com' here.",
            "            #",
            "            # If not set, defaults to your 'server_name'.",
            "            #",
            "            domain: %(acme_domain)s",
            "",
            "            # file to use for the account key. This will be generated if it doesn't",
            "            # exist.",
            "            #",
            "            # If unspecified, we will use CONFDIR/client.key.",
            "            #",
            "            account_key_file: %(default_acme_account_file)s",
            "",
            "        # List of allowed TLS fingerprints for this server to publish along",
            "        # with the signing keys for this server. Other matrix servers that",
            "        # make HTTPS requests to this server will check that the TLS",
            "        # certificates returned by this server match one of the fingerprints.",
            "        #",
            "        # Synapse automatically adds the fingerprint of its own certificate",
            "        # to the list. So if federation traffic is handled directly by synapse",
            "        # then no modification to the list is required.",
            "        #",
            "        # If synapse is run behind a load balancer that handles the TLS then it",
            "        # will be necessary to add the fingerprints of the certificates used by",
            "        # the loadbalancers to this list if they are different to the one",
            "        # synapse is using.",
            "        #",
            "        # Homeservers are permitted to cache the list of TLS fingerprints",
            "        # returned in the key responses up to the \"valid_until_ts\" returned in",
            "        # key. It may be necessary to publish the fingerprints of a new",
            "        # certificate and wait until the \"valid_until_ts\" of the previous key",
            "        # responses have passed before deploying it.",
            "        #",
            "        # You can calculate a fingerprint from a given TLS listener via:",
            "        # openssl s_client -connect $host:$port < /dev/null 2> /dev/null |",
            "        #   openssl x509 -outform DER | openssl sha256 -binary | base64 | tr -d '='",
            "        # or by checking matrix.org/federationtester/api/report?server_name=$host",
            "        #",
            "        #tls_fingerprints: [{\"sha256\": \"<base64_encoded_sha256_fingerprint>\"}]",
            "        \"\"\"",
            "            # Lowercase the string representation of boolean values",
            "            % {",
            "                x[0]: str(x[1]).lower() if isinstance(x[1], bool) else x[1]",
            "                for x in locals().items()",
            "            }",
            "        )",
            "",
            "    def read_tls_certificate(self) -> crypto.X509:",
            "        \"\"\"Reads the TLS certificate from the configured file, and returns it",
            "",
            "        Also checks if it is self-signed, and warns if so",
            "",
            "        Returns:",
            "            The certificate",
            "        \"\"\"",
            "        cert_path = self.tls_certificate_file",
            "        logger.info(\"Loading TLS certificate from %s\", cert_path)",
            "        cert_pem = self.read_file(cert_path, \"tls_certificate_path\")",
            "        cert = crypto.load_certificate(crypto.FILETYPE_PEM, cert_pem)",
            "",
            "        # Check if it is self-signed, and issue a warning if so.",
            "        if cert.get_issuer() == cert.get_subject():",
            "            warnings.warn(",
            "                (",
            "                    \"Self-signed TLS certificates will not be accepted by Synapse 1.0. \"",
            "                    \"Please either provide a valid certificate, or use Synapse's ACME \"",
            "                    \"support to provision one.\"",
            "                )",
            "            )",
            "",
            "        return cert",
            "",
            "    def read_tls_private_key(self) -> crypto.PKey:",
            "        \"\"\"Reads the TLS private key from the configured file, and returns it",
            "",
            "        Returns:",
            "            The private key",
            "        \"\"\"",
            "        private_key_path = self.tls_private_key_file",
            "        logger.info(\"Loading TLS key from %s\", private_key_path)",
            "        private_key_pem = self.read_file(private_key_path, \"tls_private_key_path\")",
            "        return crypto.load_privatekey(crypto.FILETYPE_PEM, private_key_pem)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "20": [],
            "127": [
                "TlsConfig",
                "read_config"
            ]
        },
        "addLocation": []
    },
    "synapse/push/push_rule_evaluator.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from synapse.events import EventBase"
            },
            "2": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from synapse.types import UserID"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+from synapse.util import glob_to_regex, re_word_boundary"
            },
            "4": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from synapse.util.caches.lrucache import LruCache"
            },
            "5": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " logger = logging.getLogger(__name__)"
            },
            "7": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "         r = regex_cache.get((display_name, False, True), None)"
            },
            "8": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "         if not r:"
            },
            "9": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "             r1 = re.escape(display_name)"
            },
            "10": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            r1 = _re_word_boundary(r1)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 187,
                "PatchRowcode": "+            r1 = re_word_boundary(r1)"
            },
            "12": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 188,
                "PatchRowcode": "             r = re.compile(r1, flags=re.IGNORECASE)"
            },
            "13": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 189,
                "PatchRowcode": "             regex_cache[(display_name, False, True)] = r"
            },
            "14": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 190,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 213,
                "PatchRowcode": "     try:"
            },
            "16": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": 214,
                "PatchRowcode": "         r = regex_cache.get((glob, True, word_boundary), None)"
            },
            "17": {
                "beforePatchRowNumber": 214,
                "afterPatchRowNumber": 215,
                "PatchRowcode": "         if not r:"
            },
            "18": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            r = _glob_to_re(glob, word_boundary)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 216,
                "PatchRowcode": "+            r = glob_to_regex(glob, word_boundary)"
            },
            "20": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": 217,
                "PatchRowcode": "             regex_cache[(glob, True, word_boundary)] = r"
            },
            "21": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": 218,
                "PatchRowcode": "         return bool(r.search(value))"
            },
            "22": {
                "beforePatchRowNumber": 218,
                "afterPatchRowNumber": 219,
                "PatchRowcode": "     except re.error:"
            },
            "23": {
                "beforePatchRowNumber": 219,
                "afterPatchRowNumber": 220,
                "PatchRowcode": "         logger.warning(\"Failed to parse glob to regex: %r\", glob)"
            },
            "24": {
                "beforePatchRowNumber": 220,
                "afterPatchRowNumber": 221,
                "PatchRowcode": "         return False"
            },
            "25": {
                "beforePatchRowNumber": 221,
                "afterPatchRowNumber": 222,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 222,
                "afterPatchRowNumber": 223,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 223,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def _glob_to_re(glob: str, word_boundary: bool) -> Pattern:"
            },
            "28": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"Generates regex for a given glob."
            },
            "29": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "30": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Args:"
            },
            "31": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        glob"
            },
            "32": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        word_boundary: Whether to match against word boundaries or entire string."
            },
            "33": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "34": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if IS_GLOB.search(glob):"
            },
            "35": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        r = re.escape(glob)"
            },
            "36": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "37": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        r = r.replace(r\"\\*\", \".*?\")"
            },
            "38": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        r = r.replace(r\"\\?\", \".\")"
            },
            "39": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "40": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # handle [abc], [a-z] and [!a-z] style ranges."
            },
            "41": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        r = GLOB_REGEX.sub("
            },
            "42": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            lambda x: ("
            },
            "43": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"[%s%s]\" % (x.group(1) and \"^\" or \"\", x.group(2).replace(r\"\\\\\\-\", \"-\"))"
            },
            "44": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            ),"
            },
            "45": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            r,"
            },
            "46": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        )"
            },
            "47": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if word_boundary:"
            },
            "48": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            r = _re_word_boundary(r)"
            },
            "49": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "50": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return re.compile(r, flags=re.IGNORECASE)"
            },
            "51": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        else:"
            },
            "52": {
                "beforePatchRowNumber": 248,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            r = \"^\" + r + \"$\""
            },
            "53": {
                "beforePatchRowNumber": 249,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "54": {
                "beforePatchRowNumber": 250,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return re.compile(r, flags=re.IGNORECASE)"
            },
            "55": {
                "beforePatchRowNumber": 251,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    elif word_boundary:"
            },
            "56": {
                "beforePatchRowNumber": 252,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        r = re.escape(glob)"
            },
            "57": {
                "beforePatchRowNumber": 253,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        r = _re_word_boundary(r)"
            },
            "58": {
                "beforePatchRowNumber": 254,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "59": {
                "beforePatchRowNumber": 255,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return re.compile(r, flags=re.IGNORECASE)"
            },
            "60": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    else:"
            },
            "61": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        r = \"^\" + re.escape(glob) + \"$\""
            },
            "62": {
                "beforePatchRowNumber": 258,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return re.compile(r, flags=re.IGNORECASE)"
            },
            "63": {
                "beforePatchRowNumber": 259,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "64": {
                "beforePatchRowNumber": 260,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "65": {
                "beforePatchRowNumber": 261,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def _re_word_boundary(r: str) -> str:"
            },
            "66": {
                "beforePatchRowNumber": 262,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "67": {
                "beforePatchRowNumber": 263,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Adds word boundary characters to the start and end of an"
            },
            "68": {
                "beforePatchRowNumber": 264,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    expression to require that the match occur as a whole word,"
            },
            "69": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    but do so respecting the fact that strings starting or ending"
            },
            "70": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with non-word characters will change word boundaries."
            },
            "71": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "72": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # we can't use \\b as it chokes on unicode. however \\W seems to be okay"
            },
            "73": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # as shorthand for [^0-9A-Za-z_]."
            },
            "74": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return r\"(^|\\W)%s(\\W|$)\" % (r,)"
            },
            "75": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "76": {
                "beforePatchRowNumber": 272,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "77": {
                "beforePatchRowNumber": 273,
                "afterPatchRowNumber": 224,
                "PatchRowcode": " def _flatten_dict("
            },
            "78": {
                "beforePatchRowNumber": 274,
                "afterPatchRowNumber": 225,
                "PatchRowcode": "     d: Union[EventBase, dict],"
            },
            "79": {
                "beforePatchRowNumber": 275,
                "afterPatchRowNumber": 226,
                "PatchRowcode": "     prefix: Optional[List[str]] = None,"
            }
        },
        "frontPatchFile": [
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "# Copyright 2017 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import logging",
            "import re",
            "from typing import Any, Dict, List, Optional, Pattern, Tuple, Union",
            "",
            "from synapse.events import EventBase",
            "from synapse.types import UserID",
            "from synapse.util.caches.lrucache import LruCache",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "GLOB_REGEX = re.compile(r\"\\\\\\[(\\\\\\!|)(.*)\\\\\\]\")",
            "IS_GLOB = re.compile(r\"[\\?\\*\\[\\]]\")",
            "INEQUALITY_EXPR = re.compile(\"^([=<>]*)([0-9]*)$\")",
            "",
            "",
            "def _room_member_count(",
            "    ev: EventBase, condition: Dict[str, Any], room_member_count: int",
            ") -> bool:",
            "    return _test_ineq_condition(condition, room_member_count)",
            "",
            "",
            "def _sender_notification_permission(",
            "    ev: EventBase,",
            "    condition: Dict[str, Any],",
            "    sender_power_level: int,",
            "    power_levels: Dict[str, Union[int, Dict[str, int]]],",
            ") -> bool:",
            "    notif_level_key = condition.get(\"key\")",
            "    if notif_level_key is None:",
            "        return False",
            "",
            "    notif_levels = power_levels.get(\"notifications\", {})",
            "    assert isinstance(notif_levels, dict)",
            "    room_notif_level = notif_levels.get(notif_level_key, 50)",
            "",
            "    return sender_power_level >= room_notif_level",
            "",
            "",
            "def _test_ineq_condition(condition: Dict[str, Any], number: int) -> bool:",
            "    if \"is\" not in condition:",
            "        return False",
            "    m = INEQUALITY_EXPR.match(condition[\"is\"])",
            "    if not m:",
            "        return False",
            "    ineq = m.group(1)",
            "    rhs = m.group(2)",
            "    if not rhs.isdigit():",
            "        return False",
            "    rhs_int = int(rhs)",
            "",
            "    if ineq == \"\" or ineq == \"==\":",
            "        return number == rhs_int",
            "    elif ineq == \"<\":",
            "        return number < rhs_int",
            "    elif ineq == \">\":",
            "        return number > rhs_int",
            "    elif ineq == \">=\":",
            "        return number >= rhs_int",
            "    elif ineq == \"<=\":",
            "        return number <= rhs_int",
            "    else:",
            "        return False",
            "",
            "",
            "def tweaks_for_actions(actions: List[Union[str, Dict]]) -> Dict[str, Any]:",
            "    \"\"\"",
            "    Converts a list of actions into a `tweaks` dict (which can then be passed to",
            "        the push gateway).",
            "",
            "    This function ignores all actions other than `set_tweak` actions, and treats",
            "    absent `value`s as `True`, which agrees with the only spec-defined treatment",
            "    of absent `value`s (namely, for `highlight` tweaks).",
            "",
            "    Args:",
            "        actions: list of actions",
            "            e.g. [",
            "                {\"set_tweak\": \"a\", \"value\": \"AAA\"},",
            "                {\"set_tweak\": \"b\", \"value\": \"BBB\"},",
            "                {\"set_tweak\": \"highlight\"},",
            "                \"notify\"",
            "            ]",
            "",
            "    Returns:",
            "        dictionary of tweaks for those actions",
            "            e.g. {\"a\": \"AAA\", \"b\": \"BBB\", \"highlight\": True}",
            "    \"\"\"",
            "    tweaks = {}",
            "    for a in actions:",
            "        if not isinstance(a, dict):",
            "            continue",
            "        if \"set_tweak\" in a:",
            "            # value is allowed to be absent in which case the value assumed",
            "            # should be True.",
            "            tweaks[a[\"set_tweak\"]] = a.get(\"value\", True)",
            "    return tweaks",
            "",
            "",
            "class PushRuleEvaluatorForEvent:",
            "    def __init__(",
            "        self,",
            "        event: EventBase,",
            "        room_member_count: int,",
            "        sender_power_level: int,",
            "        power_levels: Dict[str, Union[int, Dict[str, int]]],",
            "    ):",
            "        self._event = event",
            "        self._room_member_count = room_member_count",
            "        self._sender_power_level = sender_power_level",
            "        self._power_levels = power_levels",
            "",
            "        # Maps strings of e.g. 'content.body' -> event[\"content\"][\"body\"]",
            "        self._value_cache = _flatten_dict(event)",
            "",
            "    def matches(",
            "        self, condition: Dict[str, Any], user_id: str, display_name: str",
            "    ) -> bool:",
            "        if condition[\"kind\"] == \"event_match\":",
            "            return self._event_match(condition, user_id)",
            "        elif condition[\"kind\"] == \"contains_display_name\":",
            "            return self._contains_display_name(display_name)",
            "        elif condition[\"kind\"] == \"room_member_count\":",
            "            return _room_member_count(self._event, condition, self._room_member_count)",
            "        elif condition[\"kind\"] == \"sender_notification_permission\":",
            "            return _sender_notification_permission(",
            "                self._event, condition, self._sender_power_level, self._power_levels",
            "            )",
            "        else:",
            "            return True",
            "",
            "    def _event_match(self, condition: dict, user_id: str) -> bool:",
            "        pattern = condition.get(\"pattern\", None)",
            "",
            "        if not pattern:",
            "            pattern_type = condition.get(\"pattern_type\", None)",
            "            if pattern_type == \"user_id\":",
            "                pattern = user_id",
            "            elif pattern_type == \"user_localpart\":",
            "                pattern = UserID.from_string(user_id).localpart",
            "",
            "        if not pattern:",
            "            logger.warning(\"event_match condition with no pattern\")",
            "            return False",
            "",
            "        # XXX: optimisation: cache our pattern regexps",
            "        if condition[\"key\"] == \"content.body\":",
            "            body = self._event.content.get(\"body\", None)",
            "            if not body or not isinstance(body, str):",
            "                return False",
            "",
            "            return _glob_matches(pattern, body, word_boundary=True)",
            "        else:",
            "            haystack = self._get_value(condition[\"key\"])",
            "            if haystack is None:",
            "                return False",
            "",
            "            return _glob_matches(pattern, haystack)",
            "",
            "    def _contains_display_name(self, display_name: str) -> bool:",
            "        if not display_name:",
            "            return False",
            "",
            "        body = self._event.content.get(\"body\", None)",
            "        if not body or not isinstance(body, str):",
            "            return False",
            "",
            "        # Similar to _glob_matches, but do not treat display_name as a glob.",
            "        r = regex_cache.get((display_name, False, True), None)",
            "        if not r:",
            "            r1 = re.escape(display_name)",
            "            r1 = _re_word_boundary(r1)",
            "            r = re.compile(r1, flags=re.IGNORECASE)",
            "            regex_cache[(display_name, False, True)] = r",
            "",
            "        return bool(r.search(body))",
            "",
            "    def _get_value(self, dotted_key: str) -> Optional[str]:",
            "        return self._value_cache.get(dotted_key, None)",
            "",
            "",
            "# Caches (string, is_glob, word_boundary) -> regex for push. See _glob_matches",
            "regex_cache = LruCache(",
            "    50000, \"regex_push_cache\"",
            ")  # type: LruCache[Tuple[str, bool, bool], Pattern]",
            "",
            "",
            "def _glob_matches(glob: str, value: str, word_boundary: bool = False) -> bool:",
            "    \"\"\"Tests if value matches glob.",
            "",
            "    Args:",
            "        glob",
            "        value: String to test against glob.",
            "        word_boundary: Whether to match against word boundaries or entire",
            "            string. Defaults to False.",
            "    \"\"\"",
            "",
            "    try:",
            "        r = regex_cache.get((glob, True, word_boundary), None)",
            "        if not r:",
            "            r = _glob_to_re(glob, word_boundary)",
            "            regex_cache[(glob, True, word_boundary)] = r",
            "        return bool(r.search(value))",
            "    except re.error:",
            "        logger.warning(\"Failed to parse glob to regex: %r\", glob)",
            "        return False",
            "",
            "",
            "def _glob_to_re(glob: str, word_boundary: bool) -> Pattern:",
            "    \"\"\"Generates regex for a given glob.",
            "",
            "    Args:",
            "        glob",
            "        word_boundary: Whether to match against word boundaries or entire string.",
            "    \"\"\"",
            "    if IS_GLOB.search(glob):",
            "        r = re.escape(glob)",
            "",
            "        r = r.replace(r\"\\*\", \".*?\")",
            "        r = r.replace(r\"\\?\", \".\")",
            "",
            "        # handle [abc], [a-z] and [!a-z] style ranges.",
            "        r = GLOB_REGEX.sub(",
            "            lambda x: (",
            "                \"[%s%s]\" % (x.group(1) and \"^\" or \"\", x.group(2).replace(r\"\\\\\\-\", \"-\"))",
            "            ),",
            "            r,",
            "        )",
            "        if word_boundary:",
            "            r = _re_word_boundary(r)",
            "",
            "            return re.compile(r, flags=re.IGNORECASE)",
            "        else:",
            "            r = \"^\" + r + \"$\"",
            "",
            "            return re.compile(r, flags=re.IGNORECASE)",
            "    elif word_boundary:",
            "        r = re.escape(glob)",
            "        r = _re_word_boundary(r)",
            "",
            "        return re.compile(r, flags=re.IGNORECASE)",
            "    else:",
            "        r = \"^\" + re.escape(glob) + \"$\"",
            "        return re.compile(r, flags=re.IGNORECASE)",
            "",
            "",
            "def _re_word_boundary(r: str) -> str:",
            "    \"\"\"",
            "    Adds word boundary characters to the start and end of an",
            "    expression to require that the match occur as a whole word,",
            "    but do so respecting the fact that strings starting or ending",
            "    with non-word characters will change word boundaries.",
            "    \"\"\"",
            "    # we can't use \\b as it chokes on unicode. however \\W seems to be okay",
            "    # as shorthand for [^0-9A-Za-z_].",
            "    return r\"(^|\\W)%s(\\W|$)\" % (r,)",
            "",
            "",
            "def _flatten_dict(",
            "    d: Union[EventBase, dict],",
            "    prefix: Optional[List[str]] = None,",
            "    result: Optional[Dict[str, str]] = None,",
            ") -> Dict[str, str]:",
            "    if prefix is None:",
            "        prefix = []",
            "    if result is None:",
            "        result = {}",
            "    for key, value in d.items():",
            "        if isinstance(value, str):",
            "            result[\".\".join(prefix + [key])] = value.lower()",
            "        elif hasattr(value, \"items\"):",
            "            _flatten_dict(value, prefix=(prefix + [key]), result=result)",
            "",
            "    return result"
        ],
        "afterPatchFile": [
            "# Copyright 2015, 2016 OpenMarket Ltd",
            "# Copyright 2017 New Vector Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import logging",
            "import re",
            "from typing import Any, Dict, List, Optional, Pattern, Tuple, Union",
            "",
            "from synapse.events import EventBase",
            "from synapse.types import UserID",
            "from synapse.util import glob_to_regex, re_word_boundary",
            "from synapse.util.caches.lrucache import LruCache",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "GLOB_REGEX = re.compile(r\"\\\\\\[(\\\\\\!|)(.*)\\\\\\]\")",
            "IS_GLOB = re.compile(r\"[\\?\\*\\[\\]]\")",
            "INEQUALITY_EXPR = re.compile(\"^([=<>]*)([0-9]*)$\")",
            "",
            "",
            "def _room_member_count(",
            "    ev: EventBase, condition: Dict[str, Any], room_member_count: int",
            ") -> bool:",
            "    return _test_ineq_condition(condition, room_member_count)",
            "",
            "",
            "def _sender_notification_permission(",
            "    ev: EventBase,",
            "    condition: Dict[str, Any],",
            "    sender_power_level: int,",
            "    power_levels: Dict[str, Union[int, Dict[str, int]]],",
            ") -> bool:",
            "    notif_level_key = condition.get(\"key\")",
            "    if notif_level_key is None:",
            "        return False",
            "",
            "    notif_levels = power_levels.get(\"notifications\", {})",
            "    assert isinstance(notif_levels, dict)",
            "    room_notif_level = notif_levels.get(notif_level_key, 50)",
            "",
            "    return sender_power_level >= room_notif_level",
            "",
            "",
            "def _test_ineq_condition(condition: Dict[str, Any], number: int) -> bool:",
            "    if \"is\" not in condition:",
            "        return False",
            "    m = INEQUALITY_EXPR.match(condition[\"is\"])",
            "    if not m:",
            "        return False",
            "    ineq = m.group(1)",
            "    rhs = m.group(2)",
            "    if not rhs.isdigit():",
            "        return False",
            "    rhs_int = int(rhs)",
            "",
            "    if ineq == \"\" or ineq == \"==\":",
            "        return number == rhs_int",
            "    elif ineq == \"<\":",
            "        return number < rhs_int",
            "    elif ineq == \">\":",
            "        return number > rhs_int",
            "    elif ineq == \">=\":",
            "        return number >= rhs_int",
            "    elif ineq == \"<=\":",
            "        return number <= rhs_int",
            "    else:",
            "        return False",
            "",
            "",
            "def tweaks_for_actions(actions: List[Union[str, Dict]]) -> Dict[str, Any]:",
            "    \"\"\"",
            "    Converts a list of actions into a `tweaks` dict (which can then be passed to",
            "        the push gateway).",
            "",
            "    This function ignores all actions other than `set_tweak` actions, and treats",
            "    absent `value`s as `True`, which agrees with the only spec-defined treatment",
            "    of absent `value`s (namely, for `highlight` tweaks).",
            "",
            "    Args:",
            "        actions: list of actions",
            "            e.g. [",
            "                {\"set_tweak\": \"a\", \"value\": \"AAA\"},",
            "                {\"set_tweak\": \"b\", \"value\": \"BBB\"},",
            "                {\"set_tweak\": \"highlight\"},",
            "                \"notify\"",
            "            ]",
            "",
            "    Returns:",
            "        dictionary of tweaks for those actions",
            "            e.g. {\"a\": \"AAA\", \"b\": \"BBB\", \"highlight\": True}",
            "    \"\"\"",
            "    tweaks = {}",
            "    for a in actions:",
            "        if not isinstance(a, dict):",
            "            continue",
            "        if \"set_tweak\" in a:",
            "            # value is allowed to be absent in which case the value assumed",
            "            # should be True.",
            "            tweaks[a[\"set_tweak\"]] = a.get(\"value\", True)",
            "    return tweaks",
            "",
            "",
            "class PushRuleEvaluatorForEvent:",
            "    def __init__(",
            "        self,",
            "        event: EventBase,",
            "        room_member_count: int,",
            "        sender_power_level: int,",
            "        power_levels: Dict[str, Union[int, Dict[str, int]]],",
            "    ):",
            "        self._event = event",
            "        self._room_member_count = room_member_count",
            "        self._sender_power_level = sender_power_level",
            "        self._power_levels = power_levels",
            "",
            "        # Maps strings of e.g. 'content.body' -> event[\"content\"][\"body\"]",
            "        self._value_cache = _flatten_dict(event)",
            "",
            "    def matches(",
            "        self, condition: Dict[str, Any], user_id: str, display_name: str",
            "    ) -> bool:",
            "        if condition[\"kind\"] == \"event_match\":",
            "            return self._event_match(condition, user_id)",
            "        elif condition[\"kind\"] == \"contains_display_name\":",
            "            return self._contains_display_name(display_name)",
            "        elif condition[\"kind\"] == \"room_member_count\":",
            "            return _room_member_count(self._event, condition, self._room_member_count)",
            "        elif condition[\"kind\"] == \"sender_notification_permission\":",
            "            return _sender_notification_permission(",
            "                self._event, condition, self._sender_power_level, self._power_levels",
            "            )",
            "        else:",
            "            return True",
            "",
            "    def _event_match(self, condition: dict, user_id: str) -> bool:",
            "        pattern = condition.get(\"pattern\", None)",
            "",
            "        if not pattern:",
            "            pattern_type = condition.get(\"pattern_type\", None)",
            "            if pattern_type == \"user_id\":",
            "                pattern = user_id",
            "            elif pattern_type == \"user_localpart\":",
            "                pattern = UserID.from_string(user_id).localpart",
            "",
            "        if not pattern:",
            "            logger.warning(\"event_match condition with no pattern\")",
            "            return False",
            "",
            "        # XXX: optimisation: cache our pattern regexps",
            "        if condition[\"key\"] == \"content.body\":",
            "            body = self._event.content.get(\"body\", None)",
            "            if not body or not isinstance(body, str):",
            "                return False",
            "",
            "            return _glob_matches(pattern, body, word_boundary=True)",
            "        else:",
            "            haystack = self._get_value(condition[\"key\"])",
            "            if haystack is None:",
            "                return False",
            "",
            "            return _glob_matches(pattern, haystack)",
            "",
            "    def _contains_display_name(self, display_name: str) -> bool:",
            "        if not display_name:",
            "            return False",
            "",
            "        body = self._event.content.get(\"body\", None)",
            "        if not body or not isinstance(body, str):",
            "            return False",
            "",
            "        # Similar to _glob_matches, but do not treat display_name as a glob.",
            "        r = regex_cache.get((display_name, False, True), None)",
            "        if not r:",
            "            r1 = re.escape(display_name)",
            "            r1 = re_word_boundary(r1)",
            "            r = re.compile(r1, flags=re.IGNORECASE)",
            "            regex_cache[(display_name, False, True)] = r",
            "",
            "        return bool(r.search(body))",
            "",
            "    def _get_value(self, dotted_key: str) -> Optional[str]:",
            "        return self._value_cache.get(dotted_key, None)",
            "",
            "",
            "# Caches (string, is_glob, word_boundary) -> regex for push. See _glob_matches",
            "regex_cache = LruCache(",
            "    50000, \"regex_push_cache\"",
            ")  # type: LruCache[Tuple[str, bool, bool], Pattern]",
            "",
            "",
            "def _glob_matches(glob: str, value: str, word_boundary: bool = False) -> bool:",
            "    \"\"\"Tests if value matches glob.",
            "",
            "    Args:",
            "        glob",
            "        value: String to test against glob.",
            "        word_boundary: Whether to match against word boundaries or entire",
            "            string. Defaults to False.",
            "    \"\"\"",
            "",
            "    try:",
            "        r = regex_cache.get((glob, True, word_boundary), None)",
            "        if not r:",
            "            r = glob_to_regex(glob, word_boundary)",
            "            regex_cache[(glob, True, word_boundary)] = r",
            "        return bool(r.search(value))",
            "    except re.error:",
            "        logger.warning(\"Failed to parse glob to regex: %r\", glob)",
            "        return False",
            "",
            "",
            "def _flatten_dict(",
            "    d: Union[EventBase, dict],",
            "    prefix: Optional[List[str]] = None,",
            "    result: Optional[Dict[str, str]] = None,",
            ") -> Dict[str, str]:",
            "    if prefix is None:",
            "        prefix = []",
            "    if result is None:",
            "        result = {}",
            "    for key, value in d.items():",
            "        if isinstance(value, str):",
            "            result[\".\".join(prefix + [key])] = value.lower()",
            "        elif hasattr(value, \"items\"):",
            "            _flatten_dict(value, prefix=(prefix + [key]), result=result)",
            "",
            "    return result"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "186": [
                "PushRuleEvaluatorForEvent",
                "_contains_display_name"
            ],
            "215": [
                "_glob_matches"
            ],
            "223": [
                "_glob_to_re"
            ],
            "224": [
                "_glob_to_re"
            ],
            "225": [
                "_glob_to_re"
            ],
            "226": [
                "_glob_to_re"
            ],
            "227": [
                "_glob_to_re"
            ],
            "228": [
                "_glob_to_re"
            ],
            "229": [
                "_glob_to_re"
            ],
            "230": [
                "_glob_to_re"
            ],
            "231": [
                "_glob_to_re"
            ],
            "232": [
                "_glob_to_re"
            ],
            "233": [
                "_glob_to_re"
            ],
            "234": [
                "_glob_to_re"
            ],
            "235": [
                "_glob_to_re"
            ],
            "236": [
                "_glob_to_re"
            ],
            "237": [
                "_glob_to_re"
            ],
            "238": [
                "_glob_to_re"
            ],
            "239": [
                "_glob_to_re"
            ],
            "240": [
                "_glob_to_re"
            ],
            "241": [
                "_glob_to_re"
            ],
            "242": [
                "_glob_to_re"
            ],
            "243": [
                "_glob_to_re"
            ],
            "244": [
                "_glob_to_re"
            ],
            "245": [
                "_glob_to_re"
            ],
            "246": [
                "_glob_to_re"
            ],
            "247": [
                "_glob_to_re"
            ],
            "248": [
                "_glob_to_re"
            ],
            "249": [
                "_glob_to_re"
            ],
            "250": [
                "_glob_to_re"
            ],
            "251": [
                "_glob_to_re"
            ],
            "252": [
                "_glob_to_re"
            ],
            "253": [
                "_glob_to_re"
            ],
            "254": [
                "_glob_to_re"
            ],
            "255": [
                "_glob_to_re"
            ],
            "256": [
                "_glob_to_re"
            ],
            "257": [
                "_glob_to_re"
            ],
            "258": [
                "_glob_to_re"
            ],
            "259": [],
            "260": [],
            "261": [
                "_re_word_boundary"
            ],
            "262": [
                "_re_word_boundary"
            ],
            "263": [
                "_re_word_boundary"
            ],
            "264": [
                "_re_word_boundary"
            ],
            "265": [
                "_re_word_boundary"
            ],
            "266": [
                "_re_word_boundary"
            ],
            "267": [
                "_re_word_boundary"
            ],
            "268": [
                "_re_word_boundary"
            ],
            "269": [
                "_re_word_boundary"
            ],
            "270": [
                "_re_word_boundary"
            ],
            "271": [],
            "272": []
        },
        "addLocation": []
    },
    "synapse/util/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " import json"
            },
            "1": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " import logging"
            },
            "2": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import re"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+from typing import Pattern"
            },
            "4": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " import attr"
            },
            "6": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from frozendict import frozendict"
            },
            "7": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " logger = logging.getLogger(__name__)"
            },
            "8": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+_WILDCARD_RUN = re.compile(r\"([\\?\\*]+)\")"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+"
            },
            "13": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " def _reject_invalid_json(val):"
            },
            "14": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 34,
                "PatchRowcode": "     \"\"\"Do not allow Infinity, -Infinity, or NaN values in JSON.\"\"\""
            },
            "15": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "     raise ValueError(\"Invalid JSON value: '%s'\" % val)"
            },
            "16": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 162,
                "PatchRowcode": "         return failure"
            },
            "17": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 163,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": 164,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def glob_to_regex(glob):"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 165,
                "PatchRowcode": "+def glob_to_regex(glob: str, word_boundary: bool = False) -> Pattern:"
            },
            "21": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 166,
                "PatchRowcode": "     \"\"\"Converts a glob to a compiled regex object."
            },
            "22": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 167,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    The regex is anchored at the beginning and end of the string."
            },
            "24": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "25": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "     Args:"
            },
            "26": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        glob (str)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+        glob: pattern to match"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+        word_boundary: If True, the pattern will be allowed to match at word boundaries"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+           anywhere in the string. Otherwise, the pattern is anchored at the start and"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+           end of the string."
            },
            "31": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 173,
                "PatchRowcode": " "
            },
            "32": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "     Returns:"
            },
            "33": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        re.RegexObject"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+        compiled regex pattern"
            },
            "35": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "     \"\"\""
            },
            "36": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    res = \"\""
            },
            "37": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    for c in glob:"
            },
            "38": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if c == \"*\":"
            },
            "39": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            res = res + \".*\""
            },
            "40": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        elif c == \"?\":"
            },
            "41": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            res = res + \".\""
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 177,
                "PatchRowcode": "+"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 178,
                "PatchRowcode": "+    # Patterns with wildcards must be simplified to avoid performance cliffs"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 179,
                "PatchRowcode": "+    # - The glob `?**?**?` is equivalent to the glob `???*`"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+    # - The glob `???*` is equivalent to the regex `.{3,}`"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+    chunks = []"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+    for chunk in _WILDCARD_RUN.split(glob):"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+        # No wildcards? re.escape()"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+        if not _WILDCARD_RUN.match(chunk):"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+            chunks.append(re.escape(chunk))"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 186,
                "PatchRowcode": "+            continue"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 187,
                "PatchRowcode": "+"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 188,
                "PatchRowcode": "+        # Wildcards? Simplify."
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+        qmarks = chunk.count(\"?\")"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 190,
                "PatchRowcode": "+        if \"*\" in chunk:"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 191,
                "PatchRowcode": "+            chunks.append(\".{%d,}\" % qmarks)"
            },
            "57": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "         else:"
            },
            "58": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            res = res + re.escape(c)"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 193,
                "PatchRowcode": "+            chunks.append(\".{%d}\" % qmarks)"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+    res = \"\".join(chunks)"
            },
            "62": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 196,
                "PatchRowcode": " "
            },
            "63": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # \\A anchors at start of string, \\Z at end of string"
            },
            "64": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return re.compile(r\"\\A\" + res + r\"\\Z\", re.IGNORECASE)"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 197,
                "PatchRowcode": "+    if word_boundary:"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 198,
                "PatchRowcode": "+        res = re_word_boundary(res)"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 199,
                "PatchRowcode": "+    else:"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 200,
                "PatchRowcode": "+        # \\A anchors at start of string, \\Z at end of string"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 201,
                "PatchRowcode": "+        res = r\"\\A\" + res + r\"\\Z\""
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 202,
                "PatchRowcode": "+"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 203,
                "PatchRowcode": "+    return re.compile(res, re.IGNORECASE)"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 204,
                "PatchRowcode": "+"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 205,
                "PatchRowcode": "+"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 206,
                "PatchRowcode": "+def re_word_boundary(r: str) -> str:"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+    \"\"\""
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 208,
                "PatchRowcode": "+    Adds word boundary characters to the start and end of an"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+    expression to require that the match occur as a whole word,"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+    but do so respecting the fact that strings starting or ending"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+    with non-word characters will change word boundaries."
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+    \"\"\""
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+    # we can't use \\b as it chokes on unicode. however \\W seems to be okay"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+    # as shorthand for [^0-9A-Za-z_]."
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 215,
                "PatchRowcode": "+    return r\"(^|\\W)%s(\\W|$)\" % (r,)"
            }
        },
        "frontPatchFile": [
            "# Copyright 2014-2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import json",
            "import logging",
            "import re",
            "",
            "import attr",
            "from frozendict import frozendict",
            "",
            "from twisted.internet import defer, task",
            "",
            "from synapse.logging import context",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def _reject_invalid_json(val):",
            "    \"\"\"Do not allow Infinity, -Infinity, or NaN values in JSON.\"\"\"",
            "    raise ValueError(\"Invalid JSON value: '%s'\" % val)",
            "",
            "",
            "def _handle_frozendict(obj):",
            "    \"\"\"Helper for json_encoder. Makes frozendicts serializable by returning",
            "    the underlying dict",
            "    \"\"\"",
            "    if type(obj) is frozendict:",
            "        # fishing the protected dict out of the object is a bit nasty,",
            "        # but we don't really want the overhead of copying the dict.",
            "        return obj._dict",
            "    raise TypeError(",
            "        \"Object of type %s is not JSON serializable\" % obj.__class__.__name__",
            "    )",
            "",
            "",
            "# A custom JSON encoder which:",
            "#   * handles frozendicts",
            "#   * produces valid JSON (no NaNs etc)",
            "#   * reduces redundant whitespace",
            "json_encoder = json.JSONEncoder(",
            "    allow_nan=False, separators=(\",\", \":\"), default=_handle_frozendict",
            ")",
            "",
            "# Create a custom decoder to reject Python extensions to JSON.",
            "json_decoder = json.JSONDecoder(parse_constant=_reject_invalid_json)",
            "",
            "",
            "def unwrapFirstError(failure):",
            "    # defer.gatherResults and DeferredLists wrap failures.",
            "    failure.trap(defer.FirstError)",
            "    return failure.value.subFailure",
            "",
            "",
            "@attr.s(slots=True)",
            "class Clock:",
            "    \"\"\"",
            "    A Clock wraps a Twisted reactor and provides utilities on top of it.",
            "",
            "    Args:",
            "        reactor: The Twisted reactor to use.",
            "    \"\"\"",
            "",
            "    _reactor = attr.ib()",
            "",
            "    @defer.inlineCallbacks",
            "    def sleep(self, seconds):",
            "        d = defer.Deferred()",
            "        with context.PreserveLoggingContext():",
            "            self._reactor.callLater(seconds, d.callback, seconds)",
            "            res = yield d",
            "        return res",
            "",
            "    def time(self):",
            "        \"\"\"Returns the current system time in seconds since epoch.\"\"\"",
            "        return self._reactor.seconds()",
            "",
            "    def time_msec(self):",
            "        \"\"\"Returns the current system time in milliseconds since epoch.\"\"\"",
            "        return int(self.time() * 1000)",
            "",
            "    def looping_call(self, f, msec, *args, **kwargs):",
            "        \"\"\"Call a function repeatedly.",
            "",
            "        Waits `msec` initially before calling `f` for the first time.",
            "",
            "        Note that the function will be called with no logcontext, so if it is anything",
            "        other than trivial, you probably want to wrap it in run_as_background_process.",
            "",
            "        Args:",
            "            f(function): The function to call repeatedly.",
            "            msec(float): How long to wait between calls in milliseconds.",
            "            *args: Postional arguments to pass to function.",
            "            **kwargs: Key arguments to pass to function.",
            "        \"\"\"",
            "        call = task.LoopingCall(f, *args, **kwargs)",
            "        call.clock = self._reactor",
            "        d = call.start(msec / 1000.0, now=False)",
            "        d.addErrback(log_failure, \"Looping call died\", consumeErrors=False)",
            "        return call",
            "",
            "    def call_later(self, delay, callback, *args, **kwargs):",
            "        \"\"\"Call something later",
            "",
            "        Note that the function will be called with no logcontext, so if it is anything",
            "        other than trivial, you probably want to wrap it in run_as_background_process.",
            "",
            "        Args:",
            "            delay(float): How long to wait in seconds.",
            "            callback(function): Function to call",
            "            *args: Postional arguments to pass to function.",
            "            **kwargs: Key arguments to pass to function.",
            "        \"\"\"",
            "",
            "        def wrapped_callback(*args, **kwargs):",
            "            with context.PreserveLoggingContext():",
            "                callback(*args, **kwargs)",
            "",
            "        with context.PreserveLoggingContext():",
            "            return self._reactor.callLater(delay, wrapped_callback, *args, **kwargs)",
            "",
            "    def cancel_call_later(self, timer, ignore_errs=False):",
            "        try:",
            "            timer.cancel()",
            "        except Exception:",
            "            if not ignore_errs:",
            "                raise",
            "",
            "",
            "def log_failure(failure, msg, consumeErrors=True):",
            "    \"\"\"Creates a function suitable for passing to `Deferred.addErrback` that",
            "    logs any failures that occur.",
            "",
            "    Args:",
            "        msg (str): Message to log",
            "        consumeErrors (bool): If true consumes the failure, otherwise passes",
            "            on down the callback chain",
            "",
            "    Returns:",
            "        func(Failure)",
            "    \"\"\"",
            "",
            "    logger.error(",
            "        msg, exc_info=(failure.type, failure.value, failure.getTracebackObject())",
            "    )",
            "",
            "    if not consumeErrors:",
            "        return failure",
            "",
            "",
            "def glob_to_regex(glob):",
            "    \"\"\"Converts a glob to a compiled regex object.",
            "",
            "    The regex is anchored at the beginning and end of the string.",
            "",
            "    Args:",
            "        glob (str)",
            "",
            "    Returns:",
            "        re.RegexObject",
            "    \"\"\"",
            "    res = \"\"",
            "    for c in glob:",
            "        if c == \"*\":",
            "            res = res + \".*\"",
            "        elif c == \"?\":",
            "            res = res + \".\"",
            "        else:",
            "            res = res + re.escape(c)",
            "",
            "    # \\A anchors at start of string, \\Z at end of string",
            "    return re.compile(r\"\\A\" + res + r\"\\Z\", re.IGNORECASE)"
        ],
        "afterPatchFile": [
            "# Copyright 2014-2016 OpenMarket Ltd",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#     http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import json",
            "import logging",
            "import re",
            "from typing import Pattern",
            "",
            "import attr",
            "from frozendict import frozendict",
            "",
            "from twisted.internet import defer, task",
            "",
            "from synapse.logging import context",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "_WILDCARD_RUN = re.compile(r\"([\\?\\*]+)\")",
            "",
            "",
            "def _reject_invalid_json(val):",
            "    \"\"\"Do not allow Infinity, -Infinity, or NaN values in JSON.\"\"\"",
            "    raise ValueError(\"Invalid JSON value: '%s'\" % val)",
            "",
            "",
            "def _handle_frozendict(obj):",
            "    \"\"\"Helper for json_encoder. Makes frozendicts serializable by returning",
            "    the underlying dict",
            "    \"\"\"",
            "    if type(obj) is frozendict:",
            "        # fishing the protected dict out of the object is a bit nasty,",
            "        # but we don't really want the overhead of copying the dict.",
            "        return obj._dict",
            "    raise TypeError(",
            "        \"Object of type %s is not JSON serializable\" % obj.__class__.__name__",
            "    )",
            "",
            "",
            "# A custom JSON encoder which:",
            "#   * handles frozendicts",
            "#   * produces valid JSON (no NaNs etc)",
            "#   * reduces redundant whitespace",
            "json_encoder = json.JSONEncoder(",
            "    allow_nan=False, separators=(\",\", \":\"), default=_handle_frozendict",
            ")",
            "",
            "# Create a custom decoder to reject Python extensions to JSON.",
            "json_decoder = json.JSONDecoder(parse_constant=_reject_invalid_json)",
            "",
            "",
            "def unwrapFirstError(failure):",
            "    # defer.gatherResults and DeferredLists wrap failures.",
            "    failure.trap(defer.FirstError)",
            "    return failure.value.subFailure",
            "",
            "",
            "@attr.s(slots=True)",
            "class Clock:",
            "    \"\"\"",
            "    A Clock wraps a Twisted reactor and provides utilities on top of it.",
            "",
            "    Args:",
            "        reactor: The Twisted reactor to use.",
            "    \"\"\"",
            "",
            "    _reactor = attr.ib()",
            "",
            "    @defer.inlineCallbacks",
            "    def sleep(self, seconds):",
            "        d = defer.Deferred()",
            "        with context.PreserveLoggingContext():",
            "            self._reactor.callLater(seconds, d.callback, seconds)",
            "            res = yield d",
            "        return res",
            "",
            "    def time(self):",
            "        \"\"\"Returns the current system time in seconds since epoch.\"\"\"",
            "        return self._reactor.seconds()",
            "",
            "    def time_msec(self):",
            "        \"\"\"Returns the current system time in milliseconds since epoch.\"\"\"",
            "        return int(self.time() * 1000)",
            "",
            "    def looping_call(self, f, msec, *args, **kwargs):",
            "        \"\"\"Call a function repeatedly.",
            "",
            "        Waits `msec` initially before calling `f` for the first time.",
            "",
            "        Note that the function will be called with no logcontext, so if it is anything",
            "        other than trivial, you probably want to wrap it in run_as_background_process.",
            "",
            "        Args:",
            "            f(function): The function to call repeatedly.",
            "            msec(float): How long to wait between calls in milliseconds.",
            "            *args: Postional arguments to pass to function.",
            "            **kwargs: Key arguments to pass to function.",
            "        \"\"\"",
            "        call = task.LoopingCall(f, *args, **kwargs)",
            "        call.clock = self._reactor",
            "        d = call.start(msec / 1000.0, now=False)",
            "        d.addErrback(log_failure, \"Looping call died\", consumeErrors=False)",
            "        return call",
            "",
            "    def call_later(self, delay, callback, *args, **kwargs):",
            "        \"\"\"Call something later",
            "",
            "        Note that the function will be called with no logcontext, so if it is anything",
            "        other than trivial, you probably want to wrap it in run_as_background_process.",
            "",
            "        Args:",
            "            delay(float): How long to wait in seconds.",
            "            callback(function): Function to call",
            "            *args: Postional arguments to pass to function.",
            "            **kwargs: Key arguments to pass to function.",
            "        \"\"\"",
            "",
            "        def wrapped_callback(*args, **kwargs):",
            "            with context.PreserveLoggingContext():",
            "                callback(*args, **kwargs)",
            "",
            "        with context.PreserveLoggingContext():",
            "            return self._reactor.callLater(delay, wrapped_callback, *args, **kwargs)",
            "",
            "    def cancel_call_later(self, timer, ignore_errs=False):",
            "        try:",
            "            timer.cancel()",
            "        except Exception:",
            "            if not ignore_errs:",
            "                raise",
            "",
            "",
            "def log_failure(failure, msg, consumeErrors=True):",
            "    \"\"\"Creates a function suitable for passing to `Deferred.addErrback` that",
            "    logs any failures that occur.",
            "",
            "    Args:",
            "        msg (str): Message to log",
            "        consumeErrors (bool): If true consumes the failure, otherwise passes",
            "            on down the callback chain",
            "",
            "    Returns:",
            "        func(Failure)",
            "    \"\"\"",
            "",
            "    logger.error(",
            "        msg, exc_info=(failure.type, failure.value, failure.getTracebackObject())",
            "    )",
            "",
            "    if not consumeErrors:",
            "        return failure",
            "",
            "",
            "def glob_to_regex(glob: str, word_boundary: bool = False) -> Pattern:",
            "    \"\"\"Converts a glob to a compiled regex object.",
            "",
            "    Args:",
            "        glob: pattern to match",
            "        word_boundary: If True, the pattern will be allowed to match at word boundaries",
            "           anywhere in the string. Otherwise, the pattern is anchored at the start and",
            "           end of the string.",
            "",
            "    Returns:",
            "        compiled regex pattern",
            "    \"\"\"",
            "",
            "    # Patterns with wildcards must be simplified to avoid performance cliffs",
            "    # - The glob `?**?**?` is equivalent to the glob `???*`",
            "    # - The glob `???*` is equivalent to the regex `.{3,}`",
            "    chunks = []",
            "    for chunk in _WILDCARD_RUN.split(glob):",
            "        # No wildcards? re.escape()",
            "        if not _WILDCARD_RUN.match(chunk):",
            "            chunks.append(re.escape(chunk))",
            "            continue",
            "",
            "        # Wildcards? Simplify.",
            "        qmarks = chunk.count(\"?\")",
            "        if \"*\" in chunk:",
            "            chunks.append(\".{%d,}\" % qmarks)",
            "        else:",
            "            chunks.append(\".{%d}\" % qmarks)",
            "",
            "    res = \"\".join(chunks)",
            "",
            "    if word_boundary:",
            "        res = re_word_boundary(res)",
            "    else:",
            "        # \\A anchors at start of string, \\Z at end of string",
            "        res = r\"\\A\" + res + r\"\\Z\"",
            "",
            "    return re.compile(res, re.IGNORECASE)",
            "",
            "",
            "def re_word_boundary(r: str) -> str:",
            "    \"\"\"",
            "    Adds word boundary characters to the start and end of an",
            "    expression to require that the match occur as a whole word,",
            "    but do so respecting the fact that strings starting or ending",
            "    with non-word characters will change word boundaries.",
            "    \"\"\"",
            "    # we can't use \\b as it chokes on unicode. however \\W seems to be okay",
            "    # as shorthand for [^0-9A-Za-z_].",
            "    return r\"(^|\\W)%s(\\W|$)\" % (r,)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "161": [
                "glob_to_regex"
            ],
            "164": [
                "glob_to_regex"
            ],
            "165": [
                "glob_to_regex"
            ],
            "167": [
                "glob_to_regex"
            ],
            "170": [
                "glob_to_regex"
            ],
            "172": [
                "glob_to_regex"
            ],
            "173": [
                "glob_to_regex"
            ],
            "174": [
                "glob_to_regex"
            ],
            "175": [
                "glob_to_regex"
            ],
            "176": [
                "glob_to_regex"
            ],
            "177": [
                "glob_to_regex"
            ],
            "179": [
                "glob_to_regex"
            ],
            "181": [
                "glob_to_regex"
            ],
            "182": [
                "glob_to_regex"
            ]
        },
        "addLocation": []
    }
}