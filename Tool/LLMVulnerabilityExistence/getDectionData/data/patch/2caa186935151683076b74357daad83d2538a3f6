{
    "airflow/auth/managers/fab/security_manager/override.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from functools import cached_property"
            },
            "2": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from flask import g"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+from flask import flash, g"
            },
            "5": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from flask_appbuilder.const import AUTH_DB, AUTH_LDAP, AUTH_OAUTH, AUTH_OID, AUTH_REMOTE_USER"
            },
            "6": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from flask_babel import lazy_gettext"
            },
            "7": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from flask_jwt_extended import JWTManager"
            },
            "8": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from flask_login import LoginManager"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+from itsdangerous import want_bytes"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+from markupsafe import Markup"
            },
            "11": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " from werkzeug.security import generate_password_hash"
            },
            "12": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+from airflow.auth.managers.fab.models import User"
            },
            "14": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " from airflow.auth.managers.fab.models.anonymous_user import AnonymousUser"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+from airflow.www.session import AirflowDatabaseSessionInterface"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+# This is the limit of DB user sessions that we consider as \"healthy\". If you have more sessions that this"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+# number then we will refuse to delete sessions that have expired and old user sessions when resetting"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+# user's password, and raise a warning in the UI instead. Usually when you have that many sessions, it means"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+# that there is something wrong with your deployment - for example you have an automated API call that"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+# continuously creates new sessions. Such setup should be fixed by reusing sessions or by periodically"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+# purging the old sessions by using `airflow db clean` command."
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+MAX_NUM_DATABASE_USER_SESSIONS = 50000"
            },
            "24": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " class FabAirflowSecurityManagerOverride:"
            },
            "27": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 242,
                "PatchRowcode": "         \"\"\""
            },
            "28": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": 243,
                "PatchRowcode": "         user = self.get_user_by_id(userid)"
            },
            "29": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 244,
                "PatchRowcode": "         user.password = generate_password_hash(password)"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 245,
                "PatchRowcode": "+        self.reset_user_sessions(user)"
            },
            "31": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 246,
                "PatchRowcode": "         self.update_user(user)"
            },
            "32": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 247,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+    def reset_user_sessions(self, user: User) -> None:"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+        if isinstance(self.appbuilder.get_app.session_interface, AirflowDatabaseSessionInterface):"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+            interface = self.appbuilder.get_app.session_interface"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+            session = interface.db.session"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 252,
                "PatchRowcode": "+            user_session_model = interface.sql_session_model"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 253,
                "PatchRowcode": "+            num_sessions = session.query(user_session_model).count()"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 254,
                "PatchRowcode": "+            if num_sessions > MAX_NUM_DATABASE_USER_SESSIONS:"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 255,
                "PatchRowcode": "+                flash("
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+                    Markup("
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 257,
                "PatchRowcode": "+                        f\"The old sessions for user {user.username} have <b>NOT</b> been deleted!<br>\""
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+                        f\"You have a lot ({num_sessions}) of user sessions in the 'SESSIONS' table in \""
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+                        f\"your database.<br> \""
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+                        \"This indicates that this deployment might have an automated API calls that create \""
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+                        \"and not reuse sessions.<br>You should consider reusing sessions or cleaning them \""
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+                        \"periodically using db clean.<br>\""
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+                        \"Make sure to reset password for the user again after cleaning the session table \""
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+                        \"to remove old sessions of the user.\""
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 265,
                "PatchRowcode": "+                    ),"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 266,
                "PatchRowcode": "+                    \"warning\","
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 267,
                "PatchRowcode": "+                )"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 268,
                "PatchRowcode": "+            else:"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 269,
                "PatchRowcode": "+                for s in session.query(user_session_model):"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 270,
                "PatchRowcode": "+                    session_details = interface.serializer.loads(want_bytes(s.data))"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 271,
                "PatchRowcode": "+                    if session_details.get(\"_user_id\") == user.id:"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+                        session.delete(s)"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 273,
                "PatchRowcode": "+        else:"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 274,
                "PatchRowcode": "+            flash("
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 275,
                "PatchRowcode": "+                Markup("
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 276,
                "PatchRowcode": "+                    \"Since you are using `securecookie` session backend mechanism, we cannot prevent \""
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 277,
                "PatchRowcode": "+                    f\"some old sessions for user {user.username} to be reused.<br> If you want to make sure \""
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 278,
                "PatchRowcode": "+                    \"that the user is logged out from all sessions, you should consider using \""
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 279,
                "PatchRowcode": "+                    \"`database` session backend mechanism.<br> You can also change the 'secret_key` \""
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 280,
                "PatchRowcode": "+                    \"webserver configuration for all your webserver instances and restart the webserver. \""
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 281,
                "PatchRowcode": "+                    \"This however will logout all users from all sessions.\""
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 282,
                "PatchRowcode": "+                ),"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 283,
                "PatchRowcode": "+                \"warning\","
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 284,
                "PatchRowcode": "+            )"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 285,
                "PatchRowcode": "+"
            },
            "71": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 286,
                "PatchRowcode": "     def load_user(self, user_id):"
            },
            "72": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 287,
                "PatchRowcode": "         \"\"\"Load user by ID.\"\"\""
            },
            "73": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 288,
                "PatchRowcode": "         return self.get_user_by_id(int(user_id))"
            }
        },
        "frontPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from __future__ import annotations",
            "",
            "from functools import cached_property",
            "",
            "from flask import g",
            "from flask_appbuilder.const import AUTH_DB, AUTH_LDAP, AUTH_OAUTH, AUTH_OID, AUTH_REMOTE_USER",
            "from flask_babel import lazy_gettext",
            "from flask_jwt_extended import JWTManager",
            "from flask_login import LoginManager",
            "from werkzeug.security import generate_password_hash",
            "",
            "from airflow.auth.managers.fab.models.anonymous_user import AnonymousUser",
            "",
            "",
            "class FabAirflowSecurityManagerOverride:",
            "    \"\"\"",
            "    This security manager overrides the default AirflowSecurityManager security manager.",
            "",
            "    This security manager is used only if the auth manager FabAuthManager is used. It defines everything in",
            "    the security manager that is needed for the FabAuthManager to work. Any operation specific to",
            "    the AirflowSecurityManager should be defined here instead of AirflowSecurityManager.",
            "",
            "    :param appbuilder: The appbuilder.",
            "    :param actionmodelview: The obj instance for action model view.",
            "    :param authdbview: The class for auth db view.",
            "    :param authldapview: The class for auth ldap view.",
            "    :param authoauthview: The class for auth oauth view.",
            "    :param authoidview: The class for auth oid view.",
            "    :param authremoteuserview: The class for auth remote user view.",
            "    :param permissionmodelview: The class for permission model view.",
            "    :param registeruser_view: The class for register user view.",
            "    :param registeruserdbview: The class for register user db view.",
            "    :param registeruseroauthview: The class for register user oauth view.",
            "    :param registerusermodelview: The class for register user model view.",
            "    :param registeruseroidview: The class for register user oid view.",
            "    :param resetmypasswordview: The class for reset my password view.",
            "    :param resetpasswordview: The class for reset password view.",
            "    :param rolemodelview: The class for role model view.",
            "    :param user_model: The user model.",
            "    :param userinfoeditview: The class for user info edit view.",
            "    :param userdbmodelview: The class for user db model view.",
            "    :param userldapmodelview: The class for user ldap model view.",
            "    :param useroauthmodelview: The class for user oauth model view.",
            "    :param useroidmodelview: The class for user oid model view.",
            "    :param userremoteusermodelview: The class for user remote user model view.",
            "    :param userstatschartview: The class for user stats chart view.",
            "    \"\"\"",
            "",
            "    \"\"\" The obj instance for authentication view \"\"\"",
            "    auth_view = None",
            "    \"\"\" The obj instance for user view \"\"\"",
            "    user_view = None",
            "",
            "    def __init__(self, **kwargs):",
            "        super().__init__(**kwargs)",
            "",
            "        self.appbuilder = kwargs[\"appbuilder\"]",
            "        self.actionmodelview = kwargs[\"actionmodelview\"]",
            "        self.authdbview = kwargs[\"authdbview\"]",
            "        self.authldapview = kwargs[\"authldapview\"]",
            "        self.authoauthview = kwargs[\"authoauthview\"]",
            "        self.authoidview = kwargs[\"authoidview\"]",
            "        self.authremoteuserview = kwargs[\"authremoteuserview\"]",
            "        self.permissionmodelview = kwargs[\"permissionmodelview\"]",
            "        self.registeruser_view = kwargs[\"registeruser_view\"]",
            "        self.registeruserdbview = kwargs[\"registeruserdbview\"]",
            "        self.registeruseroauthview = kwargs[\"registeruseroauthview\"]",
            "        self.registerusermodelview = kwargs[\"registerusermodelview\"]",
            "        self.registeruseroidview = kwargs[\"registeruseroidview\"]",
            "        self.resetmypasswordview = kwargs[\"resetmypasswordview\"]",
            "        self.resetpasswordview = kwargs[\"resetpasswordview\"]",
            "        self.rolemodelview = kwargs[\"rolemodelview\"]",
            "        self.user_model = kwargs[\"user_model\"]",
            "        self.userinfoeditview = kwargs[\"userinfoeditview\"]",
            "        self.userdbmodelview = kwargs[\"userdbmodelview\"]",
            "        self.userldapmodelview = kwargs[\"userldapmodelview\"]",
            "        self.useroauthmodelview = kwargs[\"useroauthmodelview\"]",
            "        self.useroidmodelview = kwargs[\"useroidmodelview\"]",
            "        self.userremoteusermodelview = kwargs[\"userremoteusermodelview\"]",
            "        self.userstatschartview = kwargs[\"userstatschartview\"]",
            "",
            "        # Setup Flask login",
            "        self.lm = self.create_login_manager()",
            "",
            "        # Setup Flask-Jwt-Extended",
            "        self.create_jwt_manager()",
            "",
            "    def register_views(self):",
            "        \"\"\"Register FAB auth manager related views.\"\"\"",
            "        if not self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_VIEWS\", True):",
            "            return",
            "",
            "        if self.auth_user_registration:",
            "            if self.auth_type == AUTH_DB:",
            "                self.registeruser_view = self.registeruserdbview()",
            "            elif self.auth_type == AUTH_OID:",
            "                self.registeruser_view = self.registeruseroidview()",
            "            elif self.auth_type == AUTH_OAUTH:",
            "                self.registeruser_view = self.registeruseroauthview()",
            "            if self.registeruser_view:",
            "                self.appbuilder.add_view_no_menu(self.registeruser_view)",
            "",
            "        self.appbuilder.add_view_no_menu(self.resetpasswordview())",
            "        self.appbuilder.add_view_no_menu(self.resetmypasswordview())",
            "        self.appbuilder.add_view_no_menu(self.userinfoeditview())",
            "",
            "        if self.auth_type == AUTH_DB:",
            "            self.user_view = self.userdbmodelview",
            "            self.auth_view = self.authdbview()",
            "        elif self.auth_type == AUTH_LDAP:",
            "            self.user_view = self.userldapmodelview",
            "            self.auth_view = self.authldapview()",
            "        elif self.auth_type == AUTH_OAUTH:",
            "            self.user_view = self.useroauthmodelview",
            "            self.auth_view = self.authoauthview()",
            "        elif self.auth_type == AUTH_REMOTE_USER:",
            "            self.user_view = self.userremoteusermodelview",
            "            self.auth_view = self.authremoteuserview()",
            "        else:",
            "            self.user_view = self.useroidmodelview",
            "            self.auth_view = self.authoidview()",
            "",
            "        self.appbuilder.add_view_no_menu(self.auth_view)",
            "",
            "        # this needs to be done after the view is added, otherwise the blueprint",
            "        # is not initialized",
            "        if self.is_auth_limited:",
            "            self.limiter.limit(self.auth_rate_limit, methods=[\"POST\"])(self.auth_view.blueprint)",
            "",
            "        self.user_view = self.appbuilder.add_view(",
            "            self.user_view,",
            "            \"List Users\",",
            "            icon=\"fa-user\",",
            "            label=lazy_gettext(\"List Users\"),",
            "            category=\"Security\",",
            "            category_icon=\"fa-cogs\",",
            "            category_label=lazy_gettext(\"Security\"),",
            "        )",
            "",
            "        role_view = self.appbuilder.add_view(",
            "            self.rolemodelview,",
            "            \"List Roles\",",
            "            icon=\"fa-group\",",
            "            label=lazy_gettext(\"List Roles\"),",
            "            category=\"Security\",",
            "            category_icon=\"fa-cogs\",",
            "        )",
            "        role_view.related_views = [self.user_view.__class__]",
            "",
            "        if self.userstatschartview:",
            "            self.appbuilder.add_view(",
            "                self.userstatschartview,",
            "                \"User's Statistics\",",
            "                icon=\"fa-bar-chart-o\",",
            "                label=lazy_gettext(\"User's Statistics\"),",
            "                category=\"Security\",",
            "            )",
            "        if self.auth_user_registration:",
            "            self.appbuilder.add_view(",
            "                self.registerusermodelview,",
            "                \"User's Statistics\",",
            "                icon=\"fa-user-plus\",",
            "                label=lazy_gettext(\"User Registrations\"),",
            "                category=\"Security\",",
            "            )",
            "        self.appbuilder.menu.add_separator(\"Security\")",
            "        if self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_PERMISSION_VIEW\", True):",
            "            self.appbuilder.add_view(",
            "                self.actionmodelview,",
            "                \"Actions\",",
            "                icon=\"fa-lock\",",
            "                label=lazy_gettext(\"Actions\"),",
            "                category=\"Security\",",
            "            )",
            "        if self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_VIEW_MENU_VIEW\", True):",
            "            self.appbuilder.add_view(",
            "                self.resourcemodelview,",
            "                \"Resources\",",
            "                icon=\"fa-list-alt\",",
            "                label=lazy_gettext(\"Resources\"),",
            "                category=\"Security\",",
            "            )",
            "        if self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_PERMISSION_VIEWS_VIEW\", True):",
            "            self.appbuilder.add_view(",
            "                self.permissionmodelview,",
            "                \"Permission Pairs\",",
            "                icon=\"fa-link\",",
            "                label=lazy_gettext(\"Permissions\"),",
            "                category=\"Security\",",
            "            )",
            "",
            "    def create_login_manager(self) -> LoginManager:",
            "        \"\"\"Create the login manager.\"\"\"",
            "        lm = LoginManager(self.appbuilder.app)",
            "        lm.anonymous_user = AnonymousUser",
            "        lm.login_view = \"login\"",
            "        lm.user_loader(self.load_user)",
            "        return lm",
            "",
            "    def create_jwt_manager(self):",
            "        \"\"\"Create the JWT manager.\"\"\"",
            "        jwt_manager = JWTManager()",
            "        jwt_manager.init_app(self.appbuilder.app)",
            "        jwt_manager.user_lookup_loader(self.load_user_jwt)",
            "",
            "    def reset_password(self, userid, password):",
            "        \"\"\"",
            "        Change/Reset a user's password for authdb.",
            "",
            "        Password will be hashed and saved.",
            "        :param userid: the user id to reset the password",
            "        :param password: the clear text password to reset and save hashed on the db",
            "        \"\"\"",
            "        user = self.get_user_by_id(userid)",
            "        user.password = generate_password_hash(password)",
            "        self.update_user(user)",
            "",
            "    def load_user(self, user_id):",
            "        \"\"\"Load user by ID.\"\"\"",
            "        return self.get_user_by_id(int(user_id))",
            "",
            "    def load_user_jwt(self, _jwt_header, jwt_data):",
            "        identity = jwt_data[\"sub\"]",
            "        user = self.load_user(identity)",
            "        # Set flask g.user to JWT user, we can't do it on before request",
            "        g.user = user",
            "        return user",
            "",
            "    def get_user_by_id(self, pk):",
            "        return self.appbuilder.get_session.get(self.user_model, pk)",
            "",
            "    @property",
            "    def auth_user_registration(self):",
            "        \"\"\"Will user self registration be allowed.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_USER_REGISTRATION\"]",
            "",
            "    @property",
            "    def auth_type(self):",
            "        \"\"\"Get the auth type.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_TYPE\"]",
            "",
            "    @property",
            "    def is_auth_limited(self) -> bool:",
            "        \"\"\"Is the auth rate limited.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_RATE_LIMITED\"]",
            "",
            "    @property",
            "    def auth_rate_limit(self) -> str:",
            "        \"\"\"Get the auth rate limit.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_RATE_LIMIT\"]",
            "",
            "    @cached_property",
            "    def resourcemodelview(self):",
            "        \"\"\"Return the resource model view.\"\"\"",
            "        from airflow.www.views import ResourceModelView",
            "",
            "        return ResourceModelView"
        ],
        "afterPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "from __future__ import annotations",
            "",
            "from functools import cached_property",
            "",
            "from flask import flash, g",
            "from flask_appbuilder.const import AUTH_DB, AUTH_LDAP, AUTH_OAUTH, AUTH_OID, AUTH_REMOTE_USER",
            "from flask_babel import lazy_gettext",
            "from flask_jwt_extended import JWTManager",
            "from flask_login import LoginManager",
            "from itsdangerous import want_bytes",
            "from markupsafe import Markup",
            "from werkzeug.security import generate_password_hash",
            "",
            "from airflow.auth.managers.fab.models import User",
            "from airflow.auth.managers.fab.models.anonymous_user import AnonymousUser",
            "from airflow.www.session import AirflowDatabaseSessionInterface",
            "",
            "# This is the limit of DB user sessions that we consider as \"healthy\". If you have more sessions that this",
            "# number then we will refuse to delete sessions that have expired and old user sessions when resetting",
            "# user's password, and raise a warning in the UI instead. Usually when you have that many sessions, it means",
            "# that there is something wrong with your deployment - for example you have an automated API call that",
            "# continuously creates new sessions. Such setup should be fixed by reusing sessions or by periodically",
            "# purging the old sessions by using `airflow db clean` command.",
            "MAX_NUM_DATABASE_USER_SESSIONS = 50000",
            "",
            "",
            "class FabAirflowSecurityManagerOverride:",
            "    \"\"\"",
            "    This security manager overrides the default AirflowSecurityManager security manager.",
            "",
            "    This security manager is used only if the auth manager FabAuthManager is used. It defines everything in",
            "    the security manager that is needed for the FabAuthManager to work. Any operation specific to",
            "    the AirflowSecurityManager should be defined here instead of AirflowSecurityManager.",
            "",
            "    :param appbuilder: The appbuilder.",
            "    :param actionmodelview: The obj instance for action model view.",
            "    :param authdbview: The class for auth db view.",
            "    :param authldapview: The class for auth ldap view.",
            "    :param authoauthview: The class for auth oauth view.",
            "    :param authoidview: The class for auth oid view.",
            "    :param authremoteuserview: The class for auth remote user view.",
            "    :param permissionmodelview: The class for permission model view.",
            "    :param registeruser_view: The class for register user view.",
            "    :param registeruserdbview: The class for register user db view.",
            "    :param registeruseroauthview: The class for register user oauth view.",
            "    :param registerusermodelview: The class for register user model view.",
            "    :param registeruseroidview: The class for register user oid view.",
            "    :param resetmypasswordview: The class for reset my password view.",
            "    :param resetpasswordview: The class for reset password view.",
            "    :param rolemodelview: The class for role model view.",
            "    :param user_model: The user model.",
            "    :param userinfoeditview: The class for user info edit view.",
            "    :param userdbmodelview: The class for user db model view.",
            "    :param userldapmodelview: The class for user ldap model view.",
            "    :param useroauthmodelview: The class for user oauth model view.",
            "    :param useroidmodelview: The class for user oid model view.",
            "    :param userremoteusermodelview: The class for user remote user model view.",
            "    :param userstatschartview: The class for user stats chart view.",
            "    \"\"\"",
            "",
            "    \"\"\" The obj instance for authentication view \"\"\"",
            "    auth_view = None",
            "    \"\"\" The obj instance for user view \"\"\"",
            "    user_view = None",
            "",
            "    def __init__(self, **kwargs):",
            "        super().__init__(**kwargs)",
            "",
            "        self.appbuilder = kwargs[\"appbuilder\"]",
            "        self.actionmodelview = kwargs[\"actionmodelview\"]",
            "        self.authdbview = kwargs[\"authdbview\"]",
            "        self.authldapview = kwargs[\"authldapview\"]",
            "        self.authoauthview = kwargs[\"authoauthview\"]",
            "        self.authoidview = kwargs[\"authoidview\"]",
            "        self.authremoteuserview = kwargs[\"authremoteuserview\"]",
            "        self.permissionmodelview = kwargs[\"permissionmodelview\"]",
            "        self.registeruser_view = kwargs[\"registeruser_view\"]",
            "        self.registeruserdbview = kwargs[\"registeruserdbview\"]",
            "        self.registeruseroauthview = kwargs[\"registeruseroauthview\"]",
            "        self.registerusermodelview = kwargs[\"registerusermodelview\"]",
            "        self.registeruseroidview = kwargs[\"registeruseroidview\"]",
            "        self.resetmypasswordview = kwargs[\"resetmypasswordview\"]",
            "        self.resetpasswordview = kwargs[\"resetpasswordview\"]",
            "        self.rolemodelview = kwargs[\"rolemodelview\"]",
            "        self.user_model = kwargs[\"user_model\"]",
            "        self.userinfoeditview = kwargs[\"userinfoeditview\"]",
            "        self.userdbmodelview = kwargs[\"userdbmodelview\"]",
            "        self.userldapmodelview = kwargs[\"userldapmodelview\"]",
            "        self.useroauthmodelview = kwargs[\"useroauthmodelview\"]",
            "        self.useroidmodelview = kwargs[\"useroidmodelview\"]",
            "        self.userremoteusermodelview = kwargs[\"userremoteusermodelview\"]",
            "        self.userstatschartview = kwargs[\"userstatschartview\"]",
            "",
            "        # Setup Flask login",
            "        self.lm = self.create_login_manager()",
            "",
            "        # Setup Flask-Jwt-Extended",
            "        self.create_jwt_manager()",
            "",
            "    def register_views(self):",
            "        \"\"\"Register FAB auth manager related views.\"\"\"",
            "        if not self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_VIEWS\", True):",
            "            return",
            "",
            "        if self.auth_user_registration:",
            "            if self.auth_type == AUTH_DB:",
            "                self.registeruser_view = self.registeruserdbview()",
            "            elif self.auth_type == AUTH_OID:",
            "                self.registeruser_view = self.registeruseroidview()",
            "            elif self.auth_type == AUTH_OAUTH:",
            "                self.registeruser_view = self.registeruseroauthview()",
            "            if self.registeruser_view:",
            "                self.appbuilder.add_view_no_menu(self.registeruser_view)",
            "",
            "        self.appbuilder.add_view_no_menu(self.resetpasswordview())",
            "        self.appbuilder.add_view_no_menu(self.resetmypasswordview())",
            "        self.appbuilder.add_view_no_menu(self.userinfoeditview())",
            "",
            "        if self.auth_type == AUTH_DB:",
            "            self.user_view = self.userdbmodelview",
            "            self.auth_view = self.authdbview()",
            "        elif self.auth_type == AUTH_LDAP:",
            "            self.user_view = self.userldapmodelview",
            "            self.auth_view = self.authldapview()",
            "        elif self.auth_type == AUTH_OAUTH:",
            "            self.user_view = self.useroauthmodelview",
            "            self.auth_view = self.authoauthview()",
            "        elif self.auth_type == AUTH_REMOTE_USER:",
            "            self.user_view = self.userremoteusermodelview",
            "            self.auth_view = self.authremoteuserview()",
            "        else:",
            "            self.user_view = self.useroidmodelview",
            "            self.auth_view = self.authoidview()",
            "",
            "        self.appbuilder.add_view_no_menu(self.auth_view)",
            "",
            "        # this needs to be done after the view is added, otherwise the blueprint",
            "        # is not initialized",
            "        if self.is_auth_limited:",
            "            self.limiter.limit(self.auth_rate_limit, methods=[\"POST\"])(self.auth_view.blueprint)",
            "",
            "        self.user_view = self.appbuilder.add_view(",
            "            self.user_view,",
            "            \"List Users\",",
            "            icon=\"fa-user\",",
            "            label=lazy_gettext(\"List Users\"),",
            "            category=\"Security\",",
            "            category_icon=\"fa-cogs\",",
            "            category_label=lazy_gettext(\"Security\"),",
            "        )",
            "",
            "        role_view = self.appbuilder.add_view(",
            "            self.rolemodelview,",
            "            \"List Roles\",",
            "            icon=\"fa-group\",",
            "            label=lazy_gettext(\"List Roles\"),",
            "            category=\"Security\",",
            "            category_icon=\"fa-cogs\",",
            "        )",
            "        role_view.related_views = [self.user_view.__class__]",
            "",
            "        if self.userstatschartview:",
            "            self.appbuilder.add_view(",
            "                self.userstatschartview,",
            "                \"User's Statistics\",",
            "                icon=\"fa-bar-chart-o\",",
            "                label=lazy_gettext(\"User's Statistics\"),",
            "                category=\"Security\",",
            "            )",
            "        if self.auth_user_registration:",
            "            self.appbuilder.add_view(",
            "                self.registerusermodelview,",
            "                \"User's Statistics\",",
            "                icon=\"fa-user-plus\",",
            "                label=lazy_gettext(\"User Registrations\"),",
            "                category=\"Security\",",
            "            )",
            "        self.appbuilder.menu.add_separator(\"Security\")",
            "        if self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_PERMISSION_VIEW\", True):",
            "            self.appbuilder.add_view(",
            "                self.actionmodelview,",
            "                \"Actions\",",
            "                icon=\"fa-lock\",",
            "                label=lazy_gettext(\"Actions\"),",
            "                category=\"Security\",",
            "            )",
            "        if self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_VIEW_MENU_VIEW\", True):",
            "            self.appbuilder.add_view(",
            "                self.resourcemodelview,",
            "                \"Resources\",",
            "                icon=\"fa-list-alt\",",
            "                label=lazy_gettext(\"Resources\"),",
            "                category=\"Security\",",
            "            )",
            "        if self.appbuilder.app.config.get(\"FAB_ADD_SECURITY_PERMISSION_VIEWS_VIEW\", True):",
            "            self.appbuilder.add_view(",
            "                self.permissionmodelview,",
            "                \"Permission Pairs\",",
            "                icon=\"fa-link\",",
            "                label=lazy_gettext(\"Permissions\"),",
            "                category=\"Security\",",
            "            )",
            "",
            "    def create_login_manager(self) -> LoginManager:",
            "        \"\"\"Create the login manager.\"\"\"",
            "        lm = LoginManager(self.appbuilder.app)",
            "        lm.anonymous_user = AnonymousUser",
            "        lm.login_view = \"login\"",
            "        lm.user_loader(self.load_user)",
            "        return lm",
            "",
            "    def create_jwt_manager(self):",
            "        \"\"\"Create the JWT manager.\"\"\"",
            "        jwt_manager = JWTManager()",
            "        jwt_manager.init_app(self.appbuilder.app)",
            "        jwt_manager.user_lookup_loader(self.load_user_jwt)",
            "",
            "    def reset_password(self, userid, password):",
            "        \"\"\"",
            "        Change/Reset a user's password for authdb.",
            "",
            "        Password will be hashed and saved.",
            "        :param userid: the user id to reset the password",
            "        :param password: the clear text password to reset and save hashed on the db",
            "        \"\"\"",
            "        user = self.get_user_by_id(userid)",
            "        user.password = generate_password_hash(password)",
            "        self.reset_user_sessions(user)",
            "        self.update_user(user)",
            "",
            "    def reset_user_sessions(self, user: User) -> None:",
            "        if isinstance(self.appbuilder.get_app.session_interface, AirflowDatabaseSessionInterface):",
            "            interface = self.appbuilder.get_app.session_interface",
            "            session = interface.db.session",
            "            user_session_model = interface.sql_session_model",
            "            num_sessions = session.query(user_session_model).count()",
            "            if num_sessions > MAX_NUM_DATABASE_USER_SESSIONS:",
            "                flash(",
            "                    Markup(",
            "                        f\"The old sessions for user {user.username} have <b>NOT</b> been deleted!<br>\"",
            "                        f\"You have a lot ({num_sessions}) of user sessions in the 'SESSIONS' table in \"",
            "                        f\"your database.<br> \"",
            "                        \"This indicates that this deployment might have an automated API calls that create \"",
            "                        \"and not reuse sessions.<br>You should consider reusing sessions or cleaning them \"",
            "                        \"periodically using db clean.<br>\"",
            "                        \"Make sure to reset password for the user again after cleaning the session table \"",
            "                        \"to remove old sessions of the user.\"",
            "                    ),",
            "                    \"warning\",",
            "                )",
            "            else:",
            "                for s in session.query(user_session_model):",
            "                    session_details = interface.serializer.loads(want_bytes(s.data))",
            "                    if session_details.get(\"_user_id\") == user.id:",
            "                        session.delete(s)",
            "        else:",
            "            flash(",
            "                Markup(",
            "                    \"Since you are using `securecookie` session backend mechanism, we cannot prevent \"",
            "                    f\"some old sessions for user {user.username} to be reused.<br> If you want to make sure \"",
            "                    \"that the user is logged out from all sessions, you should consider using \"",
            "                    \"`database` session backend mechanism.<br> You can also change the 'secret_key` \"",
            "                    \"webserver configuration for all your webserver instances and restart the webserver. \"",
            "                    \"This however will logout all users from all sessions.\"",
            "                ),",
            "                \"warning\",",
            "            )",
            "",
            "    def load_user(self, user_id):",
            "        \"\"\"Load user by ID.\"\"\"",
            "        return self.get_user_by_id(int(user_id))",
            "",
            "    def load_user_jwt(self, _jwt_header, jwt_data):",
            "        identity = jwt_data[\"sub\"]",
            "        user = self.load_user(identity)",
            "        # Set flask g.user to JWT user, we can't do it on before request",
            "        g.user = user",
            "        return user",
            "",
            "    def get_user_by_id(self, pk):",
            "        return self.appbuilder.get_session.get(self.user_model, pk)",
            "",
            "    @property",
            "    def auth_user_registration(self):",
            "        \"\"\"Will user self registration be allowed.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_USER_REGISTRATION\"]",
            "",
            "    @property",
            "    def auth_type(self):",
            "        \"\"\"Get the auth type.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_TYPE\"]",
            "",
            "    @property",
            "    def is_auth_limited(self) -> bool:",
            "        \"\"\"Is the auth rate limited.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_RATE_LIMITED\"]",
            "",
            "    @property",
            "    def auth_rate_limit(self) -> str:",
            "        \"\"\"Get the auth rate limit.\"\"\"",
            "        return self.appbuilder.get_app.config[\"AUTH_RATE_LIMIT\"]",
            "",
            "    @cached_property",
            "    def resourcemodelview(self):",
            "        \"\"\"Return the resource model view.\"\"\"",
            "        from airflow.www.views import ResourceModelView",
            "",
            "        return ResourceModelView"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "22": []
        },
        "addLocation": []
    },
    "airflow/utils/db_cleanup.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " from airflow import AirflowException"
            },
            "2": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " from airflow.cli.simple_table import AirflowConsole"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+from airflow.configuration import conf"
            },
            "4": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " from airflow.models import Base"
            },
            "5": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " from airflow.utils import timezone"
            },
            "6": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " from airflow.utils.db import reflect_tables"
            },
            "7": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 116,
                "PatchRowcode": "     _TableConfig(table_name=\"celery_tasksetmeta\", recency_column_name=\"date_done\"),"
            },
            "8": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 117,
                "PatchRowcode": " ]"
            },
            "9": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 118,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+if conf.get(\"webserver\", \"session_backend\") == \"database\":"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+    config_list.append(_TableConfig(table_name=\"session\", recency_column_name=\"expiry\"))"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+"
            },
            "13": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 122,
                "PatchRowcode": " config_dict: dict[str, _TableConfig] = {x.orm_model.name: x for x in sorted(config_list)}"
            },
            "14": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 123,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 124,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"",
            "This module took inspiration from the community maintenance dag.",
            "",
            "See:",
            "(https://github.com/teamclairvoyant/airflow-maintenance-dags/blob/4e5c7682a808082561d60cbc9cafaa477b0d8c65/db-cleanup/airflow-db-cleanup.py).",
            "\"\"\"",
            "from __future__ import annotations",
            "",
            "import csv",
            "import logging",
            "import os",
            "from contextlib import contextmanager",
            "from dataclasses import dataclass",
            "from typing import Any",
            "",
            "from pendulum import DateTime",
            "from sqlalchemy import and_, column, false, func, inspect, select, table, text",
            "from sqlalchemy.exc import OperationalError, ProgrammingError",
            "from sqlalchemy.ext.compiler import compiles",
            "from sqlalchemy.orm import Query, Session, aliased",
            "from sqlalchemy.sql.expression import ClauseElement, Executable, tuple_",
            "",
            "from airflow import AirflowException",
            "from airflow.cli.simple_table import AirflowConsole",
            "from airflow.models import Base",
            "from airflow.utils import timezone",
            "from airflow.utils.db import reflect_tables",
            "from airflow.utils.helpers import ask_yesno",
            "from airflow.utils.session import NEW_SESSION, provide_session",
            "",
            "logger = logging.getLogger(__file__)",
            "",
            "ARCHIVE_TABLE_PREFIX = \"_airflow_deleted__\"",
            "",
            "",
            "@dataclass",
            "class _TableConfig:",
            "    \"\"\"",
            "    Config class for performing cleanup on a table.",
            "",
            "    :param table_name: the table",
            "    :param extra_columns: any columns besides recency_column_name that we'll need in queries",
            "    :param recency_column_name: date column to filter by",
            "    :param keep_last: whether the last record should be kept even if it's older than clean_before_timestamp",
            "    :param keep_last_filters: the \"keep last\" functionality will preserve the most recent record",
            "        in the table.  to ignore certain records even if they are the latest in the table, you can",
            "        supply additional filters here (e.g. externally triggered dag runs)",
            "    :param keep_last_group_by: if keeping the last record, can keep the last record for each group",
            "    \"\"\"",
            "",
            "    table_name: str",
            "    recency_column_name: str",
            "    extra_columns: list[str] | None = None",
            "    keep_last: bool = False",
            "    keep_last_filters: Any | None = None",
            "    keep_last_group_by: Any | None = None",
            "",
            "    def __post_init__(self):",
            "        self.recency_column = column(self.recency_column_name)",
            "        self.orm_model: Base = table(",
            "            self.table_name, *[column(x) for x in self.extra_columns or []], self.recency_column",
            "        )",
            "",
            "    def __lt__(self, other):",
            "        return self.table_name < other.table_name",
            "",
            "    @property",
            "    def readable_config(self):",
            "        return dict(",
            "            table=self.orm_model.name,",
            "            recency_column=str(self.recency_column),",
            "            keep_last=self.keep_last,",
            "            keep_last_filters=[str(x) for x in self.keep_last_filters] if self.keep_last_filters else None,",
            "            keep_last_group_by=str(self.keep_last_group_by),",
            "        )",
            "",
            "",
            "config_list: list[_TableConfig] = [",
            "    _TableConfig(table_name=\"job\", recency_column_name=\"latest_heartbeat\"),",
            "    _TableConfig(table_name=\"dag\", recency_column_name=\"last_parsed_time\"),",
            "    _TableConfig(",
            "        table_name=\"dag_run\",",
            "        recency_column_name=\"start_date\",",
            "        extra_columns=[\"dag_id\", \"external_trigger\"],",
            "        keep_last=True,",
            "        keep_last_filters=[column(\"external_trigger\") == false()],",
            "        keep_last_group_by=[\"dag_id\"],",
            "    ),",
            "    _TableConfig(table_name=\"dataset_event\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"import_error\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"log\", recency_column_name=\"dttm\"),",
            "    _TableConfig(table_name=\"sla_miss\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"task_fail\", recency_column_name=\"start_date\"),",
            "    _TableConfig(table_name=\"task_instance\", recency_column_name=\"start_date\"),",
            "    _TableConfig(table_name=\"task_reschedule\", recency_column_name=\"start_date\"),",
            "    _TableConfig(table_name=\"xcom\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"callback_request\", recency_column_name=\"created_at\"),",
            "    _TableConfig(table_name=\"celery_taskmeta\", recency_column_name=\"date_done\"),",
            "    _TableConfig(table_name=\"celery_tasksetmeta\", recency_column_name=\"date_done\"),",
            "]",
            "",
            "config_dict: dict[str, _TableConfig] = {x.orm_model.name: x for x in sorted(config_list)}",
            "",
            "",
            "def _check_for_rows(*, query: Query, print_rows=False):",
            "    num_entities = query.count()",
            "    print(f\"Found {num_entities} rows meeting deletion criteria.\")",
            "    if print_rows:",
            "        max_rows_to_print = 100",
            "        if num_entities > 0:",
            "            print(f\"Printing first {max_rows_to_print} rows.\")",
            "        logger.debug(\"print entities query: %s\", query)",
            "        for entry in query.limit(max_rows_to_print):",
            "            print(entry.__dict__)",
            "    return num_entities",
            "",
            "",
            "def _dump_table_to_file(*, target_table, file_path, export_format, session):",
            "    if export_format == \"csv\":",
            "        with open(file_path, \"w\") as f:",
            "            csv_writer = csv.writer(f)",
            "            cursor = session.execute(text(f\"SELECT * FROM {target_table}\"))",
            "            csv_writer.writerow(cursor.keys())",
            "            csv_writer.writerows(cursor.fetchall())",
            "    else:",
            "        raise AirflowException(f\"Export format {export_format} is not supported.\")",
            "",
            "",
            "def _do_delete(*, query, orm_model, skip_archive, session):",
            "    from datetime import datetime",
            "",
            "    import re2",
            "",
            "    print(\"Performing Delete...\")",
            "    # using bulk delete",
            "    # create a new table and copy the rows there",
            "    timestamp_str = re2.sub(r\"[^\\d]\", \"\", datetime.utcnow().isoformat())[:14]",
            "    target_table_name = f\"{ARCHIVE_TABLE_PREFIX}{orm_model.name}__{timestamp_str}\"",
            "    print(f\"Moving data to table {target_table_name}\")",
            "    bind = session.get_bind()",
            "    dialect_name = bind.dialect.name",
            "    if dialect_name == \"mysql\":",
            "        # MySQL with replication needs this split into two queries, so just do it for all MySQL",
            "        # ERROR 1786 (HY000): Statement violates GTID consistency: CREATE TABLE ... SELECT.",
            "        session.execute(text(f\"CREATE TABLE {target_table_name} LIKE {orm_model.name}\"))",
            "        metadata = reflect_tables([target_table_name], session)",
            "        target_table = metadata.tables[target_table_name]",
            "        insert_stm = target_table.insert().from_select(target_table.c, query)",
            "        logger.debug(\"insert statement:\\n%s\", insert_stm.compile())",
            "        session.execute(insert_stm)",
            "    else:",
            "        stmt = CreateTableAs(target_table_name, query.selectable)",
            "        logger.debug(\"ctas query:\\n%s\", stmt.compile())",
            "        session.execute(stmt)",
            "    session.commit()",
            "",
            "    # delete the rows from the old table",
            "    metadata = reflect_tables([orm_model.name, target_table_name], session)",
            "    source_table = metadata.tables[orm_model.name]",
            "    target_table = metadata.tables[target_table_name]",
            "    logger.debug(\"rows moved; purging from %s\", source_table.name)",
            "    if dialect_name == \"sqlite\":",
            "        pk_cols = source_table.primary_key.columns",
            "        delete = source_table.delete().where(",
            "            tuple_(*pk_cols).in_(",
            "                select(*[target_table.c[x.name] for x in source_table.primary_key.columns]).subquery()",
            "            )",
            "        )",
            "    else:",
            "        delete = source_table.delete().where(",
            "            and_(col == target_table.c[col.name] for col in source_table.primary_key.columns)",
            "        )",
            "    logger.debug(\"delete statement:\\n%s\", delete.compile())",
            "    session.execute(delete)",
            "    session.commit()",
            "    if skip_archive:",
            "        target_table.drop()",
            "    session.commit()",
            "    print(\"Finished Performing Delete\")",
            "",
            "",
            "def _subquery_keep_last(*, recency_column, keep_last_filters, group_by_columns, max_date_colname, session):",
            "    subquery = select(*group_by_columns, func.max(recency_column).label(max_date_colname))",
            "",
            "    if keep_last_filters is not None:",
            "        for entry in keep_last_filters:",
            "            subquery = subquery.filter(entry)",
            "",
            "    if group_by_columns is not None:",
            "        subquery = subquery.group_by(*group_by_columns)",
            "",
            "    return subquery.subquery(name=\"latest\")",
            "",
            "",
            "class CreateTableAs(Executable, ClauseElement):",
            "    \"\"\"Custom sqlalchemy clause element for CTAS operations.\"\"\"",
            "",
            "    def __init__(self, name, query):",
            "        self.name = name",
            "        self.query = query",
            "",
            "",
            "@compiles(CreateTableAs)",
            "def _compile_create_table_as__other(element, compiler, **kw):",
            "    return f\"CREATE TABLE {element.name} AS {compiler.process(element.query)}\"",
            "",
            "",
            "@compiles(CreateTableAs, \"mssql\")",
            "def _compile_create_table_as__mssql(element, compiler, **kw):",
            "    return f\"WITH cte AS ( {compiler.process(element.query)} ) SELECT * INTO {element.name} FROM cte\"",
            "",
            "",
            "def _build_query(",
            "    *,",
            "    orm_model,",
            "    recency_column,",
            "    keep_last,",
            "    keep_last_filters,",
            "    keep_last_group_by,",
            "    clean_before_timestamp,",
            "    session,",
            "    **kwargs,",
            "):",
            "    base_table_alias = \"base\"",
            "    base_table = aliased(orm_model, name=base_table_alias)",
            "    query = session.query(base_table).with_entities(text(f\"{base_table_alias}.*\"))",
            "    base_table_recency_col = base_table.c[recency_column.name]",
            "    conditions = [base_table_recency_col < clean_before_timestamp]",
            "    if keep_last:",
            "        max_date_col_name = \"max_date_per_group\"",
            "        group_by_columns = [column(x) for x in keep_last_group_by]",
            "        subquery = _subquery_keep_last(",
            "            recency_column=recency_column,",
            "            keep_last_filters=keep_last_filters,",
            "            group_by_columns=group_by_columns,",
            "            max_date_colname=max_date_col_name,",
            "            session=session,",
            "        )",
            "        query = query.select_from(base_table).outerjoin(",
            "            subquery,",
            "            and_(",
            "                *[base_table.c[x] == subquery.c[x] for x in keep_last_group_by],",
            "                base_table_recency_col == column(max_date_col_name),",
            "            ),",
            "        )",
            "        conditions.append(column(max_date_col_name).is_(None))",
            "    query = query.filter(and_(*conditions))",
            "    return query",
            "",
            "",
            "def _cleanup_table(",
            "    *,",
            "    orm_model,",
            "    recency_column,",
            "    keep_last,",
            "    keep_last_filters,",
            "    keep_last_group_by,",
            "    clean_before_timestamp,",
            "    dry_run=True,",
            "    verbose=False,",
            "    skip_archive=False,",
            "    session,",
            "    **kwargs,",
            "):",
            "    print()",
            "    if dry_run:",
            "        print(f\"Performing dry run for table {orm_model.name}\")",
            "    query = _build_query(",
            "        orm_model=orm_model,",
            "        recency_column=recency_column,",
            "        keep_last=keep_last,",
            "        keep_last_filters=keep_last_filters,",
            "        keep_last_group_by=keep_last_group_by,",
            "        clean_before_timestamp=clean_before_timestamp,",
            "        session=session,",
            "    )",
            "    logger.debug(\"old rows query:\\n%s\", query.selectable.compile())",
            "    print(f\"Checking table {orm_model.name}\")",
            "    num_rows = _check_for_rows(query=query, print_rows=False)",
            "",
            "    if num_rows and not dry_run:",
            "        _do_delete(query=query, orm_model=orm_model, skip_archive=skip_archive, session=session)",
            "",
            "    session.commit()",
            "",
            "",
            "def _confirm_delete(*, date: DateTime, tables: list[str]):",
            "    for_tables = f\" for tables {tables!r}\" if tables else \"\"",
            "    question = (",
            "        f\"You have requested that we purge all data prior to {date}{for_tables}.\\n\"",
            "        f\"This is irreversible.  Consider backing up the tables first and / or doing a dry run \"",
            "        f\"with option --dry-run.\\n\"",
            "        f\"Enter 'delete rows' (without quotes) to proceed.\"",
            "    )",
            "    print(question)",
            "    answer = input().strip()",
            "    if not answer == \"delete rows\":",
            "        raise SystemExit(\"User did not confirm; exiting.\")",
            "",
            "",
            "def _confirm_drop_archives(*, tables: list[str]):",
            "    # if length of tables is greater than 3, show the total count",
            "    if len(tables) > 3:",
            "        text_ = f\"{len(tables)} archived tables prefixed with {ARCHIVE_TABLE_PREFIX}\"",
            "    else:",
            "        text_ = f\"the following archived tables {tables}\"",
            "    question = (",
            "        f\"You have requested that we drop {text_}.\\n\"",
            "        f\"This is irreversible. Consider backing up the tables first \\n\"",
            "    )",
            "    print(question)",
            "    if len(tables) > 3:",
            "        show_tables = ask_yesno(\"Show tables? (y/n): \")",
            "        if show_tables:",
            "            print(tables, \"\\n\")",
            "    answer = input(\"Enter 'drop archived tables' (without quotes) to proceed.\\n\").strip()",
            "    if not answer == \"drop archived tables\":",
            "        raise SystemExit(\"User did not confirm; exiting.\")",
            "",
            "",
            "def _print_config(*, configs: dict[str, _TableConfig]):",
            "    data = [x.readable_config for x in configs.values()]",
            "    AirflowConsole().print_as_table(data=data)",
            "",
            "",
            "@contextmanager",
            "def _suppress_with_logging(table, session):",
            "    \"\"\"",
            "    Suppresses errors but logs them.",
            "",
            "    Also stores the exception instance so it can be referred to after exiting context.",
            "    \"\"\"",
            "    try:",
            "        yield",
            "    except (OperationalError, ProgrammingError):",
            "        logger.warning(\"Encountered error when attempting to clean table '%s'. \", table)",
            "        logger.debug(\"Traceback for table '%s'\", table, exc_info=True)",
            "        if session.is_active:",
            "            logger.debug(\"Rolling back transaction\")",
            "            session.rollback()",
            "",
            "",
            "def _effective_table_names(*, table_names: list[str] | None):",
            "    desired_table_names = set(table_names or config_dict)",
            "    effective_config_dict = {k: v for k, v in config_dict.items() if k in desired_table_names}",
            "    effective_table_names = set(effective_config_dict)",
            "    if desired_table_names != effective_table_names:",
            "        outliers = desired_table_names - effective_table_names",
            "        logger.warning(",
            "            \"The following table(s) are not valid choices and will be skipped: %s\", sorted(outliers)",
            "        )",
            "    if not effective_table_names:",
            "        raise SystemExit(\"No tables selected for db cleanup. Please choose valid table names.\")",
            "    return effective_table_names, effective_config_dict",
            "",
            "",
            "def _get_archived_table_names(table_names, session):",
            "    inspector = inspect(session.bind)",
            "    db_table_names = [x for x in inspector.get_table_names() if x.startswith(ARCHIVE_TABLE_PREFIX)]",
            "    effective_table_names, _ = _effective_table_names(table_names=table_names)",
            "    # Filter out tables that don't start with the archive prefix",
            "    archived_table_names = [",
            "        table_name",
            "        for table_name in db_table_names",
            "        if any(\"__\" + x + \"__\" in table_name for x in effective_table_names)",
            "    ]",
            "    return archived_table_names",
            "",
            "",
            "@provide_session",
            "def run_cleanup(",
            "    *,",
            "    clean_before_timestamp: DateTime,",
            "    table_names: list[str] | None = None,",
            "    dry_run: bool = False,",
            "    verbose: bool = False,",
            "    confirm: bool = True,",
            "    skip_archive: bool = False,",
            "    session: Session = NEW_SESSION,",
            "):",
            "    \"\"\"",
            "    Purges old records in airflow metadata database.",
            "",
            "    The last non-externally-triggered dag run will always be kept in order to ensure",
            "    continuity of scheduled dag runs.",
            "",
            "    Where there are foreign key relationships, deletes will cascade, so that for",
            "    example if you clean up old dag runs, the associated task instances will",
            "    be deleted.",
            "",
            "    :param clean_before_timestamp: The timestamp before which data should be purged",
            "    :param table_names: Optional. List of table names to perform maintenance on.  If list not provided,",
            "        will perform maintenance on all tables.",
            "    :param dry_run: If true, print rows meeting deletion criteria",
            "    :param verbose: If true, may provide more detailed output.",
            "    :param confirm: Require user input to confirm before processing deletions.",
            "    :param skip_archive: Set to True if you don't want the purged rows preservied in an archive table.",
            "    :param session: Session representing connection to the metadata database.",
            "    \"\"\"",
            "    clean_before_timestamp = timezone.coerce_datetime(clean_before_timestamp)",
            "    effective_table_names, effective_config_dict = _effective_table_names(table_names=table_names)",
            "    if dry_run:",
            "        print(\"Performing dry run for db cleanup.\")",
            "        print(",
            "            f\"Data prior to {clean_before_timestamp} would be purged \"",
            "            f\"from tables {effective_table_names} with the following config:\\n\"",
            "        )",
            "        _print_config(configs=effective_config_dict)",
            "    if not dry_run and confirm:",
            "        _confirm_delete(date=clean_before_timestamp, tables=sorted(effective_table_names))",
            "    existing_tables = reflect_tables(tables=None, session=session).tables",
            "    for table_name, table_config in effective_config_dict.items():",
            "        if table_name not in existing_tables:",
            "            logger.warning(\"Table %s not found.  Skipping.\", table_name)",
            "            continue",
            "        with _suppress_with_logging(table_name, session):",
            "            _cleanup_table(",
            "                clean_before_timestamp=clean_before_timestamp,",
            "                dry_run=dry_run,",
            "                verbose=verbose,",
            "                **table_config.__dict__,",
            "                skip_archive=skip_archive,",
            "                session=session,",
            "            )",
            "            session.commit()",
            "",
            "",
            "@provide_session",
            "def export_archived_records(",
            "    export_format,",
            "    output_path,",
            "    table_names=None,",
            "    drop_archives=False,",
            "    needs_confirm=True,",
            "    session: Session = NEW_SESSION,",
            "):",
            "    \"\"\"Export archived data to the given output path in the given format.\"\"\"",
            "    archived_table_names = _get_archived_table_names(table_names, session)",
            "    # If user chose to drop archives, check there are archive tables that exists",
            "    # before asking for confirmation",
            "    if drop_archives and archived_table_names and needs_confirm:",
            "        _confirm_drop_archives(tables=sorted(archived_table_names))",
            "    export_count = 0",
            "    dropped_count = 0",
            "    for table_name in archived_table_names:",
            "        logger.info(\"Exporting table %s\", table_name)",
            "        _dump_table_to_file(",
            "            target_table=table_name,",
            "            file_path=os.path.join(output_path, f\"{table_name}.{export_format}\"),",
            "            export_format=export_format,",
            "            session=session,",
            "        )",
            "        export_count += 1",
            "        if drop_archives:",
            "            logger.info(\"Dropping archived table %s\", table_name)",
            "            session.execute(text(f\"DROP TABLE {table_name}\"))",
            "            dropped_count += 1",
            "    logger.info(\"Total exported tables: %s, Total dropped tables: %s\", export_count, dropped_count)",
            "",
            "",
            "@provide_session",
            "def drop_archived_tables(table_names, needs_confirm, session):",
            "    \"\"\"Drop archived tables.\"\"\"",
            "    archived_table_names = _get_archived_table_names(table_names, session)",
            "    if needs_confirm and archived_table_names:",
            "        _confirm_drop_archives(tables=sorted(archived_table_names))",
            "    dropped_count = 0",
            "    for table_name in archived_table_names:",
            "        logger.info(\"Dropping archived table %s\", table_name)",
            "        session.execute(text(f\"DROP TABLE {table_name}\"))",
            "        dropped_count += 1",
            "    logger.info(\"Total dropped tables: %s\", dropped_count)"
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"",
            "This module took inspiration from the community maintenance dag.",
            "",
            "See:",
            "(https://github.com/teamclairvoyant/airflow-maintenance-dags/blob/4e5c7682a808082561d60cbc9cafaa477b0d8c65/db-cleanup/airflow-db-cleanup.py).",
            "\"\"\"",
            "from __future__ import annotations",
            "",
            "import csv",
            "import logging",
            "import os",
            "from contextlib import contextmanager",
            "from dataclasses import dataclass",
            "from typing import Any",
            "",
            "from pendulum import DateTime",
            "from sqlalchemy import and_, column, false, func, inspect, select, table, text",
            "from sqlalchemy.exc import OperationalError, ProgrammingError",
            "from sqlalchemy.ext.compiler import compiles",
            "from sqlalchemy.orm import Query, Session, aliased",
            "from sqlalchemy.sql.expression import ClauseElement, Executable, tuple_",
            "",
            "from airflow import AirflowException",
            "from airflow.cli.simple_table import AirflowConsole",
            "from airflow.configuration import conf",
            "from airflow.models import Base",
            "from airflow.utils import timezone",
            "from airflow.utils.db import reflect_tables",
            "from airflow.utils.helpers import ask_yesno",
            "from airflow.utils.session import NEW_SESSION, provide_session",
            "",
            "logger = logging.getLogger(__file__)",
            "",
            "ARCHIVE_TABLE_PREFIX = \"_airflow_deleted__\"",
            "",
            "",
            "@dataclass",
            "class _TableConfig:",
            "    \"\"\"",
            "    Config class for performing cleanup on a table.",
            "",
            "    :param table_name: the table",
            "    :param extra_columns: any columns besides recency_column_name that we'll need in queries",
            "    :param recency_column_name: date column to filter by",
            "    :param keep_last: whether the last record should be kept even if it's older than clean_before_timestamp",
            "    :param keep_last_filters: the \"keep last\" functionality will preserve the most recent record",
            "        in the table.  to ignore certain records even if they are the latest in the table, you can",
            "        supply additional filters here (e.g. externally triggered dag runs)",
            "    :param keep_last_group_by: if keeping the last record, can keep the last record for each group",
            "    \"\"\"",
            "",
            "    table_name: str",
            "    recency_column_name: str",
            "    extra_columns: list[str] | None = None",
            "    keep_last: bool = False",
            "    keep_last_filters: Any | None = None",
            "    keep_last_group_by: Any | None = None",
            "",
            "    def __post_init__(self):",
            "        self.recency_column = column(self.recency_column_name)",
            "        self.orm_model: Base = table(",
            "            self.table_name, *[column(x) for x in self.extra_columns or []], self.recency_column",
            "        )",
            "",
            "    def __lt__(self, other):",
            "        return self.table_name < other.table_name",
            "",
            "    @property",
            "    def readable_config(self):",
            "        return dict(",
            "            table=self.orm_model.name,",
            "            recency_column=str(self.recency_column),",
            "            keep_last=self.keep_last,",
            "            keep_last_filters=[str(x) for x in self.keep_last_filters] if self.keep_last_filters else None,",
            "            keep_last_group_by=str(self.keep_last_group_by),",
            "        )",
            "",
            "",
            "config_list: list[_TableConfig] = [",
            "    _TableConfig(table_name=\"job\", recency_column_name=\"latest_heartbeat\"),",
            "    _TableConfig(table_name=\"dag\", recency_column_name=\"last_parsed_time\"),",
            "    _TableConfig(",
            "        table_name=\"dag_run\",",
            "        recency_column_name=\"start_date\",",
            "        extra_columns=[\"dag_id\", \"external_trigger\"],",
            "        keep_last=True,",
            "        keep_last_filters=[column(\"external_trigger\") == false()],",
            "        keep_last_group_by=[\"dag_id\"],",
            "    ),",
            "    _TableConfig(table_name=\"dataset_event\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"import_error\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"log\", recency_column_name=\"dttm\"),",
            "    _TableConfig(table_name=\"sla_miss\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"task_fail\", recency_column_name=\"start_date\"),",
            "    _TableConfig(table_name=\"task_instance\", recency_column_name=\"start_date\"),",
            "    _TableConfig(table_name=\"task_reschedule\", recency_column_name=\"start_date\"),",
            "    _TableConfig(table_name=\"xcom\", recency_column_name=\"timestamp\"),",
            "    _TableConfig(table_name=\"callback_request\", recency_column_name=\"created_at\"),",
            "    _TableConfig(table_name=\"celery_taskmeta\", recency_column_name=\"date_done\"),",
            "    _TableConfig(table_name=\"celery_tasksetmeta\", recency_column_name=\"date_done\"),",
            "]",
            "",
            "if conf.get(\"webserver\", \"session_backend\") == \"database\":",
            "    config_list.append(_TableConfig(table_name=\"session\", recency_column_name=\"expiry\"))",
            "",
            "config_dict: dict[str, _TableConfig] = {x.orm_model.name: x for x in sorted(config_list)}",
            "",
            "",
            "def _check_for_rows(*, query: Query, print_rows=False):",
            "    num_entities = query.count()",
            "    print(f\"Found {num_entities} rows meeting deletion criteria.\")",
            "    if print_rows:",
            "        max_rows_to_print = 100",
            "        if num_entities > 0:",
            "            print(f\"Printing first {max_rows_to_print} rows.\")",
            "        logger.debug(\"print entities query: %s\", query)",
            "        for entry in query.limit(max_rows_to_print):",
            "            print(entry.__dict__)",
            "    return num_entities",
            "",
            "",
            "def _dump_table_to_file(*, target_table, file_path, export_format, session):",
            "    if export_format == \"csv\":",
            "        with open(file_path, \"w\") as f:",
            "            csv_writer = csv.writer(f)",
            "            cursor = session.execute(text(f\"SELECT * FROM {target_table}\"))",
            "            csv_writer.writerow(cursor.keys())",
            "            csv_writer.writerows(cursor.fetchall())",
            "    else:",
            "        raise AirflowException(f\"Export format {export_format} is not supported.\")",
            "",
            "",
            "def _do_delete(*, query, orm_model, skip_archive, session):",
            "    from datetime import datetime",
            "",
            "    import re2",
            "",
            "    print(\"Performing Delete...\")",
            "    # using bulk delete",
            "    # create a new table and copy the rows there",
            "    timestamp_str = re2.sub(r\"[^\\d]\", \"\", datetime.utcnow().isoformat())[:14]",
            "    target_table_name = f\"{ARCHIVE_TABLE_PREFIX}{orm_model.name}__{timestamp_str}\"",
            "    print(f\"Moving data to table {target_table_name}\")",
            "    bind = session.get_bind()",
            "    dialect_name = bind.dialect.name",
            "    if dialect_name == \"mysql\":",
            "        # MySQL with replication needs this split into two queries, so just do it for all MySQL",
            "        # ERROR 1786 (HY000): Statement violates GTID consistency: CREATE TABLE ... SELECT.",
            "        session.execute(text(f\"CREATE TABLE {target_table_name} LIKE {orm_model.name}\"))",
            "        metadata = reflect_tables([target_table_name], session)",
            "        target_table = metadata.tables[target_table_name]",
            "        insert_stm = target_table.insert().from_select(target_table.c, query)",
            "        logger.debug(\"insert statement:\\n%s\", insert_stm.compile())",
            "        session.execute(insert_stm)",
            "    else:",
            "        stmt = CreateTableAs(target_table_name, query.selectable)",
            "        logger.debug(\"ctas query:\\n%s\", stmt.compile())",
            "        session.execute(stmt)",
            "    session.commit()",
            "",
            "    # delete the rows from the old table",
            "    metadata = reflect_tables([orm_model.name, target_table_name], session)",
            "    source_table = metadata.tables[orm_model.name]",
            "    target_table = metadata.tables[target_table_name]",
            "    logger.debug(\"rows moved; purging from %s\", source_table.name)",
            "    if dialect_name == \"sqlite\":",
            "        pk_cols = source_table.primary_key.columns",
            "        delete = source_table.delete().where(",
            "            tuple_(*pk_cols).in_(",
            "                select(*[target_table.c[x.name] for x in source_table.primary_key.columns]).subquery()",
            "            )",
            "        )",
            "    else:",
            "        delete = source_table.delete().where(",
            "            and_(col == target_table.c[col.name] for col in source_table.primary_key.columns)",
            "        )",
            "    logger.debug(\"delete statement:\\n%s\", delete.compile())",
            "    session.execute(delete)",
            "    session.commit()",
            "    if skip_archive:",
            "        target_table.drop()",
            "    session.commit()",
            "    print(\"Finished Performing Delete\")",
            "",
            "",
            "def _subquery_keep_last(*, recency_column, keep_last_filters, group_by_columns, max_date_colname, session):",
            "    subquery = select(*group_by_columns, func.max(recency_column).label(max_date_colname))",
            "",
            "    if keep_last_filters is not None:",
            "        for entry in keep_last_filters:",
            "            subquery = subquery.filter(entry)",
            "",
            "    if group_by_columns is not None:",
            "        subquery = subquery.group_by(*group_by_columns)",
            "",
            "    return subquery.subquery(name=\"latest\")",
            "",
            "",
            "class CreateTableAs(Executable, ClauseElement):",
            "    \"\"\"Custom sqlalchemy clause element for CTAS operations.\"\"\"",
            "",
            "    def __init__(self, name, query):",
            "        self.name = name",
            "        self.query = query",
            "",
            "",
            "@compiles(CreateTableAs)",
            "def _compile_create_table_as__other(element, compiler, **kw):",
            "    return f\"CREATE TABLE {element.name} AS {compiler.process(element.query)}\"",
            "",
            "",
            "@compiles(CreateTableAs, \"mssql\")",
            "def _compile_create_table_as__mssql(element, compiler, **kw):",
            "    return f\"WITH cte AS ( {compiler.process(element.query)} ) SELECT * INTO {element.name} FROM cte\"",
            "",
            "",
            "def _build_query(",
            "    *,",
            "    orm_model,",
            "    recency_column,",
            "    keep_last,",
            "    keep_last_filters,",
            "    keep_last_group_by,",
            "    clean_before_timestamp,",
            "    session,",
            "    **kwargs,",
            "):",
            "    base_table_alias = \"base\"",
            "    base_table = aliased(orm_model, name=base_table_alias)",
            "    query = session.query(base_table).with_entities(text(f\"{base_table_alias}.*\"))",
            "    base_table_recency_col = base_table.c[recency_column.name]",
            "    conditions = [base_table_recency_col < clean_before_timestamp]",
            "    if keep_last:",
            "        max_date_col_name = \"max_date_per_group\"",
            "        group_by_columns = [column(x) for x in keep_last_group_by]",
            "        subquery = _subquery_keep_last(",
            "            recency_column=recency_column,",
            "            keep_last_filters=keep_last_filters,",
            "            group_by_columns=group_by_columns,",
            "            max_date_colname=max_date_col_name,",
            "            session=session,",
            "        )",
            "        query = query.select_from(base_table).outerjoin(",
            "            subquery,",
            "            and_(",
            "                *[base_table.c[x] == subquery.c[x] for x in keep_last_group_by],",
            "                base_table_recency_col == column(max_date_col_name),",
            "            ),",
            "        )",
            "        conditions.append(column(max_date_col_name).is_(None))",
            "    query = query.filter(and_(*conditions))",
            "    return query",
            "",
            "",
            "def _cleanup_table(",
            "    *,",
            "    orm_model,",
            "    recency_column,",
            "    keep_last,",
            "    keep_last_filters,",
            "    keep_last_group_by,",
            "    clean_before_timestamp,",
            "    dry_run=True,",
            "    verbose=False,",
            "    skip_archive=False,",
            "    session,",
            "    **kwargs,",
            "):",
            "    print()",
            "    if dry_run:",
            "        print(f\"Performing dry run for table {orm_model.name}\")",
            "    query = _build_query(",
            "        orm_model=orm_model,",
            "        recency_column=recency_column,",
            "        keep_last=keep_last,",
            "        keep_last_filters=keep_last_filters,",
            "        keep_last_group_by=keep_last_group_by,",
            "        clean_before_timestamp=clean_before_timestamp,",
            "        session=session,",
            "    )",
            "    logger.debug(\"old rows query:\\n%s\", query.selectable.compile())",
            "    print(f\"Checking table {orm_model.name}\")",
            "    num_rows = _check_for_rows(query=query, print_rows=False)",
            "",
            "    if num_rows and not dry_run:",
            "        _do_delete(query=query, orm_model=orm_model, skip_archive=skip_archive, session=session)",
            "",
            "    session.commit()",
            "",
            "",
            "def _confirm_delete(*, date: DateTime, tables: list[str]):",
            "    for_tables = f\" for tables {tables!r}\" if tables else \"\"",
            "    question = (",
            "        f\"You have requested that we purge all data prior to {date}{for_tables}.\\n\"",
            "        f\"This is irreversible.  Consider backing up the tables first and / or doing a dry run \"",
            "        f\"with option --dry-run.\\n\"",
            "        f\"Enter 'delete rows' (without quotes) to proceed.\"",
            "    )",
            "    print(question)",
            "    answer = input().strip()",
            "    if not answer == \"delete rows\":",
            "        raise SystemExit(\"User did not confirm; exiting.\")",
            "",
            "",
            "def _confirm_drop_archives(*, tables: list[str]):",
            "    # if length of tables is greater than 3, show the total count",
            "    if len(tables) > 3:",
            "        text_ = f\"{len(tables)} archived tables prefixed with {ARCHIVE_TABLE_PREFIX}\"",
            "    else:",
            "        text_ = f\"the following archived tables {tables}\"",
            "    question = (",
            "        f\"You have requested that we drop {text_}.\\n\"",
            "        f\"This is irreversible. Consider backing up the tables first \\n\"",
            "    )",
            "    print(question)",
            "    if len(tables) > 3:",
            "        show_tables = ask_yesno(\"Show tables? (y/n): \")",
            "        if show_tables:",
            "            print(tables, \"\\n\")",
            "    answer = input(\"Enter 'drop archived tables' (without quotes) to proceed.\\n\").strip()",
            "    if not answer == \"drop archived tables\":",
            "        raise SystemExit(\"User did not confirm; exiting.\")",
            "",
            "",
            "def _print_config(*, configs: dict[str, _TableConfig]):",
            "    data = [x.readable_config for x in configs.values()]",
            "    AirflowConsole().print_as_table(data=data)",
            "",
            "",
            "@contextmanager",
            "def _suppress_with_logging(table, session):",
            "    \"\"\"",
            "    Suppresses errors but logs them.",
            "",
            "    Also stores the exception instance so it can be referred to after exiting context.",
            "    \"\"\"",
            "    try:",
            "        yield",
            "    except (OperationalError, ProgrammingError):",
            "        logger.warning(\"Encountered error when attempting to clean table '%s'. \", table)",
            "        logger.debug(\"Traceback for table '%s'\", table, exc_info=True)",
            "        if session.is_active:",
            "            logger.debug(\"Rolling back transaction\")",
            "            session.rollback()",
            "",
            "",
            "def _effective_table_names(*, table_names: list[str] | None):",
            "    desired_table_names = set(table_names or config_dict)",
            "    effective_config_dict = {k: v for k, v in config_dict.items() if k in desired_table_names}",
            "    effective_table_names = set(effective_config_dict)",
            "    if desired_table_names != effective_table_names:",
            "        outliers = desired_table_names - effective_table_names",
            "        logger.warning(",
            "            \"The following table(s) are not valid choices and will be skipped: %s\", sorted(outliers)",
            "        )",
            "    if not effective_table_names:",
            "        raise SystemExit(\"No tables selected for db cleanup. Please choose valid table names.\")",
            "    return effective_table_names, effective_config_dict",
            "",
            "",
            "def _get_archived_table_names(table_names, session):",
            "    inspector = inspect(session.bind)",
            "    db_table_names = [x for x in inspector.get_table_names() if x.startswith(ARCHIVE_TABLE_PREFIX)]",
            "    effective_table_names, _ = _effective_table_names(table_names=table_names)",
            "    # Filter out tables that don't start with the archive prefix",
            "    archived_table_names = [",
            "        table_name",
            "        for table_name in db_table_names",
            "        if any(\"__\" + x + \"__\" in table_name for x in effective_table_names)",
            "    ]",
            "    return archived_table_names",
            "",
            "",
            "@provide_session",
            "def run_cleanup(",
            "    *,",
            "    clean_before_timestamp: DateTime,",
            "    table_names: list[str] | None = None,",
            "    dry_run: bool = False,",
            "    verbose: bool = False,",
            "    confirm: bool = True,",
            "    skip_archive: bool = False,",
            "    session: Session = NEW_SESSION,",
            "):",
            "    \"\"\"",
            "    Purges old records in airflow metadata database.",
            "",
            "    The last non-externally-triggered dag run will always be kept in order to ensure",
            "    continuity of scheduled dag runs.",
            "",
            "    Where there are foreign key relationships, deletes will cascade, so that for",
            "    example if you clean up old dag runs, the associated task instances will",
            "    be deleted.",
            "",
            "    :param clean_before_timestamp: The timestamp before which data should be purged",
            "    :param table_names: Optional. List of table names to perform maintenance on.  If list not provided,",
            "        will perform maintenance on all tables.",
            "    :param dry_run: If true, print rows meeting deletion criteria",
            "    :param verbose: If true, may provide more detailed output.",
            "    :param confirm: Require user input to confirm before processing deletions.",
            "    :param skip_archive: Set to True if you don't want the purged rows preservied in an archive table.",
            "    :param session: Session representing connection to the metadata database.",
            "    \"\"\"",
            "    clean_before_timestamp = timezone.coerce_datetime(clean_before_timestamp)",
            "    effective_table_names, effective_config_dict = _effective_table_names(table_names=table_names)",
            "    if dry_run:",
            "        print(\"Performing dry run for db cleanup.\")",
            "        print(",
            "            f\"Data prior to {clean_before_timestamp} would be purged \"",
            "            f\"from tables {effective_table_names} with the following config:\\n\"",
            "        )",
            "        _print_config(configs=effective_config_dict)",
            "    if not dry_run and confirm:",
            "        _confirm_delete(date=clean_before_timestamp, tables=sorted(effective_table_names))",
            "    existing_tables = reflect_tables(tables=None, session=session).tables",
            "    for table_name, table_config in effective_config_dict.items():",
            "        if table_name not in existing_tables:",
            "            logger.warning(\"Table %s not found.  Skipping.\", table_name)",
            "            continue",
            "        with _suppress_with_logging(table_name, session):",
            "            _cleanup_table(",
            "                clean_before_timestamp=clean_before_timestamp,",
            "                dry_run=dry_run,",
            "                verbose=verbose,",
            "                **table_config.__dict__,",
            "                skip_archive=skip_archive,",
            "                session=session,",
            "            )",
            "            session.commit()",
            "",
            "",
            "@provide_session",
            "def export_archived_records(",
            "    export_format,",
            "    output_path,",
            "    table_names=None,",
            "    drop_archives=False,",
            "    needs_confirm=True,",
            "    session: Session = NEW_SESSION,",
            "):",
            "    \"\"\"Export archived data to the given output path in the given format.\"\"\"",
            "    archived_table_names = _get_archived_table_names(table_names, session)",
            "    # If user chose to drop archives, check there are archive tables that exists",
            "    # before asking for confirmation",
            "    if drop_archives and archived_table_names and needs_confirm:",
            "        _confirm_drop_archives(tables=sorted(archived_table_names))",
            "    export_count = 0",
            "    dropped_count = 0",
            "    for table_name in archived_table_names:",
            "        logger.info(\"Exporting table %s\", table_name)",
            "        _dump_table_to_file(",
            "            target_table=table_name,",
            "            file_path=os.path.join(output_path, f\"{table_name}.{export_format}\"),",
            "            export_format=export_format,",
            "            session=session,",
            "        )",
            "        export_count += 1",
            "        if drop_archives:",
            "            logger.info(\"Dropping archived table %s\", table_name)",
            "            session.execute(text(f\"DROP TABLE {table_name}\"))",
            "            dropped_count += 1",
            "    logger.info(\"Total exported tables: %s, Total dropped tables: %s\", export_count, dropped_count)",
            "",
            "",
            "@provide_session",
            "def drop_archived_tables(table_names, needs_confirm, session):",
            "    \"\"\"Drop archived tables.\"\"\"",
            "    archived_table_names = _get_archived_table_names(table_names, session)",
            "    if needs_confirm and archived_table_names:",
            "        _confirm_drop_archives(tables=sorted(archived_table_names))",
            "    dropped_count = 0",
            "    for table_name in archived_table_names:",
            "        logger.info(\"Dropping archived table %s\", table_name)",
            "        session.execute(text(f\"DROP TABLE {table_name}\"))",
            "        dropped_count += 1",
            "    logger.info(\"Total dropped tables: %s\", dropped_count)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    }
}