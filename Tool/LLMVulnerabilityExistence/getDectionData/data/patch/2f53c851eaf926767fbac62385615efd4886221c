{
    "src/gevent/pywsgi.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": "    This server is intended primarily for development and testing, and"
            },
            "1": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": "    secondarily for other \"safe\" scenarios where it will not be exposed to"
            },
            "2": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": "    potentially malicious input. The code has not been security audited,"
            },
            "3": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-   and is not intended for direct exposure to the public Internet."
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+   and is not intended for direct exposure to the public Internet. For production"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 17,
                "PatchRowcode": "+   usage on the Internet, either choose a production-strength server such as"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+   gunicorn, or put a reverse proxy between gevent and the Internet."
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+.. versionchanged:: NEXT"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+   Complies more closely with the HTTP specification for chunked transfer encoding."
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+   In particular, we are much stricter about trailers, and trailers that"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+   are invalid (too long or featuring disallowed characters) forcibly close"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+   the connection to the client *after* the results have been sent."
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+   Trailers otherwise continue to be ignored and are not available to the"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+   WSGI application."
            },
            "17": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " \"\"\""
            },
            "19": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from __future__ import absolute_import"
            },
            "20": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 41,
                "PatchRowcode": " import traceback"
            },
            "21": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " from datetime import datetime"
            },
            "22": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-try:"
            },
            "24": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    from urllib import unquote"
            },
            "25": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-except ImportError:"
            },
            "26": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    from urllib.parse import unquote # python 2 pylint:disable=import-error,no-name-in-module"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+from urllib.parse import unquote"
            },
            "28": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 45,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " from gevent import socket"
            },
            "30": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " import gevent"
            },
            "31": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " "
            },
            "32": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " MAX_REQUEST_LINE = 8192"
            },
            "33": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 68,
                "PatchRowcode": " # Weekday and month names for HTTP date/time formatting; always English!"
            },
            "34": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-_WEEKDAYNAME = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]"
            },
            "35": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-_MONTHNAME = [None,  # Dummy so we can use 1-based month numbers"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+_WEEKDAYNAME = (\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+_MONTHNAME = (None,  # Dummy so we can use 1-based month numbers"
            },
            "38": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 71,
                "PatchRowcode": "               \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\","
            },
            "39": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-              \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+              \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")"
            },
            "41": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 73,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 74,
                "PatchRowcode": " # The contents of the \"HEX\" grammar rule for HTTP, upper and lowercase A-F plus digits,"
            },
            "43": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 75,
                "PatchRowcode": " # in byte form for comparing to the network."
            },
            "44": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 76,
                "PatchRowcode": " _HEX = string.hexdigits.encode('ascii')"
            },
            "45": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 77,
                "PatchRowcode": " "
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+# The characters allowed in \"token\" rules."
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+# token          = 1*tchar"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+# tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\""
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+#                / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\""
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+#                / DIGIT / ALPHA"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+#                ; any VCHAR, except delimiters"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+# ALPHA          =  %x41-5A / %x61-7A   ; A-Z / a-z"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+_ALLOWED_TOKEN_CHARS = frozenset("
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+    # Remember we have to be careful because bytestrings"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+    # inexplicably iterate as integers, which are not equal to bytes."
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+    # explicit chars then DIGIT"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+    (c.encode('ascii') for c in \"!#$%&'*+-.^_`|~0123456789\")"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+    # Then we add ALPHA"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+) | {c.encode('ascii') for c in string.ascii_letters}"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+assert b'A' in _ALLOWED_TOKEN_CHARS"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+"
            },
            "65": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 97,
                "PatchRowcode": " # Errors"
            },
            "66": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 98,
                "PatchRowcode": " _ERRORS = {}"
            },
            "67": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 99,
                "PatchRowcode": " _INTERNAL_ERROR_STATUS = '500 Internal Server Error'"
            },
            "68": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 100,
                "PatchRowcode": " _INTERNAL_ERROR_BODY = b'Internal Server Error'"
            },
            "69": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-_INTERNAL_ERROR_HEADERS = [('Content-Type', 'text/plain'),"
            },
            "70": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                           ('Connection', 'close'),"
            },
            "71": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                           ('Content-Length', str(len(_INTERNAL_ERROR_BODY)))]"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+_INTERNAL_ERROR_HEADERS = ("
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+    ('Content-Type', 'text/plain'),"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+    ('Connection', 'close'),"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+    ('Content-Length', str(len(_INTERNAL_ERROR_BODY)))"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+)"
            },
            "77": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 106,
                "PatchRowcode": " _ERRORS[500] = (_INTERNAL_ERROR_STATUS, _INTERNAL_ERROR_HEADERS, _INTERNAL_ERROR_BODY)"
            },
            "78": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 107,
                "PatchRowcode": " "
            },
            "79": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 108,
                "PatchRowcode": " _BAD_REQUEST_STATUS = '400 Bad Request'"
            },
            "80": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 109,
                "PatchRowcode": " _BAD_REQUEST_BODY = ''"
            },
            "81": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-_BAD_REQUEST_HEADERS = [('Content-Type', 'text/plain'),"
            },
            "82": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        ('Connection', 'close'),"
            },
            "83": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        ('Content-Length', str(len(_BAD_REQUEST_BODY)))]"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+_BAD_REQUEST_HEADERS = ("
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+    ('Content-Type', 'text/plain'),"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+    ('Connection', 'close'),"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+    ('Content-Length', str(len(_BAD_REQUEST_BODY)))"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+)"
            },
            "89": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 115,
                "PatchRowcode": " _ERRORS[400] = (_BAD_REQUEST_STATUS, _BAD_REQUEST_HEADERS, _BAD_REQUEST_BODY)"
            },
            "90": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 116,
                "PatchRowcode": " "
            },
            "91": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 117,
                "PatchRowcode": " _REQUEST_TOO_LONG_RESPONSE = b\"HTTP/1.1 414 Request URI Too Long\\r\\nConnection: close\\r\\nContent-length: 0\\r\\n\\r\\n\""
            },
            "92": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 239,
                "PatchRowcode": "         # Read and return the next integer chunk length. If no"
            },
            "93": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 240,
                "PatchRowcode": "         # chunk length can be read, raises _InvalidClientInput."
            },
            "94": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 241,
                "PatchRowcode": " "
            },
            "95": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Here's the production for a chunk:"
            },
            "96": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # (http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html)"
            },
            "97": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #   chunk          = chunk-size [ chunk-extension ] CRLF"
            },
            "98": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #                    chunk-data CRLF"
            },
            "99": {
                "beforePatchRowNumber": 214,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #   chunk-size     = 1*HEX"
            },
            "100": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #   chunk-extension= *( \";\" chunk-ext-name [ \"=\" chunk-ext-val ] )"
            },
            "101": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #   chunk-ext-name = token"
            },
            "102": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #   chunk-ext-val  = token | quoted-string"
            },
            "103": {
                "beforePatchRowNumber": 218,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "104": {
                "beforePatchRowNumber": 219,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # To cope with malicious or broken clients that fail to send valid"
            },
            "105": {
                "beforePatchRowNumber": 220,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # chunk lines, the strategy is to read character by character until we either reach"
            },
            "106": {
                "beforePatchRowNumber": 221,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # a ; or newline. If at any time we read a non-HEX digit, we bail. If we hit a"
            },
            "107": {
                "beforePatchRowNumber": 222,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # ;, indicating an chunk-extension, we'll read up to the next"
            },
            "108": {
                "beforePatchRowNumber": 223,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # MAX_REQUEST_LINE characters"
            },
            "109": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # looking for the CRLF, and if we don't find it, we bail. If we read more than 16 hex characters,"
            },
            "110": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # (the number needed to represent a 64-bit chunk size), we bail (this protects us from"
            },
            "111": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # a client that sends an infinite stream of `F`, for example)."
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 242,
                "PatchRowcode": "+        # Here's the production for a chunk (actually the whole body):"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 243,
                "PatchRowcode": "+        # (https://www.rfc-editor.org/rfc/rfc7230#section-4.1)"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 244,
                "PatchRowcode": "+"
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 245,
                "PatchRowcode": "+        # chunked-body   = *chunk"
            },
            "116": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+        #                  last-chunk"
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 247,
                "PatchRowcode": "+        #                  trailer-part"
            },
            "118": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+        #                  CRLF"
            },
            "119": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+        #"
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+        # chunk          = chunk-size [ chunk-ext ] CRLF"
            },
            "121": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 251,
                "PatchRowcode": "+        #                  chunk-data CRLF"
            },
            "122": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 252,
                "PatchRowcode": "+        # chunk-size     = 1*HEXDIG"
            },
            "123": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 253,
                "PatchRowcode": "+        # last-chunk     = 1*(\"0\") [ chunk-ext ] CRLF"
            },
            "124": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 254,
                "PatchRowcode": "+        # trailer-part   = *( header-field CRLF )"
            },
            "125": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 255,
                "PatchRowcode": "+        # chunk-data     = 1*OCTET ; a sequence of chunk-size octets"
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 257,
                "PatchRowcode": "+        # To cope with malicious or broken clients that fail to send"
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+        # valid chunk lines, the strategy is to read character by"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+        # character until we either reach a ; or newline. If at any"
            },
            "130": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+        # time we read a non-HEX digit, we bail. If we hit a ;,"
            },
            "131": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+        # indicating an chunk-extension, we'll read up to the next"
            },
            "132": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+        # MAX_REQUEST_LINE characters (\"A server ought to limit the"
            },
            "133": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+        # total length of chunk extensions received\") looking for the"
            },
            "134": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+        # CRLF, and if we don't find it, we bail. If we read more than"
            },
            "135": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 265,
                "PatchRowcode": "+        # 16 hex characters, (the number needed to represent a 64-bit"
            },
            "136": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 266,
                "PatchRowcode": "+        # chunk size), we bail (this protects us from a client that"
            },
            "137": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 267,
                "PatchRowcode": "+        # sends an infinite stream of `F`, for example)."
            },
            "138": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 268,
                "PatchRowcode": " "
            },
            "139": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": 269,
                "PatchRowcode": "         buf = BytesIO()"
            },
            "140": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": 270,
                "PatchRowcode": "         while 1:"
            },
            "141": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 271,
                "PatchRowcode": "             char = rfile.read(1)"
            },
            "142": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": 272,
                "PatchRowcode": "             if not char:"
            },
            "143": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 273,
                "PatchRowcode": "                 self._chunked_input_error = True"
            },
            "144": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 274,
                "PatchRowcode": "                 raise _InvalidClientInput(\"EOF before chunk end reached\")"
            },
            "145": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if char == b'\\r':"
            },
            "146": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                break"
            },
            "147": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if char == b';':"
            },
            "148": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 275,
                "PatchRowcode": "+"
            },
            "149": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 276,
                "PatchRowcode": "+            if char in ("
            },
            "150": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 277,
                "PatchRowcode": "+                b'\\r', # Beginning EOL"
            },
            "151": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 278,
                "PatchRowcode": "+                b';', # Beginning extension"
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 279,
                "PatchRowcode": "+            ):"
            },
            "153": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 280,
                "PatchRowcode": "                 break"
            },
            "154": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 281,
                "PatchRowcode": " "
            },
            "155": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if char not in _HEX:"
            },
            "156": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 282,
                "PatchRowcode": "+            if char not in _HEX: # Invalid data."
            },
            "157": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": 283,
                "PatchRowcode": "                 self._chunked_input_error = True"
            },
            "158": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 284,
                "PatchRowcode": "                 raise _InvalidClientInput(\"Non-hex data\", char)"
            },
            "159": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 285,
                "PatchRowcode": "+"
            },
            "160": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 286,
                "PatchRowcode": "             buf.write(char)"
            },
            "161": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if buf.tell() > 16:"
            },
            "162": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 287,
                "PatchRowcode": "+"
            },
            "163": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 288,
                "PatchRowcode": "+            if buf.tell() > 16: # Too many hex bytes"
            },
            "164": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 289,
                "PatchRowcode": "                 self._chunked_input_error = True"
            },
            "165": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": 290,
                "PatchRowcode": "                 raise _InvalidClientInput(\"Chunk-size too large.\")"
            },
            "166": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": 291,
                "PatchRowcode": " "
            },
            "167": {
                "beforePatchRowNumber": 260,
                "afterPatchRowNumber": 305,
                "PatchRowcode": "         if char == b'\\r':"
            },
            "168": {
                "beforePatchRowNumber": 261,
                "afterPatchRowNumber": 306,
                "PatchRowcode": "             # We either got here from the main loop or from the"
            },
            "169": {
                "beforePatchRowNumber": 262,
                "afterPatchRowNumber": 307,
                "PatchRowcode": "             # end of an extension"
            },
            "170": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 308,
                "PatchRowcode": "+            self.__read_chunk_size_crlf(rfile, newline_only=True)"
            },
            "171": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 309,
                "PatchRowcode": "+            result = int(buf.getvalue(), 16)"
            },
            "172": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 310,
                "PatchRowcode": "+            if result == 0:"
            },
            "173": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 311,
                "PatchRowcode": "+                # The only time a chunk size of zero is allowed is the final"
            },
            "174": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 312,
                "PatchRowcode": "+                # chunk. It is either followed by another \\r\\n, or some trailers"
            },
            "175": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 313,
                "PatchRowcode": "+                # which are then followed by \\r\\n."
            },
            "176": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 314,
                "PatchRowcode": "+                while self.__read_chunk_trailer(rfile):"
            },
            "177": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 315,
                "PatchRowcode": "+                    pass"
            },
            "178": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 316,
                "PatchRowcode": "+            return result"
            },
            "179": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 317,
                "PatchRowcode": "+"
            },
            "180": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 318,
                "PatchRowcode": "+    # Trailers have the following production (they are a header-field followed by CRLF)"
            },
            "181": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 319,
                "PatchRowcode": "+    # See above for the definition of \"token\"."
            },
            "182": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 320,
                "PatchRowcode": "+    #"
            },
            "183": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 321,
                "PatchRowcode": "+    # header-field   = field-name \":\" OWS field-value OWS"
            },
            "184": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 322,
                "PatchRowcode": "+    # field-name     = token"
            },
            "185": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 323,
                "PatchRowcode": "+    # field-value    = *( field-content / obs-fold )"
            },
            "186": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 324,
                "PatchRowcode": "+    # field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]"
            },
            "187": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 325,
                "PatchRowcode": "+    # field-vchar    = VCHAR / obs-text"
            },
            "188": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 326,
                "PatchRowcode": "+    # obs-fold       = CRLF 1*( SP / HTAB )"
            },
            "189": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 327,
                "PatchRowcode": "+    #                ; obsolete line folding"
            },
            "190": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 328,
                "PatchRowcode": "+    #                ; see Section 3.2.4"
            },
            "191": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 329,
                "PatchRowcode": "+"
            },
            "192": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 330,
                "PatchRowcode": "+"
            },
            "193": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 331,
                "PatchRowcode": "+    def __read_chunk_trailer(self, rfile, ):"
            },
            "194": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 332,
                "PatchRowcode": "+        # With rfile positioned just after a \\r\\n, read a trailer line."
            },
            "195": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 333,
                "PatchRowcode": "+        # Return a true value if a non-empty trailer was read, and"
            },
            "196": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 334,
                "PatchRowcode": "+        # return false if an empty trailer was read (meaning the trailers are"
            },
            "197": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 335,
                "PatchRowcode": "+        # done)."
            },
            "198": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 336,
                "PatchRowcode": "+        # If a single line exceeds the MAX_REQUEST_LINE, raise an exception."
            },
            "199": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 337,
                "PatchRowcode": "+        # If the field-name portion contains invalid characters, raise an exception."
            },
            "200": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 338,
                "PatchRowcode": "+"
            },
            "201": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 339,
                "PatchRowcode": "+        i = 0"
            },
            "202": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 340,
                "PatchRowcode": "+        empty = True"
            },
            "203": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+        seen_field_name = False"
            },
            "204": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 342,
                "PatchRowcode": "+        while i < MAX_REQUEST_LINE:"
            },
            "205": {
                "beforePatchRowNumber": 263,
                "afterPatchRowNumber": 343,
                "PatchRowcode": "             char = rfile.read(1)"
            },
            "206": {
                "beforePatchRowNumber": 264,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if char != b'\\n':"
            },
            "207": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 344,
                "PatchRowcode": "+            if char == b'\\r':"
            },
            "208": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 345,
                "PatchRowcode": "+                # Either read the next \\n or raise an error."
            },
            "209": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 346,
                "PatchRowcode": "+                self.__read_chunk_size_crlf(rfile, newline_only=True)"
            },
            "210": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 347,
                "PatchRowcode": "+                break"
            },
            "211": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+            # Not a \\r, so we are NOT an empty chunk."
            },
            "212": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 349,
                "PatchRowcode": "+            empty = False"
            },
            "213": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 350,
                "PatchRowcode": "+            if char == b':' and i > 0:"
            },
            "214": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 351,
                "PatchRowcode": "+                # We're ending the field-name part; stop validating characters."
            },
            "215": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 352,
                "PatchRowcode": "+                # Unless : was the first character..."
            },
            "216": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 353,
                "PatchRowcode": "+                seen_field_name = True"
            },
            "217": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 354,
                "PatchRowcode": "+            if not seen_field_name and char not in _ALLOWED_TOKEN_CHARS:"
            },
            "218": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 355,
                "PatchRowcode": "+                raise _InvalidClientInput('Invalid token character: %r' % (char,))"
            },
            "219": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 356,
                "PatchRowcode": "+            i += 1"
            },
            "220": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 357,
                "PatchRowcode": "+        else:"
            },
            "221": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 358,
                "PatchRowcode": "+            # We read too much"
            },
            "222": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 359,
                "PatchRowcode": "+            self._chunked_input_error = True"
            },
            "223": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+            raise _InvalidClientInput(\"Too large chunk trailer\")"
            },
            "224": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 361,
                "PatchRowcode": "+        return not empty"
            },
            "225": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 362,
                "PatchRowcode": "+"
            },
            "226": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+    def __read_chunk_size_crlf(self, rfile, newline_only=False):"
            },
            "227": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+        # Also for safety, correctly verify that we get \\r\\n when expected."
            },
            "228": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+        if not newline_only:"
            },
            "229": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+            char = rfile.read(1)"
            },
            "230": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+            if char != b'\\r':"
            },
            "231": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": 368,
                "PatchRowcode": "                 self._chunked_input_error = True"
            },
            "232": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                raise _InvalidClientInput(\"Line didn't end in CRLF\")"
            },
            "233": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return int(buf.getvalue(), 16)"
            },
            "234": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+                raise _InvalidClientInput(\"Line didn't end in CRLF: %r\" % (char,))"
            },
            "235": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+        char = rfile.read(1)"
            },
            "236": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+        if char != b'\\n':"
            },
            "237": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+            self._chunked_input_error = True"
            },
            "238": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 373,
                "PatchRowcode": "+            raise _InvalidClientInput(\"Line didn't end in LF: %r\" % (char,))"
            },
            "239": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": 374,
                "PatchRowcode": " "
            },
            "240": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "     def _chunked_read(self, length=None, use_readline=False):"
            },
            "241": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": 376,
                "PatchRowcode": "         # pylint:disable=too-many-branches"
            },
            "242": {
                "beforePatchRowNumber": 297,
                "afterPatchRowNumber": 403,
                "PatchRowcode": " "
            },
            "243": {
                "beforePatchRowNumber": 298,
                "afterPatchRowNumber": 404,
                "PatchRowcode": "                 self.position += datalen"
            },
            "244": {
                "beforePatchRowNumber": 299,
                "afterPatchRowNumber": 405,
                "PatchRowcode": "                 if self.chunk_length == self.position:"
            },
            "245": {
                "beforePatchRowNumber": 300,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    rfile.readline()"
            },
            "246": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 406,
                "PatchRowcode": "+                    self.__read_chunk_size_crlf(rfile)"
            },
            "247": {
                "beforePatchRowNumber": 301,
                "afterPatchRowNumber": 407,
                "PatchRowcode": " "
            },
            "248": {
                "beforePatchRowNumber": 302,
                "afterPatchRowNumber": 408,
                "PatchRowcode": "                 if length is not None:"
            },
            "249": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 409,
                "PatchRowcode": "                     length -= datalen"
            },
            "250": {
                "beforePatchRowNumber": 310,
                "afterPatchRowNumber": 416,
                "PatchRowcode": "                 # determine the next size to read"
            },
            "251": {
                "beforePatchRowNumber": 311,
                "afterPatchRowNumber": 417,
                "PatchRowcode": "                 self.chunk_length = self.__read_chunk_length(rfile)"
            },
            "252": {
                "beforePatchRowNumber": 312,
                "afterPatchRowNumber": 418,
                "PatchRowcode": "                 self.position = 0"
            },
            "253": {
                "beforePatchRowNumber": 313,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if self.chunk_length == 0:"
            },
            "254": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    # Last chunk. Terminates with a CRLF."
            },
            "255": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    rfile.readline()"
            },
            "256": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 419,
                "PatchRowcode": "+                # If chunk_length was 0, we already read any trailers and"
            },
            "257": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 420,
                "PatchRowcode": "+                # validated that we have ended with \\r\\n\\r\\n."
            },
            "258": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 421,
                "PatchRowcode": "+"
            },
            "259": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": 422,
                "PatchRowcode": "         return b''.join(response)"
            },
            "260": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": 423,
                "PatchRowcode": " "
            },
            "261": {
                "beforePatchRowNumber": 318,
                "afterPatchRowNumber": 424,
                "PatchRowcode": "     def read(self, length=None):"
            },
            "262": {
                "beforePatchRowNumber": 531,
                "afterPatchRowNumber": 637,
                "PatchRowcode": "         elif len(words) == 2:"
            },
            "263": {
                "beforePatchRowNumber": 532,
                "afterPatchRowNumber": 638,
                "PatchRowcode": "             self.command, self.path = words"
            },
            "264": {
                "beforePatchRowNumber": 533,
                "afterPatchRowNumber": 639,
                "PatchRowcode": "             if self.command != \"GET\":"
            },
            "265": {
                "beforePatchRowNumber": 534,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                raise _InvalidClientRequest('Expected GET method: %r' % (raw_requestline,))"
            },
            "266": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 640,
                "PatchRowcode": "+                raise _InvalidClientRequest('Expected GET method; Got command=%r; path=%r; raw=%r' % ("
            },
            "267": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 641,
                "PatchRowcode": "+                    self.command, self.path, raw_requestline,))"
            },
            "268": {
                "beforePatchRowNumber": 535,
                "afterPatchRowNumber": 642,
                "PatchRowcode": "             self.request_version = \"HTTP/0.9\""
            },
            "269": {
                "beforePatchRowNumber": 536,
                "afterPatchRowNumber": 643,
                "PatchRowcode": "             # QQQ I'm pretty sure we can drop support for HTTP/0.9"
            },
            "270": {
                "beforePatchRowNumber": 537,
                "afterPatchRowNumber": 644,
                "PatchRowcode": "         else:"
            },
            "271": {
                "beforePatchRowNumber": 996,
                "afterPatchRowNumber": 1103,
                "PatchRowcode": "             finally:"
            },
            "272": {
                "beforePatchRowNumber": 997,
                "afterPatchRowNumber": 1104,
                "PatchRowcode": "                 try:"
            },
            "273": {
                "beforePatchRowNumber": 998,
                "afterPatchRowNumber": 1105,
                "PatchRowcode": "                     self.wsgi_input._discard()"
            },
            "274": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1106,
                "PatchRowcode": "+                except _InvalidClientInput:"
            },
            "275": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1107,
                "PatchRowcode": "+                    # This one is deliberately raised to the outer"
            },
            "276": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1108,
                "PatchRowcode": "+                    # scope, because, with the incoming stream in some bad state,"
            },
            "277": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1109,
                "PatchRowcode": "+                    # we can't be sure we can synchronize and properly parse the next"
            },
            "278": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1110,
                "PatchRowcode": "+                    # request."
            },
            "279": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1111,
                "PatchRowcode": "+                    raise"
            },
            "280": {
                "beforePatchRowNumber": 999,
                "afterPatchRowNumber": 1112,
                "PatchRowcode": "                 except socket.error:"
            },
            "281": {
                "beforePatchRowNumber": 1000,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    # Don't let exceptions during discarding"
            },
            "282": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1113,
                "PatchRowcode": "+                    # Don't let socket exceptions during discarding"
            },
            "283": {
                "beforePatchRowNumber": 1001,
                "afterPatchRowNumber": 1114,
                "PatchRowcode": "                     # input override any exception that may have been"
            },
            "284": {
                "beforePatchRowNumber": 1002,
                "afterPatchRowNumber": 1115,
                "PatchRowcode": "                     # raised by the application, such as our own _InvalidClientInput."
            },
            "285": {
                "beforePatchRowNumber": 1003,
                "afterPatchRowNumber": 1116,
                "PatchRowcode": "                     # In the general case, these aren't even worth logging (see the comment"
            },
            "286": {
                "beforePatchRowNumber": 1004,
                "afterPatchRowNumber": 1117,
                "PatchRowcode": "                     # just below)"
            },
            "287": {
                "beforePatchRowNumber": 1005,
                "afterPatchRowNumber": 1118,
                "PatchRowcode": "                     pass"
            },
            "288": {
                "beforePatchRowNumber": 1006,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except _InvalidClientInput:"
            },
            "289": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1119,
                "PatchRowcode": "+        except _InvalidClientInput as ex:"
            },
            "290": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1120,
                "PatchRowcode": "+            # DO log this one because:"
            },
            "291": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1121,
                "PatchRowcode": "+            # - Some of the data may have been read and acted on by the"
            },
            "292": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1122,
                "PatchRowcode": "+            #   application;"
            },
            "293": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1123,
                "PatchRowcode": "+            # - The response may or may not have been sent;"
            },
            "294": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1124,
                "PatchRowcode": "+            # - It's likely that the client is bad, or malicious, and"
            },
            "295": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1125,
                "PatchRowcode": "+            #   users might wish to take steps to block the client."
            },
            "296": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1126,
                "PatchRowcode": "+            self._handle_client_error(ex)"
            },
            "297": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1127,
                "PatchRowcode": "+            self.close_connection = True"
            },
            "298": {
                "beforePatchRowNumber": 1007,
                "afterPatchRowNumber": 1128,
                "PatchRowcode": "             self._send_error_response_if_possible(400)"
            },
            "299": {
                "beforePatchRowNumber": 1008,
                "afterPatchRowNumber": 1129,
                "PatchRowcode": "         except socket.error as ex:"
            },
            "300": {
                "beforePatchRowNumber": 1009,
                "afterPatchRowNumber": 1130,
                "PatchRowcode": "             if ex.args[0] in self.ignored_socket_errors:"
            },
            "301": {
                "beforePatchRowNumber": 1046,
                "afterPatchRowNumber": 1167,
                "PatchRowcode": "     def _handle_client_error(self, ex):"
            },
            "302": {
                "beforePatchRowNumber": 1047,
                "afterPatchRowNumber": 1168,
                "PatchRowcode": "         # Called for invalid client input"
            },
            "303": {
                "beforePatchRowNumber": 1048,
                "afterPatchRowNumber": 1169,
                "PatchRowcode": "         # Returns the appropriate error response."
            },
            "304": {
                "beforePatchRowNumber": 1049,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if not isinstance(ex, ValueError):"
            },
            "305": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1170,
                "PatchRowcode": "+        if not isinstance(ex, (ValueError, _InvalidClientInput)):"
            },
            "306": {
                "beforePatchRowNumber": 1050,
                "afterPatchRowNumber": 1171,
                "PatchRowcode": "             # XXX: Why not self._log_error to send it through the loop's"
            },
            "307": {
                "beforePatchRowNumber": 1051,
                "afterPatchRowNumber": 1172,
                "PatchRowcode": "             # handle_error method?"
            },
            "308": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1173,
                "PatchRowcode": "+            # _InvalidClientRequest is a ValueError; _InvalidClientInput is an IOError."
            },
            "309": {
                "beforePatchRowNumber": 1052,
                "afterPatchRowNumber": 1174,
                "PatchRowcode": "             traceback.print_exc()"
            },
            "310": {
                "beforePatchRowNumber": 1053,
                "afterPatchRowNumber": 1175,
                "PatchRowcode": "         if isinstance(ex, _InvalidClientRequest):"
            },
            "311": {
                "beforePatchRowNumber": 1054,
                "afterPatchRowNumber": 1176,
                "PatchRowcode": "             # No formatting needed, that's already been handled. In fact, because the"
            },
            "312": {
                "beforePatchRowNumber": 1055,
                "afterPatchRowNumber": 1177,
                "PatchRowcode": "             # formatted message contains user input, it might have a % in it, and attempting"
            },
            "313": {
                "beforePatchRowNumber": 1056,
                "afterPatchRowNumber": 1178,
                "PatchRowcode": "             # to format that with no arguments would be an error."
            },
            "314": {
                "beforePatchRowNumber": 1057,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.log_error(ex.formatted_message)"
            },
            "315": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1179,
                "PatchRowcode": "+            # However, the error messages do not include the requesting IP"
            },
            "316": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1180,
                "PatchRowcode": "+            # necessarily, so we do add that."
            },
            "317": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1181,
                "PatchRowcode": "+            self.log_error('(from %s) %s', self.client_address, ex.formatted_message)"
            },
            "318": {
                "beforePatchRowNumber": 1058,
                "afterPatchRowNumber": 1182,
                "PatchRowcode": "         else:"
            },
            "319": {
                "beforePatchRowNumber": 1059,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.log_error('Invalid request: %s', str(ex) or ex.__class__.__name__)"
            },
            "320": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1183,
                "PatchRowcode": "+            self.log_error('Invalid request (from %s): %s',"
            },
            "321": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1184,
                "PatchRowcode": "+                           self.client_address,"
            },
            "322": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1185,
                "PatchRowcode": "+                           str(ex) or ex.__class__.__name__)"
            },
            "323": {
                "beforePatchRowNumber": 1060,
                "afterPatchRowNumber": 1186,
                "PatchRowcode": "         return ('400', _BAD_REQUEST_RESPONSE)"
            },
            "324": {
                "beforePatchRowNumber": 1061,
                "afterPatchRowNumber": 1187,
                "PatchRowcode": " "
            },
            "325": {
                "beforePatchRowNumber": 1062,
                "afterPatchRowNumber": 1188,
                "PatchRowcode": "     def _headers(self):"
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2005-2009, eventlet contributors",
            "# Copyright (c) 2009-2018, gevent contributors",
            "\"\"\"",
            "A pure-Python, gevent-friendly WSGI server implementing HTTP/1.1.",
            "",
            "The server is provided in :class:`WSGIServer`, but most of the actual",
            "WSGI work is handled by :class:`WSGIHandler` --- a new instance is",
            "created for each request. The server can be customized to use",
            "different subclasses of :class:`WSGIHandler`.",
            "",
            ".. important::",
            "",
            "   This server is intended primarily for development and testing, and",
            "   secondarily for other \"safe\" scenarios where it will not be exposed to",
            "   potentially malicious input. The code has not been security audited,",
            "   and is not intended for direct exposure to the public Internet.",
            "",
            "\"\"\"",
            "from __future__ import absolute_import",
            "",
            "# FIXME: Can we refactor to make smallor?",
            "# pylint:disable=too-many-lines",
            "",
            "import errno",
            "from io import BytesIO",
            "import string",
            "import sys",
            "import time",
            "import traceback",
            "from datetime import datetime",
            "",
            "try:",
            "    from urllib import unquote",
            "except ImportError:",
            "    from urllib.parse import unquote # python 2 pylint:disable=import-error,no-name-in-module",
            "",
            "from gevent import socket",
            "import gevent",
            "from gevent.server import StreamServer",
            "from gevent.hub import GreenletExit",
            "from gevent._compat import reraise",
            "",
            "from functools import partial",
            "unquote_latin1 = partial(unquote, encoding='latin-1')",
            "",
            "_no_undoc_members = True # Don't put undocumented things into sphinx",
            "",
            "__all__ = [",
            "    'WSGIServer',",
            "    'WSGIHandler',",
            "    'LoggingLogAdapter',",
            "    'Environ',",
            "    'SecureEnviron',",
            "    'WSGISecureEnviron',",
            "]",
            "",
            "",
            "MAX_REQUEST_LINE = 8192",
            "# Weekday and month names for HTTP date/time formatting; always English!",
            "_WEEKDAYNAME = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]",
            "_MONTHNAME = [None,  # Dummy so we can use 1-based month numbers",
            "              \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",",
            "              \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]",
            "",
            "# The contents of the \"HEX\" grammar rule for HTTP, upper and lowercase A-F plus digits,",
            "# in byte form for comparing to the network.",
            "_HEX = string.hexdigits.encode('ascii')",
            "",
            "# Errors",
            "_ERRORS = {}",
            "_INTERNAL_ERROR_STATUS = '500 Internal Server Error'",
            "_INTERNAL_ERROR_BODY = b'Internal Server Error'",
            "_INTERNAL_ERROR_HEADERS = [('Content-Type', 'text/plain'),",
            "                           ('Connection', 'close'),",
            "                           ('Content-Length', str(len(_INTERNAL_ERROR_BODY)))]",
            "_ERRORS[500] = (_INTERNAL_ERROR_STATUS, _INTERNAL_ERROR_HEADERS, _INTERNAL_ERROR_BODY)",
            "",
            "_BAD_REQUEST_STATUS = '400 Bad Request'",
            "_BAD_REQUEST_BODY = ''",
            "_BAD_REQUEST_HEADERS = [('Content-Type', 'text/plain'),",
            "                        ('Connection', 'close'),",
            "                        ('Content-Length', str(len(_BAD_REQUEST_BODY)))]",
            "_ERRORS[400] = (_BAD_REQUEST_STATUS, _BAD_REQUEST_HEADERS, _BAD_REQUEST_BODY)",
            "",
            "_REQUEST_TOO_LONG_RESPONSE = b\"HTTP/1.1 414 Request URI Too Long\\r\\nConnection: close\\r\\nContent-length: 0\\r\\n\\r\\n\"",
            "_BAD_REQUEST_RESPONSE = b\"HTTP/1.1 400 Bad Request\\r\\nConnection: close\\r\\nContent-length: 0\\r\\n\\r\\n\"",
            "_CONTINUE_RESPONSE = b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\"",
            "",
            "",
            "def format_date_time(timestamp):",
            "    # Return a byte-string of the date and time in HTTP format",
            "    # .. versionchanged:: 1.1b5",
            "    #  Return a byte string, not a native string",
            "    year, month, day, hh, mm, ss, wd, _y, _z = time.gmtime(timestamp)",
            "    value = \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (_WEEKDAYNAME[wd], day, _MONTHNAME[month], year, hh, mm, ss)",
            "    value = value.encode(\"latin-1\")",
            "    return value",
            "",
            "",
            "class _InvalidClientInput(IOError):",
            "    # Internal exception raised by Input indicating that the client",
            "    # sent invalid data at the lowest level of the stream. The result",
            "    # *should* be a HTTP 400 error.",
            "    pass",
            "",
            "",
            "class _InvalidClientRequest(ValueError):",
            "    # Internal exception raised by WSGIHandler.read_request indicating",
            "    # that the client sent an HTTP request that cannot be parsed",
            "    # (e.g., invalid grammar). The result *should* be an HTTP 400",
            "    # error. It must have exactly one argument, the fully formatted",
            "    # error string.",
            "",
            "    def __init__(self, message):",
            "        ValueError.__init__(self, message)",
            "        self.formatted_message = message",
            "",
            "",
            "class Input(object):",
            "",
            "    __slots__ = ('rfile', 'content_length', 'socket', 'position',",
            "                 'chunked_input', 'chunk_length', '_chunked_input_error')",
            "",
            "    def __init__(self, rfile, content_length, socket=None, chunked_input=False):",
            "        # pylint:disable=redefined-outer-name",
            "        self.rfile = rfile",
            "        self.content_length = content_length",
            "        self.socket = socket",
            "        self.position = 0",
            "        self.chunked_input = chunked_input",
            "        self.chunk_length = -1",
            "        self._chunked_input_error = False",
            "",
            "    def _discard(self):",
            "        if self._chunked_input_error:",
            "            # We are in an unknown state, so we can't necessarily discard",
            "            # the body (e.g., if the client keeps the socket open, we could hang",
            "            # here forever).",
            "            # In this case, we've raised an exception and the user of this object",
            "            # is going to close the socket, so we don't have to discard",
            "            return",
            "",
            "        if self.socket is None and (self.position < (self.content_length or 0) or self.chunked_input):",
            "            # ## Read and discard body",
            "            while 1:",
            "                d = self.read(16384)",
            "                if not d:",
            "                    break",
            "",
            "    def _send_100_continue(self):",
            "        if self.socket is not None:",
            "            self.socket.sendall(_CONTINUE_RESPONSE)",
            "            self.socket = None",
            "",
            "    def _do_read(self, length=None, use_readline=False):",
            "        if use_readline:",
            "            reader = self.rfile.readline",
            "        else:",
            "            reader = self.rfile.read",
            "        content_length = self.content_length",
            "        if content_length is None:",
            "            # Either Content-Length or \"Transfer-Encoding: chunked\" must be present in a request with a body",
            "            # if it was chunked, then this function would have not been called",
            "            return b''",
            "",
            "        self._send_100_continue()",
            "        left = content_length - self.position",
            "        if length is None:",
            "            length = left",
            "        elif length > left:",
            "            length = left",
            "        if not length:",
            "            return b''",
            "",
            "        # On Python 2, self.rfile is usually socket.makefile(), which",
            "        # uses cStringIO.StringIO. If *length* is greater than the C",
            "        # sizeof(int) (typically 32 bits signed), parsing the argument to",
            "        # readline raises OverflowError. StringIO.read(), OTOH, uses",
            "        # PySize_t, typically a long (64 bits). In a bare readline()",
            "        # case, because the header lines we're trying to read with",
            "        # readline are typically expected to be small, we can correct",
            "        # that failure by simply doing a smaller call to readline and",
            "        # appending; failures in read we let propagate.",
            "        try:",
            "            read = reader(length)",
            "        except OverflowError:",
            "            if not use_readline:",
            "                # Expecting to read more than 64 bits of data. Ouch!",
            "                raise",
            "            # We could loop on calls to smaller readline(), appending them",
            "            # until we actually get a newline. For uses in this module,",
            "            # we expect the actual length to be small, but WSGI applications",
            "            # are allowed to pass in an arbitrary length. (This loop isn't optimal,",
            "            # but even client applications *probably* have short lines.)",
            "            read = b''",
            "            while len(read) < length and not read.endswith(b'\\n'):",
            "                read += reader(MAX_REQUEST_LINE)",
            "",
            "        self.position += len(read)",
            "        if len(read) < length:",
            "            if (use_readline and not read.endswith(b\"\\n\")) or not use_readline:",
            "                raise IOError(\"unexpected end of file while reading request at position %s\" % (self.position,))",
            "",
            "        return read",
            "",
            "    def __read_chunk_length(self, rfile):",
            "        # Read and return the next integer chunk length. If no",
            "        # chunk length can be read, raises _InvalidClientInput.",
            "",
            "        # Here's the production for a chunk:",
            "        # (http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html)",
            "        #   chunk          = chunk-size [ chunk-extension ] CRLF",
            "        #                    chunk-data CRLF",
            "        #   chunk-size     = 1*HEX",
            "        #   chunk-extension= *( \";\" chunk-ext-name [ \"=\" chunk-ext-val ] )",
            "        #   chunk-ext-name = token",
            "        #   chunk-ext-val  = token | quoted-string",
            "",
            "        # To cope with malicious or broken clients that fail to send valid",
            "        # chunk lines, the strategy is to read character by character until we either reach",
            "        # a ; or newline. If at any time we read a non-HEX digit, we bail. If we hit a",
            "        # ;, indicating an chunk-extension, we'll read up to the next",
            "        # MAX_REQUEST_LINE characters",
            "        # looking for the CRLF, and if we don't find it, we bail. If we read more than 16 hex characters,",
            "        # (the number needed to represent a 64-bit chunk size), we bail (this protects us from",
            "        # a client that sends an infinite stream of `F`, for example).",
            "",
            "        buf = BytesIO()",
            "        while 1:",
            "            char = rfile.read(1)",
            "            if not char:",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"EOF before chunk end reached\")",
            "            if char == b'\\r':",
            "                break",
            "            if char == b';':",
            "                break",
            "",
            "            if char not in _HEX:",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Non-hex data\", char)",
            "            buf.write(char)",
            "            if buf.tell() > 16:",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Chunk-size too large.\")",
            "",
            "        if char == b';':",
            "            i = 0",
            "            while i < MAX_REQUEST_LINE:",
            "                char = rfile.read(1)",
            "                if char == b'\\r':",
            "                    break",
            "                i += 1",
            "            else:",
            "                # we read more than MAX_REQUEST_LINE without",
            "                # hitting CR",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Too large chunk extension\")",
            "",
            "        if char == b'\\r':",
            "            # We either got here from the main loop or from the",
            "            # end of an extension",
            "            char = rfile.read(1)",
            "            if char != b'\\n':",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Line didn't end in CRLF\")",
            "            return int(buf.getvalue(), 16)",
            "",
            "    def _chunked_read(self, length=None, use_readline=False):",
            "        # pylint:disable=too-many-branches",
            "        rfile = self.rfile",
            "        self._send_100_continue()",
            "",
            "        if length == 0:",
            "            return b\"\"",
            "",
            "        if use_readline:",
            "            reader = self.rfile.readline",
            "        else:",
            "            reader = self.rfile.read",
            "",
            "        response = []",
            "        while self.chunk_length != 0:",
            "            maxreadlen = self.chunk_length - self.position",
            "            if length is not None and length < maxreadlen:",
            "                maxreadlen = length",
            "",
            "            if maxreadlen > 0:",
            "                data = reader(maxreadlen)",
            "                if not data:",
            "                    self.chunk_length = 0",
            "                    self._chunked_input_error = True",
            "                    raise IOError(\"unexpected end of file while parsing chunked data\")",
            "",
            "                datalen = len(data)",
            "                response.append(data)",
            "",
            "                self.position += datalen",
            "                if self.chunk_length == self.position:",
            "                    rfile.readline()",
            "",
            "                if length is not None:",
            "                    length -= datalen",
            "                    if length == 0:",
            "                        break",
            "                if use_readline and data[-1] == b\"\\n\"[0]:",
            "                    break",
            "            else:",
            "                # We're at the beginning of a chunk, so we need to",
            "                # determine the next size to read",
            "                self.chunk_length = self.__read_chunk_length(rfile)",
            "                self.position = 0",
            "                if self.chunk_length == 0:",
            "                    # Last chunk. Terminates with a CRLF.",
            "                    rfile.readline()",
            "        return b''.join(response)",
            "",
            "    def read(self, length=None):",
            "        if length is not None and length < 0:",
            "            length = None",
            "        if self.chunked_input:",
            "            return self._chunked_read(length)",
            "        return self._do_read(length)",
            "",
            "    def readline(self, size=None):",
            "        if size is not None and size < 0:",
            "            size = None",
            "        if self.chunked_input:",
            "            return self._chunked_read(size, True)",
            "        return self._do_read(size, use_readline=True)",
            "",
            "    def readlines(self, hint=None):",
            "        # pylint:disable=unused-argument",
            "        return list(self)",
            "",
            "    def __iter__(self):",
            "        return self",
            "",
            "    def next(self):",
            "        line = self.readline()",
            "        if not line:",
            "            raise StopIteration",
            "        return line",
            "    __next__ = next",
            "",
            "",
            "try:",
            "    import mimetools",
            "    headers_factory = mimetools.Message",
            "except ImportError:",
            "    # adapt Python 3 HTTP headers to old API",
            "    from http import client # pylint:disable=import-error",
            "",
            "    class OldMessage(client.HTTPMessage):",
            "        def __init__(self, **kwargs):",
            "            super(client.HTTPMessage, self).__init__(**kwargs) # pylint:disable=bad-super-call",
            "            self.status = ''",
            "",
            "        def getheader(self, name, default=None):",
            "            return self.get(name, default)",
            "",
            "        @property",
            "        def headers(self):",
            "            for key, value in self._headers:",
            "                yield '%s: %s\\r\\n' % (key, value)",
            "",
            "        @property",
            "        def typeheader(self):",
            "            return self.get('content-type')",
            "",
            "    def headers_factory(fp, *args): # pylint:disable=unused-argument",
            "        try:",
            "            ret = client.parse_headers(fp, _class=OldMessage)",
            "        except client.LineTooLong:",
            "            ret = OldMessage()",
            "            ret.status = 'Line too long'",
            "        return ret",
            "",
            "",
            "class WSGIHandler(object):",
            "    \"\"\"",
            "    Handles HTTP requests from a socket, creates the WSGI environment, and",
            "    interacts with the WSGI application.",
            "",
            "    This is the default value of :attr:`WSGIServer.handler_class`.",
            "    This class may be subclassed carefully, and that class set on a",
            "    :class:`WSGIServer` instance through a keyword argument at",
            "    construction time.",
            "",
            "    Instances are constructed with the same arguments as passed to the",
            "    server's :meth:`WSGIServer.handle` method followed by the server",
            "    itself. The application and environment are obtained from the server.",
            "",
            "    \"\"\"",
            "    # pylint:disable=too-many-instance-attributes",
            "",
            "    protocol_version = 'HTTP/1.1'",
            "",
            "    def MessageClass(self, *args):",
            "        return headers_factory(*args)",
            "",
            "    # Attributes reset at various times for each request; not public",
            "    # documented. Class attributes to keep the constructor fast",
            "    # (but not make lint tools complain)",
            "",
            "    status = None # byte string: b'200 OK'",
            "    _orig_status = None # native string: '200 OK'",
            "    response_headers = None # list of tuples (b'name', b'value')",
            "    code = None # Integer parsed from status",
            "    provided_date = None",
            "    provided_content_length = None",
            "    close_connection = False",
            "    time_start = 0 # time.time() when begin handling request",
            "    time_finish = 0 # time.time() when done handling request",
            "    headers_sent = False # Have we already sent headers?",
            "    response_use_chunked = False # Write with transfer-encoding chunked",
            "    # Was the connection upgraded? We shouldn't try to chunk writes in that",
            "    # case.",
            "    connection_upgraded = False",
            "    environ = None # Dict from self.get_environ",
            "    application = None # application callable from self.server.application",
            "    requestline = None # native str 'GET / HTTP/1.1'",
            "    response_length = 0 # How much data we sent",
            "    result = None # The return value of the WSGI application",
            "    wsgi_input = None # Instance of Input()",
            "    content_length = 0 # From application-provided headers Incoming",
            "    # request headers, instance of MessageClass (gunicorn uses hasattr",
            "    # on this so the default value needs to be compatible with the",
            "    # API)",
            "    headers = headers_factory(BytesIO())",
            "    request_version = None # str: 'HTTP 1.1'",
            "    command = None # str: 'GET'",
            "    path = None # str: '/'",
            "",
            "    def __init__(self, sock, address, server, rfile=None):",
            "        # Deprecation: The rfile kwarg was introduced in 1.0a1 as part",
            "        # of a refactoring. It was never documented or used. It is",
            "        # considered DEPRECATED and may be removed in the future. Its",
            "        # use is not supported.",
            "",
            "        self.socket = sock",
            "        self.client_address = address",
            "        self.server = server",
            "        if rfile is None:",
            "            self.rfile = sock.makefile('rb', -1)",
            "        else:",
            "            self.rfile = rfile",
            "",
            "    def handle(self):",
            "        \"\"\"",
            "        The main request handling method, called by the server.",
            "",
            "        This method runs a request handling loop, calling",
            "        :meth:`handle_one_request` until all requests on the",
            "        connection have been handled (that is, it implements",
            "        keep-alive).",
            "        \"\"\"",
            "        try:",
            "            while self.socket is not None:",
            "                self.time_start = time.time()",
            "                self.time_finish = 0",
            "",
            "                result = self.handle_one_request()",
            "                if result is None:",
            "                    break",
            "                if result is True:",
            "                    continue",
            "",
            "                self.status, response_body = result # pylint:disable=unpacking-non-sequence",
            "                self.socket.sendall(response_body)",
            "                if self.time_finish == 0:",
            "                    self.time_finish = time.time()",
            "                self.log_request()",
            "                break",
            "        finally:",
            "            if self.socket is not None:",
            "                _sock = getattr(self.socket, '_sock', None) # Python 3",
            "                try:",
            "                    # read out request data to prevent error: [Errno 104] Connection reset by peer",
            "                    if _sock:",
            "                        try:",
            "                            # socket.recv would hang",
            "                            _sock.recv(16384)",
            "                        finally:",
            "                            _sock.close()",
            "                    self.socket.close()",
            "                except socket.error:",
            "                    pass",
            "            self.__dict__.pop('socket', None)",
            "            self.__dict__.pop('rfile', None)",
            "            self.__dict__.pop('wsgi_input', None)",
            "",
            "    def _check_http_version(self):",
            "        version_str = self.request_version",
            "        if not version_str.startswith(\"HTTP/\"):",
            "            return False",
            "        version = tuple(int(x) for x in version_str[5:].split(\".\"))  # \"HTTP/\"",
            "        if version[1] < 0 or version < (0, 9) or version >= (2, 0):",
            "            return False",
            "        return True",
            "",
            "    def read_request(self, raw_requestline):",
            "        \"\"\"",
            "        Parse the incoming request.",
            "",
            "        Parses various headers into ``self.headers`` using",
            "        :attr:`MessageClass`. Other attributes that are set upon a successful",
            "        return of this method include ``self.content_length`` and ``self.close_connection``.",
            "",
            "        :param str raw_requestline: A native :class:`str` representing",
            "           the request line. A processed version of this will be stored",
            "           into ``self.requestline``.",
            "",
            "        :raises ValueError: If the request is invalid. This error will",
            "           not be logged as a traceback (because it's a client issue, not a server problem).",
            "        :return: A boolean value indicating whether the request was successfully parsed.",
            "           This method should either return a true value or have raised a ValueError",
            "           with details about the parsing error.",
            "",
            "        .. versionchanged:: 1.1b6",
            "           Raise the previously documented :exc:`ValueError` in more cases instead of returning a",
            "           false value; this allows subclasses more opportunity to customize behaviour.",
            "        \"\"\"",
            "        # pylint:disable=too-many-branches",
            "        self.requestline = raw_requestline.rstrip()",
            "        words = self.requestline.split()",
            "        if len(words) == 3:",
            "            self.command, self.path, self.request_version = words",
            "            if not self._check_http_version():",
            "                raise _InvalidClientRequest('Invalid http version: %r' % (raw_requestline,))",
            "        elif len(words) == 2:",
            "            self.command, self.path = words",
            "            if self.command != \"GET\":",
            "                raise _InvalidClientRequest('Expected GET method: %r' % (raw_requestline,))",
            "            self.request_version = \"HTTP/0.9\"",
            "            # QQQ I'm pretty sure we can drop support for HTTP/0.9",
            "        else:",
            "            raise _InvalidClientRequest('Invalid HTTP method: %r' % (raw_requestline,))",
            "",
            "        self.headers = self.MessageClass(self.rfile, 0)",
            "",
            "        if self.headers.status:",
            "            raise _InvalidClientRequest('Invalid headers status: %r' % (self.headers.status,))",
            "",
            "        if self.headers.get(\"transfer-encoding\", \"\").lower() == \"chunked\":",
            "            try:",
            "                del self.headers[\"content-length\"]",
            "            except KeyError:",
            "                pass",
            "",
            "        content_length = self.headers.get(\"content-length\")",
            "        if content_length is not None:",
            "            content_length = int(content_length)",
            "            if content_length < 0:",
            "                raise _InvalidClientRequest('Invalid Content-Length: %r' % (content_length,))",
            "",
            "            if content_length and self.command in ('HEAD', ):",
            "                raise _InvalidClientRequest('Unexpected Content-Length')",
            "",
            "        self.content_length = content_length",
            "",
            "        if self.request_version == \"HTTP/1.1\":",
            "            conntype = self.headers.get(\"Connection\", \"\").lower()",
            "            self.close_connection = (conntype == 'close') # pylint:disable=superfluous-parens",
            "        elif self.request_version == 'HTTP/1.0':",
            "            conntype = self.headers.get(\"Connection\", \"close\").lower()",
            "            self.close_connection = (conntype != 'keep-alive') # pylint:disable=superfluous-parens",
            "        else:",
            "            # XXX: HTTP 0.9. We should drop support",
            "            self.close_connection = True",
            "",
            "        return True",
            "",
            "    _print_unexpected_exc = staticmethod(traceback.print_exc)",
            "",
            "    def log_error(self, msg, *args):",
            "        if not args:",
            "            # Already fully formatted, no need to do it again; msg",
            "            # might contain % chars that would lead to a formatting",
            "            # error.",
            "            message = msg",
            "        else:",
            "            try:",
            "                message = msg % args",
            "            except Exception: # pylint:disable=broad-except",
            "                self._print_unexpected_exc()",
            "                message = '%r %r' % (msg, args)",
            "        try:",
            "            message = '%s: %s' % (self.socket, message)",
            "        except Exception: # pylint:disable=broad-except",
            "            pass",
            "",
            "        try:",
            "            self.server.error_log.write(message + '\\n')",
            "        except Exception: # pylint:disable=broad-except",
            "            self._print_unexpected_exc()",
            "",
            "    def read_requestline(self):",
            "        \"\"\"",
            "        Read and return the HTTP request line.",
            "",
            "        Under both Python 2 and 3, this should return the native",
            "        ``str`` type; under Python 3, this probably means the bytes read",
            "        from the network need to be decoded (using the ISO-8859-1 charset, aka",
            "        latin-1).",
            "        \"\"\"",
            "        line = self.rfile.readline(MAX_REQUEST_LINE)",
            "        line = line.decode('latin-1')",
            "        return line",
            "",
            "    def handle_one_request(self):",
            "        \"\"\"",
            "        Handles one HTTP request using ``self.socket`` and ``self.rfile``.",
            "",
            "        Each invocation of this method will do several things, including (but not limited to):",
            "",
            "        - Read the request line using :meth:`read_requestline`;",
            "        - Read the rest of the request, including headers, with :meth:`read_request`;",
            "        - Construct a new WSGI environment in ``self.environ`` using :meth:`get_environ`;",
            "        - Store the application in ``self.application``, retrieving it from the server;",
            "        - Handle the remainder of the request, including invoking the application,",
            "          with :meth:`handle_one_response`",
            "",
            "        There are several possible return values to indicate the state",
            "        of the client connection:",
            "",
            "        - ``None``",
            "            The client connection is already closed or should",
            "            be closed because the WSGI application or client set the",
            "            ``Connection: close`` header. The request handling",
            "            loop should terminate and perform cleanup steps.",
            "        - (status, body)",
            "            An HTTP status and body tuple. The request was in error,",
            "            as detailed by the status and body. The request handling",
            "            loop should terminate, close the connection, and perform",
            "            cleanup steps. Note that the ``body`` is the complete contents",
            "            to send to the client, including all headers and the initial",
            "            status line.",
            "        - ``True``",
            "            The literal ``True`` value. The request was successfully handled",
            "            and the response sent to the client by :meth:`handle_one_response`.",
            "            The connection remains open to process more requests and the connection",
            "            handling loop should call this method again. This is the typical return",
            "            value.",
            "",
            "        .. seealso:: :meth:`handle`",
            "",
            "        .. versionchanged:: 1.1b6",
            "           Funnel exceptions having to do with invalid HTTP requests through",
            "           :meth:`_handle_client_error` to allow subclasses to customize. Note that",
            "           this is experimental and may change in the future.",
            "        \"\"\"",
            "        # pylint:disable=too-many-return-statements",
            "        if self.rfile.closed:",
            "            return",
            "",
            "        try:",
            "            self.requestline = self.read_requestline()",
            "            # Account for old subclasses that haven't done this",
            "            if isinstance(self.requestline, bytes):",
            "                self.requestline = self.requestline.decode('latin-1')",
            "        except socket.error:",
            "            # \"Connection reset by peer\" or other socket errors aren't interesting here",
            "            return",
            "",
            "        if not self.requestline:",
            "            return",
            "",
            "        self.response_length = 0",
            "",
            "        if len(self.requestline) >= MAX_REQUEST_LINE:",
            "            return ('414', _REQUEST_TOO_LONG_RESPONSE)",
            "",
            "        try:",
            "            # for compatibility with older versions of pywsgi, we pass self.requestline as an argument there",
            "            # NOTE: read_request is supposed to raise ValueError on invalid input; allow old",
            "            # subclasses that return a False value instead.",
            "            # NOTE: This can mutate the value of self.headers, so self.get_environ() must not be",
            "            # called until AFTER this call is done.",
            "            if not self.read_request(self.requestline):",
            "                return ('400', _BAD_REQUEST_RESPONSE)",
            "        except Exception as ex: # pylint:disable=broad-except",
            "            # Notice we don't use self.handle_error because it reports",
            "            # a 500 error to the client, and this is almost certainly",
            "            # a client error.",
            "            # Provide a hook for subclasses.",
            "            return self._handle_client_error(ex)",
            "",
            "        self.environ = self.get_environ()",
            "        self.application = self.server.application",
            "",
            "        self.handle_one_response()",
            "",
            "        if self.close_connection:",
            "            return",
            "",
            "        if self.rfile.closed:",
            "            return",
            "",
            "        return True  # read more requests",
            "",
            "    def _connection_upgrade_requested(self):",
            "        if self.headers.get('Connection', '').lower() == 'upgrade':",
            "            return True",
            "        if self.headers.get('Upgrade', '').lower() == 'websocket':",
            "            return True",
            "        return False",
            "",
            "    def finalize_headers(self):",
            "        if self.provided_date is None:",
            "            self.response_headers.append((b'Date', format_date_time(time.time())))",
            "",
            "        self.connection_upgraded = self.code == 101",
            "",
            "        if self.code not in (304, 204):",
            "            # the reply will include message-body; make sure we have either Content-Length or chunked",
            "            if self.provided_content_length is None:",
            "                if hasattr(self.result, '__len__'):",
            "                    total_len = sum(len(chunk) for chunk in self.result)",
            "                    total_len_str = str(total_len)",
            "                    total_len_str = total_len_str.encode(\"latin-1\")",
            "                    self.response_headers.append((b'Content-Length', total_len_str))",
            "                else:",
            "                    self.response_use_chunked = (",
            "                        not self.connection_upgraded",
            "                        and self.request_version != 'HTTP/1.0'",
            "                    )",
            "                    if self.response_use_chunked:",
            "                        self.response_headers.append((b'Transfer-Encoding', b'chunked'))",
            "",
            "    def _sendall(self, data):",
            "        try:",
            "            self.socket.sendall(data)",
            "        except socket.error as ex:",
            "            self.status = 'socket error: %s' % ex",
            "            if self.code > 0:",
            "                self.code = -self.code",
            "            raise",
            "        self.response_length += len(data)",
            "",
            "    def _write(self, data,",
            "               _bytearray=bytearray):",
            "        if not data:",
            "            # The application/middleware are allowed to yield",
            "            # empty bytestrings.",
            "            return",
            "",
            "        if self.response_use_chunked:",
            "            # Write the chunked encoding header",
            "            header_str = b'%x\\r\\n' % len(data)",
            "            towrite = _bytearray(header_str)",
            "",
            "            # data",
            "            towrite += data",
            "            # trailer",
            "            towrite += b'\\r\\n'",
            "            self._sendall(towrite)",
            "        else:",
            "            self._sendall(data)",
            "",
            "    ApplicationError = AssertionError",
            "",
            "    def write(self, data):",
            "        # The write() callable we return from start_response.",
            "        # https://www.python.org/dev/peps/pep-3333/#the-write-callable",
            "        # Supposed to do pretty much the same thing as yielding values",
            "        # from the application's return.",
            "        if self.code in (304, 204) and data:",
            "            raise self.ApplicationError('The %s response must have no body' % self.code)",
            "",
            "        if self.headers_sent:",
            "            self._write(data)",
            "        else:",
            "            if not self.status:",
            "                raise self.ApplicationError(\"The application did not call start_response()\")",
            "            self._write_with_headers(data)",
            "",
            "    def _write_with_headers(self, data):",
            "        self.headers_sent = True",
            "        self.finalize_headers()",
            "",
            "        # self.response_headers and self.status are already in latin-1, as encoded by self.start_response",
            "        towrite = bytearray(b'HTTP/1.1 ')",
            "        towrite += self.status",
            "        towrite += b'\\r\\n'",
            "        for header, value in self.response_headers:",
            "            towrite += header",
            "            towrite += b': '",
            "            towrite += value",
            "            towrite += b\"\\r\\n\"",
            "",
            "        towrite += b'\\r\\n'",
            "        self._sendall(towrite)",
            "        # No need to copy the data into towrite; we may make an extra syscall",
            "        # but the copy time could be substantial too, and it reduces the chances",
            "        # of sendall being able to send everything in one go",
            "        self._write(data)",
            "",
            "    def start_response(self, status, headers, exc_info=None):",
            "        \"\"\"",
            "         .. versionchanged:: 1.2a1",
            "            Avoid HTTP header injection by raising a :exc:`ValueError`",
            "            if *status* or any *header* name or value contains a carriage",
            "            return or newline.",
            "         .. versionchanged:: 1.1b5",
            "            Pro-actively handle checking the encoding of the status line",
            "            and headers during this method. On Python 2, avoid some",
            "            extra encodings.",
            "        \"\"\"",
            "        # pylint:disable=too-many-branches,too-many-statements",
            "        if exc_info:",
            "            try:",
            "                if self.headers_sent:",
            "                    # Re-raise original exception if headers sent",
            "                    reraise(*exc_info)",
            "            finally:",
            "                # Avoid dangling circular ref",
            "                exc_info = None",
            "",
            "        # Pep 3333, \"The start_response callable\":",
            "        # https://www.python.org/dev/peps/pep-3333/#the-start-response-callable",
            "        # \"Servers should check for errors in the headers at the time",
            "        # start_response is called, so that an error can be raised",
            "        # while the application is still running.\" Here, we check the encoding.",
            "        # This aids debugging: headers especially are generated programmatically",
            "        # and an encoding error in a loop or list comprehension yields an opaque",
            "        # UnicodeError without any clue which header was wrong.",
            "        # Note that this results in copying the header list at this point, not modifying it,",
            "        # although we are allowed to do so if needed. This slightly increases memory usage.",
            "        # We also check for HTTP Response Splitting vulnerabilities",
            "        response_headers = []",
            "        header = None",
            "        value = None",
            "        try:",
            "            for header, value in headers:",
            "                if not isinstance(header, str):",
            "                    raise UnicodeError(\"The header must be a native string\", header, value)",
            "                if not isinstance(value, str):",
            "                    raise UnicodeError(\"The value must be a native string\", header, value)",
            "                if '\\r' in header or '\\n' in header:",
            "                    raise ValueError('carriage return or newline in header name', header)",
            "                if '\\r' in value or '\\n' in value:",
            "                    raise ValueError('carriage return or newline in header value', value)",
            "                # Either we're on Python 2, in which case bytes is correct, or",
            "                # we're on Python 3 and the user screwed up (because it should be a native",
            "                # string). In either case, make sure that this is latin-1 compatible. Under",
            "                # Python 2, bytes.encode() will take a round-trip through the system encoding,",
            "                # which may be ascii, which is not really what we want. However, the latin-1 encoding",
            "                # can encode everything except control characters and the block from 0x7F to 0x9F, so",
            "                # explicitly round-tripping bytes through the encoding is unlikely to be of much",
            "                # benefit, so we go for speed (the WSGI spec specifically calls out allowing the range",
            "                # from 0x00 to 0xFF, although the HTTP spec forbids the control characters).",
            "                # Note: Some Python 2 implementations, like Jython, may allow non-octet (above 255) values",
            "                # in their str implementation; this is mentioned in the WSGI spec, but we don't",
            "                # run on any platform like that so we can assume that a str value is pure bytes.",
            "                response_headers.append((header.encode(\"latin-1\"),",
            "                                         value.encode(\"latin-1\")))",
            "        except UnicodeEncodeError:",
            "            # If we get here, we're guaranteed to have a header and value",
            "            raise UnicodeError(\"Non-latin1 header\", repr(header), repr(value))",
            "",
            "        # Same as above",
            "        if not isinstance(status, str):",
            "            raise UnicodeError(\"The status string must be a native string\")",
            "        if '\\r' in status or '\\n' in status:",
            "            raise ValueError(\"carriage return or newline in status\", status)",
            "        # don't assign to anything until the validation is complete, including parsing the",
            "        # code",
            "        code = int(status.split(' ', 1)[0])",
            "",
            "        self.status = status.encode(\"latin-1\")",
            "        self._orig_status = status # Preserve the native string for logging",
            "        self.response_headers = response_headers",
            "        self.code = code",
            "",
            "        provided_connection = None # Did the wsgi app give us a Connection header?",
            "        self.provided_date = None",
            "        self.provided_content_length = None",
            "",
            "        for header, value in headers:",
            "            header = header.lower()",
            "            if header == 'connection':",
            "                provided_connection = value",
            "            elif header == 'date':",
            "                self.provided_date = value",
            "            elif header == 'content-length':",
            "                self.provided_content_length = value",
            "",
            "        if self.request_version == 'HTTP/1.0' and provided_connection is None:",
            "            conntype = b'close' if self.close_connection else b'keep-alive'",
            "            response_headers.append((b'Connection', conntype))",
            "        elif provided_connection == 'close':",
            "            self.close_connection = True",
            "",
            "        if self.code in (304, 204):",
            "            if self.provided_content_length is not None and self.provided_content_length != '0':",
            "                msg = 'Invalid Content-Length for %s response: %r (must be absent or zero)' % (self.code, self.provided_content_length)",
            "                msg = msg.encode('latin-1')",
            "                raise self.ApplicationError(msg)",
            "",
            "        return self.write",
            "",
            "    def log_request(self):",
            "        self.server.log.write(self.format_request() + '\\n')",
            "",
            "    def format_request(self):",
            "        now = datetime.now().replace(microsecond=0)",
            "        length = self.response_length or '-'",
            "        if self.time_finish:",
            "            delta = '%.6f' % (self.time_finish - self.time_start)",
            "        else:",
            "            delta = '-'",
            "        client_address = self.client_address[0] if isinstance(self.client_address, tuple) else self.client_address",
            "        return '%s - - [%s] \"%s\" %s %s %s' % (",
            "            client_address or '-',",
            "            now,",
            "            self.requestline or '',",
            "            # Use the native string version of the status, saved so we don't have to",
            "            # decode. But fallback to the encoded 'status' in case of subclasses",
            "            # (Is that really necessary? At least there's no overhead.)",
            "            (self._orig_status or self.status or '000').split()[0],",
            "            length,",
            "            delta)",
            "",
            "    def process_result(self):",
            "        for data in self.result:",
            "            if data:",
            "                self.write(data)",
            "        if self.status and not self.headers_sent:",
            "            # In other words, the application returned an empty",
            "            # result iterable (and did not use the write callable)",
            "            # Trigger the flush of the headers.",
            "            self.write(b'')",
            "        if self.response_use_chunked:",
            "            self._sendall(b'0\\r\\n\\r\\n')",
            "",
            "",
            "    def run_application(self):",
            "        assert self.result is None",
            "        try:",
            "            self.result = self.application(self.environ, self.start_response)",
            "            self.process_result()",
            "        finally:",
            "            close = getattr(self.result, 'close', None)",
            "            try:",
            "                if close is not None:",
            "                    close()",
            "            finally:",
            "                # Discard the result. If it's a generator this can",
            "                # free a lot of hidden resources (if we failed to iterate",
            "                # all the way through it---the frames are automatically",
            "                # cleaned up when StopIteration is raised); but other cases",
            "                # could still free up resources sooner than otherwise.",
            "                close = None",
            "                self.result = None",
            "",
            "    #: These errors are silently ignored by :meth:`handle_one_response` to avoid producing",
            "    #: excess log entries on normal operating conditions. They indicate",
            "    #: a remote client has disconnected and there is little or nothing",
            "    #: this process can be expected to do about it. You may change this",
            "    #: value in a subclass.",
            "    #:",
            "    #: The default value includes :data:`errno.EPIPE` and :data:`errno.ECONNRESET`.",
            "    #: On Windows this also includes :data:`errno.WSAECONNABORTED`.",
            "    #:",
            "    #: This is a provisional API, subject to change. See :pr:`377`, :pr:`999`",
            "    #: and :issue:`136`.",
            "    #:",
            "    #: .. versionadded:: 1.3",
            "    ignored_socket_errors = (errno.EPIPE, errno.ECONNRESET)",
            "    try:",
            "        ignored_socket_errors += (errno.WSAECONNABORTED,)",
            "    except AttributeError:",
            "        pass # Not windows",
            "",
            "    def handle_one_response(self):",
            "        \"\"\"",
            "        Invoke the application to produce one response.",
            "",
            "        This is called by :meth:`handle_one_request` after all the",
            "        state for the request has been established. It is responsible",
            "        for error handling.",
            "        \"\"\"",
            "        self.time_start = time.time()",
            "        self.status = None",
            "        self.headers_sent = False",
            "",
            "        self.result = None",
            "        self.response_use_chunked = False",
            "        self.connection_upgraded = False",
            "        self.response_length = 0",
            "",
            "        try:",
            "            try:",
            "                self.run_application()",
            "            finally:",
            "                try:",
            "                    self.wsgi_input._discard()",
            "                except socket.error:",
            "                    # Don't let exceptions during discarding",
            "                    # input override any exception that may have been",
            "                    # raised by the application, such as our own _InvalidClientInput.",
            "                    # In the general case, these aren't even worth logging (see the comment",
            "                    # just below)",
            "                    pass",
            "        except _InvalidClientInput:",
            "            self._send_error_response_if_possible(400)",
            "        except socket.error as ex:",
            "            if ex.args[0] in self.ignored_socket_errors:",
            "                # See description of self.ignored_socket_errors.",
            "                self.close_connection = True",
            "            else:",
            "                self.handle_error(*sys.exc_info())",
            "        except: # pylint:disable=bare-except",
            "            self.handle_error(*sys.exc_info())",
            "        finally:",
            "            self.time_finish = time.time()",
            "            self.log_request()",
            "",
            "    def _send_error_response_if_possible(self, error_code):",
            "        if self.response_length:",
            "            self.close_connection = True",
            "        else:",
            "            status, headers, body = _ERRORS[error_code]",
            "            try:",
            "                self.start_response(status, headers[:])",
            "                self.write(body)",
            "            except socket.error:",
            "                self.close_connection = True",
            "",
            "    def _log_error(self, t, v, tb):",
            "        # TODO: Shouldn't we dump this to wsgi.errors? If we did that now, it would",
            "        # wind up getting logged twice",
            "        if not issubclass(t, GreenletExit):",
            "            context = self.environ",
            "            if not isinstance(context, self.server.secure_environ_class):",
            "                context = self.server.secure_environ_class(context)",
            "            self.server.loop.handle_error(context, t, v, tb)",
            "",
            "    def handle_error(self, t, v, tb):",
            "        # Called for internal, unexpected errors, NOT invalid client input",
            "        self._log_error(t, v, tb)",
            "        t = v = tb = None",
            "        self._send_error_response_if_possible(500)",
            "",
            "    def _handle_client_error(self, ex):",
            "        # Called for invalid client input",
            "        # Returns the appropriate error response.",
            "        if not isinstance(ex, ValueError):",
            "            # XXX: Why not self._log_error to send it through the loop's",
            "            # handle_error method?",
            "            traceback.print_exc()",
            "        if isinstance(ex, _InvalidClientRequest):",
            "            # No formatting needed, that's already been handled. In fact, because the",
            "            # formatted message contains user input, it might have a % in it, and attempting",
            "            # to format that with no arguments would be an error.",
            "            self.log_error(ex.formatted_message)",
            "        else:",
            "            self.log_error('Invalid request: %s', str(ex) or ex.__class__.__name__)",
            "        return ('400', _BAD_REQUEST_RESPONSE)",
            "",
            "    def _headers(self):",
            "        key = None",
            "        value = None",
            "        IGNORED_KEYS = (None, 'CONTENT_TYPE', 'CONTENT_LENGTH')",
            "        for header in self.headers.headers:",
            "            if key is not None and header[:1] in \" \\t\":",
            "                value += header",
            "                continue",
            "",
            "            if key not in IGNORED_KEYS:",
            "                yield 'HTTP_' + key, value.strip()",
            "",
            "            key, value = header.split(':', 1)",
            "            if '_' in key:",
            "                # strip incoming bad veaders",
            "                key = None",
            "            else:",
            "                key = key.replace('-', '_').upper()",
            "",
            "        if key not in IGNORED_KEYS:",
            "            yield 'HTTP_' + key, value.strip()",
            "",
            "    def get_environ(self):",
            "        \"\"\"",
            "        Construct and return a new WSGI environment dictionary for a specific request.",
            "",
            "        This should begin with asking the server for the base environment",
            "        using :meth:`WSGIServer.get_environ`, and then proceed to add the",
            "        request specific values.",
            "",
            "        By the time this method is invoked the request line and request shall have",
            "        been parsed and ``self.headers`` shall be populated.",
            "        \"\"\"",
            "        env = self.server.get_environ()",
            "        env['REQUEST_METHOD'] = self.command",
            "        # SCRIPT_NAME is explicitly implementation defined. Using an",
            "        # empty value for SCRIPT_NAME is both explicitly allowed by",
            "        # both the CGI standard and WSGI PEPs, and also the thing that",
            "        # makes the most sense from a generic server perspective (we",
            "        # have no hierarchy or understanding of URLs or files, just a",
            "        # single application to call. The empty string represents the",
            "        # application root, which is what we have). Different WSGI",
            "        # implementations handle this very differently, so portable",
            "        # applications that rely on SCRIPT_NAME will have to use a",
            "        # WSGI middleware to set it to a defined value, or otherwise",
            "        # rely on server-specific mechanisms (e.g, on waitress, use",
            "        # ``--url-prefix``, in gunicorn set the ``SCRIPT_NAME`` header",
            "        # or process environment variable, in gevent subclass",
            "        # WSGIHandler.)",
            "        #",
            "        # See https://github.com/gevent/gevent/issues/1667 for discussion.",
            "        env['SCRIPT_NAME'] = ''",
            "",
            "        path, query = self.path.split('?', 1) if '?' in self.path else (self.path, '')",
            "        # Note that self.path contains the original str object; if it contains",
            "        # encoded escapes, it will NOT match PATH_INFO.",
            "        env['PATH_INFO'] = unquote_latin1(path)",
            "        env['QUERY_STRING'] = query",
            "",
            "        if self.headers.typeheader is not None:",
            "            env['CONTENT_TYPE'] = self.headers.typeheader",
            "",
            "        length = self.headers.getheader('content-length')",
            "        if length:",
            "            env['CONTENT_LENGTH'] = length",
            "        env['SERVER_PROTOCOL'] = self.request_version",
            "",
            "        client_address = self.client_address",
            "        if isinstance(client_address, tuple):",
            "            env['REMOTE_ADDR'] = str(client_address[0])",
            "            env['REMOTE_PORT'] = str(client_address[1])",
            "",
            "        for key, value in self._headers():",
            "            if key in env:",
            "                if 'COOKIE' in key:",
            "                    env[key] += '; ' + value",
            "                else:",
            "                    env[key] += ',' + value",
            "            else:",
            "                env[key] = value",
            "",
            "        sock = self.socket if env.get('HTTP_EXPECT') == '100-continue' else None",
            "",
            "        chunked = env.get('HTTP_TRANSFER_ENCODING', '').lower() == 'chunked'",
            "        # Input refuses to read if the data isn't chunked, and there is no content_length",
            "        # provided. For 'Upgrade: Websocket' requests, neither of those things is true.",
            "        handling_reads = not self._connection_upgrade_requested()",
            "",
            "        self.wsgi_input = Input(self.rfile, self.content_length, socket=sock, chunked_input=chunked)",
            "",
            "        env['wsgi.input'] = self.wsgi_input if handling_reads else self.rfile",
            "        # This is a non-standard flag indicating that our input stream is",
            "        # self-terminated (returns EOF when consumed).",
            "        # See https://github.com/gevent/gevent/issues/1308",
            "        env['wsgi.input_terminated'] = handling_reads",
            "        return env",
            "",
            "",
            "class _NoopLog(object):",
            "    # Does nothing; implements just enough file-like methods",
            "    # to pass the WSGI validator",
            "",
            "    def write(self, *args, **kwargs):",
            "        # pylint:disable=unused-argument",
            "        return",
            "",
            "    def flush(self):",
            "        pass",
            "",
            "    def writelines(self, *args, **kwargs):",
            "        pass",
            "",
            "",
            "class LoggingLogAdapter(object):",
            "    \"\"\"",
            "    An adapter for :class:`logging.Logger` instances",
            "    to let them be used with :class:`WSGIServer`.",
            "",
            "    .. warning:: Unless the entire process is monkey-patched at a very",
            "        early part of the lifecycle (before logging is configured),",
            "        loggers are likely to not be gevent-cooperative. For example,",
            "        the socket and syslog handlers use the socket module in a way",
            "        that can block, and most handlers acquire threading locks.",
            "",
            "    .. warning:: It *may* be possible for the logging functions to be",
            "       called in the :class:`gevent.Hub` greenlet. Code running in the",
            "       hub greenlet cannot use any gevent blocking functions without triggering",
            "       a ``LoopExit``.",
            "",
            "    .. versionadded:: 1.1a3",
            "",
            "    .. versionchanged:: 1.1b6",
            "       Attributes not present on this object are proxied to the underlying",
            "       logger instance. This permits using custom :class:`~logging.Logger`",
            "       subclasses (or indeed, even duck-typed objects).",
            "",
            "    .. versionchanged:: 1.1",
            "       Strip trailing newline characters on the message passed to :meth:`write`",
            "       because log handlers will usually add one themselves.",
            "    \"\"\"",
            "",
            "    # gevent avoids importing and using logging because importing it and",
            "    # creating loggers creates native locks unless monkey-patched.",
            "",
            "    __slots__ = ('_logger', '_level')",
            "",
            "    def __init__(self, logger, level=20):",
            "        \"\"\"",
            "        Write information to the *logger* at the given *level* (default to INFO).",
            "        \"\"\"",
            "        self._logger = logger",
            "        self._level = level",
            "",
            "    def write(self, msg):",
            "        if msg and msg.endswith('\\n'):",
            "            msg = msg[:-1]",
            "        self._logger.log(self._level, msg)",
            "",
            "    def flush(self):",
            "        \"No-op; required to be a file-like object\"",
            "",
            "    def writelines(self, lines):",
            "        for line in lines:",
            "            self.write(line)",
            "",
            "    def __getattr__(self, name):",
            "        return getattr(self._logger, name)",
            "",
            "    def __setattr__(self, name, value):",
            "        if name not in LoggingLogAdapter.__slots__:",
            "            setattr(self._logger, name, value)",
            "        else:",
            "            object.__setattr__(self, name, value)",
            "",
            "    def __delattr__(self, name):",
            "        delattr(self._logger, name)",
            "",
            "####",
            "## Environ classes.",
            "# These subclass dict. They could subclass collections.UserDict on",
            "# 3.3+ and proxy to the underlying real dict to avoid a copy if we",
            "# have to print them (on 2.7 it's slightly more complicated to be an",
            "# instance of collections.MutableMapping; UserDict.UserDict isn't.)",
            "# Then we could have either the WSGIHandler.get_environ or the",
            "# WSGIServer.get_environ return one of these proxies, and",
            "# WSGIHandler.run_application would know to access the `environ.data`",
            "# attribute to be able to pass the *real* dict to the application",
            "# (because PEP3333 requires no subclasses, only actual dict objects;",
            "# wsgiref.validator and webob.Request both enforce this). This has the",
            "# advantage of not being fragile if anybody else tries to print/log",
            "# self.environ (and not requiring a copy). However, if there are any",
            "# subclasses of Handler or Server, this could break if they don't know",
            "# to return this type.",
            "####",
            "",
            "class Environ(dict):",
            "    \"\"\"",
            "    A base class that can be used for WSGI environment objects.",
            "",
            "    Provisional API.",
            "",
            "    .. versionadded:: 1.2a1",
            "    \"\"\"",
            "",
            "    __slots__ = () # add no ivars or weakref ability",
            "",
            "    def copy(self):",
            "        return self.__class__(self)",
            "",
            "    if not hasattr(dict, 'iteritems'):",
            "        # Python 3",
            "        def iteritems(self):",
            "            return self.items()",
            "",
            "    def __reduce_ex__(self, proto):",
            "        return (dict, (), None, None, iter(self.iteritems()))",
            "",
            "class SecureEnviron(Environ):",
            "    \"\"\"",
            "    An environment that does not print its keys and values",
            "    by default.",
            "",
            "    Provisional API.",
            "",
            "    This is intended to keep potentially sensitive information like",
            "    HTTP authorization and cookies from being inadvertently printed",
            "    or logged.",
            "",
            "    For debugging, each instance can have its *secure_repr* attribute",
            "    set to ``False``, which will cause it to print like a normal dict.",
            "",
            "    When *secure_repr* is ``True`` (the default), then the value of",
            "    the *whitelist_keys* attribute is consulted; if this value is",
            "    true-ish, it should be a container (something that responds to",
            "    ``in``) of key names (typically a list or set). Keys and values in",
            "    this dictionary that are in *whitelist_keys* will then be printed,",
            "    while all other values will be masked. These values may be",
            "    customized on the class by setting the *default_secure_repr* and",
            "    *default_whitelist_keys*, respectively::",
            "",
            "        >>> environ = SecureEnviron(key='value')",
            "        >>> environ # doctest: +ELLIPSIS",
            "        <pywsgi.SecureEnviron dict (keys: 1) at ...",
            "",
            "    If we whitelist the key, it gets printed::",
            "",
            "        >>> environ.whitelist_keys = {'key'}",
            "        >>> environ",
            "        {'key': 'value'}",
            "",
            "    A non-whitelisted key (*only*, to avoid doctest issues) is masked::",
            "",
            "        >>> environ['secure'] = 'secret'; del environ['key']",
            "        >>> environ",
            "        {'secure': '<MASKED>'}",
            "",
            "    We can turn it off entirely for the instance::",
            "",
            "        >>> environ.secure_repr = False",
            "        >>> environ",
            "        {'secure': 'secret'}",
            "",
            "    We can also customize it at the class level (here we use a new",
            "    class to be explicit and to avoid polluting the true default",
            "    values; we would set this class to be the ``environ_class`` of the",
            "    server)::",
            "",
            "        >>> class MyEnviron(SecureEnviron):",
            "        ...    default_whitelist_keys = ('key',)",
            "        ...",
            "        >>> environ = MyEnviron({'key': 'value'})",
            "        >>> environ",
            "        {'key': 'value'}",
            "",
            "    .. versionadded:: 1.2a1",
            "    \"\"\"",
            "",
            "    default_secure_repr = True",
            "    default_whitelist_keys = ()",
            "    default_print_masked_keys = True",
            "",
            "    # Allow instances to override the class values,",
            "    # but inherit from the class if not present. Keeps instances",
            "    # small since we can't combine __slots__ with class attributes",
            "    # of the same name.",
            "    __slots__ = ('secure_repr', 'whitelist_keys', 'print_masked_keys')",
            "",
            "    def __getattr__(self, name):",
            "        if name in SecureEnviron.__slots__:",
            "            return getattr(type(self), 'default_' + name)",
            "        raise AttributeError(name)",
            "",
            "    def __repr__(self):",
            "        if self.secure_repr:",
            "            whitelist = self.whitelist_keys",
            "            print_masked = self.print_masked_keys",
            "            if whitelist:",
            "                safe = {k: self[k] if k in whitelist else \"<MASKED>\"",
            "                        for k in self",
            "                        if k in whitelist or print_masked}",
            "                safe_repr = repr(safe)",
            "                if not print_masked and len(safe) != len(self):",
            "                    safe_repr = safe_repr[:-1] + \", (hidden keys: %d)}\" % (len(self) - len(safe))",
            "                return safe_repr",
            "            return \"<pywsgi.SecureEnviron dict (keys: %d) at %s>\" % (len(self), id(self))",
            "        return Environ.__repr__(self)",
            "    __str__ = __repr__",
            "",
            "",
            "class WSGISecureEnviron(SecureEnviron):",
            "    \"\"\"",
            "    Specializes the default list of whitelisted keys to a few",
            "    common WSGI variables.",
            "",
            "    Example::",
            "",
            "       >>> environ = WSGISecureEnviron(REMOTE_ADDR='::1', HTTP_AUTHORIZATION='secret')",
            "       >>> environ",
            "       {'REMOTE_ADDR': '::1', (hidden keys: 1)}",
            "       >>> import pprint",
            "       >>> pprint.pprint(environ)",
            "       {'REMOTE_ADDR': '::1', (hidden keys: 1)}",
            "       >>> print(pprint.pformat(environ))",
            "       {'REMOTE_ADDR': '::1', (hidden keys: 1)}",
            "    \"\"\"",
            "    default_whitelist_keys = ('REMOTE_ADDR', 'REMOTE_PORT', 'HTTP_HOST')",
            "    default_print_masked_keys = False",
            "",
            "",
            "class WSGIServer(StreamServer):",
            "    \"\"\"",
            "    A WSGI server based on :class:`StreamServer` that supports HTTPS.",
            "",
            "",
            "    :keyword log: If given, an object with a ``write`` method to which",
            "        request (access) logs will be written. If not given, defaults",
            "        to :obj:`sys.stderr`. You may pass ``None`` to disable request",
            "        logging. You may use a wrapper, around e.g., :mod:`logging`,",
            "        to support objects that don't implement a ``write`` method.",
            "        (If you pass a :class:`~logging.Logger` instance, or in",
            "        general something that provides a ``log`` method but not a",
            "        ``write`` method, such a wrapper will automatically be created",
            "        and it will be logged to at the :data:`~logging.INFO` level.)",
            "",
            "    :keyword error_log: If given, a file-like object with ``write``,",
            "        ``writelines`` and ``flush`` methods to which error logs will",
            "        be written. If not given, defaults to :obj:`sys.stderr`. You",
            "        may pass ``None`` to disable error logging (not recommended).",
            "        You may use a wrapper, around e.g., :mod:`logging`, to support",
            "        objects that don't implement the proper methods. This",
            "        parameter will become the value for ``wsgi.errors`` in the",
            "        WSGI environment (if not already set). (As with *log*,",
            "        wrappers for :class:`~logging.Logger` instances and the like",
            "        will be created automatically and logged to at the :data:`~logging.ERROR`",
            "        level.)",
            "",
            "    .. seealso::",
            "",
            "        :class:`LoggingLogAdapter`",
            "            See important warnings before attempting to use :mod:`logging`.",
            "",
            "    .. versionchanged:: 1.1a3",
            "        Added the ``error_log`` parameter, and set ``wsgi.errors`` in the WSGI",
            "        environment to this value.",
            "    .. versionchanged:: 1.1a3",
            "        Add support for passing :class:`logging.Logger` objects to the ``log`` and",
            "        ``error_log`` arguments.",
            "    .. versionchanged:: 20.6.0",
            "        Passing a ``handle`` kwarg to the constructor is now officially deprecated.",
            "    \"\"\"",
            "",
            "    #: A callable taking three arguments: (socket, address, server) and returning",
            "    #: an object with a ``handle()`` method. The callable is called once for",
            "    #: each incoming socket request, as is its handle method. The handle method should not",
            "    #: return until all use of the socket is complete.",
            "    #:",
            "    #: This class uses the :class:`WSGIHandler` object as the default value. You may",
            "    #: subclass this class and set a different default value, or you may pass",
            "    #: a value to use in the ``handler_class`` keyword constructor argument.",
            "    handler_class = WSGIHandler",
            "",
            "    #: The object to which request logs will be written.",
            "    #: It must never be None. Initialized from the ``log`` constructor",
            "    #: parameter.",
            "    log = None",
            "",
            "    #: The object to which error logs will be written.",
            "    #: It must never be None. Initialized from the ``error_log`` constructor",
            "    #: parameter.",
            "    error_log = None",
            "",
            "    #: The class of environ objects passed to the handlers.",
            "    #: Must be a dict subclass. For compliance with :pep:`3333`",
            "    #: and libraries like WebOb, this is simply :class:`dict`",
            "    #: but this can be customized in a subclass or per-instance",
            "    #: (probably to :class:`WSGISecureEnviron`).",
            "    #:",
            "    #: .. versionadded:: 1.2a1",
            "    environ_class = dict",
            "",
            "    # Undocumented internal detail: the class that WSGIHandler._log_error",
            "    # will cast to before passing to the loop.",
            "    secure_environ_class = WSGISecureEnviron",
            "",
            "    base_env = {'GATEWAY_INTERFACE': 'CGI/1.1',",
            "                'SERVER_SOFTWARE': 'gevent/%d.%d Python/%d.%d' % (gevent.version_info[:2] + sys.version_info[:2]),",
            "                'SCRIPT_NAME': '',",
            "                'wsgi.version': (1, 0),",
            "                'wsgi.multithread': False, # XXX: Aren't we really, though?",
            "                'wsgi.multiprocess': False,",
            "                'wsgi.run_once': False}",
            "",
            "    def __init__(self, listener, application=None, backlog=None, spawn='default',",
            "                 log='default', error_log='default',",
            "                 handler_class=None,",
            "                 environ=None, **ssl_args):",
            "        if 'handle' in ssl_args:",
            "            # The ultimate base class (BaseServer) uses 'handle' for",
            "            # the thing we call 'application'. We never deliberately",
            "            # bass a `handle` argument to the base class, but one",
            "            # could sneak in through ``**ssl_args``, even though that",
            "            # is not the intent, while application is None. That",
            "            # causes our own ``def handle`` method to be replaced,",
            "            # probably leading to bad results. Passing a 'handle'",
            "            # instead of an 'application' can really confuse things.",
            "            import warnings",
            "            warnings.warn(\"Passing 'handle' kwarg to WSGIServer is deprecated. \"",
            "                          \"Did you mean application?\", DeprecationWarning, stacklevel=2)",
            "",
            "        StreamServer.__init__(self, listener, backlog=backlog, spawn=spawn, **ssl_args)",
            "",
            "        if application is not None:",
            "            self.application = application",
            "        if handler_class is not None:",
            "            self.handler_class = handler_class",
            "",
            "        # Note that we can't initialize these as class variables:",
            "        # sys.stderr might get monkey patched at runtime.",
            "        def _make_log(l, level=20):",
            "            if l == 'default':",
            "                return sys.stderr",
            "            if l is None:",
            "                return _NoopLog()",
            "            if not hasattr(l, 'write') and hasattr(l, 'log'):",
            "                return LoggingLogAdapter(l, level)",
            "            return l",
            "        self.log = _make_log(log)",
            "        self.error_log = _make_log(error_log, 40) # logging.ERROR",
            "",
            "        self.set_environ(environ)",
            "        self.set_max_accept()",
            "",
            "    def set_environ(self, environ=None):",
            "        if environ is not None:",
            "            self.environ = environ",
            "        environ_update = getattr(self, 'environ', None)",
            "",
            "        self.environ = self.environ_class(self.base_env)",
            "        if self.ssl_enabled:",
            "            self.environ['wsgi.url_scheme'] = 'https'",
            "        else:",
            "            self.environ['wsgi.url_scheme'] = 'http'",
            "        if environ_update is not None:",
            "            self.environ.update(environ_update)",
            "        if self.environ.get('wsgi.errors') is None:",
            "            self.environ['wsgi.errors'] = self.error_log",
            "",
            "    def set_max_accept(self):",
            "        if self.environ.get('wsgi.multiprocess'):",
            "            self.max_accept = 1",
            "",
            "    def get_environ(self):",
            "        return self.environ_class(self.environ)",
            "",
            "    def init_socket(self):",
            "        StreamServer.init_socket(self)",
            "        self.update_environ()",
            "",
            "    def update_environ(self):",
            "        \"\"\"",
            "        Called before the first request is handled to fill in WSGI environment values.",
            "",
            "        This includes getting the correct server name and port.",
            "        \"\"\"",
            "        address = self.address",
            "        if isinstance(address, tuple):",
            "            if 'SERVER_NAME' not in self.environ:",
            "                try:",
            "                    name = socket.getfqdn(address[0])",
            "                except socket.error:",
            "                    name = str(address[0])",
            "                if not isinstance(name, str):",
            "                    name = name.decode('ascii')",
            "                self.environ['SERVER_NAME'] = name",
            "            self.environ.setdefault('SERVER_PORT', str(address[1]))",
            "        else:",
            "            self.environ.setdefault('SERVER_NAME', '')",
            "            self.environ.setdefault('SERVER_PORT', '')",
            "",
            "    def handle(self, sock, address):",
            "        \"\"\"",
            "        Create an instance of :attr:`handler_class` to handle the request.",
            "",
            "        This method blocks until the handler returns.",
            "        \"\"\"",
            "        # pylint:disable=method-hidden",
            "        handler = self.handler_class(sock, address, self)",
            "        handler.handle()",
            "",
            "def _main():",
            "    # Provisional main handler, for quick tests, not production",
            "    # usage.",
            "    from gevent import monkey; monkey.patch_all()",
            "",
            "    import argparse",
            "    import importlib",
            "",
            "    parser = argparse.ArgumentParser()",
            "    parser.add_argument(\"app\", help=\"dotted name of WSGI app callable [module:callable]\")",
            "    parser.add_argument(\"-b\", \"--bind\",",
            "                        help=\"The socket to bind\",",
            "                        default=\":8080\")",
            "",
            "    args = parser.parse_args()",
            "",
            "    module_name, app_name = args.app.split(':')",
            "    module = importlib.import_module(module_name)",
            "    app = getattr(module, app_name)",
            "    bind = args.bind",
            "",
            "    server = WSGIServer(bind, app)",
            "    server.serve_forever()",
            "",
            "if __name__ == '__main__':",
            "    _main()"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2005-2009, eventlet contributors",
            "# Copyright (c) 2009-2018, gevent contributors",
            "\"\"\"",
            "A pure-Python, gevent-friendly WSGI server implementing HTTP/1.1.",
            "",
            "The server is provided in :class:`WSGIServer`, but most of the actual",
            "WSGI work is handled by :class:`WSGIHandler` --- a new instance is",
            "created for each request. The server can be customized to use",
            "different subclasses of :class:`WSGIHandler`.",
            "",
            ".. important::",
            "",
            "   This server is intended primarily for development and testing, and",
            "   secondarily for other \"safe\" scenarios where it will not be exposed to",
            "   potentially malicious input. The code has not been security audited,",
            "   and is not intended for direct exposure to the public Internet. For production",
            "   usage on the Internet, either choose a production-strength server such as",
            "   gunicorn, or put a reverse proxy between gevent and the Internet.",
            "",
            ".. versionchanged:: NEXT",
            "",
            "   Complies more closely with the HTTP specification for chunked transfer encoding.",
            "   In particular, we are much stricter about trailers, and trailers that",
            "   are invalid (too long or featuring disallowed characters) forcibly close",
            "   the connection to the client *after* the results have been sent.",
            "",
            "   Trailers otherwise continue to be ignored and are not available to the",
            "   WSGI application.",
            "",
            "\"\"\"",
            "from __future__ import absolute_import",
            "",
            "# FIXME: Can we refactor to make smallor?",
            "# pylint:disable=too-many-lines",
            "",
            "import errno",
            "from io import BytesIO",
            "import string",
            "import sys",
            "import time",
            "import traceback",
            "from datetime import datetime",
            "",
            "from urllib.parse import unquote",
            "",
            "from gevent import socket",
            "import gevent",
            "from gevent.server import StreamServer",
            "from gevent.hub import GreenletExit",
            "from gevent._compat import reraise",
            "",
            "from functools import partial",
            "unquote_latin1 = partial(unquote, encoding='latin-1')",
            "",
            "_no_undoc_members = True # Don't put undocumented things into sphinx",
            "",
            "__all__ = [",
            "    'WSGIServer',",
            "    'WSGIHandler',",
            "    'LoggingLogAdapter',",
            "    'Environ',",
            "    'SecureEnviron',",
            "    'WSGISecureEnviron',",
            "]",
            "",
            "",
            "MAX_REQUEST_LINE = 8192",
            "# Weekday and month names for HTTP date/time formatting; always English!",
            "_WEEKDAYNAME = (\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")",
            "_MONTHNAME = (None,  # Dummy so we can use 1-based month numbers",
            "              \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",",
            "              \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")",
            "",
            "# The contents of the \"HEX\" grammar rule for HTTP, upper and lowercase A-F plus digits,",
            "# in byte form for comparing to the network.",
            "_HEX = string.hexdigits.encode('ascii')",
            "",
            "# The characters allowed in \"token\" rules.",
            "",
            "# token          = 1*tchar",
            "# tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"",
            "#                / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"",
            "#                / DIGIT / ALPHA",
            "#                ; any VCHAR, except delimiters",
            "# ALPHA          =  %x41-5A / %x61-7A   ; A-Z / a-z",
            "_ALLOWED_TOKEN_CHARS = frozenset(",
            "    # Remember we have to be careful because bytestrings",
            "    # inexplicably iterate as integers, which are not equal to bytes.",
            "",
            "    # explicit chars then DIGIT",
            "    (c.encode('ascii') for c in \"!#$%&'*+-.^_`|~0123456789\")",
            "    # Then we add ALPHA",
            ") | {c.encode('ascii') for c in string.ascii_letters}",
            "assert b'A' in _ALLOWED_TOKEN_CHARS",
            "",
            "",
            "# Errors",
            "_ERRORS = {}",
            "_INTERNAL_ERROR_STATUS = '500 Internal Server Error'",
            "_INTERNAL_ERROR_BODY = b'Internal Server Error'",
            "_INTERNAL_ERROR_HEADERS = (",
            "    ('Content-Type', 'text/plain'),",
            "    ('Connection', 'close'),",
            "    ('Content-Length', str(len(_INTERNAL_ERROR_BODY)))",
            ")",
            "_ERRORS[500] = (_INTERNAL_ERROR_STATUS, _INTERNAL_ERROR_HEADERS, _INTERNAL_ERROR_BODY)",
            "",
            "_BAD_REQUEST_STATUS = '400 Bad Request'",
            "_BAD_REQUEST_BODY = ''",
            "_BAD_REQUEST_HEADERS = (",
            "    ('Content-Type', 'text/plain'),",
            "    ('Connection', 'close'),",
            "    ('Content-Length', str(len(_BAD_REQUEST_BODY)))",
            ")",
            "_ERRORS[400] = (_BAD_REQUEST_STATUS, _BAD_REQUEST_HEADERS, _BAD_REQUEST_BODY)",
            "",
            "_REQUEST_TOO_LONG_RESPONSE = b\"HTTP/1.1 414 Request URI Too Long\\r\\nConnection: close\\r\\nContent-length: 0\\r\\n\\r\\n\"",
            "_BAD_REQUEST_RESPONSE = b\"HTTP/1.1 400 Bad Request\\r\\nConnection: close\\r\\nContent-length: 0\\r\\n\\r\\n\"",
            "_CONTINUE_RESPONSE = b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\"",
            "",
            "",
            "def format_date_time(timestamp):",
            "    # Return a byte-string of the date and time in HTTP format",
            "    # .. versionchanged:: 1.1b5",
            "    #  Return a byte string, not a native string",
            "    year, month, day, hh, mm, ss, wd, _y, _z = time.gmtime(timestamp)",
            "    value = \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (_WEEKDAYNAME[wd], day, _MONTHNAME[month], year, hh, mm, ss)",
            "    value = value.encode(\"latin-1\")",
            "    return value",
            "",
            "",
            "class _InvalidClientInput(IOError):",
            "    # Internal exception raised by Input indicating that the client",
            "    # sent invalid data at the lowest level of the stream. The result",
            "    # *should* be a HTTP 400 error.",
            "    pass",
            "",
            "",
            "class _InvalidClientRequest(ValueError):",
            "    # Internal exception raised by WSGIHandler.read_request indicating",
            "    # that the client sent an HTTP request that cannot be parsed",
            "    # (e.g., invalid grammar). The result *should* be an HTTP 400",
            "    # error. It must have exactly one argument, the fully formatted",
            "    # error string.",
            "",
            "    def __init__(self, message):",
            "        ValueError.__init__(self, message)",
            "        self.formatted_message = message",
            "",
            "",
            "class Input(object):",
            "",
            "    __slots__ = ('rfile', 'content_length', 'socket', 'position',",
            "                 'chunked_input', 'chunk_length', '_chunked_input_error')",
            "",
            "    def __init__(self, rfile, content_length, socket=None, chunked_input=False):",
            "        # pylint:disable=redefined-outer-name",
            "        self.rfile = rfile",
            "        self.content_length = content_length",
            "        self.socket = socket",
            "        self.position = 0",
            "        self.chunked_input = chunked_input",
            "        self.chunk_length = -1",
            "        self._chunked_input_error = False",
            "",
            "    def _discard(self):",
            "        if self._chunked_input_error:",
            "            # We are in an unknown state, so we can't necessarily discard",
            "            # the body (e.g., if the client keeps the socket open, we could hang",
            "            # here forever).",
            "            # In this case, we've raised an exception and the user of this object",
            "            # is going to close the socket, so we don't have to discard",
            "            return",
            "",
            "        if self.socket is None and (self.position < (self.content_length or 0) or self.chunked_input):",
            "            # ## Read and discard body",
            "            while 1:",
            "                d = self.read(16384)",
            "                if not d:",
            "                    break",
            "",
            "    def _send_100_continue(self):",
            "        if self.socket is not None:",
            "            self.socket.sendall(_CONTINUE_RESPONSE)",
            "            self.socket = None",
            "",
            "    def _do_read(self, length=None, use_readline=False):",
            "        if use_readline:",
            "            reader = self.rfile.readline",
            "        else:",
            "            reader = self.rfile.read",
            "        content_length = self.content_length",
            "        if content_length is None:",
            "            # Either Content-Length or \"Transfer-Encoding: chunked\" must be present in a request with a body",
            "            # if it was chunked, then this function would have not been called",
            "            return b''",
            "",
            "        self._send_100_continue()",
            "        left = content_length - self.position",
            "        if length is None:",
            "            length = left",
            "        elif length > left:",
            "            length = left",
            "        if not length:",
            "            return b''",
            "",
            "        # On Python 2, self.rfile is usually socket.makefile(), which",
            "        # uses cStringIO.StringIO. If *length* is greater than the C",
            "        # sizeof(int) (typically 32 bits signed), parsing the argument to",
            "        # readline raises OverflowError. StringIO.read(), OTOH, uses",
            "        # PySize_t, typically a long (64 bits). In a bare readline()",
            "        # case, because the header lines we're trying to read with",
            "        # readline are typically expected to be small, we can correct",
            "        # that failure by simply doing a smaller call to readline and",
            "        # appending; failures in read we let propagate.",
            "        try:",
            "            read = reader(length)",
            "        except OverflowError:",
            "            if not use_readline:",
            "                # Expecting to read more than 64 bits of data. Ouch!",
            "                raise",
            "            # We could loop on calls to smaller readline(), appending them",
            "            # until we actually get a newline. For uses in this module,",
            "            # we expect the actual length to be small, but WSGI applications",
            "            # are allowed to pass in an arbitrary length. (This loop isn't optimal,",
            "            # but even client applications *probably* have short lines.)",
            "            read = b''",
            "            while len(read) < length and not read.endswith(b'\\n'):",
            "                read += reader(MAX_REQUEST_LINE)",
            "",
            "        self.position += len(read)",
            "        if len(read) < length:",
            "            if (use_readline and not read.endswith(b\"\\n\")) or not use_readline:",
            "                raise IOError(\"unexpected end of file while reading request at position %s\" % (self.position,))",
            "",
            "        return read",
            "",
            "    def __read_chunk_length(self, rfile):",
            "        # Read and return the next integer chunk length. If no",
            "        # chunk length can be read, raises _InvalidClientInput.",
            "",
            "        # Here's the production for a chunk (actually the whole body):",
            "        # (https://www.rfc-editor.org/rfc/rfc7230#section-4.1)",
            "",
            "        # chunked-body   = *chunk",
            "        #                  last-chunk",
            "        #                  trailer-part",
            "        #                  CRLF",
            "        #",
            "        # chunk          = chunk-size [ chunk-ext ] CRLF",
            "        #                  chunk-data CRLF",
            "        # chunk-size     = 1*HEXDIG",
            "        # last-chunk     = 1*(\"0\") [ chunk-ext ] CRLF",
            "        # trailer-part   = *( header-field CRLF )",
            "        # chunk-data     = 1*OCTET ; a sequence of chunk-size octets",
            "",
            "        # To cope with malicious or broken clients that fail to send",
            "        # valid chunk lines, the strategy is to read character by",
            "        # character until we either reach a ; or newline. If at any",
            "        # time we read a non-HEX digit, we bail. If we hit a ;,",
            "        # indicating an chunk-extension, we'll read up to the next",
            "        # MAX_REQUEST_LINE characters (\"A server ought to limit the",
            "        # total length of chunk extensions received\") looking for the",
            "        # CRLF, and if we don't find it, we bail. If we read more than",
            "        # 16 hex characters, (the number needed to represent a 64-bit",
            "        # chunk size), we bail (this protects us from a client that",
            "        # sends an infinite stream of `F`, for example).",
            "",
            "        buf = BytesIO()",
            "        while 1:",
            "            char = rfile.read(1)",
            "            if not char:",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"EOF before chunk end reached\")",
            "",
            "            if char in (",
            "                b'\\r', # Beginning EOL",
            "                b';', # Beginning extension",
            "            ):",
            "                break",
            "",
            "            if char not in _HEX: # Invalid data.",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Non-hex data\", char)",
            "",
            "            buf.write(char)",
            "",
            "            if buf.tell() > 16: # Too many hex bytes",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Chunk-size too large.\")",
            "",
            "        if char == b';':",
            "            i = 0",
            "            while i < MAX_REQUEST_LINE:",
            "                char = rfile.read(1)",
            "                if char == b'\\r':",
            "                    break",
            "                i += 1",
            "            else:",
            "                # we read more than MAX_REQUEST_LINE without",
            "                # hitting CR",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Too large chunk extension\")",
            "",
            "        if char == b'\\r':",
            "            # We either got here from the main loop or from the",
            "            # end of an extension",
            "            self.__read_chunk_size_crlf(rfile, newline_only=True)",
            "            result = int(buf.getvalue(), 16)",
            "            if result == 0:",
            "                # The only time a chunk size of zero is allowed is the final",
            "                # chunk. It is either followed by another \\r\\n, or some trailers",
            "                # which are then followed by \\r\\n.",
            "                while self.__read_chunk_trailer(rfile):",
            "                    pass",
            "            return result",
            "",
            "    # Trailers have the following production (they are a header-field followed by CRLF)",
            "    # See above for the definition of \"token\".",
            "    #",
            "    # header-field   = field-name \":\" OWS field-value OWS",
            "    # field-name     = token",
            "    # field-value    = *( field-content / obs-fold )",
            "    # field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]",
            "    # field-vchar    = VCHAR / obs-text",
            "    # obs-fold       = CRLF 1*( SP / HTAB )",
            "    #                ; obsolete line folding",
            "    #                ; see Section 3.2.4",
            "",
            "",
            "    def __read_chunk_trailer(self, rfile, ):",
            "        # With rfile positioned just after a \\r\\n, read a trailer line.",
            "        # Return a true value if a non-empty trailer was read, and",
            "        # return false if an empty trailer was read (meaning the trailers are",
            "        # done).",
            "        # If a single line exceeds the MAX_REQUEST_LINE, raise an exception.",
            "        # If the field-name portion contains invalid characters, raise an exception.",
            "",
            "        i = 0",
            "        empty = True",
            "        seen_field_name = False",
            "        while i < MAX_REQUEST_LINE:",
            "            char = rfile.read(1)",
            "            if char == b'\\r':",
            "                # Either read the next \\n or raise an error.",
            "                self.__read_chunk_size_crlf(rfile, newline_only=True)",
            "                break",
            "            # Not a \\r, so we are NOT an empty chunk.",
            "            empty = False",
            "            if char == b':' and i > 0:",
            "                # We're ending the field-name part; stop validating characters.",
            "                # Unless : was the first character...",
            "                seen_field_name = True",
            "            if not seen_field_name and char not in _ALLOWED_TOKEN_CHARS:",
            "                raise _InvalidClientInput('Invalid token character: %r' % (char,))",
            "            i += 1",
            "        else:",
            "            # We read too much",
            "            self._chunked_input_error = True",
            "            raise _InvalidClientInput(\"Too large chunk trailer\")",
            "        return not empty",
            "",
            "    def __read_chunk_size_crlf(self, rfile, newline_only=False):",
            "        # Also for safety, correctly verify that we get \\r\\n when expected.",
            "        if not newline_only:",
            "            char = rfile.read(1)",
            "            if char != b'\\r':",
            "                self._chunked_input_error = True",
            "                raise _InvalidClientInput(\"Line didn't end in CRLF: %r\" % (char,))",
            "        char = rfile.read(1)",
            "        if char != b'\\n':",
            "            self._chunked_input_error = True",
            "            raise _InvalidClientInput(\"Line didn't end in LF: %r\" % (char,))",
            "",
            "    def _chunked_read(self, length=None, use_readline=False):",
            "        # pylint:disable=too-many-branches",
            "        rfile = self.rfile",
            "        self._send_100_continue()",
            "",
            "        if length == 0:",
            "            return b\"\"",
            "",
            "        if use_readline:",
            "            reader = self.rfile.readline",
            "        else:",
            "            reader = self.rfile.read",
            "",
            "        response = []",
            "        while self.chunk_length != 0:",
            "            maxreadlen = self.chunk_length - self.position",
            "            if length is not None and length < maxreadlen:",
            "                maxreadlen = length",
            "",
            "            if maxreadlen > 0:",
            "                data = reader(maxreadlen)",
            "                if not data:",
            "                    self.chunk_length = 0",
            "                    self._chunked_input_error = True",
            "                    raise IOError(\"unexpected end of file while parsing chunked data\")",
            "",
            "                datalen = len(data)",
            "                response.append(data)",
            "",
            "                self.position += datalen",
            "                if self.chunk_length == self.position:",
            "                    self.__read_chunk_size_crlf(rfile)",
            "",
            "                if length is not None:",
            "                    length -= datalen",
            "                    if length == 0:",
            "                        break",
            "                if use_readline and data[-1] == b\"\\n\"[0]:",
            "                    break",
            "            else:",
            "                # We're at the beginning of a chunk, so we need to",
            "                # determine the next size to read",
            "                self.chunk_length = self.__read_chunk_length(rfile)",
            "                self.position = 0",
            "                # If chunk_length was 0, we already read any trailers and",
            "                # validated that we have ended with \\r\\n\\r\\n.",
            "",
            "        return b''.join(response)",
            "",
            "    def read(self, length=None):",
            "        if length is not None and length < 0:",
            "            length = None",
            "        if self.chunked_input:",
            "            return self._chunked_read(length)",
            "        return self._do_read(length)",
            "",
            "    def readline(self, size=None):",
            "        if size is not None and size < 0:",
            "            size = None",
            "        if self.chunked_input:",
            "            return self._chunked_read(size, True)",
            "        return self._do_read(size, use_readline=True)",
            "",
            "    def readlines(self, hint=None):",
            "        # pylint:disable=unused-argument",
            "        return list(self)",
            "",
            "    def __iter__(self):",
            "        return self",
            "",
            "    def next(self):",
            "        line = self.readline()",
            "        if not line:",
            "            raise StopIteration",
            "        return line",
            "    __next__ = next",
            "",
            "",
            "try:",
            "    import mimetools",
            "    headers_factory = mimetools.Message",
            "except ImportError:",
            "    # adapt Python 3 HTTP headers to old API",
            "    from http import client # pylint:disable=import-error",
            "",
            "    class OldMessage(client.HTTPMessage):",
            "        def __init__(self, **kwargs):",
            "            super(client.HTTPMessage, self).__init__(**kwargs) # pylint:disable=bad-super-call",
            "            self.status = ''",
            "",
            "        def getheader(self, name, default=None):",
            "            return self.get(name, default)",
            "",
            "        @property",
            "        def headers(self):",
            "            for key, value in self._headers:",
            "                yield '%s: %s\\r\\n' % (key, value)",
            "",
            "        @property",
            "        def typeheader(self):",
            "            return self.get('content-type')",
            "",
            "    def headers_factory(fp, *args): # pylint:disable=unused-argument",
            "        try:",
            "            ret = client.parse_headers(fp, _class=OldMessage)",
            "        except client.LineTooLong:",
            "            ret = OldMessage()",
            "            ret.status = 'Line too long'",
            "        return ret",
            "",
            "",
            "class WSGIHandler(object):",
            "    \"\"\"",
            "    Handles HTTP requests from a socket, creates the WSGI environment, and",
            "    interacts with the WSGI application.",
            "",
            "    This is the default value of :attr:`WSGIServer.handler_class`.",
            "    This class may be subclassed carefully, and that class set on a",
            "    :class:`WSGIServer` instance through a keyword argument at",
            "    construction time.",
            "",
            "    Instances are constructed with the same arguments as passed to the",
            "    server's :meth:`WSGIServer.handle` method followed by the server",
            "    itself. The application and environment are obtained from the server.",
            "",
            "    \"\"\"",
            "    # pylint:disable=too-many-instance-attributes",
            "",
            "    protocol_version = 'HTTP/1.1'",
            "",
            "    def MessageClass(self, *args):",
            "        return headers_factory(*args)",
            "",
            "    # Attributes reset at various times for each request; not public",
            "    # documented. Class attributes to keep the constructor fast",
            "    # (but not make lint tools complain)",
            "",
            "    status = None # byte string: b'200 OK'",
            "    _orig_status = None # native string: '200 OK'",
            "    response_headers = None # list of tuples (b'name', b'value')",
            "    code = None # Integer parsed from status",
            "    provided_date = None",
            "    provided_content_length = None",
            "    close_connection = False",
            "    time_start = 0 # time.time() when begin handling request",
            "    time_finish = 0 # time.time() when done handling request",
            "    headers_sent = False # Have we already sent headers?",
            "    response_use_chunked = False # Write with transfer-encoding chunked",
            "    # Was the connection upgraded? We shouldn't try to chunk writes in that",
            "    # case.",
            "    connection_upgraded = False",
            "    environ = None # Dict from self.get_environ",
            "    application = None # application callable from self.server.application",
            "    requestline = None # native str 'GET / HTTP/1.1'",
            "    response_length = 0 # How much data we sent",
            "    result = None # The return value of the WSGI application",
            "    wsgi_input = None # Instance of Input()",
            "    content_length = 0 # From application-provided headers Incoming",
            "    # request headers, instance of MessageClass (gunicorn uses hasattr",
            "    # on this so the default value needs to be compatible with the",
            "    # API)",
            "    headers = headers_factory(BytesIO())",
            "    request_version = None # str: 'HTTP 1.1'",
            "    command = None # str: 'GET'",
            "    path = None # str: '/'",
            "",
            "    def __init__(self, sock, address, server, rfile=None):",
            "        # Deprecation: The rfile kwarg was introduced in 1.0a1 as part",
            "        # of a refactoring. It was never documented or used. It is",
            "        # considered DEPRECATED and may be removed in the future. Its",
            "        # use is not supported.",
            "",
            "        self.socket = sock",
            "        self.client_address = address",
            "        self.server = server",
            "        if rfile is None:",
            "            self.rfile = sock.makefile('rb', -1)",
            "        else:",
            "            self.rfile = rfile",
            "",
            "    def handle(self):",
            "        \"\"\"",
            "        The main request handling method, called by the server.",
            "",
            "        This method runs a request handling loop, calling",
            "        :meth:`handle_one_request` until all requests on the",
            "        connection have been handled (that is, it implements",
            "        keep-alive).",
            "        \"\"\"",
            "        try:",
            "            while self.socket is not None:",
            "                self.time_start = time.time()",
            "                self.time_finish = 0",
            "",
            "                result = self.handle_one_request()",
            "                if result is None:",
            "                    break",
            "                if result is True:",
            "                    continue",
            "",
            "                self.status, response_body = result # pylint:disable=unpacking-non-sequence",
            "                self.socket.sendall(response_body)",
            "                if self.time_finish == 0:",
            "                    self.time_finish = time.time()",
            "                self.log_request()",
            "                break",
            "        finally:",
            "            if self.socket is not None:",
            "                _sock = getattr(self.socket, '_sock', None) # Python 3",
            "                try:",
            "                    # read out request data to prevent error: [Errno 104] Connection reset by peer",
            "                    if _sock:",
            "                        try:",
            "                            # socket.recv would hang",
            "                            _sock.recv(16384)",
            "                        finally:",
            "                            _sock.close()",
            "                    self.socket.close()",
            "                except socket.error:",
            "                    pass",
            "            self.__dict__.pop('socket', None)",
            "            self.__dict__.pop('rfile', None)",
            "            self.__dict__.pop('wsgi_input', None)",
            "",
            "    def _check_http_version(self):",
            "        version_str = self.request_version",
            "        if not version_str.startswith(\"HTTP/\"):",
            "            return False",
            "        version = tuple(int(x) for x in version_str[5:].split(\".\"))  # \"HTTP/\"",
            "        if version[1] < 0 or version < (0, 9) or version >= (2, 0):",
            "            return False",
            "        return True",
            "",
            "    def read_request(self, raw_requestline):",
            "        \"\"\"",
            "        Parse the incoming request.",
            "",
            "        Parses various headers into ``self.headers`` using",
            "        :attr:`MessageClass`. Other attributes that are set upon a successful",
            "        return of this method include ``self.content_length`` and ``self.close_connection``.",
            "",
            "        :param str raw_requestline: A native :class:`str` representing",
            "           the request line. A processed version of this will be stored",
            "           into ``self.requestline``.",
            "",
            "        :raises ValueError: If the request is invalid. This error will",
            "           not be logged as a traceback (because it's a client issue, not a server problem).",
            "        :return: A boolean value indicating whether the request was successfully parsed.",
            "           This method should either return a true value or have raised a ValueError",
            "           with details about the parsing error.",
            "",
            "        .. versionchanged:: 1.1b6",
            "           Raise the previously documented :exc:`ValueError` in more cases instead of returning a",
            "           false value; this allows subclasses more opportunity to customize behaviour.",
            "        \"\"\"",
            "        # pylint:disable=too-many-branches",
            "        self.requestline = raw_requestline.rstrip()",
            "        words = self.requestline.split()",
            "        if len(words) == 3:",
            "            self.command, self.path, self.request_version = words",
            "            if not self._check_http_version():",
            "                raise _InvalidClientRequest('Invalid http version: %r' % (raw_requestline,))",
            "        elif len(words) == 2:",
            "            self.command, self.path = words",
            "            if self.command != \"GET\":",
            "                raise _InvalidClientRequest('Expected GET method; Got command=%r; path=%r; raw=%r' % (",
            "                    self.command, self.path, raw_requestline,))",
            "            self.request_version = \"HTTP/0.9\"",
            "            # QQQ I'm pretty sure we can drop support for HTTP/0.9",
            "        else:",
            "            raise _InvalidClientRequest('Invalid HTTP method: %r' % (raw_requestline,))",
            "",
            "        self.headers = self.MessageClass(self.rfile, 0)",
            "",
            "        if self.headers.status:",
            "            raise _InvalidClientRequest('Invalid headers status: %r' % (self.headers.status,))",
            "",
            "        if self.headers.get(\"transfer-encoding\", \"\").lower() == \"chunked\":",
            "            try:",
            "                del self.headers[\"content-length\"]",
            "            except KeyError:",
            "                pass",
            "",
            "        content_length = self.headers.get(\"content-length\")",
            "        if content_length is not None:",
            "            content_length = int(content_length)",
            "            if content_length < 0:",
            "                raise _InvalidClientRequest('Invalid Content-Length: %r' % (content_length,))",
            "",
            "            if content_length and self.command in ('HEAD', ):",
            "                raise _InvalidClientRequest('Unexpected Content-Length')",
            "",
            "        self.content_length = content_length",
            "",
            "        if self.request_version == \"HTTP/1.1\":",
            "            conntype = self.headers.get(\"Connection\", \"\").lower()",
            "            self.close_connection = (conntype == 'close') # pylint:disable=superfluous-parens",
            "        elif self.request_version == 'HTTP/1.0':",
            "            conntype = self.headers.get(\"Connection\", \"close\").lower()",
            "            self.close_connection = (conntype != 'keep-alive') # pylint:disable=superfluous-parens",
            "        else:",
            "            # XXX: HTTP 0.9. We should drop support",
            "            self.close_connection = True",
            "",
            "        return True",
            "",
            "    _print_unexpected_exc = staticmethod(traceback.print_exc)",
            "",
            "    def log_error(self, msg, *args):",
            "        if not args:",
            "            # Already fully formatted, no need to do it again; msg",
            "            # might contain % chars that would lead to a formatting",
            "            # error.",
            "            message = msg",
            "        else:",
            "            try:",
            "                message = msg % args",
            "            except Exception: # pylint:disable=broad-except",
            "                self._print_unexpected_exc()",
            "                message = '%r %r' % (msg, args)",
            "        try:",
            "            message = '%s: %s' % (self.socket, message)",
            "        except Exception: # pylint:disable=broad-except",
            "            pass",
            "",
            "        try:",
            "            self.server.error_log.write(message + '\\n')",
            "        except Exception: # pylint:disable=broad-except",
            "            self._print_unexpected_exc()",
            "",
            "    def read_requestline(self):",
            "        \"\"\"",
            "        Read and return the HTTP request line.",
            "",
            "        Under both Python 2 and 3, this should return the native",
            "        ``str`` type; under Python 3, this probably means the bytes read",
            "        from the network need to be decoded (using the ISO-8859-1 charset, aka",
            "        latin-1).",
            "        \"\"\"",
            "        line = self.rfile.readline(MAX_REQUEST_LINE)",
            "        line = line.decode('latin-1')",
            "        return line",
            "",
            "    def handle_one_request(self):",
            "        \"\"\"",
            "        Handles one HTTP request using ``self.socket`` and ``self.rfile``.",
            "",
            "        Each invocation of this method will do several things, including (but not limited to):",
            "",
            "        - Read the request line using :meth:`read_requestline`;",
            "        - Read the rest of the request, including headers, with :meth:`read_request`;",
            "        - Construct a new WSGI environment in ``self.environ`` using :meth:`get_environ`;",
            "        - Store the application in ``self.application``, retrieving it from the server;",
            "        - Handle the remainder of the request, including invoking the application,",
            "          with :meth:`handle_one_response`",
            "",
            "        There are several possible return values to indicate the state",
            "        of the client connection:",
            "",
            "        - ``None``",
            "            The client connection is already closed or should",
            "            be closed because the WSGI application or client set the",
            "            ``Connection: close`` header. The request handling",
            "            loop should terminate and perform cleanup steps.",
            "        - (status, body)",
            "            An HTTP status and body tuple. The request was in error,",
            "            as detailed by the status and body. The request handling",
            "            loop should terminate, close the connection, and perform",
            "            cleanup steps. Note that the ``body`` is the complete contents",
            "            to send to the client, including all headers and the initial",
            "            status line.",
            "        - ``True``",
            "            The literal ``True`` value. The request was successfully handled",
            "            and the response sent to the client by :meth:`handle_one_response`.",
            "            The connection remains open to process more requests and the connection",
            "            handling loop should call this method again. This is the typical return",
            "            value.",
            "",
            "        .. seealso:: :meth:`handle`",
            "",
            "        .. versionchanged:: 1.1b6",
            "           Funnel exceptions having to do with invalid HTTP requests through",
            "           :meth:`_handle_client_error` to allow subclasses to customize. Note that",
            "           this is experimental and may change in the future.",
            "        \"\"\"",
            "        # pylint:disable=too-many-return-statements",
            "        if self.rfile.closed:",
            "            return",
            "",
            "        try:",
            "            self.requestline = self.read_requestline()",
            "            # Account for old subclasses that haven't done this",
            "            if isinstance(self.requestline, bytes):",
            "                self.requestline = self.requestline.decode('latin-1')",
            "        except socket.error:",
            "            # \"Connection reset by peer\" or other socket errors aren't interesting here",
            "            return",
            "",
            "        if not self.requestline:",
            "            return",
            "",
            "        self.response_length = 0",
            "",
            "        if len(self.requestline) >= MAX_REQUEST_LINE:",
            "            return ('414', _REQUEST_TOO_LONG_RESPONSE)",
            "",
            "        try:",
            "            # for compatibility with older versions of pywsgi, we pass self.requestline as an argument there",
            "            # NOTE: read_request is supposed to raise ValueError on invalid input; allow old",
            "            # subclasses that return a False value instead.",
            "            # NOTE: This can mutate the value of self.headers, so self.get_environ() must not be",
            "            # called until AFTER this call is done.",
            "            if not self.read_request(self.requestline):",
            "                return ('400', _BAD_REQUEST_RESPONSE)",
            "        except Exception as ex: # pylint:disable=broad-except",
            "            # Notice we don't use self.handle_error because it reports",
            "            # a 500 error to the client, and this is almost certainly",
            "            # a client error.",
            "            # Provide a hook for subclasses.",
            "            return self._handle_client_error(ex)",
            "",
            "        self.environ = self.get_environ()",
            "        self.application = self.server.application",
            "",
            "        self.handle_one_response()",
            "",
            "        if self.close_connection:",
            "            return",
            "",
            "        if self.rfile.closed:",
            "            return",
            "",
            "        return True  # read more requests",
            "",
            "    def _connection_upgrade_requested(self):",
            "        if self.headers.get('Connection', '').lower() == 'upgrade':",
            "            return True",
            "        if self.headers.get('Upgrade', '').lower() == 'websocket':",
            "            return True",
            "        return False",
            "",
            "    def finalize_headers(self):",
            "        if self.provided_date is None:",
            "            self.response_headers.append((b'Date', format_date_time(time.time())))",
            "",
            "        self.connection_upgraded = self.code == 101",
            "",
            "        if self.code not in (304, 204):",
            "            # the reply will include message-body; make sure we have either Content-Length or chunked",
            "            if self.provided_content_length is None:",
            "                if hasattr(self.result, '__len__'):",
            "                    total_len = sum(len(chunk) for chunk in self.result)",
            "                    total_len_str = str(total_len)",
            "                    total_len_str = total_len_str.encode(\"latin-1\")",
            "                    self.response_headers.append((b'Content-Length', total_len_str))",
            "                else:",
            "                    self.response_use_chunked = (",
            "                        not self.connection_upgraded",
            "                        and self.request_version != 'HTTP/1.0'",
            "                    )",
            "                    if self.response_use_chunked:",
            "                        self.response_headers.append((b'Transfer-Encoding', b'chunked'))",
            "",
            "    def _sendall(self, data):",
            "        try:",
            "            self.socket.sendall(data)",
            "        except socket.error as ex:",
            "            self.status = 'socket error: %s' % ex",
            "            if self.code > 0:",
            "                self.code = -self.code",
            "            raise",
            "        self.response_length += len(data)",
            "",
            "    def _write(self, data,",
            "               _bytearray=bytearray):",
            "        if not data:",
            "            # The application/middleware are allowed to yield",
            "            # empty bytestrings.",
            "            return",
            "",
            "        if self.response_use_chunked:",
            "            # Write the chunked encoding header",
            "            header_str = b'%x\\r\\n' % len(data)",
            "            towrite = _bytearray(header_str)",
            "",
            "            # data",
            "            towrite += data",
            "            # trailer",
            "            towrite += b'\\r\\n'",
            "            self._sendall(towrite)",
            "        else:",
            "            self._sendall(data)",
            "",
            "    ApplicationError = AssertionError",
            "",
            "    def write(self, data):",
            "        # The write() callable we return from start_response.",
            "        # https://www.python.org/dev/peps/pep-3333/#the-write-callable",
            "        # Supposed to do pretty much the same thing as yielding values",
            "        # from the application's return.",
            "        if self.code in (304, 204) and data:",
            "            raise self.ApplicationError('The %s response must have no body' % self.code)",
            "",
            "        if self.headers_sent:",
            "            self._write(data)",
            "        else:",
            "            if not self.status:",
            "                raise self.ApplicationError(\"The application did not call start_response()\")",
            "            self._write_with_headers(data)",
            "",
            "    def _write_with_headers(self, data):",
            "        self.headers_sent = True",
            "        self.finalize_headers()",
            "",
            "        # self.response_headers and self.status are already in latin-1, as encoded by self.start_response",
            "        towrite = bytearray(b'HTTP/1.1 ')",
            "        towrite += self.status",
            "        towrite += b'\\r\\n'",
            "        for header, value in self.response_headers:",
            "            towrite += header",
            "            towrite += b': '",
            "            towrite += value",
            "            towrite += b\"\\r\\n\"",
            "",
            "        towrite += b'\\r\\n'",
            "        self._sendall(towrite)",
            "        # No need to copy the data into towrite; we may make an extra syscall",
            "        # but the copy time could be substantial too, and it reduces the chances",
            "        # of sendall being able to send everything in one go",
            "        self._write(data)",
            "",
            "    def start_response(self, status, headers, exc_info=None):",
            "        \"\"\"",
            "         .. versionchanged:: 1.2a1",
            "            Avoid HTTP header injection by raising a :exc:`ValueError`",
            "            if *status* or any *header* name or value contains a carriage",
            "            return or newline.",
            "         .. versionchanged:: 1.1b5",
            "            Pro-actively handle checking the encoding of the status line",
            "            and headers during this method. On Python 2, avoid some",
            "            extra encodings.",
            "        \"\"\"",
            "        # pylint:disable=too-many-branches,too-many-statements",
            "        if exc_info:",
            "            try:",
            "                if self.headers_sent:",
            "                    # Re-raise original exception if headers sent",
            "                    reraise(*exc_info)",
            "            finally:",
            "                # Avoid dangling circular ref",
            "                exc_info = None",
            "",
            "        # Pep 3333, \"The start_response callable\":",
            "        # https://www.python.org/dev/peps/pep-3333/#the-start-response-callable",
            "        # \"Servers should check for errors in the headers at the time",
            "        # start_response is called, so that an error can be raised",
            "        # while the application is still running.\" Here, we check the encoding.",
            "        # This aids debugging: headers especially are generated programmatically",
            "        # and an encoding error in a loop or list comprehension yields an opaque",
            "        # UnicodeError without any clue which header was wrong.",
            "        # Note that this results in copying the header list at this point, not modifying it,",
            "        # although we are allowed to do so if needed. This slightly increases memory usage.",
            "        # We also check for HTTP Response Splitting vulnerabilities",
            "        response_headers = []",
            "        header = None",
            "        value = None",
            "        try:",
            "            for header, value in headers:",
            "                if not isinstance(header, str):",
            "                    raise UnicodeError(\"The header must be a native string\", header, value)",
            "                if not isinstance(value, str):",
            "                    raise UnicodeError(\"The value must be a native string\", header, value)",
            "                if '\\r' in header or '\\n' in header:",
            "                    raise ValueError('carriage return or newline in header name', header)",
            "                if '\\r' in value or '\\n' in value:",
            "                    raise ValueError('carriage return or newline in header value', value)",
            "                # Either we're on Python 2, in which case bytes is correct, or",
            "                # we're on Python 3 and the user screwed up (because it should be a native",
            "                # string). In either case, make sure that this is latin-1 compatible. Under",
            "                # Python 2, bytes.encode() will take a round-trip through the system encoding,",
            "                # which may be ascii, which is not really what we want. However, the latin-1 encoding",
            "                # can encode everything except control characters and the block from 0x7F to 0x9F, so",
            "                # explicitly round-tripping bytes through the encoding is unlikely to be of much",
            "                # benefit, so we go for speed (the WSGI spec specifically calls out allowing the range",
            "                # from 0x00 to 0xFF, although the HTTP spec forbids the control characters).",
            "                # Note: Some Python 2 implementations, like Jython, may allow non-octet (above 255) values",
            "                # in their str implementation; this is mentioned in the WSGI spec, but we don't",
            "                # run on any platform like that so we can assume that a str value is pure bytes.",
            "                response_headers.append((header.encode(\"latin-1\"),",
            "                                         value.encode(\"latin-1\")))",
            "        except UnicodeEncodeError:",
            "            # If we get here, we're guaranteed to have a header and value",
            "            raise UnicodeError(\"Non-latin1 header\", repr(header), repr(value))",
            "",
            "        # Same as above",
            "        if not isinstance(status, str):",
            "            raise UnicodeError(\"The status string must be a native string\")",
            "        if '\\r' in status or '\\n' in status:",
            "            raise ValueError(\"carriage return or newline in status\", status)",
            "        # don't assign to anything until the validation is complete, including parsing the",
            "        # code",
            "        code = int(status.split(' ', 1)[0])",
            "",
            "        self.status = status.encode(\"latin-1\")",
            "        self._orig_status = status # Preserve the native string for logging",
            "        self.response_headers = response_headers",
            "        self.code = code",
            "",
            "        provided_connection = None # Did the wsgi app give us a Connection header?",
            "        self.provided_date = None",
            "        self.provided_content_length = None",
            "",
            "        for header, value in headers:",
            "            header = header.lower()",
            "            if header == 'connection':",
            "                provided_connection = value",
            "            elif header == 'date':",
            "                self.provided_date = value",
            "            elif header == 'content-length':",
            "                self.provided_content_length = value",
            "",
            "        if self.request_version == 'HTTP/1.0' and provided_connection is None:",
            "            conntype = b'close' if self.close_connection else b'keep-alive'",
            "            response_headers.append((b'Connection', conntype))",
            "        elif provided_connection == 'close':",
            "            self.close_connection = True",
            "",
            "        if self.code in (304, 204):",
            "            if self.provided_content_length is not None and self.provided_content_length != '0':",
            "                msg = 'Invalid Content-Length for %s response: %r (must be absent or zero)' % (self.code, self.provided_content_length)",
            "                msg = msg.encode('latin-1')",
            "                raise self.ApplicationError(msg)",
            "",
            "        return self.write",
            "",
            "    def log_request(self):",
            "        self.server.log.write(self.format_request() + '\\n')",
            "",
            "    def format_request(self):",
            "        now = datetime.now().replace(microsecond=0)",
            "        length = self.response_length or '-'",
            "        if self.time_finish:",
            "            delta = '%.6f' % (self.time_finish - self.time_start)",
            "        else:",
            "            delta = '-'",
            "        client_address = self.client_address[0] if isinstance(self.client_address, tuple) else self.client_address",
            "        return '%s - - [%s] \"%s\" %s %s %s' % (",
            "            client_address or '-',",
            "            now,",
            "            self.requestline or '',",
            "            # Use the native string version of the status, saved so we don't have to",
            "            # decode. But fallback to the encoded 'status' in case of subclasses",
            "            # (Is that really necessary? At least there's no overhead.)",
            "            (self._orig_status or self.status or '000').split()[0],",
            "            length,",
            "            delta)",
            "",
            "    def process_result(self):",
            "        for data in self.result:",
            "            if data:",
            "                self.write(data)",
            "        if self.status and not self.headers_sent:",
            "            # In other words, the application returned an empty",
            "            # result iterable (and did not use the write callable)",
            "            # Trigger the flush of the headers.",
            "            self.write(b'')",
            "        if self.response_use_chunked:",
            "            self._sendall(b'0\\r\\n\\r\\n')",
            "",
            "",
            "    def run_application(self):",
            "        assert self.result is None",
            "        try:",
            "            self.result = self.application(self.environ, self.start_response)",
            "            self.process_result()",
            "        finally:",
            "            close = getattr(self.result, 'close', None)",
            "            try:",
            "                if close is not None:",
            "                    close()",
            "            finally:",
            "                # Discard the result. If it's a generator this can",
            "                # free a lot of hidden resources (if we failed to iterate",
            "                # all the way through it---the frames are automatically",
            "                # cleaned up when StopIteration is raised); but other cases",
            "                # could still free up resources sooner than otherwise.",
            "                close = None",
            "                self.result = None",
            "",
            "    #: These errors are silently ignored by :meth:`handle_one_response` to avoid producing",
            "    #: excess log entries on normal operating conditions. They indicate",
            "    #: a remote client has disconnected and there is little or nothing",
            "    #: this process can be expected to do about it. You may change this",
            "    #: value in a subclass.",
            "    #:",
            "    #: The default value includes :data:`errno.EPIPE` and :data:`errno.ECONNRESET`.",
            "    #: On Windows this also includes :data:`errno.WSAECONNABORTED`.",
            "    #:",
            "    #: This is a provisional API, subject to change. See :pr:`377`, :pr:`999`",
            "    #: and :issue:`136`.",
            "    #:",
            "    #: .. versionadded:: 1.3",
            "    ignored_socket_errors = (errno.EPIPE, errno.ECONNRESET)",
            "    try:",
            "        ignored_socket_errors += (errno.WSAECONNABORTED,)",
            "    except AttributeError:",
            "        pass # Not windows",
            "",
            "    def handle_one_response(self):",
            "        \"\"\"",
            "        Invoke the application to produce one response.",
            "",
            "        This is called by :meth:`handle_one_request` after all the",
            "        state for the request has been established. It is responsible",
            "        for error handling.",
            "        \"\"\"",
            "        self.time_start = time.time()",
            "        self.status = None",
            "        self.headers_sent = False",
            "",
            "        self.result = None",
            "        self.response_use_chunked = False",
            "        self.connection_upgraded = False",
            "        self.response_length = 0",
            "",
            "        try:",
            "            try:",
            "                self.run_application()",
            "            finally:",
            "                try:",
            "                    self.wsgi_input._discard()",
            "                except _InvalidClientInput:",
            "                    # This one is deliberately raised to the outer",
            "                    # scope, because, with the incoming stream in some bad state,",
            "                    # we can't be sure we can synchronize and properly parse the next",
            "                    # request.",
            "                    raise",
            "                except socket.error:",
            "                    # Don't let socket exceptions during discarding",
            "                    # input override any exception that may have been",
            "                    # raised by the application, such as our own _InvalidClientInput.",
            "                    # In the general case, these aren't even worth logging (see the comment",
            "                    # just below)",
            "                    pass",
            "        except _InvalidClientInput as ex:",
            "            # DO log this one because:",
            "            # - Some of the data may have been read and acted on by the",
            "            #   application;",
            "            # - The response may or may not have been sent;",
            "            # - It's likely that the client is bad, or malicious, and",
            "            #   users might wish to take steps to block the client.",
            "            self._handle_client_error(ex)",
            "            self.close_connection = True",
            "            self._send_error_response_if_possible(400)",
            "        except socket.error as ex:",
            "            if ex.args[0] in self.ignored_socket_errors:",
            "                # See description of self.ignored_socket_errors.",
            "                self.close_connection = True",
            "            else:",
            "                self.handle_error(*sys.exc_info())",
            "        except: # pylint:disable=bare-except",
            "            self.handle_error(*sys.exc_info())",
            "        finally:",
            "            self.time_finish = time.time()",
            "            self.log_request()",
            "",
            "    def _send_error_response_if_possible(self, error_code):",
            "        if self.response_length:",
            "            self.close_connection = True",
            "        else:",
            "            status, headers, body = _ERRORS[error_code]",
            "            try:",
            "                self.start_response(status, headers[:])",
            "                self.write(body)",
            "            except socket.error:",
            "                self.close_connection = True",
            "",
            "    def _log_error(self, t, v, tb):",
            "        # TODO: Shouldn't we dump this to wsgi.errors? If we did that now, it would",
            "        # wind up getting logged twice",
            "        if not issubclass(t, GreenletExit):",
            "            context = self.environ",
            "            if not isinstance(context, self.server.secure_environ_class):",
            "                context = self.server.secure_environ_class(context)",
            "            self.server.loop.handle_error(context, t, v, tb)",
            "",
            "    def handle_error(self, t, v, tb):",
            "        # Called for internal, unexpected errors, NOT invalid client input",
            "        self._log_error(t, v, tb)",
            "        t = v = tb = None",
            "        self._send_error_response_if_possible(500)",
            "",
            "    def _handle_client_error(self, ex):",
            "        # Called for invalid client input",
            "        # Returns the appropriate error response.",
            "        if not isinstance(ex, (ValueError, _InvalidClientInput)):",
            "            # XXX: Why not self._log_error to send it through the loop's",
            "            # handle_error method?",
            "            # _InvalidClientRequest is a ValueError; _InvalidClientInput is an IOError.",
            "            traceback.print_exc()",
            "        if isinstance(ex, _InvalidClientRequest):",
            "            # No formatting needed, that's already been handled. In fact, because the",
            "            # formatted message contains user input, it might have a % in it, and attempting",
            "            # to format that with no arguments would be an error.",
            "            # However, the error messages do not include the requesting IP",
            "            # necessarily, so we do add that.",
            "            self.log_error('(from %s) %s', self.client_address, ex.formatted_message)",
            "        else:",
            "            self.log_error('Invalid request (from %s): %s',",
            "                           self.client_address,",
            "                           str(ex) or ex.__class__.__name__)",
            "        return ('400', _BAD_REQUEST_RESPONSE)",
            "",
            "    def _headers(self):",
            "        key = None",
            "        value = None",
            "        IGNORED_KEYS = (None, 'CONTENT_TYPE', 'CONTENT_LENGTH')",
            "        for header in self.headers.headers:",
            "            if key is not None and header[:1] in \" \\t\":",
            "                value += header",
            "                continue",
            "",
            "            if key not in IGNORED_KEYS:",
            "                yield 'HTTP_' + key, value.strip()",
            "",
            "            key, value = header.split(':', 1)",
            "            if '_' in key:",
            "                # strip incoming bad veaders",
            "                key = None",
            "            else:",
            "                key = key.replace('-', '_').upper()",
            "",
            "        if key not in IGNORED_KEYS:",
            "            yield 'HTTP_' + key, value.strip()",
            "",
            "    def get_environ(self):",
            "        \"\"\"",
            "        Construct and return a new WSGI environment dictionary for a specific request.",
            "",
            "        This should begin with asking the server for the base environment",
            "        using :meth:`WSGIServer.get_environ`, and then proceed to add the",
            "        request specific values.",
            "",
            "        By the time this method is invoked the request line and request shall have",
            "        been parsed and ``self.headers`` shall be populated.",
            "        \"\"\"",
            "        env = self.server.get_environ()",
            "        env['REQUEST_METHOD'] = self.command",
            "        # SCRIPT_NAME is explicitly implementation defined. Using an",
            "        # empty value for SCRIPT_NAME is both explicitly allowed by",
            "        # both the CGI standard and WSGI PEPs, and also the thing that",
            "        # makes the most sense from a generic server perspective (we",
            "        # have no hierarchy or understanding of URLs or files, just a",
            "        # single application to call. The empty string represents the",
            "        # application root, which is what we have). Different WSGI",
            "        # implementations handle this very differently, so portable",
            "        # applications that rely on SCRIPT_NAME will have to use a",
            "        # WSGI middleware to set it to a defined value, or otherwise",
            "        # rely on server-specific mechanisms (e.g, on waitress, use",
            "        # ``--url-prefix``, in gunicorn set the ``SCRIPT_NAME`` header",
            "        # or process environment variable, in gevent subclass",
            "        # WSGIHandler.)",
            "        #",
            "        # See https://github.com/gevent/gevent/issues/1667 for discussion.",
            "        env['SCRIPT_NAME'] = ''",
            "",
            "        path, query = self.path.split('?', 1) if '?' in self.path else (self.path, '')",
            "        # Note that self.path contains the original str object; if it contains",
            "        # encoded escapes, it will NOT match PATH_INFO.",
            "        env['PATH_INFO'] = unquote_latin1(path)",
            "        env['QUERY_STRING'] = query",
            "",
            "        if self.headers.typeheader is not None:",
            "            env['CONTENT_TYPE'] = self.headers.typeheader",
            "",
            "        length = self.headers.getheader('content-length')",
            "        if length:",
            "            env['CONTENT_LENGTH'] = length",
            "        env['SERVER_PROTOCOL'] = self.request_version",
            "",
            "        client_address = self.client_address",
            "        if isinstance(client_address, tuple):",
            "            env['REMOTE_ADDR'] = str(client_address[0])",
            "            env['REMOTE_PORT'] = str(client_address[1])",
            "",
            "        for key, value in self._headers():",
            "            if key in env:",
            "                if 'COOKIE' in key:",
            "                    env[key] += '; ' + value",
            "                else:",
            "                    env[key] += ',' + value",
            "            else:",
            "                env[key] = value",
            "",
            "        sock = self.socket if env.get('HTTP_EXPECT') == '100-continue' else None",
            "",
            "        chunked = env.get('HTTP_TRANSFER_ENCODING', '').lower() == 'chunked'",
            "        # Input refuses to read if the data isn't chunked, and there is no content_length",
            "        # provided. For 'Upgrade: Websocket' requests, neither of those things is true.",
            "        handling_reads = not self._connection_upgrade_requested()",
            "",
            "        self.wsgi_input = Input(self.rfile, self.content_length, socket=sock, chunked_input=chunked)",
            "",
            "        env['wsgi.input'] = self.wsgi_input if handling_reads else self.rfile",
            "        # This is a non-standard flag indicating that our input stream is",
            "        # self-terminated (returns EOF when consumed).",
            "        # See https://github.com/gevent/gevent/issues/1308",
            "        env['wsgi.input_terminated'] = handling_reads",
            "        return env",
            "",
            "",
            "class _NoopLog(object):",
            "    # Does nothing; implements just enough file-like methods",
            "    # to pass the WSGI validator",
            "",
            "    def write(self, *args, **kwargs):",
            "        # pylint:disable=unused-argument",
            "        return",
            "",
            "    def flush(self):",
            "        pass",
            "",
            "    def writelines(self, *args, **kwargs):",
            "        pass",
            "",
            "",
            "class LoggingLogAdapter(object):",
            "    \"\"\"",
            "    An adapter for :class:`logging.Logger` instances",
            "    to let them be used with :class:`WSGIServer`.",
            "",
            "    .. warning:: Unless the entire process is monkey-patched at a very",
            "        early part of the lifecycle (before logging is configured),",
            "        loggers are likely to not be gevent-cooperative. For example,",
            "        the socket and syslog handlers use the socket module in a way",
            "        that can block, and most handlers acquire threading locks.",
            "",
            "    .. warning:: It *may* be possible for the logging functions to be",
            "       called in the :class:`gevent.Hub` greenlet. Code running in the",
            "       hub greenlet cannot use any gevent blocking functions without triggering",
            "       a ``LoopExit``.",
            "",
            "    .. versionadded:: 1.1a3",
            "",
            "    .. versionchanged:: 1.1b6",
            "       Attributes not present on this object are proxied to the underlying",
            "       logger instance. This permits using custom :class:`~logging.Logger`",
            "       subclasses (or indeed, even duck-typed objects).",
            "",
            "    .. versionchanged:: 1.1",
            "       Strip trailing newline characters on the message passed to :meth:`write`",
            "       because log handlers will usually add one themselves.",
            "    \"\"\"",
            "",
            "    # gevent avoids importing and using logging because importing it and",
            "    # creating loggers creates native locks unless monkey-patched.",
            "",
            "    __slots__ = ('_logger', '_level')",
            "",
            "    def __init__(self, logger, level=20):",
            "        \"\"\"",
            "        Write information to the *logger* at the given *level* (default to INFO).",
            "        \"\"\"",
            "        self._logger = logger",
            "        self._level = level",
            "",
            "    def write(self, msg):",
            "        if msg and msg.endswith('\\n'):",
            "            msg = msg[:-1]",
            "        self._logger.log(self._level, msg)",
            "",
            "    def flush(self):",
            "        \"No-op; required to be a file-like object\"",
            "",
            "    def writelines(self, lines):",
            "        for line in lines:",
            "            self.write(line)",
            "",
            "    def __getattr__(self, name):",
            "        return getattr(self._logger, name)",
            "",
            "    def __setattr__(self, name, value):",
            "        if name not in LoggingLogAdapter.__slots__:",
            "            setattr(self._logger, name, value)",
            "        else:",
            "            object.__setattr__(self, name, value)",
            "",
            "    def __delattr__(self, name):",
            "        delattr(self._logger, name)",
            "",
            "####",
            "## Environ classes.",
            "# These subclass dict. They could subclass collections.UserDict on",
            "# 3.3+ and proxy to the underlying real dict to avoid a copy if we",
            "# have to print them (on 2.7 it's slightly more complicated to be an",
            "# instance of collections.MutableMapping; UserDict.UserDict isn't.)",
            "# Then we could have either the WSGIHandler.get_environ or the",
            "# WSGIServer.get_environ return one of these proxies, and",
            "# WSGIHandler.run_application would know to access the `environ.data`",
            "# attribute to be able to pass the *real* dict to the application",
            "# (because PEP3333 requires no subclasses, only actual dict objects;",
            "# wsgiref.validator and webob.Request both enforce this). This has the",
            "# advantage of not being fragile if anybody else tries to print/log",
            "# self.environ (and not requiring a copy). However, if there are any",
            "# subclasses of Handler or Server, this could break if they don't know",
            "# to return this type.",
            "####",
            "",
            "class Environ(dict):",
            "    \"\"\"",
            "    A base class that can be used for WSGI environment objects.",
            "",
            "    Provisional API.",
            "",
            "    .. versionadded:: 1.2a1",
            "    \"\"\"",
            "",
            "    __slots__ = () # add no ivars or weakref ability",
            "",
            "    def copy(self):",
            "        return self.__class__(self)",
            "",
            "    if not hasattr(dict, 'iteritems'):",
            "        # Python 3",
            "        def iteritems(self):",
            "            return self.items()",
            "",
            "    def __reduce_ex__(self, proto):",
            "        return (dict, (), None, None, iter(self.iteritems()))",
            "",
            "class SecureEnviron(Environ):",
            "    \"\"\"",
            "    An environment that does not print its keys and values",
            "    by default.",
            "",
            "    Provisional API.",
            "",
            "    This is intended to keep potentially sensitive information like",
            "    HTTP authorization and cookies from being inadvertently printed",
            "    or logged.",
            "",
            "    For debugging, each instance can have its *secure_repr* attribute",
            "    set to ``False``, which will cause it to print like a normal dict.",
            "",
            "    When *secure_repr* is ``True`` (the default), then the value of",
            "    the *whitelist_keys* attribute is consulted; if this value is",
            "    true-ish, it should be a container (something that responds to",
            "    ``in``) of key names (typically a list or set). Keys and values in",
            "    this dictionary that are in *whitelist_keys* will then be printed,",
            "    while all other values will be masked. These values may be",
            "    customized on the class by setting the *default_secure_repr* and",
            "    *default_whitelist_keys*, respectively::",
            "",
            "        >>> environ = SecureEnviron(key='value')",
            "        >>> environ # doctest: +ELLIPSIS",
            "        <pywsgi.SecureEnviron dict (keys: 1) at ...",
            "",
            "    If we whitelist the key, it gets printed::",
            "",
            "        >>> environ.whitelist_keys = {'key'}",
            "        >>> environ",
            "        {'key': 'value'}",
            "",
            "    A non-whitelisted key (*only*, to avoid doctest issues) is masked::",
            "",
            "        >>> environ['secure'] = 'secret'; del environ['key']",
            "        >>> environ",
            "        {'secure': '<MASKED>'}",
            "",
            "    We can turn it off entirely for the instance::",
            "",
            "        >>> environ.secure_repr = False",
            "        >>> environ",
            "        {'secure': 'secret'}",
            "",
            "    We can also customize it at the class level (here we use a new",
            "    class to be explicit and to avoid polluting the true default",
            "    values; we would set this class to be the ``environ_class`` of the",
            "    server)::",
            "",
            "        >>> class MyEnviron(SecureEnviron):",
            "        ...    default_whitelist_keys = ('key',)",
            "        ...",
            "        >>> environ = MyEnviron({'key': 'value'})",
            "        >>> environ",
            "        {'key': 'value'}",
            "",
            "    .. versionadded:: 1.2a1",
            "    \"\"\"",
            "",
            "    default_secure_repr = True",
            "    default_whitelist_keys = ()",
            "    default_print_masked_keys = True",
            "",
            "    # Allow instances to override the class values,",
            "    # but inherit from the class if not present. Keeps instances",
            "    # small since we can't combine __slots__ with class attributes",
            "    # of the same name.",
            "    __slots__ = ('secure_repr', 'whitelist_keys', 'print_masked_keys')",
            "",
            "    def __getattr__(self, name):",
            "        if name in SecureEnviron.__slots__:",
            "            return getattr(type(self), 'default_' + name)",
            "        raise AttributeError(name)",
            "",
            "    def __repr__(self):",
            "        if self.secure_repr:",
            "            whitelist = self.whitelist_keys",
            "            print_masked = self.print_masked_keys",
            "            if whitelist:",
            "                safe = {k: self[k] if k in whitelist else \"<MASKED>\"",
            "                        for k in self",
            "                        if k in whitelist or print_masked}",
            "                safe_repr = repr(safe)",
            "                if not print_masked and len(safe) != len(self):",
            "                    safe_repr = safe_repr[:-1] + \", (hidden keys: %d)}\" % (len(self) - len(safe))",
            "                return safe_repr",
            "            return \"<pywsgi.SecureEnviron dict (keys: %d) at %s>\" % (len(self), id(self))",
            "        return Environ.__repr__(self)",
            "    __str__ = __repr__",
            "",
            "",
            "class WSGISecureEnviron(SecureEnviron):",
            "    \"\"\"",
            "    Specializes the default list of whitelisted keys to a few",
            "    common WSGI variables.",
            "",
            "    Example::",
            "",
            "       >>> environ = WSGISecureEnviron(REMOTE_ADDR='::1', HTTP_AUTHORIZATION='secret')",
            "       >>> environ",
            "       {'REMOTE_ADDR': '::1', (hidden keys: 1)}",
            "       >>> import pprint",
            "       >>> pprint.pprint(environ)",
            "       {'REMOTE_ADDR': '::1', (hidden keys: 1)}",
            "       >>> print(pprint.pformat(environ))",
            "       {'REMOTE_ADDR': '::1', (hidden keys: 1)}",
            "    \"\"\"",
            "    default_whitelist_keys = ('REMOTE_ADDR', 'REMOTE_PORT', 'HTTP_HOST')",
            "    default_print_masked_keys = False",
            "",
            "",
            "class WSGIServer(StreamServer):",
            "    \"\"\"",
            "    A WSGI server based on :class:`StreamServer` that supports HTTPS.",
            "",
            "",
            "    :keyword log: If given, an object with a ``write`` method to which",
            "        request (access) logs will be written. If not given, defaults",
            "        to :obj:`sys.stderr`. You may pass ``None`` to disable request",
            "        logging. You may use a wrapper, around e.g., :mod:`logging`,",
            "        to support objects that don't implement a ``write`` method.",
            "        (If you pass a :class:`~logging.Logger` instance, or in",
            "        general something that provides a ``log`` method but not a",
            "        ``write`` method, such a wrapper will automatically be created",
            "        and it will be logged to at the :data:`~logging.INFO` level.)",
            "",
            "    :keyword error_log: If given, a file-like object with ``write``,",
            "        ``writelines`` and ``flush`` methods to which error logs will",
            "        be written. If not given, defaults to :obj:`sys.stderr`. You",
            "        may pass ``None`` to disable error logging (not recommended).",
            "        You may use a wrapper, around e.g., :mod:`logging`, to support",
            "        objects that don't implement the proper methods. This",
            "        parameter will become the value for ``wsgi.errors`` in the",
            "        WSGI environment (if not already set). (As with *log*,",
            "        wrappers for :class:`~logging.Logger` instances and the like",
            "        will be created automatically and logged to at the :data:`~logging.ERROR`",
            "        level.)",
            "",
            "    .. seealso::",
            "",
            "        :class:`LoggingLogAdapter`",
            "            See important warnings before attempting to use :mod:`logging`.",
            "",
            "    .. versionchanged:: 1.1a3",
            "        Added the ``error_log`` parameter, and set ``wsgi.errors`` in the WSGI",
            "        environment to this value.",
            "    .. versionchanged:: 1.1a3",
            "        Add support for passing :class:`logging.Logger` objects to the ``log`` and",
            "        ``error_log`` arguments.",
            "    .. versionchanged:: 20.6.0",
            "        Passing a ``handle`` kwarg to the constructor is now officially deprecated.",
            "    \"\"\"",
            "",
            "    #: A callable taking three arguments: (socket, address, server) and returning",
            "    #: an object with a ``handle()`` method. The callable is called once for",
            "    #: each incoming socket request, as is its handle method. The handle method should not",
            "    #: return until all use of the socket is complete.",
            "    #:",
            "    #: This class uses the :class:`WSGIHandler` object as the default value. You may",
            "    #: subclass this class and set a different default value, or you may pass",
            "    #: a value to use in the ``handler_class`` keyword constructor argument.",
            "    handler_class = WSGIHandler",
            "",
            "    #: The object to which request logs will be written.",
            "    #: It must never be None. Initialized from the ``log`` constructor",
            "    #: parameter.",
            "    log = None",
            "",
            "    #: The object to which error logs will be written.",
            "    #: It must never be None. Initialized from the ``error_log`` constructor",
            "    #: parameter.",
            "    error_log = None",
            "",
            "    #: The class of environ objects passed to the handlers.",
            "    #: Must be a dict subclass. For compliance with :pep:`3333`",
            "    #: and libraries like WebOb, this is simply :class:`dict`",
            "    #: but this can be customized in a subclass or per-instance",
            "    #: (probably to :class:`WSGISecureEnviron`).",
            "    #:",
            "    #: .. versionadded:: 1.2a1",
            "    environ_class = dict",
            "",
            "    # Undocumented internal detail: the class that WSGIHandler._log_error",
            "    # will cast to before passing to the loop.",
            "    secure_environ_class = WSGISecureEnviron",
            "",
            "    base_env = {'GATEWAY_INTERFACE': 'CGI/1.1',",
            "                'SERVER_SOFTWARE': 'gevent/%d.%d Python/%d.%d' % (gevent.version_info[:2] + sys.version_info[:2]),",
            "                'SCRIPT_NAME': '',",
            "                'wsgi.version': (1, 0),",
            "                'wsgi.multithread': False, # XXX: Aren't we really, though?",
            "                'wsgi.multiprocess': False,",
            "                'wsgi.run_once': False}",
            "",
            "    def __init__(self, listener, application=None, backlog=None, spawn='default',",
            "                 log='default', error_log='default',",
            "                 handler_class=None,",
            "                 environ=None, **ssl_args):",
            "        if 'handle' in ssl_args:",
            "            # The ultimate base class (BaseServer) uses 'handle' for",
            "            # the thing we call 'application'. We never deliberately",
            "            # bass a `handle` argument to the base class, but one",
            "            # could sneak in through ``**ssl_args``, even though that",
            "            # is not the intent, while application is None. That",
            "            # causes our own ``def handle`` method to be replaced,",
            "            # probably leading to bad results. Passing a 'handle'",
            "            # instead of an 'application' can really confuse things.",
            "            import warnings",
            "            warnings.warn(\"Passing 'handle' kwarg to WSGIServer is deprecated. \"",
            "                          \"Did you mean application?\", DeprecationWarning, stacklevel=2)",
            "",
            "        StreamServer.__init__(self, listener, backlog=backlog, spawn=spawn, **ssl_args)",
            "",
            "        if application is not None:",
            "            self.application = application",
            "        if handler_class is not None:",
            "            self.handler_class = handler_class",
            "",
            "        # Note that we can't initialize these as class variables:",
            "        # sys.stderr might get monkey patched at runtime.",
            "        def _make_log(l, level=20):",
            "            if l == 'default':",
            "                return sys.stderr",
            "            if l is None:",
            "                return _NoopLog()",
            "            if not hasattr(l, 'write') and hasattr(l, 'log'):",
            "                return LoggingLogAdapter(l, level)",
            "            return l",
            "        self.log = _make_log(log)",
            "        self.error_log = _make_log(error_log, 40) # logging.ERROR",
            "",
            "        self.set_environ(environ)",
            "        self.set_max_accept()",
            "",
            "    def set_environ(self, environ=None):",
            "        if environ is not None:",
            "            self.environ = environ",
            "        environ_update = getattr(self, 'environ', None)",
            "",
            "        self.environ = self.environ_class(self.base_env)",
            "        if self.ssl_enabled:",
            "            self.environ['wsgi.url_scheme'] = 'https'",
            "        else:",
            "            self.environ['wsgi.url_scheme'] = 'http'",
            "        if environ_update is not None:",
            "            self.environ.update(environ_update)",
            "        if self.environ.get('wsgi.errors') is None:",
            "            self.environ['wsgi.errors'] = self.error_log",
            "",
            "    def set_max_accept(self):",
            "        if self.environ.get('wsgi.multiprocess'):",
            "            self.max_accept = 1",
            "",
            "    def get_environ(self):",
            "        return self.environ_class(self.environ)",
            "",
            "    def init_socket(self):",
            "        StreamServer.init_socket(self)",
            "        self.update_environ()",
            "",
            "    def update_environ(self):",
            "        \"\"\"",
            "        Called before the first request is handled to fill in WSGI environment values.",
            "",
            "        This includes getting the correct server name and port.",
            "        \"\"\"",
            "        address = self.address",
            "        if isinstance(address, tuple):",
            "            if 'SERVER_NAME' not in self.environ:",
            "                try:",
            "                    name = socket.getfqdn(address[0])",
            "                except socket.error:",
            "                    name = str(address[0])",
            "                if not isinstance(name, str):",
            "                    name = name.decode('ascii')",
            "                self.environ['SERVER_NAME'] = name",
            "            self.environ.setdefault('SERVER_PORT', str(address[1]))",
            "        else:",
            "            self.environ.setdefault('SERVER_NAME', '')",
            "            self.environ.setdefault('SERVER_PORT', '')",
            "",
            "    def handle(self, sock, address):",
            "        \"\"\"",
            "        Create an instance of :attr:`handler_class` to handle the request.",
            "",
            "        This method blocks until the handler returns.",
            "        \"\"\"",
            "        # pylint:disable=method-hidden",
            "        handler = self.handler_class(sock, address, self)",
            "        handler.handle()",
            "",
            "def _main():",
            "    # Provisional main handler, for quick tests, not production",
            "    # usage.",
            "    from gevent import monkey; monkey.patch_all()",
            "",
            "    import argparse",
            "    import importlib",
            "",
            "    parser = argparse.ArgumentParser()",
            "    parser.add_argument(\"app\", help=\"dotted name of WSGI app callable [module:callable]\")",
            "    parser.add_argument(\"-b\", \"--bind\",",
            "                        help=\"The socket to bind\",",
            "                        default=\":8080\")",
            "",
            "    args = parser.parse_args()",
            "",
            "    module_name, app_name = args.app.split(':')",
            "    module = importlib.import_module(module_name)",
            "    app = getattr(module, app_name)",
            "    bind = args.bind",
            "",
            "    server = WSGIServer(bind, app)",
            "    server.serve_forever()",
            "",
            "if __name__ == '__main__':",
            "    _main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "16": [],
            "32": [],
            "33": [],
            "34": [],
            "35": [],
            "60": [
                "_WEEKDAYNAME"
            ],
            "61": [
                "_MONTHNAME"
            ],
            "63": [],
            "73": [
                "_INTERNAL_ERROR_HEADERS"
            ],
            "74": [],
            "75": [],
            "80": [
                "_BAD_REQUEST_HEADERS"
            ],
            "81": [],
            "82": [],
            "210": [
                "Input",
                "__read_chunk_length"
            ],
            "211": [
                "Input",
                "__read_chunk_length"
            ],
            "212": [
                "Input",
                "__read_chunk_length"
            ],
            "213": [
                "Input",
                "__read_chunk_length"
            ],
            "214": [
                "Input",
                "__read_chunk_length"
            ],
            "215": [
                "Input",
                "__read_chunk_length"
            ],
            "216": [
                "Input",
                "__read_chunk_length"
            ],
            "217": [
                "Input",
                "__read_chunk_length"
            ],
            "218": [
                "Input",
                "__read_chunk_length"
            ],
            "219": [
                "Input",
                "__read_chunk_length"
            ],
            "220": [
                "Input",
                "__read_chunk_length"
            ],
            "221": [
                "Input",
                "__read_chunk_length"
            ],
            "222": [
                "Input",
                "__read_chunk_length"
            ],
            "223": [
                "Input",
                "__read_chunk_length"
            ],
            "224": [
                "Input",
                "__read_chunk_length"
            ],
            "225": [
                "Input",
                "__read_chunk_length"
            ],
            "226": [
                "Input",
                "__read_chunk_length"
            ],
            "234": [
                "Input",
                "__read_chunk_length"
            ],
            "235": [
                "Input",
                "__read_chunk_length"
            ],
            "236": [
                "Input",
                "__read_chunk_length"
            ],
            "239": [
                "Input",
                "__read_chunk_length"
            ],
            "243": [
                "Input",
                "__read_chunk_length"
            ],
            "264": [
                "Input",
                "__read_chunk_length"
            ],
            "266": [
                "Input",
                "__read_chunk_length"
            ],
            "267": [
                "Input",
                "__read_chunk_length"
            ],
            "300": [
                "Input",
                "_chunked_read"
            ],
            "313": [
                "Input",
                "_chunked_read"
            ],
            "314": [
                "Input",
                "_chunked_read"
            ],
            "315": [
                "Input",
                "_chunked_read"
            ],
            "534": [
                "WSGIHandler",
                "read_request"
            ],
            "1000": [
                "WSGIHandler",
                "handle_one_response"
            ],
            "1006": [
                "WSGIHandler",
                "handle_one_response"
            ],
            "1049": [
                "WSGIHandler",
                "_handle_client_error"
            ],
            "1057": [
                "WSGIHandler",
                "_handle_client_error"
            ],
            "1059": [
                "WSGIHandler",
                "_handle_client_error"
            ]
        },
        "addLocation": []
    },
    "src/gevent/subprocess.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 360,
                "afterPatchRowNumber": 360,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 361,
                "afterPatchRowNumber": 361,
                "PatchRowcode": "     To capture standard error in the result, use ``stderr=STDOUT``::"
            },
            "2": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": 362,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 363,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        >>> print(check_output([\"/bin/sh\", \"-c\","
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+        >>> output = check_output([\"/bin/sh\", \"-c\","
            },
            "5": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": 364,
                "PatchRowcode": "         ...               \"ls -l non_existent_file ; exit 0\"],"
            },
            "6": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ...              stderr=STDOUT).decode('ascii').strip())"
            },
            "7": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ls: non_existent_file: No such file or directory"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+        ...              stderr=STDOUT).decode('ascii').strip()"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+        >>> print(output.rsplit(':', 1)[1].strip())"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+        No such file or directory"
            },
            "11": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 368,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 368,
                "afterPatchRowNumber": 369,
                "PatchRowcode": "     There is an additional optional argument, \"input\", allowing you to"
            },
            "13": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": 370,
                "PatchRowcode": "     pass a string to the subprocess's stdin.  If you use this argument"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Cooperative ``subprocess`` module.",
            "",
            ".. caution:: On POSIX platforms, this module is not usable from native",
            "   threads other than the main thread; attempting to do so will raise",
            "   a :exc:`TypeError`. This module depends on libev's fork watchers.",
            "   On POSIX systems, fork watchers are implemented using signals, and",
            "   the thread to which process-directed signals are delivered `is not",
            "   defined`_. Because each native thread has its own gevent/libev",
            "   loop, this means that a fork watcher registered with one loop",
            "   (thread) may never see the signal about a child it spawned if the",
            "   signal is sent to a different thread.",
            "",
            ".. note:: The interface of this module is intended to match that of",
            "   the standard library :mod:`subprocess` module (with many backwards",
            "   compatible extensions from Python 3 backported to Python 2). There",
            "   are some small differences between the Python 2 and Python 3",
            "   versions of that module (the Python 2 ``TimeoutExpired`` exception,",
            "   notably, extends ``Timeout`` and there is no ``SubprocessError``) and between the",
            "   POSIX and Windows versions. The HTML documentation here can only",
            "   describe one version; for definitive documentation, see the",
            "   standard library or the source code.",
            "",
            ".. _is not defined: http://www.linuxprogrammingblog.com/all-about-linux-signals?page=11",
            "\"\"\"",
            "from __future__ import absolute_import, print_function",
            "# Can we split this up to make it cleaner? See https://github.com/gevent/gevent/issues/748",
            "# pylint: disable=too-many-lines",
            "# Most of this we inherit from the standard lib",
            "# pylint: disable=bare-except,too-many-locals,too-many-statements,attribute-defined-outside-init",
            "# pylint: disable=too-many-branches,too-many-instance-attributes",
            "# Most of this is cross-platform",
            "# pylint: disable=no-member,expression-not-assigned,unused-argument,unused-variable",
            "import errno",
            "import gc",
            "import os",
            "import signal",
            "import sys",
            "import traceback",
            "# Python 3.9",
            "try:",
            "    from types import GenericAlias",
            "except ImportError:",
            "    GenericAlias = None",
            "",
            "try:",
            "    import grp",
            "except ImportError:",
            "    grp = None",
            "",
            "try:",
            "    import pwd",
            "except ImportError:",
            "    pwd = None",
            "",
            "from gevent.event import AsyncResult",
            "from gevent.hub import _get_hub_noargs as get_hub",
            "from gevent.hub import linkproxy",
            "from gevent.hub import sleep",
            "from gevent.hub import getcurrent",
            "from gevent._compat import integer_types, string_types, xrange",
            "",
            "from gevent._compat import PY311",
            "from gevent._compat import PYPY",
            "",
            "from gevent._compat import fsdecode",
            "from gevent._compat import fsencode",
            "from gevent._compat import PathLike",
            "from gevent._util import _NONE",
            "from gevent._util import copy_globals",
            "",
            "from gevent.greenlet import Greenlet, joinall",
            "spawn = Greenlet.spawn",
            "import subprocess as __subprocess__",
            "",
            "",
            "# Standard functions and classes that this module re-implements in a gevent-aware way.",
            "__implements__ = [",
            "    'Popen',",
            "    'call',",
            "    'check_call',",
            "    'check_output',",
            "]",
            "if not sys.platform.startswith('win32'):",
            "    __implements__.append(\"_posixsubprocess\")",
            "    _posixsubprocess = None",
            "",
            "",
            "# Some symbols we define that we expect to export;",
            "# useful for static analysis",
            "PIPE = \"PIPE should be imported\"",
            "",
            "# Standard functions and classes that this module re-imports.",
            "__imports__ = [",
            "    'PIPE',",
            "    'STDOUT',",
            "    'CalledProcessError',",
            "    # Windows:",
            "    'CREATE_NEW_CONSOLE',",
            "    'CREATE_NEW_PROCESS_GROUP',",
            "    'STD_INPUT_HANDLE',",
            "    'STD_OUTPUT_HANDLE',",
            "    'STD_ERROR_HANDLE',",
            "    'SW_HIDE',",
            "    'STARTF_USESTDHANDLES',",
            "    'STARTF_USESHOWWINDOW',",
            "]",
            "",
            "",
            "__extra__ = [",
            "    'MAXFD',",
            "    '_eintr_retry_call',",
            "    'STARTUPINFO',",
            "    'pywintypes',",
            "    'list2cmdline',",
            "    '_subprocess',",
            "    '_winapi',",
            "    # Python 2.5 does not have _subprocess, so we don't use it",
            "    # XXX We don't run on Py 2.5 anymore; can/could/should we use _subprocess?",
            "    # It's only used on mswindows",
            "    'WAIT_OBJECT_0',",
            "    'WaitForSingleObject',",
            "    'GetExitCodeProcess',",
            "    'GetStdHandle',",
            "    'CreatePipe',",
            "    'DuplicateHandle',",
            "    'GetCurrentProcess',",
            "    'DUPLICATE_SAME_ACCESS',",
            "    'GetModuleFileName',",
            "    'GetVersion',",
            "    'CreateProcess',",
            "    'INFINITE',",
            "    'TerminateProcess',",
            "    'STILL_ACTIVE',",
            "",
            "    # These were added for 3.5, but we make them available everywhere.",
            "    'run',",
            "    'CompletedProcess',",
            "]",
            "",
            "__imports__ += [",
            "    'DEVNULL',",
            "    'getstatusoutput',",
            "    'getoutput',",
            "    'SubprocessError',",
            "    'TimeoutExpired',",
            "]",
            "",
            "# Became standard in 3.5",
            "__extra__.remove('run')",
            "__extra__.remove('CompletedProcess')",
            "__implements__.append('run')",
            "__implements__.append('CompletedProcess')",
            "",
            "# Removed in Python 3.5; this is the exact code that was removed:",
            "# https://hg.python.org/cpython/rev/f98b0a5e5ef5",
            "__extra__.remove('MAXFD')",
            "try:",
            "    MAXFD = os.sysconf(\"SC_OPEN_MAX\")",
            "except:",
            "    MAXFD = 256",
            "",
            "",
            "# This was added to __all__ for windows in 3.6",
            "__extra__.remove('STARTUPINFO')",
            "__imports__.append('STARTUPINFO')",
            "",
            "__imports__.extend([",
            "    'ABOVE_NORMAL_PRIORITY_CLASS', 'BELOW_NORMAL_PRIORITY_CLASS',",
            "    'HIGH_PRIORITY_CLASS', 'IDLE_PRIORITY_CLASS',",
            "    'NORMAL_PRIORITY_CLASS',",
            "    'REALTIME_PRIORITY_CLASS',",
            "    'CREATE_NO_WINDOW', 'DETACHED_PROCESS',",
            "    'CREATE_DEFAULT_ERROR_MODE',",
            "    'CREATE_BREAKAWAY_FROM_JOB'",
            "])",
            "",
            "",
            "# Using os.posix_spawn() to start subprocesses",
            "# bypasses our child watchers on certain operating systems,",
            "# and with certain library versions. Possibly the right",
            "# fix is to monkey-patch os.posix_spawn like we do os.fork?",
            "# These have no effect, they're just here to match the stdlib.",
            "# TODO: When available, given a monkey patch on them, I think",
            "# we ought to be able to use them if the stdlib has identified them",
            "# as suitable.",
            "__implements__.extend([",
            "    '_use_posix_spawn',",
            "])",
            "",
            "def _use_posix_spawn():",
            "    return False",
            "",
            "_USE_POSIX_SPAWN = False",
            "",
            "if __subprocess__._USE_POSIX_SPAWN:",
            "    __implements__.extend([",
            "        '_USE_POSIX_SPAWN',",
            "    ])",
            "else:",
            "    __imports__.extend([",
            "        '_USE_POSIX_SPAWN',",
            "    ])",
            "",
            "if PY311:",
            "    # Python 3.11 added some module-level attributes to control the",
            "    # use of vfork. The docs specifically say that you should not try to read",
            "    # them, only set them, so we don't provide them.",
            "    #",
            "    # Python 3.11 also added a test,  test_surrogates_error_message, that behaves",
            "    # differently based on whether or not the pure python implementation of forking",
            "    # is in use, or the one written in C from _posixsubprocess. Obviously we don't call",
            "    # that, so we need to make us look like a pure python version; it checks that this attribute",
            "    # is none for that.",
            "    _fork_exec = None",
            "    __implements__.extend([",
            "        '_fork_exec',",
            "    ] if sys.platform != 'win32' else [",
            "    ])",
            "",
            "actually_imported = copy_globals(__subprocess__, globals(),",
            "                                 only_names=__imports__,",
            "                                 ignore_missing_names=True)",
            "# anything we couldn't import from here we may need to find",
            "# elsewhere",
            "__extra__.extend(set(__imports__).difference(set(actually_imported)))",
            "__imports__ = actually_imported",
            "del actually_imported",
            "",
            "",
            "# In Python 3 on Windows, a lot of the functions previously",
            "# in _subprocess moved to _winapi",
            "_subprocess = getattr(__subprocess__, '_subprocess', _NONE)",
            "_winapi = getattr(__subprocess__, '_winapi', _NONE)",
            "",
            "_attr_resolution_order = [__subprocess__, _subprocess, _winapi]",
            "",
            "for name in list(__extra__):",
            "    if name in globals():",
            "        continue",
            "    value = _NONE",
            "    for place in _attr_resolution_order:",
            "        value = getattr(place, name, _NONE)",
            "        if value is not _NONE:",
            "            break",
            "",
            "    if value is _NONE:",
            "        __extra__.remove(name)",
            "    else:",
            "        globals()[name] = value",
            "",
            "del _attr_resolution_order",
            "__all__ = __implements__ + __imports__",
            "# Some other things we want to document",
            "for _x in ('run', 'CompletedProcess', 'TimeoutExpired'):",
            "    if _x not in __all__:",
            "        __all__.append(_x)",
            "",
            "",
            "",
            "mswindows = sys.platform == 'win32'",
            "if mswindows:",
            "    import msvcrt # pylint: disable=import-error",
            "    class Handle(int):",
            "        closed = False",
            "",
            "        def Close(self):",
            "            if not self.closed:",
            "                self.closed = True",
            "                _winapi.CloseHandle(self)",
            "",
            "        def Detach(self):",
            "            if not self.closed:",
            "                self.closed = True",
            "                return int(self)",
            "            raise ValueError(\"already closed\")",
            "",
            "        def __repr__(self):",
            "            return \"Handle(%d)\" % int(self)",
            "",
            "        __del__ = Close",
            "        __str__ = __repr__",
            "else:",
            "    import fcntl",
            "    import pickle",
            "    from gevent import monkey",
            "    fork = monkey.get_original('os', 'fork')",
            "    from gevent.os import fork_and_watch",
            "",
            "try:",
            "    BrokenPipeError # pylint:disable=used-before-assignment",
            "except NameError: # Python 2",
            "    class BrokenPipeError(Exception):",
            "        \"Never raised, never caught.\"",
            "",
            "",
            "def call(*popenargs, **kwargs):",
            "    \"\"\"",
            "    call(args, *, stdin=None, stdout=None, stderr=None, shell=False, timeout=None) -> returncode",
            "",
            "    Run command with arguments. Wait for command to complete or",
            "    timeout, then return the returncode attribute.",
            "",
            "    The arguments are the same as for the Popen constructor.  Example::",
            "",
            "        retcode = call([\"ls\", \"-l\"])",
            "",
            "    .. versionchanged:: 1.2a1",
            "       The ``timeout`` keyword argument is now accepted on all supported",
            "       versions of Python (not just Python 3) and if it expires will raise a",
            "       :exc:`TimeoutExpired` exception (under Python 2 this is a subclass of :exc:`~.Timeout`).",
            "    \"\"\"",
            "    timeout = kwargs.pop('timeout', None)",
            "    with Popen(*popenargs, **kwargs) as p:",
            "        try:",
            "            return p.wait(timeout=timeout, _raise_exc=True)",
            "        except:",
            "            p.kill()",
            "            p.wait()",
            "            raise",
            "",
            "def check_call(*popenargs, **kwargs):",
            "    \"\"\"",
            "    check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False, timeout=None) -> 0",
            "",
            "    Run command with arguments.  Wait for command to complete.  If",
            "    the exit code was zero then return, otherwise raise",
            "    :exc:`CalledProcessError`.  The ``CalledProcessError`` object will have the",
            "    return code in the returncode attribute.",
            "",
            "    The arguments are the same as for the Popen constructor.  Example::",
            "",
            "        retcode = check_call([\"ls\", \"-l\"])",
            "    \"\"\"",
            "    retcode = call(*popenargs, **kwargs)",
            "    if retcode:",
            "        cmd = kwargs.get(\"args\")",
            "        if cmd is None:",
            "            cmd = popenargs[0]",
            "        raise CalledProcessError(retcode, cmd) # pylint:disable=undefined-variable",
            "    return 0",
            "",
            "def check_output(*popenargs, **kwargs):",
            "    r\"\"\"",
            "    check_output(args, *, input=None, stdin=None, stderr=None, shell=False, universal_newlines=False, timeout=None) -> output",
            "",
            "    Run command with arguments and return its output.",
            "",
            "    If the exit code was non-zero it raises a :exc:`CalledProcessError`.  The",
            "    ``CalledProcessError`` object will have the return code in the returncode",
            "    attribute and output in the output attribute.",
            "",
            "",
            "    The arguments are the same as for the Popen constructor.  Example::",
            "",
            "        >>> check_output([\"ls\", \"-1\", \"/dev/null\"])",
            "        '/dev/null\\n'",
            "",
            "    The ``stdout`` argument is not allowed as it is used internally.",
            "",
            "    To capture standard error in the result, use ``stderr=STDOUT``::",
            "",
            "        >>> print(check_output([\"/bin/sh\", \"-c\",",
            "        ...               \"ls -l non_existent_file ; exit 0\"],",
            "        ...              stderr=STDOUT).decode('ascii').strip())",
            "        ls: non_existent_file: No such file or directory",
            "",
            "    There is an additional optional argument, \"input\", allowing you to",
            "    pass a string to the subprocess's stdin.  If you use this argument",
            "    you may not also use the Popen constructor's \"stdin\" argument, as",
            "    it too will be used internally.  Example::",
            "",
            "        >>> check_output([\"sed\", \"-e\", \"s/foo/bar/\"],",
            "        ...              input=b\"when in the course of fooman events\\n\")",
            "        'when in the course of barman events\\n'",
            "",
            "    If ``universal_newlines=True`` is passed, the return value will be a",
            "    string rather than bytes.",
            "",
            "    .. versionchanged:: 1.2a1",
            "       The ``timeout`` keyword argument is now accepted on all supported",
            "       versions of Python (not just Python 3) and if it expires will raise a",
            "       :exc:`TimeoutExpired` exception (under Python 2 this is a subclass of :exc:`~.Timeout`).",
            "    .. versionchanged:: 1.2a1",
            "       The ``input`` keyword argument is now accepted on all supported",
            "       versions of Python, not just Python 3",
            "    .. versionchanged:: 22.08.0",
            "       Passing the ``check`` keyword argument is forbidden, just as in Python 3.11.",
            "    \"\"\"",
            "    timeout = kwargs.pop('timeout', None)",
            "    if 'stdout' in kwargs:",
            "        raise ValueError('stdout argument not allowed, it will be overridden.')",
            "    if 'check' in kwargs:",
            "        raise ValueError('check argument not allowed, it will be overridden.')",
            "    if 'input' in kwargs:",
            "        if 'stdin' in kwargs:",
            "            raise ValueError('stdin and input arguments may not both be used.')",
            "        inputdata = kwargs['input']",
            "        del kwargs['input']",
            "        kwargs['stdin'] = PIPE",
            "    else:",
            "        inputdata = None",
            "    with Popen(*popenargs, stdout=PIPE, **kwargs) as process:",
            "        try:",
            "            output, unused_err = process.communicate(inputdata, timeout=timeout)",
            "        except TimeoutExpired:",
            "            process.kill()",
            "            output, unused_err = process.communicate()",
            "            raise TimeoutExpired(process.args, timeout, output=output)",
            "        except:",
            "            process.kill()",
            "            process.wait()",
            "            raise",
            "        retcode = process.poll()",
            "        if retcode:",
            "            # pylint:disable=undefined-variable",
            "            raise CalledProcessError(retcode, process.args, output=output)",
            "    return output",
            "",
            "_PLATFORM_DEFAULT_CLOSE_FDS = object()",
            "",
            "if 'TimeoutExpired' not in globals():",
            "    # Python 2",
            "",
            "    # Make TimeoutExpired inherit from _Timeout so it can be caught",
            "    # the way we used to throw things (except Timeout), but make sure it doesn't",
            "    # init a timer. Note that we can't have a fake 'SubprocessError' that inherits",
            "    # from exception, because we need TimeoutExpired to just be a BaseException for",
            "    # bwc.",
            "    from gevent.timeout import Timeout as _Timeout",
            "",
            "    class TimeoutExpired(_Timeout):",
            "        \"\"\"",
            "        This exception is raised when the timeout expires while waiting for",
            "        a child process in `communicate`.",
            "",
            "        Under Python 2, this is a gevent extension with the same name as the",
            "        Python 3 class for source-code forward compatibility. However, it extends",
            "        :class:`gevent.timeout.Timeout` for backwards compatibility (because",
            "        we used to just raise a plain ``Timeout``); note that ``Timeout`` is a",
            "        ``BaseException``, *not* an ``Exception``.",
            "",
            "        .. versionadded:: 1.2a1",
            "        \"\"\"",
            "",
            "        def __init__(self, cmd, timeout, output=None):",
            "            _Timeout.__init__(self, None)",
            "            self.cmd = cmd",
            "            self.seconds = timeout",
            "            self.output = output",
            "",
            "        @property",
            "        def timeout(self):",
            "            return self.seconds",
            "",
            "        def __str__(self):",
            "            return (\"Command '%s' timed out after %s seconds\" %",
            "                    (self.cmd, self.timeout))",
            "",
            "",
            "if hasattr(os, 'set_inheritable'):",
            "    _set_inheritable = os.set_inheritable",
            "else:",
            "    _set_inheritable = lambda i, v: True",
            "",
            "",
            "def FileObject(*args, **kwargs):",
            "    # Defer importing FileObject until we need it",
            "    # to allow it to be configured more easily.",
            "    from gevent.fileobject import FileObject as _FileObject",
            "    globals()['FileObject'] = _FileObject",
            "    return _FileObject(*args)",
            "",
            "",
            "class _CommunicatingGreenlets(object):",
            "    # At most, exactly one of these objects may be created",
            "    # for a given Popen object. This ensures that only one background",
            "    # greenlet at a time will be reading from the file object. This matters because",
            "    # if a timeout exception is raised, the user may call back into communicate() to",
            "    # get the output (usually after killing the process; see run()). We must not",
            "    # lose output in that case (Python 3 specifically documents that raising a timeout",
            "    # doesn't lose output). Also, attempting to read from a pipe while it's already",
            "    # being read from results in `RuntimeError: reentrant call in io.BufferedReader`;",
            "    # the same thing happens if you attempt to close() it while that's in progress.",
            "    __slots__ = (",
            "        'stdin',",
            "        'stdout',",
            "        'stderr',",
            "        '_all_greenlets',",
            "    )",
            "",
            "    def __init__(self, popen, input_data):",
            "        self.stdin = self.stdout = self.stderr = None",
            "        if popen.stdin: # Even if no data, we need to close",
            "            self.stdin = spawn(self._write_and_close, popen.stdin, input_data)",
            "",
            "        # If the timeout parameter is used, and the caller calls back after",
            "        # getting a TimeoutExpired exception, we can wind up with multiple",
            "        # greenlets trying to run and read from and close stdout/stderr.",
            "        # That's bad because it can lead to 'RuntimeError: reentrant call in io.BufferedReader'.",
            "        # We can't just kill the previous greenlets when a timeout happens,",
            "        # though, because we risk losing the output collected by that greenlet",
            "        # (and Python 3, where timeout is an official parameter, explicitly says",
            "        # that no output should be lost in the event of a timeout.) Instead, we're",
            "        # watching for the exception and ignoring it. It's not elegant,",
            "        # but it works",
            "        if popen.stdout:",
            "            self.stdout = spawn(self._read_and_close, popen.stdout)",
            "",
            "        if popen.stderr:",
            "            self.stderr = spawn(self._read_and_close, popen.stderr)",
            "",
            "        all_greenlets = []",
            "        for g in self.stdin, self.stdout, self.stderr:",
            "            if g is not None:",
            "                all_greenlets.append(g)",
            "        self._all_greenlets = tuple(all_greenlets)",
            "",
            "    def __iter__(self):",
            "        return iter(self._all_greenlets)",
            "",
            "    def __bool__(self):",
            "        return bool(self._all_greenlets)",
            "",
            "    __nonzero__ = __bool__",
            "",
            "    def __len__(self):",
            "        return len(self._all_greenlets)",
            "",
            "    @staticmethod",
            "    def _write_and_close(fobj, data):",
            "        try:",
            "            if data:",
            "                fobj.write(data)",
            "                if hasattr(fobj, 'flush'):",
            "                    # 3.6 started expecting flush to be called.",
            "                    fobj.flush()",
            "        except (OSError, BrokenPipeError) as ex:",
            "            # Test cases from the stdlib can raise BrokenPipeError",
            "            # without setting an errno value. This matters because",
            "            # Python 2 doesn't have a BrokenPipeError.",
            "            if isinstance(ex, BrokenPipeError) and ex.errno is None:",
            "                ex.errno = errno.EPIPE",
            "            if ex.errno not in (errno.EPIPE, errno.EINVAL):",
            "                raise",
            "        finally:",
            "            try:",
            "                fobj.close()",
            "            except EnvironmentError:",
            "                pass",
            "",
            "    @staticmethod",
            "    def _read_and_close(fobj):",
            "        try:",
            "            return fobj.read()",
            "        finally:",
            "            try:",
            "                fobj.close()",
            "            except EnvironmentError:",
            "                pass",
            "",
            "",
            "class Popen(object):",
            "    \"\"\"",
            "    The underlying process creation and management in this module is",
            "    handled by the Popen class. It offers a lot of flexibility so that",
            "    developers are able to handle the less common cases not covered by",
            "    the convenience functions.",
            "",
            "    .. seealso:: :class:`subprocess.Popen`",
            "       This class should have the same interface as the standard library class.",
            "",
            "    .. caution::",
            "",
            "       The default values of some arguments, notably ``buffering``, differ",
            "       between Python 2 and Python 3. For the most consistent behaviour across",
            "       versions, it's best to explicitly pass the desired values.",
            "",
            "    .. caution::",
            "",
            "       On Python 2, the ``read`` method of the ``stdout`` and ``stderr`` attributes",
            "       will not be buffered unless buffering is explicitly requested (e.g., `bufsize=-1`).",
            "       This is different than the ``read`` method of the standard library attributes,",
            "       which will buffer internally even if no buffering has been requested. This",
            "       matches the Python 3 behaviour. For portability, please explicitly request",
            "       buffering if you want ``read(n)`` to return all ``n`` bytes, making more than",
            "       one system call if needed. See `issue 1701 <https://github.com/gevent/gevent/issues/1701>`_",
            "       for more context.",
            "",
            "    .. versionchanged:: 1.2a1",
            "       Instances can now be used as context managers under Python 2.7. Previously",
            "       this was restricted to Python 3.",
            "",
            "    .. versionchanged:: 1.2a1",
            "       Instances now save the ``args`` attribute under Python 2.7. Previously this was",
            "       restricted to Python 3.",
            "",
            "    .. versionchanged:: 1.2b1",
            "        Add the ``encoding`` and ``errors`` parameters for Python 3.",
            "",
            "    .. versionchanged:: 1.3a1",
            "       Accept \"path-like\" objects for the *cwd* parameter on all platforms.",
            "       This was added to Python 3.6. Previously with gevent, it only worked",
            "       on POSIX platforms on 3.6.",
            "",
            "    .. versionchanged:: 1.3a1",
            "       Add the ``text`` argument as a synonym for ``universal_newlines``,",
            "       as added on Python 3.7.",
            "",
            "    .. versionchanged:: 1.3a2",
            "       Allow the same keyword arguments under Python 2 as Python 3:",
            "       ``pass_fds``, ``start_new_session``, ``restore_signals``, ``encoding``",
            "       and ``errors``. Under Python 2, ``encoding`` and ``errors`` are ignored",
            "       because native handling of universal newlines is used.",
            "",
            "    .. versionchanged:: 1.3a2",
            "       Under Python 2, ``restore_signals`` defaults to ``False``. Previously it",
            "       defaulted to ``True``, the same as it did in Python 3.",
            "",
            "    .. versionchanged:: 20.6.0",
            "       Add the *group*, *extra_groups*, *user*, and *umask* arguments. These",
            "       were added to Python 3.9, but are available in any gevent version, provided",
            "       the underlying platform support is present.",
            "",
            "    .. versionchanged:: 20.12.0",
            "       On Python 2 only, if unbuffered binary communication is requested,",
            "       the ``stdin`` attribute of this object will have a ``write`` method that",
            "       actually performs internal buffering and looping, similar to the standard library.",
            "       It guarantees to write all the data given to it in a single call (but internally",
            "       it may make many system calls and/or trips around the event loop to accomplish this).",
            "       See :issue:`1711`.",
            "",
            "    .. versionchanged:: 21.12.0",
            "       Added the ``pipesize`` argument for compatibility with Python 3.10.",
            "       This is ignored on all platforms.",
            "",
            "    .. versionchanged:: 22.08.0",
            "       Added the ``process_group`` and ``check`` arguments for compatibility with",
            "       Python 3.11.",
            "    \"\"\"",
            "",
            "    if GenericAlias is not None:",
            "        # 3.9, annoying typing is creeping everywhere.",
            "        __class_getitem__ = classmethod(GenericAlias)",
            "",
            "    # The value returned from communicate() when there was nothing to read.",
            "    # Changes if we're in text mode or universal newlines mode.",
            "    _communicate_empty_value = b''",
            "",
            "    def __init__(self, args,",
            "                 bufsize=-1,",
            "                 executable=None,",
            "                 stdin=None, stdout=None, stderr=None,",
            "                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS, shell=False,",
            "                 cwd=None, env=None, universal_newlines=None,",
            "                 startupinfo=None, creationflags=0,",
            "                 restore_signals=True, start_new_session=False,",
            "                 pass_fds=(),",
            "                 # Added in 3.6. These are kept as ivars",
            "                 encoding=None, errors=None,",
            "                 # Added in 3.7. Not an ivar directly.",
            "                 text=None,",
            "                 # Added in 3.9",
            "                 group=None, extra_groups=None, user=None,",
            "                 umask=-1,",
            "                 # Added in 3.10, but ignored.",
            "                 pipesize=-1,",
            "                 # Added in 3.11",
            "                 process_group=None,",
            "                 # gevent additions",
            "                 threadpool=None):",
            "",
            "        self.encoding = encoding",
            "        self.errors = errors",
            "",
            "        hub = get_hub()",
            "",
            "        if bufsize is None:",
            "            # Python 2 doesn't allow None at all, but Python 3 treats",
            "            # it the same as the default. We do as well.",
            "            bufsize = -1",
            "        if not isinstance(bufsize, integer_types):",
            "            raise TypeError(\"bufsize must be an integer\")",
            "",
            "        if mswindows:",
            "            if preexec_fn is not None:",
            "                raise ValueError(\"preexec_fn is not supported on Windows \"",
            "                                 \"platforms\")",
            "",
            "            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:",
            "                close_fds = True",
            "",
            "            if threadpool is None:",
            "                threadpool = hub.threadpool",
            "            self.threadpool = threadpool",
            "            self._waiting = False",
            "        else:",
            "            # POSIX",
            "            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:",
            "                # close_fds has different defaults on Py3/Py2",
            "                close_fds = True",
            "",
            "            if pass_fds and not close_fds:",
            "                import warnings",
            "                warnings.warn(\"pass_fds overriding close_fds.\", RuntimeWarning)",
            "                close_fds = True",
            "            if startupinfo is not None:",
            "                raise ValueError(\"startupinfo is only supported on Windows \"",
            "                                 \"platforms\")",
            "            if creationflags != 0:",
            "                raise ValueError(\"creationflags is only supported on Windows \"",
            "                                 \"platforms\")",
            "            assert threadpool is None",
            "            self._loop = hub.loop",
            "",
            "        # Validate the combinations of text and universal_newlines",
            "        if (text is not None and universal_newlines is not None",
            "                and bool(universal_newlines) != bool(text)):",
            "            # pylint:disable=undefined-variable",
            "            raise SubprocessError('Cannot disambiguate when both text '",
            "                                  'and universal_newlines are supplied but '",
            "                                  'different. Pass one or the other.')",
            "",
            "        self.args = args # Previously this was Py3 only.",
            "        self.stdin = None",
            "        self.stdout = None",
            "        self.stderr = None",
            "        self.pid = None",
            "        self.returncode = None",
            "        self.universal_newlines = universal_newlines",
            "        self.result = AsyncResult()",
            "",
            "        # Input and output objects. The general principle is like",
            "        # this:",
            "        #",
            "        # Parent                   Child",
            "        # ------                   -----",
            "        # p2cwrite   ---stdin--->  p2cread",
            "        # c2pread    <--stdout---  c2pwrite",
            "        # errread    <--stderr---  errwrite",
            "        #",
            "        # On POSIX, the child objects are file descriptors.  On",
            "        # Windows, these are Windows file handles.  The parent objects",
            "        # are file descriptors on both platforms.  The parent objects",
            "        # are -1 when not using PIPEs. The child objects are -1",
            "        # when not redirecting.",
            "",
            "        (p2cread, p2cwrite,",
            "         c2pread, c2pwrite,",
            "         errread, errwrite) = self._get_handles(stdin, stdout, stderr)",
            "",
            "        # We wrap OS handles *before* launching the child, otherwise a",
            "        # quickly terminating child could make our fds unwrappable",
            "        # (see #8458).",
            "        if mswindows:",
            "            if p2cwrite != -1:",
            "                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)",
            "            if c2pread != -1:",
            "                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)",
            "            if errread != -1:",
            "                errread = msvcrt.open_osfhandle(errread.Detach(), 0)",
            "",
            "        text_mode = self.encoding or self.errors or universal_newlines or text",
            "        if text_mode or universal_newlines:",
            "            # Always a native str in universal_newlines mode, even when that",
            "            # str type is bytes. Additionally, text_mode is only true under",
            "            # Python 3, so it's actually a unicode str",
            "            self._communicate_empty_value = ''",
            "",
            "        uid, gid, gids = self.__handle_uids(user, group, extra_groups)",
            "",
            "        if p2cwrite != -1:",
            "            if text_mode:",
            "                # Under Python 3, if we left on the 'b' we'd get different results",
            "                # depending on whether we used FileObjectPosix or FileObjectThread",
            "                self.stdin = FileObject(p2cwrite, 'w', bufsize,",
            "                                        encoding=self.encoding, errors=self.errors)",
            "            else:",
            "                self.stdin = FileObject(p2cwrite, 'wb', bufsize)",
            "",
            "        if c2pread != -1:",
            "            if universal_newlines or text_mode:",
            "                self.stdout = FileObject(c2pread, 'r', bufsize,",
            "                                         encoding=self.encoding, errors=self.errors)",
            "                # NOTE: Universal Newlines are broken on Windows/Py3, at least",
            "                # in some cases. This is true in the stdlib subprocess module",
            "                # as well; the following line would fix the test cases in",
            "                # test__subprocess.py that depend on python_universal_newlines,",
            "                # but would be inconsistent with the stdlib:",
            "",
            "            else:",
            "                self.stdout = FileObject(c2pread, 'rb', bufsize)",
            "        if errread != -1:",
            "            if universal_newlines or text_mode:",
            "                self.stderr = FileObject(errread, 'r', bufsize,",
            "                                         encoding=encoding, errors=errors)",
            "            else:",
            "                self.stderr = FileObject(errread, 'rb', bufsize)",
            "",
            "        self._closed_child_pipe_fds = False",
            "        # Convert here for the sake of all platforms. os.chdir accepts",
            "        # path-like objects natively under 3.6, but CreateProcess",
            "        # doesn't.",
            "        cwd = fsdecode(cwd) if cwd is not None else None",
            "        try:",
            "            self._execute_child(args, executable, preexec_fn, close_fds,",
            "                                pass_fds, cwd, env, universal_newlines,",
            "                                startupinfo, creationflags, shell,",
            "                                p2cread, p2cwrite,",
            "                                c2pread, c2pwrite,",
            "                                errread, errwrite,",
            "                                restore_signals,",
            "                                gid, gids, uid, umask,",
            "                                start_new_session, process_group)",
            "        except:",
            "            # Cleanup if the child failed starting.",
            "            # (gevent: New in python3, but reported as gevent bug in #347.",
            "            # Note that under Py2, any error raised below will replace the",
            "            # original error so we have to use reraise)",
            "            for f in filter(None, (self.stdin, self.stdout, self.stderr)):",
            "                try:",
            "                    f.close()",
            "                except OSError:",
            "                    pass  # Ignore EBADF or other errors.",
            "",
            "            if not self._closed_child_pipe_fds:",
            "                to_close = []",
            "                if stdin == PIPE:",
            "                    to_close.append(p2cread)",
            "                if stdout == PIPE:",
            "                    to_close.append(c2pwrite)",
            "                if stderr == PIPE:",
            "                    to_close.append(errwrite)",
            "                if hasattr(self, '_devnull'):",
            "                    to_close.append(self._devnull)",
            "                for fd in to_close:",
            "                    try:",
            "                        os.close(fd)",
            "                    except OSError:",
            "                        pass",
            "            raise",
            "",
            "    def __handle_uids(self, user, group, extra_groups):",
            "        gid = None",
            "        if group is not None:",
            "            if not hasattr(os, 'setregid'):",
            "                raise ValueError(\"The 'group' parameter is not supported on the \"",
            "                                 \"current platform\")",
            "",
            "            if isinstance(group, str):",
            "                if grp is None:",
            "                    raise ValueError(\"The group parameter cannot be a string \"",
            "                                     \"on systems without the grp module\")",
            "",
            "                gid = grp.getgrnam(group).gr_gid",
            "            elif isinstance(group, int):",
            "                gid = group",
            "            else:",
            "                raise TypeError(\"Group must be a string or an integer, not {}\"",
            "                                .format(type(group)))",
            "",
            "            if gid < 0:",
            "                raise ValueError(\"Group ID cannot be negative, got %s\" % gid)",
            "",
            "        gids = None",
            "        if extra_groups is not None:",
            "            if not hasattr(os, 'setgroups'):",
            "                raise ValueError(\"The 'extra_groups' parameter is not \"",
            "                                 \"supported on the current platform\")",
            "",
            "            if isinstance(extra_groups, str):",
            "                raise ValueError(\"Groups must be a list, not a string\")",
            "",
            "            gids = []",
            "            for extra_group in extra_groups:",
            "                if isinstance(extra_group, str):",
            "                    if grp is None:",
            "                        raise ValueError(\"Items in extra_groups cannot be \"",
            "                                         \"strings on systems without the \"",
            "                                         \"grp module\")",
            "",
            "                    gids.append(grp.getgrnam(extra_group).gr_gid)",
            "                elif isinstance(extra_group, int):",
            "                    if extra_group >= 2**64:",
            "                        # This check is implicit in the C version of _Py_Gid_Converter.",
            "                        #",
            "                        # We actually need access to the C type ``gid_t`` to get",
            "                        # its actual length. This just makes the test that was added",
            "                        # for the bug pass. That's OK though, if we guess too big here,",
            "                        # we should get an OverflowError from the setgroups()",
            "                        # call we make. The only difference is the type of exception.",
            "                        #",
            "                        # See https://bugs.python.org/issue42655",
            "                        raise ValueError(\"Item in extra_groups is too large\")",
            "                    gids.append(extra_group)",
            "                else:",
            "                    raise TypeError(\"Items in extra_groups must be a string \"",
            "                                    \"or integer, not {}\"",
            "                                    .format(type(extra_group)))",
            "",
            "            # make sure that the gids are all positive here so we can do less",
            "            # checking in the C code",
            "            for gid_check in gids:",
            "                if gid_check < 0:",
            "                    raise ValueError(\"Group ID cannot be negative, got %s\" % (gid_check,))",
            "",
            "        uid = None",
            "        if user is not None:",
            "            if not hasattr(os, 'setreuid'):",
            "                raise ValueError(\"The 'user' parameter is not supported on \"",
            "                                 \"the current platform\")",
            "",
            "            if isinstance(user, str):",
            "                if pwd is None:",
            "                    raise ValueError(\"The user parameter cannot be a string \"",
            "                                     \"on systems without the pwd module\")",
            "",
            "                uid = pwd.getpwnam(user).pw_uid",
            "            elif isinstance(user, int):",
            "                uid = user",
            "            else:",
            "                raise TypeError(\"User must be a string or an integer\")",
            "",
            "            if uid < 0:",
            "                raise ValueError(\"User ID cannot be negative, got %s\" % (uid,))",
            "",
            "        return uid, gid, gids",
            "",
            "    def __repr__(self):",
            "        return '<%s at 0x%x pid=%r returncode=%r>' % (self.__class__.__name__, id(self), self.pid, self.returncode)",
            "",
            "    def _on_child(self, watcher):",
            "        watcher.stop()",
            "        status = watcher.rstatus",
            "        if os.WIFSIGNALED(status):",
            "            self.returncode = -os.WTERMSIG(status)",
            "        else:",
            "            self.returncode = os.WEXITSTATUS(status)",
            "        self.result.set(self.returncode)",
            "",
            "    def _get_devnull(self):",
            "        if not hasattr(self, '_devnull'):",
            "            self._devnull = os.open(os.devnull, os.O_RDWR)",
            "        return self._devnull",
            "",
            "    _communicating_greenlets = None",
            "",
            "    def communicate(self, input=None, timeout=None):",
            "        \"\"\"",
            "        Interact with process and return its output and error.",
            "",
            "        - Send *input* data to stdin.",
            "        - Read data from stdout and stderr, until end-of-file is reached.",
            "        - Wait for process to terminate.",
            "",
            "        The optional *input* argument should be a",
            "        string to be sent to the child process, or None, if no data",
            "        should be sent to the child.",
            "",
            "        communicate() returns a tuple (stdout, stderr).",
            "",
            "        :keyword timeout: Under Python 2, this is a gevent extension; if",
            "           given and it expires, we will raise :exc:`TimeoutExpired`, which",
            "           extends :exc:`gevent.timeout.Timeout` (note that this only extends :exc:`BaseException`,",
            "           *not* :exc:`Exception`)",
            "           Under Python 3, this raises the standard :exc:`TimeoutExpired` exception.",
            "",
            "        .. versionchanged:: 1.1a2",
            "           Under Python 2, if the *timeout* elapses, raise the :exc:`gevent.timeout.Timeout`",
            "           exception. Previously, we silently returned.",
            "        .. versionchanged:: 1.1b5",
            "           Honor a *timeout* even if there's no way to communicate with the child",
            "           (stdin, stdout, and stderr are not pipes).",
            "        \"\"\"",
            "        if self._communicating_greenlets is None:",
            "            self._communicating_greenlets = _CommunicatingGreenlets(self, input)",
            "        greenlets = self._communicating_greenlets",
            "",
            "        # If we were given stdin=stdout=stderr=None, we have no way to",
            "        # communicate with the child, and thus no greenlets to wait",
            "        # on. This is a nonsense case, but it comes up in the test",
            "        # case for Python 3.5 (test_subprocess.py",
            "        # RunFuncTestCase.test_timeout). Instead, we go directly to",
            "        # self.wait",
            "        if not greenlets and timeout is not None:",
            "            self.wait(timeout=timeout, _raise_exc=True)",
            "",
            "        done = joinall(greenlets, timeout=timeout)",
            "        # Allow finished greenlets, if any, to raise. This takes priority over",
            "        # the timeout exception.",
            "        for greenlet in done:",
            "            greenlet.get()",
            "        if timeout is not None and len(done) != len(self._communicating_greenlets):",
            "            raise TimeoutExpired(self.args, timeout)",
            "",
            "        # Close only after we're sure that everything is done",
            "        # (there was no timeout, or there was, but everything finished).",
            "        # There should be no greenlets still running, even from a prior",
            "        # attempt. If there are, then this can raise RuntimeError: 'reentrant call'.",
            "        # So we ensure that previous greenlets are dead.",
            "        for pipe in (self.stdout, self.stderr):",
            "            if pipe:",
            "                try:",
            "                    pipe.close()",
            "                except RuntimeError:",
            "                    pass",
            "",
            "        self.wait()",
            "",
            "        return (None if greenlets.stdout is None else greenlets.stdout.get(),",
            "                None if greenlets.stderr is None else greenlets.stderr.get())",
            "",
            "    def poll(self):",
            "        \"\"\"Check if child process has terminated. Set and return :attr:`returncode` attribute.\"\"\"",
            "        return self._internal_poll()",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, t, v, tb):",
            "        if self.stdout:",
            "            self.stdout.close()",
            "        if self.stderr:",
            "            self.stderr.close()",
            "        try:  # Flushing a BufferedWriter may raise an error",
            "            if self.stdin:",
            "                self.stdin.close()",
            "        finally:",
            "            # Wait for the process to terminate, to avoid zombies.",
            "            # JAM: gevent: If the process never terminates, this",
            "            # blocks forever.",
            "            self.wait()",
            "",
            "    def _gevent_result_wait(self, timeout=None, raise_exc=True):",
            "        result = self.result.wait(timeout=timeout)",
            "        if raise_exc and timeout is not None and not self.result.ready():",
            "            raise TimeoutExpired(self.args, timeout)",
            "        return result",
            "",
            "",
            "    if mswindows:",
            "        #",
            "        # Windows methods",
            "        #",
            "        def _get_handles(self, stdin, stdout, stderr):",
            "            \"\"\"Construct and return tuple with IO objects:",
            "            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite",
            "            \"\"\"",
            "            # pylint:disable=undefined-variable",
            "            if stdin is None and stdout is None and stderr is None:",
            "                return (-1, -1, -1, -1, -1, -1)",
            "",
            "            p2cread, p2cwrite = -1, -1",
            "            c2pread, c2pwrite = -1, -1",
            "            errread, errwrite = -1, -1",
            "",
            "            try:",
            "                DEVNULL",
            "            except NameError:",
            "                _devnull = object()",
            "            else:",
            "                _devnull = DEVNULL",
            "",
            "            if stdin is None:",
            "                p2cread = GetStdHandle(STD_INPUT_HANDLE)",
            "                if p2cread is None:",
            "                    p2cread, _ = CreatePipe(None, 0)",
            "                    p2cread = Handle(p2cread)",
            "                    _winapi.CloseHandle(_)",
            "            elif stdin == PIPE:",
            "                p2cread, p2cwrite = CreatePipe(None, 0)",
            "                p2cread, p2cwrite = Handle(p2cread), Handle(p2cwrite)",
            "            elif stdin == _devnull:",
            "                p2cread = msvcrt.get_osfhandle(self._get_devnull())",
            "            elif isinstance(stdin, int):",
            "                p2cread = msvcrt.get_osfhandle(stdin)",
            "            else:",
            "                # Assuming file-like object",
            "                p2cread = msvcrt.get_osfhandle(stdin.fileno())",
            "            p2cread = self._make_inheritable(p2cread)",
            "",
            "            if stdout is None:",
            "                c2pwrite = GetStdHandle(STD_OUTPUT_HANDLE)",
            "                if c2pwrite is None:",
            "                    _, c2pwrite = CreatePipe(None, 0)",
            "                    c2pwrite = Handle(c2pwrite)",
            "                    _winapi.CloseHandle(_)",
            "            elif stdout == PIPE:",
            "                c2pread, c2pwrite = CreatePipe(None, 0)",
            "                c2pread, c2pwrite = Handle(c2pread), Handle(c2pwrite)",
            "            elif stdout == _devnull:",
            "                c2pwrite = msvcrt.get_osfhandle(self._get_devnull())",
            "            elif isinstance(stdout, int):",
            "                c2pwrite = msvcrt.get_osfhandle(stdout)",
            "            else:",
            "                # Assuming file-like object",
            "                c2pwrite = msvcrt.get_osfhandle(stdout.fileno())",
            "            c2pwrite = self._make_inheritable(c2pwrite)",
            "",
            "            if stderr is None:",
            "                errwrite = GetStdHandle(STD_ERROR_HANDLE)",
            "                if errwrite is None:",
            "                    _, errwrite = CreatePipe(None, 0)",
            "                    errwrite = Handle(errwrite)",
            "                    _winapi.CloseHandle(_)",
            "            elif stderr == PIPE:",
            "                errread, errwrite = CreatePipe(None, 0)",
            "                errread, errwrite = Handle(errread), Handle(errwrite)",
            "            elif stderr == STDOUT:",
            "                errwrite = c2pwrite",
            "            elif stderr == _devnull:",
            "                errwrite = msvcrt.get_osfhandle(self._get_devnull())",
            "            elif isinstance(stderr, int):",
            "                errwrite = msvcrt.get_osfhandle(stderr)",
            "            else:",
            "                # Assuming file-like object",
            "                errwrite = msvcrt.get_osfhandle(stderr.fileno())",
            "            errwrite = self._make_inheritable(errwrite)",
            "",
            "            return (p2cread, p2cwrite,",
            "                    c2pread, c2pwrite,",
            "                    errread, errwrite)",
            "",
            "        def _make_inheritable(self, handle):",
            "            \"\"\"Return a duplicate of handle, which is inheritable\"\"\"",
            "            # pylint:disable=undefined-variable",
            "            return DuplicateHandle(GetCurrentProcess(),",
            "                                   handle, GetCurrentProcess(), 0, 1,",
            "                                   DUPLICATE_SAME_ACCESS)",
            "",
            "        def _find_w9xpopen(self):",
            "            \"\"\"Find and return absolute path to w9xpopen.exe\"\"\"",
            "            # pylint:disable=undefined-variable",
            "            w9xpopen = os.path.join(os.path.dirname(GetModuleFileName(0)),",
            "                                    \"w9xpopen.exe\")",
            "            if not os.path.exists(w9xpopen):",
            "                # Eeek - file-not-found - possibly an embedding",
            "                # situation - see if we can locate it in sys.exec_prefix",
            "                w9xpopen = os.path.join(os.path.dirname(sys.exec_prefix),",
            "                                        \"w9xpopen.exe\")",
            "                if not os.path.exists(w9xpopen):",
            "                    raise RuntimeError(\"Cannot locate w9xpopen.exe, which is \"",
            "                                       \"needed for Popen to work with your \"",
            "                                       \"shell or platform.\")",
            "            return w9xpopen",
            "",
            "",
            "        def _filter_handle_list(self, handle_list):",
            "            \"\"\"Filter out console handles that can't be used",
            "            in lpAttributeList[\"handle_list\"] and make sure the list",
            "            isn't empty. This also removes duplicate handles.\"\"\"",
            "            # An handle with it's lowest two bits set might be a special console",
            "            # handle that if passed in lpAttributeList[\"handle_list\"], will",
            "            # cause it to fail.",
            "            # Only works on 3.7+",
            "            return list({handle for handle in handle_list",
            "                         if handle & 0x3 != 0x3",
            "                         or _winapi.GetFileType(handle) !=",
            "                         _winapi.FILE_TYPE_CHAR})",
            "",
            "",
            "        def _execute_child(self, args, executable, preexec_fn, close_fds,",
            "                           pass_fds, cwd, env, universal_newlines,",
            "                           startupinfo, creationflags, shell,",
            "                           p2cread, p2cwrite,",
            "                           c2pread, c2pwrite,",
            "                           errread, errwrite,",
            "                           unused_restore_signals,",
            "                           unused_gid, unused_gids, unused_uid, unused_umask,",
            "                           unused_start_new_session, unused_process_group):",
            "            \"\"\"Execute program (MS Windows version)\"\"\"",
            "            # pylint:disable=undefined-variable",
            "            assert not pass_fds, \"pass_fds not supported on Windows.\"",
            "            if isinstance(args, str):",
            "                pass",
            "            elif isinstance(args, bytes):",
            "                if shell:",
            "                    raise TypeError('bytes args is not allowed on Windows')",
            "                args = list2cmdline([args])",
            "            elif isinstance(args, PathLike):",
            "                if shell:",
            "                    raise TypeError('path-like args is not allowed when '",
            "                                    'shell is true')",
            "                args = list2cmdline([args])",
            "            else:",
            "                args = list2cmdline(args)",
            "",
            "            if executable is not None:",
            "                executable = fsdecode(executable)",
            "",
            "            if not isinstance(args, string_types):",
            "                args = list2cmdline(args)",
            "",
            "            # Process startup details",
            "            if startupinfo is None:",
            "                startupinfo = STARTUPINFO()",
            "            elif hasattr(startupinfo, 'copy'):",
            "                # bpo-34044: Copy STARTUPINFO since it is modified below,",
            "                # so the caller can reuse it multiple times.",
            "                startupinfo = startupinfo.copy()",
            "            elif hasattr(startupinfo, '_copy'):",
            "                # When the fix was backported to Python 3.7, copy() was",
            "                # made private as _copy.",
            "                startupinfo = startupinfo._copy()",
            "",
            "            use_std_handles = -1 not in (p2cread, c2pwrite, errwrite)",
            "            if use_std_handles:",
            "                startupinfo.dwFlags |= STARTF_USESTDHANDLES",
            "                startupinfo.hStdInput = p2cread",
            "                startupinfo.hStdOutput = c2pwrite",
            "                startupinfo.hStdError = errwrite",
            "",
            "            if hasattr(startupinfo, 'lpAttributeList'):",
            "                # Support for Python >= 3.7",
            "",
            "                attribute_list = startupinfo.lpAttributeList",
            "                have_handle_list = bool(attribute_list and",
            "                                        \"handle_list\" in attribute_list and",
            "                                        attribute_list[\"handle_list\"])",
            "",
            "                # If we were given an handle_list or need to create one",
            "                if have_handle_list or (use_std_handles and close_fds):",
            "                    if attribute_list is None:",
            "                        attribute_list = startupinfo.lpAttributeList = {}",
            "                    handle_list = attribute_list[\"handle_list\"] = \\",
            "                        list(attribute_list.get(\"handle_list\", []))",
            "",
            "                    if use_std_handles:",
            "                        handle_list += [int(p2cread), int(c2pwrite), int(errwrite)]",
            "",
            "                    handle_list[:] = self._filter_handle_list(handle_list)",
            "",
            "                    if handle_list:",
            "                        if not close_fds:",
            "                            import warnings",
            "                            warnings.warn(\"startupinfo.lpAttributeList['handle_list'] \"",
            "                                          \"overriding close_fds\", RuntimeWarning)",
            "",
            "                        # When using the handle_list we always request to inherit",
            "                        # handles but the only handles that will be inherited are",
            "                        # the ones in the handle_list",
            "                        close_fds = False",
            "",
            "            if shell:",
            "                startupinfo.dwFlags |= STARTF_USESHOWWINDOW",
            "                startupinfo.wShowWindow = SW_HIDE",
            "                comspec = os.environ.get(\"COMSPEC\", \"cmd.exe\")",
            "                args = '{} /c \"{}\"'.format(comspec, args)",
            "                if GetVersion() >= 0x80000000 or os.path.basename(comspec).lower() == \"command.com\":",
            "                    # Win9x, or using command.com on NT. We need to",
            "                    # use the w9xpopen intermediate program. For more",
            "                    # information, see KB Q150956",
            "                    # (http://web.archive.org/web/20011105084002/http://support.microsoft.com/support/kb/articles/Q150/9/56.asp)",
            "                    w9xpopen = self._find_w9xpopen()",
            "                    args = '\"%s\" %s' % (w9xpopen, args)",
            "                    # Not passing CREATE_NEW_CONSOLE has been known to",
            "                    # cause random failures on win9x.  Specifically a",
            "                    # dialog: \"Your program accessed mem currently in",
            "                    # use at xxx\" and a hopeful warning about the",
            "                    # stability of your system.  Cost is Ctrl+C wont",
            "                    # kill children.",
            "                    creationflags |= CREATE_NEW_CONSOLE",
            "",
            "            # PyPy 2.7 7.3.6 is now producing these errors. This",
            "            # happens automatically on Posix platforms, and is built",
            "            # in to the CreateProcess call on CPython 2 & 3. It's not",
            "            # clear why we don't pick it up for free from the",
            "            # CreateProcess call on PyPy. Currently we don't test PyPy3 on Windows,",
            "            # so we don't know for sure if it's built into CreateProcess there.",
            "            if PYPY:",
            "                def _check_nul(s, err_kind=ValueError):",
            "                    if not s:",
            "                        return",
            "                    nul = b'\\0' if isinstance(s, bytes) else '\\0'",
            "                    if nul in s:",
            "                        # PyPy 2 expects a TypeError; Python 3 raises ValueError always.",
            "                        raise err_kind(\"argument must be a string without NUL characters\")",
            "                def _check_env():",
            "                    if not env:",
            "                        return",
            "                    for k, v in env.items():",
            "                        _check_nul(k)",
            "                        _check_nul(v)",
            "                        if '=' in k:",
            "                            raise ValueError(\"'=' not allowed in environment keys\")",
            "",
            "                _check_nul(executable)",
            "                _check_nul(args)",
            "                _check_env()",
            "",
            "            # Start the process",
            "            try:",
            "                hp, ht, pid, tid = CreateProcess(executable, args,",
            "                                                 # no special security",
            "                                                 None, None,",
            "                                                 int(not close_fds),",
            "                                                 creationflags,",
            "                                                 env,",
            "                                                 cwd, # fsdecode handled earlier",
            "                                                 startupinfo)",
            "            # except IOError as e: # From 2.6 on, pywintypes.error was defined as IOError",
            "            #     # Translate pywintypes.error to WindowsError, which is",
            "            #     # a subclass of OSError.  FIXME: We should really",
            "            #     # translate errno using _sys_errlist (or similar), but",
            "            #     # how can this be done from Python?",
            "            #     raise # don't remap here",
            "            #     raise WindowsError(*e.args)",
            "            finally:",
            "                # Child is launched. Close the parent's copy of those pipe",
            "                # handles that only the child should have open.  You need",
            "                # to make sure that no handles to the write end of the",
            "                # output pipe are maintained in this process or else the",
            "                # pipe will not close when the child process exits and the",
            "                # ReadFile will hang.",
            "                def _close(x):",
            "                    if x is not None and x != -1:",
            "                        if hasattr(x, 'Close'):",
            "                            x.Close()",
            "                        else:",
            "                            _winapi.CloseHandle(x)",
            "",
            "                _close(p2cread)",
            "                _close(c2pwrite)",
            "                _close(errwrite)",
            "                if hasattr(self, '_devnull'):",
            "                    os.close(self._devnull)",
            "",
            "            # Retain the process handle, but close the thread handle",
            "            self._child_created = True",
            "            self._handle = Handle(hp) if not hasattr(hp, 'Close') else hp",
            "            self.pid = pid",
            "            _winapi.CloseHandle(ht) if not hasattr(ht, 'Close') else ht.Close()",
            "",
            "        def _internal_poll(self):",
            "            \"\"\"Check if child process has terminated.  Returns returncode",
            "            attribute.",
            "            \"\"\"",
            "            # pylint:disable=undefined-variable",
            "            if self.returncode is None:",
            "                if WaitForSingleObject(self._handle, 0) == WAIT_OBJECT_0:",
            "                    self.returncode = GetExitCodeProcess(self._handle)",
            "                    self.result.set(self.returncode)",
            "            return self.returncode",
            "",
            "        def rawlink(self, callback):",
            "            if not self.result.ready() and not self._waiting:",
            "                self._waiting = True",
            "                Greenlet.spawn(self._wait)",
            "            self.result.rawlink(linkproxy(callback, self))",
            "            # XXX unlink",
            "",
            "        def _blocking_wait(self):",
            "            # pylint:disable=undefined-variable",
            "            WaitForSingleObject(self._handle, INFINITE)",
            "            self.returncode = GetExitCodeProcess(self._handle)",
            "            return self.returncode",
            "",
            "        def _wait(self):",
            "            self.threadpool.spawn(self._blocking_wait).rawlink(self.result)",
            "",
            "        def wait(self, timeout=None, _raise_exc=True):",
            "            \"\"\"Wait for child process to terminate.  Returns returncode",
            "            attribute.\"\"\"",
            "            if self.returncode is None:",
            "                if not self._waiting:",
            "                    self._waiting = True",
            "                    self._wait()",
            "            return self._gevent_result_wait(timeout, _raise_exc)",
            "",
            "        def send_signal(self, sig):",
            "            \"\"\"Send a signal to the process",
            "            \"\"\"",
            "            if sig == signal.SIGTERM:",
            "                self.terminate()",
            "            elif sig == signal.CTRL_C_EVENT:",
            "                os.kill(self.pid, signal.CTRL_C_EVENT)",
            "            elif sig == signal.CTRL_BREAK_EVENT:",
            "                os.kill(self.pid, signal.CTRL_BREAK_EVENT)",
            "            else:",
            "                raise ValueError(\"Unsupported signal: {}\".format(sig))",
            "",
            "        def terminate(self):",
            "            \"\"\"Terminates the process",
            "            \"\"\"",
            "            # pylint:disable=undefined-variable",
            "            # Don't terminate a process that we know has already died.",
            "            if self.returncode is not None:",
            "                return",
            "            try:",
            "                TerminateProcess(self._handle, 1)",
            "            except OSError as e:",
            "                # ERROR_ACCESS_DENIED (winerror 5) is received when the",
            "                # process already died.",
            "                if e.winerror != 5:",
            "                    raise",
            "                rc = GetExitCodeProcess(self._handle)",
            "                if rc == STILL_ACTIVE:",
            "                    raise",
            "                self.returncode = rc",
            "                self.result.set(self.returncode)",
            "",
            "        kill = terminate",
            "",
            "    else:",
            "        #",
            "        # POSIX methods",
            "        #",
            "",
            "        def rawlink(self, callback):",
            "            # Not public documented, part of the link protocol",
            "            self.result.rawlink(linkproxy(callback, self))",
            "        # XXX unlink",
            "",
            "        def _get_handles(self, stdin, stdout, stderr):",
            "            \"\"\"Construct and return tuple with IO objects:",
            "            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite",
            "            \"\"\"",
            "            p2cread, p2cwrite = -1, -1",
            "            c2pread, c2pwrite = -1, -1",
            "            errread, errwrite = -1, -1",
            "",
            "            try:",
            "                DEVNULL",
            "            except NameError:",
            "                _devnull = object()",
            "            else:",
            "                _devnull = DEVNULL",
            "",
            "            if stdin is None:",
            "                pass",
            "            elif stdin == PIPE:",
            "                p2cread, p2cwrite = self.pipe_cloexec()",
            "            elif stdin == _devnull:",
            "                p2cread = self._get_devnull()",
            "            elif isinstance(stdin, int):",
            "                p2cread = stdin",
            "            else:",
            "                # Assuming file-like object",
            "                p2cread = stdin.fileno()",
            "",
            "            if stdout is None:",
            "                pass",
            "            elif stdout == PIPE:",
            "                c2pread, c2pwrite = self.pipe_cloexec()",
            "            elif stdout == _devnull:",
            "                c2pwrite = self._get_devnull()",
            "            elif isinstance(stdout, int):",
            "                c2pwrite = stdout",
            "            else:",
            "                # Assuming file-like object",
            "                c2pwrite = stdout.fileno()",
            "",
            "            if stderr is None:",
            "                pass",
            "            elif stderr == PIPE:",
            "                errread, errwrite = self.pipe_cloexec()",
            "            elif stderr == STDOUT: # pylint:disable=undefined-variable",
            "                if c2pwrite != -1:",
            "                    errwrite = c2pwrite",
            "                else: # child's stdout is not set, use parent's stdout",
            "                    errwrite = sys.__stdout__.fileno()",
            "            elif stderr == _devnull:",
            "                errwrite = self._get_devnull()",
            "            elif isinstance(stderr, int):",
            "                errwrite = stderr",
            "            else:",
            "                # Assuming file-like object",
            "                errwrite = stderr.fileno()",
            "",
            "            return (p2cread, p2cwrite,",
            "                    c2pread, c2pwrite,",
            "                    errread, errwrite)",
            "",
            "        def _set_cloexec_flag(self, fd, cloexec=True):",
            "            try:",
            "                cloexec_flag = fcntl.FD_CLOEXEC",
            "            except AttributeError:",
            "                cloexec_flag = 1",
            "",
            "            old = fcntl.fcntl(fd, fcntl.F_GETFD)",
            "            if cloexec:",
            "                fcntl.fcntl(fd, fcntl.F_SETFD, old | cloexec_flag)",
            "            else:",
            "                fcntl.fcntl(fd, fcntl.F_SETFD, old & ~cloexec_flag)",
            "",
            "        def _remove_nonblock_flag(self, fd):",
            "            flags = fcntl.fcntl(fd, fcntl.F_GETFL) & (~os.O_NONBLOCK)",
            "            fcntl.fcntl(fd, fcntl.F_SETFL, flags)",
            "",
            "        def pipe_cloexec(self):",
            "            \"\"\"Create a pipe with FDs set CLOEXEC.\"\"\"",
            "            # Pipes' FDs are set CLOEXEC by default because we don't want them",
            "            # to be inherited by other subprocesses: the CLOEXEC flag is removed",
            "            # from the child's FDs by _dup2(), between fork() and exec().",
            "            # This is not atomic: we would need the pipe2() syscall for that.",
            "            r, w = os.pipe()",
            "            self._set_cloexec_flag(r)",
            "            self._set_cloexec_flag(w)",
            "            return r, w",
            "",
            "        _POSSIBLE_FD_DIRS = (",
            "            '/proc/self/fd', # Linux",
            "            '/dev/fd', # BSD, including macOS",
            "        )",
            "",
            "        @classmethod",
            "        def _close_fds(cls, keep, errpipe_write):",
            "            # From the C code:",
            "            # errpipe_write is part of keep. It must be closed at",
            "            # exec(), but kept open in the child process until exec() is",
            "            # called.",
            "            for path in cls._POSSIBLE_FD_DIRS:",
            "                if os.path.isdir(path):",
            "                    return cls._close_fds_from_path(path, keep, errpipe_write)",
            "            return cls._close_fds_brute_force(keep, errpipe_write)",
            "",
            "        @classmethod",
            "        def _close_fds_from_path(cls, path, keep, errpipe_write):",
            "            # path names a directory whose only entries have",
            "            # names that are ascii strings of integers in base10,",
            "            # corresponding to the fds the current process has open",
            "            try:",
            "                fds = [int(fname) for fname in os.listdir(path)]",
            "            except (ValueError, OSError):",
            "                cls._close_fds_brute_force(keep, errpipe_write)",
            "            else:",
            "                for i in keep:",
            "                    if i == errpipe_write:",
            "                        continue",
            "                    _set_inheritable(i, True)",
            "",
            "                for fd in fds:",
            "                    if fd in keep or fd < 3:",
            "                        continue",
            "                    try:",
            "                        os.close(fd)",
            "                    except:",
            "                        pass",
            "",
            "        @classmethod",
            "        def _close_fds_brute_force(cls, keep, errpipe_write):",
            "            # `keep` is a set of fds, so we",
            "            # use os.closerange from 3 to min(keep)",
            "            # and then from max(keep + 1) to MAXFD and",
            "            # loop through filling in the gaps.",
            "",
            "            # Under new python versions, we need to explicitly set",
            "            # passed fds to be inheritable or they will go away on exec",
            "",
            "            # XXX: Bug: We implicitly rely on errpipe_write being the largest open",
            "            # FD so that we don't change its cloexec flag.",
            "",
            "            assert hasattr(os, 'closerange') # Added in 2.7",
            "            keep = sorted(keep)",
            "            min_keep = min(keep)",
            "            max_keep = max(keep)",
            "            os.closerange(3, min_keep)",
            "            os.closerange(max_keep + 1, MAXFD)",
            "",
            "            for i in xrange(min_keep, max_keep):",
            "                if i in keep:",
            "                    _set_inheritable(i, True)",
            "                    continue",
            "",
            "                try:",
            "                    os.close(i)",
            "                except:",
            "                    pass",
            "",
            "        def _execute_child(self, args, executable, preexec_fn, close_fds,",
            "                           pass_fds, cwd, env, universal_newlines,",
            "                           startupinfo, creationflags, shell,",
            "                           p2cread, p2cwrite,",
            "                           c2pread, c2pwrite,",
            "                           errread, errwrite,",
            "                           restore_signals,",
            "                           gid, gids, uid, umask,",
            "                           start_new_session, process_group):",
            "            \"\"\"Execute program (POSIX version)\"\"\"",
            "",
            "            if isinstance(args, (str, bytes)):",
            "                args = [args]",
            "            elif isinstance(args, PathLike):",
            "                if shell:",
            "                    raise TypeError('path-like args is not allowed when '",
            "                                    'shell is true')",
            "                args = [fsencode(args)] # os.PathLike -> [str]",
            "            else:",
            "                args = list(args)",
            "",
            "            if shell:",
            "                # On Android the default shell is at '/system/bin/sh'.",
            "                unix_shell = (",
            "                    '/system/bin/sh' if hasattr(sys, 'getandroidapilevel') else '/bin/sh'",
            "                )",
            "                args = [unix_shell, \"-c\"] + args",
            "                if executable:",
            "                    args[0] = executable",
            "",
            "            if executable is None:",
            "                executable = args[0]",
            "",
            "            self._loop.install_sigchld()",
            "",
            "            # For transferring possible exec failure from child to parent",
            "            # The first char specifies the exception type: 0 means",
            "            # OSError, 1 means some other error.",
            "            errpipe_read, errpipe_write = self.pipe_cloexec()",
            "            # errpipe_write must not be in the standard io 0, 1, or 2 fd range.",
            "            low_fds_to_close = []",
            "            while errpipe_write < 3:",
            "                low_fds_to_close.append(errpipe_write)",
            "                errpipe_write = os.dup(errpipe_write)",
            "            for low_fd in low_fds_to_close:",
            "                os.close(low_fd)",
            "            try:",
            "                try:",
            "                    gc_was_enabled = gc.isenabled()",
            "                    # Disable gc to avoid bug where gc -> file_dealloc ->",
            "                    # write to stderr -> hang.  http://bugs.python.org/issue1336",
            "                    gc.disable()",
            "                    try:",
            "                        self.pid = fork_and_watch(self._on_child, self._loop, True, fork)",
            "                    except:",
            "                        if gc_was_enabled:",
            "                            gc.enable()",
            "                        raise",
            "                    if self.pid == 0:",
            "                        # Child",
            "",
            "                        # XXX: Technically we're doing a lot of stuff here that",
            "                        # may not be safe to do before a exec(), depending on the OS.",
            "                        # CPython 3 goes to great lengths to precompute a lot",
            "                        # of this info before the fork and pass it all to C functions that",
            "                        # try hard not to call things like malloc(). (Of course,",
            "                        # CPython 2 pretty much did what we're doing.)",
            "                        try:",
            "                            # Close parent's pipe ends",
            "                            if p2cwrite != -1:",
            "                                os.close(p2cwrite)",
            "                            if c2pread != -1:",
            "                                os.close(c2pread)",
            "                            if errread != -1:",
            "                                os.close(errread)",
            "                            os.close(errpipe_read)",
            "",
            "                            # When duping fds, if there arises a situation",
            "                            # where one of the fds is either 0, 1 or 2, it",
            "                            # is possible that it is overwritten (#12607).",
            "                            if c2pwrite == 0:",
            "                                c2pwrite = os.dup(c2pwrite)",
            "                                _set_inheritable(c2pwrite, False)",
            "                            while errwrite in (0, 1):",
            "                                errwrite = os.dup(errwrite)",
            "                                _set_inheritable(errwrite, False)",
            "",
            "                            # Dup fds for child",
            "                            def _dup2(existing, desired):",
            "                                # dup2() removes the CLOEXEC flag but",
            "                                # we must do it ourselves if dup2()",
            "                                # would be a no-op (issue #10806).",
            "                                if existing == desired:",
            "                                    self._set_cloexec_flag(existing, False)",
            "                                elif existing != -1:",
            "                                    os.dup2(existing, desired)",
            "                                try:",
            "                                    self._remove_nonblock_flag(desired)",
            "                                except OSError:",
            "                                    # Ignore EBADF, it may not actually be",
            "                                    # open yet.",
            "                                    # Tested beginning in 3.7.0b3 test_subprocess.py",
            "                                    pass",
            "                            _dup2(p2cread, 0)",
            "                            _dup2(c2pwrite, 1)",
            "                            _dup2(errwrite, 2)",
            "",
            "                            # Close pipe fds.  Make sure we don't close the",
            "                            # same fd more than once, or standard fds.",
            "                            if not True:",
            "                                closed = set([None])",
            "                                for fd in (p2cread, c2pwrite, errwrite):",
            "                                    if fd not in closed and fd > 2:",
            "                                        os.close(fd)",
            "                                        closed.add(fd)",
            "",
            "                            # Python 3 (with a working set_inheritable):",
            "                            # We no longer manually close p2cread,",
            "\t                        # c2pwrite, and errwrite here as",
            "\t                        # _close_open_fds takes care when it is",
            "\t                        # not already non-inheritable.",
            "",
            "                            if cwd is not None:",
            "                                try:",
            "                                    os.chdir(cwd)",
            "                                except OSError as e:",
            "                                    e._failed_chdir = True",
            "                                    raise",
            "",
            "                            # Python 3.9",
            "                            if umask >= 0:",
            "                                os.umask(umask)",
            "                            # XXX: CPython does _Py_RestoreSignals here.",
            "                            # Then setsid() based on ???",
            "                            if gids:",
            "                                os.setgroups(gids)",
            "                            if gid:",
            "                                os.setregid(gid, gid)",
            "                            if uid:",
            "                                os.setreuid(uid, uid)",
            "                            if process_group is not None:",
            "                                os.setpgid(0, process_group)",
            "                            if preexec_fn:",
            "                                preexec_fn()",
            "",
            "                            # Close all other fds, if asked for. This must be done",
            "                            # after preexec_fn runs.",
            "                            if close_fds:",
            "                                fds_to_keep = set(pass_fds)",
            "                                fds_to_keep.add(errpipe_write)",
            "                                self._close_fds(fds_to_keep, errpipe_write)",
            "",
            "                            if restore_signals:",
            "                                # restore the documented signals back to sig_dfl;",
            "                                # not all will be defined on every platform",
            "                                for sig in 'SIGPIPE', 'SIGXFZ', 'SIGXFSZ':",
            "                                    sig = getattr(signal, sig, None)",
            "                                    if sig is not None:",
            "                                        signal.signal(sig, signal.SIG_DFL)",
            "",
            "                            if start_new_session:",
            "                                os.setsid()",
            "",
            "                            if env is None:",
            "                                os.execvp(executable, args)",
            "                            else:",
            "                                # Python 3.6 started testing for",
            "                                # bytes values in the env; it also",
            "                                # started encoding strs using",
            "                                # fsencode and using a lower-level",
            "                                # API that takes a list of keys",
            "                                # and values. We don't have access",
            "                                # to that API, so we go the reverse direction.",
            "                                env = {os.fsdecode(k) if isinstance(k, bytes) else k:",
            "                                       os.fsdecode(v) if isinstance(v, bytes) else v",
            "                                       for k, v in env.items()}",
            "                                os.execvpe(executable, args, env)",
            "",
            "                        except:",
            "                            exc_type, exc_value, tb = sys.exc_info()",
            "                            # Save the traceback and attach it to the exception object",
            "                            exc_lines = traceback.format_exception(exc_type,",
            "                                                                   exc_value,",
            "                                                                   tb)",
            "                            exc_value.child_traceback = ''.join(exc_lines)",
            "                            os.write(errpipe_write, pickle.dumps(exc_value))",
            "",
            "                        finally:",
            "                            # Make sure that the process exits no matter what.",
            "                            # The return code does not matter much as it won't be",
            "                            # reported to the application",
            "                            os._exit(1)",
            "",
            "                    # Parent",
            "                    self._child_created = True",
            "                    if gc_was_enabled:",
            "                        gc.enable()",
            "                finally:",
            "                    # be sure the FD is closed no matter what",
            "                    os.close(errpipe_write)",
            "",
            "                # self._devnull is not always defined.",
            "                devnull_fd = getattr(self, '_devnull', None)",
            "                if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:",
            "                    os.close(p2cread)",
            "                if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:",
            "                    os.close(c2pwrite)",
            "                if errwrite != -1 and errread != -1 and errwrite != devnull_fd:",
            "                    os.close(errwrite)",
            "                if devnull_fd is not None:",
            "                    os.close(devnull_fd)",
            "                # Prevent a double close of these fds from __init__ on error.",
            "                self._closed_child_pipe_fds = True",
            "",
            "                # Wait for exec to fail or succeed; possibly raising exception",
            "                errpipe_read = FileObject(errpipe_read, 'rb')",
            "                data = errpipe_read.read()",
            "            finally:",
            "                try:",
            "                    if hasattr(errpipe_read, 'close'):",
            "                        errpipe_read.close()",
            "                    else:",
            "                        os.close(errpipe_read)",
            "                except OSError:",
            "                    # Especially on PyPy, we sometimes see the above",
            "                    # `os.close(errpipe_read)` raise an OSError.",
            "                    # It's not entirely clear why, but it happens in",
            "                    # InterprocessSignalTests.test_main sometimes, which must mean",
            "                    # we have some sort of race condition.",
            "                    pass",
            "                finally:",
            "                    errpipe_read = -1",
            "",
            "            if data != b\"\":",
            "                self.wait()",
            "                child_exception = pickle.loads(data)",
            "                for fd in (p2cwrite, c2pread, errread):",
            "                    if fd is not None and fd != -1:",
            "                        os.close(fd)",
            "                if isinstance(child_exception, OSError):",
            "                    child_exception.filename = executable",
            "                    if hasattr(child_exception, '_failed_chdir'):",
            "                        child_exception.filename = cwd",
            "                raise child_exception",
            "",
            "        def _handle_exitstatus(self, sts, _WIFSIGNALED=os.WIFSIGNALED,",
            "                               _WTERMSIG=os.WTERMSIG, _WIFEXITED=os.WIFEXITED,",
            "                               _WEXITSTATUS=os.WEXITSTATUS, _WIFSTOPPED=os.WIFSTOPPED,",
            "                               _WSTOPSIG=os.WSTOPSIG):",
            "            # This method is called (indirectly) by __del__, so it cannot",
            "            # refer to anything outside of its local scope.",
            "            # (gevent: We don't have a __del__, that's in the CPython implementation.)",
            "            if _WIFSIGNALED(sts):",
            "                self.returncode = -_WTERMSIG(sts)",
            "            elif _WIFEXITED(sts):",
            "                self.returncode = _WEXITSTATUS(sts)",
            "            elif _WIFSTOPPED(sts):",
            "                self.returncode = -_WSTOPSIG(sts)",
            "            else:",
            "                # Should never happen",
            "                raise RuntimeError(\"Unknown child exit status!\")",
            "",
            "        def _internal_poll(self):",
            "            \"\"\"Check if child process has terminated.  Returns returncode",
            "            attribute.",
            "            \"\"\"",
            "            if self.returncode is None:",
            "                if get_hub() is not getcurrent():",
            "                    sig_pending = getattr(self._loop, 'sig_pending', True)",
            "                    if sig_pending:",
            "                        sleep(0.00001)",
            "            return self.returncode",
            "",
            "        def wait(self, timeout=None, _raise_exc=True):",
            "            \"\"\"",
            "            Wait for child process to terminate.  Returns :attr:`returncode`",
            "            attribute.",
            "",
            "            :keyword timeout: The floating point number of seconds to",
            "                wait. Under Python 2, this is a gevent extension, and",
            "                we simply return if it expires. Under Python 3, if",
            "                this time elapses without finishing the process,",
            "                :exc:`TimeoutExpired` is raised.",
            "            \"\"\"",
            "            return self._gevent_result_wait(timeout, _raise_exc)",
            "",
            "        def send_signal(self, sig):",
            "            \"\"\"Send a signal to the process",
            "            \"\"\"",
            "            # Skip signalling a process that we know has already died.",
            "            if self.returncode is None:",
            "                os.kill(self.pid, sig)",
            "",
            "        def terminate(self):",
            "            \"\"\"Terminate the process with SIGTERM",
            "            \"\"\"",
            "            self.send_signal(signal.SIGTERM)",
            "",
            "        def kill(self):",
            "            \"\"\"Kill the process with SIGKILL",
            "            \"\"\"",
            "            self.send_signal(signal.SIGKILL)",
            "",
            "",
            "def _with_stdout_stderr(exc, stderr):",
            "    # Prior to Python 3.5, most exceptions didn't have stdout",
            "    # and stderr attributes and can't take the stderr attribute in their",
            "    # constructor",
            "    exc.stdout = exc.output",
            "    exc.stderr = stderr",
            "    return exc",
            "",
            "class CompletedProcess(object):",
            "    \"\"\"",
            "    A process that has finished running.",
            "",
            "    This is returned by run().",
            "",
            "    Attributes:",
            "      - args: The list or str args passed to run().",
            "      - returncode: The exit code of the process, negative for signals.",
            "      - stdout: The standard output (None if not captured).",
            "      - stderr: The standard error (None if not captured).",
            "",
            "    .. versionadded:: 1.2a1",
            "       This first appeared in Python 3.5 and is available to all",
            "       Python versions in gevent.",
            "    \"\"\"",
            "    if GenericAlias is not None:",
            "        # Sigh, 3.9 spreading typing stuff all over everything",
            "        __class_getitem__ = classmethod(GenericAlias)",
            "",
            "    def __init__(self, args, returncode, stdout=None, stderr=None):",
            "        self.args = args",
            "        self.returncode = returncode",
            "        self.stdout = stdout",
            "        self.stderr = stderr",
            "",
            "    def __repr__(self):",
            "        args = ['args={!r}'.format(self.args),",
            "                'returncode={!r}'.format(self.returncode)]",
            "        if self.stdout is not None:",
            "            args.append('stdout={!r}'.format(self.stdout))",
            "        if self.stderr is not None:",
            "            args.append('stderr={!r}'.format(self.stderr))",
            "        return \"{}({})\".format(type(self).__name__, ', '.join(args))",
            "",
            "    def check_returncode(self):",
            "        \"\"\"Raise CalledProcessError if the exit code is non-zero.\"\"\"",
            "        if self.returncode:",
            "            # pylint:disable=undefined-variable",
            "            raise _with_stdout_stderr(CalledProcessError(self.returncode, self.args, self.stdout), self.stderr)",
            "",
            "",
            "def run(*popenargs, **kwargs):",
            "    \"\"\"",
            "    run(args, *, stdin=None, input=None, stdout=None, stderr=None, shell=False, timeout=None, check=False) -> CompletedProcess",
            "",
            "    Run command with arguments and return a CompletedProcess instance.",
            "",
            "    The returned instance will have attributes args, returncode, stdout and",
            "    stderr. By default, stdout and stderr are not captured, and those attributes",
            "    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.",
            "    If check is True and the exit code was non-zero, it raises a",
            "    CalledProcessError. The CalledProcessError object will have the return code",
            "    in the returncode attribute, and output & stderr attributes if those streams",
            "    were captured.",
            "",
            "    If timeout is given, and the process takes too long, a TimeoutExpired",
            "    exception will be raised.",
            "",
            "    There is an optional argument \"input\", allowing you to",
            "    pass a string to the subprocess's stdin.  If you use this argument",
            "    you may not also use the Popen constructor's \"stdin\" argument, as",
            "    it will be used internally.",
            "    The other arguments are the same as for the Popen constructor.",
            "    If universal_newlines=True is passed, the \"input\" argument must be a",
            "    string and stdout/stderr in the returned object will be strings rather than",
            "    bytes.",
            "",
            "    .. versionadded:: 1.2a1",
            "       This function first appeared in Python 3.5. It is available on all Python",
            "       versions gevent supports.",
            "",
            "    .. versionchanged:: 1.3a2",
            "       Add the ``capture_output`` argument from Python 3.7. It automatically sets",
            "       ``stdout`` and ``stderr`` to ``PIPE``. It is an error to pass either",
            "       of those arguments along with ``capture_output``.",
            "    \"\"\"",
            "    input = kwargs.pop('input', None)",
            "    timeout = kwargs.pop('timeout', None)",
            "    check = kwargs.pop('check', False)",
            "    capture_output = kwargs.pop('capture_output', False)",
            "",
            "    if input is not None:",
            "        if 'stdin' in kwargs:",
            "            raise ValueError('stdin and input arguments may not both be used.')",
            "        kwargs['stdin'] = PIPE",
            "",
            "    if capture_output:",
            "        if ('stdout' in kwargs) or ('stderr' in kwargs):",
            "            raise ValueError('stdout and stderr arguments may not be used '",
            "                             'with capture_output.')",
            "        kwargs['stdout'] = PIPE",
            "        kwargs['stderr'] = PIPE",
            "",
            "    with Popen(*popenargs, **kwargs) as process:",
            "        try:",
            "            stdout, stderr = process.communicate(input, timeout=timeout)",
            "        except TimeoutExpired:",
            "            process.kill()",
            "            stdout, stderr = process.communicate()",
            "            raise _with_stdout_stderr(TimeoutExpired(process.args, timeout, output=stdout), stderr)",
            "        except:",
            "            process.kill()",
            "            process.wait()",
            "            raise",
            "        retcode = process.poll()",
            "        if check and retcode:",
            "            # pylint:disable=undefined-variable",
            "            raise _with_stdout_stderr(CalledProcessError(retcode, process.args, stdout), stderr)",
            "",
            "    return CompletedProcess(process.args, retcode, stdout, stderr)",
            "",
            "def _gevent_did_monkey_patch(target_module, *_args, **_kwargs):",
            "    # Beginning on 3.8 on Mac, the 'spawn' method became the default",
            "    # start method. That doesn't fire fork watchers and we can't",
            "    # easily patch to make it do so: multiprocessing uses the private",
            "    # c accelerated _subprocess module to implement this. Instead we revert",
            "    # back to using fork.",
            "    from gevent._compat import MAC",
            "",
            "    if MAC:",
            "        import multiprocessing",
            "        if hasattr(multiprocessing, 'set_start_method'):",
            "            multiprocessing.set_start_method('fork', force=True)"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Cooperative ``subprocess`` module.",
            "",
            ".. caution:: On POSIX platforms, this module is not usable from native",
            "   threads other than the main thread; attempting to do so will raise",
            "   a :exc:`TypeError`. This module depends on libev's fork watchers.",
            "   On POSIX systems, fork watchers are implemented using signals, and",
            "   the thread to which process-directed signals are delivered `is not",
            "   defined`_. Because each native thread has its own gevent/libev",
            "   loop, this means that a fork watcher registered with one loop",
            "   (thread) may never see the signal about a child it spawned if the",
            "   signal is sent to a different thread.",
            "",
            ".. note:: The interface of this module is intended to match that of",
            "   the standard library :mod:`subprocess` module (with many backwards",
            "   compatible extensions from Python 3 backported to Python 2). There",
            "   are some small differences between the Python 2 and Python 3",
            "   versions of that module (the Python 2 ``TimeoutExpired`` exception,",
            "   notably, extends ``Timeout`` and there is no ``SubprocessError``) and between the",
            "   POSIX and Windows versions. The HTML documentation here can only",
            "   describe one version; for definitive documentation, see the",
            "   standard library or the source code.",
            "",
            ".. _is not defined: http://www.linuxprogrammingblog.com/all-about-linux-signals?page=11",
            "\"\"\"",
            "from __future__ import absolute_import, print_function",
            "# Can we split this up to make it cleaner? See https://github.com/gevent/gevent/issues/748",
            "# pylint: disable=too-many-lines",
            "# Most of this we inherit from the standard lib",
            "# pylint: disable=bare-except,too-many-locals,too-many-statements,attribute-defined-outside-init",
            "# pylint: disable=too-many-branches,too-many-instance-attributes",
            "# Most of this is cross-platform",
            "# pylint: disable=no-member,expression-not-assigned,unused-argument,unused-variable",
            "import errno",
            "import gc",
            "import os",
            "import signal",
            "import sys",
            "import traceback",
            "# Python 3.9",
            "try:",
            "    from types import GenericAlias",
            "except ImportError:",
            "    GenericAlias = None",
            "",
            "try:",
            "    import grp",
            "except ImportError:",
            "    grp = None",
            "",
            "try:",
            "    import pwd",
            "except ImportError:",
            "    pwd = None",
            "",
            "from gevent.event import AsyncResult",
            "from gevent.hub import _get_hub_noargs as get_hub",
            "from gevent.hub import linkproxy",
            "from gevent.hub import sleep",
            "from gevent.hub import getcurrent",
            "from gevent._compat import integer_types, string_types, xrange",
            "",
            "from gevent._compat import PY311",
            "from gevent._compat import PYPY",
            "",
            "from gevent._compat import fsdecode",
            "from gevent._compat import fsencode",
            "from gevent._compat import PathLike",
            "from gevent._util import _NONE",
            "from gevent._util import copy_globals",
            "",
            "from gevent.greenlet import Greenlet, joinall",
            "spawn = Greenlet.spawn",
            "import subprocess as __subprocess__",
            "",
            "",
            "# Standard functions and classes that this module re-implements in a gevent-aware way.",
            "__implements__ = [",
            "    'Popen',",
            "    'call',",
            "    'check_call',",
            "    'check_output',",
            "]",
            "if not sys.platform.startswith('win32'):",
            "    __implements__.append(\"_posixsubprocess\")",
            "    _posixsubprocess = None",
            "",
            "",
            "# Some symbols we define that we expect to export;",
            "# useful for static analysis",
            "PIPE = \"PIPE should be imported\"",
            "",
            "# Standard functions and classes that this module re-imports.",
            "__imports__ = [",
            "    'PIPE',",
            "    'STDOUT',",
            "    'CalledProcessError',",
            "    # Windows:",
            "    'CREATE_NEW_CONSOLE',",
            "    'CREATE_NEW_PROCESS_GROUP',",
            "    'STD_INPUT_HANDLE',",
            "    'STD_OUTPUT_HANDLE',",
            "    'STD_ERROR_HANDLE',",
            "    'SW_HIDE',",
            "    'STARTF_USESTDHANDLES',",
            "    'STARTF_USESHOWWINDOW',",
            "]",
            "",
            "",
            "__extra__ = [",
            "    'MAXFD',",
            "    '_eintr_retry_call',",
            "    'STARTUPINFO',",
            "    'pywintypes',",
            "    'list2cmdline',",
            "    '_subprocess',",
            "    '_winapi',",
            "    # Python 2.5 does not have _subprocess, so we don't use it",
            "    # XXX We don't run on Py 2.5 anymore; can/could/should we use _subprocess?",
            "    # It's only used on mswindows",
            "    'WAIT_OBJECT_0',",
            "    'WaitForSingleObject',",
            "    'GetExitCodeProcess',",
            "    'GetStdHandle',",
            "    'CreatePipe',",
            "    'DuplicateHandle',",
            "    'GetCurrentProcess',",
            "    'DUPLICATE_SAME_ACCESS',",
            "    'GetModuleFileName',",
            "    'GetVersion',",
            "    'CreateProcess',",
            "    'INFINITE',",
            "    'TerminateProcess',",
            "    'STILL_ACTIVE',",
            "",
            "    # These were added for 3.5, but we make them available everywhere.",
            "    'run',",
            "    'CompletedProcess',",
            "]",
            "",
            "__imports__ += [",
            "    'DEVNULL',",
            "    'getstatusoutput',",
            "    'getoutput',",
            "    'SubprocessError',",
            "    'TimeoutExpired',",
            "]",
            "",
            "# Became standard in 3.5",
            "__extra__.remove('run')",
            "__extra__.remove('CompletedProcess')",
            "__implements__.append('run')",
            "__implements__.append('CompletedProcess')",
            "",
            "# Removed in Python 3.5; this is the exact code that was removed:",
            "# https://hg.python.org/cpython/rev/f98b0a5e5ef5",
            "__extra__.remove('MAXFD')",
            "try:",
            "    MAXFD = os.sysconf(\"SC_OPEN_MAX\")",
            "except:",
            "    MAXFD = 256",
            "",
            "",
            "# This was added to __all__ for windows in 3.6",
            "__extra__.remove('STARTUPINFO')",
            "__imports__.append('STARTUPINFO')",
            "",
            "__imports__.extend([",
            "    'ABOVE_NORMAL_PRIORITY_CLASS', 'BELOW_NORMAL_PRIORITY_CLASS',",
            "    'HIGH_PRIORITY_CLASS', 'IDLE_PRIORITY_CLASS',",
            "    'NORMAL_PRIORITY_CLASS',",
            "    'REALTIME_PRIORITY_CLASS',",
            "    'CREATE_NO_WINDOW', 'DETACHED_PROCESS',",
            "    'CREATE_DEFAULT_ERROR_MODE',",
            "    'CREATE_BREAKAWAY_FROM_JOB'",
            "])",
            "",
            "",
            "# Using os.posix_spawn() to start subprocesses",
            "# bypasses our child watchers on certain operating systems,",
            "# and with certain library versions. Possibly the right",
            "# fix is to monkey-patch os.posix_spawn like we do os.fork?",
            "# These have no effect, they're just here to match the stdlib.",
            "# TODO: When available, given a monkey patch on them, I think",
            "# we ought to be able to use them if the stdlib has identified them",
            "# as suitable.",
            "__implements__.extend([",
            "    '_use_posix_spawn',",
            "])",
            "",
            "def _use_posix_spawn():",
            "    return False",
            "",
            "_USE_POSIX_SPAWN = False",
            "",
            "if __subprocess__._USE_POSIX_SPAWN:",
            "    __implements__.extend([",
            "        '_USE_POSIX_SPAWN',",
            "    ])",
            "else:",
            "    __imports__.extend([",
            "        '_USE_POSIX_SPAWN',",
            "    ])",
            "",
            "if PY311:",
            "    # Python 3.11 added some module-level attributes to control the",
            "    # use of vfork. The docs specifically say that you should not try to read",
            "    # them, only set them, so we don't provide them.",
            "    #",
            "    # Python 3.11 also added a test,  test_surrogates_error_message, that behaves",
            "    # differently based on whether or not the pure python implementation of forking",
            "    # is in use, or the one written in C from _posixsubprocess. Obviously we don't call",
            "    # that, so we need to make us look like a pure python version; it checks that this attribute",
            "    # is none for that.",
            "    _fork_exec = None",
            "    __implements__.extend([",
            "        '_fork_exec',",
            "    ] if sys.platform != 'win32' else [",
            "    ])",
            "",
            "actually_imported = copy_globals(__subprocess__, globals(),",
            "                                 only_names=__imports__,",
            "                                 ignore_missing_names=True)",
            "# anything we couldn't import from here we may need to find",
            "# elsewhere",
            "__extra__.extend(set(__imports__).difference(set(actually_imported)))",
            "__imports__ = actually_imported",
            "del actually_imported",
            "",
            "",
            "# In Python 3 on Windows, a lot of the functions previously",
            "# in _subprocess moved to _winapi",
            "_subprocess = getattr(__subprocess__, '_subprocess', _NONE)",
            "_winapi = getattr(__subprocess__, '_winapi', _NONE)",
            "",
            "_attr_resolution_order = [__subprocess__, _subprocess, _winapi]",
            "",
            "for name in list(__extra__):",
            "    if name in globals():",
            "        continue",
            "    value = _NONE",
            "    for place in _attr_resolution_order:",
            "        value = getattr(place, name, _NONE)",
            "        if value is not _NONE:",
            "            break",
            "",
            "    if value is _NONE:",
            "        __extra__.remove(name)",
            "    else:",
            "        globals()[name] = value",
            "",
            "del _attr_resolution_order",
            "__all__ = __implements__ + __imports__",
            "# Some other things we want to document",
            "for _x in ('run', 'CompletedProcess', 'TimeoutExpired'):",
            "    if _x not in __all__:",
            "        __all__.append(_x)",
            "",
            "",
            "",
            "mswindows = sys.platform == 'win32'",
            "if mswindows:",
            "    import msvcrt # pylint: disable=import-error",
            "    class Handle(int):",
            "        closed = False",
            "",
            "        def Close(self):",
            "            if not self.closed:",
            "                self.closed = True",
            "                _winapi.CloseHandle(self)",
            "",
            "        def Detach(self):",
            "            if not self.closed:",
            "                self.closed = True",
            "                return int(self)",
            "            raise ValueError(\"already closed\")",
            "",
            "        def __repr__(self):",
            "            return \"Handle(%d)\" % int(self)",
            "",
            "        __del__ = Close",
            "        __str__ = __repr__",
            "else:",
            "    import fcntl",
            "    import pickle",
            "    from gevent import monkey",
            "    fork = monkey.get_original('os', 'fork')",
            "    from gevent.os import fork_and_watch",
            "",
            "try:",
            "    BrokenPipeError # pylint:disable=used-before-assignment",
            "except NameError: # Python 2",
            "    class BrokenPipeError(Exception):",
            "        \"Never raised, never caught.\"",
            "",
            "",
            "def call(*popenargs, **kwargs):",
            "    \"\"\"",
            "    call(args, *, stdin=None, stdout=None, stderr=None, shell=False, timeout=None) -> returncode",
            "",
            "    Run command with arguments. Wait for command to complete or",
            "    timeout, then return the returncode attribute.",
            "",
            "    The arguments are the same as for the Popen constructor.  Example::",
            "",
            "        retcode = call([\"ls\", \"-l\"])",
            "",
            "    .. versionchanged:: 1.2a1",
            "       The ``timeout`` keyword argument is now accepted on all supported",
            "       versions of Python (not just Python 3) and if it expires will raise a",
            "       :exc:`TimeoutExpired` exception (under Python 2 this is a subclass of :exc:`~.Timeout`).",
            "    \"\"\"",
            "    timeout = kwargs.pop('timeout', None)",
            "    with Popen(*popenargs, **kwargs) as p:",
            "        try:",
            "            return p.wait(timeout=timeout, _raise_exc=True)",
            "        except:",
            "            p.kill()",
            "            p.wait()",
            "            raise",
            "",
            "def check_call(*popenargs, **kwargs):",
            "    \"\"\"",
            "    check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False, timeout=None) -> 0",
            "",
            "    Run command with arguments.  Wait for command to complete.  If",
            "    the exit code was zero then return, otherwise raise",
            "    :exc:`CalledProcessError`.  The ``CalledProcessError`` object will have the",
            "    return code in the returncode attribute.",
            "",
            "    The arguments are the same as for the Popen constructor.  Example::",
            "",
            "        retcode = check_call([\"ls\", \"-l\"])",
            "    \"\"\"",
            "    retcode = call(*popenargs, **kwargs)",
            "    if retcode:",
            "        cmd = kwargs.get(\"args\")",
            "        if cmd is None:",
            "            cmd = popenargs[0]",
            "        raise CalledProcessError(retcode, cmd) # pylint:disable=undefined-variable",
            "    return 0",
            "",
            "def check_output(*popenargs, **kwargs):",
            "    r\"\"\"",
            "    check_output(args, *, input=None, stdin=None, stderr=None, shell=False, universal_newlines=False, timeout=None) -> output",
            "",
            "    Run command with arguments and return its output.",
            "",
            "    If the exit code was non-zero it raises a :exc:`CalledProcessError`.  The",
            "    ``CalledProcessError`` object will have the return code in the returncode",
            "    attribute and output in the output attribute.",
            "",
            "",
            "    The arguments are the same as for the Popen constructor.  Example::",
            "",
            "        >>> check_output([\"ls\", \"-1\", \"/dev/null\"])",
            "        '/dev/null\\n'",
            "",
            "    The ``stdout`` argument is not allowed as it is used internally.",
            "",
            "    To capture standard error in the result, use ``stderr=STDOUT``::",
            "",
            "        >>> output = check_output([\"/bin/sh\", \"-c\",",
            "        ...               \"ls -l non_existent_file ; exit 0\"],",
            "        ...              stderr=STDOUT).decode('ascii').strip()",
            "        >>> print(output.rsplit(':', 1)[1].strip())",
            "        No such file or directory",
            "",
            "    There is an additional optional argument, \"input\", allowing you to",
            "    pass a string to the subprocess's stdin.  If you use this argument",
            "    you may not also use the Popen constructor's \"stdin\" argument, as",
            "    it too will be used internally.  Example::",
            "",
            "        >>> check_output([\"sed\", \"-e\", \"s/foo/bar/\"],",
            "        ...              input=b\"when in the course of fooman events\\n\")",
            "        'when in the course of barman events\\n'",
            "",
            "    If ``universal_newlines=True`` is passed, the return value will be a",
            "    string rather than bytes.",
            "",
            "    .. versionchanged:: 1.2a1",
            "       The ``timeout`` keyword argument is now accepted on all supported",
            "       versions of Python (not just Python 3) and if it expires will raise a",
            "       :exc:`TimeoutExpired` exception (under Python 2 this is a subclass of :exc:`~.Timeout`).",
            "    .. versionchanged:: 1.2a1",
            "       The ``input`` keyword argument is now accepted on all supported",
            "       versions of Python, not just Python 3",
            "    .. versionchanged:: 22.08.0",
            "       Passing the ``check`` keyword argument is forbidden, just as in Python 3.11.",
            "    \"\"\"",
            "    timeout = kwargs.pop('timeout', None)",
            "    if 'stdout' in kwargs:",
            "        raise ValueError('stdout argument not allowed, it will be overridden.')",
            "    if 'check' in kwargs:",
            "        raise ValueError('check argument not allowed, it will be overridden.')",
            "    if 'input' in kwargs:",
            "        if 'stdin' in kwargs:",
            "            raise ValueError('stdin and input arguments may not both be used.')",
            "        inputdata = kwargs['input']",
            "        del kwargs['input']",
            "        kwargs['stdin'] = PIPE",
            "    else:",
            "        inputdata = None",
            "    with Popen(*popenargs, stdout=PIPE, **kwargs) as process:",
            "        try:",
            "            output, unused_err = process.communicate(inputdata, timeout=timeout)",
            "        except TimeoutExpired:",
            "            process.kill()",
            "            output, unused_err = process.communicate()",
            "            raise TimeoutExpired(process.args, timeout, output=output)",
            "        except:",
            "            process.kill()",
            "            process.wait()",
            "            raise",
            "        retcode = process.poll()",
            "        if retcode:",
            "            # pylint:disable=undefined-variable",
            "            raise CalledProcessError(retcode, process.args, output=output)",
            "    return output",
            "",
            "_PLATFORM_DEFAULT_CLOSE_FDS = object()",
            "",
            "if 'TimeoutExpired' not in globals():",
            "    # Python 2",
            "",
            "    # Make TimeoutExpired inherit from _Timeout so it can be caught",
            "    # the way we used to throw things (except Timeout), but make sure it doesn't",
            "    # init a timer. Note that we can't have a fake 'SubprocessError' that inherits",
            "    # from exception, because we need TimeoutExpired to just be a BaseException for",
            "    # bwc.",
            "    from gevent.timeout import Timeout as _Timeout",
            "",
            "    class TimeoutExpired(_Timeout):",
            "        \"\"\"",
            "        This exception is raised when the timeout expires while waiting for",
            "        a child process in `communicate`.",
            "",
            "        Under Python 2, this is a gevent extension with the same name as the",
            "        Python 3 class for source-code forward compatibility. However, it extends",
            "        :class:`gevent.timeout.Timeout` for backwards compatibility (because",
            "        we used to just raise a plain ``Timeout``); note that ``Timeout`` is a",
            "        ``BaseException``, *not* an ``Exception``.",
            "",
            "        .. versionadded:: 1.2a1",
            "        \"\"\"",
            "",
            "        def __init__(self, cmd, timeout, output=None):",
            "            _Timeout.__init__(self, None)",
            "            self.cmd = cmd",
            "            self.seconds = timeout",
            "            self.output = output",
            "",
            "        @property",
            "        def timeout(self):",
            "            return self.seconds",
            "",
            "        def __str__(self):",
            "            return (\"Command '%s' timed out after %s seconds\" %",
            "                    (self.cmd, self.timeout))",
            "",
            "",
            "if hasattr(os, 'set_inheritable'):",
            "    _set_inheritable = os.set_inheritable",
            "else:",
            "    _set_inheritable = lambda i, v: True",
            "",
            "",
            "def FileObject(*args, **kwargs):",
            "    # Defer importing FileObject until we need it",
            "    # to allow it to be configured more easily.",
            "    from gevent.fileobject import FileObject as _FileObject",
            "    globals()['FileObject'] = _FileObject",
            "    return _FileObject(*args)",
            "",
            "",
            "class _CommunicatingGreenlets(object):",
            "    # At most, exactly one of these objects may be created",
            "    # for a given Popen object. This ensures that only one background",
            "    # greenlet at a time will be reading from the file object. This matters because",
            "    # if a timeout exception is raised, the user may call back into communicate() to",
            "    # get the output (usually after killing the process; see run()). We must not",
            "    # lose output in that case (Python 3 specifically documents that raising a timeout",
            "    # doesn't lose output). Also, attempting to read from a pipe while it's already",
            "    # being read from results in `RuntimeError: reentrant call in io.BufferedReader`;",
            "    # the same thing happens if you attempt to close() it while that's in progress.",
            "    __slots__ = (",
            "        'stdin',",
            "        'stdout',",
            "        'stderr',",
            "        '_all_greenlets',",
            "    )",
            "",
            "    def __init__(self, popen, input_data):",
            "        self.stdin = self.stdout = self.stderr = None",
            "        if popen.stdin: # Even if no data, we need to close",
            "            self.stdin = spawn(self._write_and_close, popen.stdin, input_data)",
            "",
            "        # If the timeout parameter is used, and the caller calls back after",
            "        # getting a TimeoutExpired exception, we can wind up with multiple",
            "        # greenlets trying to run and read from and close stdout/stderr.",
            "        # That's bad because it can lead to 'RuntimeError: reentrant call in io.BufferedReader'.",
            "        # We can't just kill the previous greenlets when a timeout happens,",
            "        # though, because we risk losing the output collected by that greenlet",
            "        # (and Python 3, where timeout is an official parameter, explicitly says",
            "        # that no output should be lost in the event of a timeout.) Instead, we're",
            "        # watching for the exception and ignoring it. It's not elegant,",
            "        # but it works",
            "        if popen.stdout:",
            "            self.stdout = spawn(self._read_and_close, popen.stdout)",
            "",
            "        if popen.stderr:",
            "            self.stderr = spawn(self._read_and_close, popen.stderr)",
            "",
            "        all_greenlets = []",
            "        for g in self.stdin, self.stdout, self.stderr:",
            "            if g is not None:",
            "                all_greenlets.append(g)",
            "        self._all_greenlets = tuple(all_greenlets)",
            "",
            "    def __iter__(self):",
            "        return iter(self._all_greenlets)",
            "",
            "    def __bool__(self):",
            "        return bool(self._all_greenlets)",
            "",
            "    __nonzero__ = __bool__",
            "",
            "    def __len__(self):",
            "        return len(self._all_greenlets)",
            "",
            "    @staticmethod",
            "    def _write_and_close(fobj, data):",
            "        try:",
            "            if data:",
            "                fobj.write(data)",
            "                if hasattr(fobj, 'flush'):",
            "                    # 3.6 started expecting flush to be called.",
            "                    fobj.flush()",
            "        except (OSError, BrokenPipeError) as ex:",
            "            # Test cases from the stdlib can raise BrokenPipeError",
            "            # without setting an errno value. This matters because",
            "            # Python 2 doesn't have a BrokenPipeError.",
            "            if isinstance(ex, BrokenPipeError) and ex.errno is None:",
            "                ex.errno = errno.EPIPE",
            "            if ex.errno not in (errno.EPIPE, errno.EINVAL):",
            "                raise",
            "        finally:",
            "            try:",
            "                fobj.close()",
            "            except EnvironmentError:",
            "                pass",
            "",
            "    @staticmethod",
            "    def _read_and_close(fobj):",
            "        try:",
            "            return fobj.read()",
            "        finally:",
            "            try:",
            "                fobj.close()",
            "            except EnvironmentError:",
            "                pass",
            "",
            "",
            "class Popen(object):",
            "    \"\"\"",
            "    The underlying process creation and management in this module is",
            "    handled by the Popen class. It offers a lot of flexibility so that",
            "    developers are able to handle the less common cases not covered by",
            "    the convenience functions.",
            "",
            "    .. seealso:: :class:`subprocess.Popen`",
            "       This class should have the same interface as the standard library class.",
            "",
            "    .. caution::",
            "",
            "       The default values of some arguments, notably ``buffering``, differ",
            "       between Python 2 and Python 3. For the most consistent behaviour across",
            "       versions, it's best to explicitly pass the desired values.",
            "",
            "    .. caution::",
            "",
            "       On Python 2, the ``read`` method of the ``stdout`` and ``stderr`` attributes",
            "       will not be buffered unless buffering is explicitly requested (e.g., `bufsize=-1`).",
            "       This is different than the ``read`` method of the standard library attributes,",
            "       which will buffer internally even if no buffering has been requested. This",
            "       matches the Python 3 behaviour. For portability, please explicitly request",
            "       buffering if you want ``read(n)`` to return all ``n`` bytes, making more than",
            "       one system call if needed. See `issue 1701 <https://github.com/gevent/gevent/issues/1701>`_",
            "       for more context.",
            "",
            "    .. versionchanged:: 1.2a1",
            "       Instances can now be used as context managers under Python 2.7. Previously",
            "       this was restricted to Python 3.",
            "",
            "    .. versionchanged:: 1.2a1",
            "       Instances now save the ``args`` attribute under Python 2.7. Previously this was",
            "       restricted to Python 3.",
            "",
            "    .. versionchanged:: 1.2b1",
            "        Add the ``encoding`` and ``errors`` parameters for Python 3.",
            "",
            "    .. versionchanged:: 1.3a1",
            "       Accept \"path-like\" objects for the *cwd* parameter on all platforms.",
            "       This was added to Python 3.6. Previously with gevent, it only worked",
            "       on POSIX platforms on 3.6.",
            "",
            "    .. versionchanged:: 1.3a1",
            "       Add the ``text`` argument as a synonym for ``universal_newlines``,",
            "       as added on Python 3.7.",
            "",
            "    .. versionchanged:: 1.3a2",
            "       Allow the same keyword arguments under Python 2 as Python 3:",
            "       ``pass_fds``, ``start_new_session``, ``restore_signals``, ``encoding``",
            "       and ``errors``. Under Python 2, ``encoding`` and ``errors`` are ignored",
            "       because native handling of universal newlines is used.",
            "",
            "    .. versionchanged:: 1.3a2",
            "       Under Python 2, ``restore_signals`` defaults to ``False``. Previously it",
            "       defaulted to ``True``, the same as it did in Python 3.",
            "",
            "    .. versionchanged:: 20.6.0",
            "       Add the *group*, *extra_groups*, *user*, and *umask* arguments. These",
            "       were added to Python 3.9, but are available in any gevent version, provided",
            "       the underlying platform support is present.",
            "",
            "    .. versionchanged:: 20.12.0",
            "       On Python 2 only, if unbuffered binary communication is requested,",
            "       the ``stdin`` attribute of this object will have a ``write`` method that",
            "       actually performs internal buffering and looping, similar to the standard library.",
            "       It guarantees to write all the data given to it in a single call (but internally",
            "       it may make many system calls and/or trips around the event loop to accomplish this).",
            "       See :issue:`1711`.",
            "",
            "    .. versionchanged:: 21.12.0",
            "       Added the ``pipesize`` argument for compatibility with Python 3.10.",
            "       This is ignored on all platforms.",
            "",
            "    .. versionchanged:: 22.08.0",
            "       Added the ``process_group`` and ``check`` arguments for compatibility with",
            "       Python 3.11.",
            "    \"\"\"",
            "",
            "    if GenericAlias is not None:",
            "        # 3.9, annoying typing is creeping everywhere.",
            "        __class_getitem__ = classmethod(GenericAlias)",
            "",
            "    # The value returned from communicate() when there was nothing to read.",
            "    # Changes if we're in text mode or universal newlines mode.",
            "    _communicate_empty_value = b''",
            "",
            "    def __init__(self, args,",
            "                 bufsize=-1,",
            "                 executable=None,",
            "                 stdin=None, stdout=None, stderr=None,",
            "                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS, shell=False,",
            "                 cwd=None, env=None, universal_newlines=None,",
            "                 startupinfo=None, creationflags=0,",
            "                 restore_signals=True, start_new_session=False,",
            "                 pass_fds=(),",
            "                 # Added in 3.6. These are kept as ivars",
            "                 encoding=None, errors=None,",
            "                 # Added in 3.7. Not an ivar directly.",
            "                 text=None,",
            "                 # Added in 3.9",
            "                 group=None, extra_groups=None, user=None,",
            "                 umask=-1,",
            "                 # Added in 3.10, but ignored.",
            "                 pipesize=-1,",
            "                 # Added in 3.11",
            "                 process_group=None,",
            "                 # gevent additions",
            "                 threadpool=None):",
            "",
            "        self.encoding = encoding",
            "        self.errors = errors",
            "",
            "        hub = get_hub()",
            "",
            "        if bufsize is None:",
            "            # Python 2 doesn't allow None at all, but Python 3 treats",
            "            # it the same as the default. We do as well.",
            "            bufsize = -1",
            "        if not isinstance(bufsize, integer_types):",
            "            raise TypeError(\"bufsize must be an integer\")",
            "",
            "        if mswindows:",
            "            if preexec_fn is not None:",
            "                raise ValueError(\"preexec_fn is not supported on Windows \"",
            "                                 \"platforms\")",
            "",
            "            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:",
            "                close_fds = True",
            "",
            "            if threadpool is None:",
            "                threadpool = hub.threadpool",
            "            self.threadpool = threadpool",
            "            self._waiting = False",
            "        else:",
            "            # POSIX",
            "            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:",
            "                # close_fds has different defaults on Py3/Py2",
            "                close_fds = True",
            "",
            "            if pass_fds and not close_fds:",
            "                import warnings",
            "                warnings.warn(\"pass_fds overriding close_fds.\", RuntimeWarning)",
            "                close_fds = True",
            "            if startupinfo is not None:",
            "                raise ValueError(\"startupinfo is only supported on Windows \"",
            "                                 \"platforms\")",
            "            if creationflags != 0:",
            "                raise ValueError(\"creationflags is only supported on Windows \"",
            "                                 \"platforms\")",
            "            assert threadpool is None",
            "            self._loop = hub.loop",
            "",
            "        # Validate the combinations of text and universal_newlines",
            "        if (text is not None and universal_newlines is not None",
            "                and bool(universal_newlines) != bool(text)):",
            "            # pylint:disable=undefined-variable",
            "            raise SubprocessError('Cannot disambiguate when both text '",
            "                                  'and universal_newlines are supplied but '",
            "                                  'different. Pass one or the other.')",
            "",
            "        self.args = args # Previously this was Py3 only.",
            "        self.stdin = None",
            "        self.stdout = None",
            "        self.stderr = None",
            "        self.pid = None",
            "        self.returncode = None",
            "        self.universal_newlines = universal_newlines",
            "        self.result = AsyncResult()",
            "",
            "        # Input and output objects. The general principle is like",
            "        # this:",
            "        #",
            "        # Parent                   Child",
            "        # ------                   -----",
            "        # p2cwrite   ---stdin--->  p2cread",
            "        # c2pread    <--stdout---  c2pwrite",
            "        # errread    <--stderr---  errwrite",
            "        #",
            "        # On POSIX, the child objects are file descriptors.  On",
            "        # Windows, these are Windows file handles.  The parent objects",
            "        # are file descriptors on both platforms.  The parent objects",
            "        # are -1 when not using PIPEs. The child objects are -1",
            "        # when not redirecting.",
            "",
            "        (p2cread, p2cwrite,",
            "         c2pread, c2pwrite,",
            "         errread, errwrite) = self._get_handles(stdin, stdout, stderr)",
            "",
            "        # We wrap OS handles *before* launching the child, otherwise a",
            "        # quickly terminating child could make our fds unwrappable",
            "        # (see #8458).",
            "        if mswindows:",
            "            if p2cwrite != -1:",
            "                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)",
            "            if c2pread != -1:",
            "                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)",
            "            if errread != -1:",
            "                errread = msvcrt.open_osfhandle(errread.Detach(), 0)",
            "",
            "        text_mode = self.encoding or self.errors or universal_newlines or text",
            "        if text_mode or universal_newlines:",
            "            # Always a native str in universal_newlines mode, even when that",
            "            # str type is bytes. Additionally, text_mode is only true under",
            "            # Python 3, so it's actually a unicode str",
            "            self._communicate_empty_value = ''",
            "",
            "        uid, gid, gids = self.__handle_uids(user, group, extra_groups)",
            "",
            "        if p2cwrite != -1:",
            "            if text_mode:",
            "                # Under Python 3, if we left on the 'b' we'd get different results",
            "                # depending on whether we used FileObjectPosix or FileObjectThread",
            "                self.stdin = FileObject(p2cwrite, 'w', bufsize,",
            "                                        encoding=self.encoding, errors=self.errors)",
            "            else:",
            "                self.stdin = FileObject(p2cwrite, 'wb', bufsize)",
            "",
            "        if c2pread != -1:",
            "            if universal_newlines or text_mode:",
            "                self.stdout = FileObject(c2pread, 'r', bufsize,",
            "                                         encoding=self.encoding, errors=self.errors)",
            "                # NOTE: Universal Newlines are broken on Windows/Py3, at least",
            "                # in some cases. This is true in the stdlib subprocess module",
            "                # as well; the following line would fix the test cases in",
            "                # test__subprocess.py that depend on python_universal_newlines,",
            "                # but would be inconsistent with the stdlib:",
            "",
            "            else:",
            "                self.stdout = FileObject(c2pread, 'rb', bufsize)",
            "        if errread != -1:",
            "            if universal_newlines or text_mode:",
            "                self.stderr = FileObject(errread, 'r', bufsize,",
            "                                         encoding=encoding, errors=errors)",
            "            else:",
            "                self.stderr = FileObject(errread, 'rb', bufsize)",
            "",
            "        self._closed_child_pipe_fds = False",
            "        # Convert here for the sake of all platforms. os.chdir accepts",
            "        # path-like objects natively under 3.6, but CreateProcess",
            "        # doesn't.",
            "        cwd = fsdecode(cwd) if cwd is not None else None",
            "        try:",
            "            self._execute_child(args, executable, preexec_fn, close_fds,",
            "                                pass_fds, cwd, env, universal_newlines,",
            "                                startupinfo, creationflags, shell,",
            "                                p2cread, p2cwrite,",
            "                                c2pread, c2pwrite,",
            "                                errread, errwrite,",
            "                                restore_signals,",
            "                                gid, gids, uid, umask,",
            "                                start_new_session, process_group)",
            "        except:",
            "            # Cleanup if the child failed starting.",
            "            # (gevent: New in python3, but reported as gevent bug in #347.",
            "            # Note that under Py2, any error raised below will replace the",
            "            # original error so we have to use reraise)",
            "            for f in filter(None, (self.stdin, self.stdout, self.stderr)):",
            "                try:",
            "                    f.close()",
            "                except OSError:",
            "                    pass  # Ignore EBADF or other errors.",
            "",
            "            if not self._closed_child_pipe_fds:",
            "                to_close = []",
            "                if stdin == PIPE:",
            "                    to_close.append(p2cread)",
            "                if stdout == PIPE:",
            "                    to_close.append(c2pwrite)",
            "                if stderr == PIPE:",
            "                    to_close.append(errwrite)",
            "                if hasattr(self, '_devnull'):",
            "                    to_close.append(self._devnull)",
            "                for fd in to_close:",
            "                    try:",
            "                        os.close(fd)",
            "                    except OSError:",
            "                        pass",
            "            raise",
            "",
            "    def __handle_uids(self, user, group, extra_groups):",
            "        gid = None",
            "        if group is not None:",
            "            if not hasattr(os, 'setregid'):",
            "                raise ValueError(\"The 'group' parameter is not supported on the \"",
            "                                 \"current platform\")",
            "",
            "            if isinstance(group, str):",
            "                if grp is None:",
            "                    raise ValueError(\"The group parameter cannot be a string \"",
            "                                     \"on systems without the grp module\")",
            "",
            "                gid = grp.getgrnam(group).gr_gid",
            "            elif isinstance(group, int):",
            "                gid = group",
            "            else:",
            "                raise TypeError(\"Group must be a string or an integer, not {}\"",
            "                                .format(type(group)))",
            "",
            "            if gid < 0:",
            "                raise ValueError(\"Group ID cannot be negative, got %s\" % gid)",
            "",
            "        gids = None",
            "        if extra_groups is not None:",
            "            if not hasattr(os, 'setgroups'):",
            "                raise ValueError(\"The 'extra_groups' parameter is not \"",
            "                                 \"supported on the current platform\")",
            "",
            "            if isinstance(extra_groups, str):",
            "                raise ValueError(\"Groups must be a list, not a string\")",
            "",
            "            gids = []",
            "            for extra_group in extra_groups:",
            "                if isinstance(extra_group, str):",
            "                    if grp is None:",
            "                        raise ValueError(\"Items in extra_groups cannot be \"",
            "                                         \"strings on systems without the \"",
            "                                         \"grp module\")",
            "",
            "                    gids.append(grp.getgrnam(extra_group).gr_gid)",
            "                elif isinstance(extra_group, int):",
            "                    if extra_group >= 2**64:",
            "                        # This check is implicit in the C version of _Py_Gid_Converter.",
            "                        #",
            "                        # We actually need access to the C type ``gid_t`` to get",
            "                        # its actual length. This just makes the test that was added",
            "                        # for the bug pass. That's OK though, if we guess too big here,",
            "                        # we should get an OverflowError from the setgroups()",
            "                        # call we make. The only difference is the type of exception.",
            "                        #",
            "                        # See https://bugs.python.org/issue42655",
            "                        raise ValueError(\"Item in extra_groups is too large\")",
            "                    gids.append(extra_group)",
            "                else:",
            "                    raise TypeError(\"Items in extra_groups must be a string \"",
            "                                    \"or integer, not {}\"",
            "                                    .format(type(extra_group)))",
            "",
            "            # make sure that the gids are all positive here so we can do less",
            "            # checking in the C code",
            "            for gid_check in gids:",
            "                if gid_check < 0:",
            "                    raise ValueError(\"Group ID cannot be negative, got %s\" % (gid_check,))",
            "",
            "        uid = None",
            "        if user is not None:",
            "            if not hasattr(os, 'setreuid'):",
            "                raise ValueError(\"The 'user' parameter is not supported on \"",
            "                                 \"the current platform\")",
            "",
            "            if isinstance(user, str):",
            "                if pwd is None:",
            "                    raise ValueError(\"The user parameter cannot be a string \"",
            "                                     \"on systems without the pwd module\")",
            "",
            "                uid = pwd.getpwnam(user).pw_uid",
            "            elif isinstance(user, int):",
            "                uid = user",
            "            else:",
            "                raise TypeError(\"User must be a string or an integer\")",
            "",
            "            if uid < 0:",
            "                raise ValueError(\"User ID cannot be negative, got %s\" % (uid,))",
            "",
            "        return uid, gid, gids",
            "",
            "    def __repr__(self):",
            "        return '<%s at 0x%x pid=%r returncode=%r>' % (self.__class__.__name__, id(self), self.pid, self.returncode)",
            "",
            "    def _on_child(self, watcher):",
            "        watcher.stop()",
            "        status = watcher.rstatus",
            "        if os.WIFSIGNALED(status):",
            "            self.returncode = -os.WTERMSIG(status)",
            "        else:",
            "            self.returncode = os.WEXITSTATUS(status)",
            "        self.result.set(self.returncode)",
            "",
            "    def _get_devnull(self):",
            "        if not hasattr(self, '_devnull'):",
            "            self._devnull = os.open(os.devnull, os.O_RDWR)",
            "        return self._devnull",
            "",
            "    _communicating_greenlets = None",
            "",
            "    def communicate(self, input=None, timeout=None):",
            "        \"\"\"",
            "        Interact with process and return its output and error.",
            "",
            "        - Send *input* data to stdin.",
            "        - Read data from stdout and stderr, until end-of-file is reached.",
            "        - Wait for process to terminate.",
            "",
            "        The optional *input* argument should be a",
            "        string to be sent to the child process, or None, if no data",
            "        should be sent to the child.",
            "",
            "        communicate() returns a tuple (stdout, stderr).",
            "",
            "        :keyword timeout: Under Python 2, this is a gevent extension; if",
            "           given and it expires, we will raise :exc:`TimeoutExpired`, which",
            "           extends :exc:`gevent.timeout.Timeout` (note that this only extends :exc:`BaseException`,",
            "           *not* :exc:`Exception`)",
            "           Under Python 3, this raises the standard :exc:`TimeoutExpired` exception.",
            "",
            "        .. versionchanged:: 1.1a2",
            "           Under Python 2, if the *timeout* elapses, raise the :exc:`gevent.timeout.Timeout`",
            "           exception. Previously, we silently returned.",
            "        .. versionchanged:: 1.1b5",
            "           Honor a *timeout* even if there's no way to communicate with the child",
            "           (stdin, stdout, and stderr are not pipes).",
            "        \"\"\"",
            "        if self._communicating_greenlets is None:",
            "            self._communicating_greenlets = _CommunicatingGreenlets(self, input)",
            "        greenlets = self._communicating_greenlets",
            "",
            "        # If we were given stdin=stdout=stderr=None, we have no way to",
            "        # communicate with the child, and thus no greenlets to wait",
            "        # on. This is a nonsense case, but it comes up in the test",
            "        # case for Python 3.5 (test_subprocess.py",
            "        # RunFuncTestCase.test_timeout). Instead, we go directly to",
            "        # self.wait",
            "        if not greenlets and timeout is not None:",
            "            self.wait(timeout=timeout, _raise_exc=True)",
            "",
            "        done = joinall(greenlets, timeout=timeout)",
            "        # Allow finished greenlets, if any, to raise. This takes priority over",
            "        # the timeout exception.",
            "        for greenlet in done:",
            "            greenlet.get()",
            "        if timeout is not None and len(done) != len(self._communicating_greenlets):",
            "            raise TimeoutExpired(self.args, timeout)",
            "",
            "        # Close only after we're sure that everything is done",
            "        # (there was no timeout, or there was, but everything finished).",
            "        # There should be no greenlets still running, even from a prior",
            "        # attempt. If there are, then this can raise RuntimeError: 'reentrant call'.",
            "        # So we ensure that previous greenlets are dead.",
            "        for pipe in (self.stdout, self.stderr):",
            "            if pipe:",
            "                try:",
            "                    pipe.close()",
            "                except RuntimeError:",
            "                    pass",
            "",
            "        self.wait()",
            "",
            "        return (None if greenlets.stdout is None else greenlets.stdout.get(),",
            "                None if greenlets.stderr is None else greenlets.stderr.get())",
            "",
            "    def poll(self):",
            "        \"\"\"Check if child process has terminated. Set and return :attr:`returncode` attribute.\"\"\"",
            "        return self._internal_poll()",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, t, v, tb):",
            "        if self.stdout:",
            "            self.stdout.close()",
            "        if self.stderr:",
            "            self.stderr.close()",
            "        try:  # Flushing a BufferedWriter may raise an error",
            "            if self.stdin:",
            "                self.stdin.close()",
            "        finally:",
            "            # Wait for the process to terminate, to avoid zombies.",
            "            # JAM: gevent: If the process never terminates, this",
            "            # blocks forever.",
            "            self.wait()",
            "",
            "    def _gevent_result_wait(self, timeout=None, raise_exc=True):",
            "        result = self.result.wait(timeout=timeout)",
            "        if raise_exc and timeout is not None and not self.result.ready():",
            "            raise TimeoutExpired(self.args, timeout)",
            "        return result",
            "",
            "",
            "    if mswindows:",
            "        #",
            "        # Windows methods",
            "        #",
            "        def _get_handles(self, stdin, stdout, stderr):",
            "            \"\"\"Construct and return tuple with IO objects:",
            "            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite",
            "            \"\"\"",
            "            # pylint:disable=undefined-variable",
            "            if stdin is None and stdout is None and stderr is None:",
            "                return (-1, -1, -1, -1, -1, -1)",
            "",
            "            p2cread, p2cwrite = -1, -1",
            "            c2pread, c2pwrite = -1, -1",
            "            errread, errwrite = -1, -1",
            "",
            "            try:",
            "                DEVNULL",
            "            except NameError:",
            "                _devnull = object()",
            "            else:",
            "                _devnull = DEVNULL",
            "",
            "            if stdin is None:",
            "                p2cread = GetStdHandle(STD_INPUT_HANDLE)",
            "                if p2cread is None:",
            "                    p2cread, _ = CreatePipe(None, 0)",
            "                    p2cread = Handle(p2cread)",
            "                    _winapi.CloseHandle(_)",
            "            elif stdin == PIPE:",
            "                p2cread, p2cwrite = CreatePipe(None, 0)",
            "                p2cread, p2cwrite = Handle(p2cread), Handle(p2cwrite)",
            "            elif stdin == _devnull:",
            "                p2cread = msvcrt.get_osfhandle(self._get_devnull())",
            "            elif isinstance(stdin, int):",
            "                p2cread = msvcrt.get_osfhandle(stdin)",
            "            else:",
            "                # Assuming file-like object",
            "                p2cread = msvcrt.get_osfhandle(stdin.fileno())",
            "            p2cread = self._make_inheritable(p2cread)",
            "",
            "            if stdout is None:",
            "                c2pwrite = GetStdHandle(STD_OUTPUT_HANDLE)",
            "                if c2pwrite is None:",
            "                    _, c2pwrite = CreatePipe(None, 0)",
            "                    c2pwrite = Handle(c2pwrite)",
            "                    _winapi.CloseHandle(_)",
            "            elif stdout == PIPE:",
            "                c2pread, c2pwrite = CreatePipe(None, 0)",
            "                c2pread, c2pwrite = Handle(c2pread), Handle(c2pwrite)",
            "            elif stdout == _devnull:",
            "                c2pwrite = msvcrt.get_osfhandle(self._get_devnull())",
            "            elif isinstance(stdout, int):",
            "                c2pwrite = msvcrt.get_osfhandle(stdout)",
            "            else:",
            "                # Assuming file-like object",
            "                c2pwrite = msvcrt.get_osfhandle(stdout.fileno())",
            "            c2pwrite = self._make_inheritable(c2pwrite)",
            "",
            "            if stderr is None:",
            "                errwrite = GetStdHandle(STD_ERROR_HANDLE)",
            "                if errwrite is None:",
            "                    _, errwrite = CreatePipe(None, 0)",
            "                    errwrite = Handle(errwrite)",
            "                    _winapi.CloseHandle(_)",
            "            elif stderr == PIPE:",
            "                errread, errwrite = CreatePipe(None, 0)",
            "                errread, errwrite = Handle(errread), Handle(errwrite)",
            "            elif stderr == STDOUT:",
            "                errwrite = c2pwrite",
            "            elif stderr == _devnull:",
            "                errwrite = msvcrt.get_osfhandle(self._get_devnull())",
            "            elif isinstance(stderr, int):",
            "                errwrite = msvcrt.get_osfhandle(stderr)",
            "            else:",
            "                # Assuming file-like object",
            "                errwrite = msvcrt.get_osfhandle(stderr.fileno())",
            "            errwrite = self._make_inheritable(errwrite)",
            "",
            "            return (p2cread, p2cwrite,",
            "                    c2pread, c2pwrite,",
            "                    errread, errwrite)",
            "",
            "        def _make_inheritable(self, handle):",
            "            \"\"\"Return a duplicate of handle, which is inheritable\"\"\"",
            "            # pylint:disable=undefined-variable",
            "            return DuplicateHandle(GetCurrentProcess(),",
            "                                   handle, GetCurrentProcess(), 0, 1,",
            "                                   DUPLICATE_SAME_ACCESS)",
            "",
            "        def _find_w9xpopen(self):",
            "            \"\"\"Find and return absolute path to w9xpopen.exe\"\"\"",
            "            # pylint:disable=undefined-variable",
            "            w9xpopen = os.path.join(os.path.dirname(GetModuleFileName(0)),",
            "                                    \"w9xpopen.exe\")",
            "            if not os.path.exists(w9xpopen):",
            "                # Eeek - file-not-found - possibly an embedding",
            "                # situation - see if we can locate it in sys.exec_prefix",
            "                w9xpopen = os.path.join(os.path.dirname(sys.exec_prefix),",
            "                                        \"w9xpopen.exe\")",
            "                if not os.path.exists(w9xpopen):",
            "                    raise RuntimeError(\"Cannot locate w9xpopen.exe, which is \"",
            "                                       \"needed for Popen to work with your \"",
            "                                       \"shell or platform.\")",
            "            return w9xpopen",
            "",
            "",
            "        def _filter_handle_list(self, handle_list):",
            "            \"\"\"Filter out console handles that can't be used",
            "            in lpAttributeList[\"handle_list\"] and make sure the list",
            "            isn't empty. This also removes duplicate handles.\"\"\"",
            "            # An handle with it's lowest two bits set might be a special console",
            "            # handle that if passed in lpAttributeList[\"handle_list\"], will",
            "            # cause it to fail.",
            "            # Only works on 3.7+",
            "            return list({handle for handle in handle_list",
            "                         if handle & 0x3 != 0x3",
            "                         or _winapi.GetFileType(handle) !=",
            "                         _winapi.FILE_TYPE_CHAR})",
            "",
            "",
            "        def _execute_child(self, args, executable, preexec_fn, close_fds,",
            "                           pass_fds, cwd, env, universal_newlines,",
            "                           startupinfo, creationflags, shell,",
            "                           p2cread, p2cwrite,",
            "                           c2pread, c2pwrite,",
            "                           errread, errwrite,",
            "                           unused_restore_signals,",
            "                           unused_gid, unused_gids, unused_uid, unused_umask,",
            "                           unused_start_new_session, unused_process_group):",
            "            \"\"\"Execute program (MS Windows version)\"\"\"",
            "            # pylint:disable=undefined-variable",
            "            assert not pass_fds, \"pass_fds not supported on Windows.\"",
            "            if isinstance(args, str):",
            "                pass",
            "            elif isinstance(args, bytes):",
            "                if shell:",
            "                    raise TypeError('bytes args is not allowed on Windows')",
            "                args = list2cmdline([args])",
            "            elif isinstance(args, PathLike):",
            "                if shell:",
            "                    raise TypeError('path-like args is not allowed when '",
            "                                    'shell is true')",
            "                args = list2cmdline([args])",
            "            else:",
            "                args = list2cmdline(args)",
            "",
            "            if executable is not None:",
            "                executable = fsdecode(executable)",
            "",
            "            if not isinstance(args, string_types):",
            "                args = list2cmdline(args)",
            "",
            "            # Process startup details",
            "            if startupinfo is None:",
            "                startupinfo = STARTUPINFO()",
            "            elif hasattr(startupinfo, 'copy'):",
            "                # bpo-34044: Copy STARTUPINFO since it is modified below,",
            "                # so the caller can reuse it multiple times.",
            "                startupinfo = startupinfo.copy()",
            "            elif hasattr(startupinfo, '_copy'):",
            "                # When the fix was backported to Python 3.7, copy() was",
            "                # made private as _copy.",
            "                startupinfo = startupinfo._copy()",
            "",
            "            use_std_handles = -1 not in (p2cread, c2pwrite, errwrite)",
            "            if use_std_handles:",
            "                startupinfo.dwFlags |= STARTF_USESTDHANDLES",
            "                startupinfo.hStdInput = p2cread",
            "                startupinfo.hStdOutput = c2pwrite",
            "                startupinfo.hStdError = errwrite",
            "",
            "            if hasattr(startupinfo, 'lpAttributeList'):",
            "                # Support for Python >= 3.7",
            "",
            "                attribute_list = startupinfo.lpAttributeList",
            "                have_handle_list = bool(attribute_list and",
            "                                        \"handle_list\" in attribute_list and",
            "                                        attribute_list[\"handle_list\"])",
            "",
            "                # If we were given an handle_list or need to create one",
            "                if have_handle_list or (use_std_handles and close_fds):",
            "                    if attribute_list is None:",
            "                        attribute_list = startupinfo.lpAttributeList = {}",
            "                    handle_list = attribute_list[\"handle_list\"] = \\",
            "                        list(attribute_list.get(\"handle_list\", []))",
            "",
            "                    if use_std_handles:",
            "                        handle_list += [int(p2cread), int(c2pwrite), int(errwrite)]",
            "",
            "                    handle_list[:] = self._filter_handle_list(handle_list)",
            "",
            "                    if handle_list:",
            "                        if not close_fds:",
            "                            import warnings",
            "                            warnings.warn(\"startupinfo.lpAttributeList['handle_list'] \"",
            "                                          \"overriding close_fds\", RuntimeWarning)",
            "",
            "                        # When using the handle_list we always request to inherit",
            "                        # handles but the only handles that will be inherited are",
            "                        # the ones in the handle_list",
            "                        close_fds = False",
            "",
            "            if shell:",
            "                startupinfo.dwFlags |= STARTF_USESHOWWINDOW",
            "                startupinfo.wShowWindow = SW_HIDE",
            "                comspec = os.environ.get(\"COMSPEC\", \"cmd.exe\")",
            "                args = '{} /c \"{}\"'.format(comspec, args)",
            "                if GetVersion() >= 0x80000000 or os.path.basename(comspec).lower() == \"command.com\":",
            "                    # Win9x, or using command.com on NT. We need to",
            "                    # use the w9xpopen intermediate program. For more",
            "                    # information, see KB Q150956",
            "                    # (http://web.archive.org/web/20011105084002/http://support.microsoft.com/support/kb/articles/Q150/9/56.asp)",
            "                    w9xpopen = self._find_w9xpopen()",
            "                    args = '\"%s\" %s' % (w9xpopen, args)",
            "                    # Not passing CREATE_NEW_CONSOLE has been known to",
            "                    # cause random failures on win9x.  Specifically a",
            "                    # dialog: \"Your program accessed mem currently in",
            "                    # use at xxx\" and a hopeful warning about the",
            "                    # stability of your system.  Cost is Ctrl+C wont",
            "                    # kill children.",
            "                    creationflags |= CREATE_NEW_CONSOLE",
            "",
            "            # PyPy 2.7 7.3.6 is now producing these errors. This",
            "            # happens automatically on Posix platforms, and is built",
            "            # in to the CreateProcess call on CPython 2 & 3. It's not",
            "            # clear why we don't pick it up for free from the",
            "            # CreateProcess call on PyPy. Currently we don't test PyPy3 on Windows,",
            "            # so we don't know for sure if it's built into CreateProcess there.",
            "            if PYPY:",
            "                def _check_nul(s, err_kind=ValueError):",
            "                    if not s:",
            "                        return",
            "                    nul = b'\\0' if isinstance(s, bytes) else '\\0'",
            "                    if nul in s:",
            "                        # PyPy 2 expects a TypeError; Python 3 raises ValueError always.",
            "                        raise err_kind(\"argument must be a string without NUL characters\")",
            "                def _check_env():",
            "                    if not env:",
            "                        return",
            "                    for k, v in env.items():",
            "                        _check_nul(k)",
            "                        _check_nul(v)",
            "                        if '=' in k:",
            "                            raise ValueError(\"'=' not allowed in environment keys\")",
            "",
            "                _check_nul(executable)",
            "                _check_nul(args)",
            "                _check_env()",
            "",
            "            # Start the process",
            "            try:",
            "                hp, ht, pid, tid = CreateProcess(executable, args,",
            "                                                 # no special security",
            "                                                 None, None,",
            "                                                 int(not close_fds),",
            "                                                 creationflags,",
            "                                                 env,",
            "                                                 cwd, # fsdecode handled earlier",
            "                                                 startupinfo)",
            "            # except IOError as e: # From 2.6 on, pywintypes.error was defined as IOError",
            "            #     # Translate pywintypes.error to WindowsError, which is",
            "            #     # a subclass of OSError.  FIXME: We should really",
            "            #     # translate errno using _sys_errlist (or similar), but",
            "            #     # how can this be done from Python?",
            "            #     raise # don't remap here",
            "            #     raise WindowsError(*e.args)",
            "            finally:",
            "                # Child is launched. Close the parent's copy of those pipe",
            "                # handles that only the child should have open.  You need",
            "                # to make sure that no handles to the write end of the",
            "                # output pipe are maintained in this process or else the",
            "                # pipe will not close when the child process exits and the",
            "                # ReadFile will hang.",
            "                def _close(x):",
            "                    if x is not None and x != -1:",
            "                        if hasattr(x, 'Close'):",
            "                            x.Close()",
            "                        else:",
            "                            _winapi.CloseHandle(x)",
            "",
            "                _close(p2cread)",
            "                _close(c2pwrite)",
            "                _close(errwrite)",
            "                if hasattr(self, '_devnull'):",
            "                    os.close(self._devnull)",
            "",
            "            # Retain the process handle, but close the thread handle",
            "            self._child_created = True",
            "            self._handle = Handle(hp) if not hasattr(hp, 'Close') else hp",
            "            self.pid = pid",
            "            _winapi.CloseHandle(ht) if not hasattr(ht, 'Close') else ht.Close()",
            "",
            "        def _internal_poll(self):",
            "            \"\"\"Check if child process has terminated.  Returns returncode",
            "            attribute.",
            "            \"\"\"",
            "            # pylint:disable=undefined-variable",
            "            if self.returncode is None:",
            "                if WaitForSingleObject(self._handle, 0) == WAIT_OBJECT_0:",
            "                    self.returncode = GetExitCodeProcess(self._handle)",
            "                    self.result.set(self.returncode)",
            "            return self.returncode",
            "",
            "        def rawlink(self, callback):",
            "            if not self.result.ready() and not self._waiting:",
            "                self._waiting = True",
            "                Greenlet.spawn(self._wait)",
            "            self.result.rawlink(linkproxy(callback, self))",
            "            # XXX unlink",
            "",
            "        def _blocking_wait(self):",
            "            # pylint:disable=undefined-variable",
            "            WaitForSingleObject(self._handle, INFINITE)",
            "            self.returncode = GetExitCodeProcess(self._handle)",
            "            return self.returncode",
            "",
            "        def _wait(self):",
            "            self.threadpool.spawn(self._blocking_wait).rawlink(self.result)",
            "",
            "        def wait(self, timeout=None, _raise_exc=True):",
            "            \"\"\"Wait for child process to terminate.  Returns returncode",
            "            attribute.\"\"\"",
            "            if self.returncode is None:",
            "                if not self._waiting:",
            "                    self._waiting = True",
            "                    self._wait()",
            "            return self._gevent_result_wait(timeout, _raise_exc)",
            "",
            "        def send_signal(self, sig):",
            "            \"\"\"Send a signal to the process",
            "            \"\"\"",
            "            if sig == signal.SIGTERM:",
            "                self.terminate()",
            "            elif sig == signal.CTRL_C_EVENT:",
            "                os.kill(self.pid, signal.CTRL_C_EVENT)",
            "            elif sig == signal.CTRL_BREAK_EVENT:",
            "                os.kill(self.pid, signal.CTRL_BREAK_EVENT)",
            "            else:",
            "                raise ValueError(\"Unsupported signal: {}\".format(sig))",
            "",
            "        def terminate(self):",
            "            \"\"\"Terminates the process",
            "            \"\"\"",
            "            # pylint:disable=undefined-variable",
            "            # Don't terminate a process that we know has already died.",
            "            if self.returncode is not None:",
            "                return",
            "            try:",
            "                TerminateProcess(self._handle, 1)",
            "            except OSError as e:",
            "                # ERROR_ACCESS_DENIED (winerror 5) is received when the",
            "                # process already died.",
            "                if e.winerror != 5:",
            "                    raise",
            "                rc = GetExitCodeProcess(self._handle)",
            "                if rc == STILL_ACTIVE:",
            "                    raise",
            "                self.returncode = rc",
            "                self.result.set(self.returncode)",
            "",
            "        kill = terminate",
            "",
            "    else:",
            "        #",
            "        # POSIX methods",
            "        #",
            "",
            "        def rawlink(self, callback):",
            "            # Not public documented, part of the link protocol",
            "            self.result.rawlink(linkproxy(callback, self))",
            "        # XXX unlink",
            "",
            "        def _get_handles(self, stdin, stdout, stderr):",
            "            \"\"\"Construct and return tuple with IO objects:",
            "            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite",
            "            \"\"\"",
            "            p2cread, p2cwrite = -1, -1",
            "            c2pread, c2pwrite = -1, -1",
            "            errread, errwrite = -1, -1",
            "",
            "            try:",
            "                DEVNULL",
            "            except NameError:",
            "                _devnull = object()",
            "            else:",
            "                _devnull = DEVNULL",
            "",
            "            if stdin is None:",
            "                pass",
            "            elif stdin == PIPE:",
            "                p2cread, p2cwrite = self.pipe_cloexec()",
            "            elif stdin == _devnull:",
            "                p2cread = self._get_devnull()",
            "            elif isinstance(stdin, int):",
            "                p2cread = stdin",
            "            else:",
            "                # Assuming file-like object",
            "                p2cread = stdin.fileno()",
            "",
            "            if stdout is None:",
            "                pass",
            "            elif stdout == PIPE:",
            "                c2pread, c2pwrite = self.pipe_cloexec()",
            "            elif stdout == _devnull:",
            "                c2pwrite = self._get_devnull()",
            "            elif isinstance(stdout, int):",
            "                c2pwrite = stdout",
            "            else:",
            "                # Assuming file-like object",
            "                c2pwrite = stdout.fileno()",
            "",
            "            if stderr is None:",
            "                pass",
            "            elif stderr == PIPE:",
            "                errread, errwrite = self.pipe_cloexec()",
            "            elif stderr == STDOUT: # pylint:disable=undefined-variable",
            "                if c2pwrite != -1:",
            "                    errwrite = c2pwrite",
            "                else: # child's stdout is not set, use parent's stdout",
            "                    errwrite = sys.__stdout__.fileno()",
            "            elif stderr == _devnull:",
            "                errwrite = self._get_devnull()",
            "            elif isinstance(stderr, int):",
            "                errwrite = stderr",
            "            else:",
            "                # Assuming file-like object",
            "                errwrite = stderr.fileno()",
            "",
            "            return (p2cread, p2cwrite,",
            "                    c2pread, c2pwrite,",
            "                    errread, errwrite)",
            "",
            "        def _set_cloexec_flag(self, fd, cloexec=True):",
            "            try:",
            "                cloexec_flag = fcntl.FD_CLOEXEC",
            "            except AttributeError:",
            "                cloexec_flag = 1",
            "",
            "            old = fcntl.fcntl(fd, fcntl.F_GETFD)",
            "            if cloexec:",
            "                fcntl.fcntl(fd, fcntl.F_SETFD, old | cloexec_flag)",
            "            else:",
            "                fcntl.fcntl(fd, fcntl.F_SETFD, old & ~cloexec_flag)",
            "",
            "        def _remove_nonblock_flag(self, fd):",
            "            flags = fcntl.fcntl(fd, fcntl.F_GETFL) & (~os.O_NONBLOCK)",
            "            fcntl.fcntl(fd, fcntl.F_SETFL, flags)",
            "",
            "        def pipe_cloexec(self):",
            "            \"\"\"Create a pipe with FDs set CLOEXEC.\"\"\"",
            "            # Pipes' FDs are set CLOEXEC by default because we don't want them",
            "            # to be inherited by other subprocesses: the CLOEXEC flag is removed",
            "            # from the child's FDs by _dup2(), between fork() and exec().",
            "            # This is not atomic: we would need the pipe2() syscall for that.",
            "            r, w = os.pipe()",
            "            self._set_cloexec_flag(r)",
            "            self._set_cloexec_flag(w)",
            "            return r, w",
            "",
            "        _POSSIBLE_FD_DIRS = (",
            "            '/proc/self/fd', # Linux",
            "            '/dev/fd', # BSD, including macOS",
            "        )",
            "",
            "        @classmethod",
            "        def _close_fds(cls, keep, errpipe_write):",
            "            # From the C code:",
            "            # errpipe_write is part of keep. It must be closed at",
            "            # exec(), but kept open in the child process until exec() is",
            "            # called.",
            "            for path in cls._POSSIBLE_FD_DIRS:",
            "                if os.path.isdir(path):",
            "                    return cls._close_fds_from_path(path, keep, errpipe_write)",
            "            return cls._close_fds_brute_force(keep, errpipe_write)",
            "",
            "        @classmethod",
            "        def _close_fds_from_path(cls, path, keep, errpipe_write):",
            "            # path names a directory whose only entries have",
            "            # names that are ascii strings of integers in base10,",
            "            # corresponding to the fds the current process has open",
            "            try:",
            "                fds = [int(fname) for fname in os.listdir(path)]",
            "            except (ValueError, OSError):",
            "                cls._close_fds_brute_force(keep, errpipe_write)",
            "            else:",
            "                for i in keep:",
            "                    if i == errpipe_write:",
            "                        continue",
            "                    _set_inheritable(i, True)",
            "",
            "                for fd in fds:",
            "                    if fd in keep or fd < 3:",
            "                        continue",
            "                    try:",
            "                        os.close(fd)",
            "                    except:",
            "                        pass",
            "",
            "        @classmethod",
            "        def _close_fds_brute_force(cls, keep, errpipe_write):",
            "            # `keep` is a set of fds, so we",
            "            # use os.closerange from 3 to min(keep)",
            "            # and then from max(keep + 1) to MAXFD and",
            "            # loop through filling in the gaps.",
            "",
            "            # Under new python versions, we need to explicitly set",
            "            # passed fds to be inheritable or they will go away on exec",
            "",
            "            # XXX: Bug: We implicitly rely on errpipe_write being the largest open",
            "            # FD so that we don't change its cloexec flag.",
            "",
            "            assert hasattr(os, 'closerange') # Added in 2.7",
            "            keep = sorted(keep)",
            "            min_keep = min(keep)",
            "            max_keep = max(keep)",
            "            os.closerange(3, min_keep)",
            "            os.closerange(max_keep + 1, MAXFD)",
            "",
            "            for i in xrange(min_keep, max_keep):",
            "                if i in keep:",
            "                    _set_inheritable(i, True)",
            "                    continue",
            "",
            "                try:",
            "                    os.close(i)",
            "                except:",
            "                    pass",
            "",
            "        def _execute_child(self, args, executable, preexec_fn, close_fds,",
            "                           pass_fds, cwd, env, universal_newlines,",
            "                           startupinfo, creationflags, shell,",
            "                           p2cread, p2cwrite,",
            "                           c2pread, c2pwrite,",
            "                           errread, errwrite,",
            "                           restore_signals,",
            "                           gid, gids, uid, umask,",
            "                           start_new_session, process_group):",
            "            \"\"\"Execute program (POSIX version)\"\"\"",
            "",
            "            if isinstance(args, (str, bytes)):",
            "                args = [args]",
            "            elif isinstance(args, PathLike):",
            "                if shell:",
            "                    raise TypeError('path-like args is not allowed when '",
            "                                    'shell is true')",
            "                args = [fsencode(args)] # os.PathLike -> [str]",
            "            else:",
            "                args = list(args)",
            "",
            "            if shell:",
            "                # On Android the default shell is at '/system/bin/sh'.",
            "                unix_shell = (",
            "                    '/system/bin/sh' if hasattr(sys, 'getandroidapilevel') else '/bin/sh'",
            "                )",
            "                args = [unix_shell, \"-c\"] + args",
            "                if executable:",
            "                    args[0] = executable",
            "",
            "            if executable is None:",
            "                executable = args[0]",
            "",
            "            self._loop.install_sigchld()",
            "",
            "            # For transferring possible exec failure from child to parent",
            "            # The first char specifies the exception type: 0 means",
            "            # OSError, 1 means some other error.",
            "            errpipe_read, errpipe_write = self.pipe_cloexec()",
            "            # errpipe_write must not be in the standard io 0, 1, or 2 fd range.",
            "            low_fds_to_close = []",
            "            while errpipe_write < 3:",
            "                low_fds_to_close.append(errpipe_write)",
            "                errpipe_write = os.dup(errpipe_write)",
            "            for low_fd in low_fds_to_close:",
            "                os.close(low_fd)",
            "            try:",
            "                try:",
            "                    gc_was_enabled = gc.isenabled()",
            "                    # Disable gc to avoid bug where gc -> file_dealloc ->",
            "                    # write to stderr -> hang.  http://bugs.python.org/issue1336",
            "                    gc.disable()",
            "                    try:",
            "                        self.pid = fork_and_watch(self._on_child, self._loop, True, fork)",
            "                    except:",
            "                        if gc_was_enabled:",
            "                            gc.enable()",
            "                        raise",
            "                    if self.pid == 0:",
            "                        # Child",
            "",
            "                        # XXX: Technically we're doing a lot of stuff here that",
            "                        # may not be safe to do before a exec(), depending on the OS.",
            "                        # CPython 3 goes to great lengths to precompute a lot",
            "                        # of this info before the fork and pass it all to C functions that",
            "                        # try hard not to call things like malloc(). (Of course,",
            "                        # CPython 2 pretty much did what we're doing.)",
            "                        try:",
            "                            # Close parent's pipe ends",
            "                            if p2cwrite != -1:",
            "                                os.close(p2cwrite)",
            "                            if c2pread != -1:",
            "                                os.close(c2pread)",
            "                            if errread != -1:",
            "                                os.close(errread)",
            "                            os.close(errpipe_read)",
            "",
            "                            # When duping fds, if there arises a situation",
            "                            # where one of the fds is either 0, 1 or 2, it",
            "                            # is possible that it is overwritten (#12607).",
            "                            if c2pwrite == 0:",
            "                                c2pwrite = os.dup(c2pwrite)",
            "                                _set_inheritable(c2pwrite, False)",
            "                            while errwrite in (0, 1):",
            "                                errwrite = os.dup(errwrite)",
            "                                _set_inheritable(errwrite, False)",
            "",
            "                            # Dup fds for child",
            "                            def _dup2(existing, desired):",
            "                                # dup2() removes the CLOEXEC flag but",
            "                                # we must do it ourselves if dup2()",
            "                                # would be a no-op (issue #10806).",
            "                                if existing == desired:",
            "                                    self._set_cloexec_flag(existing, False)",
            "                                elif existing != -1:",
            "                                    os.dup2(existing, desired)",
            "                                try:",
            "                                    self._remove_nonblock_flag(desired)",
            "                                except OSError:",
            "                                    # Ignore EBADF, it may not actually be",
            "                                    # open yet.",
            "                                    # Tested beginning in 3.7.0b3 test_subprocess.py",
            "                                    pass",
            "                            _dup2(p2cread, 0)",
            "                            _dup2(c2pwrite, 1)",
            "                            _dup2(errwrite, 2)",
            "",
            "                            # Close pipe fds.  Make sure we don't close the",
            "                            # same fd more than once, or standard fds.",
            "                            if not True:",
            "                                closed = set([None])",
            "                                for fd in (p2cread, c2pwrite, errwrite):",
            "                                    if fd not in closed and fd > 2:",
            "                                        os.close(fd)",
            "                                        closed.add(fd)",
            "",
            "                            # Python 3 (with a working set_inheritable):",
            "                            # We no longer manually close p2cread,",
            "\t                        # c2pwrite, and errwrite here as",
            "\t                        # _close_open_fds takes care when it is",
            "\t                        # not already non-inheritable.",
            "",
            "                            if cwd is not None:",
            "                                try:",
            "                                    os.chdir(cwd)",
            "                                except OSError as e:",
            "                                    e._failed_chdir = True",
            "                                    raise",
            "",
            "                            # Python 3.9",
            "                            if umask >= 0:",
            "                                os.umask(umask)",
            "                            # XXX: CPython does _Py_RestoreSignals here.",
            "                            # Then setsid() based on ???",
            "                            if gids:",
            "                                os.setgroups(gids)",
            "                            if gid:",
            "                                os.setregid(gid, gid)",
            "                            if uid:",
            "                                os.setreuid(uid, uid)",
            "                            if process_group is not None:",
            "                                os.setpgid(0, process_group)",
            "                            if preexec_fn:",
            "                                preexec_fn()",
            "",
            "                            # Close all other fds, if asked for. This must be done",
            "                            # after preexec_fn runs.",
            "                            if close_fds:",
            "                                fds_to_keep = set(pass_fds)",
            "                                fds_to_keep.add(errpipe_write)",
            "                                self._close_fds(fds_to_keep, errpipe_write)",
            "",
            "                            if restore_signals:",
            "                                # restore the documented signals back to sig_dfl;",
            "                                # not all will be defined on every platform",
            "                                for sig in 'SIGPIPE', 'SIGXFZ', 'SIGXFSZ':",
            "                                    sig = getattr(signal, sig, None)",
            "                                    if sig is not None:",
            "                                        signal.signal(sig, signal.SIG_DFL)",
            "",
            "                            if start_new_session:",
            "                                os.setsid()",
            "",
            "                            if env is None:",
            "                                os.execvp(executable, args)",
            "                            else:",
            "                                # Python 3.6 started testing for",
            "                                # bytes values in the env; it also",
            "                                # started encoding strs using",
            "                                # fsencode and using a lower-level",
            "                                # API that takes a list of keys",
            "                                # and values. We don't have access",
            "                                # to that API, so we go the reverse direction.",
            "                                env = {os.fsdecode(k) if isinstance(k, bytes) else k:",
            "                                       os.fsdecode(v) if isinstance(v, bytes) else v",
            "                                       for k, v in env.items()}",
            "                                os.execvpe(executable, args, env)",
            "",
            "                        except:",
            "                            exc_type, exc_value, tb = sys.exc_info()",
            "                            # Save the traceback and attach it to the exception object",
            "                            exc_lines = traceback.format_exception(exc_type,",
            "                                                                   exc_value,",
            "                                                                   tb)",
            "                            exc_value.child_traceback = ''.join(exc_lines)",
            "                            os.write(errpipe_write, pickle.dumps(exc_value))",
            "",
            "                        finally:",
            "                            # Make sure that the process exits no matter what.",
            "                            # The return code does not matter much as it won't be",
            "                            # reported to the application",
            "                            os._exit(1)",
            "",
            "                    # Parent",
            "                    self._child_created = True",
            "                    if gc_was_enabled:",
            "                        gc.enable()",
            "                finally:",
            "                    # be sure the FD is closed no matter what",
            "                    os.close(errpipe_write)",
            "",
            "                # self._devnull is not always defined.",
            "                devnull_fd = getattr(self, '_devnull', None)",
            "                if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:",
            "                    os.close(p2cread)",
            "                if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:",
            "                    os.close(c2pwrite)",
            "                if errwrite != -1 and errread != -1 and errwrite != devnull_fd:",
            "                    os.close(errwrite)",
            "                if devnull_fd is not None:",
            "                    os.close(devnull_fd)",
            "                # Prevent a double close of these fds from __init__ on error.",
            "                self._closed_child_pipe_fds = True",
            "",
            "                # Wait for exec to fail or succeed; possibly raising exception",
            "                errpipe_read = FileObject(errpipe_read, 'rb')",
            "                data = errpipe_read.read()",
            "            finally:",
            "                try:",
            "                    if hasattr(errpipe_read, 'close'):",
            "                        errpipe_read.close()",
            "                    else:",
            "                        os.close(errpipe_read)",
            "                except OSError:",
            "                    # Especially on PyPy, we sometimes see the above",
            "                    # `os.close(errpipe_read)` raise an OSError.",
            "                    # It's not entirely clear why, but it happens in",
            "                    # InterprocessSignalTests.test_main sometimes, which must mean",
            "                    # we have some sort of race condition.",
            "                    pass",
            "                finally:",
            "                    errpipe_read = -1",
            "",
            "            if data != b\"\":",
            "                self.wait()",
            "                child_exception = pickle.loads(data)",
            "                for fd in (p2cwrite, c2pread, errread):",
            "                    if fd is not None and fd != -1:",
            "                        os.close(fd)",
            "                if isinstance(child_exception, OSError):",
            "                    child_exception.filename = executable",
            "                    if hasattr(child_exception, '_failed_chdir'):",
            "                        child_exception.filename = cwd",
            "                raise child_exception",
            "",
            "        def _handle_exitstatus(self, sts, _WIFSIGNALED=os.WIFSIGNALED,",
            "                               _WTERMSIG=os.WTERMSIG, _WIFEXITED=os.WIFEXITED,",
            "                               _WEXITSTATUS=os.WEXITSTATUS, _WIFSTOPPED=os.WIFSTOPPED,",
            "                               _WSTOPSIG=os.WSTOPSIG):",
            "            # This method is called (indirectly) by __del__, so it cannot",
            "            # refer to anything outside of its local scope.",
            "            # (gevent: We don't have a __del__, that's in the CPython implementation.)",
            "            if _WIFSIGNALED(sts):",
            "                self.returncode = -_WTERMSIG(sts)",
            "            elif _WIFEXITED(sts):",
            "                self.returncode = _WEXITSTATUS(sts)",
            "            elif _WIFSTOPPED(sts):",
            "                self.returncode = -_WSTOPSIG(sts)",
            "            else:",
            "                # Should never happen",
            "                raise RuntimeError(\"Unknown child exit status!\")",
            "",
            "        def _internal_poll(self):",
            "            \"\"\"Check if child process has terminated.  Returns returncode",
            "            attribute.",
            "            \"\"\"",
            "            if self.returncode is None:",
            "                if get_hub() is not getcurrent():",
            "                    sig_pending = getattr(self._loop, 'sig_pending', True)",
            "                    if sig_pending:",
            "                        sleep(0.00001)",
            "            return self.returncode",
            "",
            "        def wait(self, timeout=None, _raise_exc=True):",
            "            \"\"\"",
            "            Wait for child process to terminate.  Returns :attr:`returncode`",
            "            attribute.",
            "",
            "            :keyword timeout: The floating point number of seconds to",
            "                wait. Under Python 2, this is a gevent extension, and",
            "                we simply return if it expires. Under Python 3, if",
            "                this time elapses without finishing the process,",
            "                :exc:`TimeoutExpired` is raised.",
            "            \"\"\"",
            "            return self._gevent_result_wait(timeout, _raise_exc)",
            "",
            "        def send_signal(self, sig):",
            "            \"\"\"Send a signal to the process",
            "            \"\"\"",
            "            # Skip signalling a process that we know has already died.",
            "            if self.returncode is None:",
            "                os.kill(self.pid, sig)",
            "",
            "        def terminate(self):",
            "            \"\"\"Terminate the process with SIGTERM",
            "            \"\"\"",
            "            self.send_signal(signal.SIGTERM)",
            "",
            "        def kill(self):",
            "            \"\"\"Kill the process with SIGKILL",
            "            \"\"\"",
            "            self.send_signal(signal.SIGKILL)",
            "",
            "",
            "def _with_stdout_stderr(exc, stderr):",
            "    # Prior to Python 3.5, most exceptions didn't have stdout",
            "    # and stderr attributes and can't take the stderr attribute in their",
            "    # constructor",
            "    exc.stdout = exc.output",
            "    exc.stderr = stderr",
            "    return exc",
            "",
            "class CompletedProcess(object):",
            "    \"\"\"",
            "    A process that has finished running.",
            "",
            "    This is returned by run().",
            "",
            "    Attributes:",
            "      - args: The list or str args passed to run().",
            "      - returncode: The exit code of the process, negative for signals.",
            "      - stdout: The standard output (None if not captured).",
            "      - stderr: The standard error (None if not captured).",
            "",
            "    .. versionadded:: 1.2a1",
            "       This first appeared in Python 3.5 and is available to all",
            "       Python versions in gevent.",
            "    \"\"\"",
            "    if GenericAlias is not None:",
            "        # Sigh, 3.9 spreading typing stuff all over everything",
            "        __class_getitem__ = classmethod(GenericAlias)",
            "",
            "    def __init__(self, args, returncode, stdout=None, stderr=None):",
            "        self.args = args",
            "        self.returncode = returncode",
            "        self.stdout = stdout",
            "        self.stderr = stderr",
            "",
            "    def __repr__(self):",
            "        args = ['args={!r}'.format(self.args),",
            "                'returncode={!r}'.format(self.returncode)]",
            "        if self.stdout is not None:",
            "            args.append('stdout={!r}'.format(self.stdout))",
            "        if self.stderr is not None:",
            "            args.append('stderr={!r}'.format(self.stderr))",
            "        return \"{}({})\".format(type(self).__name__, ', '.join(args))",
            "",
            "    def check_returncode(self):",
            "        \"\"\"Raise CalledProcessError if the exit code is non-zero.\"\"\"",
            "        if self.returncode:",
            "            # pylint:disable=undefined-variable",
            "            raise _with_stdout_stderr(CalledProcessError(self.returncode, self.args, self.stdout), self.stderr)",
            "",
            "",
            "def run(*popenargs, **kwargs):",
            "    \"\"\"",
            "    run(args, *, stdin=None, input=None, stdout=None, stderr=None, shell=False, timeout=None, check=False) -> CompletedProcess",
            "",
            "    Run command with arguments and return a CompletedProcess instance.",
            "",
            "    The returned instance will have attributes args, returncode, stdout and",
            "    stderr. By default, stdout and stderr are not captured, and those attributes",
            "    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.",
            "    If check is True and the exit code was non-zero, it raises a",
            "    CalledProcessError. The CalledProcessError object will have the return code",
            "    in the returncode attribute, and output & stderr attributes if those streams",
            "    were captured.",
            "",
            "    If timeout is given, and the process takes too long, a TimeoutExpired",
            "    exception will be raised.",
            "",
            "    There is an optional argument \"input\", allowing you to",
            "    pass a string to the subprocess's stdin.  If you use this argument",
            "    you may not also use the Popen constructor's \"stdin\" argument, as",
            "    it will be used internally.",
            "    The other arguments are the same as for the Popen constructor.",
            "    If universal_newlines=True is passed, the \"input\" argument must be a",
            "    string and stdout/stderr in the returned object will be strings rather than",
            "    bytes.",
            "",
            "    .. versionadded:: 1.2a1",
            "       This function first appeared in Python 3.5. It is available on all Python",
            "       versions gevent supports.",
            "",
            "    .. versionchanged:: 1.3a2",
            "       Add the ``capture_output`` argument from Python 3.7. It automatically sets",
            "       ``stdout`` and ``stderr`` to ``PIPE``. It is an error to pass either",
            "       of those arguments along with ``capture_output``.",
            "    \"\"\"",
            "    input = kwargs.pop('input', None)",
            "    timeout = kwargs.pop('timeout', None)",
            "    check = kwargs.pop('check', False)",
            "    capture_output = kwargs.pop('capture_output', False)",
            "",
            "    if input is not None:",
            "        if 'stdin' in kwargs:",
            "            raise ValueError('stdin and input arguments may not both be used.')",
            "        kwargs['stdin'] = PIPE",
            "",
            "    if capture_output:",
            "        if ('stdout' in kwargs) or ('stderr' in kwargs):",
            "            raise ValueError('stdout and stderr arguments may not be used '",
            "                             'with capture_output.')",
            "        kwargs['stdout'] = PIPE",
            "        kwargs['stderr'] = PIPE",
            "",
            "    with Popen(*popenargs, **kwargs) as process:",
            "        try:",
            "            stdout, stderr = process.communicate(input, timeout=timeout)",
            "        except TimeoutExpired:",
            "            process.kill()",
            "            stdout, stderr = process.communicate()",
            "            raise _with_stdout_stderr(TimeoutExpired(process.args, timeout, output=stdout), stderr)",
            "        except:",
            "            process.kill()",
            "            process.wait()",
            "            raise",
            "        retcode = process.poll()",
            "        if check and retcode:",
            "            # pylint:disable=undefined-variable",
            "            raise _with_stdout_stderr(CalledProcessError(retcode, process.args, stdout), stderr)",
            "",
            "    return CompletedProcess(process.args, retcode, stdout, stderr)",
            "",
            "def _gevent_did_monkey_patch(target_module, *_args, **_kwargs):",
            "    # Beginning on 3.8 on Mac, the 'spawn' method became the default",
            "    # start method. That doesn't fire fork watchers and we can't",
            "    # easily patch to make it do so: multiprocessing uses the private",
            "    # c accelerated _subprocess module to implement this. Instead we revert",
            "    # back to using fork.",
            "    from gevent._compat import MAC",
            "",
            "    if MAC:",
            "        import multiprocessing",
            "        if hasattr(multiprocessing, 'set_start_method'):",
            "            multiprocessing.set_start_method('fork', force=True)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "363": [
                "check_output"
            ],
            "365": [
                "check_output"
            ],
            "366": [
                "check_output"
            ]
        },
        "addLocation": []
    },
    "src/gevent/testing/testcase.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": 225,
                "PatchRowcode": "                 classDict.pop(key)"
            },
            "1": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 226,
                "PatchRowcode": "                 # XXX: When did we stop doing this?"
            },
            "2": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 227,
                "PatchRowcode": "                 #value = wrap_switch_count_check(value)"
            },
            "3": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                value = _wrap_timeout(timeout, value)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 228,
                "PatchRowcode": "+                #value = _wrap_timeout(timeout, value)"
            },
            "5": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": 229,
                "PatchRowcode": "                 error_fatal = getattr(value, 'error_fatal', error_fatal)"
            },
            "6": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 230,
                "PatchRowcode": "                 if error_fatal:"
            },
            "7": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": 231,
                "PatchRowcode": "                     value = errorhandler.wrap_error_fatal(value)"
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2018 gevent community",
            "#",
            "# Permission is hereby granted, free of charge, to any person obtaining a copy",
            "# of this software and associated documentation files (the \"Software\"), to deal",
            "# in the Software without restriction, including without limitation the rights",
            "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell",
            "# copies of the Software, and to permit persons to whom the Software is",
            "# furnished to do so, subject to the following conditions:",
            "#",
            "# The above copyright notice and this permission notice shall be included in",
            "# all copies or substantial portions of the Software.",
            "#",
            "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR",
            "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,",
            "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE",
            "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER",
            "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,",
            "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN",
            "# THE SOFTWARE.",
            "from __future__ import absolute_import, print_function, division",
            "",
            "import sys",
            "import os.path",
            "from contextlib import contextmanager",
            "from unittest import TestCase as BaseTestCase",
            "from functools import wraps",
            "",
            "import gevent",
            "from gevent._util import LazyOnClass",
            "from gevent._compat import perf_counter",
            "from gevent._compat import get_clock_info",
            "from gevent._hub_local import get_hub_if_exists",
            "",
            "from . import sysinfo",
            "from . import params",
            "from . import leakcheck",
            "from . import errorhandler",
            "from . import flaky",
            "",
            "from .patched_tests_setup import get_switch_expected",
            "",
            "class TimeAssertMixin(object):",
            "    @flaky.reraises_flaky_timeout()",
            "    def assertTimeoutAlmostEqual(self, first, second, places=None, msg=None, delta=None):",
            "        try:",
            "            self.assertAlmostEqual(first, second, places=places, msg=msg, delta=delta)",
            "        except AssertionError:",
            "            flaky.reraiseFlakyTestTimeout()",
            "",
            "",
            "    if sysinfo.EXPECT_POOR_TIMER_RESOLUTION:",
            "        # pylint:disable=unused-argument",
            "        def assertTimeWithinRange(self, time_taken, min_time, max_time):",
            "            return",
            "    else:",
            "        def assertTimeWithinRange(self, time_taken, min_time, max_time):",
            "            self.assertLessEqual(time_taken, max_time)",
            "            self.assertGreaterEqual(time_taken, min_time)",
            "",
            "    @contextmanager",
            "    def runs_in_given_time(self, expected, fuzzy=None, min_time=None):",
            "        if fuzzy is None:",
            "            if sysinfo.EXPECT_POOR_TIMER_RESOLUTION or sysinfo.LIBUV:",
            "                # The noted timer jitter issues on appveyor/pypy3",
            "                fuzzy = expected * 5.0",
            "            else:",
            "                fuzzy = expected / 2.0",
            "        min_time = min_time if min_time is not None else expected - fuzzy",
            "        max_time = expected + fuzzy",
            "        start = perf_counter()",
            "        yield (min_time, max_time)",
            "        elapsed = perf_counter() - start",
            "        try:",
            "            self.assertTrue(",
            "                min_time <= elapsed <= max_time,",
            "                'Expected: %r; elapsed: %r; min: %r; max: %r; fuzzy %r; clock_info: %s' % (",
            "                    expected, elapsed, min_time, max_time, fuzzy, get_clock_info('perf_counter')",
            "                ))",
            "        except AssertionError:",
            "            flaky.reraiseFlakyTestRaceCondition()",
            "",
            "    def runs_in_no_time(",
            "            self,",
            "            fuzzy=(0.01 if not sysinfo.EXPECT_POOR_TIMER_RESOLUTION and not sysinfo.LIBUV else 1.0)):",
            "        return self.runs_in_given_time(0.0, fuzzy)",
            "",
            "",
            "class GreenletAssertMixin(object):",
            "    \"\"\"Assertions related to greenlets.\"\"\"",
            "",
            "    def assert_greenlet_ready(self, g):",
            "        self.assertTrue(g.dead, g)",
            "        self.assertTrue(g.ready(), g)",
            "        self.assertFalse(g, g)",
            "",
            "    def assert_greenlet_not_ready(self, g):",
            "        self.assertFalse(g.dead, g)",
            "        self.assertFalse(g.ready(), g)",
            "",
            "    def assert_greenlet_spawned(self, g):",
            "        self.assertTrue(g.started, g)",
            "        self.assertFalse(g.dead, g)",
            "",
            "    # No difference between spawned and switched-to once",
            "    assert_greenlet_started = assert_greenlet_spawned",
            "",
            "    def assert_greenlet_finished(self, g):",
            "        self.assertFalse(g.started, g)",
            "        self.assertTrue(g.dead, g)",
            "",
            "",
            "class StringAssertMixin(object):",
            "    \"\"\"",
            "    Assertions dealing with strings.",
            "    \"\"\"",
            "",
            "    @LazyOnClass",
            "    def HEX_NUM_RE(self):",
            "        import re",
            "        return re.compile('-?0x[0123456789abcdef]+L?', re.I)",
            "",
            "    def normalize_addr(self, s, replace='X'):",
            "        # https://github.com/PyCQA/pylint/issues/1127",
            "        return self.HEX_NUM_RE.sub(replace, s) # pylint:disable=no-member",
            "",
            "    def normalize_module(self, s, module=None, replace='module'):",
            "        if module is None:",
            "            module = type(self).__module__",
            "",
            "        return s.replace(module, replace)",
            "",
            "    def normalize(self, s):",
            "        return self.normalize_module(self.normalize_addr(s))",
            "",
            "    def assert_nstr_endswith(self, o, val):",
            "        s = str(o)",
            "        n = self.normalize(s)",
            "        self.assertTrue(n.endswith(val), (s, n))",
            "",
            "    def assert_nstr_startswith(self, o, val):",
            "        s = str(o)",
            "        n = self.normalize(s)",
            "        self.assertTrue(n.startswith(val), (s, n))",
            "",
            "",
            "",
            "class TestTimeout(gevent.Timeout):",
            "    _expire_info = ''",
            "",
            "    def __init__(self, timeout, method='Not Given'):",
            "        gevent.Timeout.__init__(",
            "            self,",
            "            timeout,",
            "            '%r: test timed out\\n' % (method,),",
            "            ref=False",
            "        )",
            "",
            "    def _on_expiration(self, prev_greenlet, ex):",
            "        from gevent.util import format_run_info",
            "        loop = gevent.get_hub().loop",
            "        debug_info = 'N/A'",
            "        if hasattr(loop, 'debug'):",
            "            debug_info = [str(s) for s in loop.debug()]",
            "        run_info = format_run_info()",
            "        self._expire_info = 'Loop Debug:\\n%s\\nRun Info:\\n%s' % (",
            "            '\\n'.join(debug_info), '\\n'.join(run_info)",
            "        )",
            "        gevent.Timeout._on_expiration(self, prev_greenlet, ex)",
            "",
            "    def __str__(self):",
            "        s = gevent.Timeout.__str__(self)",
            "        s += self._expire_info",
            "        return s",
            "",
            "def _wrap_timeout(timeout, method):",
            "    if timeout is None:",
            "        return method",
            "",
            "    @wraps(method)",
            "    def timeout_wrapper(self, *args, **kwargs):",
            "        with TestTimeout(timeout, method):",
            "            return method(self, *args, **kwargs)",
            "",
            "    return timeout_wrapper",
            "",
            "def _get_class_attr(classDict, bases, attr, default=AttributeError):",
            "    NONE = object()",
            "    value = classDict.get(attr, NONE)",
            "    if value is not NONE:",
            "        return value",
            "    for base in bases:",
            "        value = getattr(base, attr, NONE)",
            "        if value is not NONE:",
            "            return value",
            "    if default is AttributeError:",
            "        raise AttributeError('Attribute %r not found\\n%s\\n%s\\n' % (attr, classDict, bases))",
            "    return default",
            "",
            "",
            "class TestCaseMetaClass(type):",
            "    # wrap each test method with",
            "    # a) timeout check",
            "    # b) fatal error check",
            "    # c) restore the hub's error handler (see expect_one_error)",
            "    # d) totalrefcount check",
            "    def __new__(cls, classname, bases, classDict):",
            "        # pylint and pep8 fight over what this should be called (mcs or cls).",
            "        # pylint gets it right, but we cant scope disable pep8, so we go with",
            "        # its convention.",
            "        # pylint: disable=bad-mcs-classmethod-argument",
            "        timeout = classDict.get('__timeout__', 'NONE')",
            "        if timeout == 'NONE':",
            "            timeout = getattr(bases[0], '__timeout__', None)",
            "            if sysinfo.RUN_LEAKCHECKS and timeout is not None:",
            "                timeout *= 6",
            "        check_totalrefcount = _get_class_attr(classDict, bases, 'check_totalrefcount', True)",
            "",
            "        error_fatal = _get_class_attr(classDict, bases, 'error_fatal', True)",
            "        uses_handle_error = _get_class_attr(classDict, bases, 'uses_handle_error', True)",
            "        # Python 3: must copy, we mutate the classDict. Interestingly enough,",
            "        # it doesn't actually error out, but under 3.6 we wind up wrapping",
            "        # and re-wrapping the same items over and over and over.",
            "        for key, value in list(classDict.items()):",
            "            if key.startswith('test') and callable(value):",
            "                classDict.pop(key)",
            "                # XXX: When did we stop doing this?",
            "                #value = wrap_switch_count_check(value)",
            "                value = _wrap_timeout(timeout, value)",
            "                error_fatal = getattr(value, 'error_fatal', error_fatal)",
            "                if error_fatal:",
            "                    value = errorhandler.wrap_error_fatal(value)",
            "                if uses_handle_error:",
            "                    value = errorhandler.wrap_restore_handle_error(value)",
            "                if check_totalrefcount and sysinfo.RUN_LEAKCHECKS:",
            "                    value = leakcheck.wrap_refcount(value)",
            "                classDict[key] = value",
            "        return type.__new__(cls, classname, bases, classDict)",
            "",
            "def _noop():",
            "    return",
            "",
            "class SubscriberCleanupMixin(object):",
            "",
            "    def setUp(self):",
            "        super(SubscriberCleanupMixin, self).setUp()",
            "        from gevent import events",
            "        self.__old_subscribers = events.subscribers[:]",
            "",
            "    def addSubscriber(self, sub):",
            "        from gevent import events",
            "        events.subscribers.append(sub)",
            "",
            "    def tearDown(self):",
            "        from gevent import events",
            "        events.subscribers[:] = self.__old_subscribers",
            "        super(SubscriberCleanupMixin, self).tearDown()",
            "",
            "",
            "class TestCase(TestCaseMetaClass(\"NewBase\",",
            "                                 (SubscriberCleanupMixin,",
            "                                  TimeAssertMixin,",
            "                                  GreenletAssertMixin,",
            "                                  StringAssertMixin,",
            "                                  BaseTestCase,),",
            "                                 {})):",
            "    __timeout__ = params.LOCAL_TIMEOUT if not sysinfo.RUNNING_ON_CI else params.CI_TIMEOUT",
            "",
            "    switch_expected = 'default'",
            "    #: Set this to true to cause errors that get reported to the hub to",
            "    #: always get propagated to the main greenlet. This can be done at the",
            "    #: class or method level.",
            "    #: .. caution:: This can hide errors and make it look like exceptions",
            "    #:    are propagated even if they're not.",
            "    error_fatal = True",
            "    uses_handle_error = True",
            "    close_on_teardown = ()",
            "    # This is really used by the SubscriberCleanupMixin",
            "    __old_subscribers = () # pylint:disable=unused-private-member",
            "",
            "    def run(self, *args, **kwargs): # pylint:disable=signature-differs",
            "        if self.switch_expected == 'default':",
            "            self.switch_expected = get_switch_expected(self.fullname)",
            "        return super(TestCase, self).run(*args, **kwargs)",
            "",
            "    def setUp(self):",
            "        super(TestCase, self).setUp()",
            "        # Especially if we're running in leakcheck mode, where",
            "        # the same test gets executed repeatedly, we need to update the",
            "        # current time. Tests don't always go through the full event loop,",
            "        # so that doesn't always happen. test__pool.py:TestPoolYYY.test_async",
            "        # tends to show timeouts that are too short if we don't.",
            "        # XXX: Should some core part of the loop call this?",
            "        hub = get_hub_if_exists()",
            "        if hub and hub.loop:",
            "            hub.loop.update_now()",
            "        self.close_on_teardown = []",
            "        self.addCleanup(self._tearDownCloseOnTearDown)",
            "",
            "    def tearDown(self):",
            "        if getattr(self, 'skipTearDown', False):",
            "            del self.close_on_teardown[:]",
            "            return",
            "",
            "        cleanup = getattr(self, 'cleanup', _noop)",
            "        cleanup()",
            "        self._error = self._none",
            "        super(TestCase, self).tearDown()",
            "",
            "    def _tearDownCloseOnTearDown(self):",
            "        while self.close_on_teardown:",
            "            x = self.close_on_teardown.pop()",
            "            close = getattr(x, 'close', x)",
            "            try:",
            "                close()",
            "            except Exception: # pylint:disable=broad-except",
            "                pass",
            "",
            "    def _close_on_teardown(self, resource):",
            "        \"\"\"",
            "        *resource* either has a ``close`` method, or is a",
            "        callable.",
            "        \"\"\"",
            "        self.close_on_teardown.append(resource)",
            "        return resource",
            "",
            "    @property",
            "    def testname(self):",
            "        return getattr(self, '_testMethodName', '') or getattr(self, '_TestCase__testMethodName')",
            "",
            "    @property",
            "    def testcasename(self):",
            "        return self.__class__.__name__ + '.' + self.testname",
            "",
            "    @property",
            "    def modulename(self):",
            "        return os.path.basename(sys.modules[self.__class__.__module__].__file__).rsplit('.', 1)[0]",
            "",
            "    @property",
            "    def fullname(self):",
            "        return os.path.splitext(os.path.basename(self.modulename))[0] + '.' + self.testcasename",
            "",
            "    _none = (None, None, None)",
            "    # (context, kind, value)",
            "    _error = _none",
            "",
            "    def expect_one_error(self):",
            "        self.assertEqual(self._error, self._none)",
            "        gevent.get_hub().handle_error = self._store_error",
            "",
            "    def _store_error(self, where, t, value, tb):",
            "        del tb",
            "        if self._error != self._none:",
            "            gevent.get_hub().parent.throw(t, value)",
            "        else:",
            "            self._error = (where, t, value)",
            "",
            "    def peek_error(self):",
            "        return self._error",
            "",
            "    def get_error(self):",
            "        try:",
            "            return self._error",
            "        finally:",
            "            self._error = self._none",
            "",
            "    def assert_error(self, kind=None, value=None, error=None, where_type=None):",
            "        if error is None:",
            "            error = self.get_error()",
            "        econtext, ekind, evalue = error",
            "        if kind is not None:",
            "            self.assertIsInstance(kind, type)",
            "            self.assertIsNotNone(",
            "                ekind,",
            "                \"Error must not be none %r\" % (error,))",
            "            assert issubclass(ekind, kind), error",
            "        if value is not None:",
            "            if isinstance(value, str):",
            "                self.assertEqual(str(evalue), value)",
            "            else:",
            "                self.assertIs(evalue, value)",
            "        if where_type is not None:",
            "            self.assertIsInstance(econtext, where_type)",
            "        return error",
            "",
            "    def assertMonkeyPatchedFuncSignatures(self, mod_name, func_names=(), exclude=()):",
            "        # If inspect.getfullargspec is not available,",
            "        # We use inspect.getargspec because it's the only thing available",
            "        # in Python 2.7, but it is deprecated",
            "        # pylint:disable=deprecated-method,too-many-locals",
            "        import inspect",
            "        import warnings",
            "        from gevent.monkey import get_original",
            "        # XXX: Very similar to gevent.monkey.patch_module. Should refactor?",
            "        gevent_module = getattr(__import__('gevent.' + mod_name), mod_name)",
            "        module_name = getattr(gevent_module, '__target__', mod_name)",
            "",
            "        funcs_given = True",
            "        if not func_names:",
            "            funcs_given = False",
            "            func_names = getattr(gevent_module, '__implements__')",
            "",
            "        for func_name in func_names:",
            "            if func_name in exclude:",
            "                continue",
            "            gevent_func = getattr(gevent_module, func_name)",
            "            if not inspect.isfunction(gevent_func) and not funcs_given:",
            "                continue",
            "",
            "            func = get_original(module_name, func_name)",
            "",
            "            try:",
            "                with warnings.catch_warnings():",
            "                    try:",
            "                        getfullargspec = inspect.getfullargspec",
            "                    except AttributeError:",
            "                        warnings.simplefilter(\"ignore\")",
            "                        getfullargspec = inspect.getargspec",
            "                    gevent_sig = getfullargspec(gevent_func)",
            "                    sig = getfullargspec(func)",
            "            except TypeError:",
            "                if funcs_given:",
            "                    raise",
            "                # Can't do this one. If they specifically asked for it,",
            "                # it's an error, otherwise it's not.",
            "                # Python 3 can check a lot more than Python 2 can.",
            "                continue",
            "            self.assertEqual(sig.args, gevent_sig.args, func_name)",
            "            # The next two might not actually matter?",
            "            self.assertEqual(sig.varargs, gevent_sig.varargs, func_name)",
            "            self.assertEqual(sig.defaults, gevent_sig.defaults, func_name)",
            "            if hasattr(sig, 'keywords'): # the old version",
            "                msg = (func_name, sig.keywords, gevent_sig.keywords)",
            "                try:",
            "                    self.assertEqual(sig.keywords, gevent_sig.keywords, msg)",
            "                except AssertionError:",
            "                    # Ok, if we take `kwargs` and the original function doesn't,",
            "                    # that's OK. We have to do that as a compatibility hack sometimes to",
            "                    # work across multiple python versions.",
            "                    self.assertIsNone(sig.keywords, msg)",
            "                    self.assertEqual('kwargs', gevent_sig.keywords)",
            "            else:",
            "                # The new hotness. Unfortunately, we can't actually check these things",
            "                # until we drop Python 2 support from the shared code. The only known place",
            "                # this is a problem is python 3.11 socket.create_connection(), which we manually",
            "                # ignore. So the checks all pass as is.",
            "                self.assertEqual(sig.kwonlyargs, gevent_sig.kwonlyargs, func_name)",
            "                self.assertEqual(sig.kwonlydefaults, gevent_sig.kwonlydefaults, func_name)",
            "            # Should deal with others: https://docs.python.org/3/library/inspect.html#inspect.getfullargspec",
            "",
            "    def assertEqualFlakyRaceCondition(self, a, b):",
            "        try:",
            "            self.assertEqual(a, b)",
            "        except AssertionError:",
            "            flaky.reraiseFlakyTestRaceCondition()",
            "",
            "    def assertStartsWith(self, it, has_prefix):",
            "        self.assertTrue(it.startswith(has_prefix), (it, has_prefix))",
            "",
            "    def assertNotMonkeyPatched(self):",
            "        from gevent import monkey",
            "        self.assertFalse(monkey.is_anything_patched())"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2018 gevent community",
            "#",
            "# Permission is hereby granted, free of charge, to any person obtaining a copy",
            "# of this software and associated documentation files (the \"Software\"), to deal",
            "# in the Software without restriction, including without limitation the rights",
            "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell",
            "# copies of the Software, and to permit persons to whom the Software is",
            "# furnished to do so, subject to the following conditions:",
            "#",
            "# The above copyright notice and this permission notice shall be included in",
            "# all copies or substantial portions of the Software.",
            "#",
            "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR",
            "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,",
            "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE",
            "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER",
            "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,",
            "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN",
            "# THE SOFTWARE.",
            "from __future__ import absolute_import, print_function, division",
            "",
            "import sys",
            "import os.path",
            "from contextlib import contextmanager",
            "from unittest import TestCase as BaseTestCase",
            "from functools import wraps",
            "",
            "import gevent",
            "from gevent._util import LazyOnClass",
            "from gevent._compat import perf_counter",
            "from gevent._compat import get_clock_info",
            "from gevent._hub_local import get_hub_if_exists",
            "",
            "from . import sysinfo",
            "from . import params",
            "from . import leakcheck",
            "from . import errorhandler",
            "from . import flaky",
            "",
            "from .patched_tests_setup import get_switch_expected",
            "",
            "class TimeAssertMixin(object):",
            "    @flaky.reraises_flaky_timeout()",
            "    def assertTimeoutAlmostEqual(self, first, second, places=None, msg=None, delta=None):",
            "        try:",
            "            self.assertAlmostEqual(first, second, places=places, msg=msg, delta=delta)",
            "        except AssertionError:",
            "            flaky.reraiseFlakyTestTimeout()",
            "",
            "",
            "    if sysinfo.EXPECT_POOR_TIMER_RESOLUTION:",
            "        # pylint:disable=unused-argument",
            "        def assertTimeWithinRange(self, time_taken, min_time, max_time):",
            "            return",
            "    else:",
            "        def assertTimeWithinRange(self, time_taken, min_time, max_time):",
            "            self.assertLessEqual(time_taken, max_time)",
            "            self.assertGreaterEqual(time_taken, min_time)",
            "",
            "    @contextmanager",
            "    def runs_in_given_time(self, expected, fuzzy=None, min_time=None):",
            "        if fuzzy is None:",
            "            if sysinfo.EXPECT_POOR_TIMER_RESOLUTION or sysinfo.LIBUV:",
            "                # The noted timer jitter issues on appveyor/pypy3",
            "                fuzzy = expected * 5.0",
            "            else:",
            "                fuzzy = expected / 2.0",
            "        min_time = min_time if min_time is not None else expected - fuzzy",
            "        max_time = expected + fuzzy",
            "        start = perf_counter()",
            "        yield (min_time, max_time)",
            "        elapsed = perf_counter() - start",
            "        try:",
            "            self.assertTrue(",
            "                min_time <= elapsed <= max_time,",
            "                'Expected: %r; elapsed: %r; min: %r; max: %r; fuzzy %r; clock_info: %s' % (",
            "                    expected, elapsed, min_time, max_time, fuzzy, get_clock_info('perf_counter')",
            "                ))",
            "        except AssertionError:",
            "            flaky.reraiseFlakyTestRaceCondition()",
            "",
            "    def runs_in_no_time(",
            "            self,",
            "            fuzzy=(0.01 if not sysinfo.EXPECT_POOR_TIMER_RESOLUTION and not sysinfo.LIBUV else 1.0)):",
            "        return self.runs_in_given_time(0.0, fuzzy)",
            "",
            "",
            "class GreenletAssertMixin(object):",
            "    \"\"\"Assertions related to greenlets.\"\"\"",
            "",
            "    def assert_greenlet_ready(self, g):",
            "        self.assertTrue(g.dead, g)",
            "        self.assertTrue(g.ready(), g)",
            "        self.assertFalse(g, g)",
            "",
            "    def assert_greenlet_not_ready(self, g):",
            "        self.assertFalse(g.dead, g)",
            "        self.assertFalse(g.ready(), g)",
            "",
            "    def assert_greenlet_spawned(self, g):",
            "        self.assertTrue(g.started, g)",
            "        self.assertFalse(g.dead, g)",
            "",
            "    # No difference between spawned and switched-to once",
            "    assert_greenlet_started = assert_greenlet_spawned",
            "",
            "    def assert_greenlet_finished(self, g):",
            "        self.assertFalse(g.started, g)",
            "        self.assertTrue(g.dead, g)",
            "",
            "",
            "class StringAssertMixin(object):",
            "    \"\"\"",
            "    Assertions dealing with strings.",
            "    \"\"\"",
            "",
            "    @LazyOnClass",
            "    def HEX_NUM_RE(self):",
            "        import re",
            "        return re.compile('-?0x[0123456789abcdef]+L?', re.I)",
            "",
            "    def normalize_addr(self, s, replace='X'):",
            "        # https://github.com/PyCQA/pylint/issues/1127",
            "        return self.HEX_NUM_RE.sub(replace, s) # pylint:disable=no-member",
            "",
            "    def normalize_module(self, s, module=None, replace='module'):",
            "        if module is None:",
            "            module = type(self).__module__",
            "",
            "        return s.replace(module, replace)",
            "",
            "    def normalize(self, s):",
            "        return self.normalize_module(self.normalize_addr(s))",
            "",
            "    def assert_nstr_endswith(self, o, val):",
            "        s = str(o)",
            "        n = self.normalize(s)",
            "        self.assertTrue(n.endswith(val), (s, n))",
            "",
            "    def assert_nstr_startswith(self, o, val):",
            "        s = str(o)",
            "        n = self.normalize(s)",
            "        self.assertTrue(n.startswith(val), (s, n))",
            "",
            "",
            "",
            "class TestTimeout(gevent.Timeout):",
            "    _expire_info = ''",
            "",
            "    def __init__(self, timeout, method='Not Given'):",
            "        gevent.Timeout.__init__(",
            "            self,",
            "            timeout,",
            "            '%r: test timed out\\n' % (method,),",
            "            ref=False",
            "        )",
            "",
            "    def _on_expiration(self, prev_greenlet, ex):",
            "        from gevent.util import format_run_info",
            "        loop = gevent.get_hub().loop",
            "        debug_info = 'N/A'",
            "        if hasattr(loop, 'debug'):",
            "            debug_info = [str(s) for s in loop.debug()]",
            "        run_info = format_run_info()",
            "        self._expire_info = 'Loop Debug:\\n%s\\nRun Info:\\n%s' % (",
            "            '\\n'.join(debug_info), '\\n'.join(run_info)",
            "        )",
            "        gevent.Timeout._on_expiration(self, prev_greenlet, ex)",
            "",
            "    def __str__(self):",
            "        s = gevent.Timeout.__str__(self)",
            "        s += self._expire_info",
            "        return s",
            "",
            "def _wrap_timeout(timeout, method):",
            "    if timeout is None:",
            "        return method",
            "",
            "    @wraps(method)",
            "    def timeout_wrapper(self, *args, **kwargs):",
            "        with TestTimeout(timeout, method):",
            "            return method(self, *args, **kwargs)",
            "",
            "    return timeout_wrapper",
            "",
            "def _get_class_attr(classDict, bases, attr, default=AttributeError):",
            "    NONE = object()",
            "    value = classDict.get(attr, NONE)",
            "    if value is not NONE:",
            "        return value",
            "    for base in bases:",
            "        value = getattr(base, attr, NONE)",
            "        if value is not NONE:",
            "            return value",
            "    if default is AttributeError:",
            "        raise AttributeError('Attribute %r not found\\n%s\\n%s\\n' % (attr, classDict, bases))",
            "    return default",
            "",
            "",
            "class TestCaseMetaClass(type):",
            "    # wrap each test method with",
            "    # a) timeout check",
            "    # b) fatal error check",
            "    # c) restore the hub's error handler (see expect_one_error)",
            "    # d) totalrefcount check",
            "    def __new__(cls, classname, bases, classDict):",
            "        # pylint and pep8 fight over what this should be called (mcs or cls).",
            "        # pylint gets it right, but we cant scope disable pep8, so we go with",
            "        # its convention.",
            "        # pylint: disable=bad-mcs-classmethod-argument",
            "        timeout = classDict.get('__timeout__', 'NONE')",
            "        if timeout == 'NONE':",
            "            timeout = getattr(bases[0], '__timeout__', None)",
            "            if sysinfo.RUN_LEAKCHECKS and timeout is not None:",
            "                timeout *= 6",
            "        check_totalrefcount = _get_class_attr(classDict, bases, 'check_totalrefcount', True)",
            "",
            "        error_fatal = _get_class_attr(classDict, bases, 'error_fatal', True)",
            "        uses_handle_error = _get_class_attr(classDict, bases, 'uses_handle_error', True)",
            "        # Python 3: must copy, we mutate the classDict. Interestingly enough,",
            "        # it doesn't actually error out, but under 3.6 we wind up wrapping",
            "        # and re-wrapping the same items over and over and over.",
            "        for key, value in list(classDict.items()):",
            "            if key.startswith('test') and callable(value):",
            "                classDict.pop(key)",
            "                # XXX: When did we stop doing this?",
            "                #value = wrap_switch_count_check(value)",
            "                #value = _wrap_timeout(timeout, value)",
            "                error_fatal = getattr(value, 'error_fatal', error_fatal)",
            "                if error_fatal:",
            "                    value = errorhandler.wrap_error_fatal(value)",
            "                if uses_handle_error:",
            "                    value = errorhandler.wrap_restore_handle_error(value)",
            "                if check_totalrefcount and sysinfo.RUN_LEAKCHECKS:",
            "                    value = leakcheck.wrap_refcount(value)",
            "                classDict[key] = value",
            "        return type.__new__(cls, classname, bases, classDict)",
            "",
            "def _noop():",
            "    return",
            "",
            "class SubscriberCleanupMixin(object):",
            "",
            "    def setUp(self):",
            "        super(SubscriberCleanupMixin, self).setUp()",
            "        from gevent import events",
            "        self.__old_subscribers = events.subscribers[:]",
            "",
            "    def addSubscriber(self, sub):",
            "        from gevent import events",
            "        events.subscribers.append(sub)",
            "",
            "    def tearDown(self):",
            "        from gevent import events",
            "        events.subscribers[:] = self.__old_subscribers",
            "        super(SubscriberCleanupMixin, self).tearDown()",
            "",
            "",
            "class TestCase(TestCaseMetaClass(\"NewBase\",",
            "                                 (SubscriberCleanupMixin,",
            "                                  TimeAssertMixin,",
            "                                  GreenletAssertMixin,",
            "                                  StringAssertMixin,",
            "                                  BaseTestCase,),",
            "                                 {})):",
            "    __timeout__ = params.LOCAL_TIMEOUT if not sysinfo.RUNNING_ON_CI else params.CI_TIMEOUT",
            "",
            "    switch_expected = 'default'",
            "    #: Set this to true to cause errors that get reported to the hub to",
            "    #: always get propagated to the main greenlet. This can be done at the",
            "    #: class or method level.",
            "    #: .. caution:: This can hide errors and make it look like exceptions",
            "    #:    are propagated even if they're not.",
            "    error_fatal = True",
            "    uses_handle_error = True",
            "    close_on_teardown = ()",
            "    # This is really used by the SubscriberCleanupMixin",
            "    __old_subscribers = () # pylint:disable=unused-private-member",
            "",
            "    def run(self, *args, **kwargs): # pylint:disable=signature-differs",
            "        if self.switch_expected == 'default':",
            "            self.switch_expected = get_switch_expected(self.fullname)",
            "        return super(TestCase, self).run(*args, **kwargs)",
            "",
            "    def setUp(self):",
            "        super(TestCase, self).setUp()",
            "        # Especially if we're running in leakcheck mode, where",
            "        # the same test gets executed repeatedly, we need to update the",
            "        # current time. Tests don't always go through the full event loop,",
            "        # so that doesn't always happen. test__pool.py:TestPoolYYY.test_async",
            "        # tends to show timeouts that are too short if we don't.",
            "        # XXX: Should some core part of the loop call this?",
            "        hub = get_hub_if_exists()",
            "        if hub and hub.loop:",
            "            hub.loop.update_now()",
            "        self.close_on_teardown = []",
            "        self.addCleanup(self._tearDownCloseOnTearDown)",
            "",
            "    def tearDown(self):",
            "        if getattr(self, 'skipTearDown', False):",
            "            del self.close_on_teardown[:]",
            "            return",
            "",
            "        cleanup = getattr(self, 'cleanup', _noop)",
            "        cleanup()",
            "        self._error = self._none",
            "        super(TestCase, self).tearDown()",
            "",
            "    def _tearDownCloseOnTearDown(self):",
            "        while self.close_on_teardown:",
            "            x = self.close_on_teardown.pop()",
            "            close = getattr(x, 'close', x)",
            "            try:",
            "                close()",
            "            except Exception: # pylint:disable=broad-except",
            "                pass",
            "",
            "    def _close_on_teardown(self, resource):",
            "        \"\"\"",
            "        *resource* either has a ``close`` method, or is a",
            "        callable.",
            "        \"\"\"",
            "        self.close_on_teardown.append(resource)",
            "        return resource",
            "",
            "    @property",
            "    def testname(self):",
            "        return getattr(self, '_testMethodName', '') or getattr(self, '_TestCase__testMethodName')",
            "",
            "    @property",
            "    def testcasename(self):",
            "        return self.__class__.__name__ + '.' + self.testname",
            "",
            "    @property",
            "    def modulename(self):",
            "        return os.path.basename(sys.modules[self.__class__.__module__].__file__).rsplit('.', 1)[0]",
            "",
            "    @property",
            "    def fullname(self):",
            "        return os.path.splitext(os.path.basename(self.modulename))[0] + '.' + self.testcasename",
            "",
            "    _none = (None, None, None)",
            "    # (context, kind, value)",
            "    _error = _none",
            "",
            "    def expect_one_error(self):",
            "        self.assertEqual(self._error, self._none)",
            "        gevent.get_hub().handle_error = self._store_error",
            "",
            "    def _store_error(self, where, t, value, tb):",
            "        del tb",
            "        if self._error != self._none:",
            "            gevent.get_hub().parent.throw(t, value)",
            "        else:",
            "            self._error = (where, t, value)",
            "",
            "    def peek_error(self):",
            "        return self._error",
            "",
            "    def get_error(self):",
            "        try:",
            "            return self._error",
            "        finally:",
            "            self._error = self._none",
            "",
            "    def assert_error(self, kind=None, value=None, error=None, where_type=None):",
            "        if error is None:",
            "            error = self.get_error()",
            "        econtext, ekind, evalue = error",
            "        if kind is not None:",
            "            self.assertIsInstance(kind, type)",
            "            self.assertIsNotNone(",
            "                ekind,",
            "                \"Error must not be none %r\" % (error,))",
            "            assert issubclass(ekind, kind), error",
            "        if value is not None:",
            "            if isinstance(value, str):",
            "                self.assertEqual(str(evalue), value)",
            "            else:",
            "                self.assertIs(evalue, value)",
            "        if where_type is not None:",
            "            self.assertIsInstance(econtext, where_type)",
            "        return error",
            "",
            "    def assertMonkeyPatchedFuncSignatures(self, mod_name, func_names=(), exclude=()):",
            "        # If inspect.getfullargspec is not available,",
            "        # We use inspect.getargspec because it's the only thing available",
            "        # in Python 2.7, but it is deprecated",
            "        # pylint:disable=deprecated-method,too-many-locals",
            "        import inspect",
            "        import warnings",
            "        from gevent.monkey import get_original",
            "        # XXX: Very similar to gevent.monkey.patch_module. Should refactor?",
            "        gevent_module = getattr(__import__('gevent.' + mod_name), mod_name)",
            "        module_name = getattr(gevent_module, '__target__', mod_name)",
            "",
            "        funcs_given = True",
            "        if not func_names:",
            "            funcs_given = False",
            "            func_names = getattr(gevent_module, '__implements__')",
            "",
            "        for func_name in func_names:",
            "            if func_name in exclude:",
            "                continue",
            "            gevent_func = getattr(gevent_module, func_name)",
            "            if not inspect.isfunction(gevent_func) and not funcs_given:",
            "                continue",
            "",
            "            func = get_original(module_name, func_name)",
            "",
            "            try:",
            "                with warnings.catch_warnings():",
            "                    try:",
            "                        getfullargspec = inspect.getfullargspec",
            "                    except AttributeError:",
            "                        warnings.simplefilter(\"ignore\")",
            "                        getfullargspec = inspect.getargspec",
            "                    gevent_sig = getfullargspec(gevent_func)",
            "                    sig = getfullargspec(func)",
            "            except TypeError:",
            "                if funcs_given:",
            "                    raise",
            "                # Can't do this one. If they specifically asked for it,",
            "                # it's an error, otherwise it's not.",
            "                # Python 3 can check a lot more than Python 2 can.",
            "                continue",
            "            self.assertEqual(sig.args, gevent_sig.args, func_name)",
            "            # The next two might not actually matter?",
            "            self.assertEqual(sig.varargs, gevent_sig.varargs, func_name)",
            "            self.assertEqual(sig.defaults, gevent_sig.defaults, func_name)",
            "            if hasattr(sig, 'keywords'): # the old version",
            "                msg = (func_name, sig.keywords, gevent_sig.keywords)",
            "                try:",
            "                    self.assertEqual(sig.keywords, gevent_sig.keywords, msg)",
            "                except AssertionError:",
            "                    # Ok, if we take `kwargs` and the original function doesn't,",
            "                    # that's OK. We have to do that as a compatibility hack sometimes to",
            "                    # work across multiple python versions.",
            "                    self.assertIsNone(sig.keywords, msg)",
            "                    self.assertEqual('kwargs', gevent_sig.keywords)",
            "            else:",
            "                # The new hotness. Unfortunately, we can't actually check these things",
            "                # until we drop Python 2 support from the shared code. The only known place",
            "                # this is a problem is python 3.11 socket.create_connection(), which we manually",
            "                # ignore. So the checks all pass as is.",
            "                self.assertEqual(sig.kwonlyargs, gevent_sig.kwonlyargs, func_name)",
            "                self.assertEqual(sig.kwonlydefaults, gevent_sig.kwonlydefaults, func_name)",
            "            # Should deal with others: https://docs.python.org/3/library/inspect.html#inspect.getfullargspec",
            "",
            "    def assertEqualFlakyRaceCondition(self, a, b):",
            "        try:",
            "            self.assertEqual(a, b)",
            "        except AssertionError:",
            "            flaky.reraiseFlakyTestRaceCondition()",
            "",
            "    def assertStartsWith(self, it, has_prefix):",
            "        self.assertTrue(it.startswith(has_prefix), (it, has_prefix))",
            "",
            "    def assertNotMonkeyPatched(self):",
            "        from gevent import monkey",
            "        self.assertFalse(monkey.is_anything_patched())"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "228": [
                "TestCaseMetaClass",
                "__new__"
            ]
        },
        "addLocation": []
    }
}