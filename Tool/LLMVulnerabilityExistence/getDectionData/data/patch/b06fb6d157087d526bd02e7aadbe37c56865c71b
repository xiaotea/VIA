{
    "mitmproxy/addons/proxyserver.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "             in custom scripts are lowercased before they are sent."
            },
            "1": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 99,
                "PatchRowcode": "             \"\"\","
            },
            "2": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 100,
                "PatchRowcode": "         )"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+        loader.add_option("
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+            \"validate_inbound_headers\", bool, True,"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+            \"\"\""
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+            Make sure that incoming HTTP requests are not malformed."
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+            Disabling this option makes mitmproxy vulnerable to HTTP smuggling attacks."
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+            \"\"\","
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+        )"
            },
            "10": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 108,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 109,
                "PatchRowcode": "     async def running(self):"
            },
            "12": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 110,
                "PatchRowcode": "         self.master = ctx.master"
            }
        },
        "frontPatchFile": [
            "import asyncio",
            "from typing import Dict, Optional, Tuple",
            "",
            "from mitmproxy import command, ctx, exceptions, flow, http, log, master, options, platform, tcp, websocket",
            "from mitmproxy.flow import Flow",
            "from mitmproxy.proxy import commands, events, server_hooks",
            "from mitmproxy.proxy import server",
            "from mitmproxy.proxy.layers.tcp import TcpMessageInjected",
            "from mitmproxy.proxy.layers.websocket import WebSocketMessageInjected",
            "from mitmproxy.utils import asyncio_utils, human",
            "from wsproto.frame_protocol import Opcode",
            "",
            "",
            "class ProxyConnectionHandler(server.StreamConnectionHandler):",
            "    master: master.Master",
            "",
            "    def __init__(self, master, r, w, options):",
            "        self.master = master",
            "        super().__init__(r, w, options)",
            "        self.log_prefix = f\"{human.format_address(self.client.peername)}: \"",
            "",
            "    async def handle_hook(self, hook: commands.StartHook) -> None:",
            "        with self.timeout_watchdog.disarm():",
            "            # We currently only support single-argument hooks.",
            "            data, = hook.args()",
            "            await self.master.addons.handle_lifecycle(hook)",
            "            if isinstance(data, flow.Flow):",
            "                await data.wait_for_resume()",
            "",
            "    def log(self, message: str, level: str = \"info\") -> None:",
            "        x = log.LogEntry(self.log_prefix + message, level)",
            "        asyncio_utils.create_task(",
            "            self.master.addons.handle_lifecycle(log.AddLogHook(x)),",
            "            name=\"ProxyConnectionHandler.log\"",
            "        )",
            "",
            "",
            "class Proxyserver:",
            "    \"\"\"",
            "    This addon runs the actual proxy server.",
            "    \"\"\"",
            "    server: Optional[asyncio.AbstractServer]",
            "    listen_port: int",
            "    master: master.Master",
            "    options: options.Options",
            "    is_running: bool",
            "    _connections: Dict[Tuple, ProxyConnectionHandler]",
            "",
            "    def __init__(self):",
            "        self._lock = asyncio.Lock()",
            "        self.server = None",
            "        self.is_running = False",
            "        self._connections = {}",
            "",
            "    def __repr__(self):",
            "        return f\"ProxyServer({'running' if self.server else 'stopped'}, {len(self._connections)} active conns)\"",
            "",
            "    def load(self, loader):",
            "        loader.add_option(",
            "            \"connection_strategy\", str, \"eager\",",
            "            \"Determine when server connections should be established. When set to lazy, mitmproxy \"",
            "            \"tries to defer establishing an upstream connection as long as possible. This makes it possible to \"",
            "            \"use server replay while being offline. When set to eager, mitmproxy can detect protocols with \"",
            "            \"server-side greetings, as well as accurately mirror TLS ALPN negotiation.\",",
            "            choices=(\"eager\", \"lazy\")",
            "        )",
            "        loader.add_option(",
            "            \"stream_large_bodies\", Optional[str], None,",
            "            \"\"\"",
            "            Stream data to the client if response body exceeds the given",
            "            threshold. If streamed, the body will not be stored in any way.",
            "            Understands k/m/g suffixes, i.e. 3m for 3 megabytes.",
            "            \"\"\"",
            "        )",
            "        loader.add_option(",
            "            \"body_size_limit\", Optional[str], None,",
            "            \"\"\"",
            "            Byte size limit of HTTP request and response bodies. Understands",
            "            k/m/g suffixes, i.e. 3m for 3 megabytes.",
            "            \"\"\"",
            "        )",
            "        loader.add_option(",
            "            \"keep_host_header\", bool, False,",
            "            \"\"\"",
            "            Reverse Proxy: Keep the original host header instead of rewriting it",
            "            to the reverse proxy target.",
            "            \"\"\"",
            "        )",
            "        loader.add_option(",
            "            \"proxy_debug\", bool, False,",
            "            \"Enable debug logs in the proxy core.\",",
            "        )",
            "        loader.add_option(",
            "            \"normalize_outbound_headers\", bool, True,",
            "            \"\"\"",
            "            Normalize outgoing HTTP/2 header names, but emit a warning when doing so.",
            "            HTTP/2 does not allow uppercase header names. This option makes sure that HTTP/2 headers set",
            "            in custom scripts are lowercased before they are sent.",
            "            \"\"\",",
            "        )",
            "",
            "    async def running(self):",
            "        self.master = ctx.master",
            "        self.options = ctx.options",
            "        self.is_running = True",
            "        await self.refresh_server()",
            "",
            "    def configure(self, updated):",
            "        if \"stream_large_bodies\" in updated:",
            "            try:",
            "                human.parse_size(ctx.options.stream_large_bodies)",
            "            except ValueError:",
            "                raise exceptions.OptionsError(f\"Invalid stream_large_bodies specification: \"",
            "                                              f\"{ctx.options.stream_large_bodies}\")",
            "        if \"body_size_limit\" in updated:",
            "            try:",
            "                human.parse_size(ctx.options.body_size_limit)",
            "            except ValueError:",
            "                raise exceptions.OptionsError(f\"Invalid body_size_limit specification: \"",
            "                                              f\"{ctx.options.body_size_limit}\")",
            "        if \"mode\" in updated and ctx.options.mode == \"transparent\":  # pragma: no cover",
            "            platform.init_transparent_mode()",
            "        if self.is_running and any(x in updated for x in [\"server\", \"listen_host\", \"listen_port\"]):",
            "            asyncio.create_task(self.refresh_server())",
            "",
            "    async def refresh_server(self):",
            "        async with self._lock:",
            "            if self.server:",
            "                await self.shutdown_server()",
            "                self.server = None",
            "            if ctx.options.server:",
            "                if not ctx.master.addons.get(\"nextlayer\"):",
            "                    ctx.log.warn(\"Warning: Running proxyserver without nextlayer addon!\")",
            "                try:",
            "                    self.server = await asyncio.start_server(",
            "                        self.handle_connection,",
            "                        self.options.listen_host,",
            "                        self.options.listen_port,",
            "                    )",
            "                except OSError as e:",
            "                    ctx.log.error(str(e))",
            "                    return",
            "                # TODO: This is a bit confusing currently for `-p 0`.",
            "                addrs = {f\"http://{human.format_address(s.getsockname())}\" for s in self.server.sockets}",
            "                ctx.log.info(f\"Proxy server listening at {' and '.join(addrs)}\")",
            "",
            "    async def shutdown_server(self):",
            "        ctx.log.info(\"Stopping server...\")",
            "        self.server.close()",
            "        await self.server.wait_closed()",
            "        self.server = None",
            "",
            "    async def handle_connection(self, r, w):",
            "        peername = w.get_extra_info('peername')",
            "        asyncio_utils.set_task_debug_info(",
            "            asyncio.current_task(),",
            "            name=f\"Proxyserver.handle_connection\",",
            "            client=peername,",
            "        )",
            "        handler = ProxyConnectionHandler(",
            "            self.master,",
            "            r,",
            "            w,",
            "            self.options",
            "        )",
            "        self._connections[peername] = handler",
            "        try:",
            "            await handler.handle_client()",
            "        finally:",
            "            del self._connections[peername]",
            "",
            "    def inject_event(self, event: events.MessageInjected):",
            "        if event.flow.client_conn.peername not in self._connections:",
            "            raise ValueError(\"Flow is not from a live connection.\")",
            "        self._connections[event.flow.client_conn.peername].server_event(event)",
            "",
            "    @command.command(\"inject.websocket\")",
            "    def inject_websocket(self, flow: Flow, to_client: bool, message: bytes, is_text: bool = True):",
            "        if not isinstance(flow, http.HTTPFlow) or not flow.websocket:",
            "            ctx.log.warn(\"Cannot inject WebSocket messages into non-WebSocket flows.\")",
            "",
            "        msg = websocket.WebSocketMessage(",
            "            Opcode.TEXT if is_text else Opcode.BINARY,",
            "            not to_client,",
            "            message",
            "        )",
            "        event = WebSocketMessageInjected(flow, msg)",
            "        try:",
            "            self.inject_event(event)",
            "        except ValueError as e:",
            "            ctx.log.warn(str(e))",
            "",
            "    @command.command(\"inject.tcp\")",
            "    def inject_tcp(self, flow: Flow, to_client: bool, message: bytes):",
            "        if not isinstance(flow, tcp.TCPFlow):",
            "            ctx.log.warn(\"Cannot inject TCP messages into non-TCP flows.\")",
            "",
            "        event = TcpMessageInjected(flow, tcp.TCPMessage(not to_client, message))",
            "        try:",
            "            self.inject_event(event)",
            "        except ValueError as e:",
            "            ctx.log.warn(str(e))",
            "",
            "    def server_connect(self, ctx: server_hooks.ServerConnectionHookData):",
            "        assert ctx.server.address",
            "        self_connect = (",
            "            ctx.server.address[1] == self.options.listen_port",
            "            and",
            "            ctx.server.address[0] in (\"localhost\", \"127.0.0.1\", \"::1\", self.options.listen_host)",
            "        )",
            "        if self_connect:",
            "            ctx.server.error = (",
            "                \"Request destination unknown. \"",
            "                \"Unable to figure out where this request should be forwarded to.\"",
            "            )"
        ],
        "afterPatchFile": [
            "import asyncio",
            "from typing import Dict, Optional, Tuple",
            "",
            "from mitmproxy import command, ctx, exceptions, flow, http, log, master, options, platform, tcp, websocket",
            "from mitmproxy.flow import Flow",
            "from mitmproxy.proxy import commands, events, server_hooks",
            "from mitmproxy.proxy import server",
            "from mitmproxy.proxy.layers.tcp import TcpMessageInjected",
            "from mitmproxy.proxy.layers.websocket import WebSocketMessageInjected",
            "from mitmproxy.utils import asyncio_utils, human",
            "from wsproto.frame_protocol import Opcode",
            "",
            "",
            "class ProxyConnectionHandler(server.StreamConnectionHandler):",
            "    master: master.Master",
            "",
            "    def __init__(self, master, r, w, options):",
            "        self.master = master",
            "        super().__init__(r, w, options)",
            "        self.log_prefix = f\"{human.format_address(self.client.peername)}: \"",
            "",
            "    async def handle_hook(self, hook: commands.StartHook) -> None:",
            "        with self.timeout_watchdog.disarm():",
            "            # We currently only support single-argument hooks.",
            "            data, = hook.args()",
            "            await self.master.addons.handle_lifecycle(hook)",
            "            if isinstance(data, flow.Flow):",
            "                await data.wait_for_resume()",
            "",
            "    def log(self, message: str, level: str = \"info\") -> None:",
            "        x = log.LogEntry(self.log_prefix + message, level)",
            "        asyncio_utils.create_task(",
            "            self.master.addons.handle_lifecycle(log.AddLogHook(x)),",
            "            name=\"ProxyConnectionHandler.log\"",
            "        )",
            "",
            "",
            "class Proxyserver:",
            "    \"\"\"",
            "    This addon runs the actual proxy server.",
            "    \"\"\"",
            "    server: Optional[asyncio.AbstractServer]",
            "    listen_port: int",
            "    master: master.Master",
            "    options: options.Options",
            "    is_running: bool",
            "    _connections: Dict[Tuple, ProxyConnectionHandler]",
            "",
            "    def __init__(self):",
            "        self._lock = asyncio.Lock()",
            "        self.server = None",
            "        self.is_running = False",
            "        self._connections = {}",
            "",
            "    def __repr__(self):",
            "        return f\"ProxyServer({'running' if self.server else 'stopped'}, {len(self._connections)} active conns)\"",
            "",
            "    def load(self, loader):",
            "        loader.add_option(",
            "            \"connection_strategy\", str, \"eager\",",
            "            \"Determine when server connections should be established. When set to lazy, mitmproxy \"",
            "            \"tries to defer establishing an upstream connection as long as possible. This makes it possible to \"",
            "            \"use server replay while being offline. When set to eager, mitmproxy can detect protocols with \"",
            "            \"server-side greetings, as well as accurately mirror TLS ALPN negotiation.\",",
            "            choices=(\"eager\", \"lazy\")",
            "        )",
            "        loader.add_option(",
            "            \"stream_large_bodies\", Optional[str], None,",
            "            \"\"\"",
            "            Stream data to the client if response body exceeds the given",
            "            threshold. If streamed, the body will not be stored in any way.",
            "            Understands k/m/g suffixes, i.e. 3m for 3 megabytes.",
            "            \"\"\"",
            "        )",
            "        loader.add_option(",
            "            \"body_size_limit\", Optional[str], None,",
            "            \"\"\"",
            "            Byte size limit of HTTP request and response bodies. Understands",
            "            k/m/g suffixes, i.e. 3m for 3 megabytes.",
            "            \"\"\"",
            "        )",
            "        loader.add_option(",
            "            \"keep_host_header\", bool, False,",
            "            \"\"\"",
            "            Reverse Proxy: Keep the original host header instead of rewriting it",
            "            to the reverse proxy target.",
            "            \"\"\"",
            "        )",
            "        loader.add_option(",
            "            \"proxy_debug\", bool, False,",
            "            \"Enable debug logs in the proxy core.\",",
            "        )",
            "        loader.add_option(",
            "            \"normalize_outbound_headers\", bool, True,",
            "            \"\"\"",
            "            Normalize outgoing HTTP/2 header names, but emit a warning when doing so.",
            "            HTTP/2 does not allow uppercase header names. This option makes sure that HTTP/2 headers set",
            "            in custom scripts are lowercased before they are sent.",
            "            \"\"\",",
            "        )",
            "        loader.add_option(",
            "            \"validate_inbound_headers\", bool, True,",
            "            \"\"\"",
            "            Make sure that incoming HTTP requests are not malformed.",
            "            Disabling this option makes mitmproxy vulnerable to HTTP smuggling attacks.",
            "            \"\"\",",
            "        )",
            "",
            "    async def running(self):",
            "        self.master = ctx.master",
            "        self.options = ctx.options",
            "        self.is_running = True",
            "        await self.refresh_server()",
            "",
            "    def configure(self, updated):",
            "        if \"stream_large_bodies\" in updated:",
            "            try:",
            "                human.parse_size(ctx.options.stream_large_bodies)",
            "            except ValueError:",
            "                raise exceptions.OptionsError(f\"Invalid stream_large_bodies specification: \"",
            "                                              f\"{ctx.options.stream_large_bodies}\")",
            "        if \"body_size_limit\" in updated:",
            "            try:",
            "                human.parse_size(ctx.options.body_size_limit)",
            "            except ValueError:",
            "                raise exceptions.OptionsError(f\"Invalid body_size_limit specification: \"",
            "                                              f\"{ctx.options.body_size_limit}\")",
            "        if \"mode\" in updated and ctx.options.mode == \"transparent\":  # pragma: no cover",
            "            platform.init_transparent_mode()",
            "        if self.is_running and any(x in updated for x in [\"server\", \"listen_host\", \"listen_port\"]):",
            "            asyncio.create_task(self.refresh_server())",
            "",
            "    async def refresh_server(self):",
            "        async with self._lock:",
            "            if self.server:",
            "                await self.shutdown_server()",
            "                self.server = None",
            "            if ctx.options.server:",
            "                if not ctx.master.addons.get(\"nextlayer\"):",
            "                    ctx.log.warn(\"Warning: Running proxyserver without nextlayer addon!\")",
            "                try:",
            "                    self.server = await asyncio.start_server(",
            "                        self.handle_connection,",
            "                        self.options.listen_host,",
            "                        self.options.listen_port,",
            "                    )",
            "                except OSError as e:",
            "                    ctx.log.error(str(e))",
            "                    return",
            "                # TODO: This is a bit confusing currently for `-p 0`.",
            "                addrs = {f\"http://{human.format_address(s.getsockname())}\" for s in self.server.sockets}",
            "                ctx.log.info(f\"Proxy server listening at {' and '.join(addrs)}\")",
            "",
            "    async def shutdown_server(self):",
            "        ctx.log.info(\"Stopping server...\")",
            "        self.server.close()",
            "        await self.server.wait_closed()",
            "        self.server = None",
            "",
            "    async def handle_connection(self, r, w):",
            "        peername = w.get_extra_info('peername')",
            "        asyncio_utils.set_task_debug_info(",
            "            asyncio.current_task(),",
            "            name=f\"Proxyserver.handle_connection\",",
            "            client=peername,",
            "        )",
            "        handler = ProxyConnectionHandler(",
            "            self.master,",
            "            r,",
            "            w,",
            "            self.options",
            "        )",
            "        self._connections[peername] = handler",
            "        try:",
            "            await handler.handle_client()",
            "        finally:",
            "            del self._connections[peername]",
            "",
            "    def inject_event(self, event: events.MessageInjected):",
            "        if event.flow.client_conn.peername not in self._connections:",
            "            raise ValueError(\"Flow is not from a live connection.\")",
            "        self._connections[event.flow.client_conn.peername].server_event(event)",
            "",
            "    @command.command(\"inject.websocket\")",
            "    def inject_websocket(self, flow: Flow, to_client: bool, message: bytes, is_text: bool = True):",
            "        if not isinstance(flow, http.HTTPFlow) or not flow.websocket:",
            "            ctx.log.warn(\"Cannot inject WebSocket messages into non-WebSocket flows.\")",
            "",
            "        msg = websocket.WebSocketMessage(",
            "            Opcode.TEXT if is_text else Opcode.BINARY,",
            "            not to_client,",
            "            message",
            "        )",
            "        event = WebSocketMessageInjected(flow, msg)",
            "        try:",
            "            self.inject_event(event)",
            "        except ValueError as e:",
            "            ctx.log.warn(str(e))",
            "",
            "    @command.command(\"inject.tcp\")",
            "    def inject_tcp(self, flow: Flow, to_client: bool, message: bytes):",
            "        if not isinstance(flow, tcp.TCPFlow):",
            "            ctx.log.warn(\"Cannot inject TCP messages into non-TCP flows.\")",
            "",
            "        event = TcpMessageInjected(flow, tcp.TCPMessage(not to_client, message))",
            "        try:",
            "            self.inject_event(event)",
            "        except ValueError as e:",
            "            ctx.log.warn(str(e))",
            "",
            "    def server_connect(self, ctx: server_hooks.ServerConnectionHookData):",
            "        assert ctx.server.address",
            "        self_connect = (",
            "            ctx.server.address[1] == self.options.listen_port",
            "            and",
            "            ctx.server.address[0] in (\"localhost\", \"127.0.0.1\", \"::1\", self.options.listen_host)",
            "        )",
            "        if self_connect:",
            "            ctx.server.error = (",
            "                \"Request destination unknown. \"",
            "                \"Unable to figure out where this request should be forwarded to.\"",
            "            )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "litellm.utils.token_counter"
        ]
    },
    "mitmproxy/net/http/http1/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": "     read_response_head,"
            },
            "1": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": "     connection_close,"
            },
            "2": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": "     expected_http_body_size,"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 6,
                "PatchRowcode": "+    validate_headers,"
            },
            "4": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " )"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from .assemble import ("
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": "     assemble_request, assemble_request_head,"
            },
            "7": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 17,
                "PatchRowcode": "     \"read_response_head\","
            },
            "8": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 18,
                "PatchRowcode": "     \"connection_close\","
            },
            "9": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": "     \"expected_http_body_size\","
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+    \"validate_headers\","
            },
            "11": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     \"assemble_request\", \"assemble_request_head\","
            },
            "12": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 22,
                "PatchRowcode": "     \"assemble_response\", \"assemble_response_head\","
            },
            "13": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 23,
                "PatchRowcode": "     \"assemble_body\","
            }
        },
        "frontPatchFile": [
            "from .read import (",
            "    read_request_head,",
            "    read_response_head,",
            "    connection_close,",
            "    expected_http_body_size,",
            ")",
            "from .assemble import (",
            "    assemble_request, assemble_request_head,",
            "    assemble_response, assemble_response_head,",
            "    assemble_body,",
            ")",
            "",
            "",
            "__all__ = [",
            "    \"read_request_head\",",
            "    \"read_response_head\",",
            "    \"connection_close\",",
            "    \"expected_http_body_size\",",
            "    \"assemble_request\", \"assemble_request_head\",",
            "    \"assemble_response\", \"assemble_response_head\",",
            "    \"assemble_body\",",
            "]"
        ],
        "afterPatchFile": [
            "from .read import (",
            "    read_request_head,",
            "    read_response_head,",
            "    connection_close,",
            "    expected_http_body_size,",
            "    validate_headers,",
            ")",
            "from .assemble import (",
            "    assemble_request, assemble_request_head,",
            "    assemble_response, assemble_response_head,",
            "    assemble_body,",
            ")",
            "",
            "",
            "__all__ = [",
            "    \"read_request_head\",",
            "    \"read_response_head\",",
            "    \"connection_close\",",
            "    \"expected_http_body_size\",",
            "    \"validate_headers\",",
            "    \"assemble_request\", \"assemble_request_head\",",
            "    \"assemble_response\", \"assemble_response_head\",",
            "    \"assemble_body\",",
            "]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": []
    },
    "mitmproxy/net/http/http1/read.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "     )"
            },
            "1": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+# https://datatracker.ietf.org/doc/html/rfc7230#section-3.2: Header fields are tokens."
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+# \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" /  \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / DIGIT / ALPHA"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+_valid_header_name = re.compile(rb\"^[!#$%&'*+\\-.^_`|~0-9a-zA-Z]+$\")"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+def validate_headers("
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+    headers: Headers"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+) -> None:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+    \"\"\""
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+    Validate headers to avoid request smuggling attacks. Raises a ValueError if they are malformed."
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+    \"\"\""
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+    te_found = False"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+    cl_found = False"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+    for (name, value) in headers.fields:"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+        if not _valid_header_name.match(name):"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+            raise ValueError(f\"Received an invalid header name: {name!r}. Invalid header names may introduce \""
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+                             f\"request smuggling vulnerabilities. Disable the validate_inbound_headers option \""
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+                             f\"to skip this security check.\")"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+        name_lower = name.lower()"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+        te_found = te_found or name_lower == b\"transfer-encoding\""
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+        cl_found = cl_found or name_lower == b\"content-length\""
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+    if te_found and cl_found:"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+        raise ValueError(\"Received both a Transfer-Encoding and a Content-Length header, \""
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+                         \"refusing as recommended in RFC 7230 Section 3.3.3. \""
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+                         \"See https://github.com/mitmproxy/mitmproxy/issues/4799 for details. \""
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+                         \"Disable the validate_inbound_headers option to skip this security check.\")"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 73,
                "PatchRowcode": " def expected_http_body_size("
            },
            "36": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 74,
                "PatchRowcode": "         request: Request,"
            },
            "37": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "         response: Optional[Response] = None"
            },
            "38": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "     #        a message downstream."
            },
            "39": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "     #"
            },
            "40": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "     if \"transfer-encoding\" in headers:"
            },
            "41": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if \"content-length\" in headers:"
            },
            "42": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise ValueError(\"Received both a Transfer-Encoding and a Content-Length header, \""
            },
            "43": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                             \"refusing as recommended in RFC 7230 Section 3.3.3. \""
            },
            "44": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                             \"See https://github.com/mitmproxy/mitmproxy/issues/4799 for details.\")"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+        # we should make sure that there isn't also a content-length header."
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+        # this is already handled in validate_headers."
            },
            "47": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 138,
                "PatchRowcode": " "
            },
            "48": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "         te: str = headers[\"transfer-encoding\"]"
            },
            "49": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "         if not te.isascii():"
            }
        },
        "frontPatchFile": [
            "import re",
            "import time",
            "from typing import List, Tuple, Iterable, Optional",
            "",
            "from mitmproxy.http import Request, Headers, Response",
            "from mitmproxy.net.http import url",
            "",
            "",
            "def get_header_tokens(headers, key):",
            "    \"\"\"",
            "        Retrieve all tokens for a header key. A number of different headers",
            "        follow a pattern where each header line can containe comma-separated",
            "        tokens, and headers can be set multiple times.",
            "    \"\"\"",
            "    if key not in headers:",
            "        return []",
            "    tokens = headers[key].split(\",\")",
            "    return [token.strip() for token in tokens]",
            "",
            "",
            "def connection_close(http_version, headers):",
            "    \"\"\"",
            "        Checks the message to see if the client connection should be closed",
            "        according to RFC 2616 Section 8.1.",
            "        If we don't have a Connection header, HTTP 1.1 connections are assumed",
            "        to be persistent.",
            "    \"\"\"",
            "    if \"connection\" in headers:",
            "        tokens = get_header_tokens(headers, \"connection\")",
            "        if \"close\" in tokens:",
            "            return True",
            "        elif \"keep-alive\" in tokens:",
            "            return False",
            "",
            "    return http_version not in (",
            "        \"HTTP/1.1\", b\"HTTP/1.1\",",
            "        \"HTTP/2.0\", b\"HTTP/2.0\",",
            "    )",
            "",
            "",
            "def expected_http_body_size(",
            "        request: Request,",
            "        response: Optional[Response] = None",
            ") -> Optional[int]:",
            "    \"\"\"",
            "        Returns:",
            "            The expected body length:",
            "            - a positive integer, if the size is known in advance",
            "            - None, if the size in unknown in advance (chunked encoding)",
            "            - -1, if all data should be read until end of stream.",
            "",
            "        Raises:",
            "            ValueError, if the content length header is invalid",
            "    \"\"\"",
            "    # Determine response size according to http://tools.ietf.org/html/rfc7230#section-3.3, which is inlined below.",
            "    if not response:",
            "        headers = request.headers",
            "    else:",
            "        headers = response.headers",
            "",
            "        #    1.  Any response to a HEAD request and any response with a 1xx",
            "        #        (Informational), 204 (No Content), or 304 (Not Modified) status",
            "        #        code is always terminated by the first empty line after the",
            "        #        header fields, regardless of the header fields present in the",
            "        #        message, and thus cannot contain a message body.",
            "        if request.method.upper() == \"HEAD\":",
            "            return 0",
            "        if 100 <= response.status_code <= 199:",
            "            return 0",
            "        if response.status_code in (204, 304):",
            "            return 0",
            "",
            "        #    2.  Any 2xx (Successful) response to a CONNECT request implies that",
            "        #        the connection will become a tunnel immediately after the empty",
            "        #        line that concludes the header fields.  A client MUST ignore any",
            "        #        Content-Length or Transfer-Encoding header fields received in",
            "        #        such a message.",
            "        if 200 <= response.status_code <= 299 and request.method.upper() == \"CONNECT\":",
            "            return 0",
            "",
            "    #    3.  If a Transfer-Encoding header field is present and the chunked",
            "    #        transfer coding (Section 4.1) is the final encoding, the message",
            "    #        body length is determined by reading and decoding the chunked",
            "    #        data until the transfer coding indicates the data is complete.",
            "    #",
            "    #        If a Transfer-Encoding header field is present in a response and",
            "    #        the chunked transfer coding is not the final encoding, the",
            "    #        message body length is determined by reading the connection until",
            "    #        it is closed by the server.  If a Transfer-Encoding header field",
            "    #        is present in a request and the chunked transfer coding is not",
            "    #        the final encoding, the message body length cannot be determined",
            "    #        reliably; the server MUST respond with the 400 (Bad Request)",
            "    #        status code and then close the connection.",
            "    #",
            "    #        If a message is received with both a Transfer-Encoding and a",
            "    #        Content-Length header field, the Transfer-Encoding overrides the",
            "    #        Content-Length.  Such a message might indicate an attempt to",
            "    #        perform request smuggling (Section 9.5) or response splitting",
            "    #        (Section 9.4) and ought to be handled as an error.  A sender MUST",
            "    #        remove the received Content-Length field prior to forwarding such",
            "    #        a message downstream.",
            "    #",
            "    if \"transfer-encoding\" in headers:",
            "        if \"content-length\" in headers:",
            "            raise ValueError(\"Received both a Transfer-Encoding and a Content-Length header, \"",
            "                             \"refusing as recommended in RFC 7230 Section 3.3.3. \"",
            "                             \"See https://github.com/mitmproxy/mitmproxy/issues/4799 for details.\")",
            "",
            "        te: str = headers[\"transfer-encoding\"]",
            "        if not te.isascii():",
            "            # guard against .lower() transforming non-ascii to ascii",
            "            raise ValueError(f\"Invalid transfer encoding: {te!r}\")",
            "        te = te.lower().strip(\"\\t \")",
            "        te = re.sub(r\"[\\t ]*,[\\t ]*\", \",\", te)",
            "        if te in (",
            "            \"chunked\",",
            "            \"compress,chunked\",",
            "            \"deflate,chunked\",",
            "            \"gzip,chunked\",",
            "        ):",
            "            return None",
            "        elif te in (",
            "            \"compress\",",
            "            \"deflate\",",
            "            \"gzip\",",
            "            \"identity\",",
            "        ):",
            "            if response:",
            "                return -1",
            "            else:",
            "                raise ValueError(f\"Invalid request transfer encoding, message body cannot be determined reliably.\")",
            "        else:",
            "            raise ValueError(f\"Unknown transfer encoding: {headers['transfer-encoding']!r}\")",
            "",
            "    #    4.  If a message is received without Transfer-Encoding and with",
            "    #        either multiple Content-Length header fields having differing",
            "    #        field-values or a single Content-Length header field having an",
            "    #        invalid value, then the message framing is invalid and the",
            "    #        recipient MUST treat it as an unrecoverable error.  If this is a",
            "    #        request message, the server MUST respond with a 400 (Bad Request)",
            "    #        status code and then close the connection.  If this is a response",
            "    #        message received by a proxy, the proxy MUST close the connection",
            "    #        to the server, discard the received response, and send a 502 (Bad",
            "    #        Gateway) response to the client.  If this is a response message",
            "    #        received by a user agent, the user agent MUST close the",
            "    #        connection to the server and discard the received response.",
            "    #",
            "    #    5.  If a valid Content-Length header field is present without",
            "    #        Transfer-Encoding, its decimal value defines the expected message",
            "    #        body length in octets.  If the sender closes the connection or",
            "    #        the recipient times out before the indicated number of octets are",
            "    #        received, the recipient MUST consider the message to be",
            "    #        incomplete and close the connection.",
            "    if \"content-length\" in headers:",
            "        sizes = headers.get_all(\"content-length\")",
            "        different_content_length_headers = any(x != sizes[0] for x in sizes)",
            "        if different_content_length_headers:",
            "            raise ValueError(f\"Conflicting Content-Length headers: {sizes!r}\")",
            "        try:",
            "            size = int(sizes[0])",
            "        except ValueError:",
            "            raise ValueError(f\"Invalid Content-Length header: {sizes[0]!r}\")",
            "        if size < 0:",
            "            raise ValueError(f\"Negative Content-Length header: {sizes[0]!r}\")",
            "        return size",
            "",
            "    #    6.  If this is a request message and none of the above are true, then",
            "    #        the message body length is zero (no message body is present).",
            "    if not response:",
            "        return 0",
            "",
            "    #    7.  Otherwise, this is a response message without a declared message",
            "    #        body length, so the message body length is determined by the",
            "    #        number of octets received prior to the server closing the",
            "    #        connection.",
            "    return -1",
            "",
            "",
            "def raise_if_http_version_unknown(http_version: bytes) -> None:",
            "    if not re.match(br\"^HTTP/\\d\\.\\d$\", http_version):",
            "        raise ValueError(f\"Unknown HTTP version: {http_version!r}\")",
            "",
            "",
            "def _read_request_line(line: bytes) -> Tuple[str, int, bytes, bytes, bytes, bytes, bytes]:",
            "    try:",
            "        method, target, http_version = line.split()",
            "        port: Optional[int]",
            "",
            "        if target == b\"*\" or target.startswith(b\"/\"):",
            "            scheme, authority, path = b\"\", b\"\", target",
            "            host, port = \"\", 0",
            "        elif method == b\"CONNECT\":",
            "            scheme, authority, path = b\"\", target, b\"\"",
            "            host, port = url.parse_authority(authority, check=True)",
            "            if not port:",
            "                raise ValueError",
            "        else:",
            "            scheme, rest = target.split(b\"://\", maxsplit=1)",
            "            authority, _, path_ = rest.partition(b\"/\")",
            "            path = b\"/\" + path_",
            "            host, port = url.parse_authority(authority, check=True)",
            "            port = port or url.default_port(scheme)",
            "            if not port:",
            "                raise ValueError",
            "            # TODO: we can probably get rid of this check?",
            "            url.parse(target)",
            "",
            "        raise_if_http_version_unknown(http_version)",
            "    except ValueError as e:",
            "        raise ValueError(f\"Bad HTTP request line: {line!r}\") from e",
            "",
            "    return host, port, method, scheme, authority, path, http_version",
            "",
            "",
            "def _read_response_line(line: bytes) -> Tuple[bytes, int, bytes]:",
            "    try:",
            "        parts = line.split(None, 2)",
            "        if len(parts) == 2:  # handle missing message gracefully",
            "            parts.append(b\"\")",
            "",
            "        http_version, status_code_str, reason = parts",
            "        status_code = int(status_code_str)",
            "        raise_if_http_version_unknown(http_version)",
            "    except ValueError as e:",
            "        raise ValueError(f\"Bad HTTP response line: {line!r}\") from e",
            "",
            "    return http_version, status_code, reason",
            "",
            "",
            "def _read_headers(lines: Iterable[bytes]) -> Headers:",
            "    \"\"\"",
            "        Read a set of headers.",
            "        Stop once a blank line is reached.",
            "",
            "        Returns:",
            "            A headers object",
            "",
            "        Raises:",
            "            exceptions.HttpSyntaxException",
            "    \"\"\"",
            "    ret: List[Tuple[bytes, bytes]] = []",
            "    for line in lines:",
            "        if line[0] in b\" \\t\":",
            "            if not ret:",
            "                raise ValueError(\"Invalid headers\")",
            "            # continued header",
            "            ret[-1] = (ret[-1][0], ret[-1][1] + b'\\r\\n ' + line.strip())",
            "        else:",
            "            try:",
            "                name, value = line.split(b\":\", 1)",
            "                value = value.strip()",
            "                if not name:",
            "                    raise ValueError()",
            "                ret.append((name, value))",
            "            except ValueError:",
            "                raise ValueError(f\"Invalid header line: {line!r}\")",
            "    return Headers(ret)",
            "",
            "",
            "def read_request_head(lines: List[bytes]) -> Request:",
            "    \"\"\"",
            "    Parse an HTTP request head (request line + headers) from an iterable of lines",
            "",
            "    Args:",
            "        lines: The input lines",
            "",
            "    Returns:",
            "        The HTTP request object (without body)",
            "",
            "    Raises:",
            "        ValueError: The input is malformed.",
            "    \"\"\"",
            "    host, port, method, scheme, authority, path, http_version = _read_request_line(lines[0])",
            "    headers = _read_headers(lines[1:])",
            "",
            "    return Request(",
            "        host=host,",
            "        port=port,",
            "        method=method,",
            "        scheme=scheme,",
            "        authority=authority,",
            "        path=path,",
            "        http_version=http_version,",
            "        headers=headers,",
            "        content=None,",
            "        trailers=None,",
            "        timestamp_start=time.time(),",
            "        timestamp_end=None",
            "    )",
            "",
            "",
            "def read_response_head(lines: List[bytes]) -> Response:",
            "    \"\"\"",
            "    Parse an HTTP response head (response line + headers) from an iterable of lines",
            "",
            "    Args:",
            "        lines: The input lines",
            "",
            "    Returns:",
            "        The HTTP response object (without body)",
            "",
            "    Raises:",
            "        ValueError: The input is malformed.",
            "    \"\"\"",
            "    http_version, status_code, reason = _read_response_line(lines[0])",
            "    headers = _read_headers(lines[1:])",
            "",
            "    return Response(",
            "        http_version=http_version,",
            "        status_code=status_code,",
            "        reason=reason,",
            "        headers=headers,",
            "        content=None,",
            "        trailers=None,",
            "        timestamp_start=time.time(),",
            "        timestamp_end=None,",
            "    )"
        ],
        "afterPatchFile": [
            "import re",
            "import time",
            "from typing import List, Tuple, Iterable, Optional",
            "",
            "from mitmproxy.http import Request, Headers, Response",
            "from mitmproxy.net.http import url",
            "",
            "",
            "def get_header_tokens(headers, key):",
            "    \"\"\"",
            "        Retrieve all tokens for a header key. A number of different headers",
            "        follow a pattern where each header line can containe comma-separated",
            "        tokens, and headers can be set multiple times.",
            "    \"\"\"",
            "    if key not in headers:",
            "        return []",
            "    tokens = headers[key].split(\",\")",
            "    return [token.strip() for token in tokens]",
            "",
            "",
            "def connection_close(http_version, headers):",
            "    \"\"\"",
            "        Checks the message to see if the client connection should be closed",
            "        according to RFC 2616 Section 8.1.",
            "        If we don't have a Connection header, HTTP 1.1 connections are assumed",
            "        to be persistent.",
            "    \"\"\"",
            "    if \"connection\" in headers:",
            "        tokens = get_header_tokens(headers, \"connection\")",
            "        if \"close\" in tokens:",
            "            return True",
            "        elif \"keep-alive\" in tokens:",
            "            return False",
            "",
            "    return http_version not in (",
            "        \"HTTP/1.1\", b\"HTTP/1.1\",",
            "        \"HTTP/2.0\", b\"HTTP/2.0\",",
            "    )",
            "",
            "",
            "# https://datatracker.ietf.org/doc/html/rfc7230#section-3.2: Header fields are tokens.",
            "# \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" /  \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / DIGIT / ALPHA",
            "_valid_header_name = re.compile(rb\"^[!#$%&'*+\\-.^_`|~0-9a-zA-Z]+$\")",
            "",
            "",
            "def validate_headers(",
            "    headers: Headers",
            ") -> None:",
            "    \"\"\"",
            "    Validate headers to avoid request smuggling attacks. Raises a ValueError if they are malformed.",
            "    \"\"\"",
            "",
            "    te_found = False",
            "    cl_found = False",
            "",
            "    for (name, value) in headers.fields:",
            "        if not _valid_header_name.match(name):",
            "            raise ValueError(f\"Received an invalid header name: {name!r}. Invalid header names may introduce \"",
            "                             f\"request smuggling vulnerabilities. Disable the validate_inbound_headers option \"",
            "                             f\"to skip this security check.\")",
            "",
            "        name_lower = name.lower()",
            "        te_found = te_found or name_lower == b\"transfer-encoding\"",
            "        cl_found = cl_found or name_lower == b\"content-length\"",
            "",
            "    if te_found and cl_found:",
            "        raise ValueError(\"Received both a Transfer-Encoding and a Content-Length header, \"",
            "                         \"refusing as recommended in RFC 7230 Section 3.3.3. \"",
            "                         \"See https://github.com/mitmproxy/mitmproxy/issues/4799 for details. \"",
            "                         \"Disable the validate_inbound_headers option to skip this security check.\")",
            "",
            "",
            "def expected_http_body_size(",
            "        request: Request,",
            "        response: Optional[Response] = None",
            ") -> Optional[int]:",
            "    \"\"\"",
            "        Returns:",
            "            The expected body length:",
            "            - a positive integer, if the size is known in advance",
            "            - None, if the size in unknown in advance (chunked encoding)",
            "            - -1, if all data should be read until end of stream.",
            "",
            "        Raises:",
            "            ValueError, if the content length header is invalid",
            "    \"\"\"",
            "    # Determine response size according to http://tools.ietf.org/html/rfc7230#section-3.3, which is inlined below.",
            "    if not response:",
            "        headers = request.headers",
            "    else:",
            "        headers = response.headers",
            "",
            "        #    1.  Any response to a HEAD request and any response with a 1xx",
            "        #        (Informational), 204 (No Content), or 304 (Not Modified) status",
            "        #        code is always terminated by the first empty line after the",
            "        #        header fields, regardless of the header fields present in the",
            "        #        message, and thus cannot contain a message body.",
            "        if request.method.upper() == \"HEAD\":",
            "            return 0",
            "        if 100 <= response.status_code <= 199:",
            "            return 0",
            "        if response.status_code in (204, 304):",
            "            return 0",
            "",
            "        #    2.  Any 2xx (Successful) response to a CONNECT request implies that",
            "        #        the connection will become a tunnel immediately after the empty",
            "        #        line that concludes the header fields.  A client MUST ignore any",
            "        #        Content-Length or Transfer-Encoding header fields received in",
            "        #        such a message.",
            "        if 200 <= response.status_code <= 299 and request.method.upper() == \"CONNECT\":",
            "            return 0",
            "",
            "    #    3.  If a Transfer-Encoding header field is present and the chunked",
            "    #        transfer coding (Section 4.1) is the final encoding, the message",
            "    #        body length is determined by reading and decoding the chunked",
            "    #        data until the transfer coding indicates the data is complete.",
            "    #",
            "    #        If a Transfer-Encoding header field is present in a response and",
            "    #        the chunked transfer coding is not the final encoding, the",
            "    #        message body length is determined by reading the connection until",
            "    #        it is closed by the server.  If a Transfer-Encoding header field",
            "    #        is present in a request and the chunked transfer coding is not",
            "    #        the final encoding, the message body length cannot be determined",
            "    #        reliably; the server MUST respond with the 400 (Bad Request)",
            "    #        status code and then close the connection.",
            "    #",
            "    #        If a message is received with both a Transfer-Encoding and a",
            "    #        Content-Length header field, the Transfer-Encoding overrides the",
            "    #        Content-Length.  Such a message might indicate an attempt to",
            "    #        perform request smuggling (Section 9.5) or response splitting",
            "    #        (Section 9.4) and ought to be handled as an error.  A sender MUST",
            "    #        remove the received Content-Length field prior to forwarding such",
            "    #        a message downstream.",
            "    #",
            "    if \"transfer-encoding\" in headers:",
            "        # we should make sure that there isn't also a content-length header.",
            "        # this is already handled in validate_headers.",
            "",
            "        te: str = headers[\"transfer-encoding\"]",
            "        if not te.isascii():",
            "            # guard against .lower() transforming non-ascii to ascii",
            "            raise ValueError(f\"Invalid transfer encoding: {te!r}\")",
            "        te = te.lower().strip(\"\\t \")",
            "        te = re.sub(r\"[\\t ]*,[\\t ]*\", \",\", te)",
            "        if te in (",
            "            \"chunked\",",
            "            \"compress,chunked\",",
            "            \"deflate,chunked\",",
            "            \"gzip,chunked\",",
            "        ):",
            "            return None",
            "        elif te in (",
            "            \"compress\",",
            "            \"deflate\",",
            "            \"gzip\",",
            "            \"identity\",",
            "        ):",
            "            if response:",
            "                return -1",
            "            else:",
            "                raise ValueError(f\"Invalid request transfer encoding, message body cannot be determined reliably.\")",
            "        else:",
            "            raise ValueError(f\"Unknown transfer encoding: {headers['transfer-encoding']!r}\")",
            "",
            "    #    4.  If a message is received without Transfer-Encoding and with",
            "    #        either multiple Content-Length header fields having differing",
            "    #        field-values or a single Content-Length header field having an",
            "    #        invalid value, then the message framing is invalid and the",
            "    #        recipient MUST treat it as an unrecoverable error.  If this is a",
            "    #        request message, the server MUST respond with a 400 (Bad Request)",
            "    #        status code and then close the connection.  If this is a response",
            "    #        message received by a proxy, the proxy MUST close the connection",
            "    #        to the server, discard the received response, and send a 502 (Bad",
            "    #        Gateway) response to the client.  If this is a response message",
            "    #        received by a user agent, the user agent MUST close the",
            "    #        connection to the server and discard the received response.",
            "    #",
            "    #    5.  If a valid Content-Length header field is present without",
            "    #        Transfer-Encoding, its decimal value defines the expected message",
            "    #        body length in octets.  If the sender closes the connection or",
            "    #        the recipient times out before the indicated number of octets are",
            "    #        received, the recipient MUST consider the message to be",
            "    #        incomplete and close the connection.",
            "    if \"content-length\" in headers:",
            "        sizes = headers.get_all(\"content-length\")",
            "        different_content_length_headers = any(x != sizes[0] for x in sizes)",
            "        if different_content_length_headers:",
            "            raise ValueError(f\"Conflicting Content-Length headers: {sizes!r}\")",
            "        try:",
            "            size = int(sizes[0])",
            "        except ValueError:",
            "            raise ValueError(f\"Invalid Content-Length header: {sizes[0]!r}\")",
            "        if size < 0:",
            "            raise ValueError(f\"Negative Content-Length header: {sizes[0]!r}\")",
            "        return size",
            "",
            "    #    6.  If this is a request message and none of the above are true, then",
            "    #        the message body length is zero (no message body is present).",
            "    if not response:",
            "        return 0",
            "",
            "    #    7.  Otherwise, this is a response message without a declared message",
            "    #        body length, so the message body length is determined by the",
            "    #        number of octets received prior to the server closing the",
            "    #        connection.",
            "    return -1",
            "",
            "",
            "def raise_if_http_version_unknown(http_version: bytes) -> None:",
            "    if not re.match(br\"^HTTP/\\d\\.\\d$\", http_version):",
            "        raise ValueError(f\"Unknown HTTP version: {http_version!r}\")",
            "",
            "",
            "def _read_request_line(line: bytes) -> Tuple[str, int, bytes, bytes, bytes, bytes, bytes]:",
            "    try:",
            "        method, target, http_version = line.split()",
            "        port: Optional[int]",
            "",
            "        if target == b\"*\" or target.startswith(b\"/\"):",
            "            scheme, authority, path = b\"\", b\"\", target",
            "            host, port = \"\", 0",
            "        elif method == b\"CONNECT\":",
            "            scheme, authority, path = b\"\", target, b\"\"",
            "            host, port = url.parse_authority(authority, check=True)",
            "            if not port:",
            "                raise ValueError",
            "        else:",
            "            scheme, rest = target.split(b\"://\", maxsplit=1)",
            "            authority, _, path_ = rest.partition(b\"/\")",
            "            path = b\"/\" + path_",
            "            host, port = url.parse_authority(authority, check=True)",
            "            port = port or url.default_port(scheme)",
            "            if not port:",
            "                raise ValueError",
            "            # TODO: we can probably get rid of this check?",
            "            url.parse(target)",
            "",
            "        raise_if_http_version_unknown(http_version)",
            "    except ValueError as e:",
            "        raise ValueError(f\"Bad HTTP request line: {line!r}\") from e",
            "",
            "    return host, port, method, scheme, authority, path, http_version",
            "",
            "",
            "def _read_response_line(line: bytes) -> Tuple[bytes, int, bytes]:",
            "    try:",
            "        parts = line.split(None, 2)",
            "        if len(parts) == 2:  # handle missing message gracefully",
            "            parts.append(b\"\")",
            "",
            "        http_version, status_code_str, reason = parts",
            "        status_code = int(status_code_str)",
            "        raise_if_http_version_unknown(http_version)",
            "    except ValueError as e:",
            "        raise ValueError(f\"Bad HTTP response line: {line!r}\") from e",
            "",
            "    return http_version, status_code, reason",
            "",
            "",
            "def _read_headers(lines: Iterable[bytes]) -> Headers:",
            "    \"\"\"",
            "        Read a set of headers.",
            "        Stop once a blank line is reached.",
            "",
            "        Returns:",
            "            A headers object",
            "",
            "        Raises:",
            "            exceptions.HttpSyntaxException",
            "    \"\"\"",
            "    ret: List[Tuple[bytes, bytes]] = []",
            "    for line in lines:",
            "        if line[0] in b\" \\t\":",
            "            if not ret:",
            "                raise ValueError(\"Invalid headers\")",
            "            # continued header",
            "            ret[-1] = (ret[-1][0], ret[-1][1] + b'\\r\\n ' + line.strip())",
            "        else:",
            "            try:",
            "                name, value = line.split(b\":\", 1)",
            "                value = value.strip()",
            "                if not name:",
            "                    raise ValueError()",
            "                ret.append((name, value))",
            "            except ValueError:",
            "                raise ValueError(f\"Invalid header line: {line!r}\")",
            "    return Headers(ret)",
            "",
            "",
            "def read_request_head(lines: List[bytes]) -> Request:",
            "    \"\"\"",
            "    Parse an HTTP request head (request line + headers) from an iterable of lines",
            "",
            "    Args:",
            "        lines: The input lines",
            "",
            "    Returns:",
            "        The HTTP request object (without body)",
            "",
            "    Raises:",
            "        ValueError: The input is malformed.",
            "    \"\"\"",
            "    host, port, method, scheme, authority, path, http_version = _read_request_line(lines[0])",
            "    headers = _read_headers(lines[1:])",
            "",
            "    return Request(",
            "        host=host,",
            "        port=port,",
            "        method=method,",
            "        scheme=scheme,",
            "        authority=authority,",
            "        path=path,",
            "        http_version=http_version,",
            "        headers=headers,",
            "        content=None,",
            "        trailers=None,",
            "        timestamp_start=time.time(),",
            "        timestamp_end=None",
            "    )",
            "",
            "",
            "def read_response_head(lines: List[bytes]) -> Response:",
            "    \"\"\"",
            "    Parse an HTTP response head (response line + headers) from an iterable of lines",
            "",
            "    Args:",
            "        lines: The input lines",
            "",
            "    Returns:",
            "        The HTTP response object (without body)",
            "",
            "    Raises:",
            "        ValueError: The input is malformed.",
            "    \"\"\"",
            "    http_version, status_code, reason = _read_response_line(lines[0])",
            "    headers = _read_headers(lines[1:])",
            "",
            "    return Response(",
            "        http_version=http_version,",
            "        status_code=status_code,",
            "        reason=reason,",
            "        headers=headers,",
            "        content=None,",
            "        trailers=None,",
            "        timestamp_start=time.time(),",
            "        timestamp_end=None,",
            "    )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "104": [
                "expected_http_body_size"
            ],
            "105": [
                "expected_http_body_size"
            ],
            "106": [
                "expected_http_body_size"
            ],
            "107": [
                "expected_http_body_size"
            ]
        },
        "addLocation": [
            "litellm.utils.token_counter"
        ]
    },
    "mitmproxy/proxy/layers/http/_http1.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 234,
                "PatchRowcode": "                 request_head = [bytes(x) for x in request_head]  # TODO: Make url.parse compatible with bytearrays"
            },
            "1": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 235,
                "PatchRowcode": "                 try:"
            },
            "2": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "                     self.request = http1.read_request_head(request_head)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+                    if self.context.options.validate_inbound_headers:"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 238,
                "PatchRowcode": "+                        http1.validate_headers(self.request.headers)"
            },
            "5": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 239,
                "PatchRowcode": "                     expected_body_size = http1.expected_http_body_size(self.request)"
            },
            "6": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 240,
                "PatchRowcode": "                 except ValueError as e:"
            },
            "7": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 241,
                "PatchRowcode": "                     yield commands.SendData(self.conn, make_error_response(400, str(e)))"
            },
            "8": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 332,
                "PatchRowcode": "                 response_head = [bytes(x) for x in response_head]  # TODO: Make url.parse compatible with bytearrays"
            },
            "9": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 333,
                "PatchRowcode": "                 try:"
            },
            "10": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 334,
                "PatchRowcode": "                     self.response = http1.read_response_head(response_head)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 335,
                "PatchRowcode": "+                    if self.context.options.validate_inbound_headers:"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 336,
                "PatchRowcode": "+                        http1.validate_headers(self.response.headers)"
            },
            "13": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 337,
                "PatchRowcode": "                     expected_size = http1.expected_http_body_size(self.request, self.response)"
            },
            "14": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 338,
                "PatchRowcode": "                 except ValueError as e:"
            },
            "15": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 339,
                "PatchRowcode": "                     yield commands.CloseConnection(self.conn)"
            }
        },
        "frontPatchFile": [
            "import abc",
            "from typing import Callable, Optional, Type, Union",
            "",
            "import h11",
            "from h11._readers import ChunkedReader, ContentLengthReader, Http10Reader",
            "from h11._receivebuffer import ReceiveBuffer",
            "",
            "from mitmproxy import http, version",
            "from mitmproxy.connection import Connection, ConnectionState",
            "from mitmproxy.net.http import http1, status_codes",
            "from mitmproxy.proxy import commands, events, layer",
            "from mitmproxy.proxy.layers.http._base import ReceiveHttp, StreamId",
            "from mitmproxy.proxy.utils import expect",
            "from mitmproxy.utils import human",
            "from ._base import HttpConnection, format_error",
            "from ._events import HttpEvent, RequestData, RequestEndOfMessage, RequestHeaders, RequestProtocolError, ResponseData, \\",
            "    ResponseEndOfMessage, ResponseHeaders, ResponseProtocolError",
            "from ...context import Context",
            "",
            "TBodyReader = Union[ChunkedReader, Http10Reader, ContentLengthReader]",
            "",
            "",
            "class Http1Connection(HttpConnection, metaclass=abc.ABCMeta):",
            "    stream_id: Optional[StreamId] = None",
            "    request: Optional[http.Request] = None",
            "    response: Optional[http.Response] = None",
            "    request_done: bool = False",
            "    response_done: bool = False",
            "    # this is a bit of a hack to make both mypy and PyCharm happy.",
            "    state: Union[Callable[[events.Event], layer.CommandGenerator[None]], Callable]",
            "    body_reader: TBodyReader",
            "    buf: ReceiveBuffer",
            "",
            "    ReceiveProtocolError: Type[Union[RequestProtocolError, ResponseProtocolError]]",
            "    ReceiveData: Type[Union[RequestData, ResponseData]]",
            "    ReceiveEndOfMessage: Type[Union[RequestEndOfMessage, ResponseEndOfMessage]]",
            "",
            "    def __init__(self, context: Context, conn: Connection):",
            "        super().__init__(context, conn)",
            "        self.buf = ReceiveBuffer()",
            "",
            "    @abc.abstractmethod",
            "    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:",
            "        yield from ()  # pragma: no cover",
            "",
            "    @abc.abstractmethod",
            "    def read_headers(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        yield from ()  # pragma: no cover",
            "",
            "    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, HttpEvent):",
            "            yield from self.send(event)",
            "        else:",
            "            if isinstance(event, events.DataReceived) and self.state != self.passthrough:",
            "                self.buf += event.data",
            "            yield from self.state(event)",
            "",
            "    @expect(events.Start)",
            "    def start(self, _) -> layer.CommandGenerator[None]:",
            "        self.state = self.read_headers",
            "        yield from ()",
            "",
            "    state = start",
            "",
            "    def read_body(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        assert self.stream_id",
            "        while True:",
            "            try:",
            "                if isinstance(event, events.DataReceived):",
            "                    h11_event = self.body_reader(self.buf)",
            "                elif isinstance(event, events.ConnectionClosed):",
            "                    h11_event = self.body_reader.read_eof()",
            "                else:",
            "                    raise AssertionError(f\"Unexpected event: {event}\")",
            "            except h11.ProtocolError as e:",
            "                yield commands.CloseConnection(self.conn)",
            "                yield ReceiveHttp(self.ReceiveProtocolError(self.stream_id, f\"HTTP/1 protocol error: {e}\"))",
            "                return",
            "",
            "            if h11_event is None:",
            "                return",
            "            elif isinstance(h11_event, h11.Data):",
            "                data: bytes = bytes(h11_event.data)",
            "                if data:",
            "                    yield ReceiveHttp(self.ReceiveData(self.stream_id, data))",
            "            elif isinstance(h11_event, h11.EndOfMessage):",
            "                assert self.request",
            "                if h11_event.headers:",
            "                    raise NotImplementedError(f\"HTTP trailers are not implemented yet.\")",
            "                if self.request.data.method.upper() != b\"CONNECT\":",
            "                    yield ReceiveHttp(self.ReceiveEndOfMessage(self.stream_id))",
            "                is_request = isinstance(self, Http1Server)",
            "                yield from self.mark_done(",
            "                    request=is_request,",
            "                    response=not is_request",
            "                )",
            "                return",
            "",
            "    def wait(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        \"\"\"",
            "        We wait for the current flow to be finished before parsing the next message,",
            "        as we may want to upgrade to WebSocket or plain TCP before that.",
            "        \"\"\"",
            "        assert self.stream_id",
            "        if isinstance(event, events.DataReceived):",
            "            return",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            # for practical purposes, we assume that a peer which sent at least a FIN",
            "            # is not interested in any more data from us, see",
            "            # see https://github.com/httpwg/http-core/issues/22",
            "            if event.connection.state is not ConnectionState.CLOSED:",
            "                yield commands.CloseConnection(event.connection)",
            "            yield ReceiveHttp(self.ReceiveProtocolError(self.stream_id, f\"Client disconnected.\",",
            "                                                        code=status_codes.CLIENT_CLOSED_REQUEST))",
            "        else:  # pragma: no cover",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def done(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        yield from ()  # pragma: no cover",
            "",
            "    def make_pipe(self) -> layer.CommandGenerator[None]:",
            "        self.state = self.passthrough",
            "        if self.buf:",
            "            already_received = self.buf.maybe_extract_at_most(len(self.buf))",
            "            # Some clients send superfluous newlines after CONNECT, we want to eat those.",
            "            already_received = already_received.lstrip(b\"\\r\\n\")",
            "            if already_received:",
            "                yield from self.state(events.DataReceived(self.conn, already_received))",
            "",
            "    def passthrough(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        assert self.stream_id",
            "        if isinstance(event, events.DataReceived):",
            "            yield ReceiveHttp(self.ReceiveData(self.stream_id, event.data))",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            if isinstance(self, Http1Server):",
            "                yield ReceiveHttp(RequestEndOfMessage(self.stream_id))",
            "            else:",
            "                yield ReceiveHttp(ResponseEndOfMessage(self.stream_id))",
            "",
            "    def mark_done(self, *, request: bool = False, response: bool = False) -> layer.CommandGenerator[None]:",
            "        if request:",
            "            self.request_done = True",
            "        if response:",
            "            self.response_done = True",
            "        if self.request_done and self.response_done:",
            "            assert self.request",
            "            assert self.response",
            "            if should_make_pipe(self.request, self.response):",
            "                yield from self.make_pipe()",
            "                return",
            "            try:",
            "                read_until_eof_semantics = http1.expected_http_body_size(self.request, self.response) == -1",
            "            except ValueError:",
            "                # this may raise only now (and not earlier) because an addon set invalid headers,",
            "                # in which case it's not really clear what we are supposed to do.",
            "                read_until_eof_semantics = False",
            "            connection_done = (",
            "                read_until_eof_semantics",
            "                or http1.connection_close(self.request.http_version, self.request.headers)",
            "                or http1.connection_close(self.response.http_version, self.response.headers)",
            "                # If we proxy HTTP/2 to HTTP/1, we only use upstream connections for one request.",
            "                # This simplifies our connection management quite a bit as we can rely on",
            "                # the proxyserver's max-connection-per-server throttling.",
            "                or (self.request.is_http2 and isinstance(self, Http1Client))",
            "            )",
            "            if connection_done:",
            "                yield commands.CloseConnection(self.conn)",
            "                self.state = self.done",
            "                return",
            "            self.request_done = self.response_done = False",
            "            self.request = self.response = None",
            "            if isinstance(self, Http1Server):",
            "                self.stream_id += 2",
            "            else:",
            "                self.stream_id = None",
            "            self.state = self.read_headers",
            "            if self.buf:",
            "                yield from self.state(events.DataReceived(self.conn, b\"\"))",
            "",
            "",
            "class Http1Server(Http1Connection):",
            "    \"\"\"A simple HTTP/1 server with no pipelining support.\"\"\"",
            "",
            "    ReceiveProtocolError = RequestProtocolError",
            "    ReceiveData = RequestData",
            "    ReceiveEndOfMessage = RequestEndOfMessage",
            "    stream_id: int",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.client)",
            "        self.stream_id = 1",
            "",
            "    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:",
            "        assert event.stream_id == self.stream_id",
            "        if isinstance(event, ResponseHeaders):",
            "            self.response = response = event.response",
            "",
            "            if response.is_http2:",
            "                response = response.copy()",
            "                # Convert to an HTTP/1 response.",
            "                response.http_version = \"HTTP/1.1\"",
            "                # not everyone supports empty reason phrases, so we better make up one.",
            "                response.reason = status_codes.RESPONSES.get(response.status_code, \"\")",
            "                # Shall we set a Content-Length header here if there is none?",
            "                # For now, let's try to modify as little as possible.",
            "",
            "            raw = http1.assemble_response_head(response)",
            "            yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, ResponseData):",
            "            assert self.response",
            "            if \"chunked\" in self.response.headers.get(\"transfer-encoding\", \"\").lower():",
            "                raw = b\"%x\\r\\n%s\\r\\n\" % (len(event.data), event.data)",
            "            else:",
            "                raw = event.data",
            "            if raw:",
            "                yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, ResponseEndOfMessage):",
            "            assert self.response",
            "            if \"chunked\" in self.response.headers.get(\"transfer-encoding\", \"\").lower():",
            "                yield commands.SendData(self.conn, b\"0\\r\\n\\r\\n\")",
            "            yield from self.mark_done(response=True)",
            "        elif isinstance(event, ResponseProtocolError):",
            "            if not self.response and event.code != status_codes.NO_RESPONSE:",
            "                yield commands.SendData(self.conn, make_error_response(event.code, event.message))",
            "            if self.conn.state & ConnectionState.CAN_WRITE:",
            "                yield commands.CloseConnection(self.conn)",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def read_headers(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, events.DataReceived):",
            "            request_head = self.buf.maybe_extract_lines()",
            "            if request_head:",
            "                request_head = [bytes(x) for x in request_head]  # TODO: Make url.parse compatible with bytearrays",
            "                try:",
            "                    self.request = http1.read_request_head(request_head)",
            "                    expected_body_size = http1.expected_http_body_size(self.request)",
            "                except ValueError as e:",
            "                    yield commands.SendData(self.conn, make_error_response(400, str(e)))",
            "                    yield commands.CloseConnection(self.conn)",
            "                    if self.request:",
            "                        # we have headers that we can show in the ui",
            "                        yield ReceiveHttp(RequestHeaders(self.stream_id, self.request, False))",
            "                        yield ReceiveHttp(RequestProtocolError(self.stream_id, str(e), 400))",
            "                    else:",
            "                        yield commands.Log(f\"{human.format_address(self.conn.peername)}: {e}\")",
            "                    self.state = self.done",
            "                    return",
            "                yield ReceiveHttp(RequestHeaders(self.stream_id, self.request, expected_body_size == 0))",
            "                self.body_reader = make_body_reader(expected_body_size)",
            "                self.state = self.read_body",
            "                yield from self.state(event)",
            "            else:",
            "                pass  # FIXME: protect against header size DoS",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            buf = bytes(self.buf)",
            "            if buf.strip():",
            "                yield commands.Log(f\"Client closed connection before completing request headers: {buf!r}\")",
            "            yield commands.CloseConnection(self.conn)",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def mark_done(self, *, request: bool = False, response: bool = False) -> layer.CommandGenerator[None]:",
            "        yield from super().mark_done(request=request, response=response)",
            "        if self.request_done and not self.response_done:",
            "            self.state = self.wait",
            "",
            "",
            "class Http1Client(Http1Connection):",
            "    \"\"\"A simple HTTP/1 client with no pipelining support.\"\"\"",
            "",
            "    ReceiveProtocolError = ResponseProtocolError",
            "    ReceiveData = ResponseData",
            "    ReceiveEndOfMessage = ResponseEndOfMessage",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.server)",
            "",
            "    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, RequestProtocolError):",
            "            yield commands.CloseConnection(self.conn)",
            "            return",
            "",
            "        if not self.stream_id:",
            "            assert isinstance(event, RequestHeaders)",
            "            self.stream_id = event.stream_id",
            "            self.request = event.request",
            "        assert self.stream_id == event.stream_id",
            "",
            "        if isinstance(event, RequestHeaders):",
            "            request = event.request",
            "            if request.is_http2:",
            "                # Convert to an HTTP/1 request.",
            "                request = request.copy()  # (we could probably be a bit more efficient here.)",
            "                request.http_version = \"HTTP/1.1\"",
            "                if \"Host\" not in request.headers and request.authority:",
            "                    request.headers.insert(0, \"Host\", request.authority)",
            "                request.authority = \"\"",
            "            raw = http1.assemble_request_head(request)",
            "            yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, RequestData):",
            "            assert self.request",
            "            if \"chunked\" in self.request.headers.get(\"transfer-encoding\", \"\").lower():",
            "                raw = b\"%x\\r\\n%s\\r\\n\" % (len(event.data), event.data)",
            "            else:",
            "                raw = event.data",
            "            if raw:",
            "                yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, RequestEndOfMessage):",
            "            assert self.request",
            "            if \"chunked\" in self.request.headers.get(\"transfer-encoding\", \"\").lower():",
            "                yield commands.SendData(self.conn, b\"0\\r\\n\\r\\n\")",
            "            elif http1.expected_http_body_size(self.request, self.response) == -1:",
            "                yield commands.CloseConnection(self.conn, half_close=True)",
            "            yield from self.mark_done(request=True)",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def read_headers(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, events.DataReceived):",
            "            if not self.request:",
            "                # we just received some data for an unknown request.",
            "                yield commands.Log(f\"Unexpected data from server: {bytes(self.buf)!r}\")",
            "                yield commands.CloseConnection(self.conn)",
            "                return",
            "            assert self.stream_id",
            "",
            "            response_head = self.buf.maybe_extract_lines()",
            "            if response_head:",
            "                response_head = [bytes(x) for x in response_head]  # TODO: Make url.parse compatible with bytearrays",
            "                try:",
            "                    self.response = http1.read_response_head(response_head)",
            "                    expected_size = http1.expected_http_body_size(self.request, self.response)",
            "                except ValueError as e:",
            "                    yield commands.CloseConnection(self.conn)",
            "                    yield ReceiveHttp(ResponseProtocolError(self.stream_id, f\"Cannot parse HTTP response: {e}\"))",
            "                    return",
            "                yield ReceiveHttp(ResponseHeaders(self.stream_id, self.response, expected_size == 0))",
            "                self.body_reader = make_body_reader(expected_size)",
            "",
            "                self.state = self.read_body",
            "                yield from self.state(event)",
            "            else:",
            "                pass  # FIXME: protect against header size DoS",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            if self.conn.state & ConnectionState.CAN_WRITE:",
            "                yield commands.CloseConnection(self.conn)",
            "            if self.stream_id:",
            "                if self.buf:",
            "                    yield ReceiveHttp(ResponseProtocolError(self.stream_id,",
            "                                                            f\"unexpected server response: {bytes(self.buf)!r}\"))",
            "                else:",
            "                    # The server has closed the connection to prevent us from continuing.",
            "                    # We need to signal that to the stream.",
            "                    # https://tools.ietf.org/html/rfc7231#section-6.5.11",
            "                    yield ReceiveHttp(ResponseProtocolError(self.stream_id, \"server closed connection\"))",
            "            else:",
            "                return",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "",
            "def should_make_pipe(request: http.Request, response: http.Response) -> bool:",
            "    if response.status_code == 101:",
            "        return True",
            "    elif response.status_code == 200 and request.method.upper() == \"CONNECT\":",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def make_body_reader(expected_size: Optional[int]) -> TBodyReader:",
            "    if expected_size is None:",
            "        return ChunkedReader()",
            "    elif expected_size == -1:",
            "        return Http10Reader()",
            "    else:",
            "        return ContentLengthReader(expected_size)",
            "",
            "",
            "def make_error_response(",
            "    status_code: int,",
            "    message: str = \"\",",
            ") -> bytes:",
            "    resp = http.Response.make(",
            "        status_code,",
            "        format_error(status_code, message),",
            "        http.Headers(",
            "            Server=version.MITMPROXY,",
            "            Connection=\"close\",",
            "            Content_Type=\"text/html\",",
            "        )",
            "    )",
            "    return http1.assemble_response(resp)",
            "",
            "",
            "__all__ = [",
            "    \"Http1Client\",",
            "    \"Http1Server\",",
            "]"
        ],
        "afterPatchFile": [
            "import abc",
            "from typing import Callable, Optional, Type, Union",
            "",
            "import h11",
            "from h11._readers import ChunkedReader, ContentLengthReader, Http10Reader",
            "from h11._receivebuffer import ReceiveBuffer",
            "",
            "from mitmproxy import http, version",
            "from mitmproxy.connection import Connection, ConnectionState",
            "from mitmproxy.net.http import http1, status_codes",
            "from mitmproxy.proxy import commands, events, layer",
            "from mitmproxy.proxy.layers.http._base import ReceiveHttp, StreamId",
            "from mitmproxy.proxy.utils import expect",
            "from mitmproxy.utils import human",
            "from ._base import HttpConnection, format_error",
            "from ._events import HttpEvent, RequestData, RequestEndOfMessage, RequestHeaders, RequestProtocolError, ResponseData, \\",
            "    ResponseEndOfMessage, ResponseHeaders, ResponseProtocolError",
            "from ...context import Context",
            "",
            "TBodyReader = Union[ChunkedReader, Http10Reader, ContentLengthReader]",
            "",
            "",
            "class Http1Connection(HttpConnection, metaclass=abc.ABCMeta):",
            "    stream_id: Optional[StreamId] = None",
            "    request: Optional[http.Request] = None",
            "    response: Optional[http.Response] = None",
            "    request_done: bool = False",
            "    response_done: bool = False",
            "    # this is a bit of a hack to make both mypy and PyCharm happy.",
            "    state: Union[Callable[[events.Event], layer.CommandGenerator[None]], Callable]",
            "    body_reader: TBodyReader",
            "    buf: ReceiveBuffer",
            "",
            "    ReceiveProtocolError: Type[Union[RequestProtocolError, ResponseProtocolError]]",
            "    ReceiveData: Type[Union[RequestData, ResponseData]]",
            "    ReceiveEndOfMessage: Type[Union[RequestEndOfMessage, ResponseEndOfMessage]]",
            "",
            "    def __init__(self, context: Context, conn: Connection):",
            "        super().__init__(context, conn)",
            "        self.buf = ReceiveBuffer()",
            "",
            "    @abc.abstractmethod",
            "    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:",
            "        yield from ()  # pragma: no cover",
            "",
            "    @abc.abstractmethod",
            "    def read_headers(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        yield from ()  # pragma: no cover",
            "",
            "    def _handle_event(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, HttpEvent):",
            "            yield from self.send(event)",
            "        else:",
            "            if isinstance(event, events.DataReceived) and self.state != self.passthrough:",
            "                self.buf += event.data",
            "            yield from self.state(event)",
            "",
            "    @expect(events.Start)",
            "    def start(self, _) -> layer.CommandGenerator[None]:",
            "        self.state = self.read_headers",
            "        yield from ()",
            "",
            "    state = start",
            "",
            "    def read_body(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        assert self.stream_id",
            "        while True:",
            "            try:",
            "                if isinstance(event, events.DataReceived):",
            "                    h11_event = self.body_reader(self.buf)",
            "                elif isinstance(event, events.ConnectionClosed):",
            "                    h11_event = self.body_reader.read_eof()",
            "                else:",
            "                    raise AssertionError(f\"Unexpected event: {event}\")",
            "            except h11.ProtocolError as e:",
            "                yield commands.CloseConnection(self.conn)",
            "                yield ReceiveHttp(self.ReceiveProtocolError(self.stream_id, f\"HTTP/1 protocol error: {e}\"))",
            "                return",
            "",
            "            if h11_event is None:",
            "                return",
            "            elif isinstance(h11_event, h11.Data):",
            "                data: bytes = bytes(h11_event.data)",
            "                if data:",
            "                    yield ReceiveHttp(self.ReceiveData(self.stream_id, data))",
            "            elif isinstance(h11_event, h11.EndOfMessage):",
            "                assert self.request",
            "                if h11_event.headers:",
            "                    raise NotImplementedError(f\"HTTP trailers are not implemented yet.\")",
            "                if self.request.data.method.upper() != b\"CONNECT\":",
            "                    yield ReceiveHttp(self.ReceiveEndOfMessage(self.stream_id))",
            "                is_request = isinstance(self, Http1Server)",
            "                yield from self.mark_done(",
            "                    request=is_request,",
            "                    response=not is_request",
            "                )",
            "                return",
            "",
            "    def wait(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        \"\"\"",
            "        We wait for the current flow to be finished before parsing the next message,",
            "        as we may want to upgrade to WebSocket or plain TCP before that.",
            "        \"\"\"",
            "        assert self.stream_id",
            "        if isinstance(event, events.DataReceived):",
            "            return",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            # for practical purposes, we assume that a peer which sent at least a FIN",
            "            # is not interested in any more data from us, see",
            "            # see https://github.com/httpwg/http-core/issues/22",
            "            if event.connection.state is not ConnectionState.CLOSED:",
            "                yield commands.CloseConnection(event.connection)",
            "            yield ReceiveHttp(self.ReceiveProtocolError(self.stream_id, f\"Client disconnected.\",",
            "                                                        code=status_codes.CLIENT_CLOSED_REQUEST))",
            "        else:  # pragma: no cover",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def done(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        yield from ()  # pragma: no cover",
            "",
            "    def make_pipe(self) -> layer.CommandGenerator[None]:",
            "        self.state = self.passthrough",
            "        if self.buf:",
            "            already_received = self.buf.maybe_extract_at_most(len(self.buf))",
            "            # Some clients send superfluous newlines after CONNECT, we want to eat those.",
            "            already_received = already_received.lstrip(b\"\\r\\n\")",
            "            if already_received:",
            "                yield from self.state(events.DataReceived(self.conn, already_received))",
            "",
            "    def passthrough(self, event: events.Event) -> layer.CommandGenerator[None]:",
            "        assert self.stream_id",
            "        if isinstance(event, events.DataReceived):",
            "            yield ReceiveHttp(self.ReceiveData(self.stream_id, event.data))",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            if isinstance(self, Http1Server):",
            "                yield ReceiveHttp(RequestEndOfMessage(self.stream_id))",
            "            else:",
            "                yield ReceiveHttp(ResponseEndOfMessage(self.stream_id))",
            "",
            "    def mark_done(self, *, request: bool = False, response: bool = False) -> layer.CommandGenerator[None]:",
            "        if request:",
            "            self.request_done = True",
            "        if response:",
            "            self.response_done = True",
            "        if self.request_done and self.response_done:",
            "            assert self.request",
            "            assert self.response",
            "            if should_make_pipe(self.request, self.response):",
            "                yield from self.make_pipe()",
            "                return",
            "            try:",
            "                read_until_eof_semantics = http1.expected_http_body_size(self.request, self.response) == -1",
            "            except ValueError:",
            "                # this may raise only now (and not earlier) because an addon set invalid headers,",
            "                # in which case it's not really clear what we are supposed to do.",
            "                read_until_eof_semantics = False",
            "            connection_done = (",
            "                read_until_eof_semantics",
            "                or http1.connection_close(self.request.http_version, self.request.headers)",
            "                or http1.connection_close(self.response.http_version, self.response.headers)",
            "                # If we proxy HTTP/2 to HTTP/1, we only use upstream connections for one request.",
            "                # This simplifies our connection management quite a bit as we can rely on",
            "                # the proxyserver's max-connection-per-server throttling.",
            "                or (self.request.is_http2 and isinstance(self, Http1Client))",
            "            )",
            "            if connection_done:",
            "                yield commands.CloseConnection(self.conn)",
            "                self.state = self.done",
            "                return",
            "            self.request_done = self.response_done = False",
            "            self.request = self.response = None",
            "            if isinstance(self, Http1Server):",
            "                self.stream_id += 2",
            "            else:",
            "                self.stream_id = None",
            "            self.state = self.read_headers",
            "            if self.buf:",
            "                yield from self.state(events.DataReceived(self.conn, b\"\"))",
            "",
            "",
            "class Http1Server(Http1Connection):",
            "    \"\"\"A simple HTTP/1 server with no pipelining support.\"\"\"",
            "",
            "    ReceiveProtocolError = RequestProtocolError",
            "    ReceiveData = RequestData",
            "    ReceiveEndOfMessage = RequestEndOfMessage",
            "    stream_id: int",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.client)",
            "        self.stream_id = 1",
            "",
            "    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:",
            "        assert event.stream_id == self.stream_id",
            "        if isinstance(event, ResponseHeaders):",
            "            self.response = response = event.response",
            "",
            "            if response.is_http2:",
            "                response = response.copy()",
            "                # Convert to an HTTP/1 response.",
            "                response.http_version = \"HTTP/1.1\"",
            "                # not everyone supports empty reason phrases, so we better make up one.",
            "                response.reason = status_codes.RESPONSES.get(response.status_code, \"\")",
            "                # Shall we set a Content-Length header here if there is none?",
            "                # For now, let's try to modify as little as possible.",
            "",
            "            raw = http1.assemble_response_head(response)",
            "            yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, ResponseData):",
            "            assert self.response",
            "            if \"chunked\" in self.response.headers.get(\"transfer-encoding\", \"\").lower():",
            "                raw = b\"%x\\r\\n%s\\r\\n\" % (len(event.data), event.data)",
            "            else:",
            "                raw = event.data",
            "            if raw:",
            "                yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, ResponseEndOfMessage):",
            "            assert self.response",
            "            if \"chunked\" in self.response.headers.get(\"transfer-encoding\", \"\").lower():",
            "                yield commands.SendData(self.conn, b\"0\\r\\n\\r\\n\")",
            "            yield from self.mark_done(response=True)",
            "        elif isinstance(event, ResponseProtocolError):",
            "            if not self.response and event.code != status_codes.NO_RESPONSE:",
            "                yield commands.SendData(self.conn, make_error_response(event.code, event.message))",
            "            if self.conn.state & ConnectionState.CAN_WRITE:",
            "                yield commands.CloseConnection(self.conn)",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def read_headers(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, events.DataReceived):",
            "            request_head = self.buf.maybe_extract_lines()",
            "            if request_head:",
            "                request_head = [bytes(x) for x in request_head]  # TODO: Make url.parse compatible with bytearrays",
            "                try:",
            "                    self.request = http1.read_request_head(request_head)",
            "                    if self.context.options.validate_inbound_headers:",
            "                        http1.validate_headers(self.request.headers)",
            "                    expected_body_size = http1.expected_http_body_size(self.request)",
            "                except ValueError as e:",
            "                    yield commands.SendData(self.conn, make_error_response(400, str(e)))",
            "                    yield commands.CloseConnection(self.conn)",
            "                    if self.request:",
            "                        # we have headers that we can show in the ui",
            "                        yield ReceiveHttp(RequestHeaders(self.stream_id, self.request, False))",
            "                        yield ReceiveHttp(RequestProtocolError(self.stream_id, str(e), 400))",
            "                    else:",
            "                        yield commands.Log(f\"{human.format_address(self.conn.peername)}: {e}\")",
            "                    self.state = self.done",
            "                    return",
            "                yield ReceiveHttp(RequestHeaders(self.stream_id, self.request, expected_body_size == 0))",
            "                self.body_reader = make_body_reader(expected_body_size)",
            "                self.state = self.read_body",
            "                yield from self.state(event)",
            "            else:",
            "                pass  # FIXME: protect against header size DoS",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            buf = bytes(self.buf)",
            "            if buf.strip():",
            "                yield commands.Log(f\"Client closed connection before completing request headers: {buf!r}\")",
            "            yield commands.CloseConnection(self.conn)",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def mark_done(self, *, request: bool = False, response: bool = False) -> layer.CommandGenerator[None]:",
            "        yield from super().mark_done(request=request, response=response)",
            "        if self.request_done and not self.response_done:",
            "            self.state = self.wait",
            "",
            "",
            "class Http1Client(Http1Connection):",
            "    \"\"\"A simple HTTP/1 client with no pipelining support.\"\"\"",
            "",
            "    ReceiveProtocolError = ResponseProtocolError",
            "    ReceiveData = ResponseData",
            "    ReceiveEndOfMessage = ResponseEndOfMessage",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.server)",
            "",
            "    def send(self, event: HttpEvent) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, RequestProtocolError):",
            "            yield commands.CloseConnection(self.conn)",
            "            return",
            "",
            "        if not self.stream_id:",
            "            assert isinstance(event, RequestHeaders)",
            "            self.stream_id = event.stream_id",
            "            self.request = event.request",
            "        assert self.stream_id == event.stream_id",
            "",
            "        if isinstance(event, RequestHeaders):",
            "            request = event.request",
            "            if request.is_http2:",
            "                # Convert to an HTTP/1 request.",
            "                request = request.copy()  # (we could probably be a bit more efficient here.)",
            "                request.http_version = \"HTTP/1.1\"",
            "                if \"Host\" not in request.headers and request.authority:",
            "                    request.headers.insert(0, \"Host\", request.authority)",
            "                request.authority = \"\"",
            "            raw = http1.assemble_request_head(request)",
            "            yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, RequestData):",
            "            assert self.request",
            "            if \"chunked\" in self.request.headers.get(\"transfer-encoding\", \"\").lower():",
            "                raw = b\"%x\\r\\n%s\\r\\n\" % (len(event.data), event.data)",
            "            else:",
            "                raw = event.data",
            "            if raw:",
            "                yield commands.SendData(self.conn, raw)",
            "        elif isinstance(event, RequestEndOfMessage):",
            "            assert self.request",
            "            if \"chunked\" in self.request.headers.get(\"transfer-encoding\", \"\").lower():",
            "                yield commands.SendData(self.conn, b\"0\\r\\n\\r\\n\")",
            "            elif http1.expected_http_body_size(self.request, self.response) == -1:",
            "                yield commands.CloseConnection(self.conn, half_close=True)",
            "            yield from self.mark_done(request=True)",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "    def read_headers(self, event: events.ConnectionEvent) -> layer.CommandGenerator[None]:",
            "        if isinstance(event, events.DataReceived):",
            "            if not self.request:",
            "                # we just received some data for an unknown request.",
            "                yield commands.Log(f\"Unexpected data from server: {bytes(self.buf)!r}\")",
            "                yield commands.CloseConnection(self.conn)",
            "                return",
            "            assert self.stream_id",
            "",
            "            response_head = self.buf.maybe_extract_lines()",
            "            if response_head:",
            "                response_head = [bytes(x) for x in response_head]  # TODO: Make url.parse compatible with bytearrays",
            "                try:",
            "                    self.response = http1.read_response_head(response_head)",
            "                    if self.context.options.validate_inbound_headers:",
            "                        http1.validate_headers(self.response.headers)",
            "                    expected_size = http1.expected_http_body_size(self.request, self.response)",
            "                except ValueError as e:",
            "                    yield commands.CloseConnection(self.conn)",
            "                    yield ReceiveHttp(ResponseProtocolError(self.stream_id, f\"Cannot parse HTTP response: {e}\"))",
            "                    return",
            "                yield ReceiveHttp(ResponseHeaders(self.stream_id, self.response, expected_size == 0))",
            "                self.body_reader = make_body_reader(expected_size)",
            "",
            "                self.state = self.read_body",
            "                yield from self.state(event)",
            "            else:",
            "                pass  # FIXME: protect against header size DoS",
            "        elif isinstance(event, events.ConnectionClosed):",
            "            if self.conn.state & ConnectionState.CAN_WRITE:",
            "                yield commands.CloseConnection(self.conn)",
            "            if self.stream_id:",
            "                if self.buf:",
            "                    yield ReceiveHttp(ResponseProtocolError(self.stream_id,",
            "                                                            f\"unexpected server response: {bytes(self.buf)!r}\"))",
            "                else:",
            "                    # The server has closed the connection to prevent us from continuing.",
            "                    # We need to signal that to the stream.",
            "                    # https://tools.ietf.org/html/rfc7231#section-6.5.11",
            "                    yield ReceiveHttp(ResponseProtocolError(self.stream_id, \"server closed connection\"))",
            "            else:",
            "                return",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event}\")",
            "",
            "",
            "def should_make_pipe(request: http.Request, response: http.Response) -> bool:",
            "    if response.status_code == 101:",
            "        return True",
            "    elif response.status_code == 200 and request.method.upper() == \"CONNECT\":",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def make_body_reader(expected_size: Optional[int]) -> TBodyReader:",
            "    if expected_size is None:",
            "        return ChunkedReader()",
            "    elif expected_size == -1:",
            "        return Http10Reader()",
            "    else:",
            "        return ContentLengthReader(expected_size)",
            "",
            "",
            "def make_error_response(",
            "    status_code: int,",
            "    message: str = \"\",",
            ") -> bytes:",
            "    resp = http.Response.make(",
            "        status_code,",
            "        format_error(status_code, message),",
            "        http.Headers(",
            "            Server=version.MITMPROXY,",
            "            Connection=\"close\",",
            "            Content_Type=\"text/html\",",
            "        )",
            "    )",
            "    return http1.assemble_response(resp)",
            "",
            "",
            "__all__ = [",
            "    \"Http1Client\",",
            "    \"Http1Server\",",
            "]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "litellm.utils.token_counter"
        ]
    },
    "mitmproxy/proxy/layers/http/_http2.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "     h2_conf_defaults = dict("
            },
            "1": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "         header_encoding=False,"
            },
            "2": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "         validate_outbound_headers=False,"
            },
            "3": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        validate_inbound_headers=True,"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+        # validate_inbound_headers is controlled by the validate_inbound_headers option."
            },
            "5": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "         normalize_inbound_headers=False,  # changing this to True is required to pass h2spec"
            },
            "6": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "         normalize_outbound_headers=False,"
            },
            "7": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "     )"
            },
            "8": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "         if self.debug:"
            },
            "9": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "             self.h2_conf.logger = H2ConnectionLogger(f\"{human.format_address(self.context.client.peername)}: \""
            },
            "10": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "                                                      f\"{self.__class__.__name__}\")"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+        self.h2_conf.validate_inbound_headers = self.context.options.validate_inbound_headers"
            },
            "12": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "         self.h2_conn = BufferedH2Connection(self.h2_conf)"
            },
            "13": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "         self.streams = {}"
            },
            "14": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 64,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "import collections",
            "import time",
            "from enum import Enum",
            "from typing import ClassVar, DefaultDict, Dict, List, Optional, Sequence, Tuple, Type, Union",
            "",
            "import h2.config",
            "import h2.connection",
            "import h2.errors",
            "import h2.events",
            "import h2.exceptions",
            "import h2.settings",
            "import h2.stream",
            "import h2.utilities",
            "",
            "from mitmproxy import http, version",
            "from mitmproxy.connection import Connection",
            "from mitmproxy.net.http import status_codes, url",
            "from mitmproxy.utils import human",
            "from . import RequestData, RequestEndOfMessage, RequestHeaders, RequestProtocolError, ResponseData, \\",
            "    ResponseEndOfMessage, ResponseHeaders, RequestTrailers, ResponseTrailers, ResponseProtocolError",
            "from ._base import HttpConnection, HttpEvent, ReceiveHttp, format_error",
            "from ._http_h2 import BufferedH2Connection, H2ConnectionLogger",
            "from ...commands import CloseConnection, Log, SendData",
            "from ...context import Context",
            "from ...events import ConnectionClosed, DataReceived, Event, Start",
            "from ...layer import CommandGenerator",
            "from ...utils import expect",
            "",
            "",
            "class StreamState(Enum):",
            "    EXPECTING_HEADERS = 1",
            "    HEADERS_RECEIVED = 2",
            "",
            "",
            "CATCH_HYPER_H2_ERRORS = (ValueError, IndexError)",
            "",
            "",
            "class Http2Connection(HttpConnection):",
            "    h2_conf: ClassVar[h2.config.H2Configuration]",
            "    h2_conf_defaults = dict(",
            "        header_encoding=False,",
            "        validate_outbound_headers=False,",
            "        validate_inbound_headers=True,",
            "        normalize_inbound_headers=False,  # changing this to True is required to pass h2spec",
            "        normalize_outbound_headers=False,",
            "    )",
            "    h2_conn: BufferedH2Connection",
            "    streams: Dict[int, StreamState]",
            "    \"\"\"keep track of all active stream ids to send protocol errors on teardown\"\"\"",
            "",
            "    ReceiveProtocolError: Type[Union[RequestProtocolError, ResponseProtocolError]]",
            "    ReceiveData: Type[Union[RequestData, ResponseData]]",
            "    ReceiveTrailers: Type[Union[RequestTrailers, ResponseTrailers]]",
            "    ReceiveEndOfMessage: Type[Union[RequestEndOfMessage, ResponseEndOfMessage]]",
            "",
            "    def __init__(self, context: Context, conn: Connection):",
            "        super().__init__(context, conn)",
            "        if self.debug:",
            "            self.h2_conf.logger = H2ConnectionLogger(f\"{human.format_address(self.context.client.peername)}: \"",
            "                                                     f\"{self.__class__.__name__}\")",
            "        self.h2_conn = BufferedH2Connection(self.h2_conf)",
            "        self.streams = {}",
            "",
            "    def is_closed(self, stream_id: int) -> bool:",
            "        \"\"\"Check if a non-idle stream is closed\"\"\"",
            "        stream = self.h2_conn.streams.get(stream_id, None)",
            "        if (",
            "            stream is not None",
            "            and",
            "            stream.state_machine.state is not h2.stream.StreamState.CLOSED",
            "            and",
            "            self.h2_conn.state_machine.state is not h2.connection.ConnectionState.CLOSED",
            "        ):",
            "            return False",
            "        else:",
            "            return True",
            "",
            "    def is_open_for_us(self, stream_id: int) -> bool:",
            "        \"\"\"Check if we can write to a non-idle stream.\"\"\"",
            "        stream = self.h2_conn.streams.get(stream_id, None)",
            "        if (",
            "            stream is not None",
            "            and",
            "            stream.state_machine.state is not h2.stream.StreamState.HALF_CLOSED_LOCAL",
            "            and",
            "            stream.state_machine.state is not h2.stream.StreamState.CLOSED",
            "            and",
            "            self.h2_conn.state_machine.state is not h2.connection.ConnectionState.CLOSED",
            "        ):",
            "            return True",
            "        else:",
            "            return False",
            "",
            "    def _handle_event(self, event: Event) -> CommandGenerator[None]:",
            "        if isinstance(event, Start):",
            "            self.h2_conn.initiate_connection()",
            "            yield SendData(self.conn, self.h2_conn.data_to_send())",
            "",
            "        elif isinstance(event, HttpEvent):",
            "            if isinstance(event, (RequestData, ResponseData)):",
            "                if self.is_open_for_us(event.stream_id):",
            "                    self.h2_conn.send_data(event.stream_id, event.data)",
            "            elif isinstance(event, (RequestTrailers, ResponseTrailers)):",
            "                if self.is_open_for_us(event.stream_id):",
            "                    trailers = [*event.trailers.fields]",
            "                    self.h2_conn.send_headers(event.stream_id, trailers, end_stream=True)",
            "            elif isinstance(event, (RequestEndOfMessage, ResponseEndOfMessage)):",
            "                if self.is_open_for_us(event.stream_id):",
            "                    self.h2_conn.end_stream(event.stream_id)",
            "            elif isinstance(event, (RequestProtocolError, ResponseProtocolError)):",
            "                if not self.is_closed(event.stream_id):",
            "                    code = {",
            "                        status_codes.CLIENT_CLOSED_REQUEST: h2.errors.ErrorCodes.CANCEL,",
            "                    }.get(event.code, h2.errors.ErrorCodes.INTERNAL_ERROR)",
            "                    stream: h2.stream.H2Stream = self.h2_conn.streams[event.stream_id]",
            "                    send_error_message = (",
            "                        isinstance(event, ResponseProtocolError)",
            "                        and self.is_open_for_us(event.stream_id)",
            "                        and not stream.state_machine.headers_sent",
            "                        and event.code != status_codes.NO_RESPONSE",
            "                    )",
            "                    if send_error_message:",
            "                        self.h2_conn.send_headers(event.stream_id, [",
            "                            (b\":status\", b\"%d\" % event.code),",
            "                            (b\"server\", version.MITMPROXY.encode()),",
            "                            (b\"content-type\", b\"text/html\"),",
            "                        ])",
            "                        self.h2_conn.send_data(",
            "                            event.stream_id,",
            "                            format_error(event.code, event.message),",
            "                            end_stream=True",
            "                        )",
            "                    else:",
            "                        self.h2_conn.reset_stream(event.stream_id, code)",
            "            else:",
            "                raise AssertionError(f\"Unexpected event: {event}\")",
            "            data_to_send = self.h2_conn.data_to_send()",
            "            if data_to_send:",
            "                yield SendData(self.conn, data_to_send)",
            "",
            "        elif isinstance(event, DataReceived):",
            "            try:",
            "                try:",
            "                    events = self.h2_conn.receive_data(event.data)",
            "                except CATCH_HYPER_H2_ERRORS as e:  # pragma: no cover",
            "                    # this should never raise a ValueError, but we triggered one while fuzzing:",
            "                    # https://github.com/python-hyper/hyper-h2/issues/1231",
            "                    # this stays here as defense-in-depth.",
            "                    raise h2.exceptions.ProtocolError(f\"uncaught hyper-h2 error: {e}\") from e",
            "            except h2.exceptions.ProtocolError as e:",
            "                events = [e]",
            "",
            "            for h2_event in events:",
            "                if self.debug:",
            "                    yield Log(f\"{self.debug}[h2] {h2_event}\", \"debug\")",
            "                if (yield from self.handle_h2_event(h2_event)):",
            "                    if self.debug:",
            "                        yield Log(f\"{self.debug}[h2] done\", \"debug\")",
            "                    return",
            "",
            "            data_to_send = self.h2_conn.data_to_send()",
            "            if data_to_send:",
            "                yield SendData(self.conn, data_to_send)",
            "",
            "        elif isinstance(event, ConnectionClosed):",
            "            yield from self.close_connection(\"peer closed connection\")",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event!r}\")",
            "",
            "    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:",
            "        \"\"\"returns true if further processing should be stopped.\"\"\"",
            "        if isinstance(event, h2.events.DataReceived):",
            "            state = self.streams.get(event.stream_id, None)",
            "            if state is StreamState.HEADERS_RECEIVED:",
            "                yield ReceiveHttp(self.ReceiveData(event.stream_id, event.data))",
            "            elif state is StreamState.EXPECTING_HEADERS:",
            "                yield from self.protocol_error(f\"Received HTTP/2 data frame, expected headers.\")",
            "                return True",
            "            self.h2_conn.acknowledge_received_data(event.flow_controlled_length, event.stream_id)",
            "        elif isinstance(event, h2.events.TrailersReceived):",
            "            trailers = http.Headers(event.headers)",
            "            yield ReceiveHttp(self.ReceiveTrailers(event.stream_id, trailers))",
            "        elif isinstance(event, h2.events.StreamEnded):",
            "            state = self.streams.get(event.stream_id, None)",
            "            if state is StreamState.HEADERS_RECEIVED:",
            "                yield ReceiveHttp(self.ReceiveEndOfMessage(event.stream_id))",
            "            elif state is StreamState.EXPECTING_HEADERS:",
            "                raise AssertionError(\"unreachable\")",
            "            if self.is_closed(event.stream_id):",
            "                self.streams.pop(event.stream_id, None)",
            "        elif isinstance(event, h2.events.StreamReset):",
            "            if event.stream_id in self.streams:",
            "                try:",
            "                    err_str = h2.errors.ErrorCodes(event.error_code).name",
            "                except ValueError:",
            "                    err_str = str(event.error_code)",
            "                err_code = {",
            "                    h2.errors.ErrorCodes.CANCEL: status_codes.CLIENT_CLOSED_REQUEST,",
            "                }.get(event.error_code, self.ReceiveProtocolError.code)",
            "                yield ReceiveHttp(self.ReceiveProtocolError(event.stream_id, f\"stream reset by client ({err_str})\",",
            "                                                            code=err_code))",
            "                self.streams.pop(event.stream_id)",
            "            else:",
            "                pass  # We don't track priority frames which could be followed by a stream reset here.",
            "        elif isinstance(event, h2.exceptions.ProtocolError):",
            "            yield from self.protocol_error(f\"HTTP/2 protocol error: {event}\")",
            "            return True",
            "        elif isinstance(event, h2.events.ConnectionTerminated):",
            "            yield from self.close_connection(f\"HTTP/2 connection closed: {event!r}\")",
            "            return True",
            "            # The implementation above isn't really ideal, we should probably only terminate streams > last_stream_id?",
            "            # We currently lack a mechanism to signal that connections are still active but cannot be reused.",
            "            # for stream_id in self.streams:",
            "            #    if stream_id > event.last_stream_id:",
            "            #        yield ReceiveHttp(self.ReceiveProtocolError(stream_id, f\"HTTP/2 connection closed: {event!r}\"))",
            "            #        self.streams.pop(stream_id)",
            "        elif isinstance(event, h2.events.RemoteSettingsChanged):",
            "            pass",
            "        elif isinstance(event, h2.events.SettingsAcknowledged):",
            "            pass",
            "        elif isinstance(event, h2.events.PriorityUpdated):",
            "            pass",
            "        elif isinstance(event, h2.events.PingReceived):",
            "            pass",
            "        elif isinstance(event, h2.events.PingAckReceived):",
            "            pass",
            "        elif isinstance(event, h2.events.PushedStreamReceived):",
            "            yield Log(\"Received HTTP/2 push promise, even though we signalled no support.\", \"error\")",
            "        elif isinstance(event, h2.events.UnknownFrameReceived):",
            "            # https://http2.github.io/http2-spec/#rfc.section.4.1",
            "            # Implementations MUST ignore and discard any frame that has a type that is unknown.",
            "            yield Log(f\"Ignoring unknown HTTP/2 frame type: {event.frame.type}\")",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event!r}\")",
            "        return False",
            "",
            "    def protocol_error(",
            "        self,",
            "        message: str,",
            "        error_code: int = h2.errors.ErrorCodes.PROTOCOL_ERROR,",
            "    ) -> CommandGenerator[None]:",
            "        yield Log(f\"{human.format_address(self.conn.peername)}: {message}\")",
            "        self.h2_conn.close_connection(error_code, message.encode())",
            "        yield SendData(self.conn, self.h2_conn.data_to_send())",
            "        yield from self.close_connection(message)",
            "",
            "    def close_connection(self, msg: str) -> CommandGenerator[None]:",
            "        yield CloseConnection(self.conn)",
            "        for stream_id in self.streams:",
            "            yield ReceiveHttp(self.ReceiveProtocolError(stream_id, msg))",
            "        self.streams.clear()",
            "        self._handle_event = self.done  # type: ignore",
            "",
            "    @expect(DataReceived, HttpEvent, ConnectionClosed)",
            "    def done(self, _) -> CommandGenerator[None]:",
            "        yield from ()",
            "",
            "",
            "def normalize_h1_headers(headers: List[Tuple[bytes, bytes]], is_client: bool) -> List[Tuple[bytes, bytes]]:",
            "    # HTTP/1 servers commonly send capitalized headers (Content-Length vs content-length),",
            "    # which isn't valid HTTP/2. As such we normalize.",
            "    headers = h2.utilities.normalize_outbound_headers(",
            "        headers,",
            "        h2.utilities.HeaderValidationFlags(is_client, False, not is_client, False)",
            "    )",
            "    # make sure that this is not just an iterator but an iterable,",
            "    # otherwise hyper-h2 will silently drop headers.",
            "    headers = list(headers)",
            "    return headers",
            "",
            "",
            "def normalize_h2_headers(headers: List[Tuple[bytes, bytes]]) -> CommandGenerator[None]:",
            "    for i in range(len(headers)):",
            "        if not headers[i][0].islower():",
            "            yield Log(f\"Lowercased {repr(headers[i][0]).lstrip('b')} header as uppercase is not allowed with HTTP/2.\")",
            "            headers[i] = (headers[i][0].lower(), headers[i][1])",
            "",
            "",
            "class Http2Server(Http2Connection):",
            "    h2_conf = h2.config.H2Configuration(",
            "        **Http2Connection.h2_conf_defaults,",
            "        client_side=False,",
            "    )",
            "",
            "    ReceiveProtocolError = RequestProtocolError",
            "    ReceiveData = RequestData",
            "    ReceiveTrailers = RequestTrailers",
            "    ReceiveEndOfMessage = RequestEndOfMessage",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.client)",
            "",
            "    def _handle_event(self, event: Event) -> CommandGenerator[None]:",
            "        if isinstance(event, ResponseHeaders):",
            "            if self.is_open_for_us(event.stream_id):",
            "                headers = [",
            "                    (b\":status\", b\"%d\" % event.response.status_code),",
            "                    *event.response.headers.fields",
            "                ]",
            "                if event.response.is_http2:",
            "                    if self.context.options.normalize_outbound_headers:",
            "                        yield from normalize_h2_headers(headers)",
            "                else:",
            "                    headers = normalize_h1_headers(headers, False)",
            "",
            "                self.h2_conn.send_headers(",
            "                    event.stream_id,",
            "                    headers,",
            "                    end_stream=event.end_stream,",
            "                )",
            "                yield SendData(self.conn, self.h2_conn.data_to_send())",
            "        else:",
            "            yield from super()._handle_event(event)",
            "",
            "    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:",
            "        if isinstance(event, h2.events.RequestReceived):",
            "            try:",
            "                host, port, method, scheme, authority, path, headers = parse_h2_request_headers(event.headers)",
            "            except ValueError as e:",
            "                yield from self.protocol_error(f\"Invalid HTTP/2 request headers: {e}\")",
            "                return True",
            "            request = http.Request(",
            "                host=host,",
            "                port=port,",
            "                method=method,",
            "                scheme=scheme,",
            "                authority=authority,",
            "                path=path,",
            "                http_version=b\"HTTP/2.0\",",
            "                headers=headers,",
            "                content=None,",
            "                trailers=None,",
            "                timestamp_start=time.time(),",
            "                timestamp_end=None,",
            "            )",
            "            self.streams[event.stream_id] = StreamState.HEADERS_RECEIVED",
            "            yield ReceiveHttp(RequestHeaders(event.stream_id, request, end_stream=bool(event.stream_ended)))",
            "            return False",
            "        else:",
            "            return (yield from super().handle_h2_event(event))",
            "",
            "",
            "class Http2Client(Http2Connection):",
            "    h2_conf = h2.config.H2Configuration(",
            "        **Http2Connection.h2_conf_defaults,",
            "        client_side=True,",
            "    )",
            "",
            "    ReceiveProtocolError = ResponseProtocolError",
            "    ReceiveData = ResponseData",
            "    ReceiveTrailers = ResponseTrailers",
            "    ReceiveEndOfMessage = ResponseEndOfMessage",
            "",
            "    our_stream_id: Dict[int, int]",
            "    their_stream_id: Dict[int, int]",
            "    stream_queue: DefaultDict[int, List[Event]]",
            "    \"\"\"Queue of streams that we haven't sent yet because we have reached MAX_CONCURRENT_STREAMS\"\"\"",
            "    provisional_max_concurrency: Optional[int] = 10",
            "    \"\"\"A provisional currency limit before we get the server's first settings frame.\"\"\"",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.server)",
            "        # Disable HTTP/2 push for now to keep things simple.",
            "        # don't send here, that is done as part of initiate_connection().",
            "        self.h2_conn.local_settings.enable_push = 0",
            "        # hyper-h2 pitfall: we need to acknowledge here, otherwise its sends out the old settings.",
            "        self.h2_conn.local_settings.acknowledge()",
            "        self.our_stream_id = {}",
            "        self.their_stream_id = {}",
            "        self.stream_queue = collections.defaultdict(list)",
            "",
            "    def _handle_event(self, event: Event) -> CommandGenerator[None]:",
            "        # We can't reuse stream ids from the client because they may arrived reordered here",
            "        # and HTTP/2 forbids opening a stream on a lower id than what was previously sent (see test_stream_concurrency).",
            "        # To mitigate this, we transparently map the outside's stream id to our stream id.",
            "        if isinstance(event, HttpEvent):",
            "            ours = self.our_stream_id.get(event.stream_id, None)",
            "            if ours is None:",
            "                no_free_streams = (",
            "                    self.h2_conn.open_outbound_streams >=",
            "                    (self.provisional_max_concurrency or self.h2_conn.remote_settings.max_concurrent_streams)",
            "                )",
            "                if no_free_streams:",
            "                    self.stream_queue[event.stream_id].append(event)",
            "                    return",
            "                ours = self.h2_conn.get_next_available_stream_id()",
            "                self.our_stream_id[event.stream_id] = ours",
            "                self.their_stream_id[ours] = event.stream_id",
            "            event.stream_id = ours",
            "",
            "        for cmd in self._handle_event2(event):",
            "            if isinstance(cmd, ReceiveHttp):",
            "                cmd.event.stream_id = self.their_stream_id[cmd.event.stream_id]",
            "            yield cmd",
            "",
            "        can_resume_queue = (",
            "            self.stream_queue and",
            "            self.h2_conn.open_outbound_streams < (",
            "                self.provisional_max_concurrency or self.h2_conn.remote_settings.max_concurrent_streams",
            "            )",
            "        )",
            "        if can_resume_queue:",
            "            # popitem would be LIFO, but we want FIFO.",
            "            events = self.stream_queue.pop(next(iter(self.stream_queue)))",
            "            for event in events:",
            "                yield from self._handle_event(event)",
            "",
            "    def _handle_event2(self, event: Event) -> CommandGenerator[None]:",
            "        if isinstance(event, RequestHeaders):",
            "            pseudo_headers = [",
            "                (b':method', event.request.data.method),",
            "                (b':scheme', event.request.data.scheme),",
            "                (b':path', event.request.data.path),",
            "            ]",
            "            if event.request.authority:",
            "                pseudo_headers.append((b\":authority\", event.request.data.authority))",
            "",
            "            if event.request.is_http2:",
            "                hdrs = list(event.request.headers.fields)",
            "                if self.context.options.normalize_outbound_headers:",
            "                    yield from normalize_h2_headers(hdrs)",
            "            else:",
            "                headers = event.request.headers",
            "                if not event.request.authority and \"host\" in headers:",
            "                    headers = headers.copy()",
            "                    pseudo_headers.append((b\":authority\", headers.pop(b\"host\")))",
            "                hdrs = normalize_h1_headers(list(headers.fields), True)",
            "",
            "            self.h2_conn.send_headers(",
            "                event.stream_id,",
            "                pseudo_headers + hdrs,",
            "                end_stream=event.end_stream,",
            "            )",
            "            self.streams[event.stream_id] = StreamState.EXPECTING_HEADERS",
            "            yield SendData(self.conn, self.h2_conn.data_to_send())",
            "        else:",
            "            yield from super()._handle_event(event)",
            "",
            "    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:",
            "        if isinstance(event, h2.events.ResponseReceived):",
            "            if self.streams.get(event.stream_id, None) is not StreamState.EXPECTING_HEADERS:",
            "                yield from self.protocol_error(f\"Received unexpected HTTP/2 response.\")",
            "                return True",
            "",
            "            try:",
            "                status_code, headers = parse_h2_response_headers(event.headers)",
            "            except ValueError as e:",
            "                yield from self.protocol_error(f\"Invalid HTTP/2 response headers: {e}\")",
            "                return True",
            "",
            "            response = http.Response(",
            "                http_version=b\"HTTP/2.0\",",
            "                status_code=status_code,",
            "                reason=b\"\",",
            "                headers=headers,",
            "                content=None,",
            "                trailers=None,",
            "                timestamp_start=time.time(),",
            "                timestamp_end=None,",
            "            )",
            "            self.streams[event.stream_id] = StreamState.HEADERS_RECEIVED",
            "            yield ReceiveHttp(ResponseHeaders(event.stream_id, response, bool(event.stream_ended)))",
            "            return False",
            "        elif isinstance(event, h2.events.RequestReceived):",
            "            yield from self.protocol_error(f\"HTTP/2 protocol error: received request from server\")",
            "            return True",
            "        elif isinstance(event, h2.events.RemoteSettingsChanged):",
            "            # We have received at least one settings from now,",
            "            # which means we can rely on the max concurrency in remote_settings",
            "            self.provisional_max_concurrency = None",
            "            return (yield from super().handle_h2_event(event))",
            "        else:",
            "            return (yield from super().handle_h2_event(event))",
            "",
            "",
            "def split_pseudo_headers(h2_headers: Sequence[Tuple[bytes, bytes]]) -> Tuple[Dict[bytes, bytes], http.Headers]:",
            "    pseudo_headers: Dict[bytes, bytes] = {}",
            "    i = 0",
            "    for (header, value) in h2_headers:",
            "        if header.startswith(b\":\"):",
            "            if header in pseudo_headers:",
            "                raise ValueError(f\"Duplicate HTTP/2 pseudo header: {header!r}\")",
            "            pseudo_headers[header] = value",
            "            i += 1",
            "        else:",
            "            # Pseudo-headers must be at the start, we are done here.",
            "            break",
            "",
            "    headers = http.Headers(h2_headers[i:])",
            "",
            "    return pseudo_headers, headers",
            "",
            "",
            "def parse_h2_request_headers(",
            "    h2_headers: Sequence[Tuple[bytes, bytes]]",
            ") -> Tuple[str, int, bytes, bytes, bytes, bytes, http.Headers]:",
            "    \"\"\"Split HTTP/2 pseudo-headers from the actual headers and parse them.\"\"\"",
            "    pseudo_headers, headers = split_pseudo_headers(h2_headers)",
            "",
            "    try:",
            "        method: bytes = pseudo_headers.pop(b\":method\")",
            "        scheme: bytes = pseudo_headers.pop(b\":scheme\")  # this raises for HTTP/2 CONNECT requests",
            "        path: bytes = pseudo_headers.pop(b\":path\")",
            "        authority: bytes = pseudo_headers.pop(b\":authority\", b\"\")",
            "    except KeyError as e:",
            "        raise ValueError(f\"Required pseudo header is missing: {e}\")",
            "",
            "    if pseudo_headers:",
            "        raise ValueError(f\"Unknown pseudo headers: {pseudo_headers}\")",
            "",
            "    if authority:",
            "        host, port = url.parse_authority(authority, check=True)",
            "        if port is None:",
            "            port = 80 if scheme == b'http' else 443",
            "    else:",
            "        host = \"\"",
            "        port = 0",
            "",
            "    return host, port, method, scheme, authority, path, headers",
            "",
            "",
            "def parse_h2_response_headers(h2_headers: Sequence[Tuple[bytes, bytes]]) -> Tuple[int, http.Headers]:",
            "    \"\"\"Split HTTP/2 pseudo-headers from the actual headers and parse them.\"\"\"",
            "    pseudo_headers, headers = split_pseudo_headers(h2_headers)",
            "",
            "    try:",
            "        status_code: int = int(pseudo_headers.pop(b\":status\"))",
            "    except KeyError as e:",
            "        raise ValueError(f\"Required pseudo header is missing: {e}\")",
            "",
            "    if pseudo_headers:",
            "        raise ValueError(f\"Unknown pseudo headers: {pseudo_headers}\")",
            "",
            "    return status_code, headers",
            "",
            "",
            "__all__ = [",
            "    \"Http2Client\",",
            "    \"Http2Server\",",
            "]"
        ],
        "afterPatchFile": [
            "import collections",
            "import time",
            "from enum import Enum",
            "from typing import ClassVar, DefaultDict, Dict, List, Optional, Sequence, Tuple, Type, Union",
            "",
            "import h2.config",
            "import h2.connection",
            "import h2.errors",
            "import h2.events",
            "import h2.exceptions",
            "import h2.settings",
            "import h2.stream",
            "import h2.utilities",
            "",
            "from mitmproxy import http, version",
            "from mitmproxy.connection import Connection",
            "from mitmproxy.net.http import status_codes, url",
            "from mitmproxy.utils import human",
            "from . import RequestData, RequestEndOfMessage, RequestHeaders, RequestProtocolError, ResponseData, \\",
            "    ResponseEndOfMessage, ResponseHeaders, RequestTrailers, ResponseTrailers, ResponseProtocolError",
            "from ._base import HttpConnection, HttpEvent, ReceiveHttp, format_error",
            "from ._http_h2 import BufferedH2Connection, H2ConnectionLogger",
            "from ...commands import CloseConnection, Log, SendData",
            "from ...context import Context",
            "from ...events import ConnectionClosed, DataReceived, Event, Start",
            "from ...layer import CommandGenerator",
            "from ...utils import expect",
            "",
            "",
            "class StreamState(Enum):",
            "    EXPECTING_HEADERS = 1",
            "    HEADERS_RECEIVED = 2",
            "",
            "",
            "CATCH_HYPER_H2_ERRORS = (ValueError, IndexError)",
            "",
            "",
            "class Http2Connection(HttpConnection):",
            "    h2_conf: ClassVar[h2.config.H2Configuration]",
            "    h2_conf_defaults = dict(",
            "        header_encoding=False,",
            "        validate_outbound_headers=False,",
            "        # validate_inbound_headers is controlled by the validate_inbound_headers option.",
            "        normalize_inbound_headers=False,  # changing this to True is required to pass h2spec",
            "        normalize_outbound_headers=False,",
            "    )",
            "    h2_conn: BufferedH2Connection",
            "    streams: Dict[int, StreamState]",
            "    \"\"\"keep track of all active stream ids to send protocol errors on teardown\"\"\"",
            "",
            "    ReceiveProtocolError: Type[Union[RequestProtocolError, ResponseProtocolError]]",
            "    ReceiveData: Type[Union[RequestData, ResponseData]]",
            "    ReceiveTrailers: Type[Union[RequestTrailers, ResponseTrailers]]",
            "    ReceiveEndOfMessage: Type[Union[RequestEndOfMessage, ResponseEndOfMessage]]",
            "",
            "    def __init__(self, context: Context, conn: Connection):",
            "        super().__init__(context, conn)",
            "        if self.debug:",
            "            self.h2_conf.logger = H2ConnectionLogger(f\"{human.format_address(self.context.client.peername)}: \"",
            "                                                     f\"{self.__class__.__name__}\")",
            "        self.h2_conf.validate_inbound_headers = self.context.options.validate_inbound_headers",
            "        self.h2_conn = BufferedH2Connection(self.h2_conf)",
            "        self.streams = {}",
            "",
            "    def is_closed(self, stream_id: int) -> bool:",
            "        \"\"\"Check if a non-idle stream is closed\"\"\"",
            "        stream = self.h2_conn.streams.get(stream_id, None)",
            "        if (",
            "            stream is not None",
            "            and",
            "            stream.state_machine.state is not h2.stream.StreamState.CLOSED",
            "            and",
            "            self.h2_conn.state_machine.state is not h2.connection.ConnectionState.CLOSED",
            "        ):",
            "            return False",
            "        else:",
            "            return True",
            "",
            "    def is_open_for_us(self, stream_id: int) -> bool:",
            "        \"\"\"Check if we can write to a non-idle stream.\"\"\"",
            "        stream = self.h2_conn.streams.get(stream_id, None)",
            "        if (",
            "            stream is not None",
            "            and",
            "            stream.state_machine.state is not h2.stream.StreamState.HALF_CLOSED_LOCAL",
            "            and",
            "            stream.state_machine.state is not h2.stream.StreamState.CLOSED",
            "            and",
            "            self.h2_conn.state_machine.state is not h2.connection.ConnectionState.CLOSED",
            "        ):",
            "            return True",
            "        else:",
            "            return False",
            "",
            "    def _handle_event(self, event: Event) -> CommandGenerator[None]:",
            "        if isinstance(event, Start):",
            "            self.h2_conn.initiate_connection()",
            "            yield SendData(self.conn, self.h2_conn.data_to_send())",
            "",
            "        elif isinstance(event, HttpEvent):",
            "            if isinstance(event, (RequestData, ResponseData)):",
            "                if self.is_open_for_us(event.stream_id):",
            "                    self.h2_conn.send_data(event.stream_id, event.data)",
            "            elif isinstance(event, (RequestTrailers, ResponseTrailers)):",
            "                if self.is_open_for_us(event.stream_id):",
            "                    trailers = [*event.trailers.fields]",
            "                    self.h2_conn.send_headers(event.stream_id, trailers, end_stream=True)",
            "            elif isinstance(event, (RequestEndOfMessage, ResponseEndOfMessage)):",
            "                if self.is_open_for_us(event.stream_id):",
            "                    self.h2_conn.end_stream(event.stream_id)",
            "            elif isinstance(event, (RequestProtocolError, ResponseProtocolError)):",
            "                if not self.is_closed(event.stream_id):",
            "                    code = {",
            "                        status_codes.CLIENT_CLOSED_REQUEST: h2.errors.ErrorCodes.CANCEL,",
            "                    }.get(event.code, h2.errors.ErrorCodes.INTERNAL_ERROR)",
            "                    stream: h2.stream.H2Stream = self.h2_conn.streams[event.stream_id]",
            "                    send_error_message = (",
            "                        isinstance(event, ResponseProtocolError)",
            "                        and self.is_open_for_us(event.stream_id)",
            "                        and not stream.state_machine.headers_sent",
            "                        and event.code != status_codes.NO_RESPONSE",
            "                    )",
            "                    if send_error_message:",
            "                        self.h2_conn.send_headers(event.stream_id, [",
            "                            (b\":status\", b\"%d\" % event.code),",
            "                            (b\"server\", version.MITMPROXY.encode()),",
            "                            (b\"content-type\", b\"text/html\"),",
            "                        ])",
            "                        self.h2_conn.send_data(",
            "                            event.stream_id,",
            "                            format_error(event.code, event.message),",
            "                            end_stream=True",
            "                        )",
            "                    else:",
            "                        self.h2_conn.reset_stream(event.stream_id, code)",
            "            else:",
            "                raise AssertionError(f\"Unexpected event: {event}\")",
            "            data_to_send = self.h2_conn.data_to_send()",
            "            if data_to_send:",
            "                yield SendData(self.conn, data_to_send)",
            "",
            "        elif isinstance(event, DataReceived):",
            "            try:",
            "                try:",
            "                    events = self.h2_conn.receive_data(event.data)",
            "                except CATCH_HYPER_H2_ERRORS as e:  # pragma: no cover",
            "                    # this should never raise a ValueError, but we triggered one while fuzzing:",
            "                    # https://github.com/python-hyper/hyper-h2/issues/1231",
            "                    # this stays here as defense-in-depth.",
            "                    raise h2.exceptions.ProtocolError(f\"uncaught hyper-h2 error: {e}\") from e",
            "            except h2.exceptions.ProtocolError as e:",
            "                events = [e]",
            "",
            "            for h2_event in events:",
            "                if self.debug:",
            "                    yield Log(f\"{self.debug}[h2] {h2_event}\", \"debug\")",
            "                if (yield from self.handle_h2_event(h2_event)):",
            "                    if self.debug:",
            "                        yield Log(f\"{self.debug}[h2] done\", \"debug\")",
            "                    return",
            "",
            "            data_to_send = self.h2_conn.data_to_send()",
            "            if data_to_send:",
            "                yield SendData(self.conn, data_to_send)",
            "",
            "        elif isinstance(event, ConnectionClosed):",
            "            yield from self.close_connection(\"peer closed connection\")",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event!r}\")",
            "",
            "    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:",
            "        \"\"\"returns true if further processing should be stopped.\"\"\"",
            "        if isinstance(event, h2.events.DataReceived):",
            "            state = self.streams.get(event.stream_id, None)",
            "            if state is StreamState.HEADERS_RECEIVED:",
            "                yield ReceiveHttp(self.ReceiveData(event.stream_id, event.data))",
            "            elif state is StreamState.EXPECTING_HEADERS:",
            "                yield from self.protocol_error(f\"Received HTTP/2 data frame, expected headers.\")",
            "                return True",
            "            self.h2_conn.acknowledge_received_data(event.flow_controlled_length, event.stream_id)",
            "        elif isinstance(event, h2.events.TrailersReceived):",
            "            trailers = http.Headers(event.headers)",
            "            yield ReceiveHttp(self.ReceiveTrailers(event.stream_id, trailers))",
            "        elif isinstance(event, h2.events.StreamEnded):",
            "            state = self.streams.get(event.stream_id, None)",
            "            if state is StreamState.HEADERS_RECEIVED:",
            "                yield ReceiveHttp(self.ReceiveEndOfMessage(event.stream_id))",
            "            elif state is StreamState.EXPECTING_HEADERS:",
            "                raise AssertionError(\"unreachable\")",
            "            if self.is_closed(event.stream_id):",
            "                self.streams.pop(event.stream_id, None)",
            "        elif isinstance(event, h2.events.StreamReset):",
            "            if event.stream_id in self.streams:",
            "                try:",
            "                    err_str = h2.errors.ErrorCodes(event.error_code).name",
            "                except ValueError:",
            "                    err_str = str(event.error_code)",
            "                err_code = {",
            "                    h2.errors.ErrorCodes.CANCEL: status_codes.CLIENT_CLOSED_REQUEST,",
            "                }.get(event.error_code, self.ReceiveProtocolError.code)",
            "                yield ReceiveHttp(self.ReceiveProtocolError(event.stream_id, f\"stream reset by client ({err_str})\",",
            "                                                            code=err_code))",
            "                self.streams.pop(event.stream_id)",
            "            else:",
            "                pass  # We don't track priority frames which could be followed by a stream reset here.",
            "        elif isinstance(event, h2.exceptions.ProtocolError):",
            "            yield from self.protocol_error(f\"HTTP/2 protocol error: {event}\")",
            "            return True",
            "        elif isinstance(event, h2.events.ConnectionTerminated):",
            "            yield from self.close_connection(f\"HTTP/2 connection closed: {event!r}\")",
            "            return True",
            "            # The implementation above isn't really ideal, we should probably only terminate streams > last_stream_id?",
            "            # We currently lack a mechanism to signal that connections are still active but cannot be reused.",
            "            # for stream_id in self.streams:",
            "            #    if stream_id > event.last_stream_id:",
            "            #        yield ReceiveHttp(self.ReceiveProtocolError(stream_id, f\"HTTP/2 connection closed: {event!r}\"))",
            "            #        self.streams.pop(stream_id)",
            "        elif isinstance(event, h2.events.RemoteSettingsChanged):",
            "            pass",
            "        elif isinstance(event, h2.events.SettingsAcknowledged):",
            "            pass",
            "        elif isinstance(event, h2.events.PriorityUpdated):",
            "            pass",
            "        elif isinstance(event, h2.events.PingReceived):",
            "            pass",
            "        elif isinstance(event, h2.events.PingAckReceived):",
            "            pass",
            "        elif isinstance(event, h2.events.PushedStreamReceived):",
            "            yield Log(\"Received HTTP/2 push promise, even though we signalled no support.\", \"error\")",
            "        elif isinstance(event, h2.events.UnknownFrameReceived):",
            "            # https://http2.github.io/http2-spec/#rfc.section.4.1",
            "            # Implementations MUST ignore and discard any frame that has a type that is unknown.",
            "            yield Log(f\"Ignoring unknown HTTP/2 frame type: {event.frame.type}\")",
            "        else:",
            "            raise AssertionError(f\"Unexpected event: {event!r}\")",
            "        return False",
            "",
            "    def protocol_error(",
            "        self,",
            "        message: str,",
            "        error_code: int = h2.errors.ErrorCodes.PROTOCOL_ERROR,",
            "    ) -> CommandGenerator[None]:",
            "        yield Log(f\"{human.format_address(self.conn.peername)}: {message}\")",
            "        self.h2_conn.close_connection(error_code, message.encode())",
            "        yield SendData(self.conn, self.h2_conn.data_to_send())",
            "        yield from self.close_connection(message)",
            "",
            "    def close_connection(self, msg: str) -> CommandGenerator[None]:",
            "        yield CloseConnection(self.conn)",
            "        for stream_id in self.streams:",
            "            yield ReceiveHttp(self.ReceiveProtocolError(stream_id, msg))",
            "        self.streams.clear()",
            "        self._handle_event = self.done  # type: ignore",
            "",
            "    @expect(DataReceived, HttpEvent, ConnectionClosed)",
            "    def done(self, _) -> CommandGenerator[None]:",
            "        yield from ()",
            "",
            "",
            "def normalize_h1_headers(headers: List[Tuple[bytes, bytes]], is_client: bool) -> List[Tuple[bytes, bytes]]:",
            "    # HTTP/1 servers commonly send capitalized headers (Content-Length vs content-length),",
            "    # which isn't valid HTTP/2. As such we normalize.",
            "    headers = h2.utilities.normalize_outbound_headers(",
            "        headers,",
            "        h2.utilities.HeaderValidationFlags(is_client, False, not is_client, False)",
            "    )",
            "    # make sure that this is not just an iterator but an iterable,",
            "    # otherwise hyper-h2 will silently drop headers.",
            "    headers = list(headers)",
            "    return headers",
            "",
            "",
            "def normalize_h2_headers(headers: List[Tuple[bytes, bytes]]) -> CommandGenerator[None]:",
            "    for i in range(len(headers)):",
            "        if not headers[i][0].islower():",
            "            yield Log(f\"Lowercased {repr(headers[i][0]).lstrip('b')} header as uppercase is not allowed with HTTP/2.\")",
            "            headers[i] = (headers[i][0].lower(), headers[i][1])",
            "",
            "",
            "class Http2Server(Http2Connection):",
            "    h2_conf = h2.config.H2Configuration(",
            "        **Http2Connection.h2_conf_defaults,",
            "        client_side=False,",
            "    )",
            "",
            "    ReceiveProtocolError = RequestProtocolError",
            "    ReceiveData = RequestData",
            "    ReceiveTrailers = RequestTrailers",
            "    ReceiveEndOfMessage = RequestEndOfMessage",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.client)",
            "",
            "    def _handle_event(self, event: Event) -> CommandGenerator[None]:",
            "        if isinstance(event, ResponseHeaders):",
            "            if self.is_open_for_us(event.stream_id):",
            "                headers = [",
            "                    (b\":status\", b\"%d\" % event.response.status_code),",
            "                    *event.response.headers.fields",
            "                ]",
            "                if event.response.is_http2:",
            "                    if self.context.options.normalize_outbound_headers:",
            "                        yield from normalize_h2_headers(headers)",
            "                else:",
            "                    headers = normalize_h1_headers(headers, False)",
            "",
            "                self.h2_conn.send_headers(",
            "                    event.stream_id,",
            "                    headers,",
            "                    end_stream=event.end_stream,",
            "                )",
            "                yield SendData(self.conn, self.h2_conn.data_to_send())",
            "        else:",
            "            yield from super()._handle_event(event)",
            "",
            "    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:",
            "        if isinstance(event, h2.events.RequestReceived):",
            "            try:",
            "                host, port, method, scheme, authority, path, headers = parse_h2_request_headers(event.headers)",
            "            except ValueError as e:",
            "                yield from self.protocol_error(f\"Invalid HTTP/2 request headers: {e}\")",
            "                return True",
            "            request = http.Request(",
            "                host=host,",
            "                port=port,",
            "                method=method,",
            "                scheme=scheme,",
            "                authority=authority,",
            "                path=path,",
            "                http_version=b\"HTTP/2.0\",",
            "                headers=headers,",
            "                content=None,",
            "                trailers=None,",
            "                timestamp_start=time.time(),",
            "                timestamp_end=None,",
            "            )",
            "            self.streams[event.stream_id] = StreamState.HEADERS_RECEIVED",
            "            yield ReceiveHttp(RequestHeaders(event.stream_id, request, end_stream=bool(event.stream_ended)))",
            "            return False",
            "        else:",
            "            return (yield from super().handle_h2_event(event))",
            "",
            "",
            "class Http2Client(Http2Connection):",
            "    h2_conf = h2.config.H2Configuration(",
            "        **Http2Connection.h2_conf_defaults,",
            "        client_side=True,",
            "    )",
            "",
            "    ReceiveProtocolError = ResponseProtocolError",
            "    ReceiveData = ResponseData",
            "    ReceiveTrailers = ResponseTrailers",
            "    ReceiveEndOfMessage = ResponseEndOfMessage",
            "",
            "    our_stream_id: Dict[int, int]",
            "    their_stream_id: Dict[int, int]",
            "    stream_queue: DefaultDict[int, List[Event]]",
            "    \"\"\"Queue of streams that we haven't sent yet because we have reached MAX_CONCURRENT_STREAMS\"\"\"",
            "    provisional_max_concurrency: Optional[int] = 10",
            "    \"\"\"A provisional currency limit before we get the server's first settings frame.\"\"\"",
            "",
            "    def __init__(self, context: Context):",
            "        super().__init__(context, context.server)",
            "        # Disable HTTP/2 push for now to keep things simple.",
            "        # don't send here, that is done as part of initiate_connection().",
            "        self.h2_conn.local_settings.enable_push = 0",
            "        # hyper-h2 pitfall: we need to acknowledge here, otherwise its sends out the old settings.",
            "        self.h2_conn.local_settings.acknowledge()",
            "        self.our_stream_id = {}",
            "        self.their_stream_id = {}",
            "        self.stream_queue = collections.defaultdict(list)",
            "",
            "    def _handle_event(self, event: Event) -> CommandGenerator[None]:",
            "        # We can't reuse stream ids from the client because they may arrived reordered here",
            "        # and HTTP/2 forbids opening a stream on a lower id than what was previously sent (see test_stream_concurrency).",
            "        # To mitigate this, we transparently map the outside's stream id to our stream id.",
            "        if isinstance(event, HttpEvent):",
            "            ours = self.our_stream_id.get(event.stream_id, None)",
            "            if ours is None:",
            "                no_free_streams = (",
            "                    self.h2_conn.open_outbound_streams >=",
            "                    (self.provisional_max_concurrency or self.h2_conn.remote_settings.max_concurrent_streams)",
            "                )",
            "                if no_free_streams:",
            "                    self.stream_queue[event.stream_id].append(event)",
            "                    return",
            "                ours = self.h2_conn.get_next_available_stream_id()",
            "                self.our_stream_id[event.stream_id] = ours",
            "                self.their_stream_id[ours] = event.stream_id",
            "            event.stream_id = ours",
            "",
            "        for cmd in self._handle_event2(event):",
            "            if isinstance(cmd, ReceiveHttp):",
            "                cmd.event.stream_id = self.their_stream_id[cmd.event.stream_id]",
            "            yield cmd",
            "",
            "        can_resume_queue = (",
            "            self.stream_queue and",
            "            self.h2_conn.open_outbound_streams < (",
            "                self.provisional_max_concurrency or self.h2_conn.remote_settings.max_concurrent_streams",
            "            )",
            "        )",
            "        if can_resume_queue:",
            "            # popitem would be LIFO, but we want FIFO.",
            "            events = self.stream_queue.pop(next(iter(self.stream_queue)))",
            "            for event in events:",
            "                yield from self._handle_event(event)",
            "",
            "    def _handle_event2(self, event: Event) -> CommandGenerator[None]:",
            "        if isinstance(event, RequestHeaders):",
            "            pseudo_headers = [",
            "                (b':method', event.request.data.method),",
            "                (b':scheme', event.request.data.scheme),",
            "                (b':path', event.request.data.path),",
            "            ]",
            "            if event.request.authority:",
            "                pseudo_headers.append((b\":authority\", event.request.data.authority))",
            "",
            "            if event.request.is_http2:",
            "                hdrs = list(event.request.headers.fields)",
            "                if self.context.options.normalize_outbound_headers:",
            "                    yield from normalize_h2_headers(hdrs)",
            "            else:",
            "                headers = event.request.headers",
            "                if not event.request.authority and \"host\" in headers:",
            "                    headers = headers.copy()",
            "                    pseudo_headers.append((b\":authority\", headers.pop(b\"host\")))",
            "                hdrs = normalize_h1_headers(list(headers.fields), True)",
            "",
            "            self.h2_conn.send_headers(",
            "                event.stream_id,",
            "                pseudo_headers + hdrs,",
            "                end_stream=event.end_stream,",
            "            )",
            "            self.streams[event.stream_id] = StreamState.EXPECTING_HEADERS",
            "            yield SendData(self.conn, self.h2_conn.data_to_send())",
            "        else:",
            "            yield from super()._handle_event(event)",
            "",
            "    def handle_h2_event(self, event: h2.events.Event) -> CommandGenerator[bool]:",
            "        if isinstance(event, h2.events.ResponseReceived):",
            "            if self.streams.get(event.stream_id, None) is not StreamState.EXPECTING_HEADERS:",
            "                yield from self.protocol_error(f\"Received unexpected HTTP/2 response.\")",
            "                return True",
            "",
            "            try:",
            "                status_code, headers = parse_h2_response_headers(event.headers)",
            "            except ValueError as e:",
            "                yield from self.protocol_error(f\"Invalid HTTP/2 response headers: {e}\")",
            "                return True",
            "",
            "            response = http.Response(",
            "                http_version=b\"HTTP/2.0\",",
            "                status_code=status_code,",
            "                reason=b\"\",",
            "                headers=headers,",
            "                content=None,",
            "                trailers=None,",
            "                timestamp_start=time.time(),",
            "                timestamp_end=None,",
            "            )",
            "            self.streams[event.stream_id] = StreamState.HEADERS_RECEIVED",
            "            yield ReceiveHttp(ResponseHeaders(event.stream_id, response, bool(event.stream_ended)))",
            "            return False",
            "        elif isinstance(event, h2.events.RequestReceived):",
            "            yield from self.protocol_error(f\"HTTP/2 protocol error: received request from server\")",
            "            return True",
            "        elif isinstance(event, h2.events.RemoteSettingsChanged):",
            "            # We have received at least one settings from now,",
            "            # which means we can rely on the max concurrency in remote_settings",
            "            self.provisional_max_concurrency = None",
            "            return (yield from super().handle_h2_event(event))",
            "        else:",
            "            return (yield from super().handle_h2_event(event))",
            "",
            "",
            "def split_pseudo_headers(h2_headers: Sequence[Tuple[bytes, bytes]]) -> Tuple[Dict[bytes, bytes], http.Headers]:",
            "    pseudo_headers: Dict[bytes, bytes] = {}",
            "    i = 0",
            "    for (header, value) in h2_headers:",
            "        if header.startswith(b\":\"):",
            "            if header in pseudo_headers:",
            "                raise ValueError(f\"Duplicate HTTP/2 pseudo header: {header!r}\")",
            "            pseudo_headers[header] = value",
            "            i += 1",
            "        else:",
            "            # Pseudo-headers must be at the start, we are done here.",
            "            break",
            "",
            "    headers = http.Headers(h2_headers[i:])",
            "",
            "    return pseudo_headers, headers",
            "",
            "",
            "def parse_h2_request_headers(",
            "    h2_headers: Sequence[Tuple[bytes, bytes]]",
            ") -> Tuple[str, int, bytes, bytes, bytes, bytes, http.Headers]:",
            "    \"\"\"Split HTTP/2 pseudo-headers from the actual headers and parse them.\"\"\"",
            "    pseudo_headers, headers = split_pseudo_headers(h2_headers)",
            "",
            "    try:",
            "        method: bytes = pseudo_headers.pop(b\":method\")",
            "        scheme: bytes = pseudo_headers.pop(b\":scheme\")  # this raises for HTTP/2 CONNECT requests",
            "        path: bytes = pseudo_headers.pop(b\":path\")",
            "        authority: bytes = pseudo_headers.pop(b\":authority\", b\"\")",
            "    except KeyError as e:",
            "        raise ValueError(f\"Required pseudo header is missing: {e}\")",
            "",
            "    if pseudo_headers:",
            "        raise ValueError(f\"Unknown pseudo headers: {pseudo_headers}\")",
            "",
            "    if authority:",
            "        host, port = url.parse_authority(authority, check=True)",
            "        if port is None:",
            "            port = 80 if scheme == b'http' else 443",
            "    else:",
            "        host = \"\"",
            "        port = 0",
            "",
            "    return host, port, method, scheme, authority, path, headers",
            "",
            "",
            "def parse_h2_response_headers(h2_headers: Sequence[Tuple[bytes, bytes]]) -> Tuple[int, http.Headers]:",
            "    \"\"\"Split HTTP/2 pseudo-headers from the actual headers and parse them.\"\"\"",
            "    pseudo_headers, headers = split_pseudo_headers(h2_headers)",
            "",
            "    try:",
            "        status_code: int = int(pseudo_headers.pop(b\":status\"))",
            "    except KeyError as e:",
            "        raise ValueError(f\"Required pseudo header is missing: {e}\")",
            "",
            "    if pseudo_headers:",
            "        raise ValueError(f\"Unknown pseudo headers: {pseudo_headers}\")",
            "",
            "    return status_code, headers",
            "",
            "",
            "__all__ = [",
            "    \"Http2Client\",",
            "    \"Http2Server\",",
            "]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "43": [
                "Http2Connection"
            ]
        },
        "addLocation": []
    }
}