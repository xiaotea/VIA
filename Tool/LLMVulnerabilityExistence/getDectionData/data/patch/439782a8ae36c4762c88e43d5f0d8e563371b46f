{
    "pipenv/core.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " from pipenv.patched import crayons"
            },
            "1": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " from pipenv.utils import ("
            },
            "2": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": "     cmd_list_to_shell, convert_deps_to_pip, create_spinner, download_file,"
            },
            "3": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    find_python, get_canonical_names, get_source_list, is_pinned,"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+    find_python, get_canonical_names, get_host_and_port, get_source_list, is_pinned,"
            },
            "5": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     is_python_command, is_required_version, is_star, is_valid_url,"
            },
            "6": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": "     parse_indexes, pep423_name, prepare_pip_source_args, proper_case,"
            },
            "7": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": "     python_version, run_command, subprocess_run, venv_resolve_deps"
            },
            "8": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 169,
                "PatchRowcode": "         if extra_index:"
            },
            "9": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "             indexes.append(extra_index)"
            },
            "10": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "         if trusted_host:"
            },
            "11": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            trusted_hosts.append(trusted_host)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+            trusted_hosts.append(get_host_and_port(trusted_host))"
            },
            "13": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "     indexes = sorted(set(indexes))"
            },
            "14": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "     trusted_hosts = sorted(set(trusted_hosts))"
            },
            "15": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 175,
                "PatchRowcode": "     reqs = [install_req_from_parsed_requirement(f) for f in parse_requirements(r, session=pip_requests)]"
            },
            "16": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "             else:"
            },
            "17": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "                 project.add_package_to_pipfile(str(package.req), dev=dev)"
            },
            "18": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 187,
                "PatchRowcode": "     for index in indexes:"
            },
            "19": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        trusted = index in trusted_hosts"
            },
            "20": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        project.add_index_to_pipfile(index, verify_ssl=trusted)"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 188,
                "PatchRowcode": "+        # don't require HTTPS for trusted hosts (see: https://pip.pypa.io/en/stable/cli/pip/#cmdoption-trusted-host)"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+        host_and_port = get_host_and_port(index)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 190,
                "PatchRowcode": "+        require_valid_https = not any((v in trusted_hosts for v in ("
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 191,
                "PatchRowcode": "+            host_and_port,"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 192,
                "PatchRowcode": "+            host_and_port.partition(':')[0],  # also check if hostname without port is in trusted_hosts"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 193,
                "PatchRowcode": "+        )))"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+        project.add_index_to_pipfile(index, verify_ssl=require_valid_https)"
            },
            "28": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "     project.recase_pipfile()"
            },
            "29": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 196,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 197,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "import json as simplejson",
            "import logging",
            "import os",
            "from pathlib import Path",
            "from posixpath import expandvars",
            "import sys",
            "import time",
            "import warnings",
            "",
            "import click",
            "import dotenv",
            "import pipfile",
            "import vistir",
            "",
            "from pipenv import environments, exceptions, pep508checker, progress",
            "from pipenv._compat import decode_for_output, fix_utf8",
            "from pipenv.patched import crayons",
            "from pipenv.utils import (",
            "    cmd_list_to_shell, convert_deps_to_pip, create_spinner, download_file,",
            "    find_python, get_canonical_names, get_source_list, is_pinned,",
            "    is_python_command, is_required_version, is_star, is_valid_url,",
            "    parse_indexes, pep423_name, prepare_pip_source_args, proper_case,",
            "    python_version, run_command, subprocess_run, venv_resolve_deps",
            ")",
            "",
            "",
            "if environments.is_type_checking():",
            "    from typing import Dict, List, Optional, Union",
            "",
            "    from pipenv.project import Project",
            "    from pipenv.vendor.requirementslib.models.requirements import Requirement",
            "    TSourceDict = Dict[str, Union[str, bool]]",
            "",
            "",
            "# Packages that should be ignored later.",
            "BAD_PACKAGES = (",
            "    \"distribute\",",
            "    \"packaging\",",
            "    \"pip\",",
            "    \"pkg-resources\",",
            "    \"setuptools\",",
            "    \"wheel\",",
            ")",
            "",
            "FIRST_PACKAGES = (\"cython\",)",
            "",
            "if not environments.PIPENV_HIDE_EMOJIS:",
            "    now = time.localtime()",
            "    # Halloween easter-egg.",
            "    if ((now.tm_mon == 10) and (now.tm_mday == 30)) or (",
            "        (now.tm_mon == 10) and (now.tm_mday == 31)",
            "    ):",
            "        INSTALL_LABEL = \"\ud83c\udf83   \"",
            "    # Christmas easter-egg.",
            "    elif ((now.tm_mon == 12) and (now.tm_mday == 24)) or (",
            "        (now.tm_mon == 12) and (now.tm_mday == 25)",
            "    ):",
            "        INSTALL_LABEL = \"\ud83c\udf85   \"",
            "    else:",
            "        INSTALL_LABEL = \"\ud83d\udc0d   \"",
            "    INSTALL_LABEL2 = crayons.normal(\"\u2624  \", bold=True)",
            "    STARTING_LABEL = \"    \"",
            "else:",
            "    INSTALL_LABEL = \"   \"",
            "    INSTALL_LABEL2 = \"   \"",
            "    STARTING_LABEL = \"   \"",
            "",
            "# Disable colors, for the color blind and others who do not prefer colors.",
            "if environments.PIPENV_COLORBLIND:",
            "    crayons.disable()",
            "",
            "",
            "def do_clear(project):",
            "    click.echo(crayons.normal(fix_utf8(\"Clearing caches...\"), bold=True))",
            "    try:",
            "        from pip._internal import locations",
            "    except ImportError:  # pip 9.",
            "        from pip import locations",
            "",
            "    try:",
            "        vistir.path.rmtree(project.s.PIPENV_CACHE_DIR, onerror=vistir.path.handle_remove_readonly)",
            "        # Other processes may be writing into this directory simultaneously.",
            "        vistir.path.rmtree(",
            "            locations.USER_CACHE_DIR,",
            "            ignore_errors=environments.PIPENV_IS_CI,",
            "            onerror=vistir.path.handle_remove_readonly",
            "        )",
            "    except OSError as e:",
            "        # Ignore FileNotFoundError. This is needed for Python 2.7.",
            "        import errno",
            "",
            "        if e.errno == errno.ENOENT:",
            "            pass",
            "        raise",
            "",
            "",
            "def load_dot_env(project, as_dict=False):",
            "    \"\"\"Loads .env file into sys.environ.\"\"\"",
            "    if not project.s.PIPENV_DONT_LOAD_ENV:",
            "        # If the project doesn't exist yet, check current directory for a .env file",
            "        project_directory = project.project_directory or \".\"",
            "        dotenv_file = project.s.PIPENV_DOTENV_LOCATION or os.sep.join(",
            "            [project_directory, \".env\"]",
            "        )",
            "",
            "        if os.path.isfile(dotenv_file):",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Loading .env environment variables...\"), bold=True),",
            "                err=True,",
            "            )",
            "        else:",
            "            if project.s.PIPENV_DOTENV_LOCATION:",
            "                click.echo(",
            "                    \"{}: file {}={} does not exist!!\\n{}\".format(",
            "                        crayons.red(\"Warning\", bold=True),",
            "                        crayons.normal(\"PIPENV_DOTENV_LOCATION\", bold=True),",
            "                        crayons.normal(project.s.PIPENV_DOTENV_LOCATION, bold=True),",
            "                        crayons.red(\"Not loading environment variables.\", bold=True),",
            "                    ),",
            "                    err=True,",
            "                )",
            "        if as_dict:",
            "            return dotenv.dotenv_values(dotenv_file)",
            "        else:",
            "            dotenv.load_dotenv(dotenv_file, override=True)",
            "            project.s.initialize()",
            "",
            "",
            "def cleanup_virtualenv(project, bare=True):",
            "    \"\"\"Removes the virtualenv directory from the system.\"\"\"",
            "    if not bare:",
            "        click.echo(crayons.red(\"Environment creation aborted.\"))",
            "    try:",
            "        # Delete the virtualenv.",
            "        vistir.path.rmtree(project.virtualenv_location)",
            "    except OSError as e:",
            "        click.echo(",
            "            \"{} An error occurred while removing {}!\".format(",
            "                crayons.red(\"Error: \", bold=True),",
            "                crayons.green(project.virtualenv_location),",
            "            ),",
            "            err=True,",
            "        )",
            "        click.echo(crayons.cyan(e), err=True)",
            "",
            "",
            "def import_requirements(project, r=None, dev=False):",
            "    from pipenv.patched.notpip._vendor import requests as pip_requests",
            "    from pipenv.patched.notpip._internal.req.constructors import install_req_from_parsed_requirement",
            "    from pipenv.vendor.pip_shims.shims import parse_requirements",
            "",
            "    # Parse requirements.txt file with Pip's parser.",
            "    # Pip requires a `PipSession` which is a subclass of requests.Session.",
            "    # Since we're not making any network calls, it's initialized to nothing.",
            "    if r:",
            "        assert os.path.isfile(r)",
            "    # Default path, if none is provided.",
            "    if r is None:",
            "        r = project.requirements_location",
            "    with open(r) as f:",
            "        contents = f.read()",
            "    indexes = []",
            "    trusted_hosts = []",
            "    # Find and add extra indexes.",
            "    for line in contents.split(\"\\n\"):",
            "        index, extra_index, trusted_host, _ = parse_indexes(line.strip(), strict=True)",
            "        if index:",
            "            indexes = [index]",
            "        if extra_index:",
            "            indexes.append(extra_index)",
            "        if trusted_host:",
            "            trusted_hosts.append(trusted_host)",
            "    indexes = sorted(set(indexes))",
            "    trusted_hosts = sorted(set(trusted_hosts))",
            "    reqs = [install_req_from_parsed_requirement(f) for f in parse_requirements(r, session=pip_requests)]",
            "    for package in reqs:",
            "        if package.name not in BAD_PACKAGES:",
            "            if package.link is not None:",
            "                package_string = (",
            "                    f\"-e {package.link}\"",
            "                    if package.editable",
            "                    else str(package.link)",
            "                )",
            "                project.add_package_to_pipfile(package_string, dev=dev)",
            "            else:",
            "                project.add_package_to_pipfile(str(package.req), dev=dev)",
            "    for index in indexes:",
            "        trusted = index in trusted_hosts",
            "        project.add_index_to_pipfile(index, verify_ssl=trusted)",
            "    project.recase_pipfile()",
            "",
            "",
            "def ensure_environment():",
            "    # Skip this on Windows...",
            "    if os.name != \"nt\":",
            "        if \"LANG\" not in os.environ:",
            "            click.echo(",
            "                \"{}: the environment variable {} is not set!\"",
            "                \"\\nWe recommend setting this in {} (or equivalent) for \"",
            "                \"proper expected behavior.\".format(",
            "                    crayons.red(\"Warning\", bold=True),",
            "                    crayons.normal(\"LANG\", bold=True),",
            "                    crayons.green(\"~/.profile\"),",
            "                ),",
            "                err=True,",
            "            )",
            "",
            "",
            "def import_from_code(path=\".\"):",
            "    from pipreqs import pipreqs",
            "",
            "    rs = []",
            "    try:",
            "        for r in pipreqs.get_all_imports(",
            "            path, encoding=\"utf-8\", extra_ignore_dirs=[\".venv\"]",
            "        ):",
            "            if r not in BAD_PACKAGES:",
            "                rs.append(r)",
            "        pkg_names = pipreqs.get_pkg_names(rs)",
            "        return [proper_case(r) for r in pkg_names]",
            "",
            "    except Exception:",
            "        return []",
            "",
            "",
            "def ensure_pipfile(project, validate=True, skip_requirements=False, system=False):",
            "    \"\"\"Creates a Pipfile for the project, if it doesn't exist.\"\"\"",
            "",
            "    # Assert Pipfile exists.",
            "    python = project._which(\"python\") if not (project.s.USING_DEFAULT_PYTHON or system) else None",
            "    if project.pipfile_is_empty:",
            "        # Show an error message and exit if system is passed and no pipfile exists",
            "        if system and not project.s.PIPENV_VIRTUALENV:",
            "            raise exceptions.PipenvOptionsError(",
            "                \"--system\",",
            "                \"--system is intended to be used for pre-existing Pipfile \"",
            "                \"installation, not installation of specific packages. Aborting.\"",
            "            )",
            "        # If there's a requirements file, but no Pipfile...",
            "        if project.requirements_exists and not skip_requirements:",
            "            click.echo(",
            "                crayons.normal(",
            "                    fix_utf8(\"requirements.txt found, instead of Pipfile! Converting...\"),",
            "                    bold=True,",
            "                )",
            "            )",
            "            # Create a Pipfile...",
            "            project.create_pipfile(python=python)",
            "            with create_spinner(\"Importing requirements...\", project.s) as sp:",
            "                # Import requirements.txt.",
            "                try:",
            "                    import_requirements(project)",
            "                except Exception:",
            "                    sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Failed...\"))",
            "                else:",
            "                    sp.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Success!\"))",
            "            # Warn the user of side-effects.",
            "            click.echo(",
            "                \"{0}: Your {1} now contains pinned versions, if your {2} did. \\n\"",
            "                \"We recommend updating your {1} to specify the {3} version, instead.\"",
            "                \"\".format(",
            "                    crayons.red(\"Warning\", bold=True),",
            "                    crayons.normal(\"Pipfile\", bold=True),",
            "                    crayons.normal(\"requirements.txt\", bold=True),",
            "                    crayons.normal('\"*\"', bold=True),",
            "                )",
            "            )",
            "        else:",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Creating a Pipfile for this project...\"), bold=True),",
            "                err=True,",
            "            )",
            "            # Create the pipfile if it doesn't exist.",
            "            project.create_pipfile(python=python)",
            "    # Validate the Pipfile's contents.",
            "    if validate and project.virtualenv_exists and not project.s.PIPENV_SKIP_VALIDATION:",
            "        # Ensure that Pipfile is using proper casing.",
            "        p = project.parsed_pipfile",
            "        changed = project.ensure_proper_casing()",
            "        # Write changes out to disk.",
            "        if changed:",
            "            click.echo(",
            "                crayons.normal(\"Fixing package names in Pipfile...\", bold=True), err=True",
            "            )",
            "            project.write_toml(p)",
            "",
            "",
            "def find_a_system_python(line):",
            "    \"\"\"Find a Python installation from a given line.",
            "",
            "    This tries to parse the line in various of ways:",
            "",
            "    * Looks like an absolute path? Use it directly.",
            "    * Looks like a py.exe call? Use py.exe to get the executable.",
            "    * Starts with \"py\" something? Looks like a python command. Try to find it",
            "      in PATH, and use it directly.",
            "    * Search for \"python\" and \"pythonX.Y\" executables in PATH to find a match.",
            "    * Nothing fits, return None.",
            "    \"\"\"",
            "",
            "    from .vendor.pythonfinder import Finder",
            "    finder = Finder(system=False, global_search=True)",
            "    if not line:",
            "        return next(iter(finder.find_all_python_versions()), None)",
            "    # Use the windows finder executable",
            "    if (line.startswith(\"py \") or line.startswith(\"py.exe \")) and os.name == \"nt\":",
            "        line = line.split(\" \", 1)[1].lstrip(\"-\")",
            "    python_entry = find_python(finder, line)",
            "    return python_entry",
            "",
            "",
            "def ensure_python(project, three=None, python=None):",
            "    # Runtime import is necessary due to the possibility that the environments module may have been reloaded.",
            "    if project.s.PIPENV_PYTHON and python is False and three is None:",
            "        python = project.s.PIPENV_PYTHON",
            "",
            "    def abort(msg=''):",
            "        click.echo(",
            "            \"{}\\nYou can specify specific versions of Python with:\\n{}\".format(",
            "                crayons.red(msg),",
            "                crayons.yellow(",
            "                    \"$ pipenv --python {}\".format(",
            "                        os.sep.join((\"path\", \"to\", \"python\"))",
            "                    )",
            "                )",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "",
            "    project.s.USING_DEFAULT_PYTHON = three is None and not python",
            "    # Find out which python is desired.",
            "    if not python:",
            "        python = convert_three_to_python(three, python)",
            "    if not python:",
            "        python = project.required_python_version",
            "    if not python:",
            "        python = project.s.PIPENV_DEFAULT_PYTHON_VERSION",
            "    path_to_python = find_a_system_python(python)",
            "    if project.s.is_verbose():",
            "        click.echo(f\"Using python: {python}\", err=True)",
            "        click.echo(f\"Path to python: {path_to_python}\", err=True)",
            "    if not path_to_python and python is not None:",
            "        # We need to install Python.",
            "        click.echo(",
            "            \"{}: Python {} {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                crayons.cyan(python),",
            "                fix_utf8(\"was not found on your system...\"),",
            "            ),",
            "            err=True,",
            "        )",
            "        # check for python installers",
            "        from .installers import Asdf, InstallerError, InstallerNotFound, Pyenv",
            "",
            "        # prefer pyenv if both pyenv and asdf are installed as it's",
            "        # dedicated to python installs so probably the preferred",
            "        # method of the user for new python installs.",
            "        installer = None",
            "        if not project.s.PIPENV_DONT_USE_PYENV:",
            "            try:",
            "                installer = Pyenv(project)",
            "            except InstallerNotFound:",
            "                pass",
            "        if installer is None and not project.s.PIPENV_DONT_USE_ASDF:",
            "            try:",
            "                installer = Asdf(project)",
            "            except InstallerNotFound:",
            "                pass",
            "",
            "        if not installer:",
            "            abort(\"Neither 'pyenv' nor 'asdf' could be found to install Python.\")",
            "        else:",
            "            if environments.SESSION_IS_INTERACTIVE or project.s.PIPENV_YES:",
            "                try:",
            "                    version = installer.find_version_to_install(python)",
            "                except ValueError:",
            "                    abort()",
            "                except InstallerError as e:",
            "                    abort(f'Something went wrong while installing Python:\\n{e.err}')",
            "                s = \"{} {} {}\".format(",
            "                    \"Would you like us to install\",",
            "                    crayons.green(f\"CPython {version}\"),",
            "                    f\"with {installer}?\",",
            "                )",
            "                # Prompt the user to continue...",
            "                if not (project.s.PIPENV_YES or click.confirm(s, default=True)):",
            "                    abort()",
            "                else:",
            "                    # Tell the user we're installing Python.",
            "                    click.echo(",
            "                        \"{} {} {} {}{}\".format(",
            "                            crayons.normal(\"Installing\", bold=True),",
            "                            crayons.green(f\"CPython {version}\", bold=True),",
            "                            crayons.normal(f\"with {installer.cmd}\", bold=True),",
            "                            crayons.normal(\"(this may take a few minutes)\"),",
            "                            crayons.normal(\"...\", bold=True),",
            "                        )",
            "                    )",
            "                    with create_spinner(\"Installing python...\", project.s) as sp:",
            "                        try:",
            "                            c = installer.install(version)",
            "                        except InstallerError as e:",
            "                            sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "                                \"Failed...\")",
            "                            )",
            "                            click.echo(fix_utf8(\"Something went wrong...\"), err=True)",
            "                            click.echo(crayons.cyan(e.err), err=True)",
            "                        else:",
            "                            sp.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Success!\"))",
            "                            # Print the results, in a beautiful blue...",
            "                            click.echo(crayons.cyan(c.stdout), err=True)",
            "                            # Clear the pythonfinder caches",
            "                            from .vendor.pythonfinder import Finder",
            "                            finder = Finder(system=False, global_search=True)",
            "                            finder.find_python_version.cache_clear()",
            "                            finder.find_all_python_versions.cache_clear()",
            "                    # Find the newly installed Python, hopefully.",
            "                    version = str(version)",
            "                    path_to_python = find_a_system_python(version)",
            "                    try:",
            "                        assert python_version(path_to_python) == version",
            "                    except AssertionError:",
            "                        click.echo(",
            "                            \"{}: The Python you just installed is not available on your {}, apparently.\"",
            "                            \"\".format(",
            "                                crayons.red(\"Warning\", bold=True),",
            "                                crayons.normal(\"PATH\", bold=True),",
            "                            ),",
            "                            err=True,",
            "                        )",
            "                        sys.exit(1)",
            "    return path_to_python",
            "",
            "",
            "def ensure_virtualenv(project, three=None, python=None, site_packages=None, pypi_mirror=None):",
            "    \"\"\"Creates a virtualenv, if one doesn't exist.\"\"\"",
            "",
            "    def abort():",
            "        sys.exit(1)",
            "",
            "    if not project.virtualenv_exists:",
            "        try:",
            "            # Ensure environment variables are set properly.",
            "            ensure_environment()",
            "            # Ensure Python is available.",
            "            python = ensure_python(project, three=three, python=python)",
            "            if python is not None and not isinstance(python, str):",
            "                python = python.path.as_posix()",
            "            # Create the virtualenv.",
            "            # Abort if --system (or running in a virtualenv).",
            "            if project.s.PIPENV_USE_SYSTEM:",
            "                click.echo(",
            "                    crayons.red(",
            "                        \"You are attempting to re\u2013create a virtualenv that \"",
            "                        \"Pipenv did not create. Aborting.\"",
            "                    )",
            "                )",
            "                sys.exit(1)",
            "            do_create_virtualenv(",
            "                project, python=python, site_packages=site_packages, pypi_mirror=pypi_mirror",
            "            )",
            "        except KeyboardInterrupt:",
            "            # If interrupted, cleanup the virtualenv.",
            "            cleanup_virtualenv(project, bare=False)",
            "            sys.exit(1)",
            "    # If --three, --two, or --python were passed...",
            "    elif (python) or (three is not None) or (site_packages is not None):",
            "        project.s.USING_DEFAULT_PYTHON = False",
            "        # Ensure python is installed before deleting existing virtual env",
            "        python = ensure_python(project, three=three, python=python)",
            "        if python is not None and not isinstance(python, str):",
            "            python = python.path.as_posix()",
            "",
            "        click.echo(crayons.red(\"Virtualenv already exists!\"), err=True)",
            "        # If VIRTUAL_ENV is set, there is a possibility that we are",
            "        # going to remove the active virtualenv that the user cares",
            "        # about, so confirm first.",
            "        if \"VIRTUAL_ENV\" in os.environ:",
            "            if not (",
            "                project.s.PIPENV_YES or click.confirm(\"Remove existing virtualenv?\", default=True)",
            "            ):",
            "                abort()",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Removing existing virtualenv...\"), bold=True), err=True",
            "        )",
            "        # Remove the virtualenv.",
            "        cleanup_virtualenv(project, bare=True)",
            "        # Call this function again.",
            "        ensure_virtualenv(",
            "            project,",
            "            three=three,",
            "            python=python,",
            "            site_packages=site_packages,",
            "            pypi_mirror=pypi_mirror,",
            "        )",
            "",
            "",
            "def ensure_project(",
            "    project,",
            "    three=None,",
            "    python=None,",
            "    validate=True,",
            "    system=False,",
            "    warn=True,",
            "    site_packages=None,",
            "    deploy=False,",
            "    skip_requirements=False,",
            "    pypi_mirror=None,",
            "    clear=False,",
            "):",
            "    \"\"\"Ensures both Pipfile and virtualenv exist for the project.\"\"\"",
            "",
            "    # Automatically use an activated virtualenv.",
            "    if project.s.PIPENV_USE_SYSTEM:",
            "        system = True",
            "    if not project.pipfile_exists and deploy:",
            "        raise exceptions.PipfileNotFound",
            "    # Skip virtualenv creation when --system was used.",
            "    if not system:",
            "        ensure_virtualenv(",
            "            project,",
            "            three=three,",
            "            python=python,",
            "            site_packages=site_packages,",
            "            pypi_mirror=pypi_mirror,",
            "        )",
            "        if warn:",
            "            # Warn users if they are using the wrong version of Python.",
            "            if project.required_python_version:",
            "                path_to_python = project._which(\"python\") or project._which(\"py\")",
            "                if path_to_python and project.required_python_version not in (",
            "                    python_version(path_to_python) or \"\"",
            "                ):",
            "                    click.echo(",
            "                        \"{}: Your Pipfile requires {} {}, \"",
            "                        \"but you are using {} ({}).\".format(",
            "                            crayons.red(\"Warning\", bold=True),",
            "                            crayons.normal(\"python_version\", bold=True),",
            "                            crayons.cyan(project.required_python_version),",
            "                            crayons.cyan(python_version(path_to_python) or \"unknown\"),",
            "                            crayons.green(shorten_path(path_to_python)),",
            "                        ),",
            "                        err=True,",
            "                    )",
            "                    click.echo(",
            "                        \"  {} and rebuilding the virtual environment \"",
            "                        \"may resolve the issue.\".format(crayons.green(\"$ pipenv --rm\")),",
            "                        err=True,",
            "                    )",
            "                    if not deploy:",
            "                        click.echo(",
            "                            \"  {} will surely fail.\"",
            "                            \"\".format(crayons.yellow(\"$ pipenv check\")),",
            "                            err=True,",
            "                        )",
            "                    else:",
            "                        raise exceptions.DeployException",
            "    # Ensure the Pipfile exists.",
            "    ensure_pipfile(",
            "        project, validate=validate, skip_requirements=skip_requirements, system=system",
            "    )",
            "",
            "",
            "def shorten_path(location, bold=False):",
            "    \"\"\"Returns a visually shorter representation of a given system path.\"\"\"",
            "    original = location",
            "    short = os.sep.join(",
            "        [s[0] if len(s) > (len(\"2long4\")) else s for s in location.split(os.sep)]",
            "    )",
            "    short = short.split(os.sep)",
            "    short[-1] = original.split(os.sep)[-1]",
            "    if bold:",
            "        short[-1] = str(crayons.normal(short[-1], bold=True))",
            "    return os.sep.join(short)",
            "",
            "",
            "# return short",
            "def do_where(project, virtualenv=False, bare=True):",
            "    \"\"\"Executes the where functionality.\"\"\"",
            "    if not virtualenv:",
            "        if not project.pipfile_exists:",
            "            click.echo(",
            "                \"No Pipfile present at project home. Consider running \"",
            "                \"{} first to automatically generate a Pipfile for you.\"",
            "                \"\".format(crayons.green(\"`pipenv install`\")),",
            "                err=True,",
            "            )",
            "            return",
            "        location = project.pipfile_location",
            "        # Shorten the virtual display of the path to the virtualenv.",
            "        if not bare:",
            "            location = shorten_path(location)",
            "            click.echo(",
            "                \"Pipfile found at {}.\\n  Considering this to be the project home.\"",
            "                \"\".format(crayons.green(location)),",
            "                err=True,",
            "            )",
            "        else:",
            "            click.echo(project.project_directory)",
            "    else:",
            "        location = project.virtualenv_location",
            "        if not bare:",
            "            click.echo(",
            "                f\"Virtualenv location: {crayons.green(location)}\", err=True",
            "            )",
            "        else:",
            "            click.echo(location)",
            "",
            "",
            "def _cleanup_procs(project, procs, failed_deps_queue, retry=True):",
            "    while not procs.empty():",
            "        c = procs.get()",
            "        try:",
            "            out, err = c.communicate()",
            "        except AttributeError:",
            "            out, err = c.stdout, c.stderr",
            "        failed = c.returncode != 0",
            "        if \"Ignoring\" in out:",
            "            click.echo(crayons.yellow(out.strip()))",
            "        elif project.s.is_verbose():",
            "            click.echo(crayons.cyan(out.strip() or err.strip()))",
            "        # The Installation failed...",
            "        if failed:",
            "            # If there is a mismatch in installed locations or the install fails",
            "            # due to wrongful disabling of pep517, we should allow for",
            "            # additional passes at installation",
            "            if \"does not match installed location\" in err:",
            "                project.environment.expand_egg_links()",
            "                click.echo(\"{}\".format(",
            "                    crayons.yellow(",
            "                        \"Failed initial installation: Failed to overwrite existing \"",
            "                        \"package, likely due to path aliasing. Expanding and trying \"",
            "                        \"again!\"",
            "                    )",
            "                ))",
            "                dep = c.dep.copy()",
            "                dep.use_pep517 = True",
            "            elif \"Disabling PEP 517 processing is invalid\" in err:",
            "                dep = c.dep.copy()",
            "                dep.use_pep517 = True",
            "            elif not retry:",
            "                # The Installation failed...",
            "                # We echo both c.stdout and c.stderr because pip returns error details on out.",
            "                err = err.strip().splitlines() if err else []",
            "                out = out.strip().splitlines() if out else []",
            "                err_lines = [line for message in [out, err] for line in message]",
            "                # Return the subprocess' return code.",
            "                raise exceptions.InstallError(c.dep.name, extra=err_lines)",
            "            else:",
            "                # Alert the user.",
            "                dep = c.dep.copy()",
            "                dep.use_pep517 = False",
            "                click.echo(",
            "                    \"{} {}! Will try again.\".format(",
            "                        crayons.red(\"An error occurred while installing\"),",
            "                        crayons.green(dep.as_line()),",
            "                    ), err=True",
            "                )",
            "            # Save the Failed Dependency for later.",
            "            failed_deps_queue.put(dep)",
            "",
            "",
            "def batch_install(project, deps_list, procs, failed_deps_queue,",
            "                  requirements_dir, no_deps=True, ignore_hashes=False,",
            "                  allow_global=False, blocking=False, pypi_mirror=None,",
            "                  retry=True, sequential_deps=None):",
            "    from .vendor.requirementslib.models.utils import (",
            "        strip_extras_markers_from_requirement",
            "    )",
            "    if sequential_deps is None:",
            "        sequential_deps = []",
            "    failed = (not retry)",
            "    install_deps = not no_deps",
            "    if not failed:",
            "        label = INSTALL_LABEL if not environments.PIPENV_HIDE_EMOJIS else \"\"",
            "    else:",
            "        label = INSTALL_LABEL2",
            "",
            "    deps_to_install = deps_list[:]",
            "    deps_to_install.extend(sequential_deps)",
            "    deps_to_install = [",
            "        dep for dep in deps_to_install if not project.environment.is_satisfied(dep)",
            "    ]",
            "    sequential_dep_names = [d.name for d in sequential_deps]",
            "",
            "    deps_list_bar = progress.bar(",
            "        deps_to_install, width=32,",
            "        label=label",
            "    )",
            "",
            "    trusted_hosts = []",
            "    # Install these because",
            "    for dep in deps_list_bar:",
            "        extra_indexes = []",
            "        if dep.req.req:",
            "            dep.req.req = strip_extras_markers_from_requirement(dep.req.req)",
            "        if dep.markers:",
            "            dep.markers = str(strip_extras_markers_from_requirement(dep.get_markers()))",
            "        # Install the module.",
            "        is_artifact = False",
            "        if dep.is_file_or_url and (dep.is_direct_url or any(",
            "            dep.req.uri.endswith(ext) for ext in [\"zip\", \"tar.gz\"]",
            "        )):",
            "            is_artifact = True",
            "        elif dep.is_vcs:",
            "            is_artifact = True",
            "        if not project.s.PIPENV_RESOLVE_VCS and is_artifact and not dep.editable:",
            "            install_deps = True",
            "            no_deps = False",
            "",
            "        with vistir.contextmanagers.temp_environ():",
            "            if not allow_global:",
            "                os.environ[\"PIP_USER\"] = vistir.compat.fs_str(\"0\")",
            "                if \"PYTHONHOME\" in os.environ:",
            "                    del os.environ[\"PYTHONHOME\"]",
            "            if \"GIT_CONFIG\" in os.environ and dep.is_vcs:",
            "                del os.environ[\"GIT_CONFIG\"]",
            "            use_pep517 = True",
            "            if failed and not dep.is_vcs:",
            "                use_pep517 = getattr(dep, \"use_pep517\", False)",
            "",
            "            is_sequential = sequential_deps and dep.name in sequential_dep_names",
            "            is_blocking = any([dep.editable, dep.is_vcs, blocking, is_sequential])",
            "            c = pip_install(",
            "                project,",
            "                dep,",
            "                ignore_hashes=any([ignore_hashes, dep.editable, dep.is_vcs]),",
            "                allow_global=allow_global,",
            "                no_deps=not install_deps,",
            "                block=is_blocking,",
            "                index=dep.index,",
            "                requirements_dir=requirements_dir,",
            "                pypi_mirror=pypi_mirror,",
            "                trusted_hosts=trusted_hosts,",
            "                extra_indexes=extra_indexes,",
            "                use_pep517=use_pep517,",
            "            )",
            "            c.dep = dep",
            "",
            "            procs.put(c)",
            "            if procs.full() or procs.qsize() == len(deps_list) or is_sequential:",
            "                _cleanup_procs(project, procs, failed_deps_queue, retry=retry)",
            "",
            "",
            "def do_install_dependencies(",
            "    project,",
            "    dev=False,",
            "    dev_only=False,",
            "    bare=False,",
            "    emit_requirements=False,",
            "    allow_global=False,",
            "    ignore_hashes=False,",
            "    skip_lock=False,",
            "    concurrent=True,",
            "    requirements_dir=None,",
            "    pypi_mirror=None,",
            "):",
            "    \"\"\"\"",
            "    Executes the install functionality.",
            "",
            "    If emit_requirements is True, simply spits out a requirements format to stdout.",
            "    \"\"\"",
            "",
            "    import queue",
            "    if emit_requirements:",
            "        bare = True",
            "    # Load the lockfile if it exists, or if dev_only is being used.",
            "    if skip_lock or not project.lockfile_exists:",
            "        if not bare:",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Installing dependencies from Pipfile...\"), bold=True)",
            "            )",
            "        # skip_lock should completely bypass the lockfile (broken in 4dac1676)",
            "        lockfile = project.get_or_create_lockfile(from_pipfile=True)",
            "    else:",
            "        lockfile = project.get_or_create_lockfile()",
            "        if not bare:",
            "            click.echo(",
            "                crayons.normal(",
            "                    fix_utf8(\"Installing dependencies from Pipfile.lock ({})...\".format(",
            "                        lockfile[\"_meta\"].get(\"hash\", {}).get(\"sha256\")[-6:]",
            "                    )),",
            "                    bold=True,",
            "                )",
            "            )",
            "    # Allow pip to resolve dependencies when in skip-lock mode.",
            "    no_deps = not skip_lock  # skip_lock true, no_deps False, pip resolves deps",
            "    dev = dev or dev_only",
            "    deps_list = list(lockfile.get_requirements(dev=dev, only=dev_only))",
            "    if emit_requirements:",
            "        index_args = prepare_pip_source_args(",
            "            get_source_list(project, pypi_mirror=pypi_mirror)",
            "        )",
            "        index_args = \" \".join(index_args).replace(\" -\", \"\\n-\")",
            "        deps = [",
            "            req.as_line(sources=False, include_hashes=False) for req in deps_list",
            "        ]",
            "        click.echo(index_args)",
            "        click.echo(\"\\n\".join(sorted(deps)))",
            "        sys.exit(0)",
            "    if concurrent:",
            "        nprocs = project.s.PIPENV_MAX_SUBPROCESS",
            "    else:",
            "        nprocs = 1",
            "    procs = queue.Queue(maxsize=nprocs)",
            "    failed_deps_queue = queue.Queue()",
            "    if skip_lock:",
            "        ignore_hashes = True",
            "    editable_or_vcs_deps = [dep for dep in deps_list if (dep.editable or dep.vcs)]",
            "    normal_deps = [dep for dep in deps_list if not (dep.editable or dep.vcs)]",
            "    install_kwargs = {",
            "        \"no_deps\": no_deps, \"ignore_hashes\": ignore_hashes, \"allow_global\": allow_global,",
            "        \"blocking\": not concurrent, \"pypi_mirror\": pypi_mirror,",
            "        \"sequential_deps\": editable_or_vcs_deps",
            "    }",
            "",
            "    batch_install(",
            "        project, normal_deps, procs, failed_deps_queue, requirements_dir, **install_kwargs",
            "    )",
            "",
            "    if not procs.empty():",
            "        _cleanup_procs(project, procs, failed_deps_queue)",
            "",
            "    # click.echo(crayons.normal(",
            "    #     decode_for_output(\"Installing editable and vcs dependencies...\"), bold=True",
            "    # ))",
            "",
            "    # install_kwargs.update({\"blocking\": True})",
            "    # # XXX: All failed and editable/vcs deps should be installed in sequential mode!",
            "    # procs = queue.Queue(maxsize=1)",
            "    # batch_install(",
            "    #     editable_or_vcs_deps, procs, failed_deps_queue, requirements_dir,",
            "    #     **install_kwargs",
            "    # )",
            "",
            "    # Iterate over the hopefully-poorly-packaged dependencies...",
            "    if not failed_deps_queue.empty():",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Installing initially failed dependencies...\"), bold=True)",
            "        )",
            "        retry_list = []",
            "        while not failed_deps_queue.empty():",
            "            failed_dep = failed_deps_queue.get()",
            "            retry_list.append(failed_dep)",
            "        install_kwargs.update({\"retry\": False})",
            "        batch_install(",
            "            project, retry_list, procs, failed_deps_queue, requirements_dir, **install_kwargs",
            "        )",
            "    if not procs.empty():",
            "        _cleanup_procs(project, procs, failed_deps_queue, retry=False)",
            "",
            "",
            "def convert_three_to_python(three, python):",
            "    \"\"\"Converts a Three flag into a Python flag, and raises customer warnings",
            "    in the process, if needed.",
            "    \"\"\"",
            "    if not python:",
            "        if three is False:",
            "            return \"2\"",
            "",
            "        elif three is True:",
            "            return \"3\"",
            "",
            "    else:",
            "        return python",
            "",
            "",
            "def do_create_virtualenv(project, python=None, site_packages=None, pypi_mirror=None):",
            "    \"\"\"Creates a virtualenv.\"\"\"",
            "",
            "    click.echo(",
            "        crayons.normal(fix_utf8(\"Creating a virtualenv for this project...\"), bold=True), err=True",
            "    )",
            "    click.echo(",
            "        f\"Pipfile: {crayons.yellow(project.pipfile_location, bold=True)}\",",
            "        err=True,",
            "    )",
            "",
            "    # Default to using sys.executable, if Python wasn't provided.",
            "    using_string = \"Using\"",
            "    if not python:",
            "        python = sys.executable",
            "        using_string = \"Using default python from\"",
            "    click.echo(",
            "        \"{0} {1} {3} {2}\".format(",
            "            crayons.normal(using_string, bold=True),",
            "            crayons.yellow(python, bold=True),",
            "            crayons.normal(fix_utf8(\"to create virtualenv...\"), bold=True),",
            "            crayons.green(f\"({python_version(python)})\"),",
            "        ),",
            "        err=True,",
            "    )",
            "",
            "    cmd = [",
            "        Path(sys.executable).absolute().as_posix(),",
            "        \"-m\",",
            "        \"virtualenv\",",
            "        f\"--prompt={project.name}\",",
            "        f\"--python={python}\",",
            "        project.get_location_for_virtualenv(),",
            "    ]",
            "",
            "    # Pass site-packages flag to virtualenv, if desired...",
            "    if site_packages:",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Making site-packages available...\"), bold=True), err=True",
            "        )",
            "        cmd.append(\"--system-site-packages\")",
            "",
            "    if pypi_mirror:",
            "        pip_config = {\"PIP_INDEX_URL\": vistir.misc.fs_str(pypi_mirror)}",
            "    else:",
            "        pip_config = {}",
            "",
            "    # Actually create the virtualenv.",
            "    error = None",
            "    with create_spinner(\"Creating virtual environment...\", project.s) as sp:",
            "        c = subprocess_run(cmd, env=pip_config)",
            "        click.echo(crayons.cyan(f\"{c.stdout}\"), err=True)",
            "        if c.returncode != 0:",
            "            error = c.stderr if project.s.is_verbose() else exceptions.prettify_exc(c.stderr)",
            "            sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Failed creating virtual environment\"))",
            "        else:",
            "            sp.green.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Successfully created virtual environment!\"))",
            "    if error is not None:",
            "        raise exceptions.VirtualenvCreationException(",
            "            extra=crayons.red(f\"{error}\")",
            "        )",
            "",
            "    # Associate project directory with the environment.",
            "    # This mimics Pew's \"setproject\".",
            "    project_file_name = os.path.join(project.virtualenv_location, \".project\")",
            "    with open(project_file_name, \"w\") as f:",
            "        f.write(vistir.misc.fs_str(project.project_directory))",
            "    from .environment import Environment",
            "    sources = project.pipfile_sources",
            "    # project.get_location_for_virtualenv is only for if we are creating a new virtualenv",
            "    # whereas virtualenv_location is for the current path to the runtime",
            "    project._environment = Environment(",
            "        prefix=project.virtualenv_location,",
            "        is_venv=True,",
            "        sources=sources,",
            "        pipfile=project.parsed_pipfile,",
            "        project=project",
            "    )",
            "    project._environment.add_dist(\"pipenv\")",
            "    # Say where the virtualenv is.",
            "    do_where(project, virtualenv=True, bare=False)",
            "",
            "",
            "def parse_download_fname(fname, name):",
            "    fname, fextension = os.path.splitext(fname)",
            "    if fextension == \".whl\":",
            "        fname = \"-\".join(fname.split(\"-\")[:-3])",
            "    if fname.endswith(\".tar\"):",
            "        fname, _ = os.path.splitext(fname)",
            "    # Substring out package name (plus dash) from file name to get version.",
            "    version = fname[len(name) + 1 :]",
            "    # Ignore implicit post releases in version number.",
            "    if \"-\" in version and version.split(\"-\")[1].isdigit():",
            "        version = version.split(\"-\")[0]",
            "    return version",
            "",
            "",
            "def get_downloads_info(project, names_map, section):",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    info = []",
            "    p = project.parsed_pipfile",
            "    for fname in os.listdir(project.download_location):",
            "        # Get name from filename mapping.",
            "        name = Requirement.from_line(names_map[fname]).name",
            "        # Get the version info from the filenames.",
            "        version = parse_download_fname(fname, name)",
            "        # Get the hash of each file.",
            "        cmd = [",
            "            which_pip(project),",
            "            \"hash\",",
            "            os.sep.join([project.download_location, fname]),",
            "        ]",
            "        c = subprocess_run(cmd)",
            "        hash = c.stdout.split(\"--hash=\")[1].strip()",
            "        # Verify we're adding the correct version from Pipfile",
            "        # and not one from a dependency.",
            "        specified_version = p[section].get(name, \"\")",
            "        if is_required_version(version, specified_version):",
            "            info.append(dict(name=name, version=version, hash=hash))",
            "    return info",
            "",
            "",
            "def overwrite_dev(prod, dev):",
            "    dev_keys = set(list(dev.keys()))",
            "    prod_keys = set(list(prod.keys()))",
            "    for pkg in dev_keys & prod_keys:",
            "        dev[pkg] = prod[pkg]",
            "    return dev",
            "",
            "",
            "def do_lock(",
            "    project,",
            "    ctx=None,",
            "    system=False,",
            "    clear=False,",
            "    pre=False,",
            "    keep_outdated=False,",
            "    write=True,",
            "    pypi_mirror=None,",
            "):",
            "    \"\"\"Executes the freeze functionality.\"\"\"",
            "",
            "    cached_lockfile = {}",
            "    if not pre:",
            "        pre = project.settings.get(\"allow_prereleases\")",
            "    if keep_outdated:",
            "        if not project.lockfile_exists:",
            "            raise exceptions.PipenvOptionsError(",
            "                \"--keep-outdated\", ctx=ctx,",
            "                message=\"Pipfile.lock must exist to use --keep-outdated!\"",
            "            )",
            "        cached_lockfile = project.lockfile_content",
            "    # Create the lockfile.",
            "    lockfile = project._lockfile",
            "    # Cleanup lockfile.",
            "    for section in (\"default\", \"develop\"):",
            "        for k, v in lockfile[section].copy().items():",
            "            if not hasattr(v, \"keys\"):",
            "                del lockfile[section][k]",
            "    # Ensure that develop inherits from default.",
            "    dev_packages = project.dev_packages.copy()",
            "    dev_packages = overwrite_dev(project.packages, dev_packages)",
            "    # Resolve dev-package dependencies, with pip-tools.",
            "    for is_dev in [True, False]:",
            "        pipfile_section = \"dev-packages\" if is_dev else \"packages\"",
            "        if project.pipfile_exists:",
            "            packages = project.parsed_pipfile.get(pipfile_section, {})",
            "        else:",
            "            packages = getattr(project, pipfile_section.replace(\"-\", \"_\"))",
            "",
            "        if write:",
            "            # Alert the user of progress.",
            "            click.echo(",
            "                \"{} {} {}\".format(",
            "                    crayons.normal(\"Locking\"),",
            "                    crayons.yellow(\"[{}]\".format(pipfile_section.replace(\"_\", \"-\"))),",
            "                    crayons.normal(fix_utf8(\"dependencies...\")),",
            "                ),",
            "                err=True,",
            "            )",
            "",
            "        # Mutates the lockfile",
            "        venv_resolve_deps(",
            "            packages,",
            "            which=project._which,",
            "            project=project,",
            "            dev=is_dev,",
            "            clear=clear,",
            "            pre=pre,",
            "            allow_global=system,",
            "            pypi_mirror=pypi_mirror,",
            "            pipfile=packages,",
            "            lockfile=lockfile,",
            "            keep_outdated=keep_outdated",
            "        )",
            "",
            "    # Support for --keep-outdated...",
            "    if keep_outdated:",
            "        from pipenv.vendor.packaging.utils import canonicalize_name",
            "        for section_name, section in (",
            "            (\"default\", project.packages),",
            "            (\"develop\", project.dev_packages),",
            "        ):",
            "            for package_specified in section.keys():",
            "                if not is_pinned(section[package_specified]):",
            "                    canonical_name = canonicalize_name(package_specified)",
            "                    if canonical_name in cached_lockfile[section_name]:",
            "                        lockfile[section_name][canonical_name] = cached_lockfile[",
            "                            section_name",
            "                        ][canonical_name].copy()",
            "            for key in [\"default\", \"develop\"]:",
            "                packages = set(cached_lockfile[key].keys())",
            "                new_lockfile = set(lockfile[key].keys())",
            "                missing = packages - new_lockfile",
            "                for missing_pkg in missing:",
            "                    lockfile[key][missing_pkg] = cached_lockfile[key][missing_pkg].copy()",
            "    # Overwrite any develop packages with default packages.",
            "    lockfile[\"develop\"].update(overwrite_dev(lockfile.get(\"default\", {}), lockfile[\"develop\"]))",
            "    if write:",
            "        project.write_lockfile(lockfile)",
            "        click.echo(",
            "            \"{}\".format(",
            "                crayons.normal(",
            "                    \"Updated Pipfile.lock ({})!\".format(",
            "                        lockfile[\"_meta\"].get(\"hash\", {}).get(\"sha256\")[-6:]",
            "                    ),",
            "                    bold=True,",
            "                )",
            "            ),",
            "            err=True,",
            "        )",
            "    else:",
            "        return lockfile",
            "",
            "",
            "def do_purge(project, bare=False, downloads=False, allow_global=False):",
            "    \"\"\"Executes the purge functionality.\"\"\"",
            "",
            "    if downloads:",
            "        if not bare:",
            "            click.echo(crayons.normal(fix_utf8(\"Clearing out downloads directory...\"), bold=True))",
            "        vistir.path.rmtree(project.download_location)",
            "        return",
            "",
            "    # Remove comments from the output, if any.",
            "    installed = {",
            "        pep423_name(pkg.project_name) for pkg in project.environment.get_installed_packages()",
            "    }",
            "    bad_pkgs = {pep423_name(pkg) for pkg in BAD_PACKAGES}",
            "    # Remove setuptools, pip, etc from targets for removal",
            "    to_remove = installed - bad_pkgs",
            "",
            "    # Skip purging if there is no packages which needs to be removed",
            "    if not to_remove:",
            "        if not bare:",
            "            click.echo(\"Found 0 installed package, skip purging.\")",
            "            click.echo(crayons.green(\"Environment now purged and fresh!\"))",
            "        return installed",
            "",
            "    if not bare:",
            "        click.echo(",
            "            fix_utf8(f\"Found {len(to_remove)} installed package(s), purging...\")",
            "        )",
            "",
            "    command = [",
            "        which_pip(project, allow_global=allow_global),",
            "        \"uninstall\", \"-y\",",
            "    ] + list(to_remove)",
            "    if project.s.is_verbose():",
            "        click.echo(f\"$ {cmd_list_to_shell(command)}\")",
            "    c = subprocess_run(command)",
            "    if c.returncode != 0:",
            "        raise exceptions.UninstallError(installed, cmd_list_to_shell(command), c.stdout + c.stderr, c.returncode)",
            "    if not bare:",
            "        click.echo(crayons.cyan(c.stdout))",
            "        click.echo(crayons.green(\"Environment now purged and fresh!\"))",
            "    return installed",
            "",
            "",
            "def do_init(",
            "    project,",
            "    dev=False,",
            "    dev_only=False,",
            "    emit_requirements=False,",
            "    allow_global=False,",
            "    ignore_pipfile=False,",
            "    skip_lock=False,",
            "    system=False,",
            "    concurrent=True,",
            "    deploy=False,",
            "    pre=False,",
            "    keep_outdated=False,",
            "    requirements_dir=None,",
            "    pypi_mirror=None,",
            "):",
            "    \"\"\"Executes the init functionality.\"\"\"",
            "",
            "    python = None",
            "    if project.s.PIPENV_PYTHON is not None:",
            "        python = project.s.PIPENV_PYTHON",
            "    elif project.s.PIPENV_DEFAULT_PYTHON_VERSION is not None:",
            "        python = project.s.PIPENV_DEFAULT_PYTHON_VERSION",
            "",
            "    if not system and not project.s.PIPENV_USE_SYSTEM:",
            "        if not project.virtualenv_exists:",
            "            try:",
            "                do_create_virtualenv(project, python=python, three=None, pypi_mirror=pypi_mirror)",
            "            except KeyboardInterrupt:",
            "                cleanup_virtualenv(project, bare=False)",
            "                sys.exit(1)",
            "    # Ensure the Pipfile exists.",
            "    if not deploy:",
            "        ensure_pipfile(project, system=system)",
            "    if not requirements_dir:",
            "        requirements_dir = vistir.path.create_tracked_tempdir(",
            "            suffix=\"-requirements\", prefix=\"pipenv-\"",
            "        )",
            "    # Write out the lockfile if it doesn't exist, but not if the Pipfile is being ignored",
            "    if (project.lockfile_exists and not ignore_pipfile) and not skip_lock:",
            "        old_hash = project.get_lockfile_hash()",
            "        new_hash = project.calculate_pipfile_hash()",
            "        if new_hash != old_hash:",
            "            if deploy:",
            "                click.echo(",
            "                    crayons.red(",
            "                        \"Your Pipfile.lock ({}) is out of date. Expected: ({}).\".format(",
            "                            old_hash[-6:], new_hash[-6:]",
            "                        )",
            "                    )",
            "                )",
            "                raise exceptions.DeployException",
            "                sys.exit(1)",
            "            elif (system or allow_global) and not (project.s.PIPENV_VIRTUALENV):",
            "                click.echo(",
            "                    crayons.yellow(fix_utf8(",
            "                        \"Pipfile.lock ({}) out of date, but installation \"",
            "                        \"uses {} re-building lockfile must happen in \"",
            "                        \"isolation. Please rebuild lockfile in a virtualenv. \"",
            "                        \"Continuing anyway...\".format(",
            "                            old_hash[-6:], \"--system\"",
            "                        ))",
            "                    ),",
            "                    err=True,",
            "                )",
            "            else:",
            "                if old_hash:",
            "                    msg = fix_utf8(\"Pipfile.lock ({0}) out of date, updating to ({1})...\")",
            "                else:",
            "                    msg = fix_utf8(\"Pipfile.lock is corrupted, replaced with ({1})...\")",
            "                click.echo(",
            "                    crayons.yellow(msg.format(old_hash[-6:], new_hash[-6:]), bold=True),",
            "                    err=True,",
            "                )",
            "                do_lock(",
            "                    project,",
            "                    system=system,",
            "                    pre=pre,",
            "                    keep_outdated=keep_outdated,",
            "                    write=True,",
            "                    pypi_mirror=pypi_mirror,",
            "                )",
            "    # Write out the lockfile if it doesn't exist.",
            "    if not project.lockfile_exists and not skip_lock:",
            "        # Unless we're in a virtualenv not managed by pipenv, abort if we're",
            "        # using the system's python.",
            "        if (system or allow_global) and not (project.s.PIPENV_VIRTUALENV):",
            "            raise exceptions.PipenvOptionsError(",
            "                \"--system\",",
            "                \"--system is intended to be used for Pipfile installation, \"",
            "                \"not installation of specific packages. Aborting.\\n\"",
            "                \"See also: --deploy flag.\"",
            "            )",
            "        else:",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Pipfile.lock not found, creating...\"), bold=True),",
            "                err=True,",
            "            )",
            "            do_lock(",
            "                project,",
            "                system=system,",
            "                pre=pre,",
            "                keep_outdated=keep_outdated,",
            "                write=True,",
            "                pypi_mirror=pypi_mirror,",
            "            )",
            "    do_install_dependencies(",
            "        project,",
            "        dev=dev,",
            "        dev_only=dev_only,",
            "        emit_requirements=emit_requirements,",
            "        allow_global=allow_global,",
            "        skip_lock=skip_lock,",
            "        concurrent=concurrent,",
            "        requirements_dir=requirements_dir,",
            "        pypi_mirror=pypi_mirror,",
            "    )",
            "",
            "    # Hint the user what to do to activate the virtualenv.",
            "    if not allow_global and not deploy and \"PIPENV_ACTIVE\" not in os.environ:",
            "        click.echo(",
            "            \"To activate this project's virtualenv, run {}.\\n\"",
            "            \"Alternatively, run a command \"",
            "            \"inside the virtualenv with {}.\".format(",
            "                crayons.yellow(\"pipenv shell\"), crayons.yellow(\"pipenv run\")",
            "            )",
            "        )",
            "",
            "",
            "def get_pip_args(",
            "    project,",
            "    pre=False,  # type: bool",
            "    verbose=False,  # type: bool",
            "    upgrade=False,  # type: bool",
            "    require_hashes=False,  # type: bool",
            "    no_build_isolation=False,  # type: bool",
            "    no_use_pep517=False,  # type: bool",
            "    no_deps=False,  # type: bool",
            "    selective_upgrade=False,  # type: bool",
            "    src_dir=None,  # type: Optional[str]",
            "):",
            "    # type: (...) -> List[str]",
            "    from .vendor.packaging.version import parse as parse_version",
            "    arg_map = {",
            "        \"pre\": [\"--pre\"],",
            "        \"verbose\": [\"--verbose\"],",
            "        \"upgrade\": [\"--upgrade\"],",
            "        \"require_hashes\": [\"--require-hashes\"],",
            "        \"no_build_isolation\": [\"--no-build-isolation\"],",
            "        \"no_use_pep517\": [],",
            "        \"no_deps\": [\"--no-deps\"],",
            "        \"selective_upgrade\": [",
            "            \"--upgrade-strategy=only-if-needed\",",
            "            \"--exists-action={}\".format(project.s.PIP_EXISTS_ACTION or \"i\")",
            "        ],",
            "        \"src_dir\": src_dir,",
            "    }",
            "    if project.environment.pip_version >= parse_version(\"19.0\"):",
            "        arg_map[\"no_use_pep517\"].append(\"--no-use-pep517\")",
            "    if project.environment.pip_version < parse_version(\"19.1\"):",
            "        arg_map[\"no_use_pep517\"].append(\"--no-build-isolation\")",
            "    arg_set = []",
            "    for key in arg_map.keys():",
            "        if key in locals() and locals().get(key):",
            "            arg_set.extend(arg_map.get(key))",
            "        elif key == \"selective_upgrade\" and not locals().get(key):",
            "            arg_set.append(\"--exists-action=i\")",
            "    return list(vistir.misc.dedup(arg_set))",
            "",
            "",
            "def get_requirement_line(",
            "    requirement,  # type: Requirement",
            "    src_dir=None,  # type: Optional[str]",
            "    include_hashes=True,  # type: bool",
            "    format_for_file=False,  # type: bool",
            "):",
            "    # type: (...) -> Union[List[str], str]",
            "    line = None",
            "    if requirement.vcs or requirement.is_file_or_url:",
            "        if src_dir and requirement.line_instance.wheel_kwargs:",
            "            requirement.line_instance._wheel_kwargs.update({",
            "                \"src_dir\": src_dir",
            "            })",
            "        requirement.line_instance.vcsrepo",
            "        line = requirement.line_instance.line",
            "        if requirement.line_instance.markers:",
            "            line = f'{line}; {requirement.line_instance.markers}'",
            "            if not format_for_file:",
            "                line = f'\"{line}\"'",
            "        if requirement.editable:",
            "            if not format_for_file:",
            "                return [\"-e\", line]",
            "            return f'-e {line}'",
            "        if not format_for_file:",
            "            return [line]",
            "        return line",
            "    return requirement.as_line(include_hashes=include_hashes, as_list=not format_for_file)",
            "",
            "",
            "def write_requirement_to_file(",
            "    project,  # type: Project",
            "    requirement,  # type: Requirement",
            "    requirements_dir=None,  # type: Optional[str]",
            "    src_dir=None,  # type: Optional[str]",
            "    include_hashes=True  # type: bool",
            "):",
            "    # type: (...) -> str",
            "    if not requirements_dir:",
            "        requirements_dir = vistir.path.create_tracked_tempdir(",
            "            prefix=\"pipenv\", suffix=\"requirements\")",
            "    line = requirement.line_instance.get_line(",
            "        with_prefix=True, with_hashes=include_hashes, with_markers=True, as_list=False",
            "    )",
            "",
            "    f = vistir.compat.NamedTemporaryFile(",
            "        prefix=\"pipenv-\", suffix=\"-requirement.txt\", dir=requirements_dir,",
            "        delete=False",
            "    )",
            "    if project.s.is_verbose():",
            "        click.echo(",
            "            f\"Writing supplied requirement line to temporary file: {line!r}\",",
            "            err=True",
            "        )",
            "    f.write(vistir.misc.to_bytes(line))",
            "    r = f.name",
            "    f.close()",
            "    return r",
            "",
            "",
            "def pip_install(",
            "    project,",
            "    requirement=None,",
            "    r=None,",
            "    allow_global=False,",
            "    ignore_hashes=False,",
            "    no_deps=None,",
            "    block=True,",
            "    index=None,",
            "    pre=False,",
            "    selective_upgrade=False,",
            "    requirements_dir=None,",
            "    extra_indexes=None,",
            "    pypi_mirror=None,",
            "    trusted_hosts=None,",
            "    use_pep517=True",
            "):",
            "    piplogger = logging.getLogger(\"pipenv.patched.notpip._internal.commands.install\")",
            "    src_dir = None",
            "    if not trusted_hosts:",
            "        trusted_hosts = []",
            "",
            "    trusted_hosts.extend(os.environ.get(\"PIP_TRUSTED_HOSTS\", []))",
            "    if not allow_global:",
            "        src_dir = os.getenv(\"PIP_SRC\", os.getenv(\"PIP_SRC_DIR\", project.virtualenv_src_location))",
            "    else:",
            "        src_dir = os.getenv(\"PIP_SRC\", os.getenv(\"PIP_SRC_DIR\"))",
            "    if requirement:",
            "        if requirement.editable or not requirement.hashes:",
            "            ignore_hashes = True",
            "        elif not (requirement.is_vcs or requirement.editable or requirement.vcs):",
            "            ignore_hashes = False",
            "    line = None",
            "    # Try installing for each source in project.sources.",
            "    if not index and requirement.index:",
            "        index = requirement.index",
            "    if index and not extra_indexes:",
            "        extra_indexes = list(project.sources)",
            "    if requirement and requirement.vcs or requirement.editable:",
            "        requirement.index = None",
            "        # Install dependencies when a package is a non-editable VCS dependency.",
            "        # Don't specify a source directory when using --system.",
            "        if not requirement.editable and no_deps is not True:",
            "            # Leave this off becauase old lockfiles don't have all deps included",
            "            # TODO: When can it be turned back on?",
            "            no_deps = False",
            "        elif requirement.editable and no_deps is None:",
            "            no_deps = True",
            "",
            "    r = write_requirement_to_file(",
            "        project, requirement, requirements_dir=requirements_dir, src_dir=src_dir,",
            "        include_hashes=not ignore_hashes",
            "    )",
            "    sources = get_source_list(",
            "        project, index, extra_indexes=extra_indexes, trusted_hosts=trusted_hosts,",
            "        pypi_mirror=pypi_mirror",
            "    )",
            "    if r:",
            "        with open(r, \"r\") as fh:",
            "            if \"--hash\" not in fh.read():",
            "                ignore_hashes = True",
            "    if project.s.is_verbose():",
            "        piplogger.setLevel(logging.WARN)",
            "        if requirement:",
            "            click.echo(",
            "                crayons.normal(f\"Installing {requirement.name!r}\", bold=True),",
            "                err=True,",
            "            )",
            "",
            "    pip_command = [project._which(\"python\", allow_global=allow_global), \"-m\", \"pip\", \"install\"]",
            "    pip_args = get_pip_args(",
            "        project, pre=pre, verbose=project.s.is_verbose(), upgrade=True,",
            "        selective_upgrade=selective_upgrade, no_use_pep517=not use_pep517,",
            "        no_deps=no_deps, require_hashes=not ignore_hashes,",
            "    )",
            "    pip_command.extend(pip_args)",
            "    if r:",
            "        pip_command.extend([\"-r\", vistir.path.normalize_path(r)])",
            "    elif line:",
            "        pip_command.extend(line)",
            "    pip_command.extend(prepare_pip_source_args(sources))",
            "    if project.s.is_verbose():",
            "        click.echo(f\"$ {cmd_list_to_shell(pip_command)}\", err=True)",
            "    cache_dir = Path(project.s.PIPENV_CACHE_DIR)",
            "    DEFAULT_EXISTS_ACTION = \"w\"",
            "    if selective_upgrade:",
            "        DEFAULT_EXISTS_ACTION = \"i\"",
            "    exists_action = vistir.misc.fs_str(project.s.PIP_EXISTS_ACTION or DEFAULT_EXISTS_ACTION)",
            "    pip_config = {",
            "        \"PIP_CACHE_DIR\": vistir.misc.fs_str(cache_dir.as_posix()),",
            "        \"PIP_WHEEL_DIR\": vistir.misc.fs_str(cache_dir.joinpath(\"wheels\").as_posix()),",
            "        \"PIP_DESTINATION_DIR\": vistir.misc.fs_str(",
            "            cache_dir.joinpath(\"pkgs\").as_posix()",
            "        ),",
            "        \"PIP_EXISTS_ACTION\": exists_action,",
            "        \"PATH\": vistir.misc.fs_str(os.environ.get(\"PATH\")),",
            "    }",
            "    if src_dir:",
            "        if project.s.is_verbose():",
            "            click.echo(f\"Using source directory: {src_dir!r}\", err=True)",
            "        pip_config.update(",
            "            {\"PIP_SRC\": vistir.misc.fs_str(src_dir)}",
            "        )",
            "    c = subprocess_run(pip_command, block=block, env=pip_config)",
            "    c.env = pip_config",
            "    return c",
            "",
            "",
            "def pip_download(project, package_name):",
            "    cache_dir = Path(project.s.PIPENV_CACHE_DIR)",
            "    pip_config = {",
            "        \"PIP_CACHE_DIR\": vistir.misc.fs_str(cache_dir.as_posix()),",
            "        \"PIP_WHEEL_DIR\": vistir.misc.fs_str(cache_dir.joinpath(\"wheels\").as_posix()),",
            "        \"PIP_DESTINATION_DIR\": vistir.misc.fs_str(",
            "            cache_dir.joinpath(\"pkgs\").as_posix()",
            "        ),",
            "    }",
            "    for source in project.sources:",
            "        cmd = [",
            "            which_pip(project),",
            "            \"download\",",
            "            package_name,",
            "            \"-i\", source[\"url\"],",
            "            \"-d\", project.download_location,",
            "        ]",
            "        c = subprocess_run(cmd, env=pip_config)",
            "        if c.returncode == 0:",
            "            break",
            "",
            "    return c",
            "",
            "",
            "def fallback_which(command, location=None, allow_global=False, system=False):",
            "    \"\"\"",
            "    A fallback implementation of the `which` utility command that relies exclusively on",
            "    searching the path for commands.",
            "",
            "    :param str command: The command to search for, optional",
            "    :param str location: The search location to prioritize (prepend to path), defaults to None",
            "    :param bool allow_global: Whether to search the global path, defaults to False",
            "    :param bool system: Whether to use the system python instead of pipenv's python, defaults to False",
            "    :raises ValueError: Raised if no command is provided",
            "    :raises TypeError: Raised if the command provided is not a string",
            "    :return: A path to the discovered command location",
            "    :rtype: str",
            "    \"\"\"",
            "",
            "    from .vendor.pythonfinder import Finder",
            "    if not command:",
            "        raise ValueError(\"fallback_which: Must provide a command to search for...\")",
            "    if not isinstance(command, str):",
            "        raise TypeError(f\"Provided command must be a string, received {command!r}\")",
            "    global_search = system or allow_global",
            "    if location is None:",
            "        global_search = True",
            "    finder = Finder(system=False, global_search=global_search, path=location)",
            "    if is_python_command(command):",
            "        result = find_python(finder, command)",
            "        if result:",
            "            return result",
            "    result = finder.which(command)",
            "    if result:",
            "        return result.path.as_posix()",
            "    return \"\"",
            "",
            "",
            "def which_pip(project, allow_global=False):",
            "    \"\"\"Returns the location of virtualenv-installed pip.\"\"\"",
            "",
            "    location = None",
            "    if \"VIRTUAL_ENV\" in os.environ:",
            "        location = os.environ[\"VIRTUAL_ENV\"]",
            "    if allow_global:",
            "        if location:",
            "            pip = project._which(\"pip\", location=location)",
            "            if pip:",
            "                return pip",
            "",
            "        for p in (\"pip\", \"pip3\", \"pip2\"):",
            "            where = system_which(p)",
            "            if where:",
            "                return where",
            "",
            "    pip = project._which(\"pip\")",
            "    if not pip:",
            "        pip = fallback_which(\"pip\", allow_global=allow_global, location=location)",
            "    return pip",
            "",
            "",
            "def system_which(command, path=None):",
            "    \"\"\"Emulates the system's which. Returns None if not found.\"\"\"",
            "    import shutil",
            "",
            "    result = shutil.which(command, path=path)",
            "    if result is None:",
            "        _which = \"where\" if os.name == \"nt\" else \"which -a\"",
            "        env = {'PATH': path} if path else None",
            "        c = subprocess_run(f\"{_which} {command}\", shell=True, env=env)",
            "        if c.returncode == 127:",
            "            click.echo(",
            "                \"{}: the {} system utility is required for Pipenv to find Python installations properly.\"",
            "                \"\\n  Please install it.\".format(",
            "                    crayons.red(\"Warning\", bold=True), crayons.yellow(_which)",
            "                ),",
            "                err=True,",
            "            )",
            "        if c.returncode == 0:",
            "            result = next(iter(c.stdout.splitlines()), None)",
            "    return result",
            "",
            "",
            "def format_help(help):",
            "    \"\"\"Formats the help string.\"\"\"",
            "    help = help.replace(\"Options:\", str(crayons.normal(\"Options:\", bold=True)))",
            "    help = help.replace(",
            "        \"Usage: pipenv\", str(\"Usage: {}\".format(crayons.normal(\"pipenv\", bold=True)))",
            "    )",
            "    help = help.replace(\"  check\", str(crayons.red(\"  check\", bold=True)))",
            "    help = help.replace(\"  clean\", str(crayons.red(\"  clean\", bold=True)))",
            "    help = help.replace(\"  graph\", str(crayons.red(\"  graph\", bold=True)))",
            "    help = help.replace(\"  install\", str(crayons.magenta(\"  install\", bold=True)))",
            "    help = help.replace(\"  lock\", str(crayons.green(\"  lock\", bold=True)))",
            "    help = help.replace(\"  open\", str(crayons.red(\"  open\", bold=True)))",
            "    help = help.replace(\"  run\", str(crayons.yellow(\"  run\", bold=True)))",
            "    help = help.replace(\"  shell\", str(crayons.yellow(\"  shell\", bold=True)))",
            "    help = help.replace(\"  scripts\", str(crayons.yellow(\"  scripts\", bold=True)))",
            "    help = help.replace(\"  sync\", str(crayons.green(\"  sync\", bold=True)))",
            "    help = help.replace(\"  uninstall\", str(crayons.magenta(\"  uninstall\", bold=True)))",
            "    help = help.replace(\"  update\", str(crayons.green(\"  update\", bold=True)))",
            "    additional_help = \"\"\"",
            "Usage Examples:",
            "   Create a new project using Python 3.7, specifically:",
            "   $ {}",
            "",
            "   Remove project virtualenv (inferred from current directory):",
            "   $ {}",
            "",
            "   Install all dependencies for a project (including dev):",
            "   $ {}",
            "",
            "   Create a lockfile containing pre-releases:",
            "   $ {}",
            "",
            "   Show a graph of your installed dependencies:",
            "   $ {}",
            "",
            "   Check your installed dependencies for security vulnerabilities:",
            "   $ {}",
            "",
            "   Install a local setup.py into your virtual environment/Pipfile:",
            "   $ {}",
            "",
            "   Use a lower-level pip command:",
            "   $ {}",
            "",
            "Commands:\"\"\".format(",
            "        crayons.yellow(\"pipenv --python 3.7\"),",
            "        crayons.yellow(\"pipenv --rm\"),",
            "        crayons.yellow(\"pipenv install --dev\"),",
            "        crayons.yellow(\"pipenv lock --pre\"),",
            "        crayons.yellow(\"pipenv graph\"),",
            "        crayons.yellow(\"pipenv check\"),",
            "        crayons.yellow(\"pipenv install -e .\"),",
            "        crayons.yellow(\"pipenv run pip freeze\"),",
            "    )",
            "    help = help.replace(\"Commands:\", additional_help)",
            "    return help",
            "",
            "",
            "def format_pip_error(error):",
            "    error = error.replace(\"Expected\", str(crayons.green(\"Expected\", bold=True)))",
            "    error = error.replace(\"Got\", str(crayons.red(\"Got\", bold=True)))",
            "    error = error.replace(",
            "        \"THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE\",",
            "        str(",
            "            crayons.red(",
            "                \"THESE PACKAGES DO NOT MATCH THE HASHES FROM Pipfile.lock!\", bold=True",
            "            )",
            "        ),",
            "    )",
            "    error = error.replace(",
            "        \"someone may have tampered with them\",",
            "        str(crayons.red(\"someone may have tampered with them\")),",
            "    )",
            "    error = error.replace(\"option to pip install\", \"option to 'pipenv install'\")",
            "    return error",
            "",
            "",
            "def format_pip_output(out, r=None):",
            "    def gen(out):",
            "        for line in out.split(\"\\n\"):",
            "            # Remove requirements file information from pip9 output.",
            "            if \"(from -r\" in line:",
            "                yield line[: line.index(\"(from -r\")]",
            "",
            "            else:",
            "                yield line",
            "",
            "    out = \"\\n\".join([line for line in gen(out)])",
            "    return out",
            "",
            "",
            "def warn_in_virtualenv(project):",
            "    # Only warn if pipenv isn't already active.",
            "    if environments.is_in_virtualenv() and not project.s.is_quiet():",
            "        click.echo(",
            "            \"{}: Pipenv found itself running within a virtual environment, \"",
            "            \"so it will automatically use that environment, instead of \"",
            "            \"creating its own for any project. You can set \"",
            "            \"{} to force pipenv to ignore that environment and create \"",
            "            \"its own instead. You can set {} to suppress this \"",
            "            \"warning.\".format(",
            "                crayons.green(\"Courtesy Notice\"),",
            "                crayons.normal(\"PIPENV_IGNORE_VIRTUALENVS=1\", bold=True),",
            "                crayons.normal(\"PIPENV_VERBOSITY=-1\", bold=True),",
            "            ),",
            "            err=True,",
            "        )",
            "",
            "",
            "def ensure_lockfile(project, keep_outdated=False, pypi_mirror=None):",
            "    \"\"\"Ensures that the lockfile is up-to-date.\"\"\"",
            "    if not keep_outdated:",
            "        keep_outdated = project.settings.get(\"keep_outdated\")",
            "    # Write out the lockfile if it doesn't exist, but not if the Pipfile is being ignored",
            "    if project.lockfile_exists:",
            "        old_hash = project.get_lockfile_hash()",
            "        new_hash = project.calculate_pipfile_hash()",
            "        if new_hash != old_hash:",
            "            click.echo(",
            "                crayons.yellow(",
            "                    fix_utf8(\"Pipfile.lock ({}) out of date, updating to ({})...\".format(",
            "                        old_hash[-6:], new_hash[-6:]",
            "                    )),",
            "                    bold=True,",
            "                ),",
            "                err=True,",
            "            )",
            "            do_lock(project, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror)",
            "    else:",
            "        do_lock(project, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror)",
            "",
            "",
            "def do_py(project, ctx=None, system=False):",
            "    if not project.virtualenv_exists:",
            "        click.echo(",
            "            \"{}({}){}\".format(",
            "                crayons.red(\"No virtualenv has been created for this project \"),",
            "                crayons.yellow(project.project_directory, bold=True),",
            "                crayons.red(\" yet!\")",
            "            ),",
            "            err=True,",
            "        )",
            "        ctx.abort()",
            "",
            "    try:",
            "        click.echo(project._which(\"python\", allow_global=system))",
            "    except AttributeError:",
            "        click.echo(crayons.red(\"No project found!\"))",
            "",
            "",
            "def do_outdated(project, pypi_mirror=None, pre=False, clear=False):",
            "    # TODO: Allow --skip-lock here?",
            "    from collections import namedtuple",
            "",
            "    from .vendor.packaging.utils import canonicalize_name",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "    from .vendor.requirementslib.models.utils import get_version",
            "    from .vendor.vistir.compat import Mapping",
            "",
            "    packages = {}",
            "    package_info = namedtuple(\"PackageInfo\", [\"name\", \"installed\", \"available\"])",
            "",
            "    installed_packages = project.environment.get_installed_packages()",
            "    outdated_packages = {",
            "        canonicalize_name(pkg.project_name): package_info",
            "        (pkg.project_name, pkg.parsed_version, pkg.latest_version)",
            "        for pkg in project.environment.get_outdated_packages()",
            "    }",
            "    reverse_deps = {",
            "        canonicalize_name(name): deps",
            "        for name, deps in project.environment.reverse_dependencies().items()",
            "    }",
            "    for result in installed_packages:",
            "        dep = Requirement.from_line(str(result.as_requirement()))",
            "        packages.update(dep.as_pipfile())",
            "    updated_packages = {}",
            "    lockfile = do_lock(project, clear=clear, pre=pre, write=False, pypi_mirror=pypi_mirror)",
            "    for section in (\"develop\", \"default\"):",
            "        for package in lockfile[section]:",
            "            try:",
            "                updated_packages[package] = lockfile[section][package][\"version\"]",
            "            except KeyError:",
            "                pass",
            "    outdated = []",
            "    skipped = []",
            "    for package in packages:",
            "        norm_name = pep423_name(package)",
            "        if norm_name in updated_packages:",
            "            if updated_packages[norm_name] != packages[package]:",
            "                outdated.append(",
            "                    package_info(package, updated_packages[norm_name], packages[package])",
            "                )",
            "            elif canonicalize_name(package) in outdated_packages:",
            "                skipped.append(outdated_packages[canonicalize_name(package)])",
            "    for package, old_version, new_version in skipped:",
            "        name_in_pipfile = project.get_package_name_in_pipfile(package)",
            "        pipfile_version_text = \"\"",
            "        required = \"\"",
            "        version = None",
            "        if name_in_pipfile:",
            "            version = get_version(project.packages[name_in_pipfile])",
            "            rdeps = reverse_deps.get(canonicalize_name(package))",
            "            if isinstance(rdeps, Mapping) and \"required\" in rdeps:",
            "                required = \" {} required\".format(rdeps[\"required\"])",
            "            if version:",
            "                pipfile_version_text = f\" ({version} set in Pipfile)\"",
            "            else:",
            "                pipfile_version_text = \" (Unpinned in Pipfile)\"",
            "        click.echo(",
            "            crayons.yellow(",
            "                \"Skipped Update of Package {!s}: {!s} installed,{!s}{!s}, \"",
            "                \"{!s} available.\".format(",
            "                    package, old_version, required, pipfile_version_text, new_version",
            "                )",
            "            ), err=True",
            "        )",
            "    if not outdated:",
            "        click.echo(crayons.green(\"All packages are up to date!\", bold=True))",
            "        sys.exit(0)",
            "    for package, new_version, old_version in outdated:",
            "        click.echo(",
            "            \"Package {!r} out-of-date: {!r} installed, {!r} available.\".format(",
            "                package, old_version, new_version",
            "            )",
            "        )",
            "    sys.exit(bool(outdated))",
            "",
            "",
            "def do_install(",
            "    project,",
            "    packages=False,",
            "    editable_packages=False,",
            "    index_url=False,",
            "    extra_index_url=False,",
            "    dev=False,",
            "    three=False,",
            "    python=False,",
            "    pypi_mirror=None,",
            "    system=False,",
            "    lock=True,",
            "    ignore_pipfile=False,",
            "    skip_lock=False,",
            "    requirementstxt=False,",
            "    sequential=False,",
            "    pre=False,",
            "    code=False,",
            "    deploy=False,",
            "    keep_outdated=False,",
            "    selective_upgrade=False,",
            "    site_packages=None,",
            "):",
            "    from .vendor.pip_shims.shims import PipError",
            "",
            "    requirements_directory = vistir.path.create_tracked_tempdir(",
            "        suffix=\"-requirements\", prefix=\"pipenv-\"",
            "    )",
            "    warnings.filterwarnings(\"default\", category=vistir.compat.ResourceWarning)",
            "    if selective_upgrade:",
            "        keep_outdated = True",
            "    packages = packages if packages else []",
            "    editable_packages = editable_packages if editable_packages else []",
            "    package_args = [p for p in packages if p] + [p for p in editable_packages if p]",
            "    skip_requirements = False",
            "    # Don't search for requirements.txt files if the user provides one",
            "    if requirementstxt or package_args or project.pipfile_exists:",
            "        skip_requirements = True",
            "    concurrent = not sequential",
            "    # Ensure that virtualenv is available and pipfile are available",
            "    ensure_project(",
            "        project,",
            "        three=three,",
            "        python=python,",
            "        system=system,",
            "        warn=True,",
            "        deploy=deploy,",
            "        skip_requirements=skip_requirements,",
            "        pypi_mirror=pypi_mirror,",
            "        site_packages=site_packages,",
            "    )",
            "    # Don't attempt to install develop and default packages if Pipfile is missing",
            "    if not project.pipfile_exists and not (package_args or dev) and not code:",
            "        if not (ignore_pipfile or deploy):",
            "            raise exceptions.PipfileNotFound(project.path_to(\"Pipfile\"))",
            "        elif ((skip_lock and deploy) or ignore_pipfile) and not project.lockfile_exists:",
            "            raise exceptions.LockfileNotFound(project.path_to(\"Pipfile.lock\"))",
            "    # Load the --pre settings from the Pipfile.",
            "    if not pre:",
            "        pre = project.settings.get(\"allow_prereleases\")",
            "    if not keep_outdated:",
            "        keep_outdated = project.settings.get(\"keep_outdated\")",
            "    remote = requirementstxt and is_valid_url(requirementstxt)",
            "    # Warn and exit if --system is used without a pipfile.",
            "    if (system and package_args) and not project.s.PIPENV_VIRTUALENV:",
            "        raise exceptions.SystemUsageError",
            "    # Automatically use an activated virtualenv.",
            "    if project.s.PIPENV_USE_SYSTEM:",
            "        system = True",
            "    if system:",
            "        project.s.PIPENV_USE_SYSTEM = True",
            "        os.environ[\"PIPENV_USE_SYSTEM\"] = \"1\"",
            "    # Check if the file is remote or not",
            "    if remote:",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Remote requirements file provided! Downloading...\"), bold=True",
            "            ),",
            "            err=True,",
            "        )",
            "        fd = vistir.path.create_tracked_tempfile(",
            "            prefix=\"pipenv-\", suffix=\"-requirement.txt\", dir=requirements_directory",
            "        )",
            "        temp_reqs = fd.name",
            "        requirements_url = requirementstxt",
            "        # Download requirements file",
            "        try:",
            "            download_file(requirements_url, temp_reqs, project.s.PIPENV_MAX_RETRIES)",
            "        except OSError:",
            "            fd.close()",
            "            os.unlink(temp_reqs)",
            "            click.echo(",
            "                crayons.red(",
            "                    \"Unable to find requirements file at {}.\".format(",
            "                        crayons.normal(requirements_url)",
            "                    )",
            "                ),",
            "                err=True,",
            "            )",
            "            sys.exit(1)",
            "        finally:",
            "            fd.close()",
            "        # Replace the url with the temporary requirements file",
            "        requirementstxt = temp_reqs",
            "        remote = True",
            "    if requirementstxt:",
            "        error, traceback = None, None",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Requirements file provided! Importing into Pipfile...\"), bold=True",
            "            ),",
            "            err=True,",
            "        )",
            "        try:",
            "            import_requirements(project, r=project.path_to(requirementstxt), dev=dev)",
            "        except (UnicodeDecodeError, PipError) as e:",
            "            # Don't print the temp file path if remote since it will be deleted.",
            "            req_path = requirements_url if remote else project.path_to(requirementstxt)",
            "            error = (",
            "                \"Unexpected syntax in {}. Are you sure this is a \"",
            "                \"requirements.txt style file?\".format(req_path)",
            "            )",
            "            traceback = e",
            "        except AssertionError as e:",
            "            error = (",
            "                \"Requirements file doesn't appear to exist. Please ensure the file exists in your \"",
            "                \"project directory or you provided the correct path.\"",
            "            )",
            "            traceback = e",
            "        finally:",
            "            # If requirements file was provided by remote url delete the temporary file",
            "            if remote:",
            "                fd.close()  # Close for windows to allow file cleanup.",
            "                os.remove(temp_reqs)",
            "            if error and traceback:",
            "                click.echo(crayons.red(error))",
            "                click.echo(crayons.yellow(str(traceback)), err=True)",
            "                sys.exit(1)",
            "    if code:",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Discovering imports from local codebase...\"), bold=True)",
            "        )",
            "        for req in import_from_code(code):",
            "            click.echo(f\"  Found {crayons.green(req)}!\")",
            "            project.add_package_to_pipfile(req)",
            "    # Allow more than one package to be provided.",
            "    package_args = [p for p in packages] + [",
            "        f\"-e {pkg}\" for pkg in editable_packages",
            "    ]",
            "    # Support for --selective-upgrade.",
            "    # We should do this part first to make sure that we actually do selectively upgrade",
            "    # the items specified",
            "    if selective_upgrade:",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "        for i, package in enumerate(package_args[:]):",
            "            section = project.packages if not dev else project.dev_packages",
            "            package = Requirement.from_line(package)",
            "            package__name, package__val = package.pipfile_entry",
            "            try:",
            "                if not is_star(section[package__name]) and is_star(package__val):",
            "                    # Support for VCS dependencies.",
            "                    package_args[i] = convert_deps_to_pip(",
            "                        {package__name: section[package__name]}, project=project, r=False",
            "                    )[0]",
            "            except KeyError:",
            "                pass",
            "    # Install all dependencies, if none was provided.",
            "    # This basically ensures that we have a pipfile and lockfile, then it locks and",
            "    # installs from the lockfile",
            "    if not packages and not editable_packages:",
            "        # Update project settings with pre preference.",
            "        if pre:",
            "            project.update_settings({\"allow_prereleases\": pre})",
            "        do_init(",
            "            project,",
            "            dev=dev,",
            "            allow_global=system,",
            "            ignore_pipfile=ignore_pipfile,",
            "            system=system,",
            "            skip_lock=skip_lock,",
            "            concurrent=concurrent,",
            "            deploy=deploy,",
            "            pre=pre,",
            "            requirements_dir=requirements_directory,",
            "            pypi_mirror=pypi_mirror,",
            "            keep_outdated=keep_outdated",
            "        )",
            "",
            "    # This is for if the user passed in dependencies, then we want to make sure we",
            "    else:",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "        # make a tuple of (display_name, entry)",
            "        pkg_list = packages + [f'-e {pkg}' for pkg in editable_packages]",
            "        if not system and not project.virtualenv_exists:",
            "            do_init(",
            "                project,",
            "                dev=dev,",
            "                system=system,",
            "                allow_global=system,",
            "                concurrent=concurrent,",
            "                keep_outdated=keep_outdated,",
            "                requirements_dir=requirements_directory,",
            "                deploy=deploy,",
            "                pypi_mirror=pypi_mirror,",
            "                skip_lock=skip_lock,",
            "            )",
            "        pip_shims_module = os.environ.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "        for pkg_line in pkg_list:",
            "            click.echo(",
            "                crayons.normal(",
            "                    fix_utf8(f\"Installing {crayons.green(pkg_line, bold=True)}...\"),",
            "                    bold=True,",
            "                )",
            "            )",
            "            # pip install:",
            "            with vistir.contextmanagers.temp_environ(), create_spinner(\"Installing...\", project.s) as sp:",
            "                if not system:",
            "                    os.environ[\"PIP_USER\"] = vistir.compat.fs_str(\"0\")",
            "                    if \"PYTHONHOME\" in os.environ:",
            "                        del os.environ[\"PYTHONHOME\"]",
            "                sp.text = f\"Resolving {pkg_line}...\"",
            "                try:",
            "                    pkg_requirement = Requirement.from_line(pkg_line)",
            "                except ValueError as e:",
            "                    sp.write_err(vistir.compat.fs_str(\"{}: {}\".format(crayons.red(\"WARNING\"), e)))",
            "                    sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Installation Failed\"))",
            "                    sys.exit(1)",
            "                no_deps = False",
            "                sp.text = \"Installing...\"",
            "                try:",
            "                    sp.text = f\"Installing {pkg_requirement.name}...\"",
            "                    if project.s.is_verbose():",
            "                        sp.hide_and_write(f\"Installing package: {pkg_requirement.as_line(include_hashes=False)}\")",
            "                    c = pip_install(",
            "                        project,",
            "                        pkg_requirement,",
            "                        ignore_hashes=True,",
            "                        allow_global=system,",
            "                        selective_upgrade=selective_upgrade,",
            "                        no_deps=no_deps,",
            "                        pre=pre,",
            "                        requirements_dir=requirements_directory,",
            "                        index=index_url,",
            "                        extra_indexes=extra_index_url,",
            "                        pypi_mirror=pypi_mirror,",
            "                    )",
            "                    if c.returncode:",
            "                        sp.write_err(",
            "                            \"{} An error occurred while installing {}!\".format(",
            "                                crayons.red(\"Error: \", bold=True), crayons.green(pkg_line)",
            "                            ),",
            "                        )",
            "                        sp.write_err(",
            "                            vistir.compat.fs_str(f\"Error text: {c.stdout}\")",
            "                        )",
            "                        sp.write_err(crayons.cyan(vistir.compat.fs_str(format_pip_error(c.stderr))))",
            "                        if project.s.is_verbose():",
            "                            sp.write_err(crayons.cyan(vistir.compat.fs_str(format_pip_output(c.stdout))))",
            "                        if \"setup.py egg_info\" in c.stderr:",
            "                            sp.write_err(vistir.compat.fs_str(",
            "                                \"This is likely caused by a bug in {}. \"",
            "                                \"Report this to its maintainers.\".format(",
            "                                    crayons.green(pkg_requirement.name)",
            "                                )",
            "                            ))",
            "                        sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Installation Failed\"))",
            "                        sys.exit(1)",
            "                except (ValueError, RuntimeError) as e:",
            "                    sp.write_err(vistir.compat.fs_str(",
            "                        \"{}: {}\".format(crayons.red(\"WARNING\"), e),",
            "                    ))",
            "                    sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "                        \"Installation Failed\",",
            "                    ))",
            "                    sys.exit(1)",
            "                # Warn if --editable wasn't passed.",
            "                if pkg_requirement.is_vcs and not pkg_requirement.editable and not project.s.PIPENV_RESOLVE_VCS:",
            "                    sp.write_err(",
            "                        \"{}: You installed a VCS dependency in non-editable mode. \"",
            "                        \"This will work fine, but sub-dependencies will not be resolved by {}.\"",
            "                        \"\\n  To enable this sub-dependency functionality, specify that this dependency is editable.\"",
            "                        \"\".format(",
            "                            crayons.red(\"Warning\", bold=True),",
            "                            crayons.yellow(\"$ pipenv lock\"),",
            "                        )",
            "                    )",
            "                sp.write(vistir.compat.fs_str(",
            "                    \"{} {} {} {}{}\".format(",
            "                        crayons.normal(\"Adding\", bold=True),",
            "                        crayons.green(f\"{pkg_requirement.name}\", bold=True),",
            "                        crayons.normal(\"to Pipfile's\", bold=True),",
            "                        crayons.yellow(\"[dev-packages]\" if dev else \"[packages]\", bold=True),",
            "                        crayons.normal(fix_utf8(\"...\"), bold=True),",
            "                    )",
            "                ))",
            "                # Add the package to the Pipfile.",
            "                indexes = list(filter(None, [index_url, *extra_index_url]))",
            "                for index in indexes:",
            "                    index_name = project.add_index_to_pipfile(",
            "                        index, verify_ssl=index.startswith(\"https:\")",
            "                    )",
            "                    if index_url and not extra_index_url:",
            "                        pkg_requirement.index = index_name",
            "                try:",
            "                    project.add_package_to_pipfile(pkg_requirement, dev)",
            "                except ValueError:",
            "                    import traceback",
            "                    sp.write_err(",
            "                        \"{} {}\".format(",
            "                            crayons.red(\"Error:\", bold=True), traceback.format_exc()",
            "                        )",
            "                    )",
            "                    sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "                        \"Failed adding package to Pipfile\"",
            "                    ))",
            "                sp.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Installation Succeeded\"))",
            "            # Update project settings with pre preference.",
            "            if pre:",
            "                project.update_settings({\"allow_prereleases\": pre})",
            "        if pip_shims_module:",
            "            os.environ[\"PIP_SHIMS_BASE_MODULE\"] = pip_shims_module",
            "        do_init(",
            "            project,",
            "            dev=dev,",
            "            system=system,",
            "            allow_global=system,",
            "            concurrent=concurrent,",
            "            keep_outdated=keep_outdated,",
            "            requirements_dir=requirements_directory,",
            "            deploy=deploy,",
            "            pypi_mirror=pypi_mirror,",
            "            skip_lock=skip_lock,",
            "        )",
            "    sys.exit(0)",
            "",
            "",
            "def do_uninstall(",
            "    project,",
            "    packages=False,",
            "    editable_packages=False,",
            "    three=None,",
            "    python=False,",
            "    system=False,",
            "    lock=False,",
            "    all_dev=False,",
            "    all=False,",
            "    keep_outdated=False,",
            "    pypi_mirror=None,",
            "    ctx=None",
            "):",
            "    from .vendor.packaging.utils import canonicalize_name",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    # Automatically use an activated virtualenv.",
            "    if project.s.PIPENV_USE_SYSTEM:",
            "        system = True",
            "    # Ensure that virtualenv is available.",
            "    # TODO: We probably shouldn't ensure a project exists if the outcome will be to just",
            "    # install things in order to remove them... maybe tell the user to install first?",
            "    ensure_project(project, three=three, python=python, pypi_mirror=pypi_mirror)",
            "    # Un-install all dependencies, if --all was provided.",
            "    if not any([packages, editable_packages, all_dev, all]):",
            "        raise exceptions.PipenvUsageError(\"No package provided!\", ctx=ctx)",
            "    editable_pkgs = [",
            "        Requirement.from_line(f\"-e {p}\").name for p in editable_packages if p",
            "    ]",
            "    packages += editable_pkgs",
            "    package_names = {p for p in packages if p}",
            "    package_map = {",
            "        canonicalize_name(p): p for p in packages if p",
            "    }",
            "    installed_package_names = project.installed_package_names",
            "    # Intelligently detect if --dev should be used or not.",
            "    lockfile_packages = set()",
            "    if project.lockfile_exists:",
            "        project_pkg_names = project.lockfile_package_names",
            "    else:",
            "        project_pkg_names = project.pipfile_package_names",
            "    pipfile_remove = True",
            "    # Uninstall [dev-packages], if --dev was provided.",
            "    if all_dev:",
            "        if \"dev-packages\" not in project.parsed_pipfile and not project_pkg_names[\"dev\"]:",
            "            click.echo(",
            "                crayons.normal(",
            "                    \"No {} to uninstall.\".format(crayons.yellow(\"[dev-packages]\")),",
            "                    bold=True,",
            "                )",
            "            )",
            "            return",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Un-installing {}...\".format(crayons.yellow(\"[dev-packages]\"))), bold=True",
            "            )",
            "        )",
            "        package_names = set(project_pkg_names[\"dev\"]) - set(project_pkg_names[\"default\"])",
            "",
            "    # Remove known \"bad packages\" from the list.",
            "    bad_pkgs = get_canonical_names(BAD_PACKAGES)",
            "    ignored_packages = bad_pkgs & set(list(package_map.keys()))",
            "    for ignored_pkg in ignored_packages:",
            "        if project.s.is_verbose():",
            "            click.echo(f\"Ignoring {ignored_pkg}.\", err=True)",
            "        package_names.discard(package_map[ignored_pkg])",
            "",
            "    used_packages = project_pkg_names[\"combined\"] & installed_package_names",
            "    failure = False",
            "    if all:",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Un-installing all {} and {}...\".format(",
            "                    crayons.yellow(\"[dev-packages]\"),",
            "                    crayons.yellow(\"[packages]\"),",
            "                )), bold=True",
            "            )",
            "        )",
            "        do_purge(project, bare=False, allow_global=system)",
            "        sys.exit(0)",
            "",
            "    selected_pkg_map = {",
            "        canonicalize_name(p): p for p in package_names",
            "    }",
            "    packages_to_remove = [",
            "        p for normalized, p in selected_pkg_map.items()",
            "        if normalized in (used_packages - bad_pkgs)",
            "    ]",
            "    pip_path = None",
            "    for normalized, package_name in selected_pkg_map.items():",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(f\"Uninstalling {crayons.green(package_name)}...\"), bold=True",
            "            )",
            "        )",
            "        # Uninstall the package.",
            "        if package_name in packages_to_remove:",
            "            with project.environment.activated():",
            "                if pip_path is None:",
            "                    pip_path = which_pip(project, allow_global=system)",
            "                cmd = [pip_path, \"uninstall\", package_name, \"-y\"]",
            "                c = run_command(cmd, is_verbose=project.s.is_verbose())",
            "                click.echo(crayons.cyan(c.stdout))",
            "                if c.returncode != 0:",
            "                    failure = True",
            "        if not failure and pipfile_remove:",
            "            in_packages = project.get_package_name_in_pipfile(package_name, dev=False)",
            "            in_dev_packages = project.get_package_name_in_pipfile(",
            "                package_name, dev=True",
            "            )",
            "            if normalized in lockfile_packages:",
            "                click.echo(\"{} {} {} {}\".format(",
            "                    crayons.cyan(\"Removing\"),",
            "                    crayons.green(package_name),",
            "                    crayons.cyan(\"from\"),",
            "                    crayons.white(fix_utf8(\"Pipfile.lock...\")))",
            "                )",
            "                lockfile = project.get_or_create_lockfile()",
            "                if normalized in lockfile.default:",
            "                    del lockfile.default[normalized]",
            "                if normalized in lockfile.develop:",
            "                    del lockfile.develop[normalized]",
            "                lockfile.write()",
            "            if not (in_dev_packages or in_packages):",
            "                if normalized in lockfile_packages:",
            "                    continue",
            "                click.echo(",
            "                    \"No package {} to remove from Pipfile.\".format(",
            "                        crayons.green(package_name)",
            "                    )",
            "                )",
            "                continue",
            "",
            "            click.echo(",
            "                fix_utf8(f\"Removing {crayons.green(package_name)} from Pipfile...\")",
            "            )",
            "            # Remove package from both packages and dev-packages.",
            "            if in_dev_packages:",
            "                project.remove_package_from_pipfile(package_name, dev=True)",
            "            if in_packages:",
            "                project.remove_package_from_pipfile(package_name, dev=False)",
            "    if lock:",
            "        do_lock(project, system=system, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror)",
            "    sys.exit(int(failure))",
            "",
            "",
            "def do_shell(project, three=None, python=False, fancy=False, shell_args=None, pypi_mirror=None):",
            "    # Ensure that virtualenv is available.",
            "    ensure_project(",
            "        project, three=three, python=python, validate=False, pypi_mirror=pypi_mirror,",
            "    )",
            "",
            "    # Support shell compatibility mode.",
            "    if project.s.PIPENV_SHELL_FANCY:",
            "        fancy = True",
            "",
            "    from .shells import choose_shell",
            "",
            "    shell = choose_shell(project)",
            "    click.echo(fix_utf8(\"Launching subshell in virtual environment...\"), err=True)",
            "",
            "    fork_args = (",
            "        project.virtualenv_location,",
            "        project.project_directory,",
            "        shell_args,",
            "    )",
            "",
            "    # Set an environment variable, so we know we're in the environment.",
            "    # Only set PIPENV_ACTIVE after finishing reading virtualenv_location",
            "    # otherwise its value will be changed",
            "    os.environ[\"PIPENV_ACTIVE\"] = vistir.misc.fs_str(\"1\")",
            "",
            "    os.environ.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "",
            "    if fancy:",
            "        shell.fork(*fork_args)",
            "        return",
            "",
            "    try:",
            "        shell.fork_compat(*fork_args)",
            "    except (AttributeError, ImportError):",
            "        click.echo(fix_utf8(",
            "            \"Compatibility mode not supported. \"",
            "            \"Trying to continue as well-configured shell...\"),",
            "            err=True,",
            "        )",
            "        shell.fork(*fork_args)",
            "",
            "",
            "def _inline_activate_virtualenv(project):",
            "    try:",
            "        activate_this = project._which(\"activate_this.py\")",
            "        if not activate_this or not os.path.exists(activate_this):",
            "            raise exceptions.VirtualenvActivationException()",
            "        with open(activate_this) as f:",
            "            code = compile(f.read(), activate_this, \"exec\")",
            "            exec(code, dict(__file__=activate_this))",
            "    # Catch all errors, just in case.",
            "    except Exception:",
            "        click.echo(",
            "            \"{}: There was an unexpected error while activating your \"",
            "            \"virtualenv. Continuing anyway...\".format(",
            "                crayons.red(\"Warning\", bold=True)",
            "            ),",
            "            err=True,",
            "        )",
            "",
            "",
            "def _inline_activate_venv(project):",
            "    \"\"\"Built-in venv doesn't have activate_this.py, but doesn't need it anyway.",
            "",
            "    As long as we find the correct executable, built-in venv sets up the",
            "    environment automatically.",
            "",
            "    See: https://bugs.python.org/issue21496#msg218455",
            "    \"\"\"",
            "    components = []",
            "    for name in (\"bin\", \"Scripts\"):",
            "        bindir = os.path.join(project.virtualenv_location, name)",
            "        if os.path.exists(bindir):",
            "            components.append(bindir)",
            "    if \"PATH\" in os.environ:",
            "        components.append(os.environ[\"PATH\"])",
            "    os.environ[\"PATH\"] = os.pathsep.join(components)",
            "",
            "",
            "def inline_activate_virtual_environment(project):",
            "    root = project.virtualenv_location",
            "    if os.path.exists(os.path.join(root, \"pyvenv.cfg\")):",
            "        _inline_activate_venv(project)",
            "    else:",
            "        _inline_activate_virtualenv(project)",
            "    if \"VIRTUAL_ENV\" not in os.environ:",
            "        os.environ[\"VIRTUAL_ENV\"] = vistir.misc.fs_str(root)",
            "",
            "",
            "def _launch_windows_subprocess(script, env):",
            "    import subprocess",
            "",
            "    path = env.get(\"PATH\", \"\")",
            "    command = system_which(script.command, path=path)",
            "",
            "    options = {\"universal_newlines\": True, \"env\": env}",
            "    script.cmd_args[1:] = [expandvars(arg) for arg in script.args]",
            "",
            "    # Command not found, maybe this is a shell built-in?",
            "    if not command:",
            "        return subprocess.Popen(script.cmdify(), shell=True, **options)",
            "",
            "    # Try to use CreateProcess directly if possible. Specifically catch",
            "    # Windows error 193 \"Command is not a valid Win32 application\" to handle",
            "    # a \"command\" that is non-executable. See pypa/pipenv#2727.",
            "    try:",
            "        return subprocess.Popen([command] + script.args, **options)",
            "    except OSError as e:",
            "        if e.winerror != 193:",
            "            raise",
            "",
            "    # Try shell mode to use Windows's file association for file launch.",
            "    return subprocess.Popen(script.cmdify(), shell=True, **options)",
            "",
            "",
            "def do_run_nt(project, script, env):",
            "    p = _launch_windows_subprocess(script, env)",
            "    p.communicate()",
            "    sys.exit(p.returncode)",
            "",
            "",
            "def do_run_posix(project, script, command, env):",
            "    path = env.get(\"PATH\")",
            "    command_path = system_which(script.command, path=path)",
            "    if not command_path:",
            "        if project.has_script(command):",
            "            click.echo(",
            "                \"{}: the command {} (from {}) could not be found within {}.\"",
            "                \"\".format(",
            "                    crayons.red(\"Error\", bold=True),",
            "                    crayons.yellow(script.command),",
            "                    crayons.normal(command, bold=True),",
            "                    crayons.normal(\"PATH\", bold=True),",
            "                ),",
            "                err=True,",
            "            )",
            "        else:",
            "            click.echo(",
            "                \"{}: the command {} could not be found within {} or Pipfile's {}.\"",
            "                \"\".format(",
            "                    crayons.red(\"Error\", bold=True),",
            "                    crayons.yellow(command),",
            "                    crayons.normal(\"PATH\", bold=True),",
            "                    crayons.normal(\"[scripts]\", bold=True),",
            "                ),",
            "                err=True,",
            "            )",
            "        sys.exit(1)",
            "    os.execve(",
            "        command_path,",
            "        [command_path, *(os.path.expandvars(arg) for arg in script.args)],",
            "        env",
            "    )",
            "",
            "",
            "def do_run(project, command, args, three=None, python=False, pypi_mirror=None):",
            "    \"\"\"Attempt to run command either pulling from project or interpreting as executable.",
            "",
            "    Args are appended to the command in [scripts] section of project if found.",
            "    \"\"\"",
            "    from .cmdparse import ScriptEmptyError",
            "",
            "    # Ensure that virtualenv is available.",
            "    ensure_project(",
            "        project, three=three, python=python, validate=False, pypi_mirror=pypi_mirror,",
            "    )",
            "",
            "    env = os.environ.copy()",
            "    env.update(load_dot_env(project, as_dict=True) or {})",
            "    env.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "",
            "    path = env.get('PATH', '')",
            "    if project.virtualenv_location:",
            "        new_path = os.path.join(project.virtualenv_location, 'Scripts' if os.name == 'nt' else 'bin')",
            "        paths = path.split(os.pathsep)",
            "        paths.insert(0, new_path)",
            "        path = os.pathsep.join(paths)",
            "        env[\"VIRTUAL_ENV\"] = project.virtualenv_location",
            "    env[\"PATH\"] = path",
            "",
            "    # Set an environment variable, so we know we're in the environment.",
            "    # Only set PIPENV_ACTIVE after finishing reading virtualenv_location",
            "    # such as in inline_activate_virtual_environment",
            "    # otherwise its value will be changed",
            "    env[\"PIPENV_ACTIVE\"] = vistir.misc.fs_str(\"1\")",
            "    env.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "",
            "    try:",
            "        script = project.build_script(command, args)",
            "        cmd_string = cmd_list_to_shell([script.command] + script.args)",
            "        if project.s.is_verbose():",
            "            click.echo(crayons.normal(f\"$ {cmd_string}\"), err=True)",
            "    except ScriptEmptyError:",
            "        click.echo(\"Can't run script {0!r}-it's empty?\", err=True)",
            "    run_args = [project, script]",
            "    run_kwargs = {'env': env}",
            "    # We're using `do_run_nt` on CI (even if we're running on a non-nt machine)",
            "    # as a workaround for https://github.com/pypa/pipenv/issues/4909.",
            "    if os.name == \"nt\" or environments.PIPENV_IS_CI:",
            "        run_fn = do_run_nt",
            "    else:",
            "        run_fn = do_run_posix",
            "        run_kwargs.update({\"command\": command})",
            "    run_fn(*run_args, **run_kwargs)",
            "",
            "",
            "def do_check(",
            "    project,",
            "    three=None,",
            "    python=False,",
            "    system=False,",
            "    unused=False,",
            "    db=None,",
            "    ignore=None,",
            "    output=\"default\",",
            "    key=None,",
            "    quiet=False,",
            "    args=None,",
            "    pypi_mirror=None",
            "):",
            "    from pipenv.vendor.first import first",
            "    from pipenv.vendor.vistir.compat import JSONDecodeError",
            "",
            "    if not system:",
            "        # Ensure that virtualenv is available.",
            "        ensure_project(",
            "            project,",
            "            three=three,",
            "            python=python,",
            "            validate=False,",
            "            warn=False,",
            "            pypi_mirror=pypi_mirror,",
            "        )",
            "    if not args:",
            "        args = []",
            "    if unused:",
            "        deps_required = [k.lower() for k in project.packages.keys()]",
            "        deps_needed = [k.lower() for k in import_from_code(unused)]",
            "        for dep in deps_needed:",
            "            try:",
            "                deps_required.remove(dep)",
            "            except ValueError:",
            "                pass",
            "        if deps_required:",
            "            if not quiet and not project.s.is_quiet():",
            "                click.echo(",
            "                    crayons.normal(",
            "                        \"The following dependencies appear unused, and may be safe for removal:\"",
            "                    )",
            "                )",
            "                for dep in deps_required:",
            "                    click.echo(f\"  - {crayons.green(dep)}\")",
            "                sys.exit(1)",
            "        else:",
            "            sys.exit(0)",
            "    if not quiet and not project.s.is_quiet():",
            "        click.echo(crayons.normal(decode_for_output(\"Checking PEP 508 requirements...\"), bold=True))",
            "    pep508checker_path = pep508checker.__file__.rstrip(\"cdo\")",
            "    safety_path = os.path.join(",
            "        os.path.dirname(os.path.abspath(__file__)), \"patched\", \"safety\"",
            "    )",
            "    if not system:",
            "        python = project._which(\"python\")",
            "    else:",
            "        python = first(system_which(p) for p in (\"python\", \"python3\", \"python2\"))",
            "    if not python:",
            "        click.echo(crayons.red(\"The Python interpreter can't be found.\"), err=True)",
            "        sys.exit(1)",
            "    _cmd = [Path(python).as_posix()]",
            "    # Run the PEP 508 checker in the virtualenv.",
            "    cmd = _cmd + [Path(pep508checker_path).as_posix()]",
            "    c = run_command(cmd, is_verbose=project.s.is_verbose())",
            "    if c.returncode is not None:",
            "        try:",
            "            results = simplejson.loads(c.stdout.strip())",
            "        except JSONDecodeError:",
            "            click.echo(\"{}\\n{}\\n{}\".format(",
            "                crayons.white(decode_for_output(\"Failed parsing pep508 results: \"), bold=True),",
            "                c.stdout.strip(),",
            "                c.stderr.strip()",
            "            ))",
            "            sys.exit(1)",
            "    # Load the pipfile.",
            "    p = pipfile.Pipfile.load(project.pipfile_location)",
            "    failed = False",
            "    # Assert each specified requirement.",
            "    for marker, specifier in p.data[\"_meta\"][\"requires\"].items():",
            "        if marker in results:",
            "            try:",
            "                assert results[marker] == specifier",
            "            except AssertionError:",
            "                failed = True",
            "                click.echo(",
            "                    \"Specifier {} does not match {} ({}).\"",
            "                    \"\".format(",
            "                        crayons.green(marker),",
            "                        crayons.cyan(specifier),",
            "                        crayons.yellow(results[marker]),",
            "                    ),",
            "                    err=True,",
            "                )",
            "    if failed:",
            "        click.echo(crayons.red(\"Failed!\"), err=True)",
            "        sys.exit(1)",
            "    else:",
            "        if not quiet and not project.s.is_quiet():",
            "            click.echo(crayons.green(\"Passed!\"))",
            "    if not quiet and not project.s.is_quiet():",
            "        click.echo(crayons.normal(",
            "            decode_for_output(\"Checking installed package safety...\"), bold=True)",
            "        )",
            "    if ignore:",
            "        if not isinstance(ignore, (tuple, list)):",
            "            ignore = [ignore]",
            "        ignored = [[\"--ignore\", cve] for cve in ignore]",
            "        if not quiet and not project.s.is_quiet():",
            "            click.echo(",
            "                crayons.normal(",
            "                    \"Notice: Ignoring CVE(s) {}\".format(crayons.yellow(\", \".join(ignore)))",
            "                ),",
            "                err=True,",
            "            )",
            "    else:",
            "        ignored = []",
            "",
            "    switch = output",
            "    if output == \"default\":",
            "        switch = \"json\"",
            "",
            "    cmd = _cmd + [safety_path, \"check\", f\"--{switch}\"]",
            "    if db:",
            "        if not quiet and not project.s.is_quiet():",
            "            click.echo(crayons.normal(f\"Using local database {db}\"))",
            "        cmd.append(f\"--db={db}\")",
            "    elif key or project.s.PIPENV_PYUP_API_KEY:",
            "        cmd = cmd + [f\"--key={key or project.s.PIPENV_PYUP_API_KEY}\"]",
            "    if ignored:",
            "        for cve in ignored:",
            "            cmd += cve",
            "    c = run_command(cmd, catch_exceptions=False, is_verbose=project.s.is_verbose())",
            "    if output == \"default\":",
            "        try:",
            "            results = simplejson.loads(c.stdout)",
            "        except (ValueError, JSONDecodeError):",
            "            raise exceptions.JSONParseError(c.stdout, c.stderr)",
            "        except Exception:",
            "            raise exceptions.PipenvCmdError(cmd_list_to_shell(c.args), c.stdout, c.stderr, c.returncode)",
            "        for (package, resolved, installed, description, vuln, *_) in results:",
            "            click.echo(",
            "                \"{}: {} {} resolved ({} installed)!\".format(",
            "                    crayons.normal(vuln, bold=True),",
            "                    crayons.green(package),",
            "                    crayons.yellow(resolved, bold=False),",
            "                    crayons.yellow(installed, bold=True),",
            "                )",
            "            )",
            "            click.echo(f\"{description}\")",
            "            click.echo()",
            "        if c.returncode == 0:",
            "            click.echo(crayons.green(\"All good!\"))",
            "            sys.exit(0)",
            "        else:",
            "            sys.exit(1)",
            "    else:",
            "        click.echo(c.stdout)",
            "        sys.exit(c.returncode)",
            "",
            "",
            "def do_graph(project, bare=False, json=False, json_tree=False, reverse=False):",
            "    from pipenv.vendor import pipdeptree",
            "    from pipenv.vendor.vistir.compat import JSONDecodeError",
            "    pipdeptree_path = pipdeptree.__file__.rstrip(\"cdo\")",
            "    try:",
            "        python_path = project._which(\"python\")",
            "    except AttributeError:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Unable to display currently-installed dependency graph information here. \"",
            "                \"Please run within a Pipenv project.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    except RuntimeError:",
            "        pass",
            "    else:",
            "        if not os.name == 'nt':    # bugfix #4388",
            "            python_path = Path(python_path).as_posix()",
            "            pipdeptree_path = Path(pipdeptree_path).as_posix()",
            "",
            "    if reverse and json:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Using both --reverse and --json together is not supported. \"",
            "                \"Please select one of the two options.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    if reverse and json_tree:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Using both --reverse and --json-tree together is not supported. \"",
            "                \"Please select one of the two options.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    if json and json_tree:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Using both --json and --json-tree together is not supported. \"",
            "                \"Please select one of the two options.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    flag = \"\"",
            "    if json:",
            "        flag = \"--json\"",
            "    if json_tree:",
            "        flag = \"--json-tree\"",
            "    if reverse:",
            "        flag = \"--reverse\"",
            "    if not project.virtualenv_exists:",
            "        click.echo(",
            "            \"{}: No virtualenv has been created for this project yet! Consider \"",
            "            \"running {} first to automatically generate one for you or see \"",
            "            \"{} for further instructions.\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                crayons.green(\"`pipenv install`\"),",
            "                crayons.green(\"`pipenv install --help`\"),",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    cmd_args = [python_path, pipdeptree_path, \"-l\"]",
            "    if flag:",
            "        cmd_args.append(flag)",
            "    c = run_command(cmd_args, is_verbose=project.s.is_verbose())",
            "    # Run dep-tree.",
            "    if not bare:",
            "        if json:",
            "            data = []",
            "            try:",
            "                parsed = simplejson.loads(c.stdout.strip())",
            "            except JSONDecodeError:",
            "                raise exceptions.JSONParseError(c.stdout, c.stderr)",
            "            else:",
            "                for d in parsed:",
            "                    if d[\"package\"][\"key\"] not in BAD_PACKAGES:",
            "                        data.append(d)",
            "            click.echo(simplejson.dumps(data, indent=4))",
            "            sys.exit(0)",
            "        elif json_tree:",
            "",
            "            def traverse(obj):",
            "                if isinstance(obj, list):",
            "                    return [",
            "                        traverse(package)",
            "                        for package in obj",
            "                        if package[\"key\"] not in BAD_PACKAGES",
            "                    ]",
            "                else:",
            "                    obj[\"dependencies\"] = traverse(obj[\"dependencies\"])",
            "                    return obj",
            "",
            "            try:",
            "                parsed = simplejson.loads(c.stdout.strip())",
            "            except JSONDecodeError:",
            "                raise exceptions.JSONParseError(c.stdout, c.stderr)",
            "            else:",
            "                data = traverse(parsed)",
            "                click.echo(simplejson.dumps(data, indent=4))",
            "                sys.exit(0)",
            "        else:",
            "            for line in c.stdout.strip().split(\"\\n\"):",
            "                # Ignore bad packages as top level.",
            "                # TODO: This should probably be a \"==\" in + line.partition",
            "                if line.split(\"==\")[0] in BAD_PACKAGES and not reverse:",
            "                    continue",
            "",
            "                # Bold top-level packages.",
            "                if not line.startswith(\" \"):",
            "                    click.echo(crayons.normal(line, bold=True))",
            "                # Echo the rest.",
            "                else:",
            "                    click.echo(crayons.normal(line, bold=False))",
            "    else:",
            "        click.echo(c.stdout)",
            "    if c.returncode != 0:",
            "        click.echo(",
            "            \"{} {}\".format(",
            "                crayons.red(\"ERROR: \", bold=True),",
            "                crayons.white(f\"{c.stderr}\"),",
            "            ),",
            "            err=True,",
            "        )",
            "    # Return its return code.",
            "    sys.exit(c.returncode)",
            "",
            "",
            "def do_sync(",
            "    project,",
            "    dev=False,",
            "    three=None,",
            "    python=None,",
            "    bare=False,",
            "    dont_upgrade=False,",
            "    user=False,",
            "    clear=False,",
            "    unused=False,",
            "    sequential=False,",
            "    pypi_mirror=None,",
            "    system=False,",
            "    deploy=False,",
            "):",
            "    # The lock file needs to exist because sync won't write to it.",
            "    if not project.lockfile_exists:",
            "        raise exceptions.LockfileNotFound(\"Pipfile.lock\")",
            "",
            "    # Ensure that virtualenv is available if not system.",
            "    ensure_project(",
            "        project,",
            "        three=three,",
            "        python=python,",
            "        validate=False,",
            "        system=system,",
            "        deploy=deploy,",
            "        pypi_mirror=pypi_mirror,",
            "        clear=clear,",
            "    )",
            "",
            "    # Install everything.",
            "    requirements_dir = vistir.path.create_tracked_tempdir(",
            "        suffix=\"-requirements\", prefix=\"pipenv-\"",
            "    )",
            "    if system:",
            "        project.s.PIPENV_USE_SYSTEM = True",
            "        os.environ[\"PIPENV_USE_SYSTEM\"] = \"1\"",
            "    do_init(",
            "        project,",
            "        dev=dev,",
            "        allow_global=system,",
            "        concurrent=(not sequential),",
            "        requirements_dir=requirements_dir,",
            "        ignore_pipfile=True,  # Don't check if Pipfile and lock match.",
            "        pypi_mirror=pypi_mirror,",
            "        deploy=deploy,",
            "        system=system,",
            "    )",
            "    if not bare:",
            "        click.echo(crayons.green(\"All dependencies are now up-to-date!\"))",
            "",
            "",
            "def do_clean(",
            "    project, three=None, python=None, dry_run=False, bare=False, pypi_mirror=None,",
            "    system=False",
            "):",
            "    # Ensure that virtualenv is available.",
            "    from packaging.utils import canonicalize_name",
            "    ensure_project(project, three=three, python=python, validate=False, pypi_mirror=pypi_mirror)",
            "    ensure_lockfile(project, pypi_mirror=pypi_mirror)",
            "    # Make sure that the virtualenv's site packages are configured correctly",
            "    # otherwise we may end up removing from the global site packages directory",
            "    installed_package_names = project.installed_package_names.copy()",
            "    # Remove known \"bad packages\" from the list.",
            "    for bad_package in BAD_PACKAGES:",
            "        if canonicalize_name(bad_package) in installed_package_names:",
            "            if project.s.is_verbose():",
            "                click.echo(f\"Ignoring {bad_package}.\", err=True)",
            "            installed_package_names.remove(canonicalize_name(bad_package))",
            "    # Intelligently detect if --dev should be used or not.",
            "    locked_packages = {",
            "        canonicalize_name(pkg) for pkg in project.lockfile_package_names[\"combined\"]",
            "    }",
            "    for used_package in locked_packages:",
            "        if used_package in installed_package_names:",
            "            installed_package_names.remove(used_package)",
            "    failure = False",
            "    cmd = [which_pip(project, allow_global=system), \"uninstall\", \"-y\", \"-qq\"]",
            "    for apparent_bad_package in installed_package_names:",
            "        if dry_run and not bare:",
            "            click.echo(apparent_bad_package)",
            "        else:",
            "            if not bare:",
            "                click.echo(",
            "                    crayons.white(",
            "                        fix_utf8(f\"Uninstalling {apparent_bad_package}...\"), bold=True",
            "                    )",
            "                )",
            "            # Uninstall the package.",
            "            cmd = [which_pip(project), \"uninstall\", apparent_bad_package, \"-y\"]",
            "            c = run_command(cmd, is_verbose=project.s.is_verbose())",
            "            if c.returncode != 0:",
            "                failure = True",
            "    sys.exit(int(failure))"
        ],
        "afterPatchFile": [
            "import json as simplejson",
            "import logging",
            "import os",
            "from pathlib import Path",
            "from posixpath import expandvars",
            "import sys",
            "import time",
            "import warnings",
            "",
            "import click",
            "import dotenv",
            "import pipfile",
            "import vistir",
            "",
            "from pipenv import environments, exceptions, pep508checker, progress",
            "from pipenv._compat import decode_for_output, fix_utf8",
            "from pipenv.patched import crayons",
            "from pipenv.utils import (",
            "    cmd_list_to_shell, convert_deps_to_pip, create_spinner, download_file,",
            "    find_python, get_canonical_names, get_host_and_port, get_source_list, is_pinned,",
            "    is_python_command, is_required_version, is_star, is_valid_url,",
            "    parse_indexes, pep423_name, prepare_pip_source_args, proper_case,",
            "    python_version, run_command, subprocess_run, venv_resolve_deps",
            ")",
            "",
            "",
            "if environments.is_type_checking():",
            "    from typing import Dict, List, Optional, Union",
            "",
            "    from pipenv.project import Project",
            "    from pipenv.vendor.requirementslib.models.requirements import Requirement",
            "    TSourceDict = Dict[str, Union[str, bool]]",
            "",
            "",
            "# Packages that should be ignored later.",
            "BAD_PACKAGES = (",
            "    \"distribute\",",
            "    \"packaging\",",
            "    \"pip\",",
            "    \"pkg-resources\",",
            "    \"setuptools\",",
            "    \"wheel\",",
            ")",
            "",
            "FIRST_PACKAGES = (\"cython\",)",
            "",
            "if not environments.PIPENV_HIDE_EMOJIS:",
            "    now = time.localtime()",
            "    # Halloween easter-egg.",
            "    if ((now.tm_mon == 10) and (now.tm_mday == 30)) or (",
            "        (now.tm_mon == 10) and (now.tm_mday == 31)",
            "    ):",
            "        INSTALL_LABEL = \"\ud83c\udf83   \"",
            "    # Christmas easter-egg.",
            "    elif ((now.tm_mon == 12) and (now.tm_mday == 24)) or (",
            "        (now.tm_mon == 12) and (now.tm_mday == 25)",
            "    ):",
            "        INSTALL_LABEL = \"\ud83c\udf85   \"",
            "    else:",
            "        INSTALL_LABEL = \"\ud83d\udc0d   \"",
            "    INSTALL_LABEL2 = crayons.normal(\"\u2624  \", bold=True)",
            "    STARTING_LABEL = \"    \"",
            "else:",
            "    INSTALL_LABEL = \"   \"",
            "    INSTALL_LABEL2 = \"   \"",
            "    STARTING_LABEL = \"   \"",
            "",
            "# Disable colors, for the color blind and others who do not prefer colors.",
            "if environments.PIPENV_COLORBLIND:",
            "    crayons.disable()",
            "",
            "",
            "def do_clear(project):",
            "    click.echo(crayons.normal(fix_utf8(\"Clearing caches...\"), bold=True))",
            "    try:",
            "        from pip._internal import locations",
            "    except ImportError:  # pip 9.",
            "        from pip import locations",
            "",
            "    try:",
            "        vistir.path.rmtree(project.s.PIPENV_CACHE_DIR, onerror=vistir.path.handle_remove_readonly)",
            "        # Other processes may be writing into this directory simultaneously.",
            "        vistir.path.rmtree(",
            "            locations.USER_CACHE_DIR,",
            "            ignore_errors=environments.PIPENV_IS_CI,",
            "            onerror=vistir.path.handle_remove_readonly",
            "        )",
            "    except OSError as e:",
            "        # Ignore FileNotFoundError. This is needed for Python 2.7.",
            "        import errno",
            "",
            "        if e.errno == errno.ENOENT:",
            "            pass",
            "        raise",
            "",
            "",
            "def load_dot_env(project, as_dict=False):",
            "    \"\"\"Loads .env file into sys.environ.\"\"\"",
            "    if not project.s.PIPENV_DONT_LOAD_ENV:",
            "        # If the project doesn't exist yet, check current directory for a .env file",
            "        project_directory = project.project_directory or \".\"",
            "        dotenv_file = project.s.PIPENV_DOTENV_LOCATION or os.sep.join(",
            "            [project_directory, \".env\"]",
            "        )",
            "",
            "        if os.path.isfile(dotenv_file):",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Loading .env environment variables...\"), bold=True),",
            "                err=True,",
            "            )",
            "        else:",
            "            if project.s.PIPENV_DOTENV_LOCATION:",
            "                click.echo(",
            "                    \"{}: file {}={} does not exist!!\\n{}\".format(",
            "                        crayons.red(\"Warning\", bold=True),",
            "                        crayons.normal(\"PIPENV_DOTENV_LOCATION\", bold=True),",
            "                        crayons.normal(project.s.PIPENV_DOTENV_LOCATION, bold=True),",
            "                        crayons.red(\"Not loading environment variables.\", bold=True),",
            "                    ),",
            "                    err=True,",
            "                )",
            "        if as_dict:",
            "            return dotenv.dotenv_values(dotenv_file)",
            "        else:",
            "            dotenv.load_dotenv(dotenv_file, override=True)",
            "            project.s.initialize()",
            "",
            "",
            "def cleanup_virtualenv(project, bare=True):",
            "    \"\"\"Removes the virtualenv directory from the system.\"\"\"",
            "    if not bare:",
            "        click.echo(crayons.red(\"Environment creation aborted.\"))",
            "    try:",
            "        # Delete the virtualenv.",
            "        vistir.path.rmtree(project.virtualenv_location)",
            "    except OSError as e:",
            "        click.echo(",
            "            \"{} An error occurred while removing {}!\".format(",
            "                crayons.red(\"Error: \", bold=True),",
            "                crayons.green(project.virtualenv_location),",
            "            ),",
            "            err=True,",
            "        )",
            "        click.echo(crayons.cyan(e), err=True)",
            "",
            "",
            "def import_requirements(project, r=None, dev=False):",
            "    from pipenv.patched.notpip._vendor import requests as pip_requests",
            "    from pipenv.patched.notpip._internal.req.constructors import install_req_from_parsed_requirement",
            "    from pipenv.vendor.pip_shims.shims import parse_requirements",
            "",
            "    # Parse requirements.txt file with Pip's parser.",
            "    # Pip requires a `PipSession` which is a subclass of requests.Session.",
            "    # Since we're not making any network calls, it's initialized to nothing.",
            "    if r:",
            "        assert os.path.isfile(r)",
            "    # Default path, if none is provided.",
            "    if r is None:",
            "        r = project.requirements_location",
            "    with open(r) as f:",
            "        contents = f.read()",
            "    indexes = []",
            "    trusted_hosts = []",
            "    # Find and add extra indexes.",
            "    for line in contents.split(\"\\n\"):",
            "        index, extra_index, trusted_host, _ = parse_indexes(line.strip(), strict=True)",
            "        if index:",
            "            indexes = [index]",
            "        if extra_index:",
            "            indexes.append(extra_index)",
            "        if trusted_host:",
            "            trusted_hosts.append(get_host_and_port(trusted_host))",
            "    indexes = sorted(set(indexes))",
            "    trusted_hosts = sorted(set(trusted_hosts))",
            "    reqs = [install_req_from_parsed_requirement(f) for f in parse_requirements(r, session=pip_requests)]",
            "    for package in reqs:",
            "        if package.name not in BAD_PACKAGES:",
            "            if package.link is not None:",
            "                package_string = (",
            "                    f\"-e {package.link}\"",
            "                    if package.editable",
            "                    else str(package.link)",
            "                )",
            "                project.add_package_to_pipfile(package_string, dev=dev)",
            "            else:",
            "                project.add_package_to_pipfile(str(package.req), dev=dev)",
            "    for index in indexes:",
            "        # don't require HTTPS for trusted hosts (see: https://pip.pypa.io/en/stable/cli/pip/#cmdoption-trusted-host)",
            "        host_and_port = get_host_and_port(index)",
            "        require_valid_https = not any((v in trusted_hosts for v in (",
            "            host_and_port,",
            "            host_and_port.partition(':')[0],  # also check if hostname without port is in trusted_hosts",
            "        )))",
            "        project.add_index_to_pipfile(index, verify_ssl=require_valid_https)",
            "    project.recase_pipfile()",
            "",
            "",
            "def ensure_environment():",
            "    # Skip this on Windows...",
            "    if os.name != \"nt\":",
            "        if \"LANG\" not in os.environ:",
            "            click.echo(",
            "                \"{}: the environment variable {} is not set!\"",
            "                \"\\nWe recommend setting this in {} (or equivalent) for \"",
            "                \"proper expected behavior.\".format(",
            "                    crayons.red(\"Warning\", bold=True),",
            "                    crayons.normal(\"LANG\", bold=True),",
            "                    crayons.green(\"~/.profile\"),",
            "                ),",
            "                err=True,",
            "            )",
            "",
            "",
            "def import_from_code(path=\".\"):",
            "    from pipreqs import pipreqs",
            "",
            "    rs = []",
            "    try:",
            "        for r in pipreqs.get_all_imports(",
            "            path, encoding=\"utf-8\", extra_ignore_dirs=[\".venv\"]",
            "        ):",
            "            if r not in BAD_PACKAGES:",
            "                rs.append(r)",
            "        pkg_names = pipreqs.get_pkg_names(rs)",
            "        return [proper_case(r) for r in pkg_names]",
            "",
            "    except Exception:",
            "        return []",
            "",
            "",
            "def ensure_pipfile(project, validate=True, skip_requirements=False, system=False):",
            "    \"\"\"Creates a Pipfile for the project, if it doesn't exist.\"\"\"",
            "",
            "    # Assert Pipfile exists.",
            "    python = project._which(\"python\") if not (project.s.USING_DEFAULT_PYTHON or system) else None",
            "    if project.pipfile_is_empty:",
            "        # Show an error message and exit if system is passed and no pipfile exists",
            "        if system and not project.s.PIPENV_VIRTUALENV:",
            "            raise exceptions.PipenvOptionsError(",
            "                \"--system\",",
            "                \"--system is intended to be used for pre-existing Pipfile \"",
            "                \"installation, not installation of specific packages. Aborting.\"",
            "            )",
            "        # If there's a requirements file, but no Pipfile...",
            "        if project.requirements_exists and not skip_requirements:",
            "            click.echo(",
            "                crayons.normal(",
            "                    fix_utf8(\"requirements.txt found, instead of Pipfile! Converting...\"),",
            "                    bold=True,",
            "                )",
            "            )",
            "            # Create a Pipfile...",
            "            project.create_pipfile(python=python)",
            "            with create_spinner(\"Importing requirements...\", project.s) as sp:",
            "                # Import requirements.txt.",
            "                try:",
            "                    import_requirements(project)",
            "                except Exception:",
            "                    sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Failed...\"))",
            "                else:",
            "                    sp.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Success!\"))",
            "            # Warn the user of side-effects.",
            "            click.echo(",
            "                \"{0}: Your {1} now contains pinned versions, if your {2} did. \\n\"",
            "                \"We recommend updating your {1} to specify the {3} version, instead.\"",
            "                \"\".format(",
            "                    crayons.red(\"Warning\", bold=True),",
            "                    crayons.normal(\"Pipfile\", bold=True),",
            "                    crayons.normal(\"requirements.txt\", bold=True),",
            "                    crayons.normal('\"*\"', bold=True),",
            "                )",
            "            )",
            "        else:",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Creating a Pipfile for this project...\"), bold=True),",
            "                err=True,",
            "            )",
            "            # Create the pipfile if it doesn't exist.",
            "            project.create_pipfile(python=python)",
            "    # Validate the Pipfile's contents.",
            "    if validate and project.virtualenv_exists and not project.s.PIPENV_SKIP_VALIDATION:",
            "        # Ensure that Pipfile is using proper casing.",
            "        p = project.parsed_pipfile",
            "        changed = project.ensure_proper_casing()",
            "        # Write changes out to disk.",
            "        if changed:",
            "            click.echo(",
            "                crayons.normal(\"Fixing package names in Pipfile...\", bold=True), err=True",
            "            )",
            "            project.write_toml(p)",
            "",
            "",
            "def find_a_system_python(line):",
            "    \"\"\"Find a Python installation from a given line.",
            "",
            "    This tries to parse the line in various of ways:",
            "",
            "    * Looks like an absolute path? Use it directly.",
            "    * Looks like a py.exe call? Use py.exe to get the executable.",
            "    * Starts with \"py\" something? Looks like a python command. Try to find it",
            "      in PATH, and use it directly.",
            "    * Search for \"python\" and \"pythonX.Y\" executables in PATH to find a match.",
            "    * Nothing fits, return None.",
            "    \"\"\"",
            "",
            "    from .vendor.pythonfinder import Finder",
            "    finder = Finder(system=False, global_search=True)",
            "    if not line:",
            "        return next(iter(finder.find_all_python_versions()), None)",
            "    # Use the windows finder executable",
            "    if (line.startswith(\"py \") or line.startswith(\"py.exe \")) and os.name == \"nt\":",
            "        line = line.split(\" \", 1)[1].lstrip(\"-\")",
            "    python_entry = find_python(finder, line)",
            "    return python_entry",
            "",
            "",
            "def ensure_python(project, three=None, python=None):",
            "    # Runtime import is necessary due to the possibility that the environments module may have been reloaded.",
            "    if project.s.PIPENV_PYTHON and python is False and three is None:",
            "        python = project.s.PIPENV_PYTHON",
            "",
            "    def abort(msg=''):",
            "        click.echo(",
            "            \"{}\\nYou can specify specific versions of Python with:\\n{}\".format(",
            "                crayons.red(msg),",
            "                crayons.yellow(",
            "                    \"$ pipenv --python {}\".format(",
            "                        os.sep.join((\"path\", \"to\", \"python\"))",
            "                    )",
            "                )",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "",
            "    project.s.USING_DEFAULT_PYTHON = three is None and not python",
            "    # Find out which python is desired.",
            "    if not python:",
            "        python = convert_three_to_python(three, python)",
            "    if not python:",
            "        python = project.required_python_version",
            "    if not python:",
            "        python = project.s.PIPENV_DEFAULT_PYTHON_VERSION",
            "    path_to_python = find_a_system_python(python)",
            "    if project.s.is_verbose():",
            "        click.echo(f\"Using python: {python}\", err=True)",
            "        click.echo(f\"Path to python: {path_to_python}\", err=True)",
            "    if not path_to_python and python is not None:",
            "        # We need to install Python.",
            "        click.echo(",
            "            \"{}: Python {} {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                crayons.cyan(python),",
            "                fix_utf8(\"was not found on your system...\"),",
            "            ),",
            "            err=True,",
            "        )",
            "        # check for python installers",
            "        from .installers import Asdf, InstallerError, InstallerNotFound, Pyenv",
            "",
            "        # prefer pyenv if both pyenv and asdf are installed as it's",
            "        # dedicated to python installs so probably the preferred",
            "        # method of the user for new python installs.",
            "        installer = None",
            "        if not project.s.PIPENV_DONT_USE_PYENV:",
            "            try:",
            "                installer = Pyenv(project)",
            "            except InstallerNotFound:",
            "                pass",
            "        if installer is None and not project.s.PIPENV_DONT_USE_ASDF:",
            "            try:",
            "                installer = Asdf(project)",
            "            except InstallerNotFound:",
            "                pass",
            "",
            "        if not installer:",
            "            abort(\"Neither 'pyenv' nor 'asdf' could be found to install Python.\")",
            "        else:",
            "            if environments.SESSION_IS_INTERACTIVE or project.s.PIPENV_YES:",
            "                try:",
            "                    version = installer.find_version_to_install(python)",
            "                except ValueError:",
            "                    abort()",
            "                except InstallerError as e:",
            "                    abort(f'Something went wrong while installing Python:\\n{e.err}')",
            "                s = \"{} {} {}\".format(",
            "                    \"Would you like us to install\",",
            "                    crayons.green(f\"CPython {version}\"),",
            "                    f\"with {installer}?\",",
            "                )",
            "                # Prompt the user to continue...",
            "                if not (project.s.PIPENV_YES or click.confirm(s, default=True)):",
            "                    abort()",
            "                else:",
            "                    # Tell the user we're installing Python.",
            "                    click.echo(",
            "                        \"{} {} {} {}{}\".format(",
            "                            crayons.normal(\"Installing\", bold=True),",
            "                            crayons.green(f\"CPython {version}\", bold=True),",
            "                            crayons.normal(f\"with {installer.cmd}\", bold=True),",
            "                            crayons.normal(\"(this may take a few minutes)\"),",
            "                            crayons.normal(\"...\", bold=True),",
            "                        )",
            "                    )",
            "                    with create_spinner(\"Installing python...\", project.s) as sp:",
            "                        try:",
            "                            c = installer.install(version)",
            "                        except InstallerError as e:",
            "                            sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "                                \"Failed...\")",
            "                            )",
            "                            click.echo(fix_utf8(\"Something went wrong...\"), err=True)",
            "                            click.echo(crayons.cyan(e.err), err=True)",
            "                        else:",
            "                            sp.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Success!\"))",
            "                            # Print the results, in a beautiful blue...",
            "                            click.echo(crayons.cyan(c.stdout), err=True)",
            "                            # Clear the pythonfinder caches",
            "                            from .vendor.pythonfinder import Finder",
            "                            finder = Finder(system=False, global_search=True)",
            "                            finder.find_python_version.cache_clear()",
            "                            finder.find_all_python_versions.cache_clear()",
            "                    # Find the newly installed Python, hopefully.",
            "                    version = str(version)",
            "                    path_to_python = find_a_system_python(version)",
            "                    try:",
            "                        assert python_version(path_to_python) == version",
            "                    except AssertionError:",
            "                        click.echo(",
            "                            \"{}: The Python you just installed is not available on your {}, apparently.\"",
            "                            \"\".format(",
            "                                crayons.red(\"Warning\", bold=True),",
            "                                crayons.normal(\"PATH\", bold=True),",
            "                            ),",
            "                            err=True,",
            "                        )",
            "                        sys.exit(1)",
            "    return path_to_python",
            "",
            "",
            "def ensure_virtualenv(project, three=None, python=None, site_packages=None, pypi_mirror=None):",
            "    \"\"\"Creates a virtualenv, if one doesn't exist.\"\"\"",
            "",
            "    def abort():",
            "        sys.exit(1)",
            "",
            "    if not project.virtualenv_exists:",
            "        try:",
            "            # Ensure environment variables are set properly.",
            "            ensure_environment()",
            "            # Ensure Python is available.",
            "            python = ensure_python(project, three=three, python=python)",
            "            if python is not None and not isinstance(python, str):",
            "                python = python.path.as_posix()",
            "            # Create the virtualenv.",
            "            # Abort if --system (or running in a virtualenv).",
            "            if project.s.PIPENV_USE_SYSTEM:",
            "                click.echo(",
            "                    crayons.red(",
            "                        \"You are attempting to re\u2013create a virtualenv that \"",
            "                        \"Pipenv did not create. Aborting.\"",
            "                    )",
            "                )",
            "                sys.exit(1)",
            "            do_create_virtualenv(",
            "                project, python=python, site_packages=site_packages, pypi_mirror=pypi_mirror",
            "            )",
            "        except KeyboardInterrupt:",
            "            # If interrupted, cleanup the virtualenv.",
            "            cleanup_virtualenv(project, bare=False)",
            "            sys.exit(1)",
            "    # If --three, --two, or --python were passed...",
            "    elif (python) or (three is not None) or (site_packages is not None):",
            "        project.s.USING_DEFAULT_PYTHON = False",
            "        # Ensure python is installed before deleting existing virtual env",
            "        python = ensure_python(project, three=three, python=python)",
            "        if python is not None and not isinstance(python, str):",
            "            python = python.path.as_posix()",
            "",
            "        click.echo(crayons.red(\"Virtualenv already exists!\"), err=True)",
            "        # If VIRTUAL_ENV is set, there is a possibility that we are",
            "        # going to remove the active virtualenv that the user cares",
            "        # about, so confirm first.",
            "        if \"VIRTUAL_ENV\" in os.environ:",
            "            if not (",
            "                project.s.PIPENV_YES or click.confirm(\"Remove existing virtualenv?\", default=True)",
            "            ):",
            "                abort()",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Removing existing virtualenv...\"), bold=True), err=True",
            "        )",
            "        # Remove the virtualenv.",
            "        cleanup_virtualenv(project, bare=True)",
            "        # Call this function again.",
            "        ensure_virtualenv(",
            "            project,",
            "            three=three,",
            "            python=python,",
            "            site_packages=site_packages,",
            "            pypi_mirror=pypi_mirror,",
            "        )",
            "",
            "",
            "def ensure_project(",
            "    project,",
            "    three=None,",
            "    python=None,",
            "    validate=True,",
            "    system=False,",
            "    warn=True,",
            "    site_packages=None,",
            "    deploy=False,",
            "    skip_requirements=False,",
            "    pypi_mirror=None,",
            "    clear=False,",
            "):",
            "    \"\"\"Ensures both Pipfile and virtualenv exist for the project.\"\"\"",
            "",
            "    # Automatically use an activated virtualenv.",
            "    if project.s.PIPENV_USE_SYSTEM:",
            "        system = True",
            "    if not project.pipfile_exists and deploy:",
            "        raise exceptions.PipfileNotFound",
            "    # Skip virtualenv creation when --system was used.",
            "    if not system:",
            "        ensure_virtualenv(",
            "            project,",
            "            three=three,",
            "            python=python,",
            "            site_packages=site_packages,",
            "            pypi_mirror=pypi_mirror,",
            "        )",
            "        if warn:",
            "            # Warn users if they are using the wrong version of Python.",
            "            if project.required_python_version:",
            "                path_to_python = project._which(\"python\") or project._which(\"py\")",
            "                if path_to_python and project.required_python_version not in (",
            "                    python_version(path_to_python) or \"\"",
            "                ):",
            "                    click.echo(",
            "                        \"{}: Your Pipfile requires {} {}, \"",
            "                        \"but you are using {} ({}).\".format(",
            "                            crayons.red(\"Warning\", bold=True),",
            "                            crayons.normal(\"python_version\", bold=True),",
            "                            crayons.cyan(project.required_python_version),",
            "                            crayons.cyan(python_version(path_to_python) or \"unknown\"),",
            "                            crayons.green(shorten_path(path_to_python)),",
            "                        ),",
            "                        err=True,",
            "                    )",
            "                    click.echo(",
            "                        \"  {} and rebuilding the virtual environment \"",
            "                        \"may resolve the issue.\".format(crayons.green(\"$ pipenv --rm\")),",
            "                        err=True,",
            "                    )",
            "                    if not deploy:",
            "                        click.echo(",
            "                            \"  {} will surely fail.\"",
            "                            \"\".format(crayons.yellow(\"$ pipenv check\")),",
            "                            err=True,",
            "                        )",
            "                    else:",
            "                        raise exceptions.DeployException",
            "    # Ensure the Pipfile exists.",
            "    ensure_pipfile(",
            "        project, validate=validate, skip_requirements=skip_requirements, system=system",
            "    )",
            "",
            "",
            "def shorten_path(location, bold=False):",
            "    \"\"\"Returns a visually shorter representation of a given system path.\"\"\"",
            "    original = location",
            "    short = os.sep.join(",
            "        [s[0] if len(s) > (len(\"2long4\")) else s for s in location.split(os.sep)]",
            "    )",
            "    short = short.split(os.sep)",
            "    short[-1] = original.split(os.sep)[-1]",
            "    if bold:",
            "        short[-1] = str(crayons.normal(short[-1], bold=True))",
            "    return os.sep.join(short)",
            "",
            "",
            "# return short",
            "def do_where(project, virtualenv=False, bare=True):",
            "    \"\"\"Executes the where functionality.\"\"\"",
            "    if not virtualenv:",
            "        if not project.pipfile_exists:",
            "            click.echo(",
            "                \"No Pipfile present at project home. Consider running \"",
            "                \"{} first to automatically generate a Pipfile for you.\"",
            "                \"\".format(crayons.green(\"`pipenv install`\")),",
            "                err=True,",
            "            )",
            "            return",
            "        location = project.pipfile_location",
            "        # Shorten the virtual display of the path to the virtualenv.",
            "        if not bare:",
            "            location = shorten_path(location)",
            "            click.echo(",
            "                \"Pipfile found at {}.\\n  Considering this to be the project home.\"",
            "                \"\".format(crayons.green(location)),",
            "                err=True,",
            "            )",
            "        else:",
            "            click.echo(project.project_directory)",
            "    else:",
            "        location = project.virtualenv_location",
            "        if not bare:",
            "            click.echo(",
            "                f\"Virtualenv location: {crayons.green(location)}\", err=True",
            "            )",
            "        else:",
            "            click.echo(location)",
            "",
            "",
            "def _cleanup_procs(project, procs, failed_deps_queue, retry=True):",
            "    while not procs.empty():",
            "        c = procs.get()",
            "        try:",
            "            out, err = c.communicate()",
            "        except AttributeError:",
            "            out, err = c.stdout, c.stderr",
            "        failed = c.returncode != 0",
            "        if \"Ignoring\" in out:",
            "            click.echo(crayons.yellow(out.strip()))",
            "        elif project.s.is_verbose():",
            "            click.echo(crayons.cyan(out.strip() or err.strip()))",
            "        # The Installation failed...",
            "        if failed:",
            "            # If there is a mismatch in installed locations or the install fails",
            "            # due to wrongful disabling of pep517, we should allow for",
            "            # additional passes at installation",
            "            if \"does not match installed location\" in err:",
            "                project.environment.expand_egg_links()",
            "                click.echo(\"{}\".format(",
            "                    crayons.yellow(",
            "                        \"Failed initial installation: Failed to overwrite existing \"",
            "                        \"package, likely due to path aliasing. Expanding and trying \"",
            "                        \"again!\"",
            "                    )",
            "                ))",
            "                dep = c.dep.copy()",
            "                dep.use_pep517 = True",
            "            elif \"Disabling PEP 517 processing is invalid\" in err:",
            "                dep = c.dep.copy()",
            "                dep.use_pep517 = True",
            "            elif not retry:",
            "                # The Installation failed...",
            "                # We echo both c.stdout and c.stderr because pip returns error details on out.",
            "                err = err.strip().splitlines() if err else []",
            "                out = out.strip().splitlines() if out else []",
            "                err_lines = [line for message in [out, err] for line in message]",
            "                # Return the subprocess' return code.",
            "                raise exceptions.InstallError(c.dep.name, extra=err_lines)",
            "            else:",
            "                # Alert the user.",
            "                dep = c.dep.copy()",
            "                dep.use_pep517 = False",
            "                click.echo(",
            "                    \"{} {}! Will try again.\".format(",
            "                        crayons.red(\"An error occurred while installing\"),",
            "                        crayons.green(dep.as_line()),",
            "                    ), err=True",
            "                )",
            "            # Save the Failed Dependency for later.",
            "            failed_deps_queue.put(dep)",
            "",
            "",
            "def batch_install(project, deps_list, procs, failed_deps_queue,",
            "                  requirements_dir, no_deps=True, ignore_hashes=False,",
            "                  allow_global=False, blocking=False, pypi_mirror=None,",
            "                  retry=True, sequential_deps=None):",
            "    from .vendor.requirementslib.models.utils import (",
            "        strip_extras_markers_from_requirement",
            "    )",
            "    if sequential_deps is None:",
            "        sequential_deps = []",
            "    failed = (not retry)",
            "    install_deps = not no_deps",
            "    if not failed:",
            "        label = INSTALL_LABEL if not environments.PIPENV_HIDE_EMOJIS else \"\"",
            "    else:",
            "        label = INSTALL_LABEL2",
            "",
            "    deps_to_install = deps_list[:]",
            "    deps_to_install.extend(sequential_deps)",
            "    deps_to_install = [",
            "        dep for dep in deps_to_install if not project.environment.is_satisfied(dep)",
            "    ]",
            "    sequential_dep_names = [d.name for d in sequential_deps]",
            "",
            "    deps_list_bar = progress.bar(",
            "        deps_to_install, width=32,",
            "        label=label",
            "    )",
            "",
            "    trusted_hosts = []",
            "    # Install these because",
            "    for dep in deps_list_bar:",
            "        extra_indexes = []",
            "        if dep.req.req:",
            "            dep.req.req = strip_extras_markers_from_requirement(dep.req.req)",
            "        if dep.markers:",
            "            dep.markers = str(strip_extras_markers_from_requirement(dep.get_markers()))",
            "        # Install the module.",
            "        is_artifact = False",
            "        if dep.is_file_or_url and (dep.is_direct_url or any(",
            "            dep.req.uri.endswith(ext) for ext in [\"zip\", \"tar.gz\"]",
            "        )):",
            "            is_artifact = True",
            "        elif dep.is_vcs:",
            "            is_artifact = True",
            "        if not project.s.PIPENV_RESOLVE_VCS and is_artifact and not dep.editable:",
            "            install_deps = True",
            "            no_deps = False",
            "",
            "        with vistir.contextmanagers.temp_environ():",
            "            if not allow_global:",
            "                os.environ[\"PIP_USER\"] = vistir.compat.fs_str(\"0\")",
            "                if \"PYTHONHOME\" in os.environ:",
            "                    del os.environ[\"PYTHONHOME\"]",
            "            if \"GIT_CONFIG\" in os.environ and dep.is_vcs:",
            "                del os.environ[\"GIT_CONFIG\"]",
            "            use_pep517 = True",
            "            if failed and not dep.is_vcs:",
            "                use_pep517 = getattr(dep, \"use_pep517\", False)",
            "",
            "            is_sequential = sequential_deps and dep.name in sequential_dep_names",
            "            is_blocking = any([dep.editable, dep.is_vcs, blocking, is_sequential])",
            "            c = pip_install(",
            "                project,",
            "                dep,",
            "                ignore_hashes=any([ignore_hashes, dep.editable, dep.is_vcs]),",
            "                allow_global=allow_global,",
            "                no_deps=not install_deps,",
            "                block=is_blocking,",
            "                index=dep.index,",
            "                requirements_dir=requirements_dir,",
            "                pypi_mirror=pypi_mirror,",
            "                trusted_hosts=trusted_hosts,",
            "                extra_indexes=extra_indexes,",
            "                use_pep517=use_pep517,",
            "            )",
            "            c.dep = dep",
            "",
            "            procs.put(c)",
            "            if procs.full() or procs.qsize() == len(deps_list) or is_sequential:",
            "                _cleanup_procs(project, procs, failed_deps_queue, retry=retry)",
            "",
            "",
            "def do_install_dependencies(",
            "    project,",
            "    dev=False,",
            "    dev_only=False,",
            "    bare=False,",
            "    emit_requirements=False,",
            "    allow_global=False,",
            "    ignore_hashes=False,",
            "    skip_lock=False,",
            "    concurrent=True,",
            "    requirements_dir=None,",
            "    pypi_mirror=None,",
            "):",
            "    \"\"\"\"",
            "    Executes the install functionality.",
            "",
            "    If emit_requirements is True, simply spits out a requirements format to stdout.",
            "    \"\"\"",
            "",
            "    import queue",
            "    if emit_requirements:",
            "        bare = True",
            "    # Load the lockfile if it exists, or if dev_only is being used.",
            "    if skip_lock or not project.lockfile_exists:",
            "        if not bare:",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Installing dependencies from Pipfile...\"), bold=True)",
            "            )",
            "        # skip_lock should completely bypass the lockfile (broken in 4dac1676)",
            "        lockfile = project.get_or_create_lockfile(from_pipfile=True)",
            "    else:",
            "        lockfile = project.get_or_create_lockfile()",
            "        if not bare:",
            "            click.echo(",
            "                crayons.normal(",
            "                    fix_utf8(\"Installing dependencies from Pipfile.lock ({})...\".format(",
            "                        lockfile[\"_meta\"].get(\"hash\", {}).get(\"sha256\")[-6:]",
            "                    )),",
            "                    bold=True,",
            "                )",
            "            )",
            "    # Allow pip to resolve dependencies when in skip-lock mode.",
            "    no_deps = not skip_lock  # skip_lock true, no_deps False, pip resolves deps",
            "    dev = dev or dev_only",
            "    deps_list = list(lockfile.get_requirements(dev=dev, only=dev_only))",
            "    if emit_requirements:",
            "        index_args = prepare_pip_source_args(",
            "            get_source_list(project, pypi_mirror=pypi_mirror)",
            "        )",
            "        index_args = \" \".join(index_args).replace(\" -\", \"\\n-\")",
            "        deps = [",
            "            req.as_line(sources=False, include_hashes=False) for req in deps_list",
            "        ]",
            "        click.echo(index_args)",
            "        click.echo(\"\\n\".join(sorted(deps)))",
            "        sys.exit(0)",
            "    if concurrent:",
            "        nprocs = project.s.PIPENV_MAX_SUBPROCESS",
            "    else:",
            "        nprocs = 1",
            "    procs = queue.Queue(maxsize=nprocs)",
            "    failed_deps_queue = queue.Queue()",
            "    if skip_lock:",
            "        ignore_hashes = True",
            "    editable_or_vcs_deps = [dep for dep in deps_list if (dep.editable or dep.vcs)]",
            "    normal_deps = [dep for dep in deps_list if not (dep.editable or dep.vcs)]",
            "    install_kwargs = {",
            "        \"no_deps\": no_deps, \"ignore_hashes\": ignore_hashes, \"allow_global\": allow_global,",
            "        \"blocking\": not concurrent, \"pypi_mirror\": pypi_mirror,",
            "        \"sequential_deps\": editable_or_vcs_deps",
            "    }",
            "",
            "    batch_install(",
            "        project, normal_deps, procs, failed_deps_queue, requirements_dir, **install_kwargs",
            "    )",
            "",
            "    if not procs.empty():",
            "        _cleanup_procs(project, procs, failed_deps_queue)",
            "",
            "    # click.echo(crayons.normal(",
            "    #     decode_for_output(\"Installing editable and vcs dependencies...\"), bold=True",
            "    # ))",
            "",
            "    # install_kwargs.update({\"blocking\": True})",
            "    # # XXX: All failed and editable/vcs deps should be installed in sequential mode!",
            "    # procs = queue.Queue(maxsize=1)",
            "    # batch_install(",
            "    #     editable_or_vcs_deps, procs, failed_deps_queue, requirements_dir,",
            "    #     **install_kwargs",
            "    # )",
            "",
            "    # Iterate over the hopefully-poorly-packaged dependencies...",
            "    if not failed_deps_queue.empty():",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Installing initially failed dependencies...\"), bold=True)",
            "        )",
            "        retry_list = []",
            "        while not failed_deps_queue.empty():",
            "            failed_dep = failed_deps_queue.get()",
            "            retry_list.append(failed_dep)",
            "        install_kwargs.update({\"retry\": False})",
            "        batch_install(",
            "            project, retry_list, procs, failed_deps_queue, requirements_dir, **install_kwargs",
            "        )",
            "    if not procs.empty():",
            "        _cleanup_procs(project, procs, failed_deps_queue, retry=False)",
            "",
            "",
            "def convert_three_to_python(three, python):",
            "    \"\"\"Converts a Three flag into a Python flag, and raises customer warnings",
            "    in the process, if needed.",
            "    \"\"\"",
            "    if not python:",
            "        if three is False:",
            "            return \"2\"",
            "",
            "        elif three is True:",
            "            return \"3\"",
            "",
            "    else:",
            "        return python",
            "",
            "",
            "def do_create_virtualenv(project, python=None, site_packages=None, pypi_mirror=None):",
            "    \"\"\"Creates a virtualenv.\"\"\"",
            "",
            "    click.echo(",
            "        crayons.normal(fix_utf8(\"Creating a virtualenv for this project...\"), bold=True), err=True",
            "    )",
            "    click.echo(",
            "        f\"Pipfile: {crayons.yellow(project.pipfile_location, bold=True)}\",",
            "        err=True,",
            "    )",
            "",
            "    # Default to using sys.executable, if Python wasn't provided.",
            "    using_string = \"Using\"",
            "    if not python:",
            "        python = sys.executable",
            "        using_string = \"Using default python from\"",
            "    click.echo(",
            "        \"{0} {1} {3} {2}\".format(",
            "            crayons.normal(using_string, bold=True),",
            "            crayons.yellow(python, bold=True),",
            "            crayons.normal(fix_utf8(\"to create virtualenv...\"), bold=True),",
            "            crayons.green(f\"({python_version(python)})\"),",
            "        ),",
            "        err=True,",
            "    )",
            "",
            "    cmd = [",
            "        Path(sys.executable).absolute().as_posix(),",
            "        \"-m\",",
            "        \"virtualenv\",",
            "        f\"--prompt={project.name}\",",
            "        f\"--python={python}\",",
            "        project.get_location_for_virtualenv(),",
            "    ]",
            "",
            "    # Pass site-packages flag to virtualenv, if desired...",
            "    if site_packages:",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Making site-packages available...\"), bold=True), err=True",
            "        )",
            "        cmd.append(\"--system-site-packages\")",
            "",
            "    if pypi_mirror:",
            "        pip_config = {\"PIP_INDEX_URL\": vistir.misc.fs_str(pypi_mirror)}",
            "    else:",
            "        pip_config = {}",
            "",
            "    # Actually create the virtualenv.",
            "    error = None",
            "    with create_spinner(\"Creating virtual environment...\", project.s) as sp:",
            "        c = subprocess_run(cmd, env=pip_config)",
            "        click.echo(crayons.cyan(f\"{c.stdout}\"), err=True)",
            "        if c.returncode != 0:",
            "            error = c.stderr if project.s.is_verbose() else exceptions.prettify_exc(c.stderr)",
            "            sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Failed creating virtual environment\"))",
            "        else:",
            "            sp.green.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Successfully created virtual environment!\"))",
            "    if error is not None:",
            "        raise exceptions.VirtualenvCreationException(",
            "            extra=crayons.red(f\"{error}\")",
            "        )",
            "",
            "    # Associate project directory with the environment.",
            "    # This mimics Pew's \"setproject\".",
            "    project_file_name = os.path.join(project.virtualenv_location, \".project\")",
            "    with open(project_file_name, \"w\") as f:",
            "        f.write(vistir.misc.fs_str(project.project_directory))",
            "    from .environment import Environment",
            "    sources = project.pipfile_sources",
            "    # project.get_location_for_virtualenv is only for if we are creating a new virtualenv",
            "    # whereas virtualenv_location is for the current path to the runtime",
            "    project._environment = Environment(",
            "        prefix=project.virtualenv_location,",
            "        is_venv=True,",
            "        sources=sources,",
            "        pipfile=project.parsed_pipfile,",
            "        project=project",
            "    )",
            "    project._environment.add_dist(\"pipenv\")",
            "    # Say where the virtualenv is.",
            "    do_where(project, virtualenv=True, bare=False)",
            "",
            "",
            "def parse_download_fname(fname, name):",
            "    fname, fextension = os.path.splitext(fname)",
            "    if fextension == \".whl\":",
            "        fname = \"-\".join(fname.split(\"-\")[:-3])",
            "    if fname.endswith(\".tar\"):",
            "        fname, _ = os.path.splitext(fname)",
            "    # Substring out package name (plus dash) from file name to get version.",
            "    version = fname[len(name) + 1 :]",
            "    # Ignore implicit post releases in version number.",
            "    if \"-\" in version and version.split(\"-\")[1].isdigit():",
            "        version = version.split(\"-\")[0]",
            "    return version",
            "",
            "",
            "def get_downloads_info(project, names_map, section):",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    info = []",
            "    p = project.parsed_pipfile",
            "    for fname in os.listdir(project.download_location):",
            "        # Get name from filename mapping.",
            "        name = Requirement.from_line(names_map[fname]).name",
            "        # Get the version info from the filenames.",
            "        version = parse_download_fname(fname, name)",
            "        # Get the hash of each file.",
            "        cmd = [",
            "            which_pip(project),",
            "            \"hash\",",
            "            os.sep.join([project.download_location, fname]),",
            "        ]",
            "        c = subprocess_run(cmd)",
            "        hash = c.stdout.split(\"--hash=\")[1].strip()",
            "        # Verify we're adding the correct version from Pipfile",
            "        # and not one from a dependency.",
            "        specified_version = p[section].get(name, \"\")",
            "        if is_required_version(version, specified_version):",
            "            info.append(dict(name=name, version=version, hash=hash))",
            "    return info",
            "",
            "",
            "def overwrite_dev(prod, dev):",
            "    dev_keys = set(list(dev.keys()))",
            "    prod_keys = set(list(prod.keys()))",
            "    for pkg in dev_keys & prod_keys:",
            "        dev[pkg] = prod[pkg]",
            "    return dev",
            "",
            "",
            "def do_lock(",
            "    project,",
            "    ctx=None,",
            "    system=False,",
            "    clear=False,",
            "    pre=False,",
            "    keep_outdated=False,",
            "    write=True,",
            "    pypi_mirror=None,",
            "):",
            "    \"\"\"Executes the freeze functionality.\"\"\"",
            "",
            "    cached_lockfile = {}",
            "    if not pre:",
            "        pre = project.settings.get(\"allow_prereleases\")",
            "    if keep_outdated:",
            "        if not project.lockfile_exists:",
            "            raise exceptions.PipenvOptionsError(",
            "                \"--keep-outdated\", ctx=ctx,",
            "                message=\"Pipfile.lock must exist to use --keep-outdated!\"",
            "            )",
            "        cached_lockfile = project.lockfile_content",
            "    # Create the lockfile.",
            "    lockfile = project._lockfile",
            "    # Cleanup lockfile.",
            "    for section in (\"default\", \"develop\"):",
            "        for k, v in lockfile[section].copy().items():",
            "            if not hasattr(v, \"keys\"):",
            "                del lockfile[section][k]",
            "    # Ensure that develop inherits from default.",
            "    dev_packages = project.dev_packages.copy()",
            "    dev_packages = overwrite_dev(project.packages, dev_packages)",
            "    # Resolve dev-package dependencies, with pip-tools.",
            "    for is_dev in [True, False]:",
            "        pipfile_section = \"dev-packages\" if is_dev else \"packages\"",
            "        if project.pipfile_exists:",
            "            packages = project.parsed_pipfile.get(pipfile_section, {})",
            "        else:",
            "            packages = getattr(project, pipfile_section.replace(\"-\", \"_\"))",
            "",
            "        if write:",
            "            # Alert the user of progress.",
            "            click.echo(",
            "                \"{} {} {}\".format(",
            "                    crayons.normal(\"Locking\"),",
            "                    crayons.yellow(\"[{}]\".format(pipfile_section.replace(\"_\", \"-\"))),",
            "                    crayons.normal(fix_utf8(\"dependencies...\")),",
            "                ),",
            "                err=True,",
            "            )",
            "",
            "        # Mutates the lockfile",
            "        venv_resolve_deps(",
            "            packages,",
            "            which=project._which,",
            "            project=project,",
            "            dev=is_dev,",
            "            clear=clear,",
            "            pre=pre,",
            "            allow_global=system,",
            "            pypi_mirror=pypi_mirror,",
            "            pipfile=packages,",
            "            lockfile=lockfile,",
            "            keep_outdated=keep_outdated",
            "        )",
            "",
            "    # Support for --keep-outdated...",
            "    if keep_outdated:",
            "        from pipenv.vendor.packaging.utils import canonicalize_name",
            "        for section_name, section in (",
            "            (\"default\", project.packages),",
            "            (\"develop\", project.dev_packages),",
            "        ):",
            "            for package_specified in section.keys():",
            "                if not is_pinned(section[package_specified]):",
            "                    canonical_name = canonicalize_name(package_specified)",
            "                    if canonical_name in cached_lockfile[section_name]:",
            "                        lockfile[section_name][canonical_name] = cached_lockfile[",
            "                            section_name",
            "                        ][canonical_name].copy()",
            "            for key in [\"default\", \"develop\"]:",
            "                packages = set(cached_lockfile[key].keys())",
            "                new_lockfile = set(lockfile[key].keys())",
            "                missing = packages - new_lockfile",
            "                for missing_pkg in missing:",
            "                    lockfile[key][missing_pkg] = cached_lockfile[key][missing_pkg].copy()",
            "    # Overwrite any develop packages with default packages.",
            "    lockfile[\"develop\"].update(overwrite_dev(lockfile.get(\"default\", {}), lockfile[\"develop\"]))",
            "    if write:",
            "        project.write_lockfile(lockfile)",
            "        click.echo(",
            "            \"{}\".format(",
            "                crayons.normal(",
            "                    \"Updated Pipfile.lock ({})!\".format(",
            "                        lockfile[\"_meta\"].get(\"hash\", {}).get(\"sha256\")[-6:]",
            "                    ),",
            "                    bold=True,",
            "                )",
            "            ),",
            "            err=True,",
            "        )",
            "    else:",
            "        return lockfile",
            "",
            "",
            "def do_purge(project, bare=False, downloads=False, allow_global=False):",
            "    \"\"\"Executes the purge functionality.\"\"\"",
            "",
            "    if downloads:",
            "        if not bare:",
            "            click.echo(crayons.normal(fix_utf8(\"Clearing out downloads directory...\"), bold=True))",
            "        vistir.path.rmtree(project.download_location)",
            "        return",
            "",
            "    # Remove comments from the output, if any.",
            "    installed = {",
            "        pep423_name(pkg.project_name) for pkg in project.environment.get_installed_packages()",
            "    }",
            "    bad_pkgs = {pep423_name(pkg) for pkg in BAD_PACKAGES}",
            "    # Remove setuptools, pip, etc from targets for removal",
            "    to_remove = installed - bad_pkgs",
            "",
            "    # Skip purging if there is no packages which needs to be removed",
            "    if not to_remove:",
            "        if not bare:",
            "            click.echo(\"Found 0 installed package, skip purging.\")",
            "            click.echo(crayons.green(\"Environment now purged and fresh!\"))",
            "        return installed",
            "",
            "    if not bare:",
            "        click.echo(",
            "            fix_utf8(f\"Found {len(to_remove)} installed package(s), purging...\")",
            "        )",
            "",
            "    command = [",
            "        which_pip(project, allow_global=allow_global),",
            "        \"uninstall\", \"-y\",",
            "    ] + list(to_remove)",
            "    if project.s.is_verbose():",
            "        click.echo(f\"$ {cmd_list_to_shell(command)}\")",
            "    c = subprocess_run(command)",
            "    if c.returncode != 0:",
            "        raise exceptions.UninstallError(installed, cmd_list_to_shell(command), c.stdout + c.stderr, c.returncode)",
            "    if not bare:",
            "        click.echo(crayons.cyan(c.stdout))",
            "        click.echo(crayons.green(\"Environment now purged and fresh!\"))",
            "    return installed",
            "",
            "",
            "def do_init(",
            "    project,",
            "    dev=False,",
            "    dev_only=False,",
            "    emit_requirements=False,",
            "    allow_global=False,",
            "    ignore_pipfile=False,",
            "    skip_lock=False,",
            "    system=False,",
            "    concurrent=True,",
            "    deploy=False,",
            "    pre=False,",
            "    keep_outdated=False,",
            "    requirements_dir=None,",
            "    pypi_mirror=None,",
            "):",
            "    \"\"\"Executes the init functionality.\"\"\"",
            "",
            "    python = None",
            "    if project.s.PIPENV_PYTHON is not None:",
            "        python = project.s.PIPENV_PYTHON",
            "    elif project.s.PIPENV_DEFAULT_PYTHON_VERSION is not None:",
            "        python = project.s.PIPENV_DEFAULT_PYTHON_VERSION",
            "",
            "    if not system and not project.s.PIPENV_USE_SYSTEM:",
            "        if not project.virtualenv_exists:",
            "            try:",
            "                do_create_virtualenv(project, python=python, three=None, pypi_mirror=pypi_mirror)",
            "            except KeyboardInterrupt:",
            "                cleanup_virtualenv(project, bare=False)",
            "                sys.exit(1)",
            "    # Ensure the Pipfile exists.",
            "    if not deploy:",
            "        ensure_pipfile(project, system=system)",
            "    if not requirements_dir:",
            "        requirements_dir = vistir.path.create_tracked_tempdir(",
            "            suffix=\"-requirements\", prefix=\"pipenv-\"",
            "        )",
            "    # Write out the lockfile if it doesn't exist, but not if the Pipfile is being ignored",
            "    if (project.lockfile_exists and not ignore_pipfile) and not skip_lock:",
            "        old_hash = project.get_lockfile_hash()",
            "        new_hash = project.calculate_pipfile_hash()",
            "        if new_hash != old_hash:",
            "            if deploy:",
            "                click.echo(",
            "                    crayons.red(",
            "                        \"Your Pipfile.lock ({}) is out of date. Expected: ({}).\".format(",
            "                            old_hash[-6:], new_hash[-6:]",
            "                        )",
            "                    )",
            "                )",
            "                raise exceptions.DeployException",
            "                sys.exit(1)",
            "            elif (system or allow_global) and not (project.s.PIPENV_VIRTUALENV):",
            "                click.echo(",
            "                    crayons.yellow(fix_utf8(",
            "                        \"Pipfile.lock ({}) out of date, but installation \"",
            "                        \"uses {} re-building lockfile must happen in \"",
            "                        \"isolation. Please rebuild lockfile in a virtualenv. \"",
            "                        \"Continuing anyway...\".format(",
            "                            old_hash[-6:], \"--system\"",
            "                        ))",
            "                    ),",
            "                    err=True,",
            "                )",
            "            else:",
            "                if old_hash:",
            "                    msg = fix_utf8(\"Pipfile.lock ({0}) out of date, updating to ({1})...\")",
            "                else:",
            "                    msg = fix_utf8(\"Pipfile.lock is corrupted, replaced with ({1})...\")",
            "                click.echo(",
            "                    crayons.yellow(msg.format(old_hash[-6:], new_hash[-6:]), bold=True),",
            "                    err=True,",
            "                )",
            "                do_lock(",
            "                    project,",
            "                    system=system,",
            "                    pre=pre,",
            "                    keep_outdated=keep_outdated,",
            "                    write=True,",
            "                    pypi_mirror=pypi_mirror,",
            "                )",
            "    # Write out the lockfile if it doesn't exist.",
            "    if not project.lockfile_exists and not skip_lock:",
            "        # Unless we're in a virtualenv not managed by pipenv, abort if we're",
            "        # using the system's python.",
            "        if (system or allow_global) and not (project.s.PIPENV_VIRTUALENV):",
            "            raise exceptions.PipenvOptionsError(",
            "                \"--system\",",
            "                \"--system is intended to be used for Pipfile installation, \"",
            "                \"not installation of specific packages. Aborting.\\n\"",
            "                \"See also: --deploy flag.\"",
            "            )",
            "        else:",
            "            click.echo(",
            "                crayons.normal(fix_utf8(\"Pipfile.lock not found, creating...\"), bold=True),",
            "                err=True,",
            "            )",
            "            do_lock(",
            "                project,",
            "                system=system,",
            "                pre=pre,",
            "                keep_outdated=keep_outdated,",
            "                write=True,",
            "                pypi_mirror=pypi_mirror,",
            "            )",
            "    do_install_dependencies(",
            "        project,",
            "        dev=dev,",
            "        dev_only=dev_only,",
            "        emit_requirements=emit_requirements,",
            "        allow_global=allow_global,",
            "        skip_lock=skip_lock,",
            "        concurrent=concurrent,",
            "        requirements_dir=requirements_dir,",
            "        pypi_mirror=pypi_mirror,",
            "    )",
            "",
            "    # Hint the user what to do to activate the virtualenv.",
            "    if not allow_global and not deploy and \"PIPENV_ACTIVE\" not in os.environ:",
            "        click.echo(",
            "            \"To activate this project's virtualenv, run {}.\\n\"",
            "            \"Alternatively, run a command \"",
            "            \"inside the virtualenv with {}.\".format(",
            "                crayons.yellow(\"pipenv shell\"), crayons.yellow(\"pipenv run\")",
            "            )",
            "        )",
            "",
            "",
            "def get_pip_args(",
            "    project,",
            "    pre=False,  # type: bool",
            "    verbose=False,  # type: bool",
            "    upgrade=False,  # type: bool",
            "    require_hashes=False,  # type: bool",
            "    no_build_isolation=False,  # type: bool",
            "    no_use_pep517=False,  # type: bool",
            "    no_deps=False,  # type: bool",
            "    selective_upgrade=False,  # type: bool",
            "    src_dir=None,  # type: Optional[str]",
            "):",
            "    # type: (...) -> List[str]",
            "    from .vendor.packaging.version import parse as parse_version",
            "    arg_map = {",
            "        \"pre\": [\"--pre\"],",
            "        \"verbose\": [\"--verbose\"],",
            "        \"upgrade\": [\"--upgrade\"],",
            "        \"require_hashes\": [\"--require-hashes\"],",
            "        \"no_build_isolation\": [\"--no-build-isolation\"],",
            "        \"no_use_pep517\": [],",
            "        \"no_deps\": [\"--no-deps\"],",
            "        \"selective_upgrade\": [",
            "            \"--upgrade-strategy=only-if-needed\",",
            "            \"--exists-action={}\".format(project.s.PIP_EXISTS_ACTION or \"i\")",
            "        ],",
            "        \"src_dir\": src_dir,",
            "    }",
            "    if project.environment.pip_version >= parse_version(\"19.0\"):",
            "        arg_map[\"no_use_pep517\"].append(\"--no-use-pep517\")",
            "    if project.environment.pip_version < parse_version(\"19.1\"):",
            "        arg_map[\"no_use_pep517\"].append(\"--no-build-isolation\")",
            "    arg_set = []",
            "    for key in arg_map.keys():",
            "        if key in locals() and locals().get(key):",
            "            arg_set.extend(arg_map.get(key))",
            "        elif key == \"selective_upgrade\" and not locals().get(key):",
            "            arg_set.append(\"--exists-action=i\")",
            "    return list(vistir.misc.dedup(arg_set))",
            "",
            "",
            "def get_requirement_line(",
            "    requirement,  # type: Requirement",
            "    src_dir=None,  # type: Optional[str]",
            "    include_hashes=True,  # type: bool",
            "    format_for_file=False,  # type: bool",
            "):",
            "    # type: (...) -> Union[List[str], str]",
            "    line = None",
            "    if requirement.vcs or requirement.is_file_or_url:",
            "        if src_dir and requirement.line_instance.wheel_kwargs:",
            "            requirement.line_instance._wheel_kwargs.update({",
            "                \"src_dir\": src_dir",
            "            })",
            "        requirement.line_instance.vcsrepo",
            "        line = requirement.line_instance.line",
            "        if requirement.line_instance.markers:",
            "            line = f'{line}; {requirement.line_instance.markers}'",
            "            if not format_for_file:",
            "                line = f'\"{line}\"'",
            "        if requirement.editable:",
            "            if not format_for_file:",
            "                return [\"-e\", line]",
            "            return f'-e {line}'",
            "        if not format_for_file:",
            "            return [line]",
            "        return line",
            "    return requirement.as_line(include_hashes=include_hashes, as_list=not format_for_file)",
            "",
            "",
            "def write_requirement_to_file(",
            "    project,  # type: Project",
            "    requirement,  # type: Requirement",
            "    requirements_dir=None,  # type: Optional[str]",
            "    src_dir=None,  # type: Optional[str]",
            "    include_hashes=True  # type: bool",
            "):",
            "    # type: (...) -> str",
            "    if not requirements_dir:",
            "        requirements_dir = vistir.path.create_tracked_tempdir(",
            "            prefix=\"pipenv\", suffix=\"requirements\")",
            "    line = requirement.line_instance.get_line(",
            "        with_prefix=True, with_hashes=include_hashes, with_markers=True, as_list=False",
            "    )",
            "",
            "    f = vistir.compat.NamedTemporaryFile(",
            "        prefix=\"pipenv-\", suffix=\"-requirement.txt\", dir=requirements_dir,",
            "        delete=False",
            "    )",
            "    if project.s.is_verbose():",
            "        click.echo(",
            "            f\"Writing supplied requirement line to temporary file: {line!r}\",",
            "            err=True",
            "        )",
            "    f.write(vistir.misc.to_bytes(line))",
            "    r = f.name",
            "    f.close()",
            "    return r",
            "",
            "",
            "def pip_install(",
            "    project,",
            "    requirement=None,",
            "    r=None,",
            "    allow_global=False,",
            "    ignore_hashes=False,",
            "    no_deps=None,",
            "    block=True,",
            "    index=None,",
            "    pre=False,",
            "    selective_upgrade=False,",
            "    requirements_dir=None,",
            "    extra_indexes=None,",
            "    pypi_mirror=None,",
            "    trusted_hosts=None,",
            "    use_pep517=True",
            "):",
            "    piplogger = logging.getLogger(\"pipenv.patched.notpip._internal.commands.install\")",
            "    src_dir = None",
            "    if not trusted_hosts:",
            "        trusted_hosts = []",
            "",
            "    trusted_hosts.extend(os.environ.get(\"PIP_TRUSTED_HOSTS\", []))",
            "    if not allow_global:",
            "        src_dir = os.getenv(\"PIP_SRC\", os.getenv(\"PIP_SRC_DIR\", project.virtualenv_src_location))",
            "    else:",
            "        src_dir = os.getenv(\"PIP_SRC\", os.getenv(\"PIP_SRC_DIR\"))",
            "    if requirement:",
            "        if requirement.editable or not requirement.hashes:",
            "            ignore_hashes = True",
            "        elif not (requirement.is_vcs or requirement.editable or requirement.vcs):",
            "            ignore_hashes = False",
            "    line = None",
            "    # Try installing for each source in project.sources.",
            "    if not index and requirement.index:",
            "        index = requirement.index",
            "    if index and not extra_indexes:",
            "        extra_indexes = list(project.sources)",
            "    if requirement and requirement.vcs or requirement.editable:",
            "        requirement.index = None",
            "        # Install dependencies when a package is a non-editable VCS dependency.",
            "        # Don't specify a source directory when using --system.",
            "        if not requirement.editable and no_deps is not True:",
            "            # Leave this off becauase old lockfiles don't have all deps included",
            "            # TODO: When can it be turned back on?",
            "            no_deps = False",
            "        elif requirement.editable and no_deps is None:",
            "            no_deps = True",
            "",
            "    r = write_requirement_to_file(",
            "        project, requirement, requirements_dir=requirements_dir, src_dir=src_dir,",
            "        include_hashes=not ignore_hashes",
            "    )",
            "    sources = get_source_list(",
            "        project, index, extra_indexes=extra_indexes, trusted_hosts=trusted_hosts,",
            "        pypi_mirror=pypi_mirror",
            "    )",
            "    if r:",
            "        with open(r, \"r\") as fh:",
            "            if \"--hash\" not in fh.read():",
            "                ignore_hashes = True",
            "    if project.s.is_verbose():",
            "        piplogger.setLevel(logging.WARN)",
            "        if requirement:",
            "            click.echo(",
            "                crayons.normal(f\"Installing {requirement.name!r}\", bold=True),",
            "                err=True,",
            "            )",
            "",
            "    pip_command = [project._which(\"python\", allow_global=allow_global), \"-m\", \"pip\", \"install\"]",
            "    pip_args = get_pip_args(",
            "        project, pre=pre, verbose=project.s.is_verbose(), upgrade=True,",
            "        selective_upgrade=selective_upgrade, no_use_pep517=not use_pep517,",
            "        no_deps=no_deps, require_hashes=not ignore_hashes,",
            "    )",
            "    pip_command.extend(pip_args)",
            "    if r:",
            "        pip_command.extend([\"-r\", vistir.path.normalize_path(r)])",
            "    elif line:",
            "        pip_command.extend(line)",
            "    pip_command.extend(prepare_pip_source_args(sources))",
            "    if project.s.is_verbose():",
            "        click.echo(f\"$ {cmd_list_to_shell(pip_command)}\", err=True)",
            "    cache_dir = Path(project.s.PIPENV_CACHE_DIR)",
            "    DEFAULT_EXISTS_ACTION = \"w\"",
            "    if selective_upgrade:",
            "        DEFAULT_EXISTS_ACTION = \"i\"",
            "    exists_action = vistir.misc.fs_str(project.s.PIP_EXISTS_ACTION or DEFAULT_EXISTS_ACTION)",
            "    pip_config = {",
            "        \"PIP_CACHE_DIR\": vistir.misc.fs_str(cache_dir.as_posix()),",
            "        \"PIP_WHEEL_DIR\": vistir.misc.fs_str(cache_dir.joinpath(\"wheels\").as_posix()),",
            "        \"PIP_DESTINATION_DIR\": vistir.misc.fs_str(",
            "            cache_dir.joinpath(\"pkgs\").as_posix()",
            "        ),",
            "        \"PIP_EXISTS_ACTION\": exists_action,",
            "        \"PATH\": vistir.misc.fs_str(os.environ.get(\"PATH\")),",
            "    }",
            "    if src_dir:",
            "        if project.s.is_verbose():",
            "            click.echo(f\"Using source directory: {src_dir!r}\", err=True)",
            "        pip_config.update(",
            "            {\"PIP_SRC\": vistir.misc.fs_str(src_dir)}",
            "        )",
            "    c = subprocess_run(pip_command, block=block, env=pip_config)",
            "    c.env = pip_config",
            "    return c",
            "",
            "",
            "def pip_download(project, package_name):",
            "    cache_dir = Path(project.s.PIPENV_CACHE_DIR)",
            "    pip_config = {",
            "        \"PIP_CACHE_DIR\": vistir.misc.fs_str(cache_dir.as_posix()),",
            "        \"PIP_WHEEL_DIR\": vistir.misc.fs_str(cache_dir.joinpath(\"wheels\").as_posix()),",
            "        \"PIP_DESTINATION_DIR\": vistir.misc.fs_str(",
            "            cache_dir.joinpath(\"pkgs\").as_posix()",
            "        ),",
            "    }",
            "    for source in project.sources:",
            "        cmd = [",
            "            which_pip(project),",
            "            \"download\",",
            "            package_name,",
            "            \"-i\", source[\"url\"],",
            "            \"-d\", project.download_location,",
            "        ]",
            "        c = subprocess_run(cmd, env=pip_config)",
            "        if c.returncode == 0:",
            "            break",
            "",
            "    return c",
            "",
            "",
            "def fallback_which(command, location=None, allow_global=False, system=False):",
            "    \"\"\"",
            "    A fallback implementation of the `which` utility command that relies exclusively on",
            "    searching the path for commands.",
            "",
            "    :param str command: The command to search for, optional",
            "    :param str location: The search location to prioritize (prepend to path), defaults to None",
            "    :param bool allow_global: Whether to search the global path, defaults to False",
            "    :param bool system: Whether to use the system python instead of pipenv's python, defaults to False",
            "    :raises ValueError: Raised if no command is provided",
            "    :raises TypeError: Raised if the command provided is not a string",
            "    :return: A path to the discovered command location",
            "    :rtype: str",
            "    \"\"\"",
            "",
            "    from .vendor.pythonfinder import Finder",
            "    if not command:",
            "        raise ValueError(\"fallback_which: Must provide a command to search for...\")",
            "    if not isinstance(command, str):",
            "        raise TypeError(f\"Provided command must be a string, received {command!r}\")",
            "    global_search = system or allow_global",
            "    if location is None:",
            "        global_search = True",
            "    finder = Finder(system=False, global_search=global_search, path=location)",
            "    if is_python_command(command):",
            "        result = find_python(finder, command)",
            "        if result:",
            "            return result",
            "    result = finder.which(command)",
            "    if result:",
            "        return result.path.as_posix()",
            "    return \"\"",
            "",
            "",
            "def which_pip(project, allow_global=False):",
            "    \"\"\"Returns the location of virtualenv-installed pip.\"\"\"",
            "",
            "    location = None",
            "    if \"VIRTUAL_ENV\" in os.environ:",
            "        location = os.environ[\"VIRTUAL_ENV\"]",
            "    if allow_global:",
            "        if location:",
            "            pip = project._which(\"pip\", location=location)",
            "            if pip:",
            "                return pip",
            "",
            "        for p in (\"pip\", \"pip3\", \"pip2\"):",
            "            where = system_which(p)",
            "            if where:",
            "                return where",
            "",
            "    pip = project._which(\"pip\")",
            "    if not pip:",
            "        pip = fallback_which(\"pip\", allow_global=allow_global, location=location)",
            "    return pip",
            "",
            "",
            "def system_which(command, path=None):",
            "    \"\"\"Emulates the system's which. Returns None if not found.\"\"\"",
            "    import shutil",
            "",
            "    result = shutil.which(command, path=path)",
            "    if result is None:",
            "        _which = \"where\" if os.name == \"nt\" else \"which -a\"",
            "        env = {'PATH': path} if path else None",
            "        c = subprocess_run(f\"{_which} {command}\", shell=True, env=env)",
            "        if c.returncode == 127:",
            "            click.echo(",
            "                \"{}: the {} system utility is required for Pipenv to find Python installations properly.\"",
            "                \"\\n  Please install it.\".format(",
            "                    crayons.red(\"Warning\", bold=True), crayons.yellow(_which)",
            "                ),",
            "                err=True,",
            "            )",
            "        if c.returncode == 0:",
            "            result = next(iter(c.stdout.splitlines()), None)",
            "    return result",
            "",
            "",
            "def format_help(help):",
            "    \"\"\"Formats the help string.\"\"\"",
            "    help = help.replace(\"Options:\", str(crayons.normal(\"Options:\", bold=True)))",
            "    help = help.replace(",
            "        \"Usage: pipenv\", str(\"Usage: {}\".format(crayons.normal(\"pipenv\", bold=True)))",
            "    )",
            "    help = help.replace(\"  check\", str(crayons.red(\"  check\", bold=True)))",
            "    help = help.replace(\"  clean\", str(crayons.red(\"  clean\", bold=True)))",
            "    help = help.replace(\"  graph\", str(crayons.red(\"  graph\", bold=True)))",
            "    help = help.replace(\"  install\", str(crayons.magenta(\"  install\", bold=True)))",
            "    help = help.replace(\"  lock\", str(crayons.green(\"  lock\", bold=True)))",
            "    help = help.replace(\"  open\", str(crayons.red(\"  open\", bold=True)))",
            "    help = help.replace(\"  run\", str(crayons.yellow(\"  run\", bold=True)))",
            "    help = help.replace(\"  shell\", str(crayons.yellow(\"  shell\", bold=True)))",
            "    help = help.replace(\"  scripts\", str(crayons.yellow(\"  scripts\", bold=True)))",
            "    help = help.replace(\"  sync\", str(crayons.green(\"  sync\", bold=True)))",
            "    help = help.replace(\"  uninstall\", str(crayons.magenta(\"  uninstall\", bold=True)))",
            "    help = help.replace(\"  update\", str(crayons.green(\"  update\", bold=True)))",
            "    additional_help = \"\"\"",
            "Usage Examples:",
            "   Create a new project using Python 3.7, specifically:",
            "   $ {}",
            "",
            "   Remove project virtualenv (inferred from current directory):",
            "   $ {}",
            "",
            "   Install all dependencies for a project (including dev):",
            "   $ {}",
            "",
            "   Create a lockfile containing pre-releases:",
            "   $ {}",
            "",
            "   Show a graph of your installed dependencies:",
            "   $ {}",
            "",
            "   Check your installed dependencies for security vulnerabilities:",
            "   $ {}",
            "",
            "   Install a local setup.py into your virtual environment/Pipfile:",
            "   $ {}",
            "",
            "   Use a lower-level pip command:",
            "   $ {}",
            "",
            "Commands:\"\"\".format(",
            "        crayons.yellow(\"pipenv --python 3.7\"),",
            "        crayons.yellow(\"pipenv --rm\"),",
            "        crayons.yellow(\"pipenv install --dev\"),",
            "        crayons.yellow(\"pipenv lock --pre\"),",
            "        crayons.yellow(\"pipenv graph\"),",
            "        crayons.yellow(\"pipenv check\"),",
            "        crayons.yellow(\"pipenv install -e .\"),",
            "        crayons.yellow(\"pipenv run pip freeze\"),",
            "    )",
            "    help = help.replace(\"Commands:\", additional_help)",
            "    return help",
            "",
            "",
            "def format_pip_error(error):",
            "    error = error.replace(\"Expected\", str(crayons.green(\"Expected\", bold=True)))",
            "    error = error.replace(\"Got\", str(crayons.red(\"Got\", bold=True)))",
            "    error = error.replace(",
            "        \"THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE\",",
            "        str(",
            "            crayons.red(",
            "                \"THESE PACKAGES DO NOT MATCH THE HASHES FROM Pipfile.lock!\", bold=True",
            "            )",
            "        ),",
            "    )",
            "    error = error.replace(",
            "        \"someone may have tampered with them\",",
            "        str(crayons.red(\"someone may have tampered with them\")),",
            "    )",
            "    error = error.replace(\"option to pip install\", \"option to 'pipenv install'\")",
            "    return error",
            "",
            "",
            "def format_pip_output(out, r=None):",
            "    def gen(out):",
            "        for line in out.split(\"\\n\"):",
            "            # Remove requirements file information from pip9 output.",
            "            if \"(from -r\" in line:",
            "                yield line[: line.index(\"(from -r\")]",
            "",
            "            else:",
            "                yield line",
            "",
            "    out = \"\\n\".join([line for line in gen(out)])",
            "    return out",
            "",
            "",
            "def warn_in_virtualenv(project):",
            "    # Only warn if pipenv isn't already active.",
            "    if environments.is_in_virtualenv() and not project.s.is_quiet():",
            "        click.echo(",
            "            \"{}: Pipenv found itself running within a virtual environment, \"",
            "            \"so it will automatically use that environment, instead of \"",
            "            \"creating its own for any project. You can set \"",
            "            \"{} to force pipenv to ignore that environment and create \"",
            "            \"its own instead. You can set {} to suppress this \"",
            "            \"warning.\".format(",
            "                crayons.green(\"Courtesy Notice\"),",
            "                crayons.normal(\"PIPENV_IGNORE_VIRTUALENVS=1\", bold=True),",
            "                crayons.normal(\"PIPENV_VERBOSITY=-1\", bold=True),",
            "            ),",
            "            err=True,",
            "        )",
            "",
            "",
            "def ensure_lockfile(project, keep_outdated=False, pypi_mirror=None):",
            "    \"\"\"Ensures that the lockfile is up-to-date.\"\"\"",
            "    if not keep_outdated:",
            "        keep_outdated = project.settings.get(\"keep_outdated\")",
            "    # Write out the lockfile if it doesn't exist, but not if the Pipfile is being ignored",
            "    if project.lockfile_exists:",
            "        old_hash = project.get_lockfile_hash()",
            "        new_hash = project.calculate_pipfile_hash()",
            "        if new_hash != old_hash:",
            "            click.echo(",
            "                crayons.yellow(",
            "                    fix_utf8(\"Pipfile.lock ({}) out of date, updating to ({})...\".format(",
            "                        old_hash[-6:], new_hash[-6:]",
            "                    )),",
            "                    bold=True,",
            "                ),",
            "                err=True,",
            "            )",
            "            do_lock(project, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror)",
            "    else:",
            "        do_lock(project, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror)",
            "",
            "",
            "def do_py(project, ctx=None, system=False):",
            "    if not project.virtualenv_exists:",
            "        click.echo(",
            "            \"{}({}){}\".format(",
            "                crayons.red(\"No virtualenv has been created for this project \"),",
            "                crayons.yellow(project.project_directory, bold=True),",
            "                crayons.red(\" yet!\")",
            "            ),",
            "            err=True,",
            "        )",
            "        ctx.abort()",
            "",
            "    try:",
            "        click.echo(project._which(\"python\", allow_global=system))",
            "    except AttributeError:",
            "        click.echo(crayons.red(\"No project found!\"))",
            "",
            "",
            "def do_outdated(project, pypi_mirror=None, pre=False, clear=False):",
            "    # TODO: Allow --skip-lock here?",
            "    from collections import namedtuple",
            "",
            "    from .vendor.packaging.utils import canonicalize_name",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "    from .vendor.requirementslib.models.utils import get_version",
            "    from .vendor.vistir.compat import Mapping",
            "",
            "    packages = {}",
            "    package_info = namedtuple(\"PackageInfo\", [\"name\", \"installed\", \"available\"])",
            "",
            "    installed_packages = project.environment.get_installed_packages()",
            "    outdated_packages = {",
            "        canonicalize_name(pkg.project_name): package_info",
            "        (pkg.project_name, pkg.parsed_version, pkg.latest_version)",
            "        for pkg in project.environment.get_outdated_packages()",
            "    }",
            "    reverse_deps = {",
            "        canonicalize_name(name): deps",
            "        for name, deps in project.environment.reverse_dependencies().items()",
            "    }",
            "    for result in installed_packages:",
            "        dep = Requirement.from_line(str(result.as_requirement()))",
            "        packages.update(dep.as_pipfile())",
            "    updated_packages = {}",
            "    lockfile = do_lock(project, clear=clear, pre=pre, write=False, pypi_mirror=pypi_mirror)",
            "    for section in (\"develop\", \"default\"):",
            "        for package in lockfile[section]:",
            "            try:",
            "                updated_packages[package] = lockfile[section][package][\"version\"]",
            "            except KeyError:",
            "                pass",
            "    outdated = []",
            "    skipped = []",
            "    for package in packages:",
            "        norm_name = pep423_name(package)",
            "        if norm_name in updated_packages:",
            "            if updated_packages[norm_name] != packages[package]:",
            "                outdated.append(",
            "                    package_info(package, updated_packages[norm_name], packages[package])",
            "                )",
            "            elif canonicalize_name(package) in outdated_packages:",
            "                skipped.append(outdated_packages[canonicalize_name(package)])",
            "    for package, old_version, new_version in skipped:",
            "        name_in_pipfile = project.get_package_name_in_pipfile(package)",
            "        pipfile_version_text = \"\"",
            "        required = \"\"",
            "        version = None",
            "        if name_in_pipfile:",
            "            version = get_version(project.packages[name_in_pipfile])",
            "            rdeps = reverse_deps.get(canonicalize_name(package))",
            "            if isinstance(rdeps, Mapping) and \"required\" in rdeps:",
            "                required = \" {} required\".format(rdeps[\"required\"])",
            "            if version:",
            "                pipfile_version_text = f\" ({version} set in Pipfile)\"",
            "            else:",
            "                pipfile_version_text = \" (Unpinned in Pipfile)\"",
            "        click.echo(",
            "            crayons.yellow(",
            "                \"Skipped Update of Package {!s}: {!s} installed,{!s}{!s}, \"",
            "                \"{!s} available.\".format(",
            "                    package, old_version, required, pipfile_version_text, new_version",
            "                )",
            "            ), err=True",
            "        )",
            "    if not outdated:",
            "        click.echo(crayons.green(\"All packages are up to date!\", bold=True))",
            "        sys.exit(0)",
            "    for package, new_version, old_version in outdated:",
            "        click.echo(",
            "            \"Package {!r} out-of-date: {!r} installed, {!r} available.\".format(",
            "                package, old_version, new_version",
            "            )",
            "        )",
            "    sys.exit(bool(outdated))",
            "",
            "",
            "def do_install(",
            "    project,",
            "    packages=False,",
            "    editable_packages=False,",
            "    index_url=False,",
            "    extra_index_url=False,",
            "    dev=False,",
            "    three=False,",
            "    python=False,",
            "    pypi_mirror=None,",
            "    system=False,",
            "    lock=True,",
            "    ignore_pipfile=False,",
            "    skip_lock=False,",
            "    requirementstxt=False,",
            "    sequential=False,",
            "    pre=False,",
            "    code=False,",
            "    deploy=False,",
            "    keep_outdated=False,",
            "    selective_upgrade=False,",
            "    site_packages=None,",
            "):",
            "    from .vendor.pip_shims.shims import PipError",
            "",
            "    requirements_directory = vistir.path.create_tracked_tempdir(",
            "        suffix=\"-requirements\", prefix=\"pipenv-\"",
            "    )",
            "    warnings.filterwarnings(\"default\", category=vistir.compat.ResourceWarning)",
            "    if selective_upgrade:",
            "        keep_outdated = True",
            "    packages = packages if packages else []",
            "    editable_packages = editable_packages if editable_packages else []",
            "    package_args = [p for p in packages if p] + [p for p in editable_packages if p]",
            "    skip_requirements = False",
            "    # Don't search for requirements.txt files if the user provides one",
            "    if requirementstxt or package_args or project.pipfile_exists:",
            "        skip_requirements = True",
            "    concurrent = not sequential",
            "    # Ensure that virtualenv is available and pipfile are available",
            "    ensure_project(",
            "        project,",
            "        three=three,",
            "        python=python,",
            "        system=system,",
            "        warn=True,",
            "        deploy=deploy,",
            "        skip_requirements=skip_requirements,",
            "        pypi_mirror=pypi_mirror,",
            "        site_packages=site_packages,",
            "    )",
            "    # Don't attempt to install develop and default packages if Pipfile is missing",
            "    if not project.pipfile_exists and not (package_args or dev) and not code:",
            "        if not (ignore_pipfile or deploy):",
            "            raise exceptions.PipfileNotFound(project.path_to(\"Pipfile\"))",
            "        elif ((skip_lock and deploy) or ignore_pipfile) and not project.lockfile_exists:",
            "            raise exceptions.LockfileNotFound(project.path_to(\"Pipfile.lock\"))",
            "    # Load the --pre settings from the Pipfile.",
            "    if not pre:",
            "        pre = project.settings.get(\"allow_prereleases\")",
            "    if not keep_outdated:",
            "        keep_outdated = project.settings.get(\"keep_outdated\")",
            "    remote = requirementstxt and is_valid_url(requirementstxt)",
            "    # Warn and exit if --system is used without a pipfile.",
            "    if (system and package_args) and not project.s.PIPENV_VIRTUALENV:",
            "        raise exceptions.SystemUsageError",
            "    # Automatically use an activated virtualenv.",
            "    if project.s.PIPENV_USE_SYSTEM:",
            "        system = True",
            "    if system:",
            "        project.s.PIPENV_USE_SYSTEM = True",
            "        os.environ[\"PIPENV_USE_SYSTEM\"] = \"1\"",
            "    # Check if the file is remote or not",
            "    if remote:",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Remote requirements file provided! Downloading...\"), bold=True",
            "            ),",
            "            err=True,",
            "        )",
            "        fd = vistir.path.create_tracked_tempfile(",
            "            prefix=\"pipenv-\", suffix=\"-requirement.txt\", dir=requirements_directory",
            "        )",
            "        temp_reqs = fd.name",
            "        requirements_url = requirementstxt",
            "        # Download requirements file",
            "        try:",
            "            download_file(requirements_url, temp_reqs, project.s.PIPENV_MAX_RETRIES)",
            "        except OSError:",
            "            fd.close()",
            "            os.unlink(temp_reqs)",
            "            click.echo(",
            "                crayons.red(",
            "                    \"Unable to find requirements file at {}.\".format(",
            "                        crayons.normal(requirements_url)",
            "                    )",
            "                ),",
            "                err=True,",
            "            )",
            "            sys.exit(1)",
            "        finally:",
            "            fd.close()",
            "        # Replace the url with the temporary requirements file",
            "        requirementstxt = temp_reqs",
            "        remote = True",
            "    if requirementstxt:",
            "        error, traceback = None, None",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Requirements file provided! Importing into Pipfile...\"), bold=True",
            "            ),",
            "            err=True,",
            "        )",
            "        try:",
            "            import_requirements(project, r=project.path_to(requirementstxt), dev=dev)",
            "        except (UnicodeDecodeError, PipError) as e:",
            "            # Don't print the temp file path if remote since it will be deleted.",
            "            req_path = requirements_url if remote else project.path_to(requirementstxt)",
            "            error = (",
            "                \"Unexpected syntax in {}. Are you sure this is a \"",
            "                \"requirements.txt style file?\".format(req_path)",
            "            )",
            "            traceback = e",
            "        except AssertionError as e:",
            "            error = (",
            "                \"Requirements file doesn't appear to exist. Please ensure the file exists in your \"",
            "                \"project directory or you provided the correct path.\"",
            "            )",
            "            traceback = e",
            "        finally:",
            "            # If requirements file was provided by remote url delete the temporary file",
            "            if remote:",
            "                fd.close()  # Close for windows to allow file cleanup.",
            "                os.remove(temp_reqs)",
            "            if error and traceback:",
            "                click.echo(crayons.red(error))",
            "                click.echo(crayons.yellow(str(traceback)), err=True)",
            "                sys.exit(1)",
            "    if code:",
            "        click.echo(",
            "            crayons.normal(fix_utf8(\"Discovering imports from local codebase...\"), bold=True)",
            "        )",
            "        for req in import_from_code(code):",
            "            click.echo(f\"  Found {crayons.green(req)}!\")",
            "            project.add_package_to_pipfile(req)",
            "    # Allow more than one package to be provided.",
            "    package_args = [p for p in packages] + [",
            "        f\"-e {pkg}\" for pkg in editable_packages",
            "    ]",
            "    # Support for --selective-upgrade.",
            "    # We should do this part first to make sure that we actually do selectively upgrade",
            "    # the items specified",
            "    if selective_upgrade:",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "        for i, package in enumerate(package_args[:]):",
            "            section = project.packages if not dev else project.dev_packages",
            "            package = Requirement.from_line(package)",
            "            package__name, package__val = package.pipfile_entry",
            "            try:",
            "                if not is_star(section[package__name]) and is_star(package__val):",
            "                    # Support for VCS dependencies.",
            "                    package_args[i] = convert_deps_to_pip(",
            "                        {package__name: section[package__name]}, project=project, r=False",
            "                    )[0]",
            "            except KeyError:",
            "                pass",
            "    # Install all dependencies, if none was provided.",
            "    # This basically ensures that we have a pipfile and lockfile, then it locks and",
            "    # installs from the lockfile",
            "    if not packages and not editable_packages:",
            "        # Update project settings with pre preference.",
            "        if pre:",
            "            project.update_settings({\"allow_prereleases\": pre})",
            "        do_init(",
            "            project,",
            "            dev=dev,",
            "            allow_global=system,",
            "            ignore_pipfile=ignore_pipfile,",
            "            system=system,",
            "            skip_lock=skip_lock,",
            "            concurrent=concurrent,",
            "            deploy=deploy,",
            "            pre=pre,",
            "            requirements_dir=requirements_directory,",
            "            pypi_mirror=pypi_mirror,",
            "            keep_outdated=keep_outdated",
            "        )",
            "",
            "    # This is for if the user passed in dependencies, then we want to make sure we",
            "    else:",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "        # make a tuple of (display_name, entry)",
            "        pkg_list = packages + [f'-e {pkg}' for pkg in editable_packages]",
            "        if not system and not project.virtualenv_exists:",
            "            do_init(",
            "                project,",
            "                dev=dev,",
            "                system=system,",
            "                allow_global=system,",
            "                concurrent=concurrent,",
            "                keep_outdated=keep_outdated,",
            "                requirements_dir=requirements_directory,",
            "                deploy=deploy,",
            "                pypi_mirror=pypi_mirror,",
            "                skip_lock=skip_lock,",
            "            )",
            "        pip_shims_module = os.environ.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "        for pkg_line in pkg_list:",
            "            click.echo(",
            "                crayons.normal(",
            "                    fix_utf8(f\"Installing {crayons.green(pkg_line, bold=True)}...\"),",
            "                    bold=True,",
            "                )",
            "            )",
            "            # pip install:",
            "            with vistir.contextmanagers.temp_environ(), create_spinner(\"Installing...\", project.s) as sp:",
            "                if not system:",
            "                    os.environ[\"PIP_USER\"] = vistir.compat.fs_str(\"0\")",
            "                    if \"PYTHONHOME\" in os.environ:",
            "                        del os.environ[\"PYTHONHOME\"]",
            "                sp.text = f\"Resolving {pkg_line}...\"",
            "                try:",
            "                    pkg_requirement = Requirement.from_line(pkg_line)",
            "                except ValueError as e:",
            "                    sp.write_err(vistir.compat.fs_str(\"{}: {}\".format(crayons.red(\"WARNING\"), e)))",
            "                    sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Installation Failed\"))",
            "                    sys.exit(1)",
            "                no_deps = False",
            "                sp.text = \"Installing...\"",
            "                try:",
            "                    sp.text = f\"Installing {pkg_requirement.name}...\"",
            "                    if project.s.is_verbose():",
            "                        sp.hide_and_write(f\"Installing package: {pkg_requirement.as_line(include_hashes=False)}\")",
            "                    c = pip_install(",
            "                        project,",
            "                        pkg_requirement,",
            "                        ignore_hashes=True,",
            "                        allow_global=system,",
            "                        selective_upgrade=selective_upgrade,",
            "                        no_deps=no_deps,",
            "                        pre=pre,",
            "                        requirements_dir=requirements_directory,",
            "                        index=index_url,",
            "                        extra_indexes=extra_index_url,",
            "                        pypi_mirror=pypi_mirror,",
            "                    )",
            "                    if c.returncode:",
            "                        sp.write_err(",
            "                            \"{} An error occurred while installing {}!\".format(",
            "                                crayons.red(\"Error: \", bold=True), crayons.green(pkg_line)",
            "                            ),",
            "                        )",
            "                        sp.write_err(",
            "                            vistir.compat.fs_str(f\"Error text: {c.stdout}\")",
            "                        )",
            "                        sp.write_err(crayons.cyan(vistir.compat.fs_str(format_pip_error(c.stderr))))",
            "                        if project.s.is_verbose():",
            "                            sp.write_err(crayons.cyan(vistir.compat.fs_str(format_pip_output(c.stdout))))",
            "                        if \"setup.py egg_info\" in c.stderr:",
            "                            sp.write_err(vistir.compat.fs_str(",
            "                                \"This is likely caused by a bug in {}. \"",
            "                                \"Report this to its maintainers.\".format(",
            "                                    crayons.green(pkg_requirement.name)",
            "                                )",
            "                            ))",
            "                        sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Installation Failed\"))",
            "                        sys.exit(1)",
            "                except (ValueError, RuntimeError) as e:",
            "                    sp.write_err(vistir.compat.fs_str(",
            "                        \"{}: {}\".format(crayons.red(\"WARNING\"), e),",
            "                    ))",
            "                    sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "                        \"Installation Failed\",",
            "                    ))",
            "                    sys.exit(1)",
            "                # Warn if --editable wasn't passed.",
            "                if pkg_requirement.is_vcs and not pkg_requirement.editable and not project.s.PIPENV_RESOLVE_VCS:",
            "                    sp.write_err(",
            "                        \"{}: You installed a VCS dependency in non-editable mode. \"",
            "                        \"This will work fine, but sub-dependencies will not be resolved by {}.\"",
            "                        \"\\n  To enable this sub-dependency functionality, specify that this dependency is editable.\"",
            "                        \"\".format(",
            "                            crayons.red(\"Warning\", bold=True),",
            "                            crayons.yellow(\"$ pipenv lock\"),",
            "                        )",
            "                    )",
            "                sp.write(vistir.compat.fs_str(",
            "                    \"{} {} {} {}{}\".format(",
            "                        crayons.normal(\"Adding\", bold=True),",
            "                        crayons.green(f\"{pkg_requirement.name}\", bold=True),",
            "                        crayons.normal(\"to Pipfile's\", bold=True),",
            "                        crayons.yellow(\"[dev-packages]\" if dev else \"[packages]\", bold=True),",
            "                        crayons.normal(fix_utf8(\"...\"), bold=True),",
            "                    )",
            "                ))",
            "                # Add the package to the Pipfile.",
            "                indexes = list(filter(None, [index_url, *extra_index_url]))",
            "                for index in indexes:",
            "                    index_name = project.add_index_to_pipfile(",
            "                        index, verify_ssl=index.startswith(\"https:\")",
            "                    )",
            "                    if index_url and not extra_index_url:",
            "                        pkg_requirement.index = index_name",
            "                try:",
            "                    project.add_package_to_pipfile(pkg_requirement, dev)",
            "                except ValueError:",
            "                    import traceback",
            "                    sp.write_err(",
            "                        \"{} {}\".format(",
            "                            crayons.red(\"Error:\", bold=True), traceback.format_exc()",
            "                        )",
            "                    )",
            "                    sp.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "                        \"Failed adding package to Pipfile\"",
            "                    ))",
            "                sp.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Installation Succeeded\"))",
            "            # Update project settings with pre preference.",
            "            if pre:",
            "                project.update_settings({\"allow_prereleases\": pre})",
            "        if pip_shims_module:",
            "            os.environ[\"PIP_SHIMS_BASE_MODULE\"] = pip_shims_module",
            "        do_init(",
            "            project,",
            "            dev=dev,",
            "            system=system,",
            "            allow_global=system,",
            "            concurrent=concurrent,",
            "            keep_outdated=keep_outdated,",
            "            requirements_dir=requirements_directory,",
            "            deploy=deploy,",
            "            pypi_mirror=pypi_mirror,",
            "            skip_lock=skip_lock,",
            "        )",
            "    sys.exit(0)",
            "",
            "",
            "def do_uninstall(",
            "    project,",
            "    packages=False,",
            "    editable_packages=False,",
            "    three=None,",
            "    python=False,",
            "    system=False,",
            "    lock=False,",
            "    all_dev=False,",
            "    all=False,",
            "    keep_outdated=False,",
            "    pypi_mirror=None,",
            "    ctx=None",
            "):",
            "    from .vendor.packaging.utils import canonicalize_name",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    # Automatically use an activated virtualenv.",
            "    if project.s.PIPENV_USE_SYSTEM:",
            "        system = True",
            "    # Ensure that virtualenv is available.",
            "    # TODO: We probably shouldn't ensure a project exists if the outcome will be to just",
            "    # install things in order to remove them... maybe tell the user to install first?",
            "    ensure_project(project, three=three, python=python, pypi_mirror=pypi_mirror)",
            "    # Un-install all dependencies, if --all was provided.",
            "    if not any([packages, editable_packages, all_dev, all]):",
            "        raise exceptions.PipenvUsageError(\"No package provided!\", ctx=ctx)",
            "    editable_pkgs = [",
            "        Requirement.from_line(f\"-e {p}\").name for p in editable_packages if p",
            "    ]",
            "    packages += editable_pkgs",
            "    package_names = {p for p in packages if p}",
            "    package_map = {",
            "        canonicalize_name(p): p for p in packages if p",
            "    }",
            "    installed_package_names = project.installed_package_names",
            "    # Intelligently detect if --dev should be used or not.",
            "    lockfile_packages = set()",
            "    if project.lockfile_exists:",
            "        project_pkg_names = project.lockfile_package_names",
            "    else:",
            "        project_pkg_names = project.pipfile_package_names",
            "    pipfile_remove = True",
            "    # Uninstall [dev-packages], if --dev was provided.",
            "    if all_dev:",
            "        if \"dev-packages\" not in project.parsed_pipfile and not project_pkg_names[\"dev\"]:",
            "            click.echo(",
            "                crayons.normal(",
            "                    \"No {} to uninstall.\".format(crayons.yellow(\"[dev-packages]\")),",
            "                    bold=True,",
            "                )",
            "            )",
            "            return",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Un-installing {}...\".format(crayons.yellow(\"[dev-packages]\"))), bold=True",
            "            )",
            "        )",
            "        package_names = set(project_pkg_names[\"dev\"]) - set(project_pkg_names[\"default\"])",
            "",
            "    # Remove known \"bad packages\" from the list.",
            "    bad_pkgs = get_canonical_names(BAD_PACKAGES)",
            "    ignored_packages = bad_pkgs & set(list(package_map.keys()))",
            "    for ignored_pkg in ignored_packages:",
            "        if project.s.is_verbose():",
            "            click.echo(f\"Ignoring {ignored_pkg}.\", err=True)",
            "        package_names.discard(package_map[ignored_pkg])",
            "",
            "    used_packages = project_pkg_names[\"combined\"] & installed_package_names",
            "    failure = False",
            "    if all:",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(\"Un-installing all {} and {}...\".format(",
            "                    crayons.yellow(\"[dev-packages]\"),",
            "                    crayons.yellow(\"[packages]\"),",
            "                )), bold=True",
            "            )",
            "        )",
            "        do_purge(project, bare=False, allow_global=system)",
            "        sys.exit(0)",
            "",
            "    selected_pkg_map = {",
            "        canonicalize_name(p): p for p in package_names",
            "    }",
            "    packages_to_remove = [",
            "        p for normalized, p in selected_pkg_map.items()",
            "        if normalized in (used_packages - bad_pkgs)",
            "    ]",
            "    pip_path = None",
            "    for normalized, package_name in selected_pkg_map.items():",
            "        click.echo(",
            "            crayons.normal(",
            "                fix_utf8(f\"Uninstalling {crayons.green(package_name)}...\"), bold=True",
            "            )",
            "        )",
            "        # Uninstall the package.",
            "        if package_name in packages_to_remove:",
            "            with project.environment.activated():",
            "                if pip_path is None:",
            "                    pip_path = which_pip(project, allow_global=system)",
            "                cmd = [pip_path, \"uninstall\", package_name, \"-y\"]",
            "                c = run_command(cmd, is_verbose=project.s.is_verbose())",
            "                click.echo(crayons.cyan(c.stdout))",
            "                if c.returncode != 0:",
            "                    failure = True",
            "        if not failure and pipfile_remove:",
            "            in_packages = project.get_package_name_in_pipfile(package_name, dev=False)",
            "            in_dev_packages = project.get_package_name_in_pipfile(",
            "                package_name, dev=True",
            "            )",
            "            if normalized in lockfile_packages:",
            "                click.echo(\"{} {} {} {}\".format(",
            "                    crayons.cyan(\"Removing\"),",
            "                    crayons.green(package_name),",
            "                    crayons.cyan(\"from\"),",
            "                    crayons.white(fix_utf8(\"Pipfile.lock...\")))",
            "                )",
            "                lockfile = project.get_or_create_lockfile()",
            "                if normalized in lockfile.default:",
            "                    del lockfile.default[normalized]",
            "                if normalized in lockfile.develop:",
            "                    del lockfile.develop[normalized]",
            "                lockfile.write()",
            "            if not (in_dev_packages or in_packages):",
            "                if normalized in lockfile_packages:",
            "                    continue",
            "                click.echo(",
            "                    \"No package {} to remove from Pipfile.\".format(",
            "                        crayons.green(package_name)",
            "                    )",
            "                )",
            "                continue",
            "",
            "            click.echo(",
            "                fix_utf8(f\"Removing {crayons.green(package_name)} from Pipfile...\")",
            "            )",
            "            # Remove package from both packages and dev-packages.",
            "            if in_dev_packages:",
            "                project.remove_package_from_pipfile(package_name, dev=True)",
            "            if in_packages:",
            "                project.remove_package_from_pipfile(package_name, dev=False)",
            "    if lock:",
            "        do_lock(project, system=system, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror)",
            "    sys.exit(int(failure))",
            "",
            "",
            "def do_shell(project, three=None, python=False, fancy=False, shell_args=None, pypi_mirror=None):",
            "    # Ensure that virtualenv is available.",
            "    ensure_project(",
            "        project, three=three, python=python, validate=False, pypi_mirror=pypi_mirror,",
            "    )",
            "",
            "    # Support shell compatibility mode.",
            "    if project.s.PIPENV_SHELL_FANCY:",
            "        fancy = True",
            "",
            "    from .shells import choose_shell",
            "",
            "    shell = choose_shell(project)",
            "    click.echo(fix_utf8(\"Launching subshell in virtual environment...\"), err=True)",
            "",
            "    fork_args = (",
            "        project.virtualenv_location,",
            "        project.project_directory,",
            "        shell_args,",
            "    )",
            "",
            "    # Set an environment variable, so we know we're in the environment.",
            "    # Only set PIPENV_ACTIVE after finishing reading virtualenv_location",
            "    # otherwise its value will be changed",
            "    os.environ[\"PIPENV_ACTIVE\"] = vistir.misc.fs_str(\"1\")",
            "",
            "    os.environ.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "",
            "    if fancy:",
            "        shell.fork(*fork_args)",
            "        return",
            "",
            "    try:",
            "        shell.fork_compat(*fork_args)",
            "    except (AttributeError, ImportError):",
            "        click.echo(fix_utf8(",
            "            \"Compatibility mode not supported. \"",
            "            \"Trying to continue as well-configured shell...\"),",
            "            err=True,",
            "        )",
            "        shell.fork(*fork_args)",
            "",
            "",
            "def _inline_activate_virtualenv(project):",
            "    try:",
            "        activate_this = project._which(\"activate_this.py\")",
            "        if not activate_this or not os.path.exists(activate_this):",
            "            raise exceptions.VirtualenvActivationException()",
            "        with open(activate_this) as f:",
            "            code = compile(f.read(), activate_this, \"exec\")",
            "            exec(code, dict(__file__=activate_this))",
            "    # Catch all errors, just in case.",
            "    except Exception:",
            "        click.echo(",
            "            \"{}: There was an unexpected error while activating your \"",
            "            \"virtualenv. Continuing anyway...\".format(",
            "                crayons.red(\"Warning\", bold=True)",
            "            ),",
            "            err=True,",
            "        )",
            "",
            "",
            "def _inline_activate_venv(project):",
            "    \"\"\"Built-in venv doesn't have activate_this.py, but doesn't need it anyway.",
            "",
            "    As long as we find the correct executable, built-in venv sets up the",
            "    environment automatically.",
            "",
            "    See: https://bugs.python.org/issue21496#msg218455",
            "    \"\"\"",
            "    components = []",
            "    for name in (\"bin\", \"Scripts\"):",
            "        bindir = os.path.join(project.virtualenv_location, name)",
            "        if os.path.exists(bindir):",
            "            components.append(bindir)",
            "    if \"PATH\" in os.environ:",
            "        components.append(os.environ[\"PATH\"])",
            "    os.environ[\"PATH\"] = os.pathsep.join(components)",
            "",
            "",
            "def inline_activate_virtual_environment(project):",
            "    root = project.virtualenv_location",
            "    if os.path.exists(os.path.join(root, \"pyvenv.cfg\")):",
            "        _inline_activate_venv(project)",
            "    else:",
            "        _inline_activate_virtualenv(project)",
            "    if \"VIRTUAL_ENV\" not in os.environ:",
            "        os.environ[\"VIRTUAL_ENV\"] = vistir.misc.fs_str(root)",
            "",
            "",
            "def _launch_windows_subprocess(script, env):",
            "    import subprocess",
            "",
            "    path = env.get(\"PATH\", \"\")",
            "    command = system_which(script.command, path=path)",
            "",
            "    options = {\"universal_newlines\": True, \"env\": env}",
            "    script.cmd_args[1:] = [expandvars(arg) for arg in script.args]",
            "",
            "    # Command not found, maybe this is a shell built-in?",
            "    if not command:",
            "        return subprocess.Popen(script.cmdify(), shell=True, **options)",
            "",
            "    # Try to use CreateProcess directly if possible. Specifically catch",
            "    # Windows error 193 \"Command is not a valid Win32 application\" to handle",
            "    # a \"command\" that is non-executable. See pypa/pipenv#2727.",
            "    try:",
            "        return subprocess.Popen([command] + script.args, **options)",
            "    except OSError as e:",
            "        if e.winerror != 193:",
            "            raise",
            "",
            "    # Try shell mode to use Windows's file association for file launch.",
            "    return subprocess.Popen(script.cmdify(), shell=True, **options)",
            "",
            "",
            "def do_run_nt(project, script, env):",
            "    p = _launch_windows_subprocess(script, env)",
            "    p.communicate()",
            "    sys.exit(p.returncode)",
            "",
            "",
            "def do_run_posix(project, script, command, env):",
            "    path = env.get(\"PATH\")",
            "    command_path = system_which(script.command, path=path)",
            "    if not command_path:",
            "        if project.has_script(command):",
            "            click.echo(",
            "                \"{}: the command {} (from {}) could not be found within {}.\"",
            "                \"\".format(",
            "                    crayons.red(\"Error\", bold=True),",
            "                    crayons.yellow(script.command),",
            "                    crayons.normal(command, bold=True),",
            "                    crayons.normal(\"PATH\", bold=True),",
            "                ),",
            "                err=True,",
            "            )",
            "        else:",
            "            click.echo(",
            "                \"{}: the command {} could not be found within {} or Pipfile's {}.\"",
            "                \"\".format(",
            "                    crayons.red(\"Error\", bold=True),",
            "                    crayons.yellow(command),",
            "                    crayons.normal(\"PATH\", bold=True),",
            "                    crayons.normal(\"[scripts]\", bold=True),",
            "                ),",
            "                err=True,",
            "            )",
            "        sys.exit(1)",
            "    os.execve(",
            "        command_path,",
            "        [command_path, *(os.path.expandvars(arg) for arg in script.args)],",
            "        env",
            "    )",
            "",
            "",
            "def do_run(project, command, args, three=None, python=False, pypi_mirror=None):",
            "    \"\"\"Attempt to run command either pulling from project or interpreting as executable.",
            "",
            "    Args are appended to the command in [scripts] section of project if found.",
            "    \"\"\"",
            "    from .cmdparse import ScriptEmptyError",
            "",
            "    # Ensure that virtualenv is available.",
            "    ensure_project(",
            "        project, three=three, python=python, validate=False, pypi_mirror=pypi_mirror,",
            "    )",
            "",
            "    env = os.environ.copy()",
            "    env.update(load_dot_env(project, as_dict=True) or {})",
            "    env.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "",
            "    path = env.get('PATH', '')",
            "    if project.virtualenv_location:",
            "        new_path = os.path.join(project.virtualenv_location, 'Scripts' if os.name == 'nt' else 'bin')",
            "        paths = path.split(os.pathsep)",
            "        paths.insert(0, new_path)",
            "        path = os.pathsep.join(paths)",
            "        env[\"VIRTUAL_ENV\"] = project.virtualenv_location",
            "    env[\"PATH\"] = path",
            "",
            "    # Set an environment variable, so we know we're in the environment.",
            "    # Only set PIPENV_ACTIVE after finishing reading virtualenv_location",
            "    # such as in inline_activate_virtual_environment",
            "    # otherwise its value will be changed",
            "    env[\"PIPENV_ACTIVE\"] = vistir.misc.fs_str(\"1\")",
            "    env.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "",
            "    try:",
            "        script = project.build_script(command, args)",
            "        cmd_string = cmd_list_to_shell([script.command] + script.args)",
            "        if project.s.is_verbose():",
            "            click.echo(crayons.normal(f\"$ {cmd_string}\"), err=True)",
            "    except ScriptEmptyError:",
            "        click.echo(\"Can't run script {0!r}-it's empty?\", err=True)",
            "    run_args = [project, script]",
            "    run_kwargs = {'env': env}",
            "    # We're using `do_run_nt` on CI (even if we're running on a non-nt machine)",
            "    # as a workaround for https://github.com/pypa/pipenv/issues/4909.",
            "    if os.name == \"nt\" or environments.PIPENV_IS_CI:",
            "        run_fn = do_run_nt",
            "    else:",
            "        run_fn = do_run_posix",
            "        run_kwargs.update({\"command\": command})",
            "    run_fn(*run_args, **run_kwargs)",
            "",
            "",
            "def do_check(",
            "    project,",
            "    three=None,",
            "    python=False,",
            "    system=False,",
            "    unused=False,",
            "    db=None,",
            "    ignore=None,",
            "    output=\"default\",",
            "    key=None,",
            "    quiet=False,",
            "    args=None,",
            "    pypi_mirror=None",
            "):",
            "    from pipenv.vendor.first import first",
            "    from pipenv.vendor.vistir.compat import JSONDecodeError",
            "",
            "    if not system:",
            "        # Ensure that virtualenv is available.",
            "        ensure_project(",
            "            project,",
            "            three=three,",
            "            python=python,",
            "            validate=False,",
            "            warn=False,",
            "            pypi_mirror=pypi_mirror,",
            "        )",
            "    if not args:",
            "        args = []",
            "    if unused:",
            "        deps_required = [k.lower() for k in project.packages.keys()]",
            "        deps_needed = [k.lower() for k in import_from_code(unused)]",
            "        for dep in deps_needed:",
            "            try:",
            "                deps_required.remove(dep)",
            "            except ValueError:",
            "                pass",
            "        if deps_required:",
            "            if not quiet and not project.s.is_quiet():",
            "                click.echo(",
            "                    crayons.normal(",
            "                        \"The following dependencies appear unused, and may be safe for removal:\"",
            "                    )",
            "                )",
            "                for dep in deps_required:",
            "                    click.echo(f\"  - {crayons.green(dep)}\")",
            "                sys.exit(1)",
            "        else:",
            "            sys.exit(0)",
            "    if not quiet and not project.s.is_quiet():",
            "        click.echo(crayons.normal(decode_for_output(\"Checking PEP 508 requirements...\"), bold=True))",
            "    pep508checker_path = pep508checker.__file__.rstrip(\"cdo\")",
            "    safety_path = os.path.join(",
            "        os.path.dirname(os.path.abspath(__file__)), \"patched\", \"safety\"",
            "    )",
            "    if not system:",
            "        python = project._which(\"python\")",
            "    else:",
            "        python = first(system_which(p) for p in (\"python\", \"python3\", \"python2\"))",
            "    if not python:",
            "        click.echo(crayons.red(\"The Python interpreter can't be found.\"), err=True)",
            "        sys.exit(1)",
            "    _cmd = [Path(python).as_posix()]",
            "    # Run the PEP 508 checker in the virtualenv.",
            "    cmd = _cmd + [Path(pep508checker_path).as_posix()]",
            "    c = run_command(cmd, is_verbose=project.s.is_verbose())",
            "    if c.returncode is not None:",
            "        try:",
            "            results = simplejson.loads(c.stdout.strip())",
            "        except JSONDecodeError:",
            "            click.echo(\"{}\\n{}\\n{}\".format(",
            "                crayons.white(decode_for_output(\"Failed parsing pep508 results: \"), bold=True),",
            "                c.stdout.strip(),",
            "                c.stderr.strip()",
            "            ))",
            "            sys.exit(1)",
            "    # Load the pipfile.",
            "    p = pipfile.Pipfile.load(project.pipfile_location)",
            "    failed = False",
            "    # Assert each specified requirement.",
            "    for marker, specifier in p.data[\"_meta\"][\"requires\"].items():",
            "        if marker in results:",
            "            try:",
            "                assert results[marker] == specifier",
            "            except AssertionError:",
            "                failed = True",
            "                click.echo(",
            "                    \"Specifier {} does not match {} ({}).\"",
            "                    \"\".format(",
            "                        crayons.green(marker),",
            "                        crayons.cyan(specifier),",
            "                        crayons.yellow(results[marker]),",
            "                    ),",
            "                    err=True,",
            "                )",
            "    if failed:",
            "        click.echo(crayons.red(\"Failed!\"), err=True)",
            "        sys.exit(1)",
            "    else:",
            "        if not quiet and not project.s.is_quiet():",
            "            click.echo(crayons.green(\"Passed!\"))",
            "    if not quiet and not project.s.is_quiet():",
            "        click.echo(crayons.normal(",
            "            decode_for_output(\"Checking installed package safety...\"), bold=True)",
            "        )",
            "    if ignore:",
            "        if not isinstance(ignore, (tuple, list)):",
            "            ignore = [ignore]",
            "        ignored = [[\"--ignore\", cve] for cve in ignore]",
            "        if not quiet and not project.s.is_quiet():",
            "            click.echo(",
            "                crayons.normal(",
            "                    \"Notice: Ignoring CVE(s) {}\".format(crayons.yellow(\", \".join(ignore)))",
            "                ),",
            "                err=True,",
            "            )",
            "    else:",
            "        ignored = []",
            "",
            "    switch = output",
            "    if output == \"default\":",
            "        switch = \"json\"",
            "",
            "    cmd = _cmd + [safety_path, \"check\", f\"--{switch}\"]",
            "    if db:",
            "        if not quiet and not project.s.is_quiet():",
            "            click.echo(crayons.normal(f\"Using local database {db}\"))",
            "        cmd.append(f\"--db={db}\")",
            "    elif key or project.s.PIPENV_PYUP_API_KEY:",
            "        cmd = cmd + [f\"--key={key or project.s.PIPENV_PYUP_API_KEY}\"]",
            "    if ignored:",
            "        for cve in ignored:",
            "            cmd += cve",
            "    c = run_command(cmd, catch_exceptions=False, is_verbose=project.s.is_verbose())",
            "    if output == \"default\":",
            "        try:",
            "            results = simplejson.loads(c.stdout)",
            "        except (ValueError, JSONDecodeError):",
            "            raise exceptions.JSONParseError(c.stdout, c.stderr)",
            "        except Exception:",
            "            raise exceptions.PipenvCmdError(cmd_list_to_shell(c.args), c.stdout, c.stderr, c.returncode)",
            "        for (package, resolved, installed, description, vuln, *_) in results:",
            "            click.echo(",
            "                \"{}: {} {} resolved ({} installed)!\".format(",
            "                    crayons.normal(vuln, bold=True),",
            "                    crayons.green(package),",
            "                    crayons.yellow(resolved, bold=False),",
            "                    crayons.yellow(installed, bold=True),",
            "                )",
            "            )",
            "            click.echo(f\"{description}\")",
            "            click.echo()",
            "        if c.returncode == 0:",
            "            click.echo(crayons.green(\"All good!\"))",
            "            sys.exit(0)",
            "        else:",
            "            sys.exit(1)",
            "    else:",
            "        click.echo(c.stdout)",
            "        sys.exit(c.returncode)",
            "",
            "",
            "def do_graph(project, bare=False, json=False, json_tree=False, reverse=False):",
            "    from pipenv.vendor import pipdeptree",
            "    from pipenv.vendor.vistir.compat import JSONDecodeError",
            "    pipdeptree_path = pipdeptree.__file__.rstrip(\"cdo\")",
            "    try:",
            "        python_path = project._which(\"python\")",
            "    except AttributeError:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Unable to display currently-installed dependency graph information here. \"",
            "                \"Please run within a Pipenv project.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    except RuntimeError:",
            "        pass",
            "    else:",
            "        if not os.name == 'nt':    # bugfix #4388",
            "            python_path = Path(python_path).as_posix()",
            "            pipdeptree_path = Path(pipdeptree_path).as_posix()",
            "",
            "    if reverse and json:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Using both --reverse and --json together is not supported. \"",
            "                \"Please select one of the two options.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    if reverse and json_tree:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Using both --reverse and --json-tree together is not supported. \"",
            "                \"Please select one of the two options.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    if json and json_tree:",
            "        click.echo(",
            "            \"{}: {}\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                \"Using both --json and --json-tree together is not supported. \"",
            "                \"Please select one of the two options.\",",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    flag = \"\"",
            "    if json:",
            "        flag = \"--json\"",
            "    if json_tree:",
            "        flag = \"--json-tree\"",
            "    if reverse:",
            "        flag = \"--reverse\"",
            "    if not project.virtualenv_exists:",
            "        click.echo(",
            "            \"{}: No virtualenv has been created for this project yet! Consider \"",
            "            \"running {} first to automatically generate one for you or see \"",
            "            \"{} for further instructions.\".format(",
            "                crayons.red(\"Warning\", bold=True),",
            "                crayons.green(\"`pipenv install`\"),",
            "                crayons.green(\"`pipenv install --help`\"),",
            "            ),",
            "            err=True,",
            "        )",
            "        sys.exit(1)",
            "    cmd_args = [python_path, pipdeptree_path, \"-l\"]",
            "    if flag:",
            "        cmd_args.append(flag)",
            "    c = run_command(cmd_args, is_verbose=project.s.is_verbose())",
            "    # Run dep-tree.",
            "    if not bare:",
            "        if json:",
            "            data = []",
            "            try:",
            "                parsed = simplejson.loads(c.stdout.strip())",
            "            except JSONDecodeError:",
            "                raise exceptions.JSONParseError(c.stdout, c.stderr)",
            "            else:",
            "                for d in parsed:",
            "                    if d[\"package\"][\"key\"] not in BAD_PACKAGES:",
            "                        data.append(d)",
            "            click.echo(simplejson.dumps(data, indent=4))",
            "            sys.exit(0)",
            "        elif json_tree:",
            "",
            "            def traverse(obj):",
            "                if isinstance(obj, list):",
            "                    return [",
            "                        traverse(package)",
            "                        for package in obj",
            "                        if package[\"key\"] not in BAD_PACKAGES",
            "                    ]",
            "                else:",
            "                    obj[\"dependencies\"] = traverse(obj[\"dependencies\"])",
            "                    return obj",
            "",
            "            try:",
            "                parsed = simplejson.loads(c.stdout.strip())",
            "            except JSONDecodeError:",
            "                raise exceptions.JSONParseError(c.stdout, c.stderr)",
            "            else:",
            "                data = traverse(parsed)",
            "                click.echo(simplejson.dumps(data, indent=4))",
            "                sys.exit(0)",
            "        else:",
            "            for line in c.stdout.strip().split(\"\\n\"):",
            "                # Ignore bad packages as top level.",
            "                # TODO: This should probably be a \"==\" in + line.partition",
            "                if line.split(\"==\")[0] in BAD_PACKAGES and not reverse:",
            "                    continue",
            "",
            "                # Bold top-level packages.",
            "                if not line.startswith(\" \"):",
            "                    click.echo(crayons.normal(line, bold=True))",
            "                # Echo the rest.",
            "                else:",
            "                    click.echo(crayons.normal(line, bold=False))",
            "    else:",
            "        click.echo(c.stdout)",
            "    if c.returncode != 0:",
            "        click.echo(",
            "            \"{} {}\".format(",
            "                crayons.red(\"ERROR: \", bold=True),",
            "                crayons.white(f\"{c.stderr}\"),",
            "            ),",
            "            err=True,",
            "        )",
            "    # Return its return code.",
            "    sys.exit(c.returncode)",
            "",
            "",
            "def do_sync(",
            "    project,",
            "    dev=False,",
            "    three=None,",
            "    python=None,",
            "    bare=False,",
            "    dont_upgrade=False,",
            "    user=False,",
            "    clear=False,",
            "    unused=False,",
            "    sequential=False,",
            "    pypi_mirror=None,",
            "    system=False,",
            "    deploy=False,",
            "):",
            "    # The lock file needs to exist because sync won't write to it.",
            "    if not project.lockfile_exists:",
            "        raise exceptions.LockfileNotFound(\"Pipfile.lock\")",
            "",
            "    # Ensure that virtualenv is available if not system.",
            "    ensure_project(",
            "        project,",
            "        three=three,",
            "        python=python,",
            "        validate=False,",
            "        system=system,",
            "        deploy=deploy,",
            "        pypi_mirror=pypi_mirror,",
            "        clear=clear,",
            "    )",
            "",
            "    # Install everything.",
            "    requirements_dir = vistir.path.create_tracked_tempdir(",
            "        suffix=\"-requirements\", prefix=\"pipenv-\"",
            "    )",
            "    if system:",
            "        project.s.PIPENV_USE_SYSTEM = True",
            "        os.environ[\"PIPENV_USE_SYSTEM\"] = \"1\"",
            "    do_init(",
            "        project,",
            "        dev=dev,",
            "        allow_global=system,",
            "        concurrent=(not sequential),",
            "        requirements_dir=requirements_dir,",
            "        ignore_pipfile=True,  # Don't check if Pipfile and lock match.",
            "        pypi_mirror=pypi_mirror,",
            "        deploy=deploy,",
            "        system=system,",
            "    )",
            "    if not bare:",
            "        click.echo(crayons.green(\"All dependencies are now up-to-date!\"))",
            "",
            "",
            "def do_clean(",
            "    project, three=None, python=None, dry_run=False, bare=False, pypi_mirror=None,",
            "    system=False",
            "):",
            "    # Ensure that virtualenv is available.",
            "    from packaging.utils import canonicalize_name",
            "    ensure_project(project, three=three, python=python, validate=False, pypi_mirror=pypi_mirror)",
            "    ensure_lockfile(project, pypi_mirror=pypi_mirror)",
            "    # Make sure that the virtualenv's site packages are configured correctly",
            "    # otherwise we may end up removing from the global site packages directory",
            "    installed_package_names = project.installed_package_names.copy()",
            "    # Remove known \"bad packages\" from the list.",
            "    for bad_package in BAD_PACKAGES:",
            "        if canonicalize_name(bad_package) in installed_package_names:",
            "            if project.s.is_verbose():",
            "                click.echo(f\"Ignoring {bad_package}.\", err=True)",
            "            installed_package_names.remove(canonicalize_name(bad_package))",
            "    # Intelligently detect if --dev should be used or not.",
            "    locked_packages = {",
            "        canonicalize_name(pkg) for pkg in project.lockfile_package_names[\"combined\"]",
            "    }",
            "    for used_package in locked_packages:",
            "        if used_package in installed_package_names:",
            "            installed_package_names.remove(used_package)",
            "    failure = False",
            "    cmd = [which_pip(project, allow_global=system), \"uninstall\", \"-y\", \"-qq\"]",
            "    for apparent_bad_package in installed_package_names:",
            "        if dry_run and not bare:",
            "            click.echo(apparent_bad_package)",
            "        else:",
            "            if not bare:",
            "                click.echo(",
            "                    crayons.white(",
            "                        fix_utf8(f\"Uninstalling {apparent_bad_package}...\"), bold=True",
            "                    )",
            "                )",
            "            # Uninstall the package.",
            "            cmd = [which_pip(project), \"uninstall\", apparent_bad_package, \"-y\"]",
            "            c = run_command(cmd, is_verbose=project.s.is_verbose())",
            "            if c.returncode != 0:",
            "                failure = True",
            "    sys.exit(int(failure))"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "20": [],
            "172": [
                "import_requirements"
            ],
            "188": [
                "import_requirements"
            ],
            "189": [
                "import_requirements"
            ]
        },
        "addLocation": []
    },
    "pipenv/utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1643,
                "afterPatchRowNumber": 1643,
                "PatchRowcode": "     return urllib3_util.parse_url(url).host"
            },
            "1": {
                "beforePatchRowNumber": 1644,
                "afterPatchRowNumber": 1644,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 1645,
                "afterPatchRowNumber": 1645,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1646,
                "PatchRowcode": "+def get_host_and_port(url):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1647,
                "PatchRowcode": "+    \"\"\"Get the host, or the host:port pair if port is explicitly included, for the given URL."
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1648,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1649,
                "PatchRowcode": "+    Examples:"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1650,
                "PatchRowcode": "+    >>> get_host_and_port('example.com')"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1651,
                "PatchRowcode": "+    'example.com'"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1652,
                "PatchRowcode": "+    >>> get_host_and_port('example.com:443')"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1653,
                "PatchRowcode": "+    'example.com:443'"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1654,
                "PatchRowcode": "+    >>> get_host_and_port('http://example.com')"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1655,
                "PatchRowcode": "+    'example.com'"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1656,
                "PatchRowcode": "+    >>> get_host_and_port('https://example.com/')"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1657,
                "PatchRowcode": "+    'example.com'"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1658,
                "PatchRowcode": "+    >>> get_host_and_port('https://example.com:8081')"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1659,
                "PatchRowcode": "+    'example.com:8081'"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1660,
                "PatchRowcode": "+    >>> get_host_and_port('ssh://example.com')"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1661,
                "PatchRowcode": "+    'example.com'"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1662,
                "PatchRowcode": "+"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1663,
                "PatchRowcode": "+    :param url: the URL string to parse"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1664,
                "PatchRowcode": "+    :return: a string with the host:port pair if the URL includes port number explicitly; otherwise, returns host only"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1665,
                "PatchRowcode": "+    \"\"\""
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1666,
                "PatchRowcode": "+    url = urllib3_util.parse_url(url)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1667,
                "PatchRowcode": "+    return '{}:{}'.format(url.host, url.port) if url.port else url.host"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1668,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1669,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": 1646,
                "afterPatchRowNumber": 1670,
                "PatchRowcode": " def get_canonical_names(packages):"
            },
            "28": {
                "beforePatchRowNumber": 1647,
                "afterPatchRowNumber": 1671,
                "PatchRowcode": "     \"\"\"Canonicalize a list of packages and return a set of canonical names\"\"\""
            },
            "29": {
                "beforePatchRowNumber": 1648,
                "afterPatchRowNumber": 1672,
                "PatchRowcode": "     from .vendor.packaging.utils import canonicalize_name"
            }
        },
        "frontPatchFile": [
            "import contextlib",
            "import errno",
            "import logging",
            "import os",
            "import posixpath",
            "import re",
            "import shlex",
            "import hashlib",
            "import shutil",
            "import signal",
            "import stat",
            "import subprocess",
            "import sys",
            "import warnings",
            "",
            "from contextlib import contextmanager",
            "from distutils.spawn import find_executable",
            "from pathlib import Path",
            "from urllib.parse import urlparse",
            "",
            "import crayons",
            "import parse",
            "import toml",
            "import tomlkit",
            "",
            "from click import echo as click_echo",
            "",
            "from pipenv import environments",
            "from pipenv.exceptions import (",
            "    PipenvCmdError, PipenvUsageError, RequirementError, ResolutionFailure",
            ")",
            "from pipenv.pep508checker import lookup",
            "from pipenv.vendor.packaging.markers import Marker",
            "from pipenv.vendor.urllib3 import util as urllib3_util",
            "from pipenv.vendor.vistir.compat import (",
            "    Mapping, ResourceWarning, Sequence, Set, TemporaryDirectory, lru_cache",
            ")",
            "from pipenv.vendor.vistir.misc import fs_str, run",
            "from pipenv.vendor.vistir.contextmanagers import open_file",
            "",
            "",
            "if environments.MYPY_RUNNING:",
            "    from typing import Any, Dict, List, Optional, Text, Tuple, Union",
            "",
            "    from pipenv.project import Project, TSource",
            "    from pipenv.vendor.requirementslib.models.pipfile import Pipfile",
            "    from pipenv.vendor.requirementslib.models.requirements import (",
            "        Line, Requirement",
            "    )",
            "",
            "",
            "logging.basicConfig(level=logging.ERROR)",
            "",
            "specifiers = [k for k in lookup.keys()]",
            "# List of version control systems we support.",
            "VCS_LIST = (\"git\", \"svn\", \"hg\", \"bzr\")",
            "SCHEME_LIST = (\"http://\", \"https://\", \"ftp://\", \"ftps://\", \"file://\")",
            "requests_session = None  # type: ignore",
            "",
            "",
            "def _get_requests_session(max_retries=1):",
            "    \"\"\"Load requests lazily.\"\"\"",
            "    global requests_session",
            "    if requests_session is not None:",
            "        return requests_session",
            "    import requests",
            "",
            "    requests_session = requests.Session()",
            "    adapter = requests.adapters.HTTPAdapter(max_retries=max_retries)",
            "    requests_session.mount(\"https://pypi.org/pypi\", adapter)",
            "    return requests_session",
            "",
            "",
            "def cleanup_toml(tml):",
            "    toml = tml.split(\"\\n\")",
            "    new_toml = []",
            "    # Remove all empty lines from TOML.",
            "    for line in toml:",
            "        if line.strip():",
            "            new_toml.append(line)",
            "    toml = \"\\n\".join(new_toml)",
            "    new_toml = []",
            "    # Add newlines between TOML sections.",
            "    for i, line in enumerate(toml.split(\"\\n\")):",
            "        # Skip the first line.",
            "        if line.startswith(\"[\"):",
            "            if i > 0:",
            "                # Insert a newline before the heading.",
            "                new_toml.append(\"\")",
            "        new_toml.append(line)",
            "    # adding new line at the end of the TOML file",
            "    new_toml.append(\"\")",
            "    toml = \"\\n\".join(new_toml)",
            "    return toml",
            "",
            "",
            "def convert_toml_outline_tables(parsed):",
            "    \"\"\"Converts all outline tables to inline tables.\"\"\"",
            "    def convert_tomlkit_table(section):",
            "        if isinstance(section, tomlkit.items.Table):",
            "            body = section.value._body",
            "        else:",
            "            body = section._body",
            "        for key, value in body:",
            "            if not key:",
            "                continue",
            "            if hasattr(value, \"keys\") and not isinstance(value, tomlkit.items.InlineTable):",
            "                table = tomlkit.inline_table()",
            "                table.update(value.value)",
            "                section[key.key] = table",
            "",
            "    def convert_toml_table(section):",
            "        for package, value in section.items():",
            "            if hasattr(value, \"keys\") and not isinstance(value, toml.decoder.InlineTableDict):",
            "                table = toml.TomlDecoder().get_empty_inline_table()",
            "                table.update(value)",
            "                section[package] = table",
            "",
            "    is_tomlkit_parsed = isinstance(parsed, tomlkit.container.Container)",
            "    for section in (\"packages\", \"dev-packages\"):",
            "        table_data = parsed.get(section, {})",
            "        if not table_data:",
            "            continue",
            "        if is_tomlkit_parsed:",
            "            convert_tomlkit_table(table_data)",
            "        else:",
            "            convert_toml_table(table_data)",
            "",
            "    return parsed",
            "",
            "",
            "def run_command(cmd, *args, is_verbose=False, **kwargs):",
            "    \"\"\"",
            "    Take an input command and run it, handling exceptions and error codes and returning",
            "    its stdout and stderr.",
            "",
            "    :param cmd: The list of command and arguments.",
            "    :type cmd: list",
            "    :returns: A 2-tuple of the output and error from the command",
            "    :rtype: Tuple[str, str]",
            "    :raises: exceptions.PipenvCmdError",
            "    \"\"\"",
            "",
            "    from ._compat import decode_for_output",
            "    from .cmdparse import Script",
            "    catch_exceptions = kwargs.pop(\"catch_exceptions\", True)",
            "    if isinstance(cmd, ((str,), list, tuple)):",
            "        cmd = Script.parse(cmd)",
            "    if not isinstance(cmd, Script):",
            "        raise TypeError(\"Command input must be a string, list or tuple\")",
            "    if \"env\" not in kwargs:",
            "        kwargs[\"env\"] = os.environ.copy()",
            "    kwargs[\"env\"][\"PYTHONIOENCODING\"] = \"UTF-8\"",
            "    command = [cmd.command, *cmd.args]",
            "    if is_verbose:",
            "        click_echo(f\"Running command: $ {cmd.cmdify()}\")",
            "    c = subprocess_run(command, *args, **kwargs)",
            "    if is_verbose:",
            "        click_echo(\"Command output: {}\".format(",
            "            crayons.cyan(decode_for_output(c.stdout))",
            "        ), err=True)",
            "    if c.returncode and catch_exceptions:",
            "        raise PipenvCmdError(cmd.cmdify(), c.stdout, c.stderr, c.returncode)",
            "    return c",
            "",
            "",
            "def parse_python_version(output):",
            "    \"\"\"Parse a Python version output returned by `python --version`.",
            "",
            "    Return a dict with three keys: major, minor, and micro. Each value is a",
            "    string containing a version part.",
            "",
            "    Note: The micro part would be `'0'` if it's missing from the input string.",
            "    \"\"\"",
            "    version_line = output.split(\"\\n\", 1)[0]",
            "    version_pattern = re.compile(",
            "        r\"\"\"",
            "        ^                   # Beginning of line.",
            "        Python              # Literally \"Python\".",
            "        \\s                  # Space.",
            "        (?P<major>\\d+)      # Major = one or more digits.",
            "        \\.                  # Dot.",
            "        (?P<minor>\\d+)      # Minor = one or more digits.",
            "        (?:                 # Unnamed group for dot-micro.",
            "            \\.              # Dot.",
            "            (?P<micro>\\d+)  # Micro = one or more digit.",
            "        )?                  # Micro is optional because pypa/pipenv#1893.",
            "        .*                  # Trailing garbage.",
            "        $                   # End of line.",
            "    \"\"\",",
            "        re.VERBOSE,",
            "    )",
            "",
            "    match = version_pattern.match(version_line)",
            "    if not match:",
            "        return None",
            "    return match.groupdict(default=\"0\")",
            "",
            "",
            "def python_version(path_to_python):",
            "    from .vendor.pythonfinder.utils import get_python_version",
            "",
            "    if not path_to_python:",
            "        return None",
            "    try:",
            "        version = get_python_version(path_to_python)",
            "    except Exception:",
            "        return None",
            "    return version",
            "",
            "",
            "def escape_grouped_arguments(s):",
            "    \"\"\"Prepares a string for the shell (on Windows too!)",
            "",
            "    Only for use on grouped arguments (passed as a string to Popen)",
            "    \"\"\"",
            "    if s is None:",
            "        return None",
            "",
            "    # Additional escaping for windows paths",
            "    if os.name == \"nt\":",
            "        s = \"{}\".format(s.replace(\"\\\\\", \"\\\\\\\\\"))",
            "    return '\"' + s.replace(\"'\", \"'\\\\''\") + '\"'",
            "",
            "",
            "def clean_pkg_version(version):",
            "    \"\"\"Uses pip to prepare a package version string, from our internal version.\"\"\"",
            "    return pep440_version(str(version).replace(\"==\", \"\"))",
            "",
            "",
            "class HackedPythonVersion:",
            "    \"\"\"A Beautiful hack, which allows us to tell pip which version of Python we're using.\"\"\"",
            "",
            "    def __init__(self, python_version, python_path):",
            "        self.python_version = python_version",
            "        self.python_path = python_path",
            "",
            "    def __enter__(self):",
            "        # Only inject when the value is valid",
            "        if self.python_version:",
            "            os.environ[\"PIPENV_REQUESTED_PYTHON_VERSION\"] = str(self.python_version)",
            "        if self.python_path:",
            "            os.environ[\"PIP_PYTHON_PATH\"] = str(self.python_path)",
            "",
            "    def __exit__(self, *args):",
            "        # Restore original Python version information.",
            "        try:",
            "            del os.environ[\"PIPENV_REQUESTED_PYTHON_VERSION\"]",
            "        except KeyError:",
            "            pass",
            "",
            "",
            "def prepare_pip_source_args(sources, pip_args=None):",
            "    if pip_args is None:",
            "        pip_args = []",
            "    if sources:",
            "        # Add the source to notpip.",
            "        package_url = sources[0].get(\"url\")",
            "        if not package_url:",
            "            raise PipenvUsageError(\"[[source]] section does not contain a URL.\")",
            "        pip_args.extend([\"-i\", package_url])",
            "        # Trust the host if it's not verified.",
            "        if not sources[0].get(\"verify_ssl\", True):",
            "            url_parts = urllib3_util.parse_url(package_url)",
            "            url_port = f\":{url_parts.port}\" if url_parts.port else \"\"",
            "            pip_args.extend(",
            "                [\"--trusted-host\", f\"{url_parts.host}{url_port}\"]",
            "            )",
            "        # Add additional sources as extra indexes.",
            "        if len(sources) > 1:",
            "            for source in sources[1:]:",
            "                url = source.get(\"url\")",
            "                if not url:  # not harmless, just don't continue",
            "                    continue",
            "                pip_args.extend([\"--extra-index-url\", url])",
            "                # Trust the host if it's not verified.",
            "                if not source.get(\"verify_ssl\", True):",
            "                    url_parts = urllib3_util.parse_url(url)",
            "                    url_port = f\":{url_parts.port}\" if url_parts.port else \"\"",
            "                    pip_args.extend(",
            "                        [\"--trusted-host\", f\"{url_parts.host}{url_port}\"]",
            "                    )",
            "    return pip_args",
            "",
            "",
            "def get_project_index(project, index=None, trusted_hosts=None):",
            "    # type: (Optional[Union[str, TSource]], Optional[List[str]], Optional[Project]) -> TSource",
            "    from .project import SourceNotFound",
            "    if trusted_hosts is None:",
            "        trusted_hosts = []",
            "    if isinstance(index, Mapping):",
            "        return project.find_source(index.get(\"url\"))",
            "    try:",
            "        source = project.find_source(index)",
            "    except SourceNotFound:",
            "        index_url = urllib3_util.parse_url(index)",
            "        src_name = project.src_name_from_url(index)",
            "        verify_ssl = index_url.host not in trusted_hosts",
            "        source = {\"url\": index, \"verify_ssl\": verify_ssl, \"name\": src_name}",
            "    return source",
            "",
            "",
            "def get_source_list(",
            "    project,  # type: Project",
            "    index=None,  # type: Optional[Union[str, TSource]]",
            "    extra_indexes=None,  # type: Optional[List[str]]",
            "    trusted_hosts=None,  # type: Optional[List[str]]",
            "    pypi_mirror=None,  # type: Optional[str]",
            "):",
            "    # type: (...) -> List[TSource]",
            "    sources = []  # type: List[TSource]",
            "    if index:",
            "        sources.append(get_project_index(project, index))",
            "    if extra_indexes:",
            "        if isinstance(extra_indexes, str):",
            "            extra_indexes = [extra_indexes]",
            "        for source in extra_indexes:",
            "            extra_src = get_project_index(project, source)",
            "            if not sources or extra_src[\"url\"] != sources[0][\"url\"]:",
            "                sources.append(extra_src)",
            "        else:",
            "            for source in project.pipfile_sources:",
            "                if not sources or source[\"url\"] != sources[0][\"url\"]:",
            "                    sources.append(source)",
            "    if not sources:",
            "        sources = project.pipfile_sources[:]",
            "    if pypi_mirror:",
            "        sources = [",
            "            create_mirror_source(pypi_mirror) if is_pypi_url(source[\"url\"]) else source",
            "            for source in sources",
            "        ]",
            "    return sources",
            "",
            "",
            "def get_indexes_from_requirement(req, project, index=None, extra_indexes=None, trusted_hosts=None, pypi_mirror=None):",
            "    # type: (Requirement, Project, Optional[Text], Optional[List[Text]], Optional[List[Text]], Optional[Text]) -> Tuple[TSource, List[TSource], List[Text]]",
            "    index_sources = []  # type: List[TSource]",
            "    if not trusted_hosts:",
            "        trusted_hosts = []  # type: List[Text]",
            "    if extra_indexes is None:",
            "        extra_indexes = []",
            "    project_indexes = project.pipfile_sources[:]",
            "    indexes = []",
            "    if req.index:",
            "        indexes.append(req.index)",
            "    if getattr(req, \"extra_indexes\", None):",
            "        if not isinstance(req.extra_indexes, list):",
            "            indexes.append(req.extra_indexes)",
            "        else:",
            "            indexes.extend(req.extra_indexes)",
            "    indexes.extend(project_indexes)",
            "    if len(indexes) > 1:",
            "        index, extra_indexes = indexes[0], indexes[1:]",
            "    index_sources = get_source_list(project, index=index, extra_indexes=extra_indexes, trusted_hosts=trusted_hosts, pypi_mirror=pypi_mirror)",
            "    if len(index_sources) > 1:",
            "        index_source, extra_index_sources = index_sources[0], index_sources[1:]",
            "    else:",
            "        index_source, extra_index_sources = index_sources[0], []",
            "    return index_source, extra_index_sources",
            "",
            "",
            "@lru_cache()",
            "def get_pipenv_sitedir():",
            "    # type: () -> Optional[str]",
            "    import pkg_resources",
            "    site_dir = next(",
            "        iter(d for d in pkg_resources.working_set if d.key.lower() == \"pipenv\"), None",
            "    )",
            "    if site_dir is not None:",
            "        return site_dir.location",
            "    return None",
            "",
            "",
            "class HashCacheMixin:",
            "",
            "    \"\"\"Caches hashes of PyPI artifacts so we do not need to re-download them.",
            "",
            "    Hashes are only cached when the URL appears to contain a hash in it and the",
            "    cache key includes the hash value returned from the server). This ought to",
            "    avoid issues where the location on the server changes.",
            "    \"\"\"",
            "    def __init__(self, directory, session):",
            "        self.session = session",
            "        if not os.path.isdir(directory):",
            "            os.makedirs(directory, exist_ok=True)",
            "        super().__init__(directory=directory)",
            "",
            "    def get_hash(self, link):",
            "        # If there is no link hash (i.e., md5, sha256, etc.), we don't want",
            "        # to store it.",
            "        hash_value = self.get(link.url)",
            "        if not hash_value:",
            "            hash_value = self._get_file_hash(link).encode()",
            "            self.set(link.url, hash_value)",
            "        return hash_value.decode(\"utf8\")",
            "",
            "    def _get_file_hash(self, link):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        h = hashlib.new(shims.FAVORITE_HASH)",
            "        with open_file(link.url, self.session) as fp:",
            "            for chunk in iter(lambda: fp.read(8096), b\"\"):",
            "                h.update(chunk)",
            "        return \":\".join([h.name, h.hexdigest()])",
            "",
            "",
            "class Resolver:",
            "    def __init__(",
            "        self, constraints, req_dir, project, sources, index_lookup=None,",
            "        markers_lookup=None, skipped=None, clear=False, pre=False",
            "    ):",
            "        self.initial_constraints = constraints",
            "        self.req_dir = req_dir",
            "        self.project = project",
            "        self.sources = sources",
            "        self.resolved_tree = set()",
            "        self.hashes = {}",
            "        self.clear = clear",
            "        self.pre = pre",
            "        self.results = None",
            "        self.markers_lookup = markers_lookup if markers_lookup is not None else {}",
            "        self.index_lookup = index_lookup if index_lookup is not None else {}",
            "        self.skipped = skipped if skipped is not None else {}",
            "        self.markers = {}",
            "        self.requires_python_markers = {}",
            "        self._pip_args = None",
            "        self._constraints = None",
            "        self._parsed_constraints = None",
            "        self._resolver = None",
            "        self._finder = None",
            "        self._ignore_compatibility_finder = None",
            "        self._session = None",
            "        self._constraint_file = None",
            "        self._pip_options = None",
            "        self._pip_command = None",
            "        self._retry_attempts = 0",
            "        self._hash_cache = None",
            "",
            "    def __repr__(self):",
            "        return (",
            "            \"<Resolver (constraints={self.initial_constraints}, req_dir={self.req_dir}, \"",
            "            \"sources={self.sources})>\".format(self=self)",
            "        )",
            "",
            "    @staticmethod",
            "    @lru_cache()",
            "    def _get_pip_command():",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        return shims.InstallCommand()",
            "",
            "    @property",
            "    def hash_cache(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        if not self._hash_cache:",
            "            self._hash_cache = type(\"HashCache\", (HashCacheMixin, shims.SafeFileCache), {})(",
            "                os.path.join(self.project.s.PIPENV_CACHE_DIR, \"hashes\"), self.session",
            "            )",
            "        return self._hash_cache",
            "",
            "    @classmethod",
            "    def get_metadata(",
            "        cls,",
            "        deps,  # type: List[str]",
            "        index_lookup,  # type: Dict[str, str]",
            "        markers_lookup,  # type: Dict[str, str]",
            "        project,  # type: Project",
            "        sources,  # type: Dict[str, str]",
            "        req_dir=None,  # type: Optional[str]",
            "        pre=False,  # type: bool",
            "        clear=False,  # type: bool",
            "    ):",
            "        # type: (...) -> Tuple[Set[str], Dict[str, Dict[str, Union[str, bool, List[str]]]], Dict[str, str], Dict[str, str]]",
            "        constraints = set()  # type: Set[str]",
            "        skipped = dict()  # type: Dict[str, Dict[str, Union[str, bool, List[str]]]]",
            "        if index_lookup is None:",
            "            index_lookup = {}",
            "        if markers_lookup is None:",
            "            markers_lookup = {}",
            "        if not req_dir:",
            "            from .vendor.vistir.path import create_tracked_tempdir",
            "            req_dir = create_tracked_tempdir(prefix=\"pipenv-\", suffix=\"-reqdir\")",
            "        transient_resolver = cls(",
            "            [], req_dir, project, sources, index_lookup=index_lookup,",
            "            markers_lookup=markers_lookup, clear=clear, pre=pre",
            "        )",
            "        for dep in deps:",
            "            if not dep:",
            "                continue",
            "            req, req_idx, markers_idx = cls.parse_line(",
            "                dep, index_lookup=index_lookup, markers_lookup=markers_lookup, project=project",
            "            )",
            "            index_lookup.update(req_idx)",
            "            markers_lookup.update(markers_idx)",
            "            # Add dependencies of any file (e.g. wheels/tarballs), source, or local",
            "            # directories into the initial constraint pool to be resolved with the",
            "            # rest of the dependencies, while adding the files/vcs deps/paths themselves",
            "            # to the lockfile directly",
            "            constraint_update, lockfile_update = cls.get_deps_from_req(",
            "                req, resolver=transient_resolver, resolve_vcs=project.s.PIPENV_RESOLVE_VCS",
            "            )",
            "            constraints |= constraint_update",
            "            skipped.update(lockfile_update)",
            "        return constraints, skipped, index_lookup, markers_lookup",
            "",
            "    @classmethod",
            "    def parse_line(",
            "        cls,",
            "        line,  # type: str",
            "        index_lookup=None,  # type: Dict[str, str]",
            "        markers_lookup=None,  # type: Dict[str, str]",
            "        project=None  # type: Optional[Project]",
            "    ):",
            "        # type: (...) -> Tuple[Requirement, Dict[str, str], Dict[str, str]]",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "        from .vendor.requirementslib.models.utils import DIRECT_URL_RE",
            "        if index_lookup is None:",
            "            index_lookup = {}",
            "        if markers_lookup is None:",
            "            markers_lookup = {}",
            "        if project is None:",
            "            from .project import Project",
            "            project = Project()",
            "        index, extra_index, trust_host, remainder = parse_indexes(line)",
            "        line = \" \".join(remainder)",
            "        req = None  # type: Requirement",
            "        try:",
            "            req = Requirement.from_line(line)",
            "        except ValueError:",
            "            direct_url = DIRECT_URL_RE.match(line)",
            "            if direct_url:",
            "                line = \"{}#egg={}\".format(line, direct_url.groupdict()[\"name\"])",
            "                try:",
            "                    req = Requirement.from_line(line)",
            "                except ValueError:",
            "                    raise ResolutionFailure(f\"Failed to resolve requirement from line: {line!s}\")",
            "            else:",
            "                raise ResolutionFailure(f\"Failed to resolve requirement from line: {line!s}\")",
            "        if index:",
            "            try:",
            "                index_lookup[req.normalized_name] = project.get_source(",
            "                    url=index, refresh=True).get(\"name\")",
            "            except TypeError:",
            "                pass",
            "        try:",
            "            req.normalized_name",
            "        except TypeError:",
            "            raise RequirementError(req=req)",
            "        # strip the marker and re-add it later after resolution",
            "        # but we will need a fallback in case resolution fails",
            "        # eg pypiwin32",
            "        if req.markers:",
            "            markers_lookup[req.normalized_name] = req.markers.replace('\"', \"'\")",
            "        return req, index_lookup, markers_lookup",
            "",
            "    @classmethod",
            "    def get_deps_from_req(cls, req, resolver=None, resolve_vcs=True):",
            "        # type: (Requirement, Optional[\"Resolver\"], bool) -> Tuple[Set[str], Dict[str, Dict[str, Union[str, bool, List[str]]]]]",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "        from .vendor.requirementslib.models.utils import (",
            "            _requirement_to_str_lowercase_name",
            "        )",
            "        from .vendor.requirementslib.utils import is_installable_dir",
            "",
            "        # TODO: this is way too complex, refactor this",
            "        constraints = set()  # type: Set[str]",
            "        locked_deps = dict()  # type: Dict[str, Dict[str, Union[str, bool, List[str]]]]",
            "        if (req.is_file_or_url or req.is_vcs) and not req.is_wheel:",
            "            # for local packages with setup.py files and potential direct url deps:",
            "            if req.is_vcs:",
            "                req_list, lockfile = get_vcs_deps(reqs=[req])",
            "                req = next(iter(req for req in req_list if req is not None), req_list)",
            "                entry = lockfile[pep423_name(req.normalized_name)]",
            "            else:",
            "                _, entry = req.pipfile_entry",
            "            parsed_line = req.req.parsed_line  # type: Line",
            "            setup_info = None  # type: Any",
            "            try:",
            "                name = req.normalized_name",
            "            except TypeError:",
            "                raise RequirementError(req=req)",
            "            setup_info = req.req.setup_info",
            "            setup_info.get_info()",
            "            locked_deps[pep423_name(name)] = entry",
            "            requirements = []",
            "            # Allow users to toggle resolution off for non-editable VCS packages",
            "            # but leave it on for local, installable folders on the filesystem",
            "            if resolve_vcs or (",
            "                req.editable or parsed_line.is_wheel or (",
            "                    req.is_file_or_url and parsed_line.is_local",
            "                    and is_installable_dir(parsed_line.path)",
            "                )",
            "            ):",
            "                requirements = [v for v in getattr(setup_info, \"requires\", {}).values()]",
            "            for r in requirements:",
            "                if getattr(r, \"url\", None) and not getattr(r, \"editable\", False):",
            "                    if r is not None:",
            "                        if not r.url:",
            "                            continue",
            "                        line = _requirement_to_str_lowercase_name(r)",
            "                        new_req, _, _ = cls.parse_line(line)",
            "                        if r.marker and not r.marker.evaluate():",
            "                            new_constraints = {}",
            "                            _, new_entry = req.pipfile_entry",
            "                            new_lock = {",
            "                                pep423_name(new_req.normalized_name): new_entry",
            "                            }",
            "                        else:",
            "                            new_constraints, new_lock = cls.get_deps_from_req(",
            "                                new_req, resolver",
            "                            )",
            "                        locked_deps.update(new_lock)",
            "                        constraints |= new_constraints",
            "                # if there is no marker or there is a valid marker, add the constraint line",
            "                elif r and (not r.marker or (r.marker and r.marker.evaluate())):",
            "                    line = _requirement_to_str_lowercase_name(r)",
            "                    constraints.add(line)",
            "            # ensure the top level entry remains as provided",
            "            # note that we shouldn't pin versions for editable vcs deps",
            "            if not req.is_vcs:",
            "                if req.specifiers:",
            "                    locked_deps[name][\"version\"] = req.specifiers",
            "                elif parsed_line.setup_info and parsed_line.setup_info.version:",
            "                    locked_deps[name][\"version\"] = \"=={}\".format(",
            "                        parsed_line.setup_info.version",
            "                    )",
            "            # if not req.is_vcs:",
            "            locked_deps.update({name: entry})",
            "        else:",
            "            # if the dependency isn't installable, don't add it to constraints",
            "            # and instead add it directly to the lock",
            "            if req and req.requirement and (",
            "                req.requirement.marker and not req.requirement.marker.evaluate()",
            "            ):",
            "                pypi = resolver.finder if resolver else None",
            "                ireq = req.ireq",
            "                best_match = pypi.find_best_candidate(ireq.name, ireq.specifier).best_candidate if pypi else None",
            "                if best_match:",
            "                    ireq.req.specifier = ireq.specifier.__class__(f\"=={best_match.version}\")",
            "                    hashes = resolver.collect_hashes(ireq) if resolver else []",
            "                    new_req = Requirement.from_ireq(ireq)",
            "                    new_req = new_req.add_hashes(hashes)",
            "                    name, entry = new_req.pipfile_entry",
            "                    locked_deps[pep423_name(name)] = translate_markers(entry)",
            "                    click_echo(",
            "                        \"{} doesn't match your environment, \"",
            "                        \"its dependencies won't be resolved.\".format(req.as_line()),",
            "                        err=True",
            "                    )",
            "                else:",
            "                    click_echo(",
            "                        \"Could not find a version of {} that matches your environment, \"",
            "                        \"it will be skipped.\".format(req.as_line()),",
            "                        err=True",
            "                    )",
            "                return constraints, locked_deps",
            "            constraints.add(req.constraint_line)",
            "            return constraints, locked_deps",
            "        return constraints, locked_deps",
            "",
            "    @classmethod",
            "    def create(",
            "        cls,",
            "        deps,  # type: List[str]",
            "        project,  # type: Project",
            "        index_lookup=None,  # type: Dict[str, str]",
            "        markers_lookup=None,  # type: Dict[str, str]",
            "        sources=None,  # type: List[str]",
            "        req_dir=None,  # type: str",
            "        clear=False,  # type: bool",
            "        pre=False  # type: bool",
            "    ):",
            "        # type: (...) -> \"Resolver\"",
            "        from pipenv.vendor.vistir.path import create_tracked_tempdir",
            "        if not req_dir:",
            "            req_dir = create_tracked_tempdir(suffix=\"-requirements\", prefix=\"pipenv-\")",
            "        if index_lookup is None:",
            "            index_lookup = {}",
            "        if markers_lookup is None:",
            "            markers_lookup = {}",
            "        if sources is None:",
            "            sources = project.sources",
            "        constraints, skipped, index_lookup, markers_lookup = cls.get_metadata(",
            "            deps, index_lookup, markers_lookup, project, sources, req_dir=req_dir,",
            "            pre=pre, clear=clear",
            "        )",
            "        return Resolver(",
            "            constraints, req_dir, project, sources, index_lookup=index_lookup,",
            "            markers_lookup=markers_lookup, skipped=skipped, clear=clear, pre=pre",
            "        )",
            "",
            "    @classmethod",
            "    def from_pipfile(cls, project, pipfile=None, dev=False, pre=False, clear=False):",
            "        # type: (Optional[Project], Optional[Pipfile], bool, bool, bool) -> \"Resolver\"",
            "        from pipenv.vendor.vistir.path import create_tracked_tempdir",
            "        if not pipfile:",
            "            pipfile = project._pipfile",
            "        req_dir = create_tracked_tempdir(suffix=\"-requirements\", prefix=\"pipenv-\")",
            "        index_lookup, markers_lookup = {}, {}",
            "        deps = set()",
            "        if dev:",
            "            deps.update({req.as_line() for req in pipfile.dev_packages})",
            "        deps.update({req.as_line() for req in pipfile.packages})",
            "        constraints, skipped, index_lookup, markers_lookup = cls.get_metadata(",
            "            list(deps), index_lookup, markers_lookup, project, project.sources,",
            "            req_dir=req_dir, pre=pre, clear=clear",
            "        )",
            "        return Resolver(",
            "            constraints, req_dir, project, project.sources, index_lookup=index_lookup,",
            "            markers_lookup=markers_lookup, skipped=skipped, clear=clear, pre=pre",
            "        )",
            "",
            "    @property",
            "    def pip_command(self):",
            "        if self._pip_command is None:",
            "            self._pip_command = self._get_pip_command()",
            "        return self._pip_command",
            "",
            "    def prepare_pip_args(self, use_pep517=None, build_isolation=True):",
            "        pip_args = []",
            "        if self.sources:",
            "            pip_args = prepare_pip_source_args(self.sources, pip_args)",
            "        if use_pep517 is False:",
            "            pip_args.append(\"--no-use-pep517\")",
            "        if build_isolation is False:",
            "            pip_args.append(\"--no-build-isolation\")",
            "        if self.pre:",
            "            pip_args.append(\"--pre\")",
            "        pip_args.extend([\"--cache-dir\", self.project.s.PIPENV_CACHE_DIR])",
            "        return pip_args",
            "",
            "    @property",
            "    def pip_args(self):",
            "        use_pep517 = environments.get_from_env(\"USE_PEP517\", prefix=\"PIP\")",
            "        build_isolation = environments.get_from_env(\"BUILD_ISOLATION\", prefix=\"PIP\")",
            "        if self._pip_args is None:",
            "            self._pip_args = self.prepare_pip_args(",
            "                use_pep517=use_pep517, build_isolation=build_isolation",
            "            )",
            "        return self._pip_args",
            "",
            "    def prepare_constraint_file(self):",
            "        from pipenv.vendor.vistir.path import create_tracked_tempfile",
            "        constraints_file = create_tracked_tempfile(",
            "            mode=\"w\",",
            "            prefix=\"pipenv-\",",
            "            suffix=\"-constraints.txt\",",
            "            dir=self.req_dir,",
            "            delete=False,",
            "        )",
            "        skip_args = (\"build-isolation\", \"use-pep517\", \"cache-dir\")",
            "        args_to_add = [",
            "            arg for arg in self.pip_args",
            "            if not any(bad_arg in arg for bad_arg in skip_args)",
            "        ]",
            "        if self.sources:",
            "            requirementstxt_sources = \" \".join(args_to_add) if args_to_add else \"\"",
            "            requirementstxt_sources = requirementstxt_sources.replace(\" --\", \"\\n--\")",
            "            constraints_file.write(f\"{requirementstxt_sources}\\n\")",
            "        constraints = self.initial_constraints",
            "        constraints_file.write(\"\\n\".join([c for c in constraints]))",
            "        constraints_file.close()",
            "        return constraints_file.name",
            "",
            "    @property",
            "    def constraint_file(self):",
            "        if self._constraint_file is None:",
            "            self._constraint_file = self.prepare_constraint_file()",
            "        return self._constraint_file",
            "",
            "    @property",
            "    def pip_options(self):",
            "        if self._pip_options is None:",
            "            pip_options, _ = self.pip_command.parser.parse_args(self.pip_args)",
            "            pip_options.cache_dir = self.project.s.PIPENV_CACHE_DIR",
            "            pip_options.no_python_version_warning = True",
            "            pip_options.no_input = True",
            "            pip_options.progress_bar = \"off\"",
            "            pip_options.ignore_requires_python = True",
            "            pip_options.pre = self.pre or self.project.settings.get(\"allow_prereleases\", False)",
            "            self._pip_options = pip_options",
            "        return self._pip_options",
            "",
            "    @property",
            "    def session(self):",
            "        if self._session is None:",
            "            self._session = self.pip_command._build_session(self.pip_options)",
            "        return self._session",
            "",
            "    @property",
            "    def finder(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "        if self._finder is None:",
            "            self._finder = shims.get_package_finder(",
            "                install_cmd=self.pip_command,",
            "                options=self.pip_options,",
            "                session=self.session",
            "            )",
            "        return self._finder",
            "",
            "    @property",
            "    def ignore_compatibility_finder(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "        if self._ignore_compatibility_finder is None:",
            "            ignore_compatibility_finder = shims.get_package_finder(",
            "                install_cmd=self.pip_command,",
            "                options=self.pip_options,",
            "                session=self.session,",
            "            )",
            "            # It would be nice if `shims.get_package_finder` took an",
            "            # `ignore_compatibility` parameter, but that's some vendorered code",
            "            # we'd rather avoid touching.",
            "            ignore_compatibility_finder._ignore_compatibility = True",
            "            self._ignore_compatibility_finder = ignore_compatibility_finder",
            "        return self._ignore_compatibility_finder",
            "",
            "    @property",
            "    def parsed_constraints(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        if self._parsed_constraints is None:",
            "            self._parsed_constraints = shims.parse_requirements(",
            "                self.constraint_file, finder=self.finder, session=self.session,",
            "                options=self.pip_options",
            "            )",
            "        return self._parsed_constraints",
            "",
            "    @property",
            "    def constraints(self):",
            "        from pipenv.patched.notpip._internal.req.constructors import install_req_from_parsed_requirement",
            "",
            "        if self._constraints is None:",
            "            self._constraints = [",
            "                install_req_from_parsed_requirement(",
            "                    c, isolated=self.pip_options.build_isolation,",
            "                    use_pep517=self.pip_options.use_pep517, user_supplied=True",
            "                )",
            "                for c in self.parsed_constraints",
            "            ]",
            "        return self._constraints",
            "",
            "    @contextlib.contextmanager",
            "    def get_resolver(self, clear=False):",
            "        from pipenv.vendor.pip_shims.shims import (",
            "            WheelCache, get_requirement_tracker, global_tempdir_manager",
            "        )",
            "",
            "        with global_tempdir_manager(), get_requirement_tracker() as req_tracker, TemporaryDirectory(suffix=\"-build\", prefix=\"pipenv-\") as directory:",
            "            pip_options = self.pip_options",
            "            finder = self.finder",
            "            wheel_cache = WheelCache(pip_options.cache_dir, pip_options.format_control)",
            "            directory.path = directory.name",
            "            preparer = self.pip_command.make_requirement_preparer(",
            "                temp_build_dir=directory,",
            "                options=pip_options,",
            "                req_tracker=req_tracker,",
            "                session=self.session,",
            "                finder=finder,",
            "                use_user_site=False,",
            "            )",
            "            resolver = self.pip_command.make_resolver(",
            "                preparer=preparer,",
            "                finder=finder,",
            "                options=pip_options,",
            "                wheel_cache=wheel_cache,",
            "                use_user_site=False,",
            "                ignore_installed=True,",
            "                ignore_requires_python=pip_options.ignore_requires_python,",
            "                force_reinstall=pip_options.force_reinstall,",
            "                upgrade_strategy=\"to-satisfy-only\",",
            "                use_pep517=pip_options.use_pep517,",
            "            )",
            "            yield resolver",
            "",
            "    def resolve(self):",
            "        from pipenv.vendor.pip_shims.shims import InstallationError",
            "        from pipenv.exceptions import ResolutionFailure",
            "",
            "        with temp_environ(), self.get_resolver() as resolver:",
            "            try:",
            "                results = resolver.resolve(self.constraints, check_supported_wheels=False)",
            "            except InstallationError as e:",
            "                raise ResolutionFailure(message=str(e))",
            "            else:",
            "                self.results = set(results.all_requirements)",
            "                self.resolved_tree.update(self.results)",
            "        return self.resolved_tree",
            "",
            "    def resolve_constraints(self):",
            "        from .vendor.requirementslib.models.markers import marker_from_specifier",
            "        new_tree = set()",
            "        for result in self.resolved_tree:",
            "            if result.markers:",
            "                self.markers[result.name] = result.markers",
            "            else:",
            "                candidate = self.finder.find_best_candidate(result.name, result.specifier).best_candidate",
            "                if candidate:",
            "                    requires_python = candidate.link.requires_python",
            "                    if requires_python:",
            "                        marker = marker_from_specifier(requires_python)",
            "                        self.markers[result.name] = marker",
            "                        result.markers = marker",
            "                        if result.req:",
            "                            result.req.marker = marker",
            "            new_tree.add(result)",
            "        self.resolved_tree = new_tree",
            "",
            "    @classmethod",
            "    def prepend_hash_types(cls, checksums, hash_type):",
            "        cleaned_checksums = set()",
            "        for checksum in checksums:",
            "            if not checksum:",
            "                continue",
            "            if not checksum.startswith(f\"{hash_type}:\"):",
            "                checksum = f\"{hash_type}:{checksum}\"",
            "            cleaned_checksums.add(checksum)",
            "        return cleaned_checksums",
            "",
            "    def _get_hashes_from_pypi(self, ireq):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        pkg_url = f\"https://pypi.org/pypi/{ireq.name}/json\"",
            "        session = _get_requests_session(self.project.s.PIPENV_MAX_RETRIES)",
            "        try:",
            "            collected_hashes = set()",
            "            # Grab the hashes from the new warehouse API.",
            "            r = session.get(pkg_url, timeout=10)",
            "            api_releases = r.json()[\"releases\"]",
            "            cleaned_releases = {}",
            "            for api_version, api_info in api_releases.items():",
            "                api_version = clean_pkg_version(api_version)",
            "                cleaned_releases[api_version] = api_info",
            "            version = \"\"",
            "            if ireq.specifier:",
            "                spec = next(iter(s for s in ireq.specifier), None)",
            "                if spec:",
            "                    version = spec.version",
            "            for release in cleaned_releases[version]:",
            "                collected_hashes.add(release[\"digests\"][shims.FAVORITE_HASH])",
            "            return self.prepend_hash_types(collected_hashes, shims.FAVORITE_HASH)",
            "        except (ValueError, KeyError, ConnectionError):",
            "            if self.project.s.is_verbose():",
            "                click_echo(",
            "                    \"{}: Error generating hash for {}\".format(",
            "                        crayons.red(\"Warning\", bold=True), ireq.name",
            "                    ), err=True",
            "                )",
            "            return None",
            "",
            "    def collect_hashes(self, ireq):",
            "        if ireq.link:",
            "            link = ireq.link",
            "            if link.is_vcs or (link.is_file and link.is_existing_dir()):",
            "                return set()",
            "            if ireq.original_link:",
            "                return {self._get_hash_from_link(ireq.original_link)}",
            "",
            "        if not is_pinned_requirement(ireq):",
            "            return set()",
            "",
            "        if any(",
            "            \"python.org\" in source[\"url\"] or \"pypi.org\" in source[\"url\"]",
            "            for source in self.sources",
            "        ):",
            "            hashes = self._get_hashes_from_pypi(ireq)",
            "            if hashes:",
            "                return hashes",
            "",
            "        applicable_candidates = self.ignore_compatibility_finder.find_best_candidate(",
            "            ireq.name, ireq.specifier",
            "        ).iter_applicable()",
            "        return {",
            "            self._get_hash_from_link(candidate.link)",
            "            for candidate in applicable_candidates",
            "        }",
            "",
            "    def resolve_hashes(self):",
            "        if self.results is not None:",
            "            for ireq in self.results:",
            "                self.hashes[ireq] = self.collect_hashes(ireq)",
            "        return self.hashes",
            "",
            "    def _get_hash_from_link(self, link):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        if link.hash and link.hash_name == shims.FAVORITE_HASH:",
            "            return f\"{link.hash_name}:{link.hash}\"",
            "",
            "        return self.hash_cache.get_hash(link)",
            "",
            "    def _clean_skipped_result(self, req, value):",
            "        ref = None",
            "        if req.is_vcs:",
            "            ref = req.commit_hash",
            "        ireq = req.as_ireq()",
            "        entry = value.copy()",
            "        entry[\"name\"] = req.name",
            "        if entry.get(\"editable\", False) and entry.get(\"version\"):",
            "            del entry[\"version\"]",
            "        ref = ref if ref is not None else entry.get(\"ref\")",
            "        if ref:",
            "            entry[\"ref\"] = ref",
            "        collected_hashes = self.collect_hashes(ireq)",
            "        if collected_hashes:",
            "            entry[\"hashes\"] = sorted(set(collected_hashes))",
            "        return req.name, entry",
            "",
            "    def clean_results(self):",
            "        from pipenv.vendor.requirementslib.models.requirements import (",
            "            Requirement",
            "        )",
            "        reqs = [(Requirement.from_ireq(ireq), ireq) for ireq in self.resolved_tree]",
            "        results = {}",
            "        for req, ireq in reqs:",
            "            if (req.vcs and req.editable and not req.is_direct_url):",
            "                continue",
            "            elif req.normalized_name in self.skipped.keys():",
            "                continue",
            "            collected_hashes = self.hashes.get(ireq, set())",
            "            req = req.add_hashes(collected_hashes)",
            "            if collected_hashes:",
            "                collected_hashes = sorted(collected_hashes)",
            "            name, entry = format_requirement_for_lockfile(",
            "                req, self.markers_lookup, self.index_lookup, collected_hashes",
            "            )",
            "            entry = translate_markers(entry)",
            "            if name in results:",
            "                results[name].update(entry)",
            "            else:",
            "                results[name] = entry",
            "        for k in list(self.skipped.keys()):",
            "            req = Requirement.from_pipfile(k, self.skipped[k])",
            "            name, entry = self._clean_skipped_result(req, self.skipped[k])",
            "            entry = translate_markers(entry)",
            "            if name in results:",
            "                results[name].update(entry)",
            "            else:",
            "                results[name] = entry",
            "        results = list(results.values())",
            "        return results",
            "",
            "",
            "def format_requirement_for_lockfile(req, markers_lookup, index_lookup, hashes=None):",
            "    if req.specifiers:",
            "        version = str(req.get_version())",
            "    else:",
            "        version = None",
            "    index = index_lookup.get(req.normalized_name)",
            "    markers = markers_lookup.get(req.normalized_name)",
            "    req.index = index",
            "    name, pf_entry = req.pipfile_entry",
            "    name = pep423_name(req.name)",
            "    entry = {}",
            "    if isinstance(pf_entry, str):",
            "        entry[\"version\"] = pf_entry.lstrip(\"=\")",
            "    else:",
            "        entry.update(pf_entry)",
            "        if version is not None and not req.is_vcs:",
            "            entry[\"version\"] = version",
            "        if req.line_instance.is_direct_url and not req.is_vcs:",
            "            entry[\"file\"] = req.req.uri",
            "    if hashes:",
            "        entry[\"hashes\"] = sorted(set(hashes))",
            "    entry[\"name\"] = name",
            "    if index:",
            "        entry.update({\"index\": index})",
            "    if markers:",
            "        entry.update({\"markers\": markers})",
            "    entry = translate_markers(entry)",
            "    if req.vcs or req.editable:",
            "        for key in (\"index\", \"version\", \"file\"):",
            "            try:",
            "                del entry[key]",
            "            except KeyError:",
            "                pass",
            "    return name, entry",
            "",
            "",
            "def _show_warning(message, category, filename, lineno, line):",
            "    warnings.showwarning(message=message, category=category, filename=filename,",
            "                         lineno=lineno, file=sys.stderr, line=line)",
            "    sys.stderr.flush()",
            "",
            "",
            "def actually_resolve_deps(",
            "    deps,",
            "    index_lookup,",
            "    markers_lookup,",
            "    project,",
            "    sources,",
            "    clear,",
            "    pre,",
            "    req_dir=None,",
            "):",
            "    from pipenv.vendor.vistir.path import create_tracked_tempdir",
            "",
            "    if not req_dir:",
            "        req_dir = create_tracked_tempdir(suffix=\"-requirements\", prefix=\"pipenv-\")",
            "    warning_list = []",
            "",
            "    with warnings.catch_warnings(record=True) as warning_list:",
            "        resolver = Resolver.create(",
            "            deps, project, index_lookup, markers_lookup, sources, req_dir, clear, pre",
            "        )",
            "        resolver.resolve()",
            "        hashes = resolver.resolve_hashes()",
            "        resolver.resolve_constraints()",
            "        results = resolver.clean_results()",
            "    for warning in warning_list:",
            "        _show_warning(warning.message, warning.category, warning.filename, warning.lineno,",
            "                      warning.line)",
            "    return (results, hashes, resolver.markers_lookup, resolver, resolver.skipped)",
            "",
            "",
            "@contextlib.contextmanager",
            "def create_spinner(text, setting, nospin=None, spinner_name=None):",
            "    from .vendor.vistir import spin",
            "    from .vendor.vistir.misc import fs_str",
            "    if not spinner_name:",
            "        spinner_name = setting.PIPENV_SPINNER",
            "    if nospin is None:",
            "        nospin = setting.PIPENV_NOSPIN",
            "    with spin.create_spinner(",
            "        spinner_name=spinner_name,",
            "        start_text=fs_str(text),",
            "        nospin=nospin, write_to_stdout=False",
            "    ) as sp:",
            "        yield sp",
            "",
            "",
            "def resolve(cmd, sp, project):",
            "    from ._compat import decode_output",
            "    from .cmdparse import Script",
            "    from .vendor.vistir.misc import echo",
            "    c = subprocess_run(Script.parse(cmd).cmd_args, block=False, env=os.environ.copy())",
            "    is_verbose = project.s.is_verbose()",
            "    err = \"\"",
            "    for line in iter(c.stderr.readline, \"\"):",
            "        line = decode_output(line)",
            "        if not line.rstrip():",
            "            continue",
            "        err += line",
            "        if is_verbose:",
            "            sp.hide_and_write(line.rstrip())",
            "",
            "    c.wait()",
            "    returncode = c.poll()",
            "    out = c.stdout.read()",
            "    if returncode != 0:",
            "        sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "            \"Locking Failed!\"",
            "        ))",
            "        echo(out.strip(), err=True)",
            "        if not is_verbose:",
            "            echo(err, err=True)",
            "        sys.exit(returncode)",
            "    if is_verbose:",
            "        echo(out.strip(), err=True)",
            "    return subprocess.CompletedProcess(c.args, returncode, out, err)",
            "",
            "",
            "def get_locked_dep(dep, pipfile_section, prefer_pipfile=True):",
            "    # the prefer pipfile flag is not used yet, but we are introducing",
            "    # it now for development purposes",
            "    # TODO: Is this implementation clear? How can it be improved?",
            "    entry = None",
            "    cleaner_kwargs = {",
            "        \"is_top_level\": False,",
            "        \"pipfile_entry\": None",
            "    }",
            "    if isinstance(dep, Mapping) and dep.get(\"name\", \"\"):",
            "        dep_name = pep423_name(dep[\"name\"])",
            "        name = next(iter(",
            "            k for k in pipfile_section.keys()",
            "            if pep423_name(k) == dep_name",
            "        ), None)",
            "        entry = pipfile_section[name] if name else None",
            "",
            "    if entry:",
            "        cleaner_kwargs.update({\"is_top_level\": True, \"pipfile_entry\": entry})",
            "    lockfile_entry = clean_resolved_dep(dep, **cleaner_kwargs)",
            "    if entry and isinstance(entry, Mapping):",
            "        version = entry.get(\"version\", \"\") if entry else \"\"",
            "    else:",
            "        version = entry if entry else \"\"",
            "    lockfile_name, lockfile_dict = lockfile_entry.copy().popitem()",
            "    lockfile_version = lockfile_dict.get(\"version\", \"\")",
            "    # Keep pins from the lockfile",
            "    if prefer_pipfile and lockfile_version != version and version.startswith(\"==\") and \"*\" not in version:",
            "        lockfile_dict[\"version\"] = version",
            "    lockfile_entry[lockfile_name] = lockfile_dict",
            "    return lockfile_entry",
            "",
            "",
            "def prepare_lockfile(results, pipfile, lockfile):",
            "    # from .vendor.requirementslib.utils import is_vcs",
            "    for dep in results:",
            "        if not dep:",
            "            continue",
            "        # Merge in any relevant information from the pipfile entry, including",
            "        # markers, normalized names, URL info, etc that we may have dropped during lock",
            "        # if not is_vcs(dep):",
            "        lockfile_entry = get_locked_dep(dep, pipfile)",
            "        name = next(iter(k for k in lockfile_entry.keys()))",
            "        current_entry = lockfile.get(name)",
            "        if current_entry:",
            "            if not isinstance(current_entry, Mapping):",
            "                lockfile[name] = lockfile_entry[name]",
            "            else:",
            "                lockfile[name].update(lockfile_entry[name])",
            "                lockfile[name] = translate_markers(lockfile[name])",
            "        else:",
            "            lockfile[name] = lockfile_entry[name]",
            "    return lockfile",
            "",
            "",
            "def venv_resolve_deps(",
            "    deps,",
            "    which,",
            "    project,",
            "    pre=False,",
            "    clear=False,",
            "    allow_global=False,",
            "    pypi_mirror=None,",
            "    dev=False,",
            "    pipfile=None,",
            "    lockfile=None,",
            "    keep_outdated=False",
            "):",
            "    \"\"\"",
            "    Resolve dependencies for a pipenv project, acts as a portal to the target environment.",
            "",
            "    Regardless of whether a virtual environment is present or not, this will spawn",
            "    a subproces which is isolated to the target environment and which will perform",
            "    dependency resolution.  This function reads the output of that call and mutates",
            "    the provided lockfile accordingly, returning nothing.",
            "",
            "    :param List[:class:`~requirementslib.Requirement`] deps: A list of dependencies to resolve.",
            "    :param Callable which: [description]",
            "    :param project: The pipenv Project instance to use during resolution",
            "    :param Optional[bool] pre: Whether to resolve pre-release candidates, defaults to False",
            "    :param Optional[bool] clear: Whether to clear the cache during resolution, defaults to False",
            "    :param Optional[bool] allow_global: Whether to use *sys.executable* as the python binary, defaults to False",
            "    :param Optional[str] pypi_mirror: A URL to substitute any time *pypi.org* is encountered, defaults to None",
            "    :param Optional[bool] dev: Whether to target *dev-packages* or not, defaults to False",
            "    :param pipfile: A Pipfile section to operate on, defaults to None",
            "    :type pipfile: Optional[Dict[str, Union[str, Dict[str, bool, List[str]]]]]",
            "    :param Dict[str, Any] lockfile: A project lockfile to mutate, defaults to None",
            "    :param bool keep_outdated: Whether to retain outdated dependencies and resolve with them in mind, defaults to False",
            "    :raises RuntimeError: Raised on resolution failure",
            "    :return: Nothing",
            "    :rtype: None",
            "    \"\"\"",
            "",
            "    import json",
            "",
            "    from . import resolver",
            "    from ._compat import decode_for_output",
            "    from .vendor.vistir.compat import JSONDecodeError, NamedTemporaryFile, Path",
            "    from .vendor.vistir.misc import fs_str",
            "    from .vendor.vistir.path import create_tracked_tempdir",
            "",
            "    results = []",
            "    pipfile_section = \"dev-packages\" if dev else \"packages\"",
            "    lockfile_section = \"develop\" if dev else \"default\"",
            "    if not deps:",
            "        if not project.pipfile_exists:",
            "            return None",
            "        deps = project.parsed_pipfile.get(pipfile_section, {})",
            "    if not deps:",
            "        return None",
            "",
            "    if not pipfile:",
            "        pipfile = getattr(project, pipfile_section, {})",
            "    if not lockfile:",
            "        lockfile = project._lockfile",
            "    req_dir = create_tracked_tempdir(prefix=\"pipenv\", suffix=\"requirements\")",
            "    cmd = [",
            "        which(\"python\", allow_global=allow_global),",
            "        Path(resolver.__file__.rstrip(\"co\")).as_posix()",
            "    ]",
            "    if pre:",
            "        cmd.append(\"--pre\")",
            "    if clear:",
            "        cmd.append(\"--clear\")",
            "    if allow_global:",
            "        cmd.append(\"--system\")",
            "    if dev:",
            "        cmd.append(\"--dev\")",
            "    target_file = NamedTemporaryFile(prefix=\"resolver\", suffix=\".json\", delete=False)",
            "    target_file.close()",
            "    cmd.extend([\"--write\", make_posix(target_file.name)])",
            "    with temp_environ():",
            "        os.environ.update({fs_str(k): fs_str(val) for k, val in os.environ.items()})",
            "        if pypi_mirror:",
            "            os.environ[\"PIPENV_PYPI_MIRROR\"] = str(pypi_mirror)",
            "        os.environ[\"PIPENV_VERBOSITY\"] = str(project.s.PIPENV_VERBOSITY)",
            "        os.environ[\"PIPENV_REQ_DIR\"] = fs_str(req_dir)",
            "        os.environ[\"PIP_NO_INPUT\"] = fs_str(\"1\")",
            "        pipenv_site_dir = get_pipenv_sitedir()",
            "        if pipenv_site_dir is not None:",
            "            os.environ[\"PIPENV_SITE_DIR\"] = pipenv_site_dir",
            "        else:",
            "            os.environ.pop(\"PIPENV_SITE_DIR\", None)",
            "        if keep_outdated:",
            "            os.environ[\"PIPENV_KEEP_OUTDATED\"] = fs_str(\"1\")",
            "        with create_spinner(text=decode_for_output(\"Locking...\"), setting=project.s) as sp:",
            "            # This conversion is somewhat slow on local and file-type requirements since",
            "            # we now download those requirements / make temporary folders to perform",
            "            # dependency resolution on them, so we are including this step inside the",
            "            # spinner context manager for the UX improvement",
            "            sp.write(decode_for_output(\"Building requirements...\"))",
            "            deps = convert_deps_to_pip(",
            "                deps, project, r=False, include_index=True",
            "            )",
            "            constraints = set(deps)",
            "            os.environ[\"PIPENV_PACKAGES\"] = str(\"\\n\".join(constraints))",
            "            sp.write(decode_for_output(\"Resolving dependencies...\"))",
            "            c = resolve(cmd, sp, project=project)",
            "            results = c.stdout.strip()",
            "            if c.returncode == 0:",
            "                sp.green.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Success!\"))",
            "                if not project.s.is_verbose() and c.stderr.strip():",
            "                    click_echo(crayons.yellow(f\"Warning: {c.stderr.strip()}\"), err=True)",
            "            else:",
            "                sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Locking Failed!\"))",
            "                click_echo(f\"Output: {c.stdout.strip()}\", err=True)",
            "                click_echo(f\"Error: {c.stderr.strip()}\", err=True)",
            "    try:",
            "        with open(target_file.name) as fh:",
            "            results = json.load(fh)",
            "    except (IndexError, JSONDecodeError):",
            "        click_echo(c.stdout.strip(), err=True)",
            "        click_echo(c.stderr.strip(), err=True)",
            "        if os.path.exists(target_file.name):",
            "            os.unlink(target_file.name)",
            "        raise RuntimeError(\"There was a problem with locking.\")",
            "    if os.path.exists(target_file.name):",
            "        os.unlink(target_file.name)",
            "    if lockfile_section not in lockfile:",
            "        lockfile[lockfile_section] = {}",
            "    prepare_lockfile(results, pipfile, lockfile[lockfile_section])",
            "",
            "",
            "def resolve_deps(",
            "    deps,",
            "    which,",
            "    project,",
            "    sources=None,",
            "    python=False,",
            "    clear=False,",
            "    pre=False,",
            "    allow_global=False,",
            "    req_dir=None",
            "):",
            "    \"\"\"Given a list of dependencies, return a resolved list of dependencies,",
            "    using pip-tools -- and their hashes, using the warehouse API / pip.",
            "    \"\"\"",
            "    index_lookup = {}",
            "    markers_lookup = {}",
            "    python_path = which(\"python\", allow_global=allow_global)",
            "    if not os.environ.get(\"PIP_SRC\"):",
            "        os.environ[\"PIP_SRC\"] = project.virtualenv_src_location",
            "    backup_python_path = sys.executable",
            "    results = []",
            "    resolver = None",
            "    if not deps:",
            "        return results, resolver",
            "    # First (proper) attempt:",
            "    req_dir = req_dir if req_dir else os.environ.get(\"req_dir\", None)",
            "    if not req_dir:",
            "        from .vendor.vistir.path import create_tracked_tempdir",
            "        req_dir = create_tracked_tempdir(prefix=\"pipenv-\", suffix=\"-requirements\")",
            "    with HackedPythonVersion(python_version=python, python_path=python_path):",
            "        try:",
            "            results, hashes, markers_lookup, resolver, skipped = actually_resolve_deps(",
            "                deps,",
            "                index_lookup,",
            "                markers_lookup,",
            "                project,",
            "                sources,",
            "                clear,",
            "                pre,",
            "                req_dir=req_dir,",
            "            )",
            "        except RuntimeError:",
            "            # Don't exit here, like usual.",
            "            results = None",
            "    # Second (last-resort) attempt:",
            "    if results is None:",
            "        with HackedPythonVersion(",
            "            python_version=\".\".join([str(s) for s in sys.version_info[:3]]),",
            "            python_path=backup_python_path,",
            "        ):",
            "            try:",
            "                # Attempt to resolve again, with different Python version information,",
            "                # particularly for particularly particular packages.",
            "                results, hashes, markers_lookup, resolver, skipped = actually_resolve_deps(",
            "                    deps,",
            "                    index_lookup,",
            "                    markers_lookup,",
            "                    project,",
            "                    sources,",
            "                    clear,",
            "                    pre,",
            "                    req_dir=req_dir,",
            "                )",
            "            except RuntimeError:",
            "                sys.exit(1)",
            "    return results, resolver",
            "",
            "",
            "def is_star(val):",
            "    return isinstance(val, str) and val == \"*\"",
            "",
            "",
            "def is_pinned(val):",
            "    if isinstance(val, Mapping):",
            "        val = val.get(\"version\")",
            "    return isinstance(val, str) and val.startswith(\"==\")",
            "",
            "",
            "def is_pinned_requirement(ireq):",
            "    \"\"\"",
            "    Returns whether an InstallRequirement is a \"pinned\" requirement.",
            "    \"\"\"",
            "    if ireq.editable:",
            "        return False",
            "",
            "    if ireq.req is None or len(ireq.specifier) != 1:",
            "        return False",
            "",
            "    spec = next(iter(ireq.specifier))",
            "    return spec.operator in {\"==\", \"===\"} and not spec.version.endswith(\".*\")",
            "",
            "",
            "def convert_deps_to_pip(deps, project=None, r=True, include_index=True):",
            "    \"\"\"\"Converts a Pipfile-formatted dependency to a pip-formatted one.\"\"\"",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    dependencies = []",
            "    for dep_name, dep in deps.items():",
            "        if project:",
            "            project.clear_pipfile_cache()",
            "        indexes = getattr(project, \"pipfile_sources\", []) if project is not None else []",
            "        new_dep = Requirement.from_pipfile(dep_name, dep)",
            "        if new_dep.index:",
            "            include_index = True",
            "        req = new_dep.as_line(sources=indexes if include_index else None).strip()",
            "        dependencies.append(req)",
            "    if not r:",
            "        return dependencies",
            "",
            "    # Write requirements.txt to tmp directory.",
            "    from .vendor.vistir.path import create_tracked_tempfile",
            "    f = create_tracked_tempfile(suffix=\"-requirements.txt\", delete=False)",
            "    f.write(\"\\n\".join(dependencies).encode(\"utf-8\"))",
            "    f.close()",
            "    return f.name",
            "",
            "",
            "def mkdir_p(newdir):",
            "    \"\"\"works the way a good mkdir should :)",
            "        - already exists, silently complete",
            "        - regular file in the way, raise an exception",
            "        - parent directory(ies) does not exist, make them as well",
            "        From: http://code.activestate.com/recipes/82465-a-friendly-mkdir/",
            "    \"\"\"",
            "    if os.path.isdir(newdir):",
            "        pass",
            "    elif os.path.isfile(newdir):",
            "        raise OSError(",
            "            \"a file with the same name as the desired dir, '{}', already exists.\".format(",
            "                newdir",
            "            )",
            "        )",
            "",
            "    else:",
            "        head, tail = os.path.split(newdir)",
            "        if head and not os.path.isdir(head):",
            "            mkdir_p(head)",
            "        if tail:",
            "            # Even though we've checked that the directory doesn't exist above, it might exist",
            "            # now if some other process has created it between now and the time we checked it.",
            "            try:",
            "                os.mkdir(newdir)",
            "            except OSError as exn:",
            "                # If we failed because the directory does exist, that's not a problem -",
            "                # that's what we were trying to do anyway. Only re-raise the exception",
            "                # if we failed for some other reason.",
            "                if exn.errno != errno.EEXIST:",
            "                    raise",
            "",
            "",
            "def is_required_version(version, specified_version):",
            "    \"\"\"Check to see if there's a hard requirement for version",
            "    number provided in the Pipfile.",
            "    \"\"\"",
            "    # Certain packages may be defined with multiple values.",
            "    if isinstance(specified_version, dict):",
            "        specified_version = specified_version.get(\"version\", \"\")",
            "    if specified_version.startswith(\"==\"):",
            "        return version.strip() == specified_version.split(\"==\")[1].strip()",
            "",
            "    return True",
            "",
            "",
            "def is_editable(pipfile_entry):",
            "    if hasattr(pipfile_entry, \"get\"):",
            "        return pipfile_entry.get(\"editable\", False) and any(",
            "            pipfile_entry.get(key) for key in (\"file\", \"path\") + VCS_LIST",
            "        )",
            "    return False",
            "",
            "",
            "def is_installable_file(path):",
            "    \"\"\"Determine if a path can potentially be installed\"\"\"",
            "    from .patched.notpip._internal.utils.packaging import specifiers",
            "    from .vendor.pip_shims.shims import is_archive_file, is_installable_dir",
            "",
            "    if hasattr(path, \"keys\") and any(",
            "        key for key in path.keys() if key in [\"file\", \"path\"]",
            "    ):",
            "        path = urlparse(path[\"file\"]).path if \"file\" in path else path[\"path\"]",
            "    if not isinstance(path, str) or path == \"*\":",
            "        return False",
            "",
            "    # If the string starts with a valid specifier operator, test if it is a valid",
            "    # specifier set before making a path object (to avoid breaking windows)",
            "    if any(path.startswith(spec) for spec in \"!=<>~\"):",
            "        try:",
            "            specifiers.SpecifierSet(path)",
            "        # If this is not a valid specifier, just move on and try it as a path",
            "        except specifiers.InvalidSpecifier:",
            "            pass",
            "        else:",
            "            return False",
            "",
            "    if not os.path.exists(os.path.abspath(path)):",
            "        return False",
            "",
            "    lookup_path = Path(path)",
            "    absolute_path = f\"{lookup_path.absolute()}\"",
            "    if lookup_path.is_dir() and is_installable_dir(absolute_path):",
            "        return True",
            "",
            "    elif lookup_path.is_file() and is_archive_file(absolute_path):",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def is_file(package):",
            "    \"\"\"Determine if a package name is for a File dependency.\"\"\"",
            "    if hasattr(package, \"keys\"):",
            "        return any(key for key in package.keys() if key in [\"file\", \"path\"])",
            "",
            "    if os.path.exists(str(package)):",
            "        return True",
            "",
            "    for start in SCHEME_LIST:",
            "        if str(package).startswith(start):",
            "            return True",
            "",
            "    return False",
            "",
            "",
            "def pep440_version(version):",
            "    \"\"\"Normalize version to PEP 440 standards\"\"\"",
            "    # Use pip built-in version parser.",
            "    from pipenv.vendor.pip_shims import shims",
            "",
            "    return str(shims.parse_version(version))",
            "",
            "",
            "def pep423_name(name):",
            "    \"\"\"Normalize package name to PEP 423 style standard.\"\"\"",
            "    name = name.lower()",
            "    if any(i not in name for i in (VCS_LIST + SCHEME_LIST)):",
            "        return name.replace(\"_\", \"-\")",
            "",
            "    else:",
            "        return name",
            "",
            "",
            "def proper_case(package_name):",
            "    \"\"\"Properly case project name from pypi.org.\"\"\"",
            "    # Hit the simple API.",
            "    r = _get_requests_session().get(",
            "        f\"https://pypi.org/pypi/{package_name}/json\", timeout=0.3, stream=True",
            "    )",
            "    if not r.ok:",
            "        raise OSError(",
            "            f\"Unable to find package {package_name} in PyPI repository.\"",
            "        )",
            "",
            "    r = parse.parse(\"https://pypi.org/pypi/{name}/json\", r.url)",
            "    good_name = r[\"name\"]",
            "    return good_name",
            "",
            "",
            "def get_windows_path(*args):",
            "    \"\"\"Sanitize a path for windows environments",
            "",
            "    Accepts an arbitrary list of arguments and makes a clean windows path\"\"\"",
            "    return os.path.normpath(os.path.join(*args))",
            "",
            "",
            "def find_windows_executable(bin_path, exe_name):",
            "    \"\"\"Given an executable name, search the given location for an executable\"\"\"",
            "    requested_path = get_windows_path(bin_path, exe_name)",
            "    if os.path.isfile(requested_path):",
            "        return requested_path",
            "",
            "    try:",
            "        pathext = os.environ[\"PATHEXT\"]",
            "    except KeyError:",
            "        pass",
            "    else:",
            "        for ext in pathext.split(os.pathsep):",
            "            path = get_windows_path(bin_path, exe_name + ext.strip().lower())",
            "            if os.path.isfile(path):",
            "                return path",
            "",
            "    return find_executable(exe_name)",
            "",
            "",
            "def path_to_url(path):",
            "",
            "    return Path(normalize_drive(os.path.abspath(path))).as_uri()",
            "",
            "",
            "def normalize_path(path):",
            "    return os.path.expandvars(os.path.expanduser(",
            "        os.path.normcase(os.path.normpath(os.path.abspath(str(path))))",
            "    ))",
            "",
            "",
            "def get_url_name(url):",
            "    if not isinstance(url, str):",
            "        return",
            "    return urllib3_util.parse_url(url).host",
            "",
            "",
            "def get_canonical_names(packages):",
            "    \"\"\"Canonicalize a list of packages and return a set of canonical names\"\"\"",
            "    from .vendor.packaging.utils import canonicalize_name",
            "",
            "    if not isinstance(packages, Sequence):",
            "        if not isinstance(packages, str):",
            "            return packages",
            "        packages = [packages]",
            "    return {canonicalize_name(pkg) for pkg in packages if pkg}",
            "",
            "",
            "def walk_up(bottom):",
            "    \"\"\"Mimic os.walk, but walk 'up' instead of down the directory tree.",
            "    From: https://gist.github.com/zdavkeos/1098474",
            "    \"\"\"",
            "    bottom = os.path.realpath(bottom)",
            "    # Get files in current dir.",
            "    try:",
            "        names = os.listdir(bottom)",
            "    except Exception:",
            "        return",
            "",
            "    dirs, nondirs = [], []",
            "    for name in names:",
            "        if os.path.isdir(os.path.join(bottom, name)):",
            "            dirs.append(name)",
            "        else:",
            "            nondirs.append(name)",
            "    yield bottom, dirs, nondirs",
            "",
            "    new_path = os.path.realpath(os.path.join(bottom, \"..\"))",
            "    # See if we are at the top.",
            "    if new_path == bottom:",
            "        return",
            "",
            "    yield from walk_up(new_path)",
            "",
            "",
            "def find_requirements(max_depth=3):",
            "    \"\"\"Returns the path of a requirements.txt file in parent directories.\"\"\"",
            "    i = 0",
            "    for c, d, f in walk_up(os.getcwd()):",
            "        i += 1",
            "        if i < max_depth:",
            "            r = os.path.join(c, \"requirements.txt\")",
            "            if os.path.isfile(r):",
            "                return r",
            "",
            "    raise RuntimeError(\"No requirements.txt found!\")",
            "",
            "",
            "# Borrowed from Pew.",
            "# See https://github.com/berdario/pew/blob/master/pew/_utils.py#L82",
            "@contextmanager",
            "def temp_environ():",
            "    \"\"\"Allow the ability to set os.environ temporarily\"\"\"",
            "    environ = dict(os.environ)",
            "    try:",
            "        yield",
            "",
            "    finally:",
            "        os.environ.clear()",
            "        os.environ.update(environ)",
            "",
            "",
            "@contextmanager",
            "def temp_path():",
            "    \"\"\"Allow the ability to set os.environ temporarily\"\"\"",
            "    path = [p for p in sys.path]",
            "    try:",
            "        yield",
            "    finally:",
            "        sys.path = [p for p in path]",
            "",
            "",
            "def load_path(python):",
            "    import json",
            "",
            "    from pathlib import Path",
            "    python = Path(python).as_posix()",
            "    json_dump_commmand = '\"import json, sys; print(json.dumps(sys.path));\"'",
            "    c = subprocess_run([python, \"-c\", json_dump_commmand])",
            "    if c.returncode == 0:",
            "        return json.loads(c.stdout.strip())",
            "    else:",
            "        return []",
            "",
            "",
            "def is_valid_url(url):",
            "    \"\"\"Checks if a given string is an url\"\"\"",
            "    pieces = urlparse(url)",
            "    return all([pieces.scheme, pieces.netloc])",
            "",
            "",
            "def is_pypi_url(url):",
            "    return bool(re.match(r\"^http[s]?:\\/\\/pypi(?:\\.python)?\\.org\\/simple[\\/]?$\", url))",
            "",
            "",
            "def replace_pypi_sources(sources, pypi_replacement_source):",
            "    return [pypi_replacement_source] + [",
            "        source for source in sources if not is_pypi_url(source[\"url\"])",
            "    ]",
            "",
            "",
            "def create_mirror_source(url):",
            "    return {",
            "        \"url\": url,",
            "        \"verify_ssl\": url.startswith(\"https://\"),",
            "        \"name\": urlparse(url).hostname,",
            "    }",
            "",
            "",
            "def download_file(url, filename, max_retries=1):",
            "    \"\"\"Downloads file from url to a path with filename\"\"\"",
            "    r = _get_requests_session(max_retries).get(url, stream=True)",
            "    if not r.ok:",
            "        raise OSError(\"Unable to download file\")",
            "",
            "    with open(filename, \"wb\") as f:",
            "        f.write(r.content)",
            "",
            "",
            "def normalize_drive(path):",
            "    \"\"\"Normalize drive in path so they stay consistent.",
            "",
            "    This currently only affects local drives on Windows, which can be",
            "    identified with either upper or lower cased drive names. The case is",
            "    always converted to uppercase because it seems to be preferred.",
            "",
            "    See: <https://github.com/pypa/pipenv/issues/1218>",
            "    \"\"\"",
            "    if os.name != \"nt\" or not isinstance(path, str):",
            "        return path",
            "",
            "    drive, tail = os.path.splitdrive(path)",
            "    # Only match (lower cased) local drives (e.g. 'c:'), not UNC mounts.",
            "    if drive.islower() and len(drive) == 2 and drive[1] == \":\":",
            "        return f\"{drive.upper()}{tail}\"",
            "",
            "    return path",
            "",
            "",
            "def is_readonly_path(fn):",
            "    \"\"\"Check if a provided path exists and is readonly.",
            "",
            "    Permissions check is `bool(path.stat & stat.S_IREAD)` or `not os.access(path, os.W_OK)`",
            "    \"\"\"",
            "    if os.path.exists(fn):",
            "        return (os.stat(fn).st_mode & stat.S_IREAD) or not os.access(fn, os.W_OK)",
            "",
            "    return False",
            "",
            "",
            "def set_write_bit(fn):",
            "    if isinstance(fn, str) and not os.path.exists(fn):",
            "        return",
            "    os.chmod(fn, stat.S_IWRITE | stat.S_IWUSR | stat.S_IRUSR)",
            "    return",
            "",
            "",
            "def rmtree(directory, ignore_errors=False):",
            "    shutil.rmtree(",
            "        directory, ignore_errors=ignore_errors, onerror=handle_remove_readonly",
            "    )",
            "",
            "",
            "def handle_remove_readonly(func, path, exc):",
            "    \"\"\"Error handler for shutil.rmtree.",
            "",
            "    Windows source repo folders are read-only by default, so this error handler",
            "    attempts to set them as writeable and then proceed with deletion.\"\"\"",
            "    # Check for read-only attribute",
            "    default_warning_message = (",
            "        \"Unable to remove file due to permissions restriction: {!r}\"",
            "    )",
            "    # split the initial exception out into its type, exception, and traceback",
            "    exc_type, exc_exception, exc_tb = exc",
            "    if is_readonly_path(path):",
            "        # Apply write permission and call original function",
            "        set_write_bit(path)",
            "        try:",
            "            func(path)",
            "        except OSError as e:",
            "            if e.errno in [errno.EACCES, errno.EPERM]:",
            "                warnings.warn(default_warning_message.format(path), ResourceWarning)",
            "                return",
            "",
            "    if exc_exception.errno in [errno.EACCES, errno.EPERM]:",
            "        warnings.warn(default_warning_message.format(path), ResourceWarning)",
            "        return",
            "",
            "    raise exc",
            "",
            "",
            "def escape_cmd(cmd):",
            "    if any(special_char in cmd for special_char in [\"<\", \">\", \"&\", \".\", \"^\", \"|\", \"?\"]):",
            "        cmd = f'\\\"{cmd}\\\"'",
            "    return cmd",
            "",
            "",
            "def safe_expandvars(value):",
            "    \"\"\"Call os.path.expandvars if value is a string, otherwise do nothing.",
            "    \"\"\"",
            "    if isinstance(value, str):",
            "        return os.path.expandvars(value)",
            "    return value",
            "",
            "",
            "def get_vcs_deps(",
            "    project=None,",
            "    dev=False,",
            "    pypi_mirror=None,",
            "    packages=None,",
            "    reqs=None",
            "):",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    section = \"vcs_dev_packages\" if dev else \"vcs_packages\"",
            "    if reqs is None:",
            "        reqs = []",
            "    lockfile = {}",
            "    if not reqs:",
            "        if not project and not packages:",
            "            raise ValueError(",
            "                \"Must supply either a project or a pipfile section to lock vcs dependencies.\"",
            "            )",
            "        if not packages:",
            "            try:",
            "                packages = getattr(project, section)",
            "            except AttributeError:",
            "                return [], []",
            "        reqs = [Requirement.from_pipfile(name, entry) for name, entry in packages.items()]",
            "    result = []",
            "    for requirement in reqs:",
            "        name = requirement.normalized_name",
            "        commit_hash = None",
            "        if requirement.is_vcs:",
            "            try:",
            "                with temp_path(), locked_repository(requirement) as repo:",
            "                    from pipenv.vendor.requirementslib.models.requirements import (",
            "                        Requirement",
            "                    )",
            "",
            "                    # from distutils.sysconfig import get_python_lib",
            "                    # sys.path = [repo.checkout_directory, \"\", \".\", get_python_lib(plat_specific=0)]",
            "                    commit_hash = repo.get_commit_hash()",
            "                    name = requirement.normalized_name",
            "                    lockfile[name] = requirement.pipfile_entry[1]",
            "                    lockfile[name]['ref'] = commit_hash",
            "                    result.append(requirement)",
            "            except OSError:",
            "                continue",
            "    return result, lockfile",
            "",
            "",
            "def translate_markers(pipfile_entry):",
            "    \"\"\"Take a pipfile entry and normalize its markers",
            "",
            "    Provide a pipfile entry which may have 'markers' as a key or it may have",
            "    any valid key from `packaging.markers.marker_context.keys()` and standardize",
            "    the format into {'markers': 'key == \"some_value\"'}.",
            "",
            "    :param pipfile_entry: A dictionariy of keys and values representing a pipfile entry",
            "    :type pipfile_entry: dict",
            "    :returns: A normalized dictionary with cleaned marker entries",
            "    \"\"\"",
            "    if not isinstance(pipfile_entry, Mapping):",
            "        raise TypeError(\"Entry is not a pipfile formatted mapping.\")",
            "    from .vendor.packaging.markers import default_environment",
            "    from .vendor.vistir.misc import dedup",
            "",
            "    allowed_marker_keys = [\"markers\"] + list(default_environment().keys())",
            "    provided_keys = list(pipfile_entry.keys()) if hasattr(pipfile_entry, \"keys\") else []",
            "    pipfile_markers = set(provided_keys) & set(allowed_marker_keys)",
            "    new_pipfile = dict(pipfile_entry).copy()",
            "    marker_set = set()",
            "    if \"markers\" in new_pipfile:",
            "        marker_str = new_pipfile.pop(\"markers\")",
            "        if marker_str:",
            "            marker = str(Marker(marker_str))",
            "            if 'extra' not in marker:",
            "                marker_set.add(marker)",
            "    for m in pipfile_markers:",
            "        entry = f\"{pipfile_entry[m]}\"",
            "        if m != \"markers\":",
            "            marker_set.add(str(Marker(f\"{m} {entry}\")))",
            "            new_pipfile.pop(m)",
            "    if marker_set:",
            "        new_pipfile[\"markers\"] = str(Marker(\" or \".join(",
            "            f\"{s}\" if \" and \" in s else s",
            "            for s in sorted(dedup(marker_set))",
            "        ))).replace('\"', \"'\")",
            "    return new_pipfile",
            "",
            "",
            "def clean_resolved_dep(dep, is_top_level=False, pipfile_entry=None):",
            "    from .vendor.requirementslib.utils import is_vcs",
            "    name = pep423_name(dep[\"name\"])",
            "    lockfile = {}",
            "    # We use this to determine if there are any markers on top level packages",
            "    # So we can make sure those win out during resolution if the packages reoccur",
            "    if \"version\" in dep and dep[\"version\"] and not dep.get(\"editable\", False):",
            "        version = \"{}\".format(dep[\"version\"])",
            "        if not version.startswith(\"==\"):",
            "            version = f\"=={version}\"",
            "        lockfile[\"version\"] = version",
            "    if is_vcs(dep):",
            "        ref = dep.get(\"ref\", None)",
            "        if ref is not None:",
            "            lockfile[\"ref\"] = ref",
            "        vcs_type = next(iter(k for k in dep.keys() if k in VCS_LIST), None)",
            "        if vcs_type:",
            "            lockfile[vcs_type] = dep[vcs_type]",
            "        if \"subdirectory\" in dep:",
            "            lockfile[\"subdirectory\"] = dep[\"subdirectory\"]",
            "    for key in [\"hashes\", \"index\", \"extras\", \"editable\"]:",
            "        if key in dep:",
            "            lockfile[key] = dep[key]",
            "    # In case we lock a uri or a file when the user supplied a path",
            "    # remove the uri or file keys from the entry and keep the path",
            "    fs_key = next(iter(k for k in [\"path\", \"file\"] if k in dep), None)",
            "    pipfile_fs_key = None",
            "    if pipfile_entry:",
            "        pipfile_fs_key = next(iter(k for k in [\"path\", \"file\"] if k in pipfile_entry), None)",
            "    if fs_key and pipfile_fs_key and fs_key != pipfile_fs_key:",
            "        lockfile[pipfile_fs_key] = pipfile_entry[pipfile_fs_key]",
            "    elif fs_key is not None:",
            "        lockfile[fs_key] = dep[fs_key]",
            "",
            "    # If a package is **PRESENT** in the pipfile but has no markers, make sure we",
            "    # **NEVER** include markers in the lockfile",
            "    if \"markers\" in dep and dep.get(\"markers\", \"\").strip():",
            "        # First, handle the case where there is no top level dependency in the pipfile",
            "        if not is_top_level:",
            "            translated = translate_markers(dep).get(\"markers\", \"\").strip()",
            "            if translated:",
            "                try:",
            "                    lockfile[\"markers\"] = translated",
            "                except TypeError:",
            "                    pass",
            "        # otherwise make sure we are prioritizing whatever the pipfile says about the markers",
            "        # If the pipfile says nothing, then we should put nothing in the lockfile",
            "        else:",
            "            try:",
            "                pipfile_entry = translate_markers(pipfile_entry)",
            "                lockfile[\"markers\"] = pipfile_entry.get(\"markers\")",
            "            except TypeError:",
            "                pass",
            "    return {name: lockfile}",
            "",
            "",
            "def get_workon_home():",
            "    workon_home = os.environ.get(\"WORKON_HOME\")",
            "    if not workon_home:",
            "        if os.name == \"nt\":",
            "            workon_home = \"~/.virtualenvs\"",
            "        else:",
            "            workon_home = os.path.join(",
            "                os.environ.get(\"XDG_DATA_HOME\", \"~/.local/share\"), \"virtualenvs\"",
            "            )",
            "    # Create directory if it does not already exist",
            "    expanded_path = Path(os.path.expandvars(workon_home)).expanduser()",
            "    mkdir_p(str(expanded_path))",
            "    return expanded_path",
            "",
            "",
            "def is_virtual_environment(path):",
            "    \"\"\"Check if a given path is a virtual environment's root.",
            "",
            "    This is done by checking if the directory contains a Python executable in",
            "    its bin/Scripts directory. Not technically correct, but good enough for",
            "    general usage.",
            "    \"\"\"",
            "    if not path.is_dir():",
            "        return False",
            "    for bindir_name in ('bin', 'Scripts'):",
            "        for python in path.joinpath(bindir_name).glob('python*'):",
            "            try:",
            "                exeness = python.is_file() and os.access(str(python), os.X_OK)",
            "            except OSError:",
            "                exeness = False",
            "            if exeness:",
            "                return True",
            "    return False",
            "",
            "",
            "@contextmanager",
            "def locked_repository(requirement):",
            "    from .vendor.vistir.path import create_tracked_tempdir",
            "    if not requirement.is_vcs:",
            "        return",
            "    original_base = os.environ.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "    os.environ[\"PIP_SHIMS_BASE_MODULE\"] = fs_str(\"pipenv.patched.notpip\")",
            "    src_dir = create_tracked_tempdir(prefix=\"pipenv-\", suffix=\"-src\")",
            "    try:",
            "        with requirement.req.locked_vcs_repo(src_dir=src_dir) as repo:",
            "            yield repo",
            "    finally:",
            "        if original_base:",
            "            os.environ[\"PIP_SHIMS_BASE_MODULE\"] = original_base",
            "",
            "",
            "@contextmanager",
            "def chdir(path):",
            "    \"\"\"Context manager to change working directories.\"\"\"",
            "    if not path:",
            "        return",
            "    prev_cwd = Path.cwd().as_posix()",
            "    if isinstance(path, Path):",
            "        path = path.as_posix()",
            "    os.chdir(str(path))",
            "    try:",
            "        yield",
            "    finally:",
            "        os.chdir(prev_cwd)",
            "",
            "",
            "def looks_like_dir(path):",
            "    seps = (sep for sep in (os.path.sep, os.path.altsep) if sep is not None)",
            "    return any(sep in path for sep in seps)",
            "",
            "",
            "def parse_indexes(line, strict=False):",
            "    from argparse import ArgumentParser",
            "",
            "    comment_re = re.compile(r\"(?:^|\\s+)#.*$\")",
            "    line = comment_re.sub(\"\", line)",
            "    parser = ArgumentParser(\"indexes\", allow_abbrev=False)",
            "    parser.add_argument(\"-i\", \"--index-url\", dest=\"index\")",
            "    parser.add_argument(\"--extra-index-url\", dest=\"extra_index\")",
            "    parser.add_argument(\"--trusted-host\", dest=\"trusted_host\")",
            "    args, remainder = parser.parse_known_args(line.split())",
            "    index = args.index",
            "    extra_index = args.extra_index",
            "    trusted_host = args.trusted_host",
            "    if strict and sum(",
            "        bool(arg) for arg in (index, extra_index, trusted_host, remainder)",
            "    ) > 1:",
            "        raise ValueError(\"Index arguments must be on their own lines.\")",
            "    return index, extra_index, trusted_host, remainder",
            "",
            "",
            "@contextmanager",
            "def sys_version(version_tuple):",
            "    \"\"\"",
            "    Set a temporary sys.version_info tuple",
            "",
            "    :param version_tuple: a fake sys.version_info tuple",
            "    \"\"\"",
            "",
            "    old_version = sys.version_info",
            "    sys.version_info = version_tuple",
            "    yield",
            "    sys.version_info = old_version",
            "",
            "",
            "def add_to_set(original_set, element):",
            "    \"\"\"Given a set and some arbitrary element, add the element(s) to the set\"\"\"",
            "    if not element:",
            "        return original_set",
            "    if isinstance(element, Set):",
            "        original_set |= element",
            "    elif isinstance(element, (list, tuple)):",
            "        original_set |= set(element)",
            "    else:",
            "        original_set.add(element)",
            "    return original_set",
            "",
            "",
            "def is_url_equal(url, other_url):",
            "    # type: (str, str) -> bool",
            "    \"\"\"",
            "    Compare two urls by scheme, host, and path, ignoring auth",
            "",
            "    :param str url: The initial URL to compare",
            "    :param str url: Second url to compare to the first",
            "    :return: Whether the URLs are equal without **auth**, **query**, and **fragment**",
            "    :rtype: bool",
            "",
            "    >>> is_url_equal(\"https://user:pass@mydomain.com/some/path?some_query\",",
            "                     \"https://user2:pass2@mydomain.com/some/path\")",
            "    True",
            "",
            "    >>> is_url_equal(\"https://user:pass@mydomain.com/some/path?some_query\",",
            "                 \"https://mydomain.com/some?some_query\")",
            "    False",
            "    \"\"\"",
            "    if not isinstance(url, str):",
            "        raise TypeError(f\"Expected string for url, received {url!r}\")",
            "    if not isinstance(other_url, str):",
            "        raise TypeError(f\"Expected string for url, received {other_url!r}\")",
            "    parsed_url = urllib3_util.parse_url(url)",
            "    parsed_other_url = urllib3_util.parse_url(other_url)",
            "    unparsed = parsed_url._replace(auth=None, query=None, fragment=None).url",
            "    unparsed_other = parsed_other_url._replace(auth=None, query=None, fragment=None).url",
            "    return unparsed == unparsed_other",
            "",
            "",
            "@lru_cache()",
            "def make_posix(path):",
            "    # type: (str) -> str",
            "    \"\"\"",
            "    Convert a path with possible windows-style separators to a posix-style path",
            "    (with **/** separators instead of **\\\\** separators).",
            "",
            "    :param Text path: A path to convert.",
            "    :return: A converted posix-style path",
            "    :rtype: Text",
            "",
            "    >>> make_posix(\"c:/users/user/venvs/some_venv\\\\Lib\\\\site-packages\")",
            "    \"c:/users/user/venvs/some_venv/Lib/site-packages\"",
            "",
            "    >>> make_posix(\"c:\\\\users\\\\user\\\\venvs\\\\some_venv\")",
            "    \"c:/users/user/venvs/some_venv\"",
            "    \"\"\"",
            "    if not isinstance(path, str):",
            "        raise TypeError(f\"Expected a string for path, received {path!r}...\")",
            "    starts_with_sep = path.startswith(os.path.sep)",
            "    separated = normalize_path(path).split(os.path.sep)",
            "    if isinstance(separated, (list, tuple)):",
            "        path = posixpath.join(*separated)",
            "        if starts_with_sep:",
            "            path = f\"/{path}\"",
            "    return path",
            "",
            "",
            "def get_pipenv_dist(pkg=\"pipenv\", pipenv_site=None):",
            "    from .resolver import find_site_path",
            "    pipenv_libdir = os.path.dirname(os.path.abspath(__file__))",
            "    if pipenv_site is None:",
            "        pipenv_site = os.path.dirname(pipenv_libdir)",
            "    pipenv_dist, _ = find_site_path(pkg, site_dir=pipenv_site)",
            "    return pipenv_dist",
            "",
            "",
            "def find_python(finder, line=None):",
            "    \"\"\"",
            "    Given a `pythonfinder.Finder` instance and an optional line, find a corresponding python",
            "",
            "    :param finder: A :class:`pythonfinder.Finder` instance to use for searching",
            "    :type finder: :class:pythonfinder.Finder`",
            "    :param str line: A version, path, name, or nothing, defaults to None",
            "    :return: A path to python",
            "    :rtype: str",
            "    \"\"\"",
            "",
            "    if line and not isinstance(line, str):",
            "        raise TypeError(",
            "            f\"Invalid python search type: expected string, received {line!r}\"",
            "        )",
            "    if line and os.path.isabs(line):",
            "        if os.name == \"nt\":",
            "            line = make_posix(line)",
            "        return line",
            "    if not finder:",
            "        from pipenv.vendor.pythonfinder import Finder",
            "        finder = Finder(global_search=True)",
            "    if not line:",
            "        result = next(iter(finder.find_all_python_versions()), None)",
            "    elif line and line[0].isdigit() or re.match(r'[\\d\\.]+', line):",
            "        result = finder.find_python_version(line)",
            "    else:",
            "        result = finder.find_python_version(name=line)",
            "    if not result:",
            "        result = finder.which(line)",
            "    if not result and not line.startswith(\"python\"):",
            "        line = f\"python{line}\"",
            "        result = find_python(finder, line)",
            "",
            "    if result:",
            "        if not isinstance(result, str):",
            "            return result.path.as_posix()",
            "        return result",
            "    return",
            "",
            "",
            "def is_python_command(line):",
            "    \"\"\"",
            "    Given an input, checks whether the input is a request for python or notself.",
            "",
            "    This can be a version, a python runtime name, or a generic 'python' or 'pythonX.Y'",
            "",
            "    :param str line: A potential request to find python",
            "    :returns: Whether the line is a python lookup",
            "    :rtype: bool",
            "    \"\"\"",
            "",
            "    if not isinstance(line, str):",
            "        raise TypeError(f\"Not a valid command to check: {line!r}\")",
            "",
            "    from pipenv.vendor.pythonfinder.utils import PYTHON_IMPLEMENTATIONS",
            "    is_version = re.match(r'\\d+(\\.\\d+)*', line)",
            "    if (line.startswith(\"python\") or is_version",
            "            or any(line.startswith(v) for v in PYTHON_IMPLEMENTATIONS)):",
            "        return True",
            "    # we are less sure about this but we can guess",
            "    if line.startswith(\"py\"):",
            "        return True",
            "    return False",
            "",
            "",
            "@contextlib.contextmanager",
            "def interrupt_handled_subprocess(",
            "    cmd, verbose=False, return_object=True, write_to_stdout=False, combine_stderr=True,",
            "    block=True, nospin=True, env=None",
            "):",
            "    \"\"\"Given a :class:`subprocess.Popen` instance, wrap it in exception handlers.",
            "",
            "    Terminates the subprocess when and if a `SystemExit` or `KeyboardInterrupt` are",
            "    processed.",
            "",
            "    Arguments:",
            "        :param str cmd: A command to run",
            "        :param bool verbose: Whether to run with verbose mode enabled, default False",
            "        :param bool return_object: Whether to return a subprocess instance or a 2-tuple, default True",
            "        :param bool write_to_stdout: Whether to write directly to stdout, default False",
            "        :param bool combine_stderr: Whether to combine stdout and stderr, default True",
            "        :param bool block: Whether the subprocess should be a blocking subprocess, default True",
            "        :param bool nospin: Whether to suppress the spinner with the subprocess, default True",
            "        :param Optional[Dict[str, str]] env: A dictionary to merge into the subprocess environment",
            "        :return: A subprocess, wrapped in exception handlers, as a context manager",
            "        :rtype: :class:`subprocess.Popen` obj: An instance of a running subprocess",
            "    \"\"\"",
            "    obj = run(",
            "        cmd, verbose=verbose, return_object=True, write_to_stdout=False,",
            "        combine_stderr=False, block=True, nospin=True, env=env,",
            "    )",
            "    try:",
            "        yield obj",
            "    except (SystemExit, KeyboardInterrupt):",
            "        if os.name == \"nt\":",
            "            os.kill(obj.pid, signal.CTRL_BREAK_EVENT)",
            "        else:",
            "            os.kill(obj.pid, signal.SIGINT)",
            "        obj.wait()",
            "        raise",
            "",
            "",
            "def subprocess_run(",
            "    args, *, block=True, text=True, capture_output=True,",
            "    encoding=\"utf-8\", env=None, **other_kwargs",
            "):",
            "    \"\"\"A backward compatible version of subprocess.run().",
            "",
            "    It outputs text with default encoding, and store all outputs in the returned object instead of",
            "    printing onto stdout.",
            "    \"\"\"",
            "    _env = os.environ.copy()",
            "    _env[\"PYTHONIOENCODING\"] = encoding",
            "    if env:",
            "        _env.update(env)",
            "    other_kwargs[\"env\"] = _env",
            "    if capture_output:",
            "        other_kwargs['stdout'] = subprocess.PIPE",
            "        other_kwargs['stderr'] = subprocess.PIPE",
            "    if block:",
            "        return subprocess.run(",
            "            args, universal_newlines=text,",
            "            encoding=encoding, **other_kwargs",
            "        )",
            "    else:",
            "        return subprocess.Popen(",
            "            args, universal_newlines=text,",
            "            encoding=encoding, **other_kwargs",
            "        )",
            "",
            "",
            "def cmd_list_to_shell(args):",
            "    \"\"\"Convert a list of arguments to a quoted shell command.\"\"\"",
            "    return \" \".join(shlex.quote(str(token)) for token in args)"
        ],
        "afterPatchFile": [
            "import contextlib",
            "import errno",
            "import logging",
            "import os",
            "import posixpath",
            "import re",
            "import shlex",
            "import hashlib",
            "import shutil",
            "import signal",
            "import stat",
            "import subprocess",
            "import sys",
            "import warnings",
            "",
            "from contextlib import contextmanager",
            "from distutils.spawn import find_executable",
            "from pathlib import Path",
            "from urllib.parse import urlparse",
            "",
            "import crayons",
            "import parse",
            "import toml",
            "import tomlkit",
            "",
            "from click import echo as click_echo",
            "",
            "from pipenv import environments",
            "from pipenv.exceptions import (",
            "    PipenvCmdError, PipenvUsageError, RequirementError, ResolutionFailure",
            ")",
            "from pipenv.pep508checker import lookup",
            "from pipenv.vendor.packaging.markers import Marker",
            "from pipenv.vendor.urllib3 import util as urllib3_util",
            "from pipenv.vendor.vistir.compat import (",
            "    Mapping, ResourceWarning, Sequence, Set, TemporaryDirectory, lru_cache",
            ")",
            "from pipenv.vendor.vistir.misc import fs_str, run",
            "from pipenv.vendor.vistir.contextmanagers import open_file",
            "",
            "",
            "if environments.MYPY_RUNNING:",
            "    from typing import Any, Dict, List, Optional, Text, Tuple, Union",
            "",
            "    from pipenv.project import Project, TSource",
            "    from pipenv.vendor.requirementslib.models.pipfile import Pipfile",
            "    from pipenv.vendor.requirementslib.models.requirements import (",
            "        Line, Requirement",
            "    )",
            "",
            "",
            "logging.basicConfig(level=logging.ERROR)",
            "",
            "specifiers = [k for k in lookup.keys()]",
            "# List of version control systems we support.",
            "VCS_LIST = (\"git\", \"svn\", \"hg\", \"bzr\")",
            "SCHEME_LIST = (\"http://\", \"https://\", \"ftp://\", \"ftps://\", \"file://\")",
            "requests_session = None  # type: ignore",
            "",
            "",
            "def _get_requests_session(max_retries=1):",
            "    \"\"\"Load requests lazily.\"\"\"",
            "    global requests_session",
            "    if requests_session is not None:",
            "        return requests_session",
            "    import requests",
            "",
            "    requests_session = requests.Session()",
            "    adapter = requests.adapters.HTTPAdapter(max_retries=max_retries)",
            "    requests_session.mount(\"https://pypi.org/pypi\", adapter)",
            "    return requests_session",
            "",
            "",
            "def cleanup_toml(tml):",
            "    toml = tml.split(\"\\n\")",
            "    new_toml = []",
            "    # Remove all empty lines from TOML.",
            "    for line in toml:",
            "        if line.strip():",
            "            new_toml.append(line)",
            "    toml = \"\\n\".join(new_toml)",
            "    new_toml = []",
            "    # Add newlines between TOML sections.",
            "    for i, line in enumerate(toml.split(\"\\n\")):",
            "        # Skip the first line.",
            "        if line.startswith(\"[\"):",
            "            if i > 0:",
            "                # Insert a newline before the heading.",
            "                new_toml.append(\"\")",
            "        new_toml.append(line)",
            "    # adding new line at the end of the TOML file",
            "    new_toml.append(\"\")",
            "    toml = \"\\n\".join(new_toml)",
            "    return toml",
            "",
            "",
            "def convert_toml_outline_tables(parsed):",
            "    \"\"\"Converts all outline tables to inline tables.\"\"\"",
            "    def convert_tomlkit_table(section):",
            "        if isinstance(section, tomlkit.items.Table):",
            "            body = section.value._body",
            "        else:",
            "            body = section._body",
            "        for key, value in body:",
            "            if not key:",
            "                continue",
            "            if hasattr(value, \"keys\") and not isinstance(value, tomlkit.items.InlineTable):",
            "                table = tomlkit.inline_table()",
            "                table.update(value.value)",
            "                section[key.key] = table",
            "",
            "    def convert_toml_table(section):",
            "        for package, value in section.items():",
            "            if hasattr(value, \"keys\") and not isinstance(value, toml.decoder.InlineTableDict):",
            "                table = toml.TomlDecoder().get_empty_inline_table()",
            "                table.update(value)",
            "                section[package] = table",
            "",
            "    is_tomlkit_parsed = isinstance(parsed, tomlkit.container.Container)",
            "    for section in (\"packages\", \"dev-packages\"):",
            "        table_data = parsed.get(section, {})",
            "        if not table_data:",
            "            continue",
            "        if is_tomlkit_parsed:",
            "            convert_tomlkit_table(table_data)",
            "        else:",
            "            convert_toml_table(table_data)",
            "",
            "    return parsed",
            "",
            "",
            "def run_command(cmd, *args, is_verbose=False, **kwargs):",
            "    \"\"\"",
            "    Take an input command and run it, handling exceptions and error codes and returning",
            "    its stdout and stderr.",
            "",
            "    :param cmd: The list of command and arguments.",
            "    :type cmd: list",
            "    :returns: A 2-tuple of the output and error from the command",
            "    :rtype: Tuple[str, str]",
            "    :raises: exceptions.PipenvCmdError",
            "    \"\"\"",
            "",
            "    from ._compat import decode_for_output",
            "    from .cmdparse import Script",
            "    catch_exceptions = kwargs.pop(\"catch_exceptions\", True)",
            "    if isinstance(cmd, ((str,), list, tuple)):",
            "        cmd = Script.parse(cmd)",
            "    if not isinstance(cmd, Script):",
            "        raise TypeError(\"Command input must be a string, list or tuple\")",
            "    if \"env\" not in kwargs:",
            "        kwargs[\"env\"] = os.environ.copy()",
            "    kwargs[\"env\"][\"PYTHONIOENCODING\"] = \"UTF-8\"",
            "    command = [cmd.command, *cmd.args]",
            "    if is_verbose:",
            "        click_echo(f\"Running command: $ {cmd.cmdify()}\")",
            "    c = subprocess_run(command, *args, **kwargs)",
            "    if is_verbose:",
            "        click_echo(\"Command output: {}\".format(",
            "            crayons.cyan(decode_for_output(c.stdout))",
            "        ), err=True)",
            "    if c.returncode and catch_exceptions:",
            "        raise PipenvCmdError(cmd.cmdify(), c.stdout, c.stderr, c.returncode)",
            "    return c",
            "",
            "",
            "def parse_python_version(output):",
            "    \"\"\"Parse a Python version output returned by `python --version`.",
            "",
            "    Return a dict with three keys: major, minor, and micro. Each value is a",
            "    string containing a version part.",
            "",
            "    Note: The micro part would be `'0'` if it's missing from the input string.",
            "    \"\"\"",
            "    version_line = output.split(\"\\n\", 1)[0]",
            "    version_pattern = re.compile(",
            "        r\"\"\"",
            "        ^                   # Beginning of line.",
            "        Python              # Literally \"Python\".",
            "        \\s                  # Space.",
            "        (?P<major>\\d+)      # Major = one or more digits.",
            "        \\.                  # Dot.",
            "        (?P<minor>\\d+)      # Minor = one or more digits.",
            "        (?:                 # Unnamed group for dot-micro.",
            "            \\.              # Dot.",
            "            (?P<micro>\\d+)  # Micro = one or more digit.",
            "        )?                  # Micro is optional because pypa/pipenv#1893.",
            "        .*                  # Trailing garbage.",
            "        $                   # End of line.",
            "    \"\"\",",
            "        re.VERBOSE,",
            "    )",
            "",
            "    match = version_pattern.match(version_line)",
            "    if not match:",
            "        return None",
            "    return match.groupdict(default=\"0\")",
            "",
            "",
            "def python_version(path_to_python):",
            "    from .vendor.pythonfinder.utils import get_python_version",
            "",
            "    if not path_to_python:",
            "        return None",
            "    try:",
            "        version = get_python_version(path_to_python)",
            "    except Exception:",
            "        return None",
            "    return version",
            "",
            "",
            "def escape_grouped_arguments(s):",
            "    \"\"\"Prepares a string for the shell (on Windows too!)",
            "",
            "    Only for use on grouped arguments (passed as a string to Popen)",
            "    \"\"\"",
            "    if s is None:",
            "        return None",
            "",
            "    # Additional escaping for windows paths",
            "    if os.name == \"nt\":",
            "        s = \"{}\".format(s.replace(\"\\\\\", \"\\\\\\\\\"))",
            "    return '\"' + s.replace(\"'\", \"'\\\\''\") + '\"'",
            "",
            "",
            "def clean_pkg_version(version):",
            "    \"\"\"Uses pip to prepare a package version string, from our internal version.\"\"\"",
            "    return pep440_version(str(version).replace(\"==\", \"\"))",
            "",
            "",
            "class HackedPythonVersion:",
            "    \"\"\"A Beautiful hack, which allows us to tell pip which version of Python we're using.\"\"\"",
            "",
            "    def __init__(self, python_version, python_path):",
            "        self.python_version = python_version",
            "        self.python_path = python_path",
            "",
            "    def __enter__(self):",
            "        # Only inject when the value is valid",
            "        if self.python_version:",
            "            os.environ[\"PIPENV_REQUESTED_PYTHON_VERSION\"] = str(self.python_version)",
            "        if self.python_path:",
            "            os.environ[\"PIP_PYTHON_PATH\"] = str(self.python_path)",
            "",
            "    def __exit__(self, *args):",
            "        # Restore original Python version information.",
            "        try:",
            "            del os.environ[\"PIPENV_REQUESTED_PYTHON_VERSION\"]",
            "        except KeyError:",
            "            pass",
            "",
            "",
            "def prepare_pip_source_args(sources, pip_args=None):",
            "    if pip_args is None:",
            "        pip_args = []",
            "    if sources:",
            "        # Add the source to notpip.",
            "        package_url = sources[0].get(\"url\")",
            "        if not package_url:",
            "            raise PipenvUsageError(\"[[source]] section does not contain a URL.\")",
            "        pip_args.extend([\"-i\", package_url])",
            "        # Trust the host if it's not verified.",
            "        if not sources[0].get(\"verify_ssl\", True):",
            "            url_parts = urllib3_util.parse_url(package_url)",
            "            url_port = f\":{url_parts.port}\" if url_parts.port else \"\"",
            "            pip_args.extend(",
            "                [\"--trusted-host\", f\"{url_parts.host}{url_port}\"]",
            "            )",
            "        # Add additional sources as extra indexes.",
            "        if len(sources) > 1:",
            "            for source in sources[1:]:",
            "                url = source.get(\"url\")",
            "                if not url:  # not harmless, just don't continue",
            "                    continue",
            "                pip_args.extend([\"--extra-index-url\", url])",
            "                # Trust the host if it's not verified.",
            "                if not source.get(\"verify_ssl\", True):",
            "                    url_parts = urllib3_util.parse_url(url)",
            "                    url_port = f\":{url_parts.port}\" if url_parts.port else \"\"",
            "                    pip_args.extend(",
            "                        [\"--trusted-host\", f\"{url_parts.host}{url_port}\"]",
            "                    )",
            "    return pip_args",
            "",
            "",
            "def get_project_index(project, index=None, trusted_hosts=None):",
            "    # type: (Optional[Union[str, TSource]], Optional[List[str]], Optional[Project]) -> TSource",
            "    from .project import SourceNotFound",
            "    if trusted_hosts is None:",
            "        trusted_hosts = []",
            "    if isinstance(index, Mapping):",
            "        return project.find_source(index.get(\"url\"))",
            "    try:",
            "        source = project.find_source(index)",
            "    except SourceNotFound:",
            "        index_url = urllib3_util.parse_url(index)",
            "        src_name = project.src_name_from_url(index)",
            "        verify_ssl = index_url.host not in trusted_hosts",
            "        source = {\"url\": index, \"verify_ssl\": verify_ssl, \"name\": src_name}",
            "    return source",
            "",
            "",
            "def get_source_list(",
            "    project,  # type: Project",
            "    index=None,  # type: Optional[Union[str, TSource]]",
            "    extra_indexes=None,  # type: Optional[List[str]]",
            "    trusted_hosts=None,  # type: Optional[List[str]]",
            "    pypi_mirror=None,  # type: Optional[str]",
            "):",
            "    # type: (...) -> List[TSource]",
            "    sources = []  # type: List[TSource]",
            "    if index:",
            "        sources.append(get_project_index(project, index))",
            "    if extra_indexes:",
            "        if isinstance(extra_indexes, str):",
            "            extra_indexes = [extra_indexes]",
            "        for source in extra_indexes:",
            "            extra_src = get_project_index(project, source)",
            "            if not sources or extra_src[\"url\"] != sources[0][\"url\"]:",
            "                sources.append(extra_src)",
            "        else:",
            "            for source in project.pipfile_sources:",
            "                if not sources or source[\"url\"] != sources[0][\"url\"]:",
            "                    sources.append(source)",
            "    if not sources:",
            "        sources = project.pipfile_sources[:]",
            "    if pypi_mirror:",
            "        sources = [",
            "            create_mirror_source(pypi_mirror) if is_pypi_url(source[\"url\"]) else source",
            "            for source in sources",
            "        ]",
            "    return sources",
            "",
            "",
            "def get_indexes_from_requirement(req, project, index=None, extra_indexes=None, trusted_hosts=None, pypi_mirror=None):",
            "    # type: (Requirement, Project, Optional[Text], Optional[List[Text]], Optional[List[Text]], Optional[Text]) -> Tuple[TSource, List[TSource], List[Text]]",
            "    index_sources = []  # type: List[TSource]",
            "    if not trusted_hosts:",
            "        trusted_hosts = []  # type: List[Text]",
            "    if extra_indexes is None:",
            "        extra_indexes = []",
            "    project_indexes = project.pipfile_sources[:]",
            "    indexes = []",
            "    if req.index:",
            "        indexes.append(req.index)",
            "    if getattr(req, \"extra_indexes\", None):",
            "        if not isinstance(req.extra_indexes, list):",
            "            indexes.append(req.extra_indexes)",
            "        else:",
            "            indexes.extend(req.extra_indexes)",
            "    indexes.extend(project_indexes)",
            "    if len(indexes) > 1:",
            "        index, extra_indexes = indexes[0], indexes[1:]",
            "    index_sources = get_source_list(project, index=index, extra_indexes=extra_indexes, trusted_hosts=trusted_hosts, pypi_mirror=pypi_mirror)",
            "    if len(index_sources) > 1:",
            "        index_source, extra_index_sources = index_sources[0], index_sources[1:]",
            "    else:",
            "        index_source, extra_index_sources = index_sources[0], []",
            "    return index_source, extra_index_sources",
            "",
            "",
            "@lru_cache()",
            "def get_pipenv_sitedir():",
            "    # type: () -> Optional[str]",
            "    import pkg_resources",
            "    site_dir = next(",
            "        iter(d for d in pkg_resources.working_set if d.key.lower() == \"pipenv\"), None",
            "    )",
            "    if site_dir is not None:",
            "        return site_dir.location",
            "    return None",
            "",
            "",
            "class HashCacheMixin:",
            "",
            "    \"\"\"Caches hashes of PyPI artifacts so we do not need to re-download them.",
            "",
            "    Hashes are only cached when the URL appears to contain a hash in it and the",
            "    cache key includes the hash value returned from the server). This ought to",
            "    avoid issues where the location on the server changes.",
            "    \"\"\"",
            "    def __init__(self, directory, session):",
            "        self.session = session",
            "        if not os.path.isdir(directory):",
            "            os.makedirs(directory, exist_ok=True)",
            "        super().__init__(directory=directory)",
            "",
            "    def get_hash(self, link):",
            "        # If there is no link hash (i.e., md5, sha256, etc.), we don't want",
            "        # to store it.",
            "        hash_value = self.get(link.url)",
            "        if not hash_value:",
            "            hash_value = self._get_file_hash(link).encode()",
            "            self.set(link.url, hash_value)",
            "        return hash_value.decode(\"utf8\")",
            "",
            "    def _get_file_hash(self, link):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        h = hashlib.new(shims.FAVORITE_HASH)",
            "        with open_file(link.url, self.session) as fp:",
            "            for chunk in iter(lambda: fp.read(8096), b\"\"):",
            "                h.update(chunk)",
            "        return \":\".join([h.name, h.hexdigest()])",
            "",
            "",
            "class Resolver:",
            "    def __init__(",
            "        self, constraints, req_dir, project, sources, index_lookup=None,",
            "        markers_lookup=None, skipped=None, clear=False, pre=False",
            "    ):",
            "        self.initial_constraints = constraints",
            "        self.req_dir = req_dir",
            "        self.project = project",
            "        self.sources = sources",
            "        self.resolved_tree = set()",
            "        self.hashes = {}",
            "        self.clear = clear",
            "        self.pre = pre",
            "        self.results = None",
            "        self.markers_lookup = markers_lookup if markers_lookup is not None else {}",
            "        self.index_lookup = index_lookup if index_lookup is not None else {}",
            "        self.skipped = skipped if skipped is not None else {}",
            "        self.markers = {}",
            "        self.requires_python_markers = {}",
            "        self._pip_args = None",
            "        self._constraints = None",
            "        self._parsed_constraints = None",
            "        self._resolver = None",
            "        self._finder = None",
            "        self._ignore_compatibility_finder = None",
            "        self._session = None",
            "        self._constraint_file = None",
            "        self._pip_options = None",
            "        self._pip_command = None",
            "        self._retry_attempts = 0",
            "        self._hash_cache = None",
            "",
            "    def __repr__(self):",
            "        return (",
            "            \"<Resolver (constraints={self.initial_constraints}, req_dir={self.req_dir}, \"",
            "            \"sources={self.sources})>\".format(self=self)",
            "        )",
            "",
            "    @staticmethod",
            "    @lru_cache()",
            "    def _get_pip_command():",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        return shims.InstallCommand()",
            "",
            "    @property",
            "    def hash_cache(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        if not self._hash_cache:",
            "            self._hash_cache = type(\"HashCache\", (HashCacheMixin, shims.SafeFileCache), {})(",
            "                os.path.join(self.project.s.PIPENV_CACHE_DIR, \"hashes\"), self.session",
            "            )",
            "        return self._hash_cache",
            "",
            "    @classmethod",
            "    def get_metadata(",
            "        cls,",
            "        deps,  # type: List[str]",
            "        index_lookup,  # type: Dict[str, str]",
            "        markers_lookup,  # type: Dict[str, str]",
            "        project,  # type: Project",
            "        sources,  # type: Dict[str, str]",
            "        req_dir=None,  # type: Optional[str]",
            "        pre=False,  # type: bool",
            "        clear=False,  # type: bool",
            "    ):",
            "        # type: (...) -> Tuple[Set[str], Dict[str, Dict[str, Union[str, bool, List[str]]]], Dict[str, str], Dict[str, str]]",
            "        constraints = set()  # type: Set[str]",
            "        skipped = dict()  # type: Dict[str, Dict[str, Union[str, bool, List[str]]]]",
            "        if index_lookup is None:",
            "            index_lookup = {}",
            "        if markers_lookup is None:",
            "            markers_lookup = {}",
            "        if not req_dir:",
            "            from .vendor.vistir.path import create_tracked_tempdir",
            "            req_dir = create_tracked_tempdir(prefix=\"pipenv-\", suffix=\"-reqdir\")",
            "        transient_resolver = cls(",
            "            [], req_dir, project, sources, index_lookup=index_lookup,",
            "            markers_lookup=markers_lookup, clear=clear, pre=pre",
            "        )",
            "        for dep in deps:",
            "            if not dep:",
            "                continue",
            "            req, req_idx, markers_idx = cls.parse_line(",
            "                dep, index_lookup=index_lookup, markers_lookup=markers_lookup, project=project",
            "            )",
            "            index_lookup.update(req_idx)",
            "            markers_lookup.update(markers_idx)",
            "            # Add dependencies of any file (e.g. wheels/tarballs), source, or local",
            "            # directories into the initial constraint pool to be resolved with the",
            "            # rest of the dependencies, while adding the files/vcs deps/paths themselves",
            "            # to the lockfile directly",
            "            constraint_update, lockfile_update = cls.get_deps_from_req(",
            "                req, resolver=transient_resolver, resolve_vcs=project.s.PIPENV_RESOLVE_VCS",
            "            )",
            "            constraints |= constraint_update",
            "            skipped.update(lockfile_update)",
            "        return constraints, skipped, index_lookup, markers_lookup",
            "",
            "    @classmethod",
            "    def parse_line(",
            "        cls,",
            "        line,  # type: str",
            "        index_lookup=None,  # type: Dict[str, str]",
            "        markers_lookup=None,  # type: Dict[str, str]",
            "        project=None  # type: Optional[Project]",
            "    ):",
            "        # type: (...) -> Tuple[Requirement, Dict[str, str], Dict[str, str]]",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "        from .vendor.requirementslib.models.utils import DIRECT_URL_RE",
            "        if index_lookup is None:",
            "            index_lookup = {}",
            "        if markers_lookup is None:",
            "            markers_lookup = {}",
            "        if project is None:",
            "            from .project import Project",
            "            project = Project()",
            "        index, extra_index, trust_host, remainder = parse_indexes(line)",
            "        line = \" \".join(remainder)",
            "        req = None  # type: Requirement",
            "        try:",
            "            req = Requirement.from_line(line)",
            "        except ValueError:",
            "            direct_url = DIRECT_URL_RE.match(line)",
            "            if direct_url:",
            "                line = \"{}#egg={}\".format(line, direct_url.groupdict()[\"name\"])",
            "                try:",
            "                    req = Requirement.from_line(line)",
            "                except ValueError:",
            "                    raise ResolutionFailure(f\"Failed to resolve requirement from line: {line!s}\")",
            "            else:",
            "                raise ResolutionFailure(f\"Failed to resolve requirement from line: {line!s}\")",
            "        if index:",
            "            try:",
            "                index_lookup[req.normalized_name] = project.get_source(",
            "                    url=index, refresh=True).get(\"name\")",
            "            except TypeError:",
            "                pass",
            "        try:",
            "            req.normalized_name",
            "        except TypeError:",
            "            raise RequirementError(req=req)",
            "        # strip the marker and re-add it later after resolution",
            "        # but we will need a fallback in case resolution fails",
            "        # eg pypiwin32",
            "        if req.markers:",
            "            markers_lookup[req.normalized_name] = req.markers.replace('\"', \"'\")",
            "        return req, index_lookup, markers_lookup",
            "",
            "    @classmethod",
            "    def get_deps_from_req(cls, req, resolver=None, resolve_vcs=True):",
            "        # type: (Requirement, Optional[\"Resolver\"], bool) -> Tuple[Set[str], Dict[str, Dict[str, Union[str, bool, List[str]]]]]",
            "        from .vendor.requirementslib.models.requirements import Requirement",
            "        from .vendor.requirementslib.models.utils import (",
            "            _requirement_to_str_lowercase_name",
            "        )",
            "        from .vendor.requirementslib.utils import is_installable_dir",
            "",
            "        # TODO: this is way too complex, refactor this",
            "        constraints = set()  # type: Set[str]",
            "        locked_deps = dict()  # type: Dict[str, Dict[str, Union[str, bool, List[str]]]]",
            "        if (req.is_file_or_url or req.is_vcs) and not req.is_wheel:",
            "            # for local packages with setup.py files and potential direct url deps:",
            "            if req.is_vcs:",
            "                req_list, lockfile = get_vcs_deps(reqs=[req])",
            "                req = next(iter(req for req in req_list if req is not None), req_list)",
            "                entry = lockfile[pep423_name(req.normalized_name)]",
            "            else:",
            "                _, entry = req.pipfile_entry",
            "            parsed_line = req.req.parsed_line  # type: Line",
            "            setup_info = None  # type: Any",
            "            try:",
            "                name = req.normalized_name",
            "            except TypeError:",
            "                raise RequirementError(req=req)",
            "            setup_info = req.req.setup_info",
            "            setup_info.get_info()",
            "            locked_deps[pep423_name(name)] = entry",
            "            requirements = []",
            "            # Allow users to toggle resolution off for non-editable VCS packages",
            "            # but leave it on for local, installable folders on the filesystem",
            "            if resolve_vcs or (",
            "                req.editable or parsed_line.is_wheel or (",
            "                    req.is_file_or_url and parsed_line.is_local",
            "                    and is_installable_dir(parsed_line.path)",
            "                )",
            "            ):",
            "                requirements = [v for v in getattr(setup_info, \"requires\", {}).values()]",
            "            for r in requirements:",
            "                if getattr(r, \"url\", None) and not getattr(r, \"editable\", False):",
            "                    if r is not None:",
            "                        if not r.url:",
            "                            continue",
            "                        line = _requirement_to_str_lowercase_name(r)",
            "                        new_req, _, _ = cls.parse_line(line)",
            "                        if r.marker and not r.marker.evaluate():",
            "                            new_constraints = {}",
            "                            _, new_entry = req.pipfile_entry",
            "                            new_lock = {",
            "                                pep423_name(new_req.normalized_name): new_entry",
            "                            }",
            "                        else:",
            "                            new_constraints, new_lock = cls.get_deps_from_req(",
            "                                new_req, resolver",
            "                            )",
            "                        locked_deps.update(new_lock)",
            "                        constraints |= new_constraints",
            "                # if there is no marker or there is a valid marker, add the constraint line",
            "                elif r and (not r.marker or (r.marker and r.marker.evaluate())):",
            "                    line = _requirement_to_str_lowercase_name(r)",
            "                    constraints.add(line)",
            "            # ensure the top level entry remains as provided",
            "            # note that we shouldn't pin versions for editable vcs deps",
            "            if not req.is_vcs:",
            "                if req.specifiers:",
            "                    locked_deps[name][\"version\"] = req.specifiers",
            "                elif parsed_line.setup_info and parsed_line.setup_info.version:",
            "                    locked_deps[name][\"version\"] = \"=={}\".format(",
            "                        parsed_line.setup_info.version",
            "                    )",
            "            # if not req.is_vcs:",
            "            locked_deps.update({name: entry})",
            "        else:",
            "            # if the dependency isn't installable, don't add it to constraints",
            "            # and instead add it directly to the lock",
            "            if req and req.requirement and (",
            "                req.requirement.marker and not req.requirement.marker.evaluate()",
            "            ):",
            "                pypi = resolver.finder if resolver else None",
            "                ireq = req.ireq",
            "                best_match = pypi.find_best_candidate(ireq.name, ireq.specifier).best_candidate if pypi else None",
            "                if best_match:",
            "                    ireq.req.specifier = ireq.specifier.__class__(f\"=={best_match.version}\")",
            "                    hashes = resolver.collect_hashes(ireq) if resolver else []",
            "                    new_req = Requirement.from_ireq(ireq)",
            "                    new_req = new_req.add_hashes(hashes)",
            "                    name, entry = new_req.pipfile_entry",
            "                    locked_deps[pep423_name(name)] = translate_markers(entry)",
            "                    click_echo(",
            "                        \"{} doesn't match your environment, \"",
            "                        \"its dependencies won't be resolved.\".format(req.as_line()),",
            "                        err=True",
            "                    )",
            "                else:",
            "                    click_echo(",
            "                        \"Could not find a version of {} that matches your environment, \"",
            "                        \"it will be skipped.\".format(req.as_line()),",
            "                        err=True",
            "                    )",
            "                return constraints, locked_deps",
            "            constraints.add(req.constraint_line)",
            "            return constraints, locked_deps",
            "        return constraints, locked_deps",
            "",
            "    @classmethod",
            "    def create(",
            "        cls,",
            "        deps,  # type: List[str]",
            "        project,  # type: Project",
            "        index_lookup=None,  # type: Dict[str, str]",
            "        markers_lookup=None,  # type: Dict[str, str]",
            "        sources=None,  # type: List[str]",
            "        req_dir=None,  # type: str",
            "        clear=False,  # type: bool",
            "        pre=False  # type: bool",
            "    ):",
            "        # type: (...) -> \"Resolver\"",
            "        from pipenv.vendor.vistir.path import create_tracked_tempdir",
            "        if not req_dir:",
            "            req_dir = create_tracked_tempdir(suffix=\"-requirements\", prefix=\"pipenv-\")",
            "        if index_lookup is None:",
            "            index_lookup = {}",
            "        if markers_lookup is None:",
            "            markers_lookup = {}",
            "        if sources is None:",
            "            sources = project.sources",
            "        constraints, skipped, index_lookup, markers_lookup = cls.get_metadata(",
            "            deps, index_lookup, markers_lookup, project, sources, req_dir=req_dir,",
            "            pre=pre, clear=clear",
            "        )",
            "        return Resolver(",
            "            constraints, req_dir, project, sources, index_lookup=index_lookup,",
            "            markers_lookup=markers_lookup, skipped=skipped, clear=clear, pre=pre",
            "        )",
            "",
            "    @classmethod",
            "    def from_pipfile(cls, project, pipfile=None, dev=False, pre=False, clear=False):",
            "        # type: (Optional[Project], Optional[Pipfile], bool, bool, bool) -> \"Resolver\"",
            "        from pipenv.vendor.vistir.path import create_tracked_tempdir",
            "        if not pipfile:",
            "            pipfile = project._pipfile",
            "        req_dir = create_tracked_tempdir(suffix=\"-requirements\", prefix=\"pipenv-\")",
            "        index_lookup, markers_lookup = {}, {}",
            "        deps = set()",
            "        if dev:",
            "            deps.update({req.as_line() for req in pipfile.dev_packages})",
            "        deps.update({req.as_line() for req in pipfile.packages})",
            "        constraints, skipped, index_lookup, markers_lookup = cls.get_metadata(",
            "            list(deps), index_lookup, markers_lookup, project, project.sources,",
            "            req_dir=req_dir, pre=pre, clear=clear",
            "        )",
            "        return Resolver(",
            "            constraints, req_dir, project, project.sources, index_lookup=index_lookup,",
            "            markers_lookup=markers_lookup, skipped=skipped, clear=clear, pre=pre",
            "        )",
            "",
            "    @property",
            "    def pip_command(self):",
            "        if self._pip_command is None:",
            "            self._pip_command = self._get_pip_command()",
            "        return self._pip_command",
            "",
            "    def prepare_pip_args(self, use_pep517=None, build_isolation=True):",
            "        pip_args = []",
            "        if self.sources:",
            "            pip_args = prepare_pip_source_args(self.sources, pip_args)",
            "        if use_pep517 is False:",
            "            pip_args.append(\"--no-use-pep517\")",
            "        if build_isolation is False:",
            "            pip_args.append(\"--no-build-isolation\")",
            "        if self.pre:",
            "            pip_args.append(\"--pre\")",
            "        pip_args.extend([\"--cache-dir\", self.project.s.PIPENV_CACHE_DIR])",
            "        return pip_args",
            "",
            "    @property",
            "    def pip_args(self):",
            "        use_pep517 = environments.get_from_env(\"USE_PEP517\", prefix=\"PIP\")",
            "        build_isolation = environments.get_from_env(\"BUILD_ISOLATION\", prefix=\"PIP\")",
            "        if self._pip_args is None:",
            "            self._pip_args = self.prepare_pip_args(",
            "                use_pep517=use_pep517, build_isolation=build_isolation",
            "            )",
            "        return self._pip_args",
            "",
            "    def prepare_constraint_file(self):",
            "        from pipenv.vendor.vistir.path import create_tracked_tempfile",
            "        constraints_file = create_tracked_tempfile(",
            "            mode=\"w\",",
            "            prefix=\"pipenv-\",",
            "            suffix=\"-constraints.txt\",",
            "            dir=self.req_dir,",
            "            delete=False,",
            "        )",
            "        skip_args = (\"build-isolation\", \"use-pep517\", \"cache-dir\")",
            "        args_to_add = [",
            "            arg for arg in self.pip_args",
            "            if not any(bad_arg in arg for bad_arg in skip_args)",
            "        ]",
            "        if self.sources:",
            "            requirementstxt_sources = \" \".join(args_to_add) if args_to_add else \"\"",
            "            requirementstxt_sources = requirementstxt_sources.replace(\" --\", \"\\n--\")",
            "            constraints_file.write(f\"{requirementstxt_sources}\\n\")",
            "        constraints = self.initial_constraints",
            "        constraints_file.write(\"\\n\".join([c for c in constraints]))",
            "        constraints_file.close()",
            "        return constraints_file.name",
            "",
            "    @property",
            "    def constraint_file(self):",
            "        if self._constraint_file is None:",
            "            self._constraint_file = self.prepare_constraint_file()",
            "        return self._constraint_file",
            "",
            "    @property",
            "    def pip_options(self):",
            "        if self._pip_options is None:",
            "            pip_options, _ = self.pip_command.parser.parse_args(self.pip_args)",
            "            pip_options.cache_dir = self.project.s.PIPENV_CACHE_DIR",
            "            pip_options.no_python_version_warning = True",
            "            pip_options.no_input = True",
            "            pip_options.progress_bar = \"off\"",
            "            pip_options.ignore_requires_python = True",
            "            pip_options.pre = self.pre or self.project.settings.get(\"allow_prereleases\", False)",
            "            self._pip_options = pip_options",
            "        return self._pip_options",
            "",
            "    @property",
            "    def session(self):",
            "        if self._session is None:",
            "            self._session = self.pip_command._build_session(self.pip_options)",
            "        return self._session",
            "",
            "    @property",
            "    def finder(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "        if self._finder is None:",
            "            self._finder = shims.get_package_finder(",
            "                install_cmd=self.pip_command,",
            "                options=self.pip_options,",
            "                session=self.session",
            "            )",
            "        return self._finder",
            "",
            "    @property",
            "    def ignore_compatibility_finder(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "        if self._ignore_compatibility_finder is None:",
            "            ignore_compatibility_finder = shims.get_package_finder(",
            "                install_cmd=self.pip_command,",
            "                options=self.pip_options,",
            "                session=self.session,",
            "            )",
            "            # It would be nice if `shims.get_package_finder` took an",
            "            # `ignore_compatibility` parameter, but that's some vendorered code",
            "            # we'd rather avoid touching.",
            "            ignore_compatibility_finder._ignore_compatibility = True",
            "            self._ignore_compatibility_finder = ignore_compatibility_finder",
            "        return self._ignore_compatibility_finder",
            "",
            "    @property",
            "    def parsed_constraints(self):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        if self._parsed_constraints is None:",
            "            self._parsed_constraints = shims.parse_requirements(",
            "                self.constraint_file, finder=self.finder, session=self.session,",
            "                options=self.pip_options",
            "            )",
            "        return self._parsed_constraints",
            "",
            "    @property",
            "    def constraints(self):",
            "        from pipenv.patched.notpip._internal.req.constructors import install_req_from_parsed_requirement",
            "",
            "        if self._constraints is None:",
            "            self._constraints = [",
            "                install_req_from_parsed_requirement(",
            "                    c, isolated=self.pip_options.build_isolation,",
            "                    use_pep517=self.pip_options.use_pep517, user_supplied=True",
            "                )",
            "                for c in self.parsed_constraints",
            "            ]",
            "        return self._constraints",
            "",
            "    @contextlib.contextmanager",
            "    def get_resolver(self, clear=False):",
            "        from pipenv.vendor.pip_shims.shims import (",
            "            WheelCache, get_requirement_tracker, global_tempdir_manager",
            "        )",
            "",
            "        with global_tempdir_manager(), get_requirement_tracker() as req_tracker, TemporaryDirectory(suffix=\"-build\", prefix=\"pipenv-\") as directory:",
            "            pip_options = self.pip_options",
            "            finder = self.finder",
            "            wheel_cache = WheelCache(pip_options.cache_dir, pip_options.format_control)",
            "            directory.path = directory.name",
            "            preparer = self.pip_command.make_requirement_preparer(",
            "                temp_build_dir=directory,",
            "                options=pip_options,",
            "                req_tracker=req_tracker,",
            "                session=self.session,",
            "                finder=finder,",
            "                use_user_site=False,",
            "            )",
            "            resolver = self.pip_command.make_resolver(",
            "                preparer=preparer,",
            "                finder=finder,",
            "                options=pip_options,",
            "                wheel_cache=wheel_cache,",
            "                use_user_site=False,",
            "                ignore_installed=True,",
            "                ignore_requires_python=pip_options.ignore_requires_python,",
            "                force_reinstall=pip_options.force_reinstall,",
            "                upgrade_strategy=\"to-satisfy-only\",",
            "                use_pep517=pip_options.use_pep517,",
            "            )",
            "            yield resolver",
            "",
            "    def resolve(self):",
            "        from pipenv.vendor.pip_shims.shims import InstallationError",
            "        from pipenv.exceptions import ResolutionFailure",
            "",
            "        with temp_environ(), self.get_resolver() as resolver:",
            "            try:",
            "                results = resolver.resolve(self.constraints, check_supported_wheels=False)",
            "            except InstallationError as e:",
            "                raise ResolutionFailure(message=str(e))",
            "            else:",
            "                self.results = set(results.all_requirements)",
            "                self.resolved_tree.update(self.results)",
            "        return self.resolved_tree",
            "",
            "    def resolve_constraints(self):",
            "        from .vendor.requirementslib.models.markers import marker_from_specifier",
            "        new_tree = set()",
            "        for result in self.resolved_tree:",
            "            if result.markers:",
            "                self.markers[result.name] = result.markers",
            "            else:",
            "                candidate = self.finder.find_best_candidate(result.name, result.specifier).best_candidate",
            "                if candidate:",
            "                    requires_python = candidate.link.requires_python",
            "                    if requires_python:",
            "                        marker = marker_from_specifier(requires_python)",
            "                        self.markers[result.name] = marker",
            "                        result.markers = marker",
            "                        if result.req:",
            "                            result.req.marker = marker",
            "            new_tree.add(result)",
            "        self.resolved_tree = new_tree",
            "",
            "    @classmethod",
            "    def prepend_hash_types(cls, checksums, hash_type):",
            "        cleaned_checksums = set()",
            "        for checksum in checksums:",
            "            if not checksum:",
            "                continue",
            "            if not checksum.startswith(f\"{hash_type}:\"):",
            "                checksum = f\"{hash_type}:{checksum}\"",
            "            cleaned_checksums.add(checksum)",
            "        return cleaned_checksums",
            "",
            "    def _get_hashes_from_pypi(self, ireq):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        pkg_url = f\"https://pypi.org/pypi/{ireq.name}/json\"",
            "        session = _get_requests_session(self.project.s.PIPENV_MAX_RETRIES)",
            "        try:",
            "            collected_hashes = set()",
            "            # Grab the hashes from the new warehouse API.",
            "            r = session.get(pkg_url, timeout=10)",
            "            api_releases = r.json()[\"releases\"]",
            "            cleaned_releases = {}",
            "            for api_version, api_info in api_releases.items():",
            "                api_version = clean_pkg_version(api_version)",
            "                cleaned_releases[api_version] = api_info",
            "            version = \"\"",
            "            if ireq.specifier:",
            "                spec = next(iter(s for s in ireq.specifier), None)",
            "                if spec:",
            "                    version = spec.version",
            "            for release in cleaned_releases[version]:",
            "                collected_hashes.add(release[\"digests\"][shims.FAVORITE_HASH])",
            "            return self.prepend_hash_types(collected_hashes, shims.FAVORITE_HASH)",
            "        except (ValueError, KeyError, ConnectionError):",
            "            if self.project.s.is_verbose():",
            "                click_echo(",
            "                    \"{}: Error generating hash for {}\".format(",
            "                        crayons.red(\"Warning\", bold=True), ireq.name",
            "                    ), err=True",
            "                )",
            "            return None",
            "",
            "    def collect_hashes(self, ireq):",
            "        if ireq.link:",
            "            link = ireq.link",
            "            if link.is_vcs or (link.is_file and link.is_existing_dir()):",
            "                return set()",
            "            if ireq.original_link:",
            "                return {self._get_hash_from_link(ireq.original_link)}",
            "",
            "        if not is_pinned_requirement(ireq):",
            "            return set()",
            "",
            "        if any(",
            "            \"python.org\" in source[\"url\"] or \"pypi.org\" in source[\"url\"]",
            "            for source in self.sources",
            "        ):",
            "            hashes = self._get_hashes_from_pypi(ireq)",
            "            if hashes:",
            "                return hashes",
            "",
            "        applicable_candidates = self.ignore_compatibility_finder.find_best_candidate(",
            "            ireq.name, ireq.specifier",
            "        ).iter_applicable()",
            "        return {",
            "            self._get_hash_from_link(candidate.link)",
            "            for candidate in applicable_candidates",
            "        }",
            "",
            "    def resolve_hashes(self):",
            "        if self.results is not None:",
            "            for ireq in self.results:",
            "                self.hashes[ireq] = self.collect_hashes(ireq)",
            "        return self.hashes",
            "",
            "    def _get_hash_from_link(self, link):",
            "        from pipenv.vendor.pip_shims import shims",
            "",
            "        if link.hash and link.hash_name == shims.FAVORITE_HASH:",
            "            return f\"{link.hash_name}:{link.hash}\"",
            "",
            "        return self.hash_cache.get_hash(link)",
            "",
            "    def _clean_skipped_result(self, req, value):",
            "        ref = None",
            "        if req.is_vcs:",
            "            ref = req.commit_hash",
            "        ireq = req.as_ireq()",
            "        entry = value.copy()",
            "        entry[\"name\"] = req.name",
            "        if entry.get(\"editable\", False) and entry.get(\"version\"):",
            "            del entry[\"version\"]",
            "        ref = ref if ref is not None else entry.get(\"ref\")",
            "        if ref:",
            "            entry[\"ref\"] = ref",
            "        collected_hashes = self.collect_hashes(ireq)",
            "        if collected_hashes:",
            "            entry[\"hashes\"] = sorted(set(collected_hashes))",
            "        return req.name, entry",
            "",
            "    def clean_results(self):",
            "        from pipenv.vendor.requirementslib.models.requirements import (",
            "            Requirement",
            "        )",
            "        reqs = [(Requirement.from_ireq(ireq), ireq) for ireq in self.resolved_tree]",
            "        results = {}",
            "        for req, ireq in reqs:",
            "            if (req.vcs and req.editable and not req.is_direct_url):",
            "                continue",
            "            elif req.normalized_name in self.skipped.keys():",
            "                continue",
            "            collected_hashes = self.hashes.get(ireq, set())",
            "            req = req.add_hashes(collected_hashes)",
            "            if collected_hashes:",
            "                collected_hashes = sorted(collected_hashes)",
            "            name, entry = format_requirement_for_lockfile(",
            "                req, self.markers_lookup, self.index_lookup, collected_hashes",
            "            )",
            "            entry = translate_markers(entry)",
            "            if name in results:",
            "                results[name].update(entry)",
            "            else:",
            "                results[name] = entry",
            "        for k in list(self.skipped.keys()):",
            "            req = Requirement.from_pipfile(k, self.skipped[k])",
            "            name, entry = self._clean_skipped_result(req, self.skipped[k])",
            "            entry = translate_markers(entry)",
            "            if name in results:",
            "                results[name].update(entry)",
            "            else:",
            "                results[name] = entry",
            "        results = list(results.values())",
            "        return results",
            "",
            "",
            "def format_requirement_for_lockfile(req, markers_lookup, index_lookup, hashes=None):",
            "    if req.specifiers:",
            "        version = str(req.get_version())",
            "    else:",
            "        version = None",
            "    index = index_lookup.get(req.normalized_name)",
            "    markers = markers_lookup.get(req.normalized_name)",
            "    req.index = index",
            "    name, pf_entry = req.pipfile_entry",
            "    name = pep423_name(req.name)",
            "    entry = {}",
            "    if isinstance(pf_entry, str):",
            "        entry[\"version\"] = pf_entry.lstrip(\"=\")",
            "    else:",
            "        entry.update(pf_entry)",
            "        if version is not None and not req.is_vcs:",
            "            entry[\"version\"] = version",
            "        if req.line_instance.is_direct_url and not req.is_vcs:",
            "            entry[\"file\"] = req.req.uri",
            "    if hashes:",
            "        entry[\"hashes\"] = sorted(set(hashes))",
            "    entry[\"name\"] = name",
            "    if index:",
            "        entry.update({\"index\": index})",
            "    if markers:",
            "        entry.update({\"markers\": markers})",
            "    entry = translate_markers(entry)",
            "    if req.vcs or req.editable:",
            "        for key in (\"index\", \"version\", \"file\"):",
            "            try:",
            "                del entry[key]",
            "            except KeyError:",
            "                pass",
            "    return name, entry",
            "",
            "",
            "def _show_warning(message, category, filename, lineno, line):",
            "    warnings.showwarning(message=message, category=category, filename=filename,",
            "                         lineno=lineno, file=sys.stderr, line=line)",
            "    sys.stderr.flush()",
            "",
            "",
            "def actually_resolve_deps(",
            "    deps,",
            "    index_lookup,",
            "    markers_lookup,",
            "    project,",
            "    sources,",
            "    clear,",
            "    pre,",
            "    req_dir=None,",
            "):",
            "    from pipenv.vendor.vistir.path import create_tracked_tempdir",
            "",
            "    if not req_dir:",
            "        req_dir = create_tracked_tempdir(suffix=\"-requirements\", prefix=\"pipenv-\")",
            "    warning_list = []",
            "",
            "    with warnings.catch_warnings(record=True) as warning_list:",
            "        resolver = Resolver.create(",
            "            deps, project, index_lookup, markers_lookup, sources, req_dir, clear, pre",
            "        )",
            "        resolver.resolve()",
            "        hashes = resolver.resolve_hashes()",
            "        resolver.resolve_constraints()",
            "        results = resolver.clean_results()",
            "    for warning in warning_list:",
            "        _show_warning(warning.message, warning.category, warning.filename, warning.lineno,",
            "                      warning.line)",
            "    return (results, hashes, resolver.markers_lookup, resolver, resolver.skipped)",
            "",
            "",
            "@contextlib.contextmanager",
            "def create_spinner(text, setting, nospin=None, spinner_name=None):",
            "    from .vendor.vistir import spin",
            "    from .vendor.vistir.misc import fs_str",
            "    if not spinner_name:",
            "        spinner_name = setting.PIPENV_SPINNER",
            "    if nospin is None:",
            "        nospin = setting.PIPENV_NOSPIN",
            "    with spin.create_spinner(",
            "        spinner_name=spinner_name,",
            "        start_text=fs_str(text),",
            "        nospin=nospin, write_to_stdout=False",
            "    ) as sp:",
            "        yield sp",
            "",
            "",
            "def resolve(cmd, sp, project):",
            "    from ._compat import decode_output",
            "    from .cmdparse import Script",
            "    from .vendor.vistir.misc import echo",
            "    c = subprocess_run(Script.parse(cmd).cmd_args, block=False, env=os.environ.copy())",
            "    is_verbose = project.s.is_verbose()",
            "    err = \"\"",
            "    for line in iter(c.stderr.readline, \"\"):",
            "        line = decode_output(line)",
            "        if not line.rstrip():",
            "            continue",
            "        err += line",
            "        if is_verbose:",
            "            sp.hide_and_write(line.rstrip())",
            "",
            "    c.wait()",
            "    returncode = c.poll()",
            "    out = c.stdout.read()",
            "    if returncode != 0:",
            "        sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(",
            "            \"Locking Failed!\"",
            "        ))",
            "        echo(out.strip(), err=True)",
            "        if not is_verbose:",
            "            echo(err, err=True)",
            "        sys.exit(returncode)",
            "    if is_verbose:",
            "        echo(out.strip(), err=True)",
            "    return subprocess.CompletedProcess(c.args, returncode, out, err)",
            "",
            "",
            "def get_locked_dep(dep, pipfile_section, prefer_pipfile=True):",
            "    # the prefer pipfile flag is not used yet, but we are introducing",
            "    # it now for development purposes",
            "    # TODO: Is this implementation clear? How can it be improved?",
            "    entry = None",
            "    cleaner_kwargs = {",
            "        \"is_top_level\": False,",
            "        \"pipfile_entry\": None",
            "    }",
            "    if isinstance(dep, Mapping) and dep.get(\"name\", \"\"):",
            "        dep_name = pep423_name(dep[\"name\"])",
            "        name = next(iter(",
            "            k for k in pipfile_section.keys()",
            "            if pep423_name(k) == dep_name",
            "        ), None)",
            "        entry = pipfile_section[name] if name else None",
            "",
            "    if entry:",
            "        cleaner_kwargs.update({\"is_top_level\": True, \"pipfile_entry\": entry})",
            "    lockfile_entry = clean_resolved_dep(dep, **cleaner_kwargs)",
            "    if entry and isinstance(entry, Mapping):",
            "        version = entry.get(\"version\", \"\") if entry else \"\"",
            "    else:",
            "        version = entry if entry else \"\"",
            "    lockfile_name, lockfile_dict = lockfile_entry.copy().popitem()",
            "    lockfile_version = lockfile_dict.get(\"version\", \"\")",
            "    # Keep pins from the lockfile",
            "    if prefer_pipfile and lockfile_version != version and version.startswith(\"==\") and \"*\" not in version:",
            "        lockfile_dict[\"version\"] = version",
            "    lockfile_entry[lockfile_name] = lockfile_dict",
            "    return lockfile_entry",
            "",
            "",
            "def prepare_lockfile(results, pipfile, lockfile):",
            "    # from .vendor.requirementslib.utils import is_vcs",
            "    for dep in results:",
            "        if not dep:",
            "            continue",
            "        # Merge in any relevant information from the pipfile entry, including",
            "        # markers, normalized names, URL info, etc that we may have dropped during lock",
            "        # if not is_vcs(dep):",
            "        lockfile_entry = get_locked_dep(dep, pipfile)",
            "        name = next(iter(k for k in lockfile_entry.keys()))",
            "        current_entry = lockfile.get(name)",
            "        if current_entry:",
            "            if not isinstance(current_entry, Mapping):",
            "                lockfile[name] = lockfile_entry[name]",
            "            else:",
            "                lockfile[name].update(lockfile_entry[name])",
            "                lockfile[name] = translate_markers(lockfile[name])",
            "        else:",
            "            lockfile[name] = lockfile_entry[name]",
            "    return lockfile",
            "",
            "",
            "def venv_resolve_deps(",
            "    deps,",
            "    which,",
            "    project,",
            "    pre=False,",
            "    clear=False,",
            "    allow_global=False,",
            "    pypi_mirror=None,",
            "    dev=False,",
            "    pipfile=None,",
            "    lockfile=None,",
            "    keep_outdated=False",
            "):",
            "    \"\"\"",
            "    Resolve dependencies for a pipenv project, acts as a portal to the target environment.",
            "",
            "    Regardless of whether a virtual environment is present or not, this will spawn",
            "    a subproces which is isolated to the target environment and which will perform",
            "    dependency resolution.  This function reads the output of that call and mutates",
            "    the provided lockfile accordingly, returning nothing.",
            "",
            "    :param List[:class:`~requirementslib.Requirement`] deps: A list of dependencies to resolve.",
            "    :param Callable which: [description]",
            "    :param project: The pipenv Project instance to use during resolution",
            "    :param Optional[bool] pre: Whether to resolve pre-release candidates, defaults to False",
            "    :param Optional[bool] clear: Whether to clear the cache during resolution, defaults to False",
            "    :param Optional[bool] allow_global: Whether to use *sys.executable* as the python binary, defaults to False",
            "    :param Optional[str] pypi_mirror: A URL to substitute any time *pypi.org* is encountered, defaults to None",
            "    :param Optional[bool] dev: Whether to target *dev-packages* or not, defaults to False",
            "    :param pipfile: A Pipfile section to operate on, defaults to None",
            "    :type pipfile: Optional[Dict[str, Union[str, Dict[str, bool, List[str]]]]]",
            "    :param Dict[str, Any] lockfile: A project lockfile to mutate, defaults to None",
            "    :param bool keep_outdated: Whether to retain outdated dependencies and resolve with them in mind, defaults to False",
            "    :raises RuntimeError: Raised on resolution failure",
            "    :return: Nothing",
            "    :rtype: None",
            "    \"\"\"",
            "",
            "    import json",
            "",
            "    from . import resolver",
            "    from ._compat import decode_for_output",
            "    from .vendor.vistir.compat import JSONDecodeError, NamedTemporaryFile, Path",
            "    from .vendor.vistir.misc import fs_str",
            "    from .vendor.vistir.path import create_tracked_tempdir",
            "",
            "    results = []",
            "    pipfile_section = \"dev-packages\" if dev else \"packages\"",
            "    lockfile_section = \"develop\" if dev else \"default\"",
            "    if not deps:",
            "        if not project.pipfile_exists:",
            "            return None",
            "        deps = project.parsed_pipfile.get(pipfile_section, {})",
            "    if not deps:",
            "        return None",
            "",
            "    if not pipfile:",
            "        pipfile = getattr(project, pipfile_section, {})",
            "    if not lockfile:",
            "        lockfile = project._lockfile",
            "    req_dir = create_tracked_tempdir(prefix=\"pipenv\", suffix=\"requirements\")",
            "    cmd = [",
            "        which(\"python\", allow_global=allow_global),",
            "        Path(resolver.__file__.rstrip(\"co\")).as_posix()",
            "    ]",
            "    if pre:",
            "        cmd.append(\"--pre\")",
            "    if clear:",
            "        cmd.append(\"--clear\")",
            "    if allow_global:",
            "        cmd.append(\"--system\")",
            "    if dev:",
            "        cmd.append(\"--dev\")",
            "    target_file = NamedTemporaryFile(prefix=\"resolver\", suffix=\".json\", delete=False)",
            "    target_file.close()",
            "    cmd.extend([\"--write\", make_posix(target_file.name)])",
            "    with temp_environ():",
            "        os.environ.update({fs_str(k): fs_str(val) for k, val in os.environ.items()})",
            "        if pypi_mirror:",
            "            os.environ[\"PIPENV_PYPI_MIRROR\"] = str(pypi_mirror)",
            "        os.environ[\"PIPENV_VERBOSITY\"] = str(project.s.PIPENV_VERBOSITY)",
            "        os.environ[\"PIPENV_REQ_DIR\"] = fs_str(req_dir)",
            "        os.environ[\"PIP_NO_INPUT\"] = fs_str(\"1\")",
            "        pipenv_site_dir = get_pipenv_sitedir()",
            "        if pipenv_site_dir is not None:",
            "            os.environ[\"PIPENV_SITE_DIR\"] = pipenv_site_dir",
            "        else:",
            "            os.environ.pop(\"PIPENV_SITE_DIR\", None)",
            "        if keep_outdated:",
            "            os.environ[\"PIPENV_KEEP_OUTDATED\"] = fs_str(\"1\")",
            "        with create_spinner(text=decode_for_output(\"Locking...\"), setting=project.s) as sp:",
            "            # This conversion is somewhat slow on local and file-type requirements since",
            "            # we now download those requirements / make temporary folders to perform",
            "            # dependency resolution on them, so we are including this step inside the",
            "            # spinner context manager for the UX improvement",
            "            sp.write(decode_for_output(\"Building requirements...\"))",
            "            deps = convert_deps_to_pip(",
            "                deps, project, r=False, include_index=True",
            "            )",
            "            constraints = set(deps)",
            "            os.environ[\"PIPENV_PACKAGES\"] = str(\"\\n\".join(constraints))",
            "            sp.write(decode_for_output(\"Resolving dependencies...\"))",
            "            c = resolve(cmd, sp, project=project)",
            "            results = c.stdout.strip()",
            "            if c.returncode == 0:",
            "                sp.green.ok(environments.PIPENV_SPINNER_OK_TEXT.format(\"Success!\"))",
            "                if not project.s.is_verbose() and c.stderr.strip():",
            "                    click_echo(crayons.yellow(f\"Warning: {c.stderr.strip()}\"), err=True)",
            "            else:",
            "                sp.red.fail(environments.PIPENV_SPINNER_FAIL_TEXT.format(\"Locking Failed!\"))",
            "                click_echo(f\"Output: {c.stdout.strip()}\", err=True)",
            "                click_echo(f\"Error: {c.stderr.strip()}\", err=True)",
            "    try:",
            "        with open(target_file.name) as fh:",
            "            results = json.load(fh)",
            "    except (IndexError, JSONDecodeError):",
            "        click_echo(c.stdout.strip(), err=True)",
            "        click_echo(c.stderr.strip(), err=True)",
            "        if os.path.exists(target_file.name):",
            "            os.unlink(target_file.name)",
            "        raise RuntimeError(\"There was a problem with locking.\")",
            "    if os.path.exists(target_file.name):",
            "        os.unlink(target_file.name)",
            "    if lockfile_section not in lockfile:",
            "        lockfile[lockfile_section] = {}",
            "    prepare_lockfile(results, pipfile, lockfile[lockfile_section])",
            "",
            "",
            "def resolve_deps(",
            "    deps,",
            "    which,",
            "    project,",
            "    sources=None,",
            "    python=False,",
            "    clear=False,",
            "    pre=False,",
            "    allow_global=False,",
            "    req_dir=None",
            "):",
            "    \"\"\"Given a list of dependencies, return a resolved list of dependencies,",
            "    using pip-tools -- and their hashes, using the warehouse API / pip.",
            "    \"\"\"",
            "    index_lookup = {}",
            "    markers_lookup = {}",
            "    python_path = which(\"python\", allow_global=allow_global)",
            "    if not os.environ.get(\"PIP_SRC\"):",
            "        os.environ[\"PIP_SRC\"] = project.virtualenv_src_location",
            "    backup_python_path = sys.executable",
            "    results = []",
            "    resolver = None",
            "    if not deps:",
            "        return results, resolver",
            "    # First (proper) attempt:",
            "    req_dir = req_dir if req_dir else os.environ.get(\"req_dir\", None)",
            "    if not req_dir:",
            "        from .vendor.vistir.path import create_tracked_tempdir",
            "        req_dir = create_tracked_tempdir(prefix=\"pipenv-\", suffix=\"-requirements\")",
            "    with HackedPythonVersion(python_version=python, python_path=python_path):",
            "        try:",
            "            results, hashes, markers_lookup, resolver, skipped = actually_resolve_deps(",
            "                deps,",
            "                index_lookup,",
            "                markers_lookup,",
            "                project,",
            "                sources,",
            "                clear,",
            "                pre,",
            "                req_dir=req_dir,",
            "            )",
            "        except RuntimeError:",
            "            # Don't exit here, like usual.",
            "            results = None",
            "    # Second (last-resort) attempt:",
            "    if results is None:",
            "        with HackedPythonVersion(",
            "            python_version=\".\".join([str(s) for s in sys.version_info[:3]]),",
            "            python_path=backup_python_path,",
            "        ):",
            "            try:",
            "                # Attempt to resolve again, with different Python version information,",
            "                # particularly for particularly particular packages.",
            "                results, hashes, markers_lookup, resolver, skipped = actually_resolve_deps(",
            "                    deps,",
            "                    index_lookup,",
            "                    markers_lookup,",
            "                    project,",
            "                    sources,",
            "                    clear,",
            "                    pre,",
            "                    req_dir=req_dir,",
            "                )",
            "            except RuntimeError:",
            "                sys.exit(1)",
            "    return results, resolver",
            "",
            "",
            "def is_star(val):",
            "    return isinstance(val, str) and val == \"*\"",
            "",
            "",
            "def is_pinned(val):",
            "    if isinstance(val, Mapping):",
            "        val = val.get(\"version\")",
            "    return isinstance(val, str) and val.startswith(\"==\")",
            "",
            "",
            "def is_pinned_requirement(ireq):",
            "    \"\"\"",
            "    Returns whether an InstallRequirement is a \"pinned\" requirement.",
            "    \"\"\"",
            "    if ireq.editable:",
            "        return False",
            "",
            "    if ireq.req is None or len(ireq.specifier) != 1:",
            "        return False",
            "",
            "    spec = next(iter(ireq.specifier))",
            "    return spec.operator in {\"==\", \"===\"} and not spec.version.endswith(\".*\")",
            "",
            "",
            "def convert_deps_to_pip(deps, project=None, r=True, include_index=True):",
            "    \"\"\"\"Converts a Pipfile-formatted dependency to a pip-formatted one.\"\"\"",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    dependencies = []",
            "    for dep_name, dep in deps.items():",
            "        if project:",
            "            project.clear_pipfile_cache()",
            "        indexes = getattr(project, \"pipfile_sources\", []) if project is not None else []",
            "        new_dep = Requirement.from_pipfile(dep_name, dep)",
            "        if new_dep.index:",
            "            include_index = True",
            "        req = new_dep.as_line(sources=indexes if include_index else None).strip()",
            "        dependencies.append(req)",
            "    if not r:",
            "        return dependencies",
            "",
            "    # Write requirements.txt to tmp directory.",
            "    from .vendor.vistir.path import create_tracked_tempfile",
            "    f = create_tracked_tempfile(suffix=\"-requirements.txt\", delete=False)",
            "    f.write(\"\\n\".join(dependencies).encode(\"utf-8\"))",
            "    f.close()",
            "    return f.name",
            "",
            "",
            "def mkdir_p(newdir):",
            "    \"\"\"works the way a good mkdir should :)",
            "        - already exists, silently complete",
            "        - regular file in the way, raise an exception",
            "        - parent directory(ies) does not exist, make them as well",
            "        From: http://code.activestate.com/recipes/82465-a-friendly-mkdir/",
            "    \"\"\"",
            "    if os.path.isdir(newdir):",
            "        pass",
            "    elif os.path.isfile(newdir):",
            "        raise OSError(",
            "            \"a file with the same name as the desired dir, '{}', already exists.\".format(",
            "                newdir",
            "            )",
            "        )",
            "",
            "    else:",
            "        head, tail = os.path.split(newdir)",
            "        if head and not os.path.isdir(head):",
            "            mkdir_p(head)",
            "        if tail:",
            "            # Even though we've checked that the directory doesn't exist above, it might exist",
            "            # now if some other process has created it between now and the time we checked it.",
            "            try:",
            "                os.mkdir(newdir)",
            "            except OSError as exn:",
            "                # If we failed because the directory does exist, that's not a problem -",
            "                # that's what we were trying to do anyway. Only re-raise the exception",
            "                # if we failed for some other reason.",
            "                if exn.errno != errno.EEXIST:",
            "                    raise",
            "",
            "",
            "def is_required_version(version, specified_version):",
            "    \"\"\"Check to see if there's a hard requirement for version",
            "    number provided in the Pipfile.",
            "    \"\"\"",
            "    # Certain packages may be defined with multiple values.",
            "    if isinstance(specified_version, dict):",
            "        specified_version = specified_version.get(\"version\", \"\")",
            "    if specified_version.startswith(\"==\"):",
            "        return version.strip() == specified_version.split(\"==\")[1].strip()",
            "",
            "    return True",
            "",
            "",
            "def is_editable(pipfile_entry):",
            "    if hasattr(pipfile_entry, \"get\"):",
            "        return pipfile_entry.get(\"editable\", False) and any(",
            "            pipfile_entry.get(key) for key in (\"file\", \"path\") + VCS_LIST",
            "        )",
            "    return False",
            "",
            "",
            "def is_installable_file(path):",
            "    \"\"\"Determine if a path can potentially be installed\"\"\"",
            "    from .patched.notpip._internal.utils.packaging import specifiers",
            "    from .vendor.pip_shims.shims import is_archive_file, is_installable_dir",
            "",
            "    if hasattr(path, \"keys\") and any(",
            "        key for key in path.keys() if key in [\"file\", \"path\"]",
            "    ):",
            "        path = urlparse(path[\"file\"]).path if \"file\" in path else path[\"path\"]",
            "    if not isinstance(path, str) or path == \"*\":",
            "        return False",
            "",
            "    # If the string starts with a valid specifier operator, test if it is a valid",
            "    # specifier set before making a path object (to avoid breaking windows)",
            "    if any(path.startswith(spec) for spec in \"!=<>~\"):",
            "        try:",
            "            specifiers.SpecifierSet(path)",
            "        # If this is not a valid specifier, just move on and try it as a path",
            "        except specifiers.InvalidSpecifier:",
            "            pass",
            "        else:",
            "            return False",
            "",
            "    if not os.path.exists(os.path.abspath(path)):",
            "        return False",
            "",
            "    lookup_path = Path(path)",
            "    absolute_path = f\"{lookup_path.absolute()}\"",
            "    if lookup_path.is_dir() and is_installable_dir(absolute_path):",
            "        return True",
            "",
            "    elif lookup_path.is_file() and is_archive_file(absolute_path):",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def is_file(package):",
            "    \"\"\"Determine if a package name is for a File dependency.\"\"\"",
            "    if hasattr(package, \"keys\"):",
            "        return any(key for key in package.keys() if key in [\"file\", \"path\"])",
            "",
            "    if os.path.exists(str(package)):",
            "        return True",
            "",
            "    for start in SCHEME_LIST:",
            "        if str(package).startswith(start):",
            "            return True",
            "",
            "    return False",
            "",
            "",
            "def pep440_version(version):",
            "    \"\"\"Normalize version to PEP 440 standards\"\"\"",
            "    # Use pip built-in version parser.",
            "    from pipenv.vendor.pip_shims import shims",
            "",
            "    return str(shims.parse_version(version))",
            "",
            "",
            "def pep423_name(name):",
            "    \"\"\"Normalize package name to PEP 423 style standard.\"\"\"",
            "    name = name.lower()",
            "    if any(i not in name for i in (VCS_LIST + SCHEME_LIST)):",
            "        return name.replace(\"_\", \"-\")",
            "",
            "    else:",
            "        return name",
            "",
            "",
            "def proper_case(package_name):",
            "    \"\"\"Properly case project name from pypi.org.\"\"\"",
            "    # Hit the simple API.",
            "    r = _get_requests_session().get(",
            "        f\"https://pypi.org/pypi/{package_name}/json\", timeout=0.3, stream=True",
            "    )",
            "    if not r.ok:",
            "        raise OSError(",
            "            f\"Unable to find package {package_name} in PyPI repository.\"",
            "        )",
            "",
            "    r = parse.parse(\"https://pypi.org/pypi/{name}/json\", r.url)",
            "    good_name = r[\"name\"]",
            "    return good_name",
            "",
            "",
            "def get_windows_path(*args):",
            "    \"\"\"Sanitize a path for windows environments",
            "",
            "    Accepts an arbitrary list of arguments and makes a clean windows path\"\"\"",
            "    return os.path.normpath(os.path.join(*args))",
            "",
            "",
            "def find_windows_executable(bin_path, exe_name):",
            "    \"\"\"Given an executable name, search the given location for an executable\"\"\"",
            "    requested_path = get_windows_path(bin_path, exe_name)",
            "    if os.path.isfile(requested_path):",
            "        return requested_path",
            "",
            "    try:",
            "        pathext = os.environ[\"PATHEXT\"]",
            "    except KeyError:",
            "        pass",
            "    else:",
            "        for ext in pathext.split(os.pathsep):",
            "            path = get_windows_path(bin_path, exe_name + ext.strip().lower())",
            "            if os.path.isfile(path):",
            "                return path",
            "",
            "    return find_executable(exe_name)",
            "",
            "",
            "def path_to_url(path):",
            "",
            "    return Path(normalize_drive(os.path.abspath(path))).as_uri()",
            "",
            "",
            "def normalize_path(path):",
            "    return os.path.expandvars(os.path.expanduser(",
            "        os.path.normcase(os.path.normpath(os.path.abspath(str(path))))",
            "    ))",
            "",
            "",
            "def get_url_name(url):",
            "    if not isinstance(url, str):",
            "        return",
            "    return urllib3_util.parse_url(url).host",
            "",
            "",
            "def get_host_and_port(url):",
            "    \"\"\"Get the host, or the host:port pair if port is explicitly included, for the given URL.",
            "",
            "    Examples:",
            "    >>> get_host_and_port('example.com')",
            "    'example.com'",
            "    >>> get_host_and_port('example.com:443')",
            "    'example.com:443'",
            "    >>> get_host_and_port('http://example.com')",
            "    'example.com'",
            "    >>> get_host_and_port('https://example.com/')",
            "    'example.com'",
            "    >>> get_host_and_port('https://example.com:8081')",
            "    'example.com:8081'",
            "    >>> get_host_and_port('ssh://example.com')",
            "    'example.com'",
            "",
            "    :param url: the URL string to parse",
            "    :return: a string with the host:port pair if the URL includes port number explicitly; otherwise, returns host only",
            "    \"\"\"",
            "    url = urllib3_util.parse_url(url)",
            "    return '{}:{}'.format(url.host, url.port) if url.port else url.host",
            "",
            "",
            "def get_canonical_names(packages):",
            "    \"\"\"Canonicalize a list of packages and return a set of canonical names\"\"\"",
            "    from .vendor.packaging.utils import canonicalize_name",
            "",
            "    if not isinstance(packages, Sequence):",
            "        if not isinstance(packages, str):",
            "            return packages",
            "        packages = [packages]",
            "    return {canonicalize_name(pkg) for pkg in packages if pkg}",
            "",
            "",
            "def walk_up(bottom):",
            "    \"\"\"Mimic os.walk, but walk 'up' instead of down the directory tree.",
            "    From: https://gist.github.com/zdavkeos/1098474",
            "    \"\"\"",
            "    bottom = os.path.realpath(bottom)",
            "    # Get files in current dir.",
            "    try:",
            "        names = os.listdir(bottom)",
            "    except Exception:",
            "        return",
            "",
            "    dirs, nondirs = [], []",
            "    for name in names:",
            "        if os.path.isdir(os.path.join(bottom, name)):",
            "            dirs.append(name)",
            "        else:",
            "            nondirs.append(name)",
            "    yield bottom, dirs, nondirs",
            "",
            "    new_path = os.path.realpath(os.path.join(bottom, \"..\"))",
            "    # See if we are at the top.",
            "    if new_path == bottom:",
            "        return",
            "",
            "    yield from walk_up(new_path)",
            "",
            "",
            "def find_requirements(max_depth=3):",
            "    \"\"\"Returns the path of a requirements.txt file in parent directories.\"\"\"",
            "    i = 0",
            "    for c, d, f in walk_up(os.getcwd()):",
            "        i += 1",
            "        if i < max_depth:",
            "            r = os.path.join(c, \"requirements.txt\")",
            "            if os.path.isfile(r):",
            "                return r",
            "",
            "    raise RuntimeError(\"No requirements.txt found!\")",
            "",
            "",
            "# Borrowed from Pew.",
            "# See https://github.com/berdario/pew/blob/master/pew/_utils.py#L82",
            "@contextmanager",
            "def temp_environ():",
            "    \"\"\"Allow the ability to set os.environ temporarily\"\"\"",
            "    environ = dict(os.environ)",
            "    try:",
            "        yield",
            "",
            "    finally:",
            "        os.environ.clear()",
            "        os.environ.update(environ)",
            "",
            "",
            "@contextmanager",
            "def temp_path():",
            "    \"\"\"Allow the ability to set os.environ temporarily\"\"\"",
            "    path = [p for p in sys.path]",
            "    try:",
            "        yield",
            "    finally:",
            "        sys.path = [p for p in path]",
            "",
            "",
            "def load_path(python):",
            "    import json",
            "",
            "    from pathlib import Path",
            "    python = Path(python).as_posix()",
            "    json_dump_commmand = '\"import json, sys; print(json.dumps(sys.path));\"'",
            "    c = subprocess_run([python, \"-c\", json_dump_commmand])",
            "    if c.returncode == 0:",
            "        return json.loads(c.stdout.strip())",
            "    else:",
            "        return []",
            "",
            "",
            "def is_valid_url(url):",
            "    \"\"\"Checks if a given string is an url\"\"\"",
            "    pieces = urlparse(url)",
            "    return all([pieces.scheme, pieces.netloc])",
            "",
            "",
            "def is_pypi_url(url):",
            "    return bool(re.match(r\"^http[s]?:\\/\\/pypi(?:\\.python)?\\.org\\/simple[\\/]?$\", url))",
            "",
            "",
            "def replace_pypi_sources(sources, pypi_replacement_source):",
            "    return [pypi_replacement_source] + [",
            "        source for source in sources if not is_pypi_url(source[\"url\"])",
            "    ]",
            "",
            "",
            "def create_mirror_source(url):",
            "    return {",
            "        \"url\": url,",
            "        \"verify_ssl\": url.startswith(\"https://\"),",
            "        \"name\": urlparse(url).hostname,",
            "    }",
            "",
            "",
            "def download_file(url, filename, max_retries=1):",
            "    \"\"\"Downloads file from url to a path with filename\"\"\"",
            "    r = _get_requests_session(max_retries).get(url, stream=True)",
            "    if not r.ok:",
            "        raise OSError(\"Unable to download file\")",
            "",
            "    with open(filename, \"wb\") as f:",
            "        f.write(r.content)",
            "",
            "",
            "def normalize_drive(path):",
            "    \"\"\"Normalize drive in path so they stay consistent.",
            "",
            "    This currently only affects local drives on Windows, which can be",
            "    identified with either upper or lower cased drive names. The case is",
            "    always converted to uppercase because it seems to be preferred.",
            "",
            "    See: <https://github.com/pypa/pipenv/issues/1218>",
            "    \"\"\"",
            "    if os.name != \"nt\" or not isinstance(path, str):",
            "        return path",
            "",
            "    drive, tail = os.path.splitdrive(path)",
            "    # Only match (lower cased) local drives (e.g. 'c:'), not UNC mounts.",
            "    if drive.islower() and len(drive) == 2 and drive[1] == \":\":",
            "        return f\"{drive.upper()}{tail}\"",
            "",
            "    return path",
            "",
            "",
            "def is_readonly_path(fn):",
            "    \"\"\"Check if a provided path exists and is readonly.",
            "",
            "    Permissions check is `bool(path.stat & stat.S_IREAD)` or `not os.access(path, os.W_OK)`",
            "    \"\"\"",
            "    if os.path.exists(fn):",
            "        return (os.stat(fn).st_mode & stat.S_IREAD) or not os.access(fn, os.W_OK)",
            "",
            "    return False",
            "",
            "",
            "def set_write_bit(fn):",
            "    if isinstance(fn, str) and not os.path.exists(fn):",
            "        return",
            "    os.chmod(fn, stat.S_IWRITE | stat.S_IWUSR | stat.S_IRUSR)",
            "    return",
            "",
            "",
            "def rmtree(directory, ignore_errors=False):",
            "    shutil.rmtree(",
            "        directory, ignore_errors=ignore_errors, onerror=handle_remove_readonly",
            "    )",
            "",
            "",
            "def handle_remove_readonly(func, path, exc):",
            "    \"\"\"Error handler for shutil.rmtree.",
            "",
            "    Windows source repo folders are read-only by default, so this error handler",
            "    attempts to set them as writeable and then proceed with deletion.\"\"\"",
            "    # Check for read-only attribute",
            "    default_warning_message = (",
            "        \"Unable to remove file due to permissions restriction: {!r}\"",
            "    )",
            "    # split the initial exception out into its type, exception, and traceback",
            "    exc_type, exc_exception, exc_tb = exc",
            "    if is_readonly_path(path):",
            "        # Apply write permission and call original function",
            "        set_write_bit(path)",
            "        try:",
            "            func(path)",
            "        except OSError as e:",
            "            if e.errno in [errno.EACCES, errno.EPERM]:",
            "                warnings.warn(default_warning_message.format(path), ResourceWarning)",
            "                return",
            "",
            "    if exc_exception.errno in [errno.EACCES, errno.EPERM]:",
            "        warnings.warn(default_warning_message.format(path), ResourceWarning)",
            "        return",
            "",
            "    raise exc",
            "",
            "",
            "def escape_cmd(cmd):",
            "    if any(special_char in cmd for special_char in [\"<\", \">\", \"&\", \".\", \"^\", \"|\", \"?\"]):",
            "        cmd = f'\\\"{cmd}\\\"'",
            "    return cmd",
            "",
            "",
            "def safe_expandvars(value):",
            "    \"\"\"Call os.path.expandvars if value is a string, otherwise do nothing.",
            "    \"\"\"",
            "    if isinstance(value, str):",
            "        return os.path.expandvars(value)",
            "    return value",
            "",
            "",
            "def get_vcs_deps(",
            "    project=None,",
            "    dev=False,",
            "    pypi_mirror=None,",
            "    packages=None,",
            "    reqs=None",
            "):",
            "    from .vendor.requirementslib.models.requirements import Requirement",
            "",
            "    section = \"vcs_dev_packages\" if dev else \"vcs_packages\"",
            "    if reqs is None:",
            "        reqs = []",
            "    lockfile = {}",
            "    if not reqs:",
            "        if not project and not packages:",
            "            raise ValueError(",
            "                \"Must supply either a project or a pipfile section to lock vcs dependencies.\"",
            "            )",
            "        if not packages:",
            "            try:",
            "                packages = getattr(project, section)",
            "            except AttributeError:",
            "                return [], []",
            "        reqs = [Requirement.from_pipfile(name, entry) for name, entry in packages.items()]",
            "    result = []",
            "    for requirement in reqs:",
            "        name = requirement.normalized_name",
            "        commit_hash = None",
            "        if requirement.is_vcs:",
            "            try:",
            "                with temp_path(), locked_repository(requirement) as repo:",
            "                    from pipenv.vendor.requirementslib.models.requirements import (",
            "                        Requirement",
            "                    )",
            "",
            "                    # from distutils.sysconfig import get_python_lib",
            "                    # sys.path = [repo.checkout_directory, \"\", \".\", get_python_lib(plat_specific=0)]",
            "                    commit_hash = repo.get_commit_hash()",
            "                    name = requirement.normalized_name",
            "                    lockfile[name] = requirement.pipfile_entry[1]",
            "                    lockfile[name]['ref'] = commit_hash",
            "                    result.append(requirement)",
            "            except OSError:",
            "                continue",
            "    return result, lockfile",
            "",
            "",
            "def translate_markers(pipfile_entry):",
            "    \"\"\"Take a pipfile entry and normalize its markers",
            "",
            "    Provide a pipfile entry which may have 'markers' as a key or it may have",
            "    any valid key from `packaging.markers.marker_context.keys()` and standardize",
            "    the format into {'markers': 'key == \"some_value\"'}.",
            "",
            "    :param pipfile_entry: A dictionariy of keys and values representing a pipfile entry",
            "    :type pipfile_entry: dict",
            "    :returns: A normalized dictionary with cleaned marker entries",
            "    \"\"\"",
            "    if not isinstance(pipfile_entry, Mapping):",
            "        raise TypeError(\"Entry is not a pipfile formatted mapping.\")",
            "    from .vendor.packaging.markers import default_environment",
            "    from .vendor.vistir.misc import dedup",
            "",
            "    allowed_marker_keys = [\"markers\"] + list(default_environment().keys())",
            "    provided_keys = list(pipfile_entry.keys()) if hasattr(pipfile_entry, \"keys\") else []",
            "    pipfile_markers = set(provided_keys) & set(allowed_marker_keys)",
            "    new_pipfile = dict(pipfile_entry).copy()",
            "    marker_set = set()",
            "    if \"markers\" in new_pipfile:",
            "        marker_str = new_pipfile.pop(\"markers\")",
            "        if marker_str:",
            "            marker = str(Marker(marker_str))",
            "            if 'extra' not in marker:",
            "                marker_set.add(marker)",
            "    for m in pipfile_markers:",
            "        entry = f\"{pipfile_entry[m]}\"",
            "        if m != \"markers\":",
            "            marker_set.add(str(Marker(f\"{m} {entry}\")))",
            "            new_pipfile.pop(m)",
            "    if marker_set:",
            "        new_pipfile[\"markers\"] = str(Marker(\" or \".join(",
            "            f\"{s}\" if \" and \" in s else s",
            "            for s in sorted(dedup(marker_set))",
            "        ))).replace('\"', \"'\")",
            "    return new_pipfile",
            "",
            "",
            "def clean_resolved_dep(dep, is_top_level=False, pipfile_entry=None):",
            "    from .vendor.requirementslib.utils import is_vcs",
            "    name = pep423_name(dep[\"name\"])",
            "    lockfile = {}",
            "    # We use this to determine if there are any markers on top level packages",
            "    # So we can make sure those win out during resolution if the packages reoccur",
            "    if \"version\" in dep and dep[\"version\"] and not dep.get(\"editable\", False):",
            "        version = \"{}\".format(dep[\"version\"])",
            "        if not version.startswith(\"==\"):",
            "            version = f\"=={version}\"",
            "        lockfile[\"version\"] = version",
            "    if is_vcs(dep):",
            "        ref = dep.get(\"ref\", None)",
            "        if ref is not None:",
            "            lockfile[\"ref\"] = ref",
            "        vcs_type = next(iter(k for k in dep.keys() if k in VCS_LIST), None)",
            "        if vcs_type:",
            "            lockfile[vcs_type] = dep[vcs_type]",
            "        if \"subdirectory\" in dep:",
            "            lockfile[\"subdirectory\"] = dep[\"subdirectory\"]",
            "    for key in [\"hashes\", \"index\", \"extras\", \"editable\"]:",
            "        if key in dep:",
            "            lockfile[key] = dep[key]",
            "    # In case we lock a uri or a file when the user supplied a path",
            "    # remove the uri or file keys from the entry and keep the path",
            "    fs_key = next(iter(k for k in [\"path\", \"file\"] if k in dep), None)",
            "    pipfile_fs_key = None",
            "    if pipfile_entry:",
            "        pipfile_fs_key = next(iter(k for k in [\"path\", \"file\"] if k in pipfile_entry), None)",
            "    if fs_key and pipfile_fs_key and fs_key != pipfile_fs_key:",
            "        lockfile[pipfile_fs_key] = pipfile_entry[pipfile_fs_key]",
            "    elif fs_key is not None:",
            "        lockfile[fs_key] = dep[fs_key]",
            "",
            "    # If a package is **PRESENT** in the pipfile but has no markers, make sure we",
            "    # **NEVER** include markers in the lockfile",
            "    if \"markers\" in dep and dep.get(\"markers\", \"\").strip():",
            "        # First, handle the case where there is no top level dependency in the pipfile",
            "        if not is_top_level:",
            "            translated = translate_markers(dep).get(\"markers\", \"\").strip()",
            "            if translated:",
            "                try:",
            "                    lockfile[\"markers\"] = translated",
            "                except TypeError:",
            "                    pass",
            "        # otherwise make sure we are prioritizing whatever the pipfile says about the markers",
            "        # If the pipfile says nothing, then we should put nothing in the lockfile",
            "        else:",
            "            try:",
            "                pipfile_entry = translate_markers(pipfile_entry)",
            "                lockfile[\"markers\"] = pipfile_entry.get(\"markers\")",
            "            except TypeError:",
            "                pass",
            "    return {name: lockfile}",
            "",
            "",
            "def get_workon_home():",
            "    workon_home = os.environ.get(\"WORKON_HOME\")",
            "    if not workon_home:",
            "        if os.name == \"nt\":",
            "            workon_home = \"~/.virtualenvs\"",
            "        else:",
            "            workon_home = os.path.join(",
            "                os.environ.get(\"XDG_DATA_HOME\", \"~/.local/share\"), \"virtualenvs\"",
            "            )",
            "    # Create directory if it does not already exist",
            "    expanded_path = Path(os.path.expandvars(workon_home)).expanduser()",
            "    mkdir_p(str(expanded_path))",
            "    return expanded_path",
            "",
            "",
            "def is_virtual_environment(path):",
            "    \"\"\"Check if a given path is a virtual environment's root.",
            "",
            "    This is done by checking if the directory contains a Python executable in",
            "    its bin/Scripts directory. Not technically correct, but good enough for",
            "    general usage.",
            "    \"\"\"",
            "    if not path.is_dir():",
            "        return False",
            "    for bindir_name in ('bin', 'Scripts'):",
            "        for python in path.joinpath(bindir_name).glob('python*'):",
            "            try:",
            "                exeness = python.is_file() and os.access(str(python), os.X_OK)",
            "            except OSError:",
            "                exeness = False",
            "            if exeness:",
            "                return True",
            "    return False",
            "",
            "",
            "@contextmanager",
            "def locked_repository(requirement):",
            "    from .vendor.vistir.path import create_tracked_tempdir",
            "    if not requirement.is_vcs:",
            "        return",
            "    original_base = os.environ.pop(\"PIP_SHIMS_BASE_MODULE\", None)",
            "    os.environ[\"PIP_SHIMS_BASE_MODULE\"] = fs_str(\"pipenv.patched.notpip\")",
            "    src_dir = create_tracked_tempdir(prefix=\"pipenv-\", suffix=\"-src\")",
            "    try:",
            "        with requirement.req.locked_vcs_repo(src_dir=src_dir) as repo:",
            "            yield repo",
            "    finally:",
            "        if original_base:",
            "            os.environ[\"PIP_SHIMS_BASE_MODULE\"] = original_base",
            "",
            "",
            "@contextmanager",
            "def chdir(path):",
            "    \"\"\"Context manager to change working directories.\"\"\"",
            "    if not path:",
            "        return",
            "    prev_cwd = Path.cwd().as_posix()",
            "    if isinstance(path, Path):",
            "        path = path.as_posix()",
            "    os.chdir(str(path))",
            "    try:",
            "        yield",
            "    finally:",
            "        os.chdir(prev_cwd)",
            "",
            "",
            "def looks_like_dir(path):",
            "    seps = (sep for sep in (os.path.sep, os.path.altsep) if sep is not None)",
            "    return any(sep in path for sep in seps)",
            "",
            "",
            "def parse_indexes(line, strict=False):",
            "    from argparse import ArgumentParser",
            "",
            "    comment_re = re.compile(r\"(?:^|\\s+)#.*$\")",
            "    line = comment_re.sub(\"\", line)",
            "    parser = ArgumentParser(\"indexes\", allow_abbrev=False)",
            "    parser.add_argument(\"-i\", \"--index-url\", dest=\"index\")",
            "    parser.add_argument(\"--extra-index-url\", dest=\"extra_index\")",
            "    parser.add_argument(\"--trusted-host\", dest=\"trusted_host\")",
            "    args, remainder = parser.parse_known_args(line.split())",
            "    index = args.index",
            "    extra_index = args.extra_index",
            "    trusted_host = args.trusted_host",
            "    if strict and sum(",
            "        bool(arg) for arg in (index, extra_index, trusted_host, remainder)",
            "    ) > 1:",
            "        raise ValueError(\"Index arguments must be on their own lines.\")",
            "    return index, extra_index, trusted_host, remainder",
            "",
            "",
            "@contextmanager",
            "def sys_version(version_tuple):",
            "    \"\"\"",
            "    Set a temporary sys.version_info tuple",
            "",
            "    :param version_tuple: a fake sys.version_info tuple",
            "    \"\"\"",
            "",
            "    old_version = sys.version_info",
            "    sys.version_info = version_tuple",
            "    yield",
            "    sys.version_info = old_version",
            "",
            "",
            "def add_to_set(original_set, element):",
            "    \"\"\"Given a set and some arbitrary element, add the element(s) to the set\"\"\"",
            "    if not element:",
            "        return original_set",
            "    if isinstance(element, Set):",
            "        original_set |= element",
            "    elif isinstance(element, (list, tuple)):",
            "        original_set |= set(element)",
            "    else:",
            "        original_set.add(element)",
            "    return original_set",
            "",
            "",
            "def is_url_equal(url, other_url):",
            "    # type: (str, str) -> bool",
            "    \"\"\"",
            "    Compare two urls by scheme, host, and path, ignoring auth",
            "",
            "    :param str url: The initial URL to compare",
            "    :param str url: Second url to compare to the first",
            "    :return: Whether the URLs are equal without **auth**, **query**, and **fragment**",
            "    :rtype: bool",
            "",
            "    >>> is_url_equal(\"https://user:pass@mydomain.com/some/path?some_query\",",
            "                     \"https://user2:pass2@mydomain.com/some/path\")",
            "    True",
            "",
            "    >>> is_url_equal(\"https://user:pass@mydomain.com/some/path?some_query\",",
            "                 \"https://mydomain.com/some?some_query\")",
            "    False",
            "    \"\"\"",
            "    if not isinstance(url, str):",
            "        raise TypeError(f\"Expected string for url, received {url!r}\")",
            "    if not isinstance(other_url, str):",
            "        raise TypeError(f\"Expected string for url, received {other_url!r}\")",
            "    parsed_url = urllib3_util.parse_url(url)",
            "    parsed_other_url = urllib3_util.parse_url(other_url)",
            "    unparsed = parsed_url._replace(auth=None, query=None, fragment=None).url",
            "    unparsed_other = parsed_other_url._replace(auth=None, query=None, fragment=None).url",
            "    return unparsed == unparsed_other",
            "",
            "",
            "@lru_cache()",
            "def make_posix(path):",
            "    # type: (str) -> str",
            "    \"\"\"",
            "    Convert a path with possible windows-style separators to a posix-style path",
            "    (with **/** separators instead of **\\\\** separators).",
            "",
            "    :param Text path: A path to convert.",
            "    :return: A converted posix-style path",
            "    :rtype: Text",
            "",
            "    >>> make_posix(\"c:/users/user/venvs/some_venv\\\\Lib\\\\site-packages\")",
            "    \"c:/users/user/venvs/some_venv/Lib/site-packages\"",
            "",
            "    >>> make_posix(\"c:\\\\users\\\\user\\\\venvs\\\\some_venv\")",
            "    \"c:/users/user/venvs/some_venv\"",
            "    \"\"\"",
            "    if not isinstance(path, str):",
            "        raise TypeError(f\"Expected a string for path, received {path!r}...\")",
            "    starts_with_sep = path.startswith(os.path.sep)",
            "    separated = normalize_path(path).split(os.path.sep)",
            "    if isinstance(separated, (list, tuple)):",
            "        path = posixpath.join(*separated)",
            "        if starts_with_sep:",
            "            path = f\"/{path}\"",
            "    return path",
            "",
            "",
            "def get_pipenv_dist(pkg=\"pipenv\", pipenv_site=None):",
            "    from .resolver import find_site_path",
            "    pipenv_libdir = os.path.dirname(os.path.abspath(__file__))",
            "    if pipenv_site is None:",
            "        pipenv_site = os.path.dirname(pipenv_libdir)",
            "    pipenv_dist, _ = find_site_path(pkg, site_dir=pipenv_site)",
            "    return pipenv_dist",
            "",
            "",
            "def find_python(finder, line=None):",
            "    \"\"\"",
            "    Given a `pythonfinder.Finder` instance and an optional line, find a corresponding python",
            "",
            "    :param finder: A :class:`pythonfinder.Finder` instance to use for searching",
            "    :type finder: :class:pythonfinder.Finder`",
            "    :param str line: A version, path, name, or nothing, defaults to None",
            "    :return: A path to python",
            "    :rtype: str",
            "    \"\"\"",
            "",
            "    if line and not isinstance(line, str):",
            "        raise TypeError(",
            "            f\"Invalid python search type: expected string, received {line!r}\"",
            "        )",
            "    if line and os.path.isabs(line):",
            "        if os.name == \"nt\":",
            "            line = make_posix(line)",
            "        return line",
            "    if not finder:",
            "        from pipenv.vendor.pythonfinder import Finder",
            "        finder = Finder(global_search=True)",
            "    if not line:",
            "        result = next(iter(finder.find_all_python_versions()), None)",
            "    elif line and line[0].isdigit() or re.match(r'[\\d\\.]+', line):",
            "        result = finder.find_python_version(line)",
            "    else:",
            "        result = finder.find_python_version(name=line)",
            "    if not result:",
            "        result = finder.which(line)",
            "    if not result and not line.startswith(\"python\"):",
            "        line = f\"python{line}\"",
            "        result = find_python(finder, line)",
            "",
            "    if result:",
            "        if not isinstance(result, str):",
            "            return result.path.as_posix()",
            "        return result",
            "    return",
            "",
            "",
            "def is_python_command(line):",
            "    \"\"\"",
            "    Given an input, checks whether the input is a request for python or notself.",
            "",
            "    This can be a version, a python runtime name, or a generic 'python' or 'pythonX.Y'",
            "",
            "    :param str line: A potential request to find python",
            "    :returns: Whether the line is a python lookup",
            "    :rtype: bool",
            "    \"\"\"",
            "",
            "    if not isinstance(line, str):",
            "        raise TypeError(f\"Not a valid command to check: {line!r}\")",
            "",
            "    from pipenv.vendor.pythonfinder.utils import PYTHON_IMPLEMENTATIONS",
            "    is_version = re.match(r'\\d+(\\.\\d+)*', line)",
            "    if (line.startswith(\"python\") or is_version",
            "            or any(line.startswith(v) for v in PYTHON_IMPLEMENTATIONS)):",
            "        return True",
            "    # we are less sure about this but we can guess",
            "    if line.startswith(\"py\"):",
            "        return True",
            "    return False",
            "",
            "",
            "@contextlib.contextmanager",
            "def interrupt_handled_subprocess(",
            "    cmd, verbose=False, return_object=True, write_to_stdout=False, combine_stderr=True,",
            "    block=True, nospin=True, env=None",
            "):",
            "    \"\"\"Given a :class:`subprocess.Popen` instance, wrap it in exception handlers.",
            "",
            "    Terminates the subprocess when and if a `SystemExit` or `KeyboardInterrupt` are",
            "    processed.",
            "",
            "    Arguments:",
            "        :param str cmd: A command to run",
            "        :param bool verbose: Whether to run with verbose mode enabled, default False",
            "        :param bool return_object: Whether to return a subprocess instance or a 2-tuple, default True",
            "        :param bool write_to_stdout: Whether to write directly to stdout, default False",
            "        :param bool combine_stderr: Whether to combine stdout and stderr, default True",
            "        :param bool block: Whether the subprocess should be a blocking subprocess, default True",
            "        :param bool nospin: Whether to suppress the spinner with the subprocess, default True",
            "        :param Optional[Dict[str, str]] env: A dictionary to merge into the subprocess environment",
            "        :return: A subprocess, wrapped in exception handlers, as a context manager",
            "        :rtype: :class:`subprocess.Popen` obj: An instance of a running subprocess",
            "    \"\"\"",
            "    obj = run(",
            "        cmd, verbose=verbose, return_object=True, write_to_stdout=False,",
            "        combine_stderr=False, block=True, nospin=True, env=env,",
            "    )",
            "    try:",
            "        yield obj",
            "    except (SystemExit, KeyboardInterrupt):",
            "        if os.name == \"nt\":",
            "            os.kill(obj.pid, signal.CTRL_BREAK_EVENT)",
            "        else:",
            "            os.kill(obj.pid, signal.SIGINT)",
            "        obj.wait()",
            "        raise",
            "",
            "",
            "def subprocess_run(",
            "    args, *, block=True, text=True, capture_output=True,",
            "    encoding=\"utf-8\", env=None, **other_kwargs",
            "):",
            "    \"\"\"A backward compatible version of subprocess.run().",
            "",
            "    It outputs text with default encoding, and store all outputs in the returned object instead of",
            "    printing onto stdout.",
            "    \"\"\"",
            "    _env = os.environ.copy()",
            "    _env[\"PYTHONIOENCODING\"] = encoding",
            "    if env:",
            "        _env.update(env)",
            "    other_kwargs[\"env\"] = _env",
            "    if capture_output:",
            "        other_kwargs['stdout'] = subprocess.PIPE",
            "        other_kwargs['stderr'] = subprocess.PIPE",
            "    if block:",
            "        return subprocess.run(",
            "            args, universal_newlines=text,",
            "            encoding=encoding, **other_kwargs",
            "        )",
            "    else:",
            "        return subprocess.Popen(",
            "            args, universal_newlines=text,",
            "            encoding=encoding, **other_kwargs",
            "        )",
            "",
            "",
            "def cmd_list_to_shell(args):",
            "    \"\"\"Convert a list of arguments to a quoted shell command.\"\"\"",
            "    return \" \".join(shlex.quote(str(token)) for token in args)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "flower.command"
        ]
    }
}