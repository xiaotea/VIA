{
    "libs/core/langchain_core/utils/html.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "     Returns:"
            },
            "1": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "         List[str]: sub links"
            },
            "2": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 69,
                "PatchRowcode": "     \"\"\""
            },
            "3": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    base_url = base_url if base_url is not None else url"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+    base_url_to_use = base_url if base_url is not None else url"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+    parsed_base_url = urlparse(base_url_to_use)"
            },
            "6": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 72,
                "PatchRowcode": "     all_links = find_all_links(raw_html, pattern=pattern)"
            },
            "7": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 73,
                "PatchRowcode": "     absolute_paths = set()"
            },
            "8": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 74,
                "PatchRowcode": "     for link in all_links:"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+        parsed_link = urlparse(link)"
            },
            "10": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "         # Some may be absolute links like https://to/path"
            },
            "11": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if link.startswith(\"http\"):"
            },
            "12": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            absolute_paths.add(link)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+        if parsed_link.scheme == \"http\" or parsed_link.scheme == \"https\":"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+            absolute_path = link"
            },
            "15": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 79,
                "PatchRowcode": "         # Some may have omitted the protocol like //to/path"
            },
            "16": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 80,
                "PatchRowcode": "         elif link.startswith(\"//\"):"
            },
            "17": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+            absolute_path = f\"{urlparse(url).scheme}:{link}\""
            },
            "19": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "         else:"
            },
            "20": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            absolute_paths.add(urljoin(url, link))"
            },
            "21": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    res = []"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 83,
                "PatchRowcode": "+            absolute_path = urljoin(url, parsed_link.path)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+        absolute_paths.add(absolute_path)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 85,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+    results = []"
            },
            "26": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "     for path in absolute_paths:"
            },
            "27": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if any(path.startswith(exclude) for exclude in exclude_prefixes):"
            },
            "28": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            continue"
            },
            "29": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if prevent_outside and not path.startswith(base_url):"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+        if any(path.startswith(exclude_prefix) for exclude_prefix in exclude_prefixes):"
            },
            "31": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "             continue"
            },
            "32": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        res.append(path)"
            },
            "33": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return res"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+        if prevent_outside:"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+            parsed_path = urlparse(path)"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+            if parsed_base_url.netloc != parsed_path.netloc:"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+                continue"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+            # Will take care of verifying rest of path after netloc"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+            # if it's more specific"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+            if not path.startswith(base_url_to_use):"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+                continue"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+        results.append(path)"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+    return results"
            }
        },
        "frontPatchFile": [
            "import re",
            "from typing import List, Optional, Sequence, Union",
            "from urllib.parse import urljoin, urlparse",
            "",
            "PREFIXES_TO_IGNORE = (\"javascript:\", \"mailto:\", \"#\")",
            "SUFFIXES_TO_IGNORE = (",
            "    \".css\",",
            "    \".js\",",
            "    \".ico\",",
            "    \".png\",",
            "    \".jpg\",",
            "    \".jpeg\",",
            "    \".gif\",",
            "    \".svg\",",
            "    \".csv\",",
            "    \".bz2\",",
            "    \".zip\",",
            "    \".epub\",",
            ")",
            "SUFFIXES_TO_IGNORE_REGEX = (",
            "    \"(?!\" + \"|\".join([re.escape(s) + r\"[\\#'\\\"]\" for s in SUFFIXES_TO_IGNORE]) + \")\"",
            ")",
            "PREFIXES_TO_IGNORE_REGEX = (",
            "    \"(?!\" + \"|\".join([re.escape(s) for s in PREFIXES_TO_IGNORE]) + \")\"",
            ")",
            "DEFAULT_LINK_REGEX = (",
            "    rf\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)[\\#'\\\"]\"",
            ")",
            "",
            "",
            "def find_all_links(",
            "    raw_html: str, *, pattern: Union[str, re.Pattern, None] = None",
            ") -> List[str]:",
            "    \"\"\"Extract all links from a raw html string.",
            "",
            "    Args:",
            "        raw_html: original html.",
            "        pattern: Regex to use for extracting links from raw html.",
            "",
            "    Returns:",
            "        List[str]: all links",
            "    \"\"\"",
            "    pattern = pattern or DEFAULT_LINK_REGEX",
            "    return list(set(re.findall(pattern, raw_html)))",
            "",
            "",
            "def extract_sub_links(",
            "    raw_html: str,",
            "    url: str,",
            "    *,",
            "    base_url: Optional[str] = None,",
            "    pattern: Union[str, re.Pattern, None] = None,",
            "    prevent_outside: bool = True,",
            "    exclude_prefixes: Sequence[str] = (),",
            ") -> List[str]:",
            "    \"\"\"Extract all links from a raw html string and convert into absolute paths.",
            "",
            "    Args:",
            "        raw_html: original html.",
            "        url: the url of the html.",
            "        base_url: the base url to check for outside links against.",
            "        pattern: Regex to use for extracting links from raw html.",
            "        prevent_outside: If True, ignore external links which are not children",
            "            of the base url.",
            "        exclude_prefixes: Exclude any URLs that start with one of these prefixes.",
            "",
            "    Returns:",
            "        List[str]: sub links",
            "    \"\"\"",
            "    base_url = base_url if base_url is not None else url",
            "    all_links = find_all_links(raw_html, pattern=pattern)",
            "    absolute_paths = set()",
            "    for link in all_links:",
            "        # Some may be absolute links like https://to/path",
            "        if link.startswith(\"http\"):",
            "            absolute_paths.add(link)",
            "        # Some may have omitted the protocol like //to/path",
            "        elif link.startswith(\"//\"):",
            "            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")",
            "        else:",
            "            absolute_paths.add(urljoin(url, link))",
            "    res = []",
            "    for path in absolute_paths:",
            "        if any(path.startswith(exclude) for exclude in exclude_prefixes):",
            "            continue",
            "        if prevent_outside and not path.startswith(base_url):",
            "            continue",
            "        res.append(path)",
            "    return res"
        ],
        "afterPatchFile": [
            "import re",
            "from typing import List, Optional, Sequence, Union",
            "from urllib.parse import urljoin, urlparse",
            "",
            "PREFIXES_TO_IGNORE = (\"javascript:\", \"mailto:\", \"#\")",
            "SUFFIXES_TO_IGNORE = (",
            "    \".css\",",
            "    \".js\",",
            "    \".ico\",",
            "    \".png\",",
            "    \".jpg\",",
            "    \".jpeg\",",
            "    \".gif\",",
            "    \".svg\",",
            "    \".csv\",",
            "    \".bz2\",",
            "    \".zip\",",
            "    \".epub\",",
            ")",
            "SUFFIXES_TO_IGNORE_REGEX = (",
            "    \"(?!\" + \"|\".join([re.escape(s) + r\"[\\#'\\\"]\" for s in SUFFIXES_TO_IGNORE]) + \")\"",
            ")",
            "PREFIXES_TO_IGNORE_REGEX = (",
            "    \"(?!\" + \"|\".join([re.escape(s) for s in PREFIXES_TO_IGNORE]) + \")\"",
            ")",
            "DEFAULT_LINK_REGEX = (",
            "    rf\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)[\\#'\\\"]\"",
            ")",
            "",
            "",
            "def find_all_links(",
            "    raw_html: str, *, pattern: Union[str, re.Pattern, None] = None",
            ") -> List[str]:",
            "    \"\"\"Extract all links from a raw html string.",
            "",
            "    Args:",
            "        raw_html: original html.",
            "        pattern: Regex to use for extracting links from raw html.",
            "",
            "    Returns:",
            "        List[str]: all links",
            "    \"\"\"",
            "    pattern = pattern or DEFAULT_LINK_REGEX",
            "    return list(set(re.findall(pattern, raw_html)))",
            "",
            "",
            "def extract_sub_links(",
            "    raw_html: str,",
            "    url: str,",
            "    *,",
            "    base_url: Optional[str] = None,",
            "    pattern: Union[str, re.Pattern, None] = None,",
            "    prevent_outside: bool = True,",
            "    exclude_prefixes: Sequence[str] = (),",
            ") -> List[str]:",
            "    \"\"\"Extract all links from a raw html string and convert into absolute paths.",
            "",
            "    Args:",
            "        raw_html: original html.",
            "        url: the url of the html.",
            "        base_url: the base url to check for outside links against.",
            "        pattern: Regex to use for extracting links from raw html.",
            "        prevent_outside: If True, ignore external links which are not children",
            "            of the base url.",
            "        exclude_prefixes: Exclude any URLs that start with one of these prefixes.",
            "",
            "    Returns:",
            "        List[str]: sub links",
            "    \"\"\"",
            "    base_url_to_use = base_url if base_url is not None else url",
            "    parsed_base_url = urlparse(base_url_to_use)",
            "    all_links = find_all_links(raw_html, pattern=pattern)",
            "    absolute_paths = set()",
            "    for link in all_links:",
            "        parsed_link = urlparse(link)",
            "        # Some may be absolute links like https://to/path",
            "        if parsed_link.scheme == \"http\" or parsed_link.scheme == \"https\":",
            "            absolute_path = link",
            "        # Some may have omitted the protocol like //to/path",
            "        elif link.startswith(\"//\"):",
            "            absolute_path = f\"{urlparse(url).scheme}:{link}\"",
            "        else:",
            "            absolute_path = urljoin(url, parsed_link.path)",
            "        absolute_paths.add(absolute_path)",
            "",
            "    results = []",
            "    for path in absolute_paths:",
            "        if any(path.startswith(exclude_prefix) for exclude_prefix in exclude_prefixes):",
            "            continue",
            "",
            "        if prevent_outside:",
            "            parsed_path = urlparse(path)",
            "",
            "            if parsed_base_url.netloc != parsed_path.netloc:",
            "                continue",
            "",
            "            # Will take care of verifying rest of path after netloc",
            "            # if it's more specific",
            "            if not path.startswith(base_url_to_use):",
            "                continue",
            "",
            "        results.append(path)",
            "    return results"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "70": [
                "extract_sub_links"
            ],
            "75": [
                "extract_sub_links"
            ],
            "76": [
                "extract_sub_links"
            ],
            "79": [
                "extract_sub_links"
            ],
            "81": [
                "extract_sub_links"
            ],
            "82": [
                "extract_sub_links"
            ],
            "84": [
                "extract_sub_links"
            ],
            "85": [
                "extract_sub_links"
            ],
            "86": [
                "extract_sub_links"
            ],
            "88": [
                "extract_sub_links"
            ],
            "89": [
                "extract_sub_links"
            ]
        },
        "addLocation": []
    },
    "libs/core/tests/unit_tests/utils/test_html.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "         )"
            },
            "1": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "     )"
            },
            "2": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "     assert actual == expected"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+def test_prevent_outside() -> None:"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 162,
                "PatchRowcode": "+    \"\"\"Test that prevent outside compares against full base URL.\"\"\""
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 163,
                "PatchRowcode": "+    html = ("
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 164,
                "PatchRowcode": "+        '<a href=\"https://foobar.comic.com\">BAD</a>'"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 165,
                "PatchRowcode": "+        '<a href=\"https://foobar.comic:9999\">BAD</a>'"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 166,
                "PatchRowcode": "+        '<a href=\"https://foobar.com:9999\">BAD</a>'"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+        '<a href=\"http://foobar.com:9999/\">BAD</a>'"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 168,
                "PatchRowcode": "+        '<a href=\"https://foobar.com/OK\">OK</a>'"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+        '<a href=\"http://foobar.com/BAD\">BAD</a>'  # Change in scheme is not OK here"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+    )"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+    expected = sorted("
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 173,
                "PatchRowcode": "+        ["
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+            \"https://foobar.com/OK\","
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+        ]"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 176,
                "PatchRowcode": "+    )"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 177,
                "PatchRowcode": "+    actual = sorted("
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 178,
                "PatchRowcode": "+        extract_sub_links("
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 179,
                "PatchRowcode": "+            html,"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+            \"https://foobar.com/hello/bill.html\","
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+            base_url=\"https://foobar.com\","
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+            prevent_outside=True,"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+        )"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+    )"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+    assert actual == expected"
            }
        },
        "frontPatchFile": [
            "from langchain_core.utils.html import (",
            "    PREFIXES_TO_IGNORE,",
            "    SUFFIXES_TO_IGNORE,",
            "    extract_sub_links,",
            "    find_all_links,",
            ")",
            "",
            "",
            "def test_find_all_links_none() -> None:",
            "    html = \"<span>Hello world</span>\"",
            "    actual = find_all_links(html)",
            "    assert actual == []",
            "",
            "",
            "def test_find_all_links_single() -> None:",
            "    htmls = [",
            "        \"href='foobar.com'\",",
            "        'href=\"foobar.com\"',",
            "        '<div><a class=\"blah\" href=\"foobar.com\">hullo</a></div>',",
            "    ]",
            "    actual = [find_all_links(html) for html in htmls]",
            "    assert actual == [[\"foobar.com\"]] * 3",
            "",
            "",
            "def test_find_all_links_multiple() -> None:",
            "    html = (",
            "        '<div><a class=\"blah\" href=\"https://foobar.com\">hullo</a></div>'",
            "        '<div><a class=\"bleh\" href=\"/baz/cool\">buhbye</a></div>'",
            "    )",
            "    actual = find_all_links(html)",
            "    assert sorted(actual) == [",
            "        \"/baz/cool\",",
            "        \"https://foobar.com\",",
            "    ]",
            "",
            "",
            "def test_find_all_links_ignore_suffix() -> None:",
            "    html = 'href=\"foobar{suffix}\"'",
            "    for suffix in SUFFIXES_TO_IGNORE:",
            "        actual = find_all_links(html.format(suffix=suffix))",
            "        assert actual == []",
            "",
            "    # Don't ignore if pattern doesn't occur at end of link.",
            "    html = 'href=\"foobar{suffix}more\"'",
            "    for suffix in SUFFIXES_TO_IGNORE:",
            "        actual = find_all_links(html.format(suffix=suffix))",
            "        assert actual == [f\"foobar{suffix}more\"]",
            "",
            "",
            "def test_find_all_links_ignore_prefix() -> None:",
            "    html = 'href=\"{prefix}foobar\"'",
            "    for prefix in PREFIXES_TO_IGNORE:",
            "        actual = find_all_links(html.format(prefix=prefix))",
            "        assert actual == []",
            "",
            "    # Don't ignore if pattern doesn't occur at beginning of link.",
            "    html = 'href=\"foobar{prefix}more\"'",
            "    for prefix in PREFIXES_TO_IGNORE:",
            "        # Pound signs are split on when not prefixes.",
            "        if prefix == \"#\":",
            "            continue",
            "        actual = find_all_links(html.format(prefix=prefix))",
            "        assert actual == [f\"foobar{prefix}more\"]",
            "",
            "",
            "def test_find_all_links_drop_fragment() -> None:",
            "    html = 'href=\"foobar.com/woah#section_one\"'",
            "    actual = find_all_links(html)",
            "    assert actual == [\"foobar.com/woah\"]",
            "",
            "",
            "def test_extract_sub_links() -> None:",
            "    html = (",
            "        '<a href=\"https://foobar.com\">one</a>'",
            "        '<a href=\"http://baz.net\">two</a>'",
            "        '<a href=\"//foobar.com/hello\">three</a>'",
            "        '<a href=\"/how/are/you/doing\">four</a>'",
            "    )",
            "    expected = sorted(",
            "        [",
            "            \"https://foobar.com\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/how/are/you/doing\",",
            "        ]",
            "    )",
            "    actual = sorted(extract_sub_links(html, \"https://foobar.com\"))",
            "    assert actual == expected",
            "",
            "    actual = extract_sub_links(html, \"https://foobar.com/hello\")",
            "    expected = [\"https://foobar.com/hello\"]",
            "    assert actual == expected",
            "",
            "    actual = sorted(",
            "        extract_sub_links(html, \"https://foobar.com/hello\", prevent_outside=False)",
            "    )",
            "    expected = sorted(",
            "        [",
            "            \"https://foobar.com\",",
            "            \"http://baz.net\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/how/are/you/doing\",",
            "        ]",
            "    )",
            "    assert actual == expected",
            "",
            "",
            "def test_extract_sub_links_base() -> None:",
            "    html = (",
            "        '<a href=\"https://foobar.com\">one</a>'",
            "        '<a href=\"http://baz.net\">two</a>'",
            "        '<a href=\"//foobar.com/hello\">three</a>'",
            "        '<a href=\"/how/are/you/doing\">four</a>'",
            "        '<a href=\"alexis.html\"</a>'",
            "    )",
            "",
            "    expected = sorted(",
            "        [",
            "            \"https://foobar.com\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/how/are/you/doing\",",
            "            \"https://foobar.com/hello/alexis.html\",",
            "        ]",
            "    )",
            "    actual = sorted(",
            "        extract_sub_links(",
            "            html, \"https://foobar.com/hello/bill.html\", base_url=\"https://foobar.com\"",
            "        )",
            "    )",
            "    assert actual == expected",
            "",
            "",
            "def test_extract_sub_links_exclude() -> None:",
            "    html = (",
            "        '<a href=\"https://foobar.com\">one</a>'",
            "        '<a href=\"http://baz.net\">two</a>'",
            "        '<a href=\"//foobar.com/hello\">three</a>'",
            "        '<a href=\"/how/are/you/doing\">four</a>'",
            "        '<a href=\"alexis.html\"</a>'",
            "    )",
            "",
            "    expected = sorted(",
            "        [",
            "            \"http://baz.net\",",
            "            \"https://foobar.com\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/hello/alexis.html\",",
            "        ]",
            "    )",
            "    actual = sorted(",
            "        extract_sub_links(",
            "            html,",
            "            \"https://foobar.com/hello/bill.html\",",
            "            base_url=\"https://foobar.com\",",
            "            prevent_outside=False,",
            "            exclude_prefixes=(\"https://foobar.com/how\", \"http://baz.org\"),",
            "        )",
            "    )",
            "    assert actual == expected"
        ],
        "afterPatchFile": [
            "from langchain_core.utils.html import (",
            "    PREFIXES_TO_IGNORE,",
            "    SUFFIXES_TO_IGNORE,",
            "    extract_sub_links,",
            "    find_all_links,",
            ")",
            "",
            "",
            "def test_find_all_links_none() -> None:",
            "    html = \"<span>Hello world</span>\"",
            "    actual = find_all_links(html)",
            "    assert actual == []",
            "",
            "",
            "def test_find_all_links_single() -> None:",
            "    htmls = [",
            "        \"href='foobar.com'\",",
            "        'href=\"foobar.com\"',",
            "        '<div><a class=\"blah\" href=\"foobar.com\">hullo</a></div>',",
            "    ]",
            "    actual = [find_all_links(html) for html in htmls]",
            "    assert actual == [[\"foobar.com\"]] * 3",
            "",
            "",
            "def test_find_all_links_multiple() -> None:",
            "    html = (",
            "        '<div><a class=\"blah\" href=\"https://foobar.com\">hullo</a></div>'",
            "        '<div><a class=\"bleh\" href=\"/baz/cool\">buhbye</a></div>'",
            "    )",
            "    actual = find_all_links(html)",
            "    assert sorted(actual) == [",
            "        \"/baz/cool\",",
            "        \"https://foobar.com\",",
            "    ]",
            "",
            "",
            "def test_find_all_links_ignore_suffix() -> None:",
            "    html = 'href=\"foobar{suffix}\"'",
            "    for suffix in SUFFIXES_TO_IGNORE:",
            "        actual = find_all_links(html.format(suffix=suffix))",
            "        assert actual == []",
            "",
            "    # Don't ignore if pattern doesn't occur at end of link.",
            "    html = 'href=\"foobar{suffix}more\"'",
            "    for suffix in SUFFIXES_TO_IGNORE:",
            "        actual = find_all_links(html.format(suffix=suffix))",
            "        assert actual == [f\"foobar{suffix}more\"]",
            "",
            "",
            "def test_find_all_links_ignore_prefix() -> None:",
            "    html = 'href=\"{prefix}foobar\"'",
            "    for prefix in PREFIXES_TO_IGNORE:",
            "        actual = find_all_links(html.format(prefix=prefix))",
            "        assert actual == []",
            "",
            "    # Don't ignore if pattern doesn't occur at beginning of link.",
            "    html = 'href=\"foobar{prefix}more\"'",
            "    for prefix in PREFIXES_TO_IGNORE:",
            "        # Pound signs are split on when not prefixes.",
            "        if prefix == \"#\":",
            "            continue",
            "        actual = find_all_links(html.format(prefix=prefix))",
            "        assert actual == [f\"foobar{prefix}more\"]",
            "",
            "",
            "def test_find_all_links_drop_fragment() -> None:",
            "    html = 'href=\"foobar.com/woah#section_one\"'",
            "    actual = find_all_links(html)",
            "    assert actual == [\"foobar.com/woah\"]",
            "",
            "",
            "def test_extract_sub_links() -> None:",
            "    html = (",
            "        '<a href=\"https://foobar.com\">one</a>'",
            "        '<a href=\"http://baz.net\">two</a>'",
            "        '<a href=\"//foobar.com/hello\">three</a>'",
            "        '<a href=\"/how/are/you/doing\">four</a>'",
            "    )",
            "    expected = sorted(",
            "        [",
            "            \"https://foobar.com\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/how/are/you/doing\",",
            "        ]",
            "    )",
            "    actual = sorted(extract_sub_links(html, \"https://foobar.com\"))",
            "    assert actual == expected",
            "",
            "    actual = extract_sub_links(html, \"https://foobar.com/hello\")",
            "    expected = [\"https://foobar.com/hello\"]",
            "    assert actual == expected",
            "",
            "    actual = sorted(",
            "        extract_sub_links(html, \"https://foobar.com/hello\", prevent_outside=False)",
            "    )",
            "    expected = sorted(",
            "        [",
            "            \"https://foobar.com\",",
            "            \"http://baz.net\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/how/are/you/doing\",",
            "        ]",
            "    )",
            "    assert actual == expected",
            "",
            "",
            "def test_extract_sub_links_base() -> None:",
            "    html = (",
            "        '<a href=\"https://foobar.com\">one</a>'",
            "        '<a href=\"http://baz.net\">two</a>'",
            "        '<a href=\"//foobar.com/hello\">three</a>'",
            "        '<a href=\"/how/are/you/doing\">four</a>'",
            "        '<a href=\"alexis.html\"</a>'",
            "    )",
            "",
            "    expected = sorted(",
            "        [",
            "            \"https://foobar.com\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/how/are/you/doing\",",
            "            \"https://foobar.com/hello/alexis.html\",",
            "        ]",
            "    )",
            "    actual = sorted(",
            "        extract_sub_links(",
            "            html, \"https://foobar.com/hello/bill.html\", base_url=\"https://foobar.com\"",
            "        )",
            "    )",
            "    assert actual == expected",
            "",
            "",
            "def test_extract_sub_links_exclude() -> None:",
            "    html = (",
            "        '<a href=\"https://foobar.com\">one</a>'",
            "        '<a href=\"http://baz.net\">two</a>'",
            "        '<a href=\"//foobar.com/hello\">three</a>'",
            "        '<a href=\"/how/are/you/doing\">four</a>'",
            "        '<a href=\"alexis.html\"</a>'",
            "    )",
            "",
            "    expected = sorted(",
            "        [",
            "            \"http://baz.net\",",
            "            \"https://foobar.com\",",
            "            \"https://foobar.com/hello\",",
            "            \"https://foobar.com/hello/alexis.html\",",
            "        ]",
            "    )",
            "    actual = sorted(",
            "        extract_sub_links(",
            "            html,",
            "            \"https://foobar.com/hello/bill.html\",",
            "            base_url=\"https://foobar.com\",",
            "            prevent_outside=False,",
            "            exclude_prefixes=(\"https://foobar.com/how\", \"http://baz.org\"),",
            "        )",
            "    )",
            "    assert actual == expected",
            "",
            "",
            "def test_prevent_outside() -> None:",
            "    \"\"\"Test that prevent outside compares against full base URL.\"\"\"",
            "    html = (",
            "        '<a href=\"https://foobar.comic.com\">BAD</a>'",
            "        '<a href=\"https://foobar.comic:9999\">BAD</a>'",
            "        '<a href=\"https://foobar.com:9999\">BAD</a>'",
            "        '<a href=\"http://foobar.com:9999/\">BAD</a>'",
            "        '<a href=\"https://foobar.com/OK\">OK</a>'",
            "        '<a href=\"http://foobar.com/BAD\">BAD</a>'  # Change in scheme is not OK here",
            "    )",
            "",
            "    expected = sorted(",
            "        [",
            "            \"https://foobar.com/OK\",",
            "        ]",
            "    )",
            "    actual = sorted(",
            "        extract_sub_links(",
            "            html,",
            "            \"https://foobar.com/hello/bill.html\",",
            "            base_url=\"https://foobar.com\",",
            "            prevent_outside=True,",
            "        )",
            "    )",
            "    assert actual == expected"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.pyload.webui.app"
        ]
    }
}