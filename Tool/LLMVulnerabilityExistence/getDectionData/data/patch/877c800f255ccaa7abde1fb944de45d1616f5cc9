{
    "django/db/backends/base/operations.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from django.db.backends import utils"
            },
            "1": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from django.utils import timezone"
            },
            "2": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from django.utils.encoding import force_str"
            },
            "3": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from django.utils.regex_helper import _lazy_re_compile"
            },
            "4": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " class BaseDatabaseOperations:"
            },
            "7": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "     # Prefix for EXPLAIN queries, or None EXPLAIN isn't supported."
            },
            "8": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "     explain_prefix = None"
            },
            "9": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 56,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    extract_trunc_lookup_pattern = _lazy_re_compile(r\"[\\w\\-_()]+\")"
            },
            "11": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "12": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "     def __init__(self, connection):"
            },
            "13": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "         self.connection = connection"
            },
            "14": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "         self._cache = None"
            },
            "15": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 100,
                "PatchRowcode": "         \"\"\""
            },
            "16": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 101,
                "PatchRowcode": "         return \"%s\""
            },
            "17": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 102,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def date_extract_sql(self, lookup_type, field_name):"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+    def date_extract_sql(self, lookup_type, sql, params):"
            },
            "20": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "         \"\"\""
            },
            "21": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "         Given a lookup_type of 'year', 'month', or 'day', return the SQL that"
            },
            "22": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 106,
                "PatchRowcode": "         extracts a value from the given date field field_name."
            },
            "23": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 110,
                "PatchRowcode": "             \"method\""
            },
            "24": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 111,
                "PatchRowcode": "         )"
            },
            "25": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 112,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def date_trunc_sql(self, lookup_type, field_name, tzname=None):"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+    def date_trunc_sql(self, lookup_type, sql, params, tzname=None):"
            },
            "28": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "         \"\"\""
            },
            "29": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "         Given a lookup_type of 'year', 'month', or 'day', return the SQL that"
            },
            "30": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 116,
                "PatchRowcode": "         truncates the given date or datetime field field_name to a date object"
            },
            "31": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "             \"method.\""
            },
            "32": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "         )"
            },
            "33": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 126,
                "PatchRowcode": " "
            },
            "34": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_cast_date_sql(self, field_name, tzname):"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+    def datetime_cast_date_sql(self, sql, params, tzname):"
            },
            "36": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "         \"\"\""
            },
            "37": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "         Return the SQL to cast a datetime value to date value."
            },
            "38": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "         \"\"\""
            },
            "39": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "             \"datetime_cast_date_sql() method.\""
            },
            "40": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "         )"
            },
            "41": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 135,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_cast_time_sql(self, field_name, tzname):"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+    def datetime_cast_time_sql(self, sql, params, tzname):"
            },
            "44": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "         \"\"\""
            },
            "45": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "         Return the SQL to cast a datetime value to time value."
            },
            "46": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "         \"\"\""
            },
            "47": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "             \"datetime_cast_time_sql() method\""
            },
            "48": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "         )"
            },
            "49": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 144,
                "PatchRowcode": " "
            },
            "50": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_extract_sql(self, lookup_type, field_name, tzname):"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+    def datetime_extract_sql(self, lookup_type, sql, params, tzname):"
            },
            "52": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "         \"\"\""
            },
            "53": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "         Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or"
            },
            "54": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "         'second', return the SQL that extracts a value from the given"
            },
            "55": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 153,
                "PatchRowcode": "             \"method\""
            },
            "56": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "         )"
            },
            "57": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 155,
                "PatchRowcode": " "
            },
            "58": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_trunc_sql(self, lookup_type, field_name, tzname):"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 156,
                "PatchRowcode": "+    def datetime_trunc_sql(self, lookup_type, sql, params, tzname):"
            },
            "60": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "         \"\"\""
            },
            "61": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "         Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or"
            },
            "62": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "         'second', return the SQL that truncates the given datetime field"
            },
            "63": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "             \"method\""
            },
            "64": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "         )"
            },
            "65": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 166,
                "PatchRowcode": " "
            },
            "66": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def time_trunc_sql(self, lookup_type, field_name, tzname=None):"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+    def time_trunc_sql(self, lookup_type, sql, params, tzname=None):"
            },
            "68": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "         \"\"\""
            },
            "69": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 169,
                "PatchRowcode": "         Given a lookup_type of 'hour', 'minute' or 'second', return the SQL"
            },
            "70": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "         that truncates the given time or datetime field field_name to a time"
            },
            "71": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "             \"subclasses of BaseDatabaseOperations may require a time_trunc_sql() method\""
            },
            "72": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "         )"
            },
            "73": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 179,
                "PatchRowcode": " "
            },
            "74": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def time_extract_sql(self, lookup_type, field_name):"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+    def time_extract_sql(self, lookup_type, sql, params):"
            },
            "76": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "         \"\"\""
            },
            "77": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "         Given a lookup_type of 'hour', 'minute', or 'second', return the SQL"
            },
            "78": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 183,
                "PatchRowcode": "         that extracts a value from the given time field field_name."
            },
            "79": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "         \"\"\""
            },
            "80": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return self.date_extract_sql(lookup_type, field_name)"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+        return self.date_extract_sql(lookup_type, sql, params)"
            },
            "82": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 186,
                "PatchRowcode": " "
            },
            "83": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 187,
                "PatchRowcode": "     def deferrable_sql(self):"
            },
            "84": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 188,
                "PatchRowcode": "         \"\"\""
            }
        },
        "frontPatchFile": [
            "import datetime",
            "import decimal",
            "from importlib import import_module",
            "",
            "import sqlparse",
            "",
            "from django.conf import settings",
            "from django.db import NotSupportedError, transaction",
            "from django.db.backends import utils",
            "from django.utils import timezone",
            "from django.utils.encoding import force_str",
            "from django.utils.regex_helper import _lazy_re_compile",
            "",
            "",
            "class BaseDatabaseOperations:",
            "    \"\"\"",
            "    Encapsulate backend-specific differences, such as the way a backend",
            "    performs ordering or calculates the ID of a recently-inserted row.",
            "    \"\"\"",
            "",
            "    compiler_module = \"django.db.models.sql.compiler\"",
            "",
            "    # Integer field safe ranges by `internal_type` as documented",
            "    # in docs/ref/models/fields.txt.",
            "    integer_field_ranges = {",
            "        \"SmallIntegerField\": (-32768, 32767),",
            "        \"IntegerField\": (-2147483648, 2147483647),",
            "        \"BigIntegerField\": (-9223372036854775808, 9223372036854775807),",
            "        \"PositiveBigIntegerField\": (0, 9223372036854775807),",
            "        \"PositiveSmallIntegerField\": (0, 32767),",
            "        \"PositiveIntegerField\": (0, 2147483647),",
            "        \"SmallAutoField\": (-32768, 32767),",
            "        \"AutoField\": (-2147483648, 2147483647),",
            "        \"BigAutoField\": (-9223372036854775808, 9223372036854775807),",
            "    }",
            "    set_operators = {",
            "        \"union\": \"UNION\",",
            "        \"intersection\": \"INTERSECT\",",
            "        \"difference\": \"EXCEPT\",",
            "    }",
            "    # Mapping of Field.get_internal_type() (typically the model field's class",
            "    # name) to the data type to use for the Cast() function, if different from",
            "    # DatabaseWrapper.data_types.",
            "    cast_data_types = {}",
            "    # CharField data type if the max_length argument isn't provided.",
            "    cast_char_field_without_max_length = None",
            "",
            "    # Start and end points for window expressions.",
            "    PRECEDING = \"PRECEDING\"",
            "    FOLLOWING = \"FOLLOWING\"",
            "    UNBOUNDED_PRECEDING = \"UNBOUNDED \" + PRECEDING",
            "    UNBOUNDED_FOLLOWING = \"UNBOUNDED \" + FOLLOWING",
            "    CURRENT_ROW = \"CURRENT ROW\"",
            "",
            "    # Prefix for EXPLAIN queries, or None EXPLAIN isn't supported.",
            "    explain_prefix = None",
            "",
            "    extract_trunc_lookup_pattern = _lazy_re_compile(r\"[\\w\\-_()]+\")",
            "",
            "    def __init__(self, connection):",
            "        self.connection = connection",
            "        self._cache = None",
            "",
            "    def autoinc_sql(self, table, column):",
            "        \"\"\"",
            "        Return any SQL needed to support auto-incrementing primary keys, or",
            "        None if no SQL is necessary.",
            "",
            "        This SQL is executed when a table is created.",
            "        \"\"\"",
            "        return None",
            "",
            "    def bulk_batch_size(self, fields, objs):",
            "        \"\"\"",
            "        Return the maximum allowed batch size for the backend. The fields",
            "        are the fields going to be inserted in the batch, the objs contains",
            "        all the objects to be inserted.",
            "        \"\"\"",
            "        return len(objs)",
            "",
            "    def format_for_duration_arithmetic(self, sql):",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a \"",
            "            \"format_for_duration_arithmetic() method.\"",
            "        )",
            "",
            "    def cache_key_culling_sql(self):",
            "        \"\"\"",
            "        Return an SQL query that retrieves the first cache key greater than the",
            "        n smallest.",
            "",
            "        This is used by the 'db' cache backend to determine where to start",
            "        culling.",
            "        \"\"\"",
            "        cache_key = self.quote_name(\"cache_key\")",
            "        return f\"SELECT {cache_key} FROM %s ORDER BY {cache_key} LIMIT 1 OFFSET %%s\"",
            "",
            "    def unification_cast_sql(self, output_field):",
            "        \"\"\"",
            "        Given a field instance, return the SQL that casts the result of a union",
            "        to that type. The resulting string should contain a '%s' placeholder",
            "        for the expression being cast.",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def date_extract_sql(self, lookup_type, field_name):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', or 'day', return the SQL that",
            "        extracts a value from the given date field field_name.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a date_extract_sql() \"",
            "            \"method\"",
            "        )",
            "",
            "    def date_trunc_sql(self, lookup_type, field_name, tzname=None):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', or 'day', return the SQL that",
            "        truncates the given date or datetime field field_name to a date object",
            "        with only the given specificity.",
            "",
            "        If `tzname` is provided, the given value is truncated in a specific",
            "        timezone.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a date_trunc_sql() \"",
            "            \"method.\"",
            "        )",
            "",
            "    def datetime_cast_date_sql(self, field_name, tzname):",
            "        \"\"\"",
            "        Return the SQL to cast a datetime value to date value.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a \"",
            "            \"datetime_cast_date_sql() method.\"",
            "        )",
            "",
            "    def datetime_cast_time_sql(self, field_name, tzname):",
            "        \"\"\"",
            "        Return the SQL to cast a datetime value to time value.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a \"",
            "            \"datetime_cast_time_sql() method\"",
            "        )",
            "",
            "    def datetime_extract_sql(self, lookup_type, field_name, tzname):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or",
            "        'second', return the SQL that extracts a value from the given",
            "        datetime field field_name.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a datetime_extract_sql() \"",
            "            \"method\"",
            "        )",
            "",
            "    def datetime_trunc_sql(self, lookup_type, field_name, tzname):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or",
            "        'second', return the SQL that truncates the given datetime field",
            "        field_name to a datetime object with only the given specificity.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a datetime_trunc_sql() \"",
            "            \"method\"",
            "        )",
            "",
            "    def time_trunc_sql(self, lookup_type, field_name, tzname=None):",
            "        \"\"\"",
            "        Given a lookup_type of 'hour', 'minute' or 'second', return the SQL",
            "        that truncates the given time or datetime field field_name to a time",
            "        object with only the given specificity.",
            "",
            "        If `tzname` is provided, the given value is truncated in a specific",
            "        timezone.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a time_trunc_sql() method\"",
            "        )",
            "",
            "    def time_extract_sql(self, lookup_type, field_name):",
            "        \"\"\"",
            "        Given a lookup_type of 'hour', 'minute', or 'second', return the SQL",
            "        that extracts a value from the given time field field_name.",
            "        \"\"\"",
            "        return self.date_extract_sql(lookup_type, field_name)",
            "",
            "    def deferrable_sql(self):",
            "        \"\"\"",
            "        Return the SQL to make a constraint \"initially deferred\" during a",
            "        CREATE TABLE statement.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def distinct_sql(self, fields, params):",
            "        \"\"\"",
            "        Return an SQL DISTINCT clause which removes duplicate rows from the",
            "        result set. If any fields are given, only check the given fields for",
            "        duplicates.",
            "        \"\"\"",
            "        if fields:",
            "            raise NotSupportedError(",
            "                \"DISTINCT ON fields is not supported by this database backend\"",
            "            )",
            "        else:",
            "            return [\"DISTINCT\"], []",
            "",
            "    def fetch_returned_insert_columns(self, cursor, returning_params):",
            "        \"\"\"",
            "        Given a cursor object that has just performed an INSERT...RETURNING",
            "        statement into a table, return the newly created data.",
            "        \"\"\"",
            "        return cursor.fetchone()",
            "",
            "    def field_cast_sql(self, db_type, internal_type):",
            "        \"\"\"",
            "        Given a column type (e.g. 'BLOB', 'VARCHAR') and an internal type",
            "        (e.g. 'GenericIPAddressField'), return the SQL to cast it before using",
            "        it in a WHERE statement. The resulting string should contain a '%s'",
            "        placeholder for the column being searched against.",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def force_no_ordering(self):",
            "        \"\"\"",
            "        Return a list used in the \"ORDER BY\" clause to force no ordering at",
            "        all. Return an empty list to include nothing in the ordering.",
            "        \"\"\"",
            "        return []",
            "",
            "    def for_update_sql(self, nowait=False, skip_locked=False, of=(), no_key=False):",
            "        \"\"\"",
            "        Return the FOR UPDATE SQL clause to lock rows for an update operation.",
            "        \"\"\"",
            "        return \"FOR%s UPDATE%s%s%s\" % (",
            "            \" NO KEY\" if no_key else \"\",",
            "            \" OF %s\" % \", \".join(of) if of else \"\",",
            "            \" NOWAIT\" if nowait else \"\",",
            "            \" SKIP LOCKED\" if skip_locked else \"\",",
            "        )",
            "",
            "    def _get_limit_offset_params(self, low_mark, high_mark):",
            "        offset = low_mark or 0",
            "        if high_mark is not None:",
            "            return (high_mark - offset), offset",
            "        elif offset:",
            "            return self.connection.ops.no_limit_value(), offset",
            "        return None, offset",
            "",
            "    def limit_offset_sql(self, low_mark, high_mark):",
            "        \"\"\"Return LIMIT/OFFSET SQL clause.\"\"\"",
            "        limit, offset = self._get_limit_offset_params(low_mark, high_mark)",
            "        return \" \".join(",
            "            sql",
            "            for sql in (",
            "                (\"LIMIT %d\" % limit) if limit else None,",
            "                (\"OFFSET %d\" % offset) if offset else None,",
            "            )",
            "            if sql",
            "        )",
            "",
            "    def last_executed_query(self, cursor, sql, params):",
            "        \"\"\"",
            "        Return a string of the query last executed by the given cursor, with",
            "        placeholders replaced with actual values.",
            "",
            "        `sql` is the raw query containing placeholders and `params` is the",
            "        sequence of parameters. These are used by default, but this method",
            "        exists for database backends to provide a better implementation",
            "        according to their own quoting schemes.",
            "        \"\"\"",
            "        # Convert params to contain string values.",
            "        def to_string(s):",
            "            return force_str(s, strings_only=True, errors=\"replace\")",
            "",
            "        if isinstance(params, (list, tuple)):",
            "            u_params = tuple(to_string(val) for val in params)",
            "        elif params is None:",
            "            u_params = ()",
            "        else:",
            "            u_params = {to_string(k): to_string(v) for k, v in params.items()}",
            "",
            "        return \"QUERY = %r - PARAMS = %r\" % (sql, u_params)",
            "",
            "    def last_insert_id(self, cursor, table_name, pk_name):",
            "        \"\"\"",
            "        Given a cursor object that has just performed an INSERT statement into",
            "        a table that has an auto-incrementing ID, return the newly created ID.",
            "",
            "        `pk_name` is the name of the primary-key column.",
            "        \"\"\"",
            "        return cursor.lastrowid",
            "",
            "    def lookup_cast(self, lookup_type, internal_type=None):",
            "        \"\"\"",
            "        Return the string to use in a query when performing lookups",
            "        (\"contains\", \"like\", etc.). It should contain a '%s' placeholder for",
            "        the column being searched against.",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def max_in_list_size(self):",
            "        \"\"\"",
            "        Return the maximum number of items that can be passed in a single 'IN'",
            "        list condition, or None if the backend does not impose a limit.",
            "        \"\"\"",
            "        return None",
            "",
            "    def max_name_length(self):",
            "        \"\"\"",
            "        Return the maximum length of table and column names, or None if there",
            "        is no limit.",
            "        \"\"\"",
            "        return None",
            "",
            "    def no_limit_value(self):",
            "        \"\"\"",
            "        Return the value to use for the LIMIT when we are wanting \"LIMIT",
            "        infinity\". Return None if the limit clause can be omitted in this case.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a no_limit_value() method\"",
            "        )",
            "",
            "    def pk_default_value(self):",
            "        \"\"\"",
            "        Return the value to use during an INSERT statement to specify that",
            "        the field should use its default value.",
            "        \"\"\"",
            "        return \"DEFAULT\"",
            "",
            "    def prepare_sql_script(self, sql):",
            "        \"\"\"",
            "        Take an SQL script that may contain multiple lines and return a list",
            "        of statements to feed to successive cursor.execute() calls.",
            "",
            "        Since few databases are able to process raw SQL scripts in a single",
            "        cursor.execute() call and PEP 249 doesn't talk about this use case,",
            "        the default implementation is conservative.",
            "        \"\"\"",
            "        return [",
            "            sqlparse.format(statement, strip_comments=True)",
            "            for statement in sqlparse.split(sql)",
            "            if statement",
            "        ]",
            "",
            "    def process_clob(self, value):",
            "        \"\"\"",
            "        Return the value of a CLOB column, for backends that return a locator",
            "        object that requires additional processing.",
            "        \"\"\"",
            "        return value",
            "",
            "    def return_insert_columns(self, fields):",
            "        \"\"\"",
            "        For backends that support returning columns as part of an insert query,",
            "        return the SQL and params to append to the INSERT query. The returned",
            "        fragment should contain a format string to hold the appropriate column.",
            "        \"\"\"",
            "        pass",
            "",
            "    def compiler(self, compiler_name):",
            "        \"\"\"",
            "        Return the SQLCompiler class corresponding to the given name,",
            "        in the namespace corresponding to the `compiler_module` attribute",
            "        on this backend.",
            "        \"\"\"",
            "        if self._cache is None:",
            "            self._cache = import_module(self.compiler_module)",
            "        return getattr(self._cache, compiler_name)",
            "",
            "    def quote_name(self, name):",
            "        \"\"\"",
            "        Return a quoted version of the given table, index, or column name. Do",
            "        not quote the given name if it's already been quoted.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a quote_name() method\"",
            "        )",
            "",
            "    def regex_lookup(self, lookup_type):",
            "        \"\"\"",
            "        Return the string to use in a query when performing regular expression",
            "        lookups (using \"regex\" or \"iregex\"). It should contain a '%s'",
            "        placeholder for the column being searched against.",
            "",
            "        If the feature is not supported (or part of it is not supported), raise",
            "        NotImplementedError.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a regex_lookup() method\"",
            "        )",
            "",
            "    def savepoint_create_sql(self, sid):",
            "        \"\"\"",
            "        Return the SQL for starting a new savepoint. Only required if the",
            "        \"uses_savepoints\" feature is True. The \"sid\" parameter is a string",
            "        for the savepoint id.",
            "        \"\"\"",
            "        return \"SAVEPOINT %s\" % self.quote_name(sid)",
            "",
            "    def savepoint_commit_sql(self, sid):",
            "        \"\"\"",
            "        Return the SQL for committing the given savepoint.",
            "        \"\"\"",
            "        return \"RELEASE SAVEPOINT %s\" % self.quote_name(sid)",
            "",
            "    def savepoint_rollback_sql(self, sid):",
            "        \"\"\"",
            "        Return the SQL for rolling back the given savepoint.",
            "        \"\"\"",
            "        return \"ROLLBACK TO SAVEPOINT %s\" % self.quote_name(sid)",
            "",
            "    def set_time_zone_sql(self):",
            "        \"\"\"",
            "        Return the SQL that will set the connection's time zone.",
            "",
            "        Return '' if the backend doesn't support time zones.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
            "        \"\"\"",
            "        Return a list of SQL statements required to remove all data from",
            "        the given database tables (without actually removing the tables",
            "        themselves).",
            "",
            "        The `style` argument is a Style object as returned by either",
            "        color_style() or no_style() in django.core.management.color.",
            "",
            "        If `reset_sequences` is True, the list includes SQL statements required",
            "        to reset the sequences.",
            "",
            "        The `allow_cascade` argument determines whether truncation may cascade",
            "        to tables with foreign keys pointing the tables being truncated.",
            "        PostgreSQL requires a cascade even if these tables are empty.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations must provide an sql_flush() method\"",
            "        )",
            "",
            "    def execute_sql_flush(self, sql_list):",
            "        \"\"\"Execute a list of SQL statements to flush the database.\"\"\"",
            "        with transaction.atomic(",
            "            using=self.connection.alias,",
            "            savepoint=self.connection.features.can_rollback_ddl,",
            "        ):",
            "            with self.connection.cursor() as cursor:",
            "                for sql in sql_list:",
            "                    cursor.execute(sql)",
            "",
            "    def sequence_reset_by_name_sql(self, style, sequences):",
            "        \"\"\"",
            "        Return a list of the SQL statements required to reset sequences",
            "        passed in `sequences`.",
            "",
            "        The `style` argument is a Style object as returned by either",
            "        color_style() or no_style() in django.core.management.color.",
            "        \"\"\"",
            "        return []",
            "",
            "    def sequence_reset_sql(self, style, model_list):",
            "        \"\"\"",
            "        Return a list of the SQL statements required to reset sequences for",
            "        the given models.",
            "",
            "        The `style` argument is a Style object as returned by either",
            "        color_style() or no_style() in django.core.management.color.",
            "        \"\"\"",
            "        return []  # No sequence reset required by default.",
            "",
            "    def start_transaction_sql(self):",
            "        \"\"\"Return the SQL statement required to start a transaction.\"\"\"",
            "        return \"BEGIN;\"",
            "",
            "    def end_transaction_sql(self, success=True):",
            "        \"\"\"Return the SQL statement required to end a transaction.\"\"\"",
            "        if not success:",
            "            return \"ROLLBACK;\"",
            "        return \"COMMIT;\"",
            "",
            "    def tablespace_sql(self, tablespace, inline=False):",
            "        \"\"\"",
            "        Return the SQL that will be used in a query to define the tablespace.",
            "",
            "        Return '' if the backend doesn't support tablespaces.",
            "",
            "        If `inline` is True, append the SQL to a row; otherwise append it to",
            "        the entire CREATE TABLE or CREATE INDEX statement.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def prep_for_like_query(self, x):",
            "        \"\"\"Prepare a value for use in a LIKE query.\"\"\"",
            "        return str(x).replace(\"\\\\\", \"\\\\\\\\\").replace(\"%\", r\"\\%\").replace(\"_\", r\"\\_\")",
            "",
            "    # Same as prep_for_like_query(), but called for \"iexact\" matches, which",
            "    # need not necessarily be implemented using \"LIKE\" in the backend.",
            "    prep_for_iexact_query = prep_for_like_query",
            "",
            "    def validate_autopk_value(self, value):",
            "        \"\"\"",
            "        Certain backends do not accept some values for \"serial\" fields",
            "        (for example zero in MySQL). Raise a ValueError if the value is",
            "        invalid, otherwise return the validated value.",
            "        \"\"\"",
            "        return value",
            "",
            "    def adapt_unknown_value(self, value):",
            "        \"\"\"",
            "        Transform a value to something compatible with the backend driver.",
            "",
            "        This method only depends on the type of the value. It's designed for",
            "        cases where the target type isn't known, such as .raw() SQL queries.",
            "        As a consequence it may not work perfectly in all circumstances.",
            "        \"\"\"",
            "        if isinstance(value, datetime.datetime):  # must be before date",
            "            return self.adapt_datetimefield_value(value)",
            "        elif isinstance(value, datetime.date):",
            "            return self.adapt_datefield_value(value)",
            "        elif isinstance(value, datetime.time):",
            "            return self.adapt_timefield_value(value)",
            "        elif isinstance(value, decimal.Decimal):",
            "            return self.adapt_decimalfield_value(value)",
            "        else:",
            "            return value",
            "",
            "    def adapt_datefield_value(self, value):",
            "        \"\"\"",
            "        Transform a date value to an object compatible with what is expected",
            "        by the backend driver for date columns.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        return str(value)",
            "",
            "    def adapt_datetimefield_value(self, value):",
            "        \"\"\"",
            "        Transform a datetime value to an object compatible with what is expected",
            "        by the backend driver for datetime columns.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        return str(value)",
            "",
            "    def adapt_timefield_value(self, value):",
            "        \"\"\"",
            "        Transform a time value to an object compatible with what is expected",
            "        by the backend driver for time columns.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        if timezone.is_aware(value):",
            "            raise ValueError(\"Django does not support timezone-aware times.\")",
            "        return str(value)",
            "",
            "    def adapt_decimalfield_value(self, value, max_digits=None, decimal_places=None):",
            "        \"\"\"",
            "        Transform a decimal.Decimal value to an object compatible with what is",
            "        expected by the backend driver for decimal (numeric) columns.",
            "        \"\"\"",
            "        return utils.format_number(value, max_digits, decimal_places)",
            "",
            "    def adapt_ipaddressfield_value(self, value):",
            "        \"\"\"",
            "        Transform a string representation of an IP address into the expected",
            "        type for the backend driver.",
            "        \"\"\"",
            "        return value or None",
            "",
            "    def year_lookup_bounds_for_date_field(self, value, iso_year=False):",
            "        \"\"\"",
            "        Return a two-elements list with the lower and upper bound to be used",
            "        with a BETWEEN operator to query a DateField value using a year",
            "        lookup.",
            "",
            "        `value` is an int, containing the looked-up year.",
            "        If `iso_year` is True, return bounds for ISO-8601 week-numbering years.",
            "        \"\"\"",
            "        if iso_year:",
            "            first = datetime.date.fromisocalendar(value, 1, 1)",
            "            second = datetime.date.fromisocalendar(",
            "                value + 1, 1, 1",
            "            ) - datetime.timedelta(days=1)",
            "        else:",
            "            first = datetime.date(value, 1, 1)",
            "            second = datetime.date(value, 12, 31)",
            "        first = self.adapt_datefield_value(first)",
            "        second = self.adapt_datefield_value(second)",
            "        return [first, second]",
            "",
            "    def year_lookup_bounds_for_datetime_field(self, value, iso_year=False):",
            "        \"\"\"",
            "        Return a two-elements list with the lower and upper bound to be used",
            "        with a BETWEEN operator to query a DateTimeField value using a year",
            "        lookup.",
            "",
            "        `value` is an int, containing the looked-up year.",
            "        If `iso_year` is True, return bounds for ISO-8601 week-numbering years.",
            "        \"\"\"",
            "        if iso_year:",
            "            first = datetime.datetime.fromisocalendar(value, 1, 1)",
            "            second = datetime.datetime.fromisocalendar(",
            "                value + 1, 1, 1",
            "            ) - datetime.timedelta(microseconds=1)",
            "        else:",
            "            first = datetime.datetime(value, 1, 1)",
            "            second = datetime.datetime(value, 12, 31, 23, 59, 59, 999999)",
            "        if settings.USE_TZ:",
            "            tz = timezone.get_current_timezone()",
            "            first = timezone.make_aware(first, tz)",
            "            second = timezone.make_aware(second, tz)",
            "        first = self.adapt_datetimefield_value(first)",
            "        second = self.adapt_datetimefield_value(second)",
            "        return [first, second]",
            "",
            "    def get_db_converters(self, expression):",
            "        \"\"\"",
            "        Return a list of functions needed to convert field data.",
            "",
            "        Some field types on some backends do not provide data in the correct",
            "        format, this is the hook for converter functions.",
            "        \"\"\"",
            "        return []",
            "",
            "    def convert_durationfield_value(self, value, expression, connection):",
            "        if value is not None:",
            "            return datetime.timedelta(0, 0, value)",
            "",
            "    def check_expression_support(self, expression):",
            "        \"\"\"",
            "        Check that the backend supports the provided expression.",
            "",
            "        This is used on specific backends to rule out known expressions",
            "        that have problematic or nonexistent implementations. If the",
            "        expression has a known problem, the backend should raise",
            "        NotSupportedError.",
            "        \"\"\"",
            "        pass",
            "",
            "    def conditional_expression_supported_in_where_clause(self, expression):",
            "        \"\"\"",
            "        Return True, if the conditional expression is supported in the WHERE",
            "        clause.",
            "        \"\"\"",
            "        return True",
            "",
            "    def combine_expression(self, connector, sub_expressions):",
            "        \"\"\"",
            "        Combine a list of subexpressions into a single expression, using",
            "        the provided connecting operator. This is required because operators",
            "        can vary between backends (e.g., Oracle with %% and &) and between",
            "        subexpression types (e.g., date expressions).",
            "        \"\"\"",
            "        conn = \" %s \" % connector",
            "        return conn.join(sub_expressions)",
            "",
            "    def combine_duration_expression(self, connector, sub_expressions):",
            "        return self.combine_expression(connector, sub_expressions)",
            "",
            "    def binary_placeholder_sql(self, value):",
            "        \"\"\"",
            "        Some backends require special syntax to insert binary content (MySQL",
            "        for example uses '_binary %s').",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def modify_insert_params(self, placeholder, params):",
            "        \"\"\"",
            "        Allow modification of insert parameters. Needed for Oracle Spatial",
            "        backend due to #10888.",
            "        \"\"\"",
            "        return params",
            "",
            "    def integer_field_range(self, internal_type):",
            "        \"\"\"",
            "        Given an integer field internal type (e.g. 'PositiveIntegerField'),",
            "        return a tuple of the (min_value, max_value) form representing the",
            "        range of the column type bound to the field.",
            "        \"\"\"",
            "        return self.integer_field_ranges[internal_type]",
            "",
            "    def subtract_temporals(self, internal_type, lhs, rhs):",
            "        if self.connection.features.supports_temporal_subtraction:",
            "            lhs_sql, lhs_params = lhs",
            "            rhs_sql, rhs_params = rhs",
            "            return \"(%s - %s)\" % (lhs_sql, rhs_sql), (*lhs_params, *rhs_params)",
            "        raise NotSupportedError(",
            "            \"This backend does not support %s subtraction.\" % internal_type",
            "        )",
            "",
            "    def window_frame_start(self, start):",
            "        if isinstance(start, int):",
            "            if start < 0:",
            "                return \"%d %s\" % (abs(start), self.PRECEDING)",
            "            elif start == 0:",
            "                return self.CURRENT_ROW",
            "        elif start is None:",
            "            return self.UNBOUNDED_PRECEDING",
            "        raise ValueError(",
            "            \"start argument must be a negative integer, zero, or None, but got '%s'.\"",
            "            % start",
            "        )",
            "",
            "    def window_frame_end(self, end):",
            "        if isinstance(end, int):",
            "            if end == 0:",
            "                return self.CURRENT_ROW",
            "            elif end > 0:",
            "                return \"%d %s\" % (end, self.FOLLOWING)",
            "        elif end is None:",
            "            return self.UNBOUNDED_FOLLOWING",
            "        raise ValueError(",
            "            \"end argument must be a positive integer, zero, or None, but got '%s'.\"",
            "            % end",
            "        )",
            "",
            "    def window_frame_rows_start_end(self, start=None, end=None):",
            "        \"\"\"",
            "        Return SQL for start and end points in an OVER clause window frame.",
            "        \"\"\"",
            "        if not self.connection.features.supports_over_clause:",
            "            raise NotSupportedError(\"This backend does not support window expressions.\")",
            "        return self.window_frame_start(start), self.window_frame_end(end)",
            "",
            "    def window_frame_range_start_end(self, start=None, end=None):",
            "        start_, end_ = self.window_frame_rows_start_end(start, end)",
            "        features = self.connection.features",
            "        if features.only_supports_unbounded_with_preceding_and_following and (",
            "            (start and start < 0) or (end and end > 0)",
            "        ):",
            "            raise NotSupportedError(",
            "                \"%s only supports UNBOUNDED together with PRECEDING and \"",
            "                \"FOLLOWING.\" % self.connection.display_name",
            "            )",
            "        return start_, end_",
            "",
            "    def explain_query_prefix(self, format=None, **options):",
            "        if not self.connection.features.supports_explaining_query_execution:",
            "            raise NotSupportedError(",
            "                \"This backend does not support explaining query execution.\"",
            "            )",
            "        if format:",
            "            supported_formats = self.connection.features.supported_explain_formats",
            "            normalized_format = format.upper()",
            "            if normalized_format not in supported_formats:",
            "                msg = \"%s is not a recognized format.\" % normalized_format",
            "                if supported_formats:",
            "                    msg += \" Allowed formats: %s\" % \", \".join(sorted(supported_formats))",
            "                else:",
            "                    msg += (",
            "                        f\" {self.connection.display_name} does not support any formats.\"",
            "                    )",
            "                raise ValueError(msg)",
            "        if options:",
            "            raise ValueError(\"Unknown options: %s\" % \", \".join(sorted(options.keys())))",
            "        return self.explain_prefix",
            "",
            "    def insert_statement(self, on_conflict=None):",
            "        return \"INSERT INTO\"",
            "",
            "    def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
            "        return \"\""
        ],
        "afterPatchFile": [
            "import datetime",
            "import decimal",
            "from importlib import import_module",
            "",
            "import sqlparse",
            "",
            "from django.conf import settings",
            "from django.db import NotSupportedError, transaction",
            "from django.db.backends import utils",
            "from django.utils import timezone",
            "from django.utils.encoding import force_str",
            "",
            "",
            "class BaseDatabaseOperations:",
            "    \"\"\"",
            "    Encapsulate backend-specific differences, such as the way a backend",
            "    performs ordering or calculates the ID of a recently-inserted row.",
            "    \"\"\"",
            "",
            "    compiler_module = \"django.db.models.sql.compiler\"",
            "",
            "    # Integer field safe ranges by `internal_type` as documented",
            "    # in docs/ref/models/fields.txt.",
            "    integer_field_ranges = {",
            "        \"SmallIntegerField\": (-32768, 32767),",
            "        \"IntegerField\": (-2147483648, 2147483647),",
            "        \"BigIntegerField\": (-9223372036854775808, 9223372036854775807),",
            "        \"PositiveBigIntegerField\": (0, 9223372036854775807),",
            "        \"PositiveSmallIntegerField\": (0, 32767),",
            "        \"PositiveIntegerField\": (0, 2147483647),",
            "        \"SmallAutoField\": (-32768, 32767),",
            "        \"AutoField\": (-2147483648, 2147483647),",
            "        \"BigAutoField\": (-9223372036854775808, 9223372036854775807),",
            "    }",
            "    set_operators = {",
            "        \"union\": \"UNION\",",
            "        \"intersection\": \"INTERSECT\",",
            "        \"difference\": \"EXCEPT\",",
            "    }",
            "    # Mapping of Field.get_internal_type() (typically the model field's class",
            "    # name) to the data type to use for the Cast() function, if different from",
            "    # DatabaseWrapper.data_types.",
            "    cast_data_types = {}",
            "    # CharField data type if the max_length argument isn't provided.",
            "    cast_char_field_without_max_length = None",
            "",
            "    # Start and end points for window expressions.",
            "    PRECEDING = \"PRECEDING\"",
            "    FOLLOWING = \"FOLLOWING\"",
            "    UNBOUNDED_PRECEDING = \"UNBOUNDED \" + PRECEDING",
            "    UNBOUNDED_FOLLOWING = \"UNBOUNDED \" + FOLLOWING",
            "    CURRENT_ROW = \"CURRENT ROW\"",
            "",
            "    # Prefix for EXPLAIN queries, or None EXPLAIN isn't supported.",
            "    explain_prefix = None",
            "",
            "    def __init__(self, connection):",
            "        self.connection = connection",
            "        self._cache = None",
            "",
            "    def autoinc_sql(self, table, column):",
            "        \"\"\"",
            "        Return any SQL needed to support auto-incrementing primary keys, or",
            "        None if no SQL is necessary.",
            "",
            "        This SQL is executed when a table is created.",
            "        \"\"\"",
            "        return None",
            "",
            "    def bulk_batch_size(self, fields, objs):",
            "        \"\"\"",
            "        Return the maximum allowed batch size for the backend. The fields",
            "        are the fields going to be inserted in the batch, the objs contains",
            "        all the objects to be inserted.",
            "        \"\"\"",
            "        return len(objs)",
            "",
            "    def format_for_duration_arithmetic(self, sql):",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a \"",
            "            \"format_for_duration_arithmetic() method.\"",
            "        )",
            "",
            "    def cache_key_culling_sql(self):",
            "        \"\"\"",
            "        Return an SQL query that retrieves the first cache key greater than the",
            "        n smallest.",
            "",
            "        This is used by the 'db' cache backend to determine where to start",
            "        culling.",
            "        \"\"\"",
            "        cache_key = self.quote_name(\"cache_key\")",
            "        return f\"SELECT {cache_key} FROM %s ORDER BY {cache_key} LIMIT 1 OFFSET %%s\"",
            "",
            "    def unification_cast_sql(self, output_field):",
            "        \"\"\"",
            "        Given a field instance, return the SQL that casts the result of a union",
            "        to that type. The resulting string should contain a '%s' placeholder",
            "        for the expression being cast.",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def date_extract_sql(self, lookup_type, sql, params):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', or 'day', return the SQL that",
            "        extracts a value from the given date field field_name.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a date_extract_sql() \"",
            "            \"method\"",
            "        )",
            "",
            "    def date_trunc_sql(self, lookup_type, sql, params, tzname=None):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', or 'day', return the SQL that",
            "        truncates the given date or datetime field field_name to a date object",
            "        with only the given specificity.",
            "",
            "        If `tzname` is provided, the given value is truncated in a specific",
            "        timezone.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a date_trunc_sql() \"",
            "            \"method.\"",
            "        )",
            "",
            "    def datetime_cast_date_sql(self, sql, params, tzname):",
            "        \"\"\"",
            "        Return the SQL to cast a datetime value to date value.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a \"",
            "            \"datetime_cast_date_sql() method.\"",
            "        )",
            "",
            "    def datetime_cast_time_sql(self, sql, params, tzname):",
            "        \"\"\"",
            "        Return the SQL to cast a datetime value to time value.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a \"",
            "            \"datetime_cast_time_sql() method\"",
            "        )",
            "",
            "    def datetime_extract_sql(self, lookup_type, sql, params, tzname):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or",
            "        'second', return the SQL that extracts a value from the given",
            "        datetime field field_name.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a datetime_extract_sql() \"",
            "            \"method\"",
            "        )",
            "",
            "    def datetime_trunc_sql(self, lookup_type, sql, params, tzname):",
            "        \"\"\"",
            "        Given a lookup_type of 'year', 'month', 'day', 'hour', 'minute', or",
            "        'second', return the SQL that truncates the given datetime field",
            "        field_name to a datetime object with only the given specificity.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a datetime_trunc_sql() \"",
            "            \"method\"",
            "        )",
            "",
            "    def time_trunc_sql(self, lookup_type, sql, params, tzname=None):",
            "        \"\"\"",
            "        Given a lookup_type of 'hour', 'minute' or 'second', return the SQL",
            "        that truncates the given time or datetime field field_name to a time",
            "        object with only the given specificity.",
            "",
            "        If `tzname` is provided, the given value is truncated in a specific",
            "        timezone.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a time_trunc_sql() method\"",
            "        )",
            "",
            "    def time_extract_sql(self, lookup_type, sql, params):",
            "        \"\"\"",
            "        Given a lookup_type of 'hour', 'minute', or 'second', return the SQL",
            "        that extracts a value from the given time field field_name.",
            "        \"\"\"",
            "        return self.date_extract_sql(lookup_type, sql, params)",
            "",
            "    def deferrable_sql(self):",
            "        \"\"\"",
            "        Return the SQL to make a constraint \"initially deferred\" during a",
            "        CREATE TABLE statement.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def distinct_sql(self, fields, params):",
            "        \"\"\"",
            "        Return an SQL DISTINCT clause which removes duplicate rows from the",
            "        result set. If any fields are given, only check the given fields for",
            "        duplicates.",
            "        \"\"\"",
            "        if fields:",
            "            raise NotSupportedError(",
            "                \"DISTINCT ON fields is not supported by this database backend\"",
            "            )",
            "        else:",
            "            return [\"DISTINCT\"], []",
            "",
            "    def fetch_returned_insert_columns(self, cursor, returning_params):",
            "        \"\"\"",
            "        Given a cursor object that has just performed an INSERT...RETURNING",
            "        statement into a table, return the newly created data.",
            "        \"\"\"",
            "        return cursor.fetchone()",
            "",
            "    def field_cast_sql(self, db_type, internal_type):",
            "        \"\"\"",
            "        Given a column type (e.g. 'BLOB', 'VARCHAR') and an internal type",
            "        (e.g. 'GenericIPAddressField'), return the SQL to cast it before using",
            "        it in a WHERE statement. The resulting string should contain a '%s'",
            "        placeholder for the column being searched against.",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def force_no_ordering(self):",
            "        \"\"\"",
            "        Return a list used in the \"ORDER BY\" clause to force no ordering at",
            "        all. Return an empty list to include nothing in the ordering.",
            "        \"\"\"",
            "        return []",
            "",
            "    def for_update_sql(self, nowait=False, skip_locked=False, of=(), no_key=False):",
            "        \"\"\"",
            "        Return the FOR UPDATE SQL clause to lock rows for an update operation.",
            "        \"\"\"",
            "        return \"FOR%s UPDATE%s%s%s\" % (",
            "            \" NO KEY\" if no_key else \"\",",
            "            \" OF %s\" % \", \".join(of) if of else \"\",",
            "            \" NOWAIT\" if nowait else \"\",",
            "            \" SKIP LOCKED\" if skip_locked else \"\",",
            "        )",
            "",
            "    def _get_limit_offset_params(self, low_mark, high_mark):",
            "        offset = low_mark or 0",
            "        if high_mark is not None:",
            "            return (high_mark - offset), offset",
            "        elif offset:",
            "            return self.connection.ops.no_limit_value(), offset",
            "        return None, offset",
            "",
            "    def limit_offset_sql(self, low_mark, high_mark):",
            "        \"\"\"Return LIMIT/OFFSET SQL clause.\"\"\"",
            "        limit, offset = self._get_limit_offset_params(low_mark, high_mark)",
            "        return \" \".join(",
            "            sql",
            "            for sql in (",
            "                (\"LIMIT %d\" % limit) if limit else None,",
            "                (\"OFFSET %d\" % offset) if offset else None,",
            "            )",
            "            if sql",
            "        )",
            "",
            "    def last_executed_query(self, cursor, sql, params):",
            "        \"\"\"",
            "        Return a string of the query last executed by the given cursor, with",
            "        placeholders replaced with actual values.",
            "",
            "        `sql` is the raw query containing placeholders and `params` is the",
            "        sequence of parameters. These are used by default, but this method",
            "        exists for database backends to provide a better implementation",
            "        according to their own quoting schemes.",
            "        \"\"\"",
            "        # Convert params to contain string values.",
            "        def to_string(s):",
            "            return force_str(s, strings_only=True, errors=\"replace\")",
            "",
            "        if isinstance(params, (list, tuple)):",
            "            u_params = tuple(to_string(val) for val in params)",
            "        elif params is None:",
            "            u_params = ()",
            "        else:",
            "            u_params = {to_string(k): to_string(v) for k, v in params.items()}",
            "",
            "        return \"QUERY = %r - PARAMS = %r\" % (sql, u_params)",
            "",
            "    def last_insert_id(self, cursor, table_name, pk_name):",
            "        \"\"\"",
            "        Given a cursor object that has just performed an INSERT statement into",
            "        a table that has an auto-incrementing ID, return the newly created ID.",
            "",
            "        `pk_name` is the name of the primary-key column.",
            "        \"\"\"",
            "        return cursor.lastrowid",
            "",
            "    def lookup_cast(self, lookup_type, internal_type=None):",
            "        \"\"\"",
            "        Return the string to use in a query when performing lookups",
            "        (\"contains\", \"like\", etc.). It should contain a '%s' placeholder for",
            "        the column being searched against.",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def max_in_list_size(self):",
            "        \"\"\"",
            "        Return the maximum number of items that can be passed in a single 'IN'",
            "        list condition, or None if the backend does not impose a limit.",
            "        \"\"\"",
            "        return None",
            "",
            "    def max_name_length(self):",
            "        \"\"\"",
            "        Return the maximum length of table and column names, or None if there",
            "        is no limit.",
            "        \"\"\"",
            "        return None",
            "",
            "    def no_limit_value(self):",
            "        \"\"\"",
            "        Return the value to use for the LIMIT when we are wanting \"LIMIT",
            "        infinity\". Return None if the limit clause can be omitted in this case.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a no_limit_value() method\"",
            "        )",
            "",
            "    def pk_default_value(self):",
            "        \"\"\"",
            "        Return the value to use during an INSERT statement to specify that",
            "        the field should use its default value.",
            "        \"\"\"",
            "        return \"DEFAULT\"",
            "",
            "    def prepare_sql_script(self, sql):",
            "        \"\"\"",
            "        Take an SQL script that may contain multiple lines and return a list",
            "        of statements to feed to successive cursor.execute() calls.",
            "",
            "        Since few databases are able to process raw SQL scripts in a single",
            "        cursor.execute() call and PEP 249 doesn't talk about this use case,",
            "        the default implementation is conservative.",
            "        \"\"\"",
            "        return [",
            "            sqlparse.format(statement, strip_comments=True)",
            "            for statement in sqlparse.split(sql)",
            "            if statement",
            "        ]",
            "",
            "    def process_clob(self, value):",
            "        \"\"\"",
            "        Return the value of a CLOB column, for backends that return a locator",
            "        object that requires additional processing.",
            "        \"\"\"",
            "        return value",
            "",
            "    def return_insert_columns(self, fields):",
            "        \"\"\"",
            "        For backends that support returning columns as part of an insert query,",
            "        return the SQL and params to append to the INSERT query. The returned",
            "        fragment should contain a format string to hold the appropriate column.",
            "        \"\"\"",
            "        pass",
            "",
            "    def compiler(self, compiler_name):",
            "        \"\"\"",
            "        Return the SQLCompiler class corresponding to the given name,",
            "        in the namespace corresponding to the `compiler_module` attribute",
            "        on this backend.",
            "        \"\"\"",
            "        if self._cache is None:",
            "            self._cache = import_module(self.compiler_module)",
            "        return getattr(self._cache, compiler_name)",
            "",
            "    def quote_name(self, name):",
            "        \"\"\"",
            "        Return a quoted version of the given table, index, or column name. Do",
            "        not quote the given name if it's already been quoted.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a quote_name() method\"",
            "        )",
            "",
            "    def regex_lookup(self, lookup_type):",
            "        \"\"\"",
            "        Return the string to use in a query when performing regular expression",
            "        lookups (using \"regex\" or \"iregex\"). It should contain a '%s'",
            "        placeholder for the column being searched against.",
            "",
            "        If the feature is not supported (or part of it is not supported), raise",
            "        NotImplementedError.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations may require a regex_lookup() method\"",
            "        )",
            "",
            "    def savepoint_create_sql(self, sid):",
            "        \"\"\"",
            "        Return the SQL for starting a new savepoint. Only required if the",
            "        \"uses_savepoints\" feature is True. The \"sid\" parameter is a string",
            "        for the savepoint id.",
            "        \"\"\"",
            "        return \"SAVEPOINT %s\" % self.quote_name(sid)",
            "",
            "    def savepoint_commit_sql(self, sid):",
            "        \"\"\"",
            "        Return the SQL for committing the given savepoint.",
            "        \"\"\"",
            "        return \"RELEASE SAVEPOINT %s\" % self.quote_name(sid)",
            "",
            "    def savepoint_rollback_sql(self, sid):",
            "        \"\"\"",
            "        Return the SQL for rolling back the given savepoint.",
            "        \"\"\"",
            "        return \"ROLLBACK TO SAVEPOINT %s\" % self.quote_name(sid)",
            "",
            "    def set_time_zone_sql(self):",
            "        \"\"\"",
            "        Return the SQL that will set the connection's time zone.",
            "",
            "        Return '' if the backend doesn't support time zones.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
            "        \"\"\"",
            "        Return a list of SQL statements required to remove all data from",
            "        the given database tables (without actually removing the tables",
            "        themselves).",
            "",
            "        The `style` argument is a Style object as returned by either",
            "        color_style() or no_style() in django.core.management.color.",
            "",
            "        If `reset_sequences` is True, the list includes SQL statements required",
            "        to reset the sequences.",
            "",
            "        The `allow_cascade` argument determines whether truncation may cascade",
            "        to tables with foreign keys pointing the tables being truncated.",
            "        PostgreSQL requires a cascade even if these tables are empty.",
            "        \"\"\"",
            "        raise NotImplementedError(",
            "            \"subclasses of BaseDatabaseOperations must provide an sql_flush() method\"",
            "        )",
            "",
            "    def execute_sql_flush(self, sql_list):",
            "        \"\"\"Execute a list of SQL statements to flush the database.\"\"\"",
            "        with transaction.atomic(",
            "            using=self.connection.alias,",
            "            savepoint=self.connection.features.can_rollback_ddl,",
            "        ):",
            "            with self.connection.cursor() as cursor:",
            "                for sql in sql_list:",
            "                    cursor.execute(sql)",
            "",
            "    def sequence_reset_by_name_sql(self, style, sequences):",
            "        \"\"\"",
            "        Return a list of the SQL statements required to reset sequences",
            "        passed in `sequences`.",
            "",
            "        The `style` argument is a Style object as returned by either",
            "        color_style() or no_style() in django.core.management.color.",
            "        \"\"\"",
            "        return []",
            "",
            "    def sequence_reset_sql(self, style, model_list):",
            "        \"\"\"",
            "        Return a list of the SQL statements required to reset sequences for",
            "        the given models.",
            "",
            "        The `style` argument is a Style object as returned by either",
            "        color_style() or no_style() in django.core.management.color.",
            "        \"\"\"",
            "        return []  # No sequence reset required by default.",
            "",
            "    def start_transaction_sql(self):",
            "        \"\"\"Return the SQL statement required to start a transaction.\"\"\"",
            "        return \"BEGIN;\"",
            "",
            "    def end_transaction_sql(self, success=True):",
            "        \"\"\"Return the SQL statement required to end a transaction.\"\"\"",
            "        if not success:",
            "            return \"ROLLBACK;\"",
            "        return \"COMMIT;\"",
            "",
            "    def tablespace_sql(self, tablespace, inline=False):",
            "        \"\"\"",
            "        Return the SQL that will be used in a query to define the tablespace.",
            "",
            "        Return '' if the backend doesn't support tablespaces.",
            "",
            "        If `inline` is True, append the SQL to a row; otherwise append it to",
            "        the entire CREATE TABLE or CREATE INDEX statement.",
            "        \"\"\"",
            "        return \"\"",
            "",
            "    def prep_for_like_query(self, x):",
            "        \"\"\"Prepare a value for use in a LIKE query.\"\"\"",
            "        return str(x).replace(\"\\\\\", \"\\\\\\\\\").replace(\"%\", r\"\\%\").replace(\"_\", r\"\\_\")",
            "",
            "    # Same as prep_for_like_query(), but called for \"iexact\" matches, which",
            "    # need not necessarily be implemented using \"LIKE\" in the backend.",
            "    prep_for_iexact_query = prep_for_like_query",
            "",
            "    def validate_autopk_value(self, value):",
            "        \"\"\"",
            "        Certain backends do not accept some values for \"serial\" fields",
            "        (for example zero in MySQL). Raise a ValueError if the value is",
            "        invalid, otherwise return the validated value.",
            "        \"\"\"",
            "        return value",
            "",
            "    def adapt_unknown_value(self, value):",
            "        \"\"\"",
            "        Transform a value to something compatible with the backend driver.",
            "",
            "        This method only depends on the type of the value. It's designed for",
            "        cases where the target type isn't known, such as .raw() SQL queries.",
            "        As a consequence it may not work perfectly in all circumstances.",
            "        \"\"\"",
            "        if isinstance(value, datetime.datetime):  # must be before date",
            "            return self.adapt_datetimefield_value(value)",
            "        elif isinstance(value, datetime.date):",
            "            return self.adapt_datefield_value(value)",
            "        elif isinstance(value, datetime.time):",
            "            return self.adapt_timefield_value(value)",
            "        elif isinstance(value, decimal.Decimal):",
            "            return self.adapt_decimalfield_value(value)",
            "        else:",
            "            return value",
            "",
            "    def adapt_datefield_value(self, value):",
            "        \"\"\"",
            "        Transform a date value to an object compatible with what is expected",
            "        by the backend driver for date columns.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        return str(value)",
            "",
            "    def adapt_datetimefield_value(self, value):",
            "        \"\"\"",
            "        Transform a datetime value to an object compatible with what is expected",
            "        by the backend driver for datetime columns.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        return str(value)",
            "",
            "    def adapt_timefield_value(self, value):",
            "        \"\"\"",
            "        Transform a time value to an object compatible with what is expected",
            "        by the backend driver for time columns.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        if timezone.is_aware(value):",
            "            raise ValueError(\"Django does not support timezone-aware times.\")",
            "        return str(value)",
            "",
            "    def adapt_decimalfield_value(self, value, max_digits=None, decimal_places=None):",
            "        \"\"\"",
            "        Transform a decimal.Decimal value to an object compatible with what is",
            "        expected by the backend driver for decimal (numeric) columns.",
            "        \"\"\"",
            "        return utils.format_number(value, max_digits, decimal_places)",
            "",
            "    def adapt_ipaddressfield_value(self, value):",
            "        \"\"\"",
            "        Transform a string representation of an IP address into the expected",
            "        type for the backend driver.",
            "        \"\"\"",
            "        return value or None",
            "",
            "    def year_lookup_bounds_for_date_field(self, value, iso_year=False):",
            "        \"\"\"",
            "        Return a two-elements list with the lower and upper bound to be used",
            "        with a BETWEEN operator to query a DateField value using a year",
            "        lookup.",
            "",
            "        `value` is an int, containing the looked-up year.",
            "        If `iso_year` is True, return bounds for ISO-8601 week-numbering years.",
            "        \"\"\"",
            "        if iso_year:",
            "            first = datetime.date.fromisocalendar(value, 1, 1)",
            "            second = datetime.date.fromisocalendar(",
            "                value + 1, 1, 1",
            "            ) - datetime.timedelta(days=1)",
            "        else:",
            "            first = datetime.date(value, 1, 1)",
            "            second = datetime.date(value, 12, 31)",
            "        first = self.adapt_datefield_value(first)",
            "        second = self.adapt_datefield_value(second)",
            "        return [first, second]",
            "",
            "    def year_lookup_bounds_for_datetime_field(self, value, iso_year=False):",
            "        \"\"\"",
            "        Return a two-elements list with the lower and upper bound to be used",
            "        with a BETWEEN operator to query a DateTimeField value using a year",
            "        lookup.",
            "",
            "        `value` is an int, containing the looked-up year.",
            "        If `iso_year` is True, return bounds for ISO-8601 week-numbering years.",
            "        \"\"\"",
            "        if iso_year:",
            "            first = datetime.datetime.fromisocalendar(value, 1, 1)",
            "            second = datetime.datetime.fromisocalendar(",
            "                value + 1, 1, 1",
            "            ) - datetime.timedelta(microseconds=1)",
            "        else:",
            "            first = datetime.datetime(value, 1, 1)",
            "            second = datetime.datetime(value, 12, 31, 23, 59, 59, 999999)",
            "        if settings.USE_TZ:",
            "            tz = timezone.get_current_timezone()",
            "            first = timezone.make_aware(first, tz)",
            "            second = timezone.make_aware(second, tz)",
            "        first = self.adapt_datetimefield_value(first)",
            "        second = self.adapt_datetimefield_value(second)",
            "        return [first, second]",
            "",
            "    def get_db_converters(self, expression):",
            "        \"\"\"",
            "        Return a list of functions needed to convert field data.",
            "",
            "        Some field types on some backends do not provide data in the correct",
            "        format, this is the hook for converter functions.",
            "        \"\"\"",
            "        return []",
            "",
            "    def convert_durationfield_value(self, value, expression, connection):",
            "        if value is not None:",
            "            return datetime.timedelta(0, 0, value)",
            "",
            "    def check_expression_support(self, expression):",
            "        \"\"\"",
            "        Check that the backend supports the provided expression.",
            "",
            "        This is used on specific backends to rule out known expressions",
            "        that have problematic or nonexistent implementations. If the",
            "        expression has a known problem, the backend should raise",
            "        NotSupportedError.",
            "        \"\"\"",
            "        pass",
            "",
            "    def conditional_expression_supported_in_where_clause(self, expression):",
            "        \"\"\"",
            "        Return True, if the conditional expression is supported in the WHERE",
            "        clause.",
            "        \"\"\"",
            "        return True",
            "",
            "    def combine_expression(self, connector, sub_expressions):",
            "        \"\"\"",
            "        Combine a list of subexpressions into a single expression, using",
            "        the provided connecting operator. This is required because operators",
            "        can vary between backends (e.g., Oracle with %% and &) and between",
            "        subexpression types (e.g., date expressions).",
            "        \"\"\"",
            "        conn = \" %s \" % connector",
            "        return conn.join(sub_expressions)",
            "",
            "    def combine_duration_expression(self, connector, sub_expressions):",
            "        return self.combine_expression(connector, sub_expressions)",
            "",
            "    def binary_placeholder_sql(self, value):",
            "        \"\"\"",
            "        Some backends require special syntax to insert binary content (MySQL",
            "        for example uses '_binary %s').",
            "        \"\"\"",
            "        return \"%s\"",
            "",
            "    def modify_insert_params(self, placeholder, params):",
            "        \"\"\"",
            "        Allow modification of insert parameters. Needed for Oracle Spatial",
            "        backend due to #10888.",
            "        \"\"\"",
            "        return params",
            "",
            "    def integer_field_range(self, internal_type):",
            "        \"\"\"",
            "        Given an integer field internal type (e.g. 'PositiveIntegerField'),",
            "        return a tuple of the (min_value, max_value) form representing the",
            "        range of the column type bound to the field.",
            "        \"\"\"",
            "        return self.integer_field_ranges[internal_type]",
            "",
            "    def subtract_temporals(self, internal_type, lhs, rhs):",
            "        if self.connection.features.supports_temporal_subtraction:",
            "            lhs_sql, lhs_params = lhs",
            "            rhs_sql, rhs_params = rhs",
            "            return \"(%s - %s)\" % (lhs_sql, rhs_sql), (*lhs_params, *rhs_params)",
            "        raise NotSupportedError(",
            "            \"This backend does not support %s subtraction.\" % internal_type",
            "        )",
            "",
            "    def window_frame_start(self, start):",
            "        if isinstance(start, int):",
            "            if start < 0:",
            "                return \"%d %s\" % (abs(start), self.PRECEDING)",
            "            elif start == 0:",
            "                return self.CURRENT_ROW",
            "        elif start is None:",
            "            return self.UNBOUNDED_PRECEDING",
            "        raise ValueError(",
            "            \"start argument must be a negative integer, zero, or None, but got '%s'.\"",
            "            % start",
            "        )",
            "",
            "    def window_frame_end(self, end):",
            "        if isinstance(end, int):",
            "            if end == 0:",
            "                return self.CURRENT_ROW",
            "            elif end > 0:",
            "                return \"%d %s\" % (end, self.FOLLOWING)",
            "        elif end is None:",
            "            return self.UNBOUNDED_FOLLOWING",
            "        raise ValueError(",
            "            \"end argument must be a positive integer, zero, or None, but got '%s'.\"",
            "            % end",
            "        )",
            "",
            "    def window_frame_rows_start_end(self, start=None, end=None):",
            "        \"\"\"",
            "        Return SQL for start and end points in an OVER clause window frame.",
            "        \"\"\"",
            "        if not self.connection.features.supports_over_clause:",
            "            raise NotSupportedError(\"This backend does not support window expressions.\")",
            "        return self.window_frame_start(start), self.window_frame_end(end)",
            "",
            "    def window_frame_range_start_end(self, start=None, end=None):",
            "        start_, end_ = self.window_frame_rows_start_end(start, end)",
            "        features = self.connection.features",
            "        if features.only_supports_unbounded_with_preceding_and_following and (",
            "            (start and start < 0) or (end and end > 0)",
            "        ):",
            "            raise NotSupportedError(",
            "                \"%s only supports UNBOUNDED together with PRECEDING and \"",
            "                \"FOLLOWING.\" % self.connection.display_name",
            "            )",
            "        return start_, end_",
            "",
            "    def explain_query_prefix(self, format=None, **options):",
            "        if not self.connection.features.supports_explaining_query_execution:",
            "            raise NotSupportedError(",
            "                \"This backend does not support explaining query execution.\"",
            "            )",
            "        if format:",
            "            supported_formats = self.connection.features.supported_explain_formats",
            "            normalized_format = format.upper()",
            "            if normalized_format not in supported_formats:",
            "                msg = \"%s is not a recognized format.\" % normalized_format",
            "                if supported_formats:",
            "                    msg += \" Allowed formats: %s\" % \", \".join(sorted(supported_formats))",
            "                else:",
            "                    msg += (",
            "                        f\" {self.connection.display_name} does not support any formats.\"",
            "                    )",
            "                raise ValueError(msg)",
            "        if options:",
            "            raise ValueError(\"Unknown options: %s\" % \", \".join(sorted(options.keys())))",
            "        return self.explain_prefix",
            "",
            "    def insert_statement(self, on_conflict=None):",
            "        return \"INSERT INTO\"",
            "",
            "    def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
            "        return \"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "12": [],
            "58": [
                "BaseDatabaseOperations"
            ],
            "59": [
                "BaseDatabaseOperations"
            ],
            "106": [
                "BaseDatabaseOperations",
                "date_extract_sql"
            ],
            "116": [
                "BaseDatabaseOperations",
                "date_trunc_sql"
            ],
            "130": [
                "BaseDatabaseOperations",
                "datetime_cast_date_sql"
            ],
            "139": [
                "BaseDatabaseOperations",
                "datetime_cast_time_sql"
            ],
            "148": [
                "BaseDatabaseOperations",
                "datetime_extract_sql"
            ],
            "159": [
                "BaseDatabaseOperations",
                "datetime_trunc_sql"
            ],
            "170": [
                "BaseDatabaseOperations",
                "time_trunc_sql"
            ],
            "183": [
                "BaseDatabaseOperations",
                "time_extract_sql"
            ],
            "188": [
                "BaseDatabaseOperations",
                "time_extract_sql"
            ]
        },
        "addLocation": []
    },
    "django/db/backends/mysql/operations.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from django.db.models.constants import OnConflict"
            },
            "1": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from django.utils import timezone"
            },
            "2": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from django.utils.encoding import force_str"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+from django.utils.regex_helper import _lazy_re_compile"
            },
            "4": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " class DatabaseOperations(BaseDatabaseOperations):"
            },
            "7": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "     cast_char_field_without_max_length = \"char\""
            },
            "8": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "     explain_prefix = \"EXPLAIN\""
            },
            "9": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def date_extract_sql(self, lookup_type, field_name):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+    # EXTRACT format cannot be passed in parameters."
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+    _extract_format_re = _lazy_re_compile(r\"[A-Z_]+\")"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+    def date_extract_sql(self, lookup_type, sql, params):"
            },
            "15": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "         # https://dev.mysql.com/doc/mysql/en/date-and-time-functions.html"
            },
            "16": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 46,
                "PatchRowcode": "         if lookup_type == \"week_day\":"
            },
            "17": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 47,
                "PatchRowcode": "             # DAYOFWEEK() returns an integer, 1-7, Sunday=1."
            },
            "18": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"DAYOFWEEK(%s)\" % field_name"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+            return f\"DAYOFWEEK({sql})\", params"
            },
            "20": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 49,
                "PatchRowcode": "         elif lookup_type == \"iso_week_day\":"
            },
            "21": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "             # WEEKDAY() returns an integer, 0-6, Monday=0."
            },
            "22": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"WEEKDAY(%s) + 1\" % field_name"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+            return f\"WEEKDAY({sql}) + 1\", params"
            },
            "24": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "         elif lookup_type == \"week\":"
            },
            "25": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "             # Override the value of default_week_format for consistency with"
            },
            "26": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "             # other database backends."
            },
            "27": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "             # Mode 3: Monday, 1-53, with 4 or more days this year."
            },
            "28": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"WEEK(%s, 3)\" % field_name"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+            return f\"WEEK({sql}, 3)\", params"
            },
            "30": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "         elif lookup_type == \"iso_year\":"
            },
            "31": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "             # Get the year part from the YEARWEEK function, which returns a"
            },
            "32": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "             # number as year * 100 + week."
            },
            "33": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"TRUNCATE(YEARWEEK(%s, 3), -2) / 100\" % field_name"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+            return f\"TRUNCATE(YEARWEEK({sql}, 3), -2) / 100\", params"
            },
            "35": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "         else:"
            },
            "36": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "             # EXTRACT returns 1-53 based on ISO-8601 for the week number."
            },
            "37": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"EXTRACT(%s FROM %s)\" % (lookup_type.upper(), field_name)"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+            lookup_type = lookup_type.upper()"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+            if not self._extract_format_re.fullmatch(lookup_type):"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+                raise ValueError(f\"Invalid loookup type: {lookup_type!r}\")"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+            return f\"EXTRACT({lookup_type} FROM {sql})\", params"
            },
            "42": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " "
            },
            "43": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def date_trunc_sql(self, lookup_type, field_name, tzname=None):"
            },
            "44": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        field_name = self._convert_field_to_tz(field_name, tzname)"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+    def date_trunc_sql(self, lookup_type, sql, params, tzname=None):"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+        sql, params = self._convert_field_to_tz(sql, params, tzname)"
            },
            "47": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "         fields = {"
            },
            "48": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"year\": \"%%Y-01-01\","
            },
            "49": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"month\": \"%%Y-%%m-01\","
            },
            "50": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        }  # Use double percents to escape."
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+            \"year\": \"%Y-01-01\","
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+            \"month\": \"%Y-%m-01\","
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+        }"
            },
            "54": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 74,
                "PatchRowcode": "         if lookup_type in fields:"
            },
            "55": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "             format_str = fields[lookup_type]"
            },
            "56": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"CAST(DATE_FORMAT(%s, '%s') AS DATE)\" % (field_name, format_str)"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+            return f\"CAST(DATE_FORMAT({sql}, %s) AS DATE)\", (*params, format_str)"
            },
            "58": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "         elif lookup_type == \"quarter\":"
            },
            "59": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 78,
                "PatchRowcode": "             return ("
            },
            "60": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"MAKEDATE(YEAR(%s), 1) + \""
            },
            "61": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"INTERVAL QUARTER(%s) QUARTER - INTERVAL 1 QUARTER\""
            },
            "62": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                % (field_name, field_name)"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+                f\"MAKEDATE(YEAR({sql}), 1) + \""
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+                f\"INTERVAL QUARTER({sql}) QUARTER - INTERVAL 1 QUARTER\","
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+                (*params, *params),"
            },
            "66": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "             )"
            },
            "67": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "         elif lookup_type == \"week\":"
            },
            "68": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"DATE_SUB(%s, INTERVAL WEEKDAY(%s) DAY)\" % (field_name, field_name)"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 84,
                "PatchRowcode": "+            return f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY)\", (*params, *params)"
            },
            "70": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "         else:"
            },
            "71": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"DATE(%s)\" % (field_name)"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+            return f\"DATE({sql})\", params"
            },
            "73": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 87,
                "PatchRowcode": " "
            },
            "74": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "     def _prepare_tzname_delta(self, tzname):"
            },
            "75": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "         tzname, sign, offset = split_tzname_delta(tzname)"
            },
            "76": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "         return f\"{sign}{offset}\" if offset else tzname"
            },
            "77": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 91,
                "PatchRowcode": " "
            },
            "78": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def _convert_field_to_tz(self, field_name, tzname):"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+    def _convert_field_to_tz(self, sql, params, tzname):"
            },
            "80": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "         if tzname and settings.USE_TZ and self.connection.timezone_name != tzname:"
            },
            "81": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            field_name = \"CONVERT_TZ(%s, '%s', '%s')\" % ("
            },
            "82": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                field_name,"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+            return f\"CONVERT_TZ({sql}, %s, %s)\", ("
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+                *params,"
            },
            "85": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 96,
                "PatchRowcode": "                 self.connection.timezone_name,"
            },
            "86": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 97,
                "PatchRowcode": "                 self._prepare_tzname_delta(tzname),"
            },
            "87": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "             )"
            },
            "88": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return field_name"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+        return sql, params"
            },
            "90": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 100,
                "PatchRowcode": " "
            },
            "91": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_cast_date_sql(self, field_name, tzname):"
            },
            "92": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        field_name = self._convert_field_to_tz(field_name, tzname)"
            },
            "93": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return \"DATE(%s)\" % field_name"
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+    def datetime_cast_date_sql(self, sql, params, tzname):"
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+        sql, params = self._convert_field_to_tz(sql, params, tzname)"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+        return f\"DATE({sql})\", params"
            },
            "97": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 104,
                "PatchRowcode": " "
            },
            "98": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_cast_time_sql(self, field_name, tzname):"
            },
            "99": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        field_name = self._convert_field_to_tz(field_name, tzname)"
            },
            "100": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return \"TIME(%s)\" % field_name"
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+    def datetime_cast_time_sql(self, sql, params, tzname):"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        sql, params = self._convert_field_to_tz(sql, params, tzname)"
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+        return f\"TIME({sql})\", params"
            },
            "104": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 108,
                "PatchRowcode": " "
            },
            "105": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_extract_sql(self, lookup_type, field_name, tzname):"
            },
            "106": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        field_name = self._convert_field_to_tz(field_name, tzname)"
            },
            "107": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return self.date_extract_sql(lookup_type, field_name)"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+    def datetime_extract_sql(self, lookup_type, sql, params, tzname):"
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+        sql, params = self._convert_field_to_tz(sql, params, tzname)"
            },
            "110": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        return self.date_extract_sql(lookup_type, sql, params)"
            },
            "111": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 112,
                "PatchRowcode": " "
            },
            "112": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def datetime_trunc_sql(self, lookup_type, field_name, tzname):"
            },
            "113": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        field_name = self._convert_field_to_tz(field_name, tzname)"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+    def datetime_trunc_sql(self, lookup_type, sql, params, tzname):"
            },
            "115": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+        sql, params = self._convert_field_to_tz(sql, params, tzname)"
            },
            "116": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "         fields = [\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\"]"
            },
            "117": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        format = ("
            },
            "118": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"%%Y-\","
            },
            "119": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"%%m\","
            },
            "120": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"-%%d\","
            },
            "121": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \" %%H:\","
            },
            "122": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"%%i\","
            },
            "123": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \":%%s\","
            },
            "124": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        )  # Use double percents to escape."
            },
            "125": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+        format = (\"%Y-\", \"%m\", \"-%d\", \" %H:\", \"%i\", \":%s\")"
            },
            "126": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 117,
                "PatchRowcode": "         format_def = (\"0000-\", \"01\", \"-01\", \" 00:\", \"00\", \":00\")"
            },
            "127": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "         if lookup_type == \"quarter\":"
            },
            "128": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "             return ("
            },
            "129": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"CAST(DATE_FORMAT(MAKEDATE(YEAR({field_name}), 1) + \""
            },
            "130": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"INTERVAL QUARTER({field_name}) QUARTER - \""
            },
            "131": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                + \"INTERVAL 1 QUARTER, '%%Y-%%m-01 00:00:00') AS DATETIME)\""
            },
            "132": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            ).format(field_name=field_name)"
            },
            "133": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+                f\"CAST(DATE_FORMAT(MAKEDATE(YEAR({sql}), 1) + \""
            },
            "134": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+                f\"INTERVAL QUARTER({sql}) QUARTER - \""
            },
            "135": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 122,
                "PatchRowcode": "+                f\"INTERVAL 1 QUARTER, %s) AS DATETIME)\""
            },
            "136": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 123,
                "PatchRowcode": "+            ), (*params, *params, \"%Y-%m-01 00:00:00\")"
            },
            "137": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "         if lookup_type == \"week\":"
            },
            "138": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "             return ("
            },
            "139": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"CAST(DATE_FORMAT(DATE_SUB({field_name}, \""
            },
            "140": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"INTERVAL WEEKDAY({field_name}) DAY), \""
            },
            "141": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"'%%Y-%%m-%%d 00:00:00') AS DATETIME)\""
            },
            "142": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            ).format(field_name=field_name)"
            },
            "143": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+                f\"CAST(DATE_FORMAT(\""
            },
            "144": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+                f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY), %s) AS DATETIME)\""
            },
            "145": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+            ), (*params, *params, \"%Y-%m-%d 00:00:00\")"
            },
            "146": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "         try:"
            },
            "147": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "             i = fields.index(lookup_type) + 1"
            },
            "148": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 131,
                "PatchRowcode": "         except ValueError:"
            },
            "149": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            sql = field_name"
            },
            "150": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+            pass"
            },
            "151": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "         else:"
            },
            "152": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "             format_str = \"\".join(format[:i] + format_def[i:])"
            },
            "153": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            sql = \"CAST(DATE_FORMAT(%s, '%s') AS DATETIME)\" % (field_name, format_str)"
            },
            "154": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return sql"
            },
            "155": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 135,
                "PatchRowcode": "+            return f\"CAST(DATE_FORMAT({sql}, %s) AS DATETIME)\", (*params, format_str)"
            },
            "156": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+        return sql, params"
            },
            "157": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 137,
                "PatchRowcode": " "
            },
            "158": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def time_trunc_sql(self, lookup_type, field_name, tzname=None):"
            },
            "159": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        field_name = self._convert_field_to_tz(field_name, tzname)"
            },
            "160": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+    def time_trunc_sql(self, lookup_type, sql, params, tzname=None):"
            },
            "161": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+        sql, params = self._convert_field_to_tz(sql, params, tzname)"
            },
            "162": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "         fields = {"
            },
            "163": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"hour\": \"%%H:00:00\","
            },
            "164": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"minute\": \"%%H:%%i:00\","
            },
            "165": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"second\": \"%%H:%%i:%%s\","
            },
            "166": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        }  # Use double percents to escape."
            },
            "167": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 141,
                "PatchRowcode": "+            \"hour\": \"%H:00:00\","
            },
            "168": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+            \"minute\": \"%H:%i:00\","
            },
            "169": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+            \"second\": \"%H:%i:%s\","
            },
            "170": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 144,
                "PatchRowcode": "+        }"
            },
            "171": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 145,
                "PatchRowcode": "         if lookup_type in fields:"
            },
            "172": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "             format_str = fields[lookup_type]"
            },
            "173": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"CAST(DATE_FORMAT(%s, '%s') AS TIME)\" % (field_name, format_str)"
            },
            "174": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+            return f\"CAST(DATE_FORMAT({sql}, %s) AS TIME)\", (*params, format_str)"
            },
            "175": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "         else:"
            },
            "176": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return \"TIME(%s)\" % (field_name)"
            },
            "177": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+            return f\"TIME({sql})\", params"
            },
            "178": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            },
            "179": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "     def fetch_returned_insert_rows(self, cursor):"
            },
            "180": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "         \"\"\""
            }
        },
        "frontPatchFile": [
            "import uuid",
            "",
            "from django.conf import settings",
            "from django.db.backends.base.operations import BaseDatabaseOperations",
            "from django.db.backends.utils import split_tzname_delta",
            "from django.db.models import Exists, ExpressionWrapper, Lookup",
            "from django.db.models.constants import OnConflict",
            "from django.utils import timezone",
            "from django.utils.encoding import force_str",
            "",
            "",
            "class DatabaseOperations(BaseDatabaseOperations):",
            "    compiler_module = \"django.db.backends.mysql.compiler\"",
            "",
            "    # MySQL stores positive fields as UNSIGNED ints.",
            "    integer_field_ranges = {",
            "        **BaseDatabaseOperations.integer_field_ranges,",
            "        \"PositiveSmallIntegerField\": (0, 65535),",
            "        \"PositiveIntegerField\": (0, 4294967295),",
            "        \"PositiveBigIntegerField\": (0, 18446744073709551615),",
            "    }",
            "    cast_data_types = {",
            "        \"AutoField\": \"signed integer\",",
            "        \"BigAutoField\": \"signed integer\",",
            "        \"SmallAutoField\": \"signed integer\",",
            "        \"CharField\": \"char(%(max_length)s)\",",
            "        \"DecimalField\": \"decimal(%(max_digits)s, %(decimal_places)s)\",",
            "        \"TextField\": \"char\",",
            "        \"IntegerField\": \"signed integer\",",
            "        \"BigIntegerField\": \"signed integer\",",
            "        \"SmallIntegerField\": \"signed integer\",",
            "        \"PositiveBigIntegerField\": \"unsigned integer\",",
            "        \"PositiveIntegerField\": \"unsigned integer\",",
            "        \"PositiveSmallIntegerField\": \"unsigned integer\",",
            "        \"DurationField\": \"signed integer\",",
            "    }",
            "    cast_char_field_without_max_length = \"char\"",
            "    explain_prefix = \"EXPLAIN\"",
            "",
            "    def date_extract_sql(self, lookup_type, field_name):",
            "        # https://dev.mysql.com/doc/mysql/en/date-and-time-functions.html",
            "        if lookup_type == \"week_day\":",
            "            # DAYOFWEEK() returns an integer, 1-7, Sunday=1.",
            "            return \"DAYOFWEEK(%s)\" % field_name",
            "        elif lookup_type == \"iso_week_day\":",
            "            # WEEKDAY() returns an integer, 0-6, Monday=0.",
            "            return \"WEEKDAY(%s) + 1\" % field_name",
            "        elif lookup_type == \"week\":",
            "            # Override the value of default_week_format for consistency with",
            "            # other database backends.",
            "            # Mode 3: Monday, 1-53, with 4 or more days this year.",
            "            return \"WEEK(%s, 3)\" % field_name",
            "        elif lookup_type == \"iso_year\":",
            "            # Get the year part from the YEARWEEK function, which returns a",
            "            # number as year * 100 + week.",
            "            return \"TRUNCATE(YEARWEEK(%s, 3), -2) / 100\" % field_name",
            "        else:",
            "            # EXTRACT returns 1-53 based on ISO-8601 for the week number.",
            "            return \"EXTRACT(%s FROM %s)\" % (lookup_type.upper(), field_name)",
            "",
            "    def date_trunc_sql(self, lookup_type, field_name, tzname=None):",
            "        field_name = self._convert_field_to_tz(field_name, tzname)",
            "        fields = {",
            "            \"year\": \"%%Y-01-01\",",
            "            \"month\": \"%%Y-%%m-01\",",
            "        }  # Use double percents to escape.",
            "        if lookup_type in fields:",
            "            format_str = fields[lookup_type]",
            "            return \"CAST(DATE_FORMAT(%s, '%s') AS DATE)\" % (field_name, format_str)",
            "        elif lookup_type == \"quarter\":",
            "            return (",
            "                \"MAKEDATE(YEAR(%s), 1) + \"",
            "                \"INTERVAL QUARTER(%s) QUARTER - INTERVAL 1 QUARTER\"",
            "                % (field_name, field_name)",
            "            )",
            "        elif lookup_type == \"week\":",
            "            return \"DATE_SUB(%s, INTERVAL WEEKDAY(%s) DAY)\" % (field_name, field_name)",
            "        else:",
            "            return \"DATE(%s)\" % (field_name)",
            "",
            "    def _prepare_tzname_delta(self, tzname):",
            "        tzname, sign, offset = split_tzname_delta(tzname)",
            "        return f\"{sign}{offset}\" if offset else tzname",
            "",
            "    def _convert_field_to_tz(self, field_name, tzname):",
            "        if tzname and settings.USE_TZ and self.connection.timezone_name != tzname:",
            "            field_name = \"CONVERT_TZ(%s, '%s', '%s')\" % (",
            "                field_name,",
            "                self.connection.timezone_name,",
            "                self._prepare_tzname_delta(tzname),",
            "            )",
            "        return field_name",
            "",
            "    def datetime_cast_date_sql(self, field_name, tzname):",
            "        field_name = self._convert_field_to_tz(field_name, tzname)",
            "        return \"DATE(%s)\" % field_name",
            "",
            "    def datetime_cast_time_sql(self, field_name, tzname):",
            "        field_name = self._convert_field_to_tz(field_name, tzname)",
            "        return \"TIME(%s)\" % field_name",
            "",
            "    def datetime_extract_sql(self, lookup_type, field_name, tzname):",
            "        field_name = self._convert_field_to_tz(field_name, tzname)",
            "        return self.date_extract_sql(lookup_type, field_name)",
            "",
            "    def datetime_trunc_sql(self, lookup_type, field_name, tzname):",
            "        field_name = self._convert_field_to_tz(field_name, tzname)",
            "        fields = [\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\"]",
            "        format = (",
            "            \"%%Y-\",",
            "            \"%%m\",",
            "            \"-%%d\",",
            "            \" %%H:\",",
            "            \"%%i\",",
            "            \":%%s\",",
            "        )  # Use double percents to escape.",
            "        format_def = (\"0000-\", \"01\", \"-01\", \" 00:\", \"00\", \":00\")",
            "        if lookup_type == \"quarter\":",
            "            return (",
            "                \"CAST(DATE_FORMAT(MAKEDATE(YEAR({field_name}), 1) + \"",
            "                \"INTERVAL QUARTER({field_name}) QUARTER - \"",
            "                + \"INTERVAL 1 QUARTER, '%%Y-%%m-01 00:00:00') AS DATETIME)\"",
            "            ).format(field_name=field_name)",
            "        if lookup_type == \"week\":",
            "            return (",
            "                \"CAST(DATE_FORMAT(DATE_SUB({field_name}, \"",
            "                \"INTERVAL WEEKDAY({field_name}) DAY), \"",
            "                \"'%%Y-%%m-%%d 00:00:00') AS DATETIME)\"",
            "            ).format(field_name=field_name)",
            "        try:",
            "            i = fields.index(lookup_type) + 1",
            "        except ValueError:",
            "            sql = field_name",
            "        else:",
            "            format_str = \"\".join(format[:i] + format_def[i:])",
            "            sql = \"CAST(DATE_FORMAT(%s, '%s') AS DATETIME)\" % (field_name, format_str)",
            "        return sql",
            "",
            "    def time_trunc_sql(self, lookup_type, field_name, tzname=None):",
            "        field_name = self._convert_field_to_tz(field_name, tzname)",
            "        fields = {",
            "            \"hour\": \"%%H:00:00\",",
            "            \"minute\": \"%%H:%%i:00\",",
            "            \"second\": \"%%H:%%i:%%s\",",
            "        }  # Use double percents to escape.",
            "        if lookup_type in fields:",
            "            format_str = fields[lookup_type]",
            "            return \"CAST(DATE_FORMAT(%s, '%s') AS TIME)\" % (field_name, format_str)",
            "        else:",
            "            return \"TIME(%s)\" % (field_name)",
            "",
            "    def fetch_returned_insert_rows(self, cursor):",
            "        \"\"\"",
            "        Given a cursor object that has just performed an INSERT...RETURNING",
            "        statement into a table, return the tuple of returned data.",
            "        \"\"\"",
            "        return cursor.fetchall()",
            "",
            "    def format_for_duration_arithmetic(self, sql):",
            "        return \"INTERVAL %s MICROSECOND\" % sql",
            "",
            "    def force_no_ordering(self):",
            "        \"\"\"",
            "        \"ORDER BY NULL\" prevents MySQL from implicitly ordering by grouped",
            "        columns. If no ordering would otherwise be applied, we don't want any",
            "        implicit sorting going on.",
            "        \"\"\"",
            "        return [(None, (\"NULL\", [], False))]",
            "",
            "    def adapt_decimalfield_value(self, value, max_digits=None, decimal_places=None):",
            "        return value",
            "",
            "    def last_executed_query(self, cursor, sql, params):",
            "        # With MySQLdb, cursor objects have an (undocumented) \"_executed\"",
            "        # attribute where the exact query sent to the database is saved.",
            "        # See MySQLdb/cursors.py in the source distribution.",
            "        # MySQLdb returns string, PyMySQL bytes.",
            "        return force_str(getattr(cursor, \"_executed\", None), errors=\"replace\")",
            "",
            "    def no_limit_value(self):",
            "        # 2**64 - 1, as recommended by the MySQL documentation",
            "        return 18446744073709551615",
            "",
            "    def quote_name(self, name):",
            "        if name.startswith(\"`\") and name.endswith(\"`\"):",
            "            return name  # Quoting once is enough.",
            "        return \"`%s`\" % name",
            "",
            "    def return_insert_columns(self, fields):",
            "        # MySQL and MariaDB < 10.5.0 don't support an INSERT...RETURNING",
            "        # statement.",
            "        if not fields:",
            "            return \"\", ()",
            "        columns = [",
            "            \"%s.%s\"",
            "            % (",
            "                self.quote_name(field.model._meta.db_table),",
            "                self.quote_name(field.column),",
            "            )",
            "            for field in fields",
            "        ]",
            "        return \"RETURNING %s\" % \", \".join(columns), ()",
            "",
            "    def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
            "        if not tables:",
            "            return []",
            "",
            "        sql = [\"SET FOREIGN_KEY_CHECKS = 0;\"]",
            "        if reset_sequences:",
            "            # It's faster to TRUNCATE tables that require a sequence reset",
            "            # since ALTER TABLE AUTO_INCREMENT is slower than TRUNCATE.",
            "            sql.extend(",
            "                \"%s %s;\"",
            "                % (",
            "                    style.SQL_KEYWORD(\"TRUNCATE\"),",
            "                    style.SQL_FIELD(self.quote_name(table_name)),",
            "                )",
            "                for table_name in tables",
            "            )",
            "        else:",
            "            # Otherwise issue a simple DELETE since it's faster than TRUNCATE",
            "            # and preserves sequences.",
            "            sql.extend(",
            "                \"%s %s %s;\"",
            "                % (",
            "                    style.SQL_KEYWORD(\"DELETE\"),",
            "                    style.SQL_KEYWORD(\"FROM\"),",
            "                    style.SQL_FIELD(self.quote_name(table_name)),",
            "                )",
            "                for table_name in tables",
            "            )",
            "        sql.append(\"SET FOREIGN_KEY_CHECKS = 1;\")",
            "        return sql",
            "",
            "    def sequence_reset_by_name_sql(self, style, sequences):",
            "        return [",
            "            \"%s %s %s %s = 1;\"",
            "            % (",
            "                style.SQL_KEYWORD(\"ALTER\"),",
            "                style.SQL_KEYWORD(\"TABLE\"),",
            "                style.SQL_FIELD(self.quote_name(sequence_info[\"table\"])),",
            "                style.SQL_FIELD(\"AUTO_INCREMENT\"),",
            "            )",
            "            for sequence_info in sequences",
            "        ]",
            "",
            "    def validate_autopk_value(self, value):",
            "        # Zero in AUTO_INCREMENT field does not work without the",
            "        # NO_AUTO_VALUE_ON_ZERO SQL mode.",
            "        if value == 0 and not self.connection.features.allows_auto_pk_0:",
            "            raise ValueError(",
            "                \"The database backend does not accept 0 as a value for AutoField.\"",
            "            )",
            "        return value",
            "",
            "    def adapt_datetimefield_value(self, value):",
            "        if value is None:",
            "            return None",
            "",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        # MySQL doesn't support tz-aware datetimes",
            "        if timezone.is_aware(value):",
            "            if settings.USE_TZ:",
            "                value = timezone.make_naive(value, self.connection.timezone)",
            "            else:",
            "                raise ValueError(",
            "                    \"MySQL backend does not support timezone-aware datetimes when \"",
            "                    \"USE_TZ is False.\"",
            "                )",
            "        return str(value)",
            "",
            "    def adapt_timefield_value(self, value):",
            "        if value is None:",
            "            return None",
            "",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        # MySQL doesn't support tz-aware times",
            "        if timezone.is_aware(value):",
            "            raise ValueError(\"MySQL backend does not support timezone-aware times.\")",
            "",
            "        return value.isoformat(timespec=\"microseconds\")",
            "",
            "    def max_name_length(self):",
            "        return 64",
            "",
            "    def pk_default_value(self):",
            "        return \"NULL\"",
            "",
            "    def bulk_insert_sql(self, fields, placeholder_rows):",
            "        placeholder_rows_sql = (\", \".join(row) for row in placeholder_rows)",
            "        values_sql = \", \".join(\"(%s)\" % sql for sql in placeholder_rows_sql)",
            "        return \"VALUES \" + values_sql",
            "",
            "    def combine_expression(self, connector, sub_expressions):",
            "        if connector == \"^\":",
            "            return \"POW(%s)\" % \",\".join(sub_expressions)",
            "        # Convert the result to a signed integer since MySQL's binary operators",
            "        # return an unsigned integer.",
            "        elif connector in (\"&\", \"|\", \"<<\", \"#\"):",
            "            connector = \"^\" if connector == \"#\" else connector",
            "            return \"CONVERT(%s, SIGNED)\" % connector.join(sub_expressions)",
            "        elif connector == \">>\":",
            "            lhs, rhs = sub_expressions",
            "            return \"FLOOR(%(lhs)s / POW(2, %(rhs)s))\" % {\"lhs\": lhs, \"rhs\": rhs}",
            "        return super().combine_expression(connector, sub_expressions)",
            "",
            "    def get_db_converters(self, expression):",
            "        converters = super().get_db_converters(expression)",
            "        internal_type = expression.output_field.get_internal_type()",
            "        if internal_type == \"BooleanField\":",
            "            converters.append(self.convert_booleanfield_value)",
            "        elif internal_type == \"DateTimeField\":",
            "            if settings.USE_TZ:",
            "                converters.append(self.convert_datetimefield_value)",
            "        elif internal_type == \"UUIDField\":",
            "            converters.append(self.convert_uuidfield_value)",
            "        return converters",
            "",
            "    def convert_booleanfield_value(self, value, expression, connection):",
            "        if value in (0, 1):",
            "            value = bool(value)",
            "        return value",
            "",
            "    def convert_datetimefield_value(self, value, expression, connection):",
            "        if value is not None:",
            "            value = timezone.make_aware(value, self.connection.timezone)",
            "        return value",
            "",
            "    def convert_uuidfield_value(self, value, expression, connection):",
            "        if value is not None:",
            "            value = uuid.UUID(value)",
            "        return value",
            "",
            "    def binary_placeholder_sql(self, value):",
            "        return (",
            "            \"_binary %s\" if value is not None and not hasattr(value, \"as_sql\") else \"%s\"",
            "        )",
            "",
            "    def subtract_temporals(self, internal_type, lhs, rhs):",
            "        lhs_sql, lhs_params = lhs",
            "        rhs_sql, rhs_params = rhs",
            "        if internal_type == \"TimeField\":",
            "            if self.connection.mysql_is_mariadb:",
            "                # MariaDB includes the microsecond component in TIME_TO_SEC as",
            "                # a decimal. MySQL returns an integer without microseconds.",
            "                return (",
            "                    \"CAST((TIME_TO_SEC(%(lhs)s) - TIME_TO_SEC(%(rhs)s)) \"",
            "                    \"* 1000000 AS SIGNED)\"",
            "                ) % {",
            "                    \"lhs\": lhs_sql,",
            "                    \"rhs\": rhs_sql,",
            "                }, (",
            "                    *lhs_params,",
            "                    *rhs_params,",
            "                )",
            "            return (",
            "                \"((TIME_TO_SEC(%(lhs)s) * 1000000 + MICROSECOND(%(lhs)s)) -\"",
            "                \" (TIME_TO_SEC(%(rhs)s) * 1000000 + MICROSECOND(%(rhs)s)))\"",
            "            ) % {\"lhs\": lhs_sql, \"rhs\": rhs_sql}, tuple(lhs_params) * 2 + tuple(",
            "                rhs_params",
            "            ) * 2",
            "        params = (*rhs_params, *lhs_params)",
            "        return \"TIMESTAMPDIFF(MICROSECOND, %s, %s)\" % (rhs_sql, lhs_sql), params",
            "",
            "    def explain_query_prefix(self, format=None, **options):",
            "        # Alias MySQL's TRADITIONAL to TEXT for consistency with other backends.",
            "        if format and format.upper() == \"TEXT\":",
            "            format = \"TRADITIONAL\"",
            "        elif (",
            "            not format and \"TREE\" in self.connection.features.supported_explain_formats",
            "        ):",
            "            # Use TREE by default (if supported) as it's more informative.",
            "            format = \"TREE\"",
            "        analyze = options.pop(\"analyze\", False)",
            "        prefix = super().explain_query_prefix(format, **options)",
            "        if analyze and self.connection.features.supports_explain_analyze:",
            "            # MariaDB uses ANALYZE instead of EXPLAIN ANALYZE.",
            "            prefix = (",
            "                \"ANALYZE\" if self.connection.mysql_is_mariadb else prefix + \" ANALYZE\"",
            "            )",
            "        if format and not (analyze and not self.connection.mysql_is_mariadb):",
            "            # Only MariaDB supports the analyze option with formats.",
            "            prefix += \" FORMAT=%s\" % format",
            "        return prefix",
            "",
            "    def regex_lookup(self, lookup_type):",
            "        # REGEXP BINARY doesn't work correctly in MySQL 8+ and REGEXP_LIKE",
            "        # doesn't exist in MySQL 5.x or in MariaDB.",
            "        if (",
            "            self.connection.mysql_version < (8, 0, 0)",
            "            or self.connection.mysql_is_mariadb",
            "        ):",
            "            if lookup_type == \"regex\":",
            "                return \"%s REGEXP BINARY %s\"",
            "            return \"%s REGEXP %s\"",
            "",
            "        match_option = \"c\" if lookup_type == \"regex\" else \"i\"",
            "        return \"REGEXP_LIKE(%%s, %%s, '%s')\" % match_option",
            "",
            "    def insert_statement(self, on_conflict=None):",
            "        if on_conflict == OnConflict.IGNORE:",
            "            return \"INSERT IGNORE INTO\"",
            "        return super().insert_statement(on_conflict=on_conflict)",
            "",
            "    def lookup_cast(self, lookup_type, internal_type=None):",
            "        lookup = \"%s\"",
            "        if internal_type == \"JSONField\":",
            "            if self.connection.mysql_is_mariadb or lookup_type in (",
            "                \"iexact\",",
            "                \"contains\",",
            "                \"icontains\",",
            "                \"startswith\",",
            "                \"istartswith\",",
            "                \"endswith\",",
            "                \"iendswith\",",
            "                \"regex\",",
            "                \"iregex\",",
            "            ):",
            "                lookup = \"JSON_UNQUOTE(%s)\"",
            "        return lookup",
            "",
            "    def conditional_expression_supported_in_where_clause(self, expression):",
            "        # MySQL ignores indexes with boolean fields unless they're compared",
            "        # directly to a boolean value.",
            "        if isinstance(expression, (Exists, Lookup)):",
            "            return True",
            "        if isinstance(expression, ExpressionWrapper) and expression.conditional:",
            "            return self.conditional_expression_supported_in_where_clause(",
            "                expression.expression",
            "            )",
            "        if getattr(expression, \"conditional\", False):",
            "            return False",
            "        return super().conditional_expression_supported_in_where_clause(expression)",
            "",
            "    def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
            "        if on_conflict == OnConflict.UPDATE:",
            "            conflict_suffix_sql = \"ON DUPLICATE KEY UPDATE %(fields)s\"",
            "            # The use of VALUES() is deprecated in MySQL 8.0.20+. Instead, use",
            "            # aliases for the new row and its columns available in MySQL",
            "            # 8.0.19+.",
            "            if not self.connection.mysql_is_mariadb:",
            "                if self.connection.mysql_version >= (8, 0, 19):",
            "                    conflict_suffix_sql = f\"AS new {conflict_suffix_sql}\"",
            "                    field_sql = \"%(field)s = new.%(field)s\"",
            "                else:",
            "                    field_sql = \"%(field)s = VALUES(%(field)s)\"",
            "            # Use VALUE() on MariaDB.",
            "            else:",
            "                field_sql = \"%(field)s = VALUE(%(field)s)\"",
            "",
            "            fields = \", \".join(",
            "                [",
            "                    field_sql % {\"field\": field}",
            "                    for field in map(self.quote_name, update_fields)",
            "                ]",
            "            )",
            "            return conflict_suffix_sql % {\"fields\": fields}",
            "        return super().on_conflict_suffix_sql(",
            "            fields,",
            "            on_conflict,",
            "            update_fields,",
            "            unique_fields,",
            "        )"
        ],
        "afterPatchFile": [
            "import uuid",
            "",
            "from django.conf import settings",
            "from django.db.backends.base.operations import BaseDatabaseOperations",
            "from django.db.backends.utils import split_tzname_delta",
            "from django.db.models import Exists, ExpressionWrapper, Lookup",
            "from django.db.models.constants import OnConflict",
            "from django.utils import timezone",
            "from django.utils.encoding import force_str",
            "from django.utils.regex_helper import _lazy_re_compile",
            "",
            "",
            "class DatabaseOperations(BaseDatabaseOperations):",
            "    compiler_module = \"django.db.backends.mysql.compiler\"",
            "",
            "    # MySQL stores positive fields as UNSIGNED ints.",
            "    integer_field_ranges = {",
            "        **BaseDatabaseOperations.integer_field_ranges,",
            "        \"PositiveSmallIntegerField\": (0, 65535),",
            "        \"PositiveIntegerField\": (0, 4294967295),",
            "        \"PositiveBigIntegerField\": (0, 18446744073709551615),",
            "    }",
            "    cast_data_types = {",
            "        \"AutoField\": \"signed integer\",",
            "        \"BigAutoField\": \"signed integer\",",
            "        \"SmallAutoField\": \"signed integer\",",
            "        \"CharField\": \"char(%(max_length)s)\",",
            "        \"DecimalField\": \"decimal(%(max_digits)s, %(decimal_places)s)\",",
            "        \"TextField\": \"char\",",
            "        \"IntegerField\": \"signed integer\",",
            "        \"BigIntegerField\": \"signed integer\",",
            "        \"SmallIntegerField\": \"signed integer\",",
            "        \"PositiveBigIntegerField\": \"unsigned integer\",",
            "        \"PositiveIntegerField\": \"unsigned integer\",",
            "        \"PositiveSmallIntegerField\": \"unsigned integer\",",
            "        \"DurationField\": \"signed integer\",",
            "    }",
            "    cast_char_field_without_max_length = \"char\"",
            "    explain_prefix = \"EXPLAIN\"",
            "",
            "    # EXTRACT format cannot be passed in parameters.",
            "    _extract_format_re = _lazy_re_compile(r\"[A-Z_]+\")",
            "",
            "    def date_extract_sql(self, lookup_type, sql, params):",
            "        # https://dev.mysql.com/doc/mysql/en/date-and-time-functions.html",
            "        if lookup_type == \"week_day\":",
            "            # DAYOFWEEK() returns an integer, 1-7, Sunday=1.",
            "            return f\"DAYOFWEEK({sql})\", params",
            "        elif lookup_type == \"iso_week_day\":",
            "            # WEEKDAY() returns an integer, 0-6, Monday=0.",
            "            return f\"WEEKDAY({sql}) + 1\", params",
            "        elif lookup_type == \"week\":",
            "            # Override the value of default_week_format for consistency with",
            "            # other database backends.",
            "            # Mode 3: Monday, 1-53, with 4 or more days this year.",
            "            return f\"WEEK({sql}, 3)\", params",
            "        elif lookup_type == \"iso_year\":",
            "            # Get the year part from the YEARWEEK function, which returns a",
            "            # number as year * 100 + week.",
            "            return f\"TRUNCATE(YEARWEEK({sql}, 3), -2) / 100\", params",
            "        else:",
            "            # EXTRACT returns 1-53 based on ISO-8601 for the week number.",
            "            lookup_type = lookup_type.upper()",
            "            if not self._extract_format_re.fullmatch(lookup_type):",
            "                raise ValueError(f\"Invalid loookup type: {lookup_type!r}\")",
            "            return f\"EXTRACT({lookup_type} FROM {sql})\", params",
            "",
            "    def date_trunc_sql(self, lookup_type, sql, params, tzname=None):",
            "        sql, params = self._convert_field_to_tz(sql, params, tzname)",
            "        fields = {",
            "            \"year\": \"%Y-01-01\",",
            "            \"month\": \"%Y-%m-01\",",
            "        }",
            "        if lookup_type in fields:",
            "            format_str = fields[lookup_type]",
            "            return f\"CAST(DATE_FORMAT({sql}, %s) AS DATE)\", (*params, format_str)",
            "        elif lookup_type == \"quarter\":",
            "            return (",
            "                f\"MAKEDATE(YEAR({sql}), 1) + \"",
            "                f\"INTERVAL QUARTER({sql}) QUARTER - INTERVAL 1 QUARTER\",",
            "                (*params, *params),",
            "            )",
            "        elif lookup_type == \"week\":",
            "            return f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY)\", (*params, *params)",
            "        else:",
            "            return f\"DATE({sql})\", params",
            "",
            "    def _prepare_tzname_delta(self, tzname):",
            "        tzname, sign, offset = split_tzname_delta(tzname)",
            "        return f\"{sign}{offset}\" if offset else tzname",
            "",
            "    def _convert_field_to_tz(self, sql, params, tzname):",
            "        if tzname and settings.USE_TZ and self.connection.timezone_name != tzname:",
            "            return f\"CONVERT_TZ({sql}, %s, %s)\", (",
            "                *params,",
            "                self.connection.timezone_name,",
            "                self._prepare_tzname_delta(tzname),",
            "            )",
            "        return sql, params",
            "",
            "    def datetime_cast_date_sql(self, sql, params, tzname):",
            "        sql, params = self._convert_field_to_tz(sql, params, tzname)",
            "        return f\"DATE({sql})\", params",
            "",
            "    def datetime_cast_time_sql(self, sql, params, tzname):",
            "        sql, params = self._convert_field_to_tz(sql, params, tzname)",
            "        return f\"TIME({sql})\", params",
            "",
            "    def datetime_extract_sql(self, lookup_type, sql, params, tzname):",
            "        sql, params = self._convert_field_to_tz(sql, params, tzname)",
            "        return self.date_extract_sql(lookup_type, sql, params)",
            "",
            "    def datetime_trunc_sql(self, lookup_type, sql, params, tzname):",
            "        sql, params = self._convert_field_to_tz(sql, params, tzname)",
            "        fields = [\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\"]",
            "        format = (\"%Y-\", \"%m\", \"-%d\", \" %H:\", \"%i\", \":%s\")",
            "        format_def = (\"0000-\", \"01\", \"-01\", \" 00:\", \"00\", \":00\")",
            "        if lookup_type == \"quarter\":",
            "            return (",
            "                f\"CAST(DATE_FORMAT(MAKEDATE(YEAR({sql}), 1) + \"",
            "                f\"INTERVAL QUARTER({sql}) QUARTER - \"",
            "                f\"INTERVAL 1 QUARTER, %s) AS DATETIME)\"",
            "            ), (*params, *params, \"%Y-%m-01 00:00:00\")",
            "        if lookup_type == \"week\":",
            "            return (",
            "                f\"CAST(DATE_FORMAT(\"",
            "                f\"DATE_SUB({sql}, INTERVAL WEEKDAY({sql}) DAY), %s) AS DATETIME)\"",
            "            ), (*params, *params, \"%Y-%m-%d 00:00:00\")",
            "        try:",
            "            i = fields.index(lookup_type) + 1",
            "        except ValueError:",
            "            pass",
            "        else:",
            "            format_str = \"\".join(format[:i] + format_def[i:])",
            "            return f\"CAST(DATE_FORMAT({sql}, %s) AS DATETIME)\", (*params, format_str)",
            "        return sql, params",
            "",
            "    def time_trunc_sql(self, lookup_type, sql, params, tzname=None):",
            "        sql, params = self._convert_field_to_tz(sql, params, tzname)",
            "        fields = {",
            "            \"hour\": \"%H:00:00\",",
            "            \"minute\": \"%H:%i:00\",",
            "            \"second\": \"%H:%i:%s\",",
            "        }",
            "        if lookup_type in fields:",
            "            format_str = fields[lookup_type]",
            "            return f\"CAST(DATE_FORMAT({sql}, %s) AS TIME)\", (*params, format_str)",
            "        else:",
            "            return f\"TIME({sql})\", params",
            "",
            "    def fetch_returned_insert_rows(self, cursor):",
            "        \"\"\"",
            "        Given a cursor object that has just performed an INSERT...RETURNING",
            "        statement into a table, return the tuple of returned data.",
            "        \"\"\"",
            "        return cursor.fetchall()",
            "",
            "    def format_for_duration_arithmetic(self, sql):",
            "        return \"INTERVAL %s MICROSECOND\" % sql",
            "",
            "    def force_no_ordering(self):",
            "        \"\"\"",
            "        \"ORDER BY NULL\" prevents MySQL from implicitly ordering by grouped",
            "        columns. If no ordering would otherwise be applied, we don't want any",
            "        implicit sorting going on.",
            "        \"\"\"",
            "        return [(None, (\"NULL\", [], False))]",
            "",
            "    def adapt_decimalfield_value(self, value, max_digits=None, decimal_places=None):",
            "        return value",
            "",
            "    def last_executed_query(self, cursor, sql, params):",
            "        # With MySQLdb, cursor objects have an (undocumented) \"_executed\"",
            "        # attribute where the exact query sent to the database is saved.",
            "        # See MySQLdb/cursors.py in the source distribution.",
            "        # MySQLdb returns string, PyMySQL bytes.",
            "        return force_str(getattr(cursor, \"_executed\", None), errors=\"replace\")",
            "",
            "    def no_limit_value(self):",
            "        # 2**64 - 1, as recommended by the MySQL documentation",
            "        return 18446744073709551615",
            "",
            "    def quote_name(self, name):",
            "        if name.startswith(\"`\") and name.endswith(\"`\"):",
            "            return name  # Quoting once is enough.",
            "        return \"`%s`\" % name",
            "",
            "    def return_insert_columns(self, fields):",
            "        # MySQL and MariaDB < 10.5.0 don't support an INSERT...RETURNING",
            "        # statement.",
            "        if not fields:",
            "            return \"\", ()",
            "        columns = [",
            "            \"%s.%s\"",
            "            % (",
            "                self.quote_name(field.model._meta.db_table),",
            "                self.quote_name(field.column),",
            "            )",
            "            for field in fields",
            "        ]",
            "        return \"RETURNING %s\" % \", \".join(columns), ()",
            "",
            "    def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):",
            "        if not tables:",
            "            return []",
            "",
            "        sql = [\"SET FOREIGN_KEY_CHECKS = 0;\"]",
            "        if reset_sequences:",
            "            # It's faster to TRUNCATE tables that require a sequence reset",
            "            # since ALTER TABLE AUTO_INCREMENT is slower than TRUNCATE.",
            "            sql.extend(",
            "                \"%s %s;\"",
            "                % (",
            "                    style.SQL_KEYWORD(\"TRUNCATE\"),",
            "                    style.SQL_FIELD(self.quote_name(table_name)),",
            "                )",
            "                for table_name in tables",
            "            )",
            "        else:",
            "            # Otherwise issue a simple DELETE since it's faster than TRUNCATE",
            "            # and preserves sequences.",
            "            sql.extend(",
            "                \"%s %s %s;\"",
            "                % (",
            "                    style.SQL_KEYWORD(\"DELETE\"),",
            "                    style.SQL_KEYWORD(\"FROM\"),",
            "                    style.SQL_FIELD(self.quote_name(table_name)),",
            "                )",
            "                for table_name in tables",
            "            )",
            "        sql.append(\"SET FOREIGN_KEY_CHECKS = 1;\")",
            "        return sql",
            "",
            "    def sequence_reset_by_name_sql(self, style, sequences):",
            "        return [",
            "            \"%s %s %s %s = 1;\"",
            "            % (",
            "                style.SQL_KEYWORD(\"ALTER\"),",
            "                style.SQL_KEYWORD(\"TABLE\"),",
            "                style.SQL_FIELD(self.quote_name(sequence_info[\"table\"])),",
            "                style.SQL_FIELD(\"AUTO_INCREMENT\"),",
            "            )",
            "            for sequence_info in sequences",
            "        ]",
            "",
            "    def validate_autopk_value(self, value):",
            "        # Zero in AUTO_INCREMENT field does not work without the",
            "        # NO_AUTO_VALUE_ON_ZERO SQL mode.",
            "        if value == 0 and not self.connection.features.allows_auto_pk_0:",
            "            raise ValueError(",
            "                \"The database backend does not accept 0 as a value for AutoField.\"",
            "            )",
            "        return value",
            "",
            "    def adapt_datetimefield_value(self, value):",
            "        if value is None:",
            "            return None",
            "",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        # MySQL doesn't support tz-aware datetimes",
            "        if timezone.is_aware(value):",
            "            if settings.USE_TZ:",
            "                value = timezone.make_naive(value, self.connection.timezone)",
            "            else:",
            "                raise ValueError(",
            "                    \"MySQL backend does not support timezone-aware datetimes when \"",
            "                    \"USE_TZ is False.\"",
            "                )",
            "        return str(value)",
            "",
            "    def adapt_timefield_value(self, value):",
            "        if value is None:",
            "            return None",
            "",
            "        # Expression values are adapted by the database.",
            "        if hasattr(value, \"resolve_expression\"):",
            "            return value",
            "",
            "        # MySQL doesn't support tz-aware times",
            "        if timezone.is_aware(value):",
            "            raise ValueError(\"MySQL backend does not support timezone-aware times.\")",
            "",
            "        return value.isoformat(timespec=\"microseconds\")",
            "",
            "    def max_name_length(self):",
            "        return 64",
            "",
            "    def pk_default_value(self):",
            "        return \"NULL\"",
            "",
            "    def bulk_insert_sql(self, fields, placeholder_rows):",
            "        placeholder_rows_sql = (\", \".join(row) for row in placeholder_rows)",
            "        values_sql = \", \".join(\"(%s)\" % sql for sql in placeholder_rows_sql)",
            "        return \"VALUES \" + values_sql",
            "",
            "    def combine_expression(self, connector, sub_expressions):",
            "        if connector == \"^\":",
            "            return \"POW(%s)\" % \",\".join(sub_expressions)",
            "        # Convert the result to a signed integer since MySQL's binary operators",
            "        # return an unsigned integer.",
            "        elif connector in (\"&\", \"|\", \"<<\", \"#\"):",
            "            connector = \"^\" if connector == \"#\" else connector",
            "            return \"CONVERT(%s, SIGNED)\" % connector.join(sub_expressions)",
            "        elif connector == \">>\":",
            "            lhs, rhs = sub_expressions",
            "            return \"FLOOR(%(lhs)s / POW(2, %(rhs)s))\" % {\"lhs\": lhs, \"rhs\": rhs}",
            "        return super().combine_expression(connector, sub_expressions)",
            "",
            "    def get_db_converters(self, expression):",
            "        converters = super().get_db_converters(expression)",
            "        internal_type = expression.output_field.get_internal_type()",
            "        if internal_type == \"BooleanField\":",
            "            converters.append(self.convert_booleanfield_value)",
            "        elif internal_type == \"DateTimeField\":",
            "            if settings.USE_TZ:",
            "                converters.append(self.convert_datetimefield_value)",
            "        elif internal_type == \"UUIDField\":",
            "            converters.append(self.convert_uuidfield_value)",
            "        return converters",
            "",
            "    def convert_booleanfield_value(self, value, expression, connection):",
            "        if value in (0, 1):",
            "            value = bool(value)",
            "        return value",
            "",
            "    def convert_datetimefield_value(self, value, expression, connection):",
            "        if value is not None:",
            "            value = timezone.make_aware(value, self.connection.timezone)",
            "        return value",
            "",
            "    def convert_uuidfield_value(self, value, expression, connection):",
            "        if value is not None:",
            "            value = uuid.UUID(value)",
            "        return value",
            "",
            "    def binary_placeholder_sql(self, value):",
            "        return (",
            "            \"_binary %s\" if value is not None and not hasattr(value, \"as_sql\") else \"%s\"",
            "        )",
            "",
            "    def subtract_temporals(self, internal_type, lhs, rhs):",
            "        lhs_sql, lhs_params = lhs",
            "        rhs_sql, rhs_params = rhs",
            "        if internal_type == \"TimeField\":",
            "            if self.connection.mysql_is_mariadb:",
            "                # MariaDB includes the microsecond component in TIME_TO_SEC as",
            "                # a decimal. MySQL returns an integer without microseconds.",
            "                return (",
            "                    \"CAST((TIME_TO_SEC(%(lhs)s) - TIME_TO_SEC(%(rhs)s)) \"",
            "                    \"* 1000000 AS SIGNED)\"",
            "                ) % {",
            "                    \"lhs\": lhs_sql,",
            "                    \"rhs\": rhs_sql,",
            "                }, (",
            "                    *lhs_params,",
            "                    *rhs_params,",
            "                )",
            "            return (",
            "                \"((TIME_TO_SEC(%(lhs)s) * 1000000 + MICROSECOND(%(lhs)s)) -\"",
            "                \" (TIME_TO_SEC(%(rhs)s) * 1000000 + MICROSECOND(%(rhs)s)))\"",
            "            ) % {\"lhs\": lhs_sql, \"rhs\": rhs_sql}, tuple(lhs_params) * 2 + tuple(",
            "                rhs_params",
            "            ) * 2",
            "        params = (*rhs_params, *lhs_params)",
            "        return \"TIMESTAMPDIFF(MICROSECOND, %s, %s)\" % (rhs_sql, lhs_sql), params",
            "",
            "    def explain_query_prefix(self, format=None, **options):",
            "        # Alias MySQL's TRADITIONAL to TEXT for consistency with other backends.",
            "        if format and format.upper() == \"TEXT\":",
            "            format = \"TRADITIONAL\"",
            "        elif (",
            "            not format and \"TREE\" in self.connection.features.supported_explain_formats",
            "        ):",
            "            # Use TREE by default (if supported) as it's more informative.",
            "            format = \"TREE\"",
            "        analyze = options.pop(\"analyze\", False)",
            "        prefix = super().explain_query_prefix(format, **options)",
            "        if analyze and self.connection.features.supports_explain_analyze:",
            "            # MariaDB uses ANALYZE instead of EXPLAIN ANALYZE.",
            "            prefix = (",
            "                \"ANALYZE\" if self.connection.mysql_is_mariadb else prefix + \" ANALYZE\"",
            "            )",
            "        if format and not (analyze and not self.connection.mysql_is_mariadb):",
            "            # Only MariaDB supports the analyze option with formats.",
            "            prefix += \" FORMAT=%s\" % format",
            "        return prefix",
            "",
            "    def regex_lookup(self, lookup_type):",
            "        # REGEXP BINARY doesn't work correctly in MySQL 8+ and REGEXP_LIKE",
            "        # doesn't exist in MySQL 5.x or in MariaDB.",
            "        if (",
            "            self.connection.mysql_version < (8, 0, 0)",
            "            or self.connection.mysql_is_mariadb",
            "        ):",
            "            if lookup_type == \"regex\":",
            "                return \"%s REGEXP BINARY %s\"",
            "            return \"%s REGEXP %s\"",
            "",
            "        match_option = \"c\" if lookup_type == \"regex\" else \"i\"",
            "        return \"REGEXP_LIKE(%%s, %%s, '%s')\" % match_option",
            "",
            "    def insert_statement(self, on_conflict=None):",
            "        if on_conflict == OnConflict.IGNORE:",
            "            return \"INSERT IGNORE INTO\"",
            "        return super().insert_statement(on_conflict=on_conflict)",
            "",
            "    def lookup_cast(self, lookup_type, internal_type=None):",
            "        lookup = \"%s\"",
            "        if internal_type == \"JSONField\":",
            "            if self.connection.mysql_is_mariadb or lookup_type in (",
            "                \"iexact\",",
            "                \"contains\",",
            "                \"icontains\",",
            "                \"startswith\",",
            "                \"istartswith\",",
            "                \"endswith\",",
            "                \"iendswith\",",
            "                \"regex\",",
            "                \"iregex\",",
            "            ):",
            "                lookup = \"JSON_UNQUOTE(%s)\"",
            "        return lookup",
            "",
            "    def conditional_expression_supported_in_where_clause(self, expression):",
            "        # MySQL ignores indexes with boolean fields unless they're compared",
            "        # directly to a boolean value.",
            "        if isinstance(expression, (Exists, Lookup)):",
            "            return True",
            "        if isinstance(expression, ExpressionWrapper) and expression.conditional:",
            "            return self.conditional_expression_supported_in_where_clause(",
            "                expression.expression",
            "            )",
            "        if getattr(expression, \"conditional\", False):",
            "            return False",
            "        return super().conditional_expression_supported_in_where_clause(expression)",
            "",
            "    def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):",
            "        if on_conflict == OnConflict.UPDATE:",
            "            conflict_suffix_sql = \"ON DUPLICATE KEY UPDATE %(fields)s\"",
            "            # The use of VALUES() is deprecated in MySQL 8.0.20+. Instead, use",
            "            # aliases for the new row and its columns available in MySQL",
            "            # 8.0.19+.",
            "            if not self.connection.mysql_is_mariadb:",
            "                if self.connection.mysql_version >= (8, 0, 19):",
            "                    conflict_suffix_sql = f\"AS new {conflict_suffix_sql}\"",
            "                    field_sql = \"%(field)s = new.%(field)s\"",
            "                else:",
            "                    field_sql = \"%(field)s = VALUES(%(field)s)\"",
            "            # Use VALUE() on MariaDB.",
            "            else:",
            "                field_sql = \"%(field)s = VALUE(%(field)s)\"",
            "",
            "            fields = \", \".join(",
            "                [",
            "                    field_sql % {\"field\": field}",
            "                    for field in map(self.quote_name, update_fields)",
            "                ]",
            "            )",
            "            return conflict_suffix_sql % {\"fields\": fields}",
            "        return super().on_conflict_suffix_sql(",
            "            fields,",
            "            on_conflict,",
            "            update_fields,",
            "            unique_fields,",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "40": [
                "DatabaseOperations",
                "date_extract_sql"
            ],
            "44": [
                "DatabaseOperations",
                "date_extract_sql"
            ],
            "47": [
                "DatabaseOperations",
                "date_extract_sql"
            ],
            "52": [
                "DatabaseOperations",
                "date_extract_sql"
            ],
            "56": [
                "DatabaseOperations",
                "date_extract_sql"
            ],
            "59": [
                "DatabaseOperations",
                "date_extract_sql"
            ],
            "61": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "62": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "64": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "65": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "66": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "69": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "72": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "73": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "74": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "77": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "79": [
                "DatabaseOperations",
                "date_trunc_sql"
            ],
            "85": [
                "DatabaseOperations",
                "_convert_field_to_tz"
            ],
            "87": [
                "DatabaseOperations",
                "_convert_field_to_tz"
            ],
            "88": [
                "DatabaseOperations",
                "_convert_field_to_tz"
            ],
            "92": [
                "DatabaseOperations",
                "_convert_field_to_tz"
            ],
            "94": [
                "DatabaseOperations",
                "datetime_cast_date_sql"
            ],
            "95": [
                "DatabaseOperations",
                "datetime_cast_date_sql"
            ],
            "96": [
                "DatabaseOperations",
                "datetime_cast_date_sql"
            ],
            "98": [
                "DatabaseOperations",
                "datetime_cast_time_sql"
            ],
            "99": [
                "DatabaseOperations",
                "datetime_cast_time_sql"
            ],
            "100": [
                "DatabaseOperations",
                "datetime_cast_time_sql"
            ],
            "102": [
                "DatabaseOperations",
                "datetime_extract_sql"
            ],
            "103": [
                "DatabaseOperations",
                "datetime_extract_sql"
            ],
            "104": [
                "DatabaseOperations",
                "datetime_extract_sql"
            ],
            "106": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "107": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "109": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "110": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "111": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "112": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "113": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "114": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "115": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "116": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "120": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "121": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "122": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "123": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "126": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "127": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "128": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "129": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "133": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "136": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "137": [
                "DatabaseOperations",
                "datetime_trunc_sql"
            ],
            "139": [
                "DatabaseOperations",
                "time_trunc_sql"
            ],
            "140": [
                "DatabaseOperations",
                "time_trunc_sql"
            ],
            "142": [
                "DatabaseOperations",
                "time_trunc_sql"
            ],
            "143": [
                "DatabaseOperations",
                "time_trunc_sql"
            ],
            "144": [
                "DatabaseOperations",
                "time_trunc_sql"
            ],
            "145": [
                "DatabaseOperations",
                "time_trunc_sql"
            ],
            "148": [
                "DatabaseOperations",
                "time_trunc_sql"
            ],
            "150": [
                "DatabaseOperations",
                "time_trunc_sql"
            ]
        },
        "addLocation": []
    }
}