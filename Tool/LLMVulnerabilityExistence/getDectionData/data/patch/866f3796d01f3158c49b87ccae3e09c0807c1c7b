{
    "web/server/codechecker_server/cmd/server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 212,
                "PatchRowcode": " CONFIG_DIRECTORY, and the credentials are printed to the server's standard"
            },
            "1": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": 213,
                "PatchRowcode": " output. The plaintext credentials are NEVER accessible again.\"\"\")"
            },
            "2": {
                "beforePatchRowNumber": 214,
                "afterPatchRowNumber": 214,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    root_account.add_argument('--reset-root',"
            },
            "4": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                              dest=\"reset_root\","
            },
            "5": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                              action='store_true',"
            },
            "6": {
                "beforePatchRowNumber": 218,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                              default=argparse.SUPPRESS,"
            },
            "7": {
                "beforePatchRowNumber": 219,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                              required=False,"
            },
            "8": {
                "beforePatchRowNumber": 220,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                              help=\"Force the server to recreate the master \""
            },
            "9": {
                "beforePatchRowNumber": 221,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                   \"superuser (root) account name and \""
            },
            "10": {
                "beforePatchRowNumber": 222,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                   \"password. The previous credentials will \""
            },
            "11": {
                "beforePatchRowNumber": 223,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                   \"be invalidated, and the new ones will be \""
            },
            "12": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                   \"printed to the standard output.\")"
            },
            "13": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "14": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": 215,
                "PatchRowcode": "     root_account.add_argument('--force-authentication',"
            },
            "15": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 216,
                "PatchRowcode": "                               dest=\"force_auth\","
            },
            "16": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": 217,
                "PatchRowcode": "                               action='store_true',"
            },
            "17": {
                "beforePatchRowNumber": 932,
                "afterPatchRowNumber": 921,
                "PatchRowcode": "             not os.path.isdir(os.path.dirname(args.sqlite)):"
            },
            "18": {
                "beforePatchRowNumber": 933,
                "afterPatchRowNumber": 922,
                "PatchRowcode": "         os.makedirs(os.path.dirname(args.sqlite))"
            },
            "19": {
                "beforePatchRowNumber": 934,
                "afterPatchRowNumber": 923,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 935,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if 'reset_root' in args:"
            },
            "21": {
                "beforePatchRowNumber": 936,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "22": {
                "beforePatchRowNumber": 937,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            os.remove(os.path.join(args.config_directory, 'root.user'))"
            },
            "23": {
                "beforePatchRowNumber": 938,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            LOG.info(\"Master superuser (root) credentials invalidated and \""
            },
            "24": {
                "beforePatchRowNumber": 939,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                     \"deleted. New ones will be generated...\")"
            },
            "25": {
                "beforePatchRowNumber": 940,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except OSError:"
            },
            "26": {
                "beforePatchRowNumber": 941,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # File doesn't exist."
            },
            "27": {
                "beforePatchRowNumber": 942,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            pass"
            },
            "28": {
                "beforePatchRowNumber": 943,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "29": {
                "beforePatchRowNumber": 944,
                "afterPatchRowNumber": 924,
                "PatchRowcode": "     if 'force_auth' in args:"
            },
            "30": {
                "beforePatchRowNumber": 945,
                "afterPatchRowNumber": 925,
                "PatchRowcode": "         LOG.info(\"'--force-authentication' was passed as a command-line \""
            },
            "31": {
                "beforePatchRowNumber": 946,
                "afterPatchRowNumber": 926,
                "PatchRowcode": "                  \"option. The server will ask for users to authenticate!\")"
            }
        },
        "frontPatchFile": [
            "# -------------------------------------------------------------------------",
            "#",
            "#  Part of the CodeChecker project, under the Apache License v2.0 with",
            "#  LLVM Exceptions. See LICENSE for license information.",
            "#  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception",
            "#",
            "# -------------------------------------------------------------------------",
            "\"\"\"",
            "Handler for the subcommand that is used to start and manage CodeChecker",
            "servers, which are used to query analysis report information.",
            "\"\"\"",
            "",
            "",
            "import argparse",
            "import errno",
            "from functools import partial",
            "import os",
            "import signal",
            "import socket",
            "import sys",
            "import time",
            "from typing import List, Optional, Tuple, cast",
            "",
            "from alembic import config",
            "from alembic import script",
            "from alembic.util import CommandError",
            "import psutil",
            "from sqlalchemy.exc import SQLAlchemyError",
            "from sqlalchemy.orm import sessionmaker",
            "",
            "from codechecker_api_shared.ttypes import DBStatus",
            "",
            "from codechecker_report_converter import twodim",
            "",
            "from codechecker_common import arg, cmd_config, logger, util",
            "from codechecker_common.compatibility.multiprocessing import Pool, cpu_count",
            "",
            "from codechecker_server import instance_manager, server",
            "from codechecker_server.database import database",
            "from codechecker_server.database.config_db_model \\",
            "    import IDENTIFIER as CONFIG_META",
            "from codechecker_server.database.config_db_model \\",
            "    import Product as ORMProduct",
            "from codechecker_server.database.run_db_model \\",
            "    import IDENTIFIER as RUN_META",
            "",
            "from codechecker_web.shared import webserver_context, database_status, \\",
            "    host_check, env",
            "",
            "LOG = logger.get_logger('server')",
            "",
            "",
            "def get_argparser_ctor_args():",
            "    \"\"\"",
            "    This method returns a dict containing the kwargs for constructing an",
            "    argparse.ArgumentParser (either directly or as a subparser).",
            "    \"\"\"",
            "",
            "    return {",
            "        'prog': 'CodeChecker server',",
            "        'formatter_class': arg.RawDescriptionDefaultHelpFormatter,",
            "",
            "        # Description is shown when the command's help is queried directly",
            "        'description': \"\"\"",
            "The CodeChecker Web server is used to handle the storage and navigation of",
            "analysis results. A started server can be connected to via a Web browser, or",
            "by using the 'CodeChecker cmd' command-line client.\"\"\",",
            "",
            "        # Help is shown when the \"parent\" CodeChecker command lists the",
            "        # individual subcommands.",
            "        'help': \"Start and manage the CodeChecker Web server.\"",
            "    }",
            "",
            "",
            "def add_arguments_to_parser(parser):",
            "    \"\"\"",
            "    Add the subcommand's arguments to the given argparse.ArgumentParser.",
            "    \"\"\"",
            "",
            "    default_workspace = env.get_default_workspace()",
            "",
            "    # TODO: --workspace is an outdated concept in 'store'. Later on,",
            "    # it shall be deprecated, as changes to db_handler commence.",
            "    parser.add_argument('-w', '--workspace',",
            "                        type=str,",
            "                        dest=\"workspace\",",
            "                        default=default_workspace,",
            "                        required=False,",
            "                        help=\"Directory where CodeChecker can store analysis \"",
            "                             \"result related data, such as the database. \"",
            "                             \"(Cannot be specified at the same time with \"",
            "                             \"'--sqlite' or '--config-directory'.)\")",
            "",
            "    parser.add_argument('-f', '--config-directory',",
            "                        type=str,",
            "                        dest=\"config_directory\",",
            "                        default=default_workspace,",
            "                        required=False,",
            "                        help=\"Directory where CodeChecker server should read \"",
            "                             \"server-specific configuration (such as \"",
            "                             \"authentication settings, TLS certificate\"",
            "                             \" (cert.pem) and key (key.pem)) from.\")",
            "",
            "    parser.add_argument('--host',",
            "                        type=str,",
            "                        dest=\"listen_address\",",
            "                        default=\"localhost\",",
            "                        required=False,",
            "                        help=\"The IP address or hostname of the server on \"",
            "                             \"which it should listen for connections. \"",
            "                             \"For IPv6 listening, specify an IPv6 address, \"",
            "                             \"such as \\\"::1\\\".\")",
            "",
            "    # TODO: -v/--view-port is too verbose. The server's -p/--port is used",
            "    # symmetrically in 'CodeChecker cmd' anyways.",
            "    parser.add_argument('-v', '--view-port',  # TODO: <- Deprecate and remove.",
            "                        '-p', '--port',",
            "                        type=int,",
            "                        dest=\"view_port\",",
            "                        metavar='PORT',",
            "                        default=8001,",
            "                        required=False,",
            "                        help=\"The port which will be used as listen port for \"",
            "                             \"the server.\")",
            "",
            "    # TODO: This should be removed later on, in favour of --host.",
            "    parser.add_argument('--not-host-only',",
            "                        dest=\"not_host_only\",",
            "                        action=\"store_true\",",
            "                        required=False,",
            "                        help=\"If specified, storing and viewing the results \"",
            "                             \"will be possible not only by browsers and \"",
            "                             \"clients running locally, but to everyone, who \"",
            "                             \"can access the server over the Internet. \"",
            "                             \"(Equivalent to specifying '--host \\\"::\\\"'.)\")",
            "",
            "    parser.add_argument('--skip-db-cleanup',",
            "                        dest=\"skip_db_cleanup\",",
            "                        action='store_true',",
            "                        default=False,",
            "                        required=False,",
            "                        help=\"Skip performing cleanup jobs on the database \"",
            "                             \"like removing unused files.\")",
            "",
            "    cmd_config.add_option(parser)",
            "",
            "    dbmodes = parser.add_argument_group(\"configuration database arguments\")",
            "",
            "    dbmodes = dbmodes.add_mutually_exclusive_group(required=False)",
            "",
            "    dbmodes.add_argument('--sqlite',",
            "                         type=str,",
            "                         dest=\"sqlite\",",
            "                         metavar='SQLITE_FILE',",
            "                         default=os.path.join(",
            "                             '<CONFIG_DIRECTORY>',",
            "                             \"config.sqlite\"),",
            "                         required=False,",
            "                         help=\"Path of the SQLite database file to use.\")",
            "",
            "    dbmodes.add_argument('--postgresql',",
            "                         dest=\"postgresql\",",
            "                         action='store_true',",
            "                         required=False,",
            "                         default=argparse.SUPPRESS,",
            "                         help=\"Specifies that a PostgreSQL database is to be \"",
            "                              \"used instead of SQLite. See the \\\"PostgreSQL \"",
            "                              \"arguments\\\" section on how to configure the \"",
            "                              \"database connection.\")",
            "",
            "    pgsql = parser.add_argument_group(\"PostgreSQL arguments\",",
            "                                      \"Values of these arguments are ignored, \"",
            "                                      \"unless '--postgresql' is specified!\")",
            "",
            "    # TODO: --dbSOMETHING arguments are kept to not break interface from",
            "    # old command. Database using commands such as \"CodeChecker store\" no",
            "    # longer supports these --- it would be ideal to break and remove args",
            "    # with this style and only keep --db-SOMETHING.",
            "    pgsql.add_argument('--dbaddress', '--db-host',",
            "                       type=str,",
            "                       dest=\"dbaddress\",",
            "                       default=\"localhost\",",
            "                       required=False,",
            "                       help=\"Database server address.\")",
            "",
            "    pgsql.add_argument('--dbport', '--db-port',",
            "                       type=int,",
            "                       dest=\"dbport\",",
            "                       default=5432,",
            "                       required=False,",
            "                       help=\"Database server port.\")",
            "",
            "    pgsql.add_argument('--dbusername', '--db-username',",
            "                       type=str,",
            "                       dest=\"dbusername\",",
            "                       default='codechecker',",
            "                       required=False,",
            "                       help=\"Username to use for connection.\")",
            "",
            "    pgsql.add_argument('--dbname', '--db-name',",
            "                       type=str,",
            "                       dest=\"dbname\",",
            "                       default=\"config\",",
            "                       required=False,",
            "                       help=\"Name of the database to use.\")",
            "",
            "    root_account = parser.add_argument_group(",
            "        \"root account arguments\",",
            "        \"\"\"",
            "Servers automatically create a root user to access the server's configuration",
            "via the clients. This user is created at first start and saved in the",
            "CONFIG_DIRECTORY, and the credentials are printed to the server's standard",
            "output. The plaintext credentials are NEVER accessible again.\"\"\")",
            "",
            "    root_account.add_argument('--reset-root',",
            "                              dest=\"reset_root\",",
            "                              action='store_true',",
            "                              default=argparse.SUPPRESS,",
            "                              required=False,",
            "                              help=\"Force the server to recreate the master \"",
            "                                   \"superuser (root) account name and \"",
            "                                   \"password. The previous credentials will \"",
            "                                   \"be invalidated, and the new ones will be \"",
            "                                   \"printed to the standard output.\")",
            "",
            "    root_account.add_argument('--force-authentication',",
            "                              dest=\"force_auth\",",
            "                              action='store_true',",
            "                              default=argparse.SUPPRESS,",
            "                              required=False,",
            "                              help=\"Force the server to run in \"",
            "                                   \"authentication requiring mode, despite \"",
            "                                   \"the configuration value in \"",
            "                                   \"'server_config.json'. This is needed \"",
            "                                   \"if you need to edit the product \"",
            "                                   \"configuration of a server that would not \"",
            "                                   \"require authentication otherwise.\")",
            "",
            "    instance_mgmnt = parser.add_argument_group(\"running server management\")",
            "",
            "    instance_mgmnt = instance_mgmnt. \\",
            "        add_mutually_exclusive_group(required=False)",
            "",
            "    instance_mgmnt.add_argument('-l', '--list',",
            "                                dest=\"list\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"List the servers that has been started \"",
            "                                     \"by you.\")",
            "",
            "    instance_mgmnt.add_argument('-r', '--reload',",
            "                                dest=\"reload\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Sends the CodeChecker server process a \"",
            "                                     \"SIGHUP signal, causing it to reread \"",
            "                                     \"it's configuration files.\")",
            "",
            "    # TODO: '-s' was removed from 'quickcheck', it shouldn't be here either?",
            "    instance_mgmnt.add_argument('-s', '--stop',",
            "                                dest=\"stop\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Stops the server associated with \"",
            "                                     \"the given view-port and workspace.\")",
            "",
            "    instance_mgmnt.add_argument('--stop-all',",
            "                                dest=\"stop_all\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Stops all of your running CodeChecker \"",
            "                                     \"server instances.\")",
            "",
            "    database_mgmnt = parser.add_argument_group(",
            "            \"Database management arguments.\",",
            "            \"\"\"",
            "WARNING these commands needs to be called with the same workspace and",
            "configuration arguments as the server so the configuration database will be",
            "found which is required for the schema migration. Migration can be done",
            "without a running server but pay attention to use the same arguments which",
            "will be used to start the server.",
            "",
            "NOTE:",
            "Before migration it is advised to create a full a backup of the product",
            "databases.",
            "\"\"\")",
            "",
            "    database_mgmnt = database_mgmnt. \\",
            "        add_mutually_exclusive_group(required=False)",
            "",
            "    database_mgmnt.add_argument('--db-status',",
            "                                type=str,",
            "                                dest=\"status\",",
            "                                action='store',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Name of the product to get \"",
            "                                     \"the database status for. \"",
            "                                     \"Use 'all' to list the database \"",
            "                                     \"statuses for all of the products.\")",
            "",
            "    database_mgmnt.add_argument('--db-upgrade-schema',",
            "                                type=str,",
            "                                dest='product_to_upgrade',",
            "                                action='store',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Name of the product to upgrade to the \"",
            "                                     \"latest database schema available in \"",
            "                                     \"the package. Use 'all' to upgrade all \"",
            "                                     \"of the products. \"",
            "                                     \"NOTE: Before migration it is advised\"",
            "                                     \" to create a full backup of \"",
            "                                     \"the product databases.\")",
            "",
            "    database_mgmnt.add_argument('--db-force-upgrade',",
            "                                dest='force_upgrade',",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Force the server to do database \"",
            "                                     \"migration without user interaction. \"",
            "                                     \"NOTE: Please use with caution and \"",
            "                                     \"before automatic migration it is \"",
            "                                     \"advised to create a full backup of the \"",
            "                                     \"product databases.\")",
            "",
            "    logger.add_verbose_arguments(parser)",
            "",
            "    def __handle(args):",
            "        \"\"\"Custom handler for 'server' so custom error messages can be",
            "        printed without having to capture 'parser' in main.\"\"\"",
            "",
            "        def arg_match(options):",
            "            return util.arg_match(options, sys.argv[1:])",
            "",
            "        # See if there is a \"PostgreSQL argument\" specified in the invocation",
            "        # without '--postgresql' being there. There is no way to distinguish",
            "        # a default argument and a deliberately specified argument without",
            "        # inspecting sys.argv.",
            "        options = ['--dbaddress', '--dbport', '--dbusername', '--dbname',",
            "                   '--db-host', '--db-port', '--db-username', '--db-name']",
            "        psql_args_matching = arg_match(options)",
            "        if any(psql_args_matching) and 'postgresql' not in args:",
            "            parser.error(f\"argument {psql_args_matching[0]}: not allowed \"",
            "                         \"without argument --postgresql\")",
            "            # parser.error() terminates with return code 2.",
            "",
            "        # --not-host-only is a \"shortcut\", actually a to-be-deprecated",
            "        # call which means '--host \"\"'.",
            "        # TODO: Actually deprecate --not-host-only later on.",
            "        options = ['--not-host-only', '--host']",
            "        if set(arg_match(options)) == set(options):",
            "            parser.error(\"argument --not-host-only: not allowed with \"",
            "                         \"argument --host, as it is a shortcut to --host \"",
            "                         \"\\\"::\\\"\")",
            "        else:",
            "            # Apply the shortcut.",
            "            if arg_match(['--not-host-only']):",
            "                args.listen_address = \"::\"  # Listen on every interface.",
            "",
            "            # --not-host-only is just a shortcut optstring, no actual use",
            "            # is intended later on.",
            "            delattr(args, 'not_host_only')",
            "",
            "        # --workspace and --sqlite cannot be specified either, as",
            "        # both point to a database location.",
            "        options = ['--sqlite', '--workspace']",
            "        options_short = ['--sqlite', '-w']",
            "        if set(arg_match(options)) == set(options) or \\",
            "                set(arg_match(options_short)) == set(options_short):",
            "            parser.error(\"argument --sqlite: not allowed with \"",
            "                         \"argument --workspace\")",
            "",
            "        # --workspace and --config-directory also aren't allowed together now,",
            "        # the latter one is expected to replace the earlier.",
            "        options = ['--config-directory', '--workspace']",
            "        options_short = ['--config-directory', '-w']",
            "        if set(arg_match(options)) == set(options) or \\",
            "                set(arg_match(options_short)) == set(options_short):",
            "            parser.error(\"argument --config-directory: not allowed with \"",
            "                         \"argument --workspace\")",
            "",
            "        # If workspace is specified, sqlite is workspace/config.sqlite",
            "        # and config_directory is the workspace directory.",
            "        if arg_match(['--workspace', '-w']):",
            "            args.config_directory = args.workspace",
            "            args.sqlite = os.path.join(args.workspace,",
            "                                       'config.sqlite')",
            "            setattr(args, 'dbdatadir', os.path.join(args.workspace,",
            "                                                    'pgsql_data'))",
            "",
            "        # Workspace should not exist as a Namespace key.",
            "        delattr(args, 'workspace')",
            "",
            "        if '<CONFIG_DIRECTORY>' in args.sqlite:",
            "            # Replace the placeholder variable with the actual value.",
            "            args.sqlite = args.sqlite.replace('<CONFIG_DIRECTORY>',",
            "                                              args.config_directory)",
            "",
            "        # Convert relative sqlite file path to absolute.",
            "        if 'sqlite' in args:",
            "            args.sqlite = os.path.abspath(args.sqlite)",
            "",
            "        if 'postgresql' not in args:",
            "            # Later called database modules need the argument to be actually",
            "            # present, even though the default is suppressed in the optstring.",
            "            setattr(args, 'postgresql', False)",
            "",
            "            # This is not needed by the database starter as we are",
            "            # running SQLite.",
            "            if 'dbdatadir' in args:",
            "                delattr(args, 'dbdatadir')",
            "        else:",
            "            # If --postgresql is given, --sqlite is useless.",
            "            delattr(args, 'sqlite')",
            "",
            "        # Indicate in args that we are in instance manager mode.",
            "        if \"list\" in args or \"stop\" in args or \"stop_all\" in args:",
            "            setattr(args, \"instance_manager\", True)",
            "",
            "        # If everything is fine, do call the handler for the subcommand.",
            "        main(args)",
            "",
            "    parser.set_defaults(",
            "        func=__handle, func_process_config_file=cmd_config.process_config_file)",
            "",
            "",
            "def print_prod_status(prod_status):",
            "    \"\"\"",
            "    Print the database statuses for each of the products.",
            "    \"\"\"",
            "",
            "    header = ['Product endpoint', 'Database status',",
            "              'Database location',",
            "              'Schema version in the database',",
            "              'Schema version in the package']",
            "    rows = []",
            "",
            "    for k, v in prod_status.items():",
            "        db_status, schema_ver, package_ver, db_location = v",
            "        db_status_msg = database_status.db_status_msg.get(db_status)",
            "        if schema_ver == package_ver:",
            "            schema_ver += \" (up to date)\"",
            "        rows.append([k, db_status_msg, db_location, str(schema_ver),",
            "                     package_ver])",
            "",
            "    prod_status = twodim.to_str('table',",
            "                                header,",
            "                                rows,",
            "                                sort_by_column_number=0)",
            "    LOG.info('Status of products:\\n%s', prod_status)",
            "",
            "",
            "def get_schema_version_from_package(migration_root):",
            "    \"\"\"",
            "    Returns the latest schema version in the package.",
            "    \"\"\"",
            "",
            "    cfg = config.Config()",
            "    cfg.set_main_option(\"script_location\", migration_root)",
            "    pckg_schema_ver = script.ScriptDirectory.from_config(cfg)",
            "    return pckg_schema_ver.get_current_head()",
            "",
            "",
            "def check_product_db_status(cfg_sql_server, migration_root, environ):",
            "    \"\"\"",
            "    Check the products for database statuses.",
            "",
            "    :returns: dictionary of product endpoints with database statuses",
            "    \"\"\"",
            "    engine = cfg_sql_server.create_engine()",
            "    config_session = sessionmaker(bind=engine)",
            "    sess = config_session()",
            "",
            "    products: List[ORMProduct] = []",
            "    try:",
            "        products = sess.query(ORMProduct) \\",
            "            .order_by(ORMProduct.endpoint.asc()) \\",
            "            .all()",
            "    except Exception as ex:",
            "        LOG.debug(ex)",
            "        LOG.error(\"Failed to get product configurations from the database.\")",
            "        LOG.error(\"Please check your command arguments.\")",
            "        sys.exit(1)",
            "    finally:",
            "        # sys.exit raises SystemExit, which still performs finally clauses!",
            "        sess.close()",
            "        engine.dispose()",
            "",
            "    package_schema = get_schema_version_from_package(migration_root)",
            "",
            "    db_errors = [DBStatus.FAILED_TO_CONNECT,",
            "                 DBStatus.MISSING,",
            "                 DBStatus.SCHEMA_INIT_ERROR,",
            "                 DBStatus.SCHEMA_MISSING]",
            "",
            "    prod_status = {}",
            "    for pd in products:",
            "        db = database.SQLServer.from_connection_string(pd.connection,",
            "                                                       pd.endpoint,",
            "                                                       RUN_META,",
            "                                                       migration_root,",
            "                                                       interactive=False,",
            "                                                       env=environ)",
            "        db_location = db.get_db_location()",
            "",
            "        try:",
            "            status = db.connect()",
            "            s_ver = db.get_schema_version()",
            "            if s_ver in db_errors:",
            "                s_ver = None",
            "            prod_status[pd.endpoint] = (status, s_ver, package_schema,",
            "                                        db_location)",
            "        except Exception:",
            "            LOG.error(\"Unable to get the status for product '%s', \"",
            "                      \"considering as if the connection failed.\",",
            "                      pd.endpoint)",
            "            prod_status[pd.endpoint] = (DBStatus.FAILED_TO_CONNECT, None,",
            "                                        package_schema, db_location)",
            "",
            "    return prod_status",
            "",
            "",
            "def __db_status_check(cfg_sql_server, migration_root, environ,",
            "                      product_name=None) -> int:",
            "    \"\"\"",
            "    Check and print database statuses for the given product.",
            "    \"\"\"",
            "    if not product_name:",
            "        return 0",
            "",
            "    LOG.debug(\"Checking database status for %s product.\", product_name)",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server, migration_root,",
            "                                            environ)",
            "",
            "    if product_name != \"all\":",
            "        avail = prod_statuses.get(product_name)",
            "        if not avail:",
            "            LOG.error(\"No product was found with this endpoint: %s\",",
            "                      str(product_name))",
            "            return 1",
            "",
            "        prod_statuses = {k: v for k, v in prod_statuses.items()",
            "                         if k == product_name}",
            "",
            "    print_prod_status(prod_statuses)",
            "    return 0",
            "",
            "",
            "class NonExistentProductError(Exception):",
            "    def __init__(self, product_name):",
            "        super().__init__(f\"Non-existent product '{product_name}'\")",
            "        self.product_name = product_name",
            "",
            "",
            "def __db_migration(migration_root,",
            "                   environ,",
            "                   endpoint: str,",
            "                   connection_string: str,",
            "                   init_instead_of_upgrade: bool) -> DBStatus:",
            "    try:",
            "        db = database.SQLServer.from_connection_string(connection_string,",
            "                                                       endpoint,",
            "                                                       RUN_META,",
            "                                                       migration_root,",
            "                                                       interactive=False,",
            "                                                       env=environ)",
            "        if init_instead_of_upgrade:",
            "            LOG.info(\"[%s] Initialising...\", endpoint)",
            "            status = db.connect(init=True)",
            "        else:",
            "            LOG.info(\"[%s] Upgrading...\", endpoint)",
            "            db.connect(init=False)",
            "            status = db.upgrade()",
            "",
            "        status_str = database_status.db_status_msg.get(",
            "            status, \"Unknown database status\")",
            "        LOG.info(\"[%s] Done %s. %s\", endpoint,",
            "                 \"initialising\" if init_instead_of_upgrade else \"upgrading\",",
            "                 status_str)",
            "        return status",
            "    except (CommandError, SQLAlchemyError):",
            "        LOG.error(\"A database error occurred during the init/migration of \"",
            "                  \"'%s'\", endpoint)",
            "        import traceback",
            "        traceback.print_exc()",
            "        return DBStatus.SCHEMA_INIT_ERROR if init_instead_of_upgrade \\",
            "            else DBStatus.SCHEMA_UPGRADE_FAILED",
            "    except Exception as e:",
            "        LOG.error(\"A generic error '%s' occurred during the init/migration \"",
            "                  \"of '%s'\", str(type(e)), endpoint)",
            "        import traceback",
            "        traceback.print_exc()",
            "        return DBStatus.SCHEMA_INIT_ERROR if init_instead_of_upgrade \\",
            "            else DBStatus.SCHEMA_UPGRADE_FAILED",
            "",
            "",
            "def __db_migration_multiple(",
            "    cfg_sql_server, migration_root, environ,",
            "    products_requested_for_upgrade: Optional[List[str]] = None,",
            "    force_upgrade: bool = False",
            ") -> int:",
            "    \"\"\"",
            "    Migrates the schema for the product database",
            "    ``products_requested_for_upgrade`` if specified, or all configured",
            "    products (default).",
            "    \"\"\"",
            "    LOG.info(\"Preparing schema upgrade for '%s'\",",
            "             \"', '\".join(products_requested_for_upgrade)",
            "             if products_requested_for_upgrade else \"<all products>\")",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server,",
            "                                            migration_root,",
            "                                            environ)",
            "    products_to_upgrade: List[str] = []",
            "    for endpoint in (products_requested_for_upgrade or []):",
            "        avail = prod_statuses.get(endpoint)",
            "        if not avail:",
            "            LOG.error(\"No product was found with endpoint '%s'\", endpoint)",
            "            return 1",
            "        products_to_upgrade.append(endpoint)",
            "",
            "    products_to_upgrade = list(prod_statuses.keys())",
            "    products_to_upgrade.sort()",
            "",
            "    def _get_migration_decisions() -> List[Tuple[str, str, bool]]:",
            "        # The lifetime of the CONFIG database connection is scoped to this",
            "        # helper function, as keeping it alive throughout PRODUCT migrations",
            "        # could cause timeouts.",
            "        cfg_engine = cfg_sql_server.create_engine()",
            "        cfg_session_factory = sessionmaker(bind=cfg_engine)",
            "        cfg_session = cfg_session_factory()",
            "",
            "        scheduled_upgrades_or_inits: List[Tuple[str, str, bool]] = []",
            "        for endpoint in products_to_upgrade:",
            "            LOG.info(\"Checking: %s\", endpoint)",
            "            connection_str: Optional[str] = None",
            "",
            "            try:",
            "                product: Optional[ORMProduct] = cfg_session \\",
            "                    .query(ORMProduct.connection) \\",
            "                    .filter(ORMProduct.endpoint == endpoint) \\",
            "                    .one_or_none()",
            "                if product is None:",
            "                    raise NonExistentProductError(endpoint)",
            "",
            "                connection_str = product.connection",
            "            except NonExistentProductError as nepe:",
            "                LOG.error(\"Attempted to upgrade product '%s', but it was not \"",
            "                          \"found in the server's configuration database.\",",
            "                          nepe.product_name)",
            "                continue",
            "            except Exception:",
            "                LOG.error(\"Failed to get the configuration for product '%s'\",",
            "                          endpoint)",
            "                import traceback",
            "                traceback.print_exc()",
            "                continue",
            "",
            "            try:",
            "                db = database.SQLServer.from_connection_string(",
            "                    cast(str, connection_str),",
            "                    endpoint,",
            "                    RUN_META,",
            "                    migration_root,",
            "                    interactive=False,",
            "                    env=environ)",
            "                db_status = db.connect()",
            "",
            "                status_str = database_status.db_status_msg.get(",
            "                    db_status, \"Unknown database status\")",
            "                LOG.info(status_str)",
            "",
            "                if db_status == DBStatus.SCHEMA_MISSING:",
            "                    question = \"Do you want to initialize a new schema for \" \\",
            "                               f\"'{endpoint}'\" \\",
            "                               \"? Y(es)/n(o) \"",
            "                    if force_upgrade or env.get_user_input(question):",
            "                        LOG.info(\"[%s] Schema will be initialised...\",",
            "                                 endpoint)",
            "                        scheduled_upgrades_or_inits.append(",
            "                            (endpoint, cast(str, connection_str), True))",
            "                    else:",
            "                        LOG.info(\"[%s] No schema initialization will be done.\",",
            "                                 endpoint)",
            "                elif db_status == DBStatus.SCHEMA_MISMATCH_OK:",
            "                    question = f\"Do you want to upgrade '{endpoint}' to new \" \\",
            "                               \"schema? Y(es)/n(o) \"",
            "                    if force_upgrade or env.get_user_input(question):",
            "                        LOG.info(\"[%s] Schema will be upgraded...\", endpoint)",
            "                        scheduled_upgrades_or_inits.append(",
            "                            (endpoint, cast(str, connection_str), False))",
            "                    else:",
            "                        LOG.info(\"[%s] No schema migration will be done.\",",
            "                                 endpoint)",
            "            except (CommandError, SQLAlchemyError):",
            "                LOG.error(\"A database error occurred during the preparation \"",
            "                          \"for the init/migration of '%s'\", endpoint)",
            "                import traceback",
            "                traceback.print_exc()",
            "            except Exception as e:",
            "                LOG.error(\"A generic error '%s' occurred during the \"",
            "                          \"preparation for the init/migration of '%s'\",",
            "                          str(type(e)), endpoint)",
            "                import traceback",
            "                traceback.print_exc()",
            "",
            "        cfg_session.close()",
            "        cfg_engine.dispose()",
            "        return scheduled_upgrades_or_inits",
            "",
            "    LOG.warning(\"Please note after migration only newer CodeChecker versions \"",
            "                \"can be used to start the server!\")",
            "    LOG.warning(\"It is advised to make a full backup of your run databases.\")",
            "    LOG.info(\"========================\")",
            "    scheduled_upgrades_or_inits = _get_migration_decisions()",
            "    LOG.info(\"========================\")",
            "",
            "    if scheduled_upgrades_or_inits:",
            "        failed_products: List[Tuple[str, DBStatus]] = []",
            "        thr_count = util.clamp(1, len(scheduled_upgrades_or_inits),",
            "                               cpu_count())",
            "        with Pool(max_workers=thr_count) as executor:",
            "            LOG.info(\"Initialising/upgrading products using %d concurrent \"",
            "                     \"jobs...\", thr_count)",
            "            for product_cfg, return_status in \\",
            "                    zip(scheduled_upgrades_or_inits, executor.map(",
            "                        # Bind the first 2 non-changing arguments of",
            "                        # __db_migration, this is fixed for the execution.",
            "                        partial(__db_migration, migration_root, environ),",
            "                        # Transform List[Tuple[str, str, bool]] into an",
            "                        # Iterable[Tuple[str], Tuple[str], Tuple[bool]],",
            "                        # and immediately unpack it, thus providing the other",
            "                        # 3 arguments of __db_migration as a parameter pack.",
            "                        *zip(*scheduled_upgrades_or_inits))):",
            "                if return_status != DBStatus.OK:",
            "                    failed_products.append((product_cfg[0], return_status))",
            "",
            "        if failed_products:",
            "            prod_status = []",
            "            for p in failed_products:",
            "                status = database_status.db_status_msg.get(",
            "                    p[1], \"Unknown database status\")",
            "                prod_status.append(f\"'{p[0]}' ({status})\")",
            "",
            "            LOG.error(\"The following products failed to upgrade: %s\",",
            "                      ', '.join(prod_status))",
            "        else:",
            "            LOG.info(\"Schema initialisation(s)/upgrade(s) executed \"",
            "                     \"successfully.\")",
            "    LOG.info(\"========================\")",
            "",
            "    # This function always returns 0 if the upgrades were attempted, because",
            "    # the server can start with some products that have failed to init/migrate.",
            "    # It will just simply disallow the connection to those products.",
            "    return 0",
            "",
            "",
            "def kill_process_tree(parent_pid, recursive=False):",
            "    \"\"\"Stop the process tree try it gracefully first.",
            "",
            "    Try to stop the parent and child processes gracefuly",
            "    first if they do not stop in time send a kill signal",
            "    to every member of the process tree.",
            "",
            "    There is a similar function in the analyzer part please",
            "    consider to update that in case of changing this.",
            "    \"\"\"",
            "    proc = psutil.Process(parent_pid)",
            "    children = proc.children(recursive)",
            "",
            "    # Send a SIGTERM (Ctrl-C) to the main process",
            "    proc.terminate()",
            "",
            "    # If children processes don't stop gracefully in time,",
            "    # slaughter them by force.",
            "    _, still_alive = psutil.wait_procs(children, timeout=5)",
            "    for p in still_alive:",
            "        p.kill()",
            "",
            "    # Wait until this process is running.",
            "    n = 0",
            "    timeout = 10",
            "    while proc.is_running():",
            "        if n > timeout:",
            "            LOG.warning(\"Waiting for process %s to stop has been timed out\"",
            "                        \"(timeout = %s)! Process is still running!\",",
            "                        parent_pid, timeout)",
            "            break",
            "",
            "        time.sleep(1)",
            "        n += 1",
            "",
            "",
            "def __instance_management(args):",
            "    \"\"\"Handles the instance-manager commands --list/--stop/--stop-all.\"\"\"",
            "",
            "    # TODO: The server stopping and listing must be revised on its invocation",
            "    # once \"workspace\", as a concept, is removed.",
            "    # QUESTION: What is the bestest way here to identify a server for the user?",
            "    if 'list' in args:",
            "        instances = instance_manager.get_instances()",
            "",
            "        instances_on_multiple_hosts = any(True for inst in instances",
            "                                          if inst['hostname'] !=",
            "                                          socket.gethostname())",
            "        if not instances_on_multiple_hosts:",
            "            head = ['Workspace', 'View port']",
            "        else:",
            "            head = ['Workspace', 'Computer host', 'View port']",
            "",
            "        rows = []",
            "        for instance in instances:",
            "            if not instances_on_multiple_hosts:",
            "                rows.append((instance['workspace'], str(instance['port'])))",
            "            else:",
            "                rows.append((instance['workspace'],",
            "                             instance['hostname']",
            "                             if instance['hostname'] != socket.gethostname()",
            "                             else '',",
            "                             str(instance['port'])))",
            "",
            "        print(\"Your running CodeChecker servers:\")",
            "        print(twodim.to_str('table', head, rows))",
            "    elif 'stop' in args or 'stop_all' in args:",
            "        for i in instance_manager.get_instances():",
            "            if i['hostname'] != socket.gethostname():",
            "                continue",
            "",
            "            # A STOP only stops the server associated with the given workspace",
            "            # and view-port.",
            "            if 'stop' in args and \\",
            "                not (i['port'] == args.view_port and",
            "                     os.path.abspath(i['workspace']) ==",
            "                     os.path.abspath(args.config_directory)):",
            "                continue",
            "",
            "            try:",
            "                kill_process_tree(i['pid'])",
            "                LOG.info(\"Stopped CodeChecker server running on port %s \"",
            "                         \"in workspace %s (PID: %s)\",",
            "                         i['port'], i['workspace'], i['pid'])",
            "            except Exception:",
            "                # Let the exception come out if the commands fail",
            "                LOG.error(\"Couldn't stop process PID #%s\", str(i['pid']))",
            "                raise",
            "",
            "",
            "def __reload_config(args):",
            "    \"\"\"",
            "    Sends the CodeChecker server process a SIGHUP signal, causing it to",
            "    reread it's configuration files.",
            "    \"\"\"",
            "    for i in instance_manager.get_instances():",
            "        if i['hostname'] != socket.gethostname():",
            "            continue",
            "",
            "        # A RELOAD only reloads the server associated with the given workspace",
            "        # and view-port.",
            "        if 'reload' in args and \\",
            "                not (i['port'] == args.view_port and",
            "                     os.path.abspath(i['workspace']) ==",
            "                     os.path.abspath(args.config_directory)):",
            "            continue",
            "",
            "        try:",
            "            if sys.platform != \"win32\":",
            "                os.kill(i['pid'], signal.SIGHUP)",
            "        except Exception:",
            "            LOG.error(\"Couldn't reload configuration file for process PID #%s\",",
            "                      str(i['pid']))",
            "            raise",
            "",
            "",
            "def is_localhost(address):",
            "    \"\"\"",
            "    Check if address is one of the valid values and try to get the",
            "    IP-addresses from the system.",
            "    \"\"\"",
            "",
            "    valid_values = ['localhost', '0.0.0.0', '*', '::1']",
            "",
            "    try:",
            "        valid_values.append(socket.gethostbyname('localhost'))",
            "    except socket.herror:",
            "        LOG.debug(\"Failed to get IP address for localhost.\")",
            "",
            "    try:",
            "        valid_values.append(socket.gethostbyname(socket.gethostname()))",
            "    except (socket.herror, socket.gaierror):",
            "        LOG.debug(\"Failed to get IP address for hostname '%s'\",",
            "                  socket.gethostname())",
            "",
            "    return address in valid_values",
            "",
            "",
            "def server_init_start(args):",
            "    \"\"\"",
            "    Start or manage a CodeChecker report server.",
            "    \"\"\"",
            "",
            "    if 'list' in args or 'stop' in args or 'stop_all' in args:",
            "        # Set the instance manager flag to True to be able watch for it during",
            "        # logger setup.",
            "        setattr(args, \"instance_manager\", True)",
            "        __instance_management(args)",
            "        sys.exit(0)",
            "",
            "    if 'reload' in args:",
            "        __reload_config(args)",
            "        sys.exit(0)",
            "",
            "    # Actual server starting from this point.",
            "    if not host_check.check_zlib():",
            "        raise ModuleNotFoundError(\"zlib is not available on the system!\")",
            "",
            "    # WARNING",
            "    # In case of SQLite args.dbaddress default value is used",
            "    # for which the is_localhost should return true.",
            "    if is_localhost(args.dbaddress) and \\",
            "            not os.path.exists(args.config_directory):",
            "        os.makedirs(args.config_directory)",
            "",
            "    # Make sure the SQLite file can be created if it not exists.",
            "    if 'sqlite' in args and \\",
            "            not os.path.isdir(os.path.dirname(args.sqlite)):",
            "        os.makedirs(os.path.dirname(args.sqlite))",
            "",
            "    if 'reset_root' in args:",
            "        try:",
            "            os.remove(os.path.join(args.config_directory, 'root.user'))",
            "            LOG.info(\"Master superuser (root) credentials invalidated and \"",
            "                     \"deleted. New ones will be generated...\")",
            "        except OSError:",
            "            # File doesn't exist.",
            "            pass",
            "",
            "    if 'force_auth' in args:",
            "        LOG.info(\"'--force-authentication' was passed as a command-line \"",
            "                 \"option. The server will ask for users to authenticate!\")",
            "",
            "    context = webserver_context.get_context()",
            "    context.codechecker_workspace = args.config_directory",
            "    context.db_username = args.dbusername",
            "",
            "    environ = env.extend(context.path_env_extra,",
            "                         context.ld_lib_path_extra)",
            "",
            "    cfg_sql_server = database.SQLServer.from_cmdline_args(",
            "        vars(args), \"config\", CONFIG_META, context.config_migration_root,",
            "        interactive=True, env=environ)",
            "",
            "    LOG.info(\"Checking configuration database ...\")",
            "    db_status = cfg_sql_server.connect()",
            "    db_status_msg = database_status.db_status_msg.get(db_status)",
            "    LOG.info(db_status_msg)",
            "",
            "    if db_status == DBStatus.SCHEMA_MISSING:",
            "        LOG.debug(\"Config database schema is missing, initializing new.\")",
            "        db_status = cfg_sql_server.connect(init=True)",
            "        if db_status != DBStatus.OK:",
            "            LOG.error(\"Config database initialization failed!\")",
            "            LOG.error(\"Please check debug logs.\")",
            "            sys.exit(1)",
            "",
            "    if db_status == DBStatus.SCHEMA_MISMATCH_NO:",
            "        LOG.debug(\"Configuration database schema mismatch.\")",
            "        LOG.debug(\"No schema upgrade is possible.\")",
            "        sys.exit(1)",
            "",
            "    force_upgrade = 'force_upgrade' in args",
            "",
            "    if db_status == DBStatus.SCHEMA_MISMATCH_OK:",
            "        LOG.debug(\"Configuration database schema mismatch!\")",
            "        LOG.debug(\"Schema upgrade is possible.\")",
            "        LOG.warning(\"Please note after migration only newer CodeChecker \"",
            "                    \"versions can be used to start the server!\")",
            "        LOG.warning(\"It is advised to make a full backup of your \"",
            "                    \"configuration database!\")",
            "        LOG.warning(cfg_sql_server.get_db_location())",
            "",
            "        question = \"Do you want to upgrade to the new schema?\" \\",
            "                   \" Y(es)/n(o) \"",
            "        if force_upgrade or env.get_user_input(question):",
            "            LOG.info(\"Upgrading schema ...\")",
            "            new_status = cfg_sql_server.upgrade()",
            "            status_str = database_status.db_status_msg.get(",
            "                new_status, \"Unknown database status\")",
            "            LOG.info(status_str)",
            "            if new_status != DBStatus.OK:",
            "                LOG.error(\"Schema migration failed\")",
            "                sys.exit(new_status)",
            "        else:",
            "            LOG.info(\"No schema migration was done.\")",
            "            sys.exit(0)",
            "",
            "    if db_status == DBStatus.MISSING:",
            "        LOG.error(\"Missing configuration database.\")",
            "        LOG.error(\"Server can not be started.\")",
            "        sys.exit(1)",
            "",
            "    # Configuration database setup and check is needed before database",
            "    # statuses can be checked.",
            "    try:",
            "        if args.status:",
            "            ret = __db_status_check(cfg_sql_server,",
            "                                    context.migration_root,",
            "                                    environ,",
            "                                    args.status)",
            "            sys.exit(ret)",
            "    except AttributeError:",
            "        LOG.debug('Status was not in the arguments.')",
            "",
            "    try:",
            "        if args.product_to_upgrade:",
            "            ret = __db_migration_multiple(",
            "                cfg_sql_server,",
            "                context.migration_root,",
            "                environ,",
            "                [args.product_to_upgrade]",
            "                if args.product_to_upgrade != \"all\" else None,",
            "                force_upgrade)",
            "            sys.exit(ret)",
            "    except AttributeError:",
            "        LOG.debug('Product upgrade was not in the arguments.')",
            "",
            "    # Create the main database link from the arguments passed over the",
            "    # command line.",
            "    cfg_dir = os.path.abspath(args.config_directory)",
            "    default_product_path = os.path.join(cfg_dir, 'Default.sqlite')",
            "    create_default_product = 'sqlite' in args and \\",
            "                             not os.path.exists(default_product_path)",
            "",
            "    if create_default_product:",
            "        # Create a default product and add it to the configuration database.",
            "        LOG.debug(\"Create default product...\")",
            "        LOG.debug(\"Configuring schema and migration...\")",
            "",
            "        prod_server = database.SQLiteDatabase(",
            "            \"Default\", default_product_path, RUN_META,",
            "            context.run_migration_root, environ)",
            "",
            "        LOG.debug(\"Checking 'Default' product database.\")",
            "        db_status = prod_server.connect()",
            "        if db_status != DBStatus.MISSING:",
            "            db_status = prod_server.connect(init=True)",
            "            LOG.debug(database_status.db_status_msg.get(db_status))",
            "            if db_status != DBStatus.OK:",
            "                LOG.error(\"Failed to configure default product\")",
            "                sys.exit(1)",
            "",
            "        product_conn_string = prod_server.get_connection_string()",
            "",
            "        server.add_initial_run_database(",
            "            cfg_sql_server, product_conn_string)",
            "",
            "        LOG.info(\"Product 'Default' at '%s' created and set up.\",",
            "                 default_product_path)",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server,",
            "                                            context.run_migration_root,",
            "                                            environ)",
            "",
            "    upgrade_available = {}",
            "    for k, v in prod_statuses.items():",
            "        db_status, _, _, _ = v",
            "        if db_status in (DBStatus.SCHEMA_MISMATCH_OK, DBStatus.SCHEMA_MISSING):",
            "            upgrade_available[k] = v",
            "",
            "    if upgrade_available:",
            "        print_prod_status(prod_statuses)",
            "        LOG.warning(\"Multiple products can be upgraded, make a backup!\")",
            "        __db_migration_multiple(cfg_sql_server,",
            "                                context.run_migration_root,",
            "                                environ,",
            "                                None,",
            "                                force_upgrade)",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server,",
            "                                            context.run_migration_root,",
            "                                            environ)",
            "    print_prod_status(prod_statuses)",
            "",
            "    non_ok_db = False",
            "    for k, v in prod_statuses.items():",
            "        db_status, _, _, _ = v",
            "        if db_status != DBStatus.OK:",
            "            non_ok_db = True",
            "        break",
            "",
            "    if non_ok_db:",
            "        LOG.error(\"There are some database issues.\")",
            "        if not force_upgrade:",
            "            status_str = \"Do you want to start the server? Y(es)/n(o) \"",
            "            if not env.get_user_input(status_str):",
            "                sys.exit(1)",
            "",
            "    # Start database viewer.",
            "    package_data = {'www_root': context.www_root,",
            "                    'doc_root': context.doc_root,",
            "                    'version': context.package_git_tag}",
            "",
            "    try:",
            "        server.start_server(args.config_directory,",
            "                            package_data,",
            "                            args.view_port,",
            "                            cfg_sql_server,",
            "                            args.listen_address,",
            "                            'force_auth' in args,",
            "                            args.skip_db_cleanup,",
            "                            context,",
            "                            environ)",
            "    except socket.error as err:",
            "        if err.errno == errno.EADDRINUSE:",
            "            LOG.error(\"Server can't be started, maybe port number (%s) is \"",
            "                      \"already used. Check the connection parameters. Use \"",
            "                      \"the option '-p 0' to find a free port automatically.\",",
            "                      args.view_port)",
            "            sys.exit(1)",
            "        else:",
            "            raise",
            "",
            "",
            "def main(args):",
            "    \"\"\"",
            "    Setup a logger server based on the configuration and",
            "    manage the CodeChecker server.",
            "    \"\"\"",
            "    workspace = (",
            "        args.config_directory",
            "        if \"config_directory\" in args and not hasattr(args, \"instance_manager\")",
            "        else None",
            "    )",
            "",
            "    # Create workspace directory before logging is initialized.",
            "    if workspace and not os.path.exists(args.config_directory):",
            "        LOG.info(\"Creating non existing config directory: %s\",",
            "                 args.config_directory)",
            "        os.makedirs(args.config_directory)",
            "",
            "    with logger.LogCfgServer(",
            "        args.verbose if \"verbose\" in args else None, workspace=workspace",
            "    ):",
            "        try:",
            "            cmd_config.check_config_file(args)",
            "        except FileNotFoundError as fnerr:",
            "            LOG.error(fnerr)",
            "            sys.exit(1)",
            "        server_init_start(args)"
        ],
        "afterPatchFile": [
            "# -------------------------------------------------------------------------",
            "#",
            "#  Part of the CodeChecker project, under the Apache License v2.0 with",
            "#  LLVM Exceptions. See LICENSE for license information.",
            "#  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception",
            "#",
            "# -------------------------------------------------------------------------",
            "\"\"\"",
            "Handler for the subcommand that is used to start and manage CodeChecker",
            "servers, which are used to query analysis report information.",
            "\"\"\"",
            "",
            "",
            "import argparse",
            "import errno",
            "from functools import partial",
            "import os",
            "import signal",
            "import socket",
            "import sys",
            "import time",
            "from typing import List, Optional, Tuple, cast",
            "",
            "from alembic import config",
            "from alembic import script",
            "from alembic.util import CommandError",
            "import psutil",
            "from sqlalchemy.exc import SQLAlchemyError",
            "from sqlalchemy.orm import sessionmaker",
            "",
            "from codechecker_api_shared.ttypes import DBStatus",
            "",
            "from codechecker_report_converter import twodim",
            "",
            "from codechecker_common import arg, cmd_config, logger, util",
            "from codechecker_common.compatibility.multiprocessing import Pool, cpu_count",
            "",
            "from codechecker_server import instance_manager, server",
            "from codechecker_server.database import database",
            "from codechecker_server.database.config_db_model \\",
            "    import IDENTIFIER as CONFIG_META",
            "from codechecker_server.database.config_db_model \\",
            "    import Product as ORMProduct",
            "from codechecker_server.database.run_db_model \\",
            "    import IDENTIFIER as RUN_META",
            "",
            "from codechecker_web.shared import webserver_context, database_status, \\",
            "    host_check, env",
            "",
            "LOG = logger.get_logger('server')",
            "",
            "",
            "def get_argparser_ctor_args():",
            "    \"\"\"",
            "    This method returns a dict containing the kwargs for constructing an",
            "    argparse.ArgumentParser (either directly or as a subparser).",
            "    \"\"\"",
            "",
            "    return {",
            "        'prog': 'CodeChecker server',",
            "        'formatter_class': arg.RawDescriptionDefaultHelpFormatter,",
            "",
            "        # Description is shown when the command's help is queried directly",
            "        'description': \"\"\"",
            "The CodeChecker Web server is used to handle the storage and navigation of",
            "analysis results. A started server can be connected to via a Web browser, or",
            "by using the 'CodeChecker cmd' command-line client.\"\"\",",
            "",
            "        # Help is shown when the \"parent\" CodeChecker command lists the",
            "        # individual subcommands.",
            "        'help': \"Start and manage the CodeChecker Web server.\"",
            "    }",
            "",
            "",
            "def add_arguments_to_parser(parser):",
            "    \"\"\"",
            "    Add the subcommand's arguments to the given argparse.ArgumentParser.",
            "    \"\"\"",
            "",
            "    default_workspace = env.get_default_workspace()",
            "",
            "    # TODO: --workspace is an outdated concept in 'store'. Later on,",
            "    # it shall be deprecated, as changes to db_handler commence.",
            "    parser.add_argument('-w', '--workspace',",
            "                        type=str,",
            "                        dest=\"workspace\",",
            "                        default=default_workspace,",
            "                        required=False,",
            "                        help=\"Directory where CodeChecker can store analysis \"",
            "                             \"result related data, such as the database. \"",
            "                             \"(Cannot be specified at the same time with \"",
            "                             \"'--sqlite' or '--config-directory'.)\")",
            "",
            "    parser.add_argument('-f', '--config-directory',",
            "                        type=str,",
            "                        dest=\"config_directory\",",
            "                        default=default_workspace,",
            "                        required=False,",
            "                        help=\"Directory where CodeChecker server should read \"",
            "                             \"server-specific configuration (such as \"",
            "                             \"authentication settings, TLS certificate\"",
            "                             \" (cert.pem) and key (key.pem)) from.\")",
            "",
            "    parser.add_argument('--host',",
            "                        type=str,",
            "                        dest=\"listen_address\",",
            "                        default=\"localhost\",",
            "                        required=False,",
            "                        help=\"The IP address or hostname of the server on \"",
            "                             \"which it should listen for connections. \"",
            "                             \"For IPv6 listening, specify an IPv6 address, \"",
            "                             \"such as \\\"::1\\\".\")",
            "",
            "    # TODO: -v/--view-port is too verbose. The server's -p/--port is used",
            "    # symmetrically in 'CodeChecker cmd' anyways.",
            "    parser.add_argument('-v', '--view-port',  # TODO: <- Deprecate and remove.",
            "                        '-p', '--port',",
            "                        type=int,",
            "                        dest=\"view_port\",",
            "                        metavar='PORT',",
            "                        default=8001,",
            "                        required=False,",
            "                        help=\"The port which will be used as listen port for \"",
            "                             \"the server.\")",
            "",
            "    # TODO: This should be removed later on, in favour of --host.",
            "    parser.add_argument('--not-host-only',",
            "                        dest=\"not_host_only\",",
            "                        action=\"store_true\",",
            "                        required=False,",
            "                        help=\"If specified, storing and viewing the results \"",
            "                             \"will be possible not only by browsers and \"",
            "                             \"clients running locally, but to everyone, who \"",
            "                             \"can access the server over the Internet. \"",
            "                             \"(Equivalent to specifying '--host \\\"::\\\"'.)\")",
            "",
            "    parser.add_argument('--skip-db-cleanup',",
            "                        dest=\"skip_db_cleanup\",",
            "                        action='store_true',",
            "                        default=False,",
            "                        required=False,",
            "                        help=\"Skip performing cleanup jobs on the database \"",
            "                             \"like removing unused files.\")",
            "",
            "    cmd_config.add_option(parser)",
            "",
            "    dbmodes = parser.add_argument_group(\"configuration database arguments\")",
            "",
            "    dbmodes = dbmodes.add_mutually_exclusive_group(required=False)",
            "",
            "    dbmodes.add_argument('--sqlite',",
            "                         type=str,",
            "                         dest=\"sqlite\",",
            "                         metavar='SQLITE_FILE',",
            "                         default=os.path.join(",
            "                             '<CONFIG_DIRECTORY>',",
            "                             \"config.sqlite\"),",
            "                         required=False,",
            "                         help=\"Path of the SQLite database file to use.\")",
            "",
            "    dbmodes.add_argument('--postgresql',",
            "                         dest=\"postgresql\",",
            "                         action='store_true',",
            "                         required=False,",
            "                         default=argparse.SUPPRESS,",
            "                         help=\"Specifies that a PostgreSQL database is to be \"",
            "                              \"used instead of SQLite. See the \\\"PostgreSQL \"",
            "                              \"arguments\\\" section on how to configure the \"",
            "                              \"database connection.\")",
            "",
            "    pgsql = parser.add_argument_group(\"PostgreSQL arguments\",",
            "                                      \"Values of these arguments are ignored, \"",
            "                                      \"unless '--postgresql' is specified!\")",
            "",
            "    # TODO: --dbSOMETHING arguments are kept to not break interface from",
            "    # old command. Database using commands such as \"CodeChecker store\" no",
            "    # longer supports these --- it would be ideal to break and remove args",
            "    # with this style and only keep --db-SOMETHING.",
            "    pgsql.add_argument('--dbaddress', '--db-host',",
            "                       type=str,",
            "                       dest=\"dbaddress\",",
            "                       default=\"localhost\",",
            "                       required=False,",
            "                       help=\"Database server address.\")",
            "",
            "    pgsql.add_argument('--dbport', '--db-port',",
            "                       type=int,",
            "                       dest=\"dbport\",",
            "                       default=5432,",
            "                       required=False,",
            "                       help=\"Database server port.\")",
            "",
            "    pgsql.add_argument('--dbusername', '--db-username',",
            "                       type=str,",
            "                       dest=\"dbusername\",",
            "                       default='codechecker',",
            "                       required=False,",
            "                       help=\"Username to use for connection.\")",
            "",
            "    pgsql.add_argument('--dbname', '--db-name',",
            "                       type=str,",
            "                       dest=\"dbname\",",
            "                       default=\"config\",",
            "                       required=False,",
            "                       help=\"Name of the database to use.\")",
            "",
            "    root_account = parser.add_argument_group(",
            "        \"root account arguments\",",
            "        \"\"\"",
            "Servers automatically create a root user to access the server's configuration",
            "via the clients. This user is created at first start and saved in the",
            "CONFIG_DIRECTORY, and the credentials are printed to the server's standard",
            "output. The plaintext credentials are NEVER accessible again.\"\"\")",
            "",
            "    root_account.add_argument('--force-authentication',",
            "                              dest=\"force_auth\",",
            "                              action='store_true',",
            "                              default=argparse.SUPPRESS,",
            "                              required=False,",
            "                              help=\"Force the server to run in \"",
            "                                   \"authentication requiring mode, despite \"",
            "                                   \"the configuration value in \"",
            "                                   \"'server_config.json'. This is needed \"",
            "                                   \"if you need to edit the product \"",
            "                                   \"configuration of a server that would not \"",
            "                                   \"require authentication otherwise.\")",
            "",
            "    instance_mgmnt = parser.add_argument_group(\"running server management\")",
            "",
            "    instance_mgmnt = instance_mgmnt. \\",
            "        add_mutually_exclusive_group(required=False)",
            "",
            "    instance_mgmnt.add_argument('-l', '--list',",
            "                                dest=\"list\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"List the servers that has been started \"",
            "                                     \"by you.\")",
            "",
            "    instance_mgmnt.add_argument('-r', '--reload',",
            "                                dest=\"reload\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Sends the CodeChecker server process a \"",
            "                                     \"SIGHUP signal, causing it to reread \"",
            "                                     \"it's configuration files.\")",
            "",
            "    # TODO: '-s' was removed from 'quickcheck', it shouldn't be here either?",
            "    instance_mgmnt.add_argument('-s', '--stop',",
            "                                dest=\"stop\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Stops the server associated with \"",
            "                                     \"the given view-port and workspace.\")",
            "",
            "    instance_mgmnt.add_argument('--stop-all',",
            "                                dest=\"stop_all\",",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Stops all of your running CodeChecker \"",
            "                                     \"server instances.\")",
            "",
            "    database_mgmnt = parser.add_argument_group(",
            "            \"Database management arguments.\",",
            "            \"\"\"",
            "WARNING these commands needs to be called with the same workspace and",
            "configuration arguments as the server so the configuration database will be",
            "found which is required for the schema migration. Migration can be done",
            "without a running server but pay attention to use the same arguments which",
            "will be used to start the server.",
            "",
            "NOTE:",
            "Before migration it is advised to create a full a backup of the product",
            "databases.",
            "\"\"\")",
            "",
            "    database_mgmnt = database_mgmnt. \\",
            "        add_mutually_exclusive_group(required=False)",
            "",
            "    database_mgmnt.add_argument('--db-status',",
            "                                type=str,",
            "                                dest=\"status\",",
            "                                action='store',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Name of the product to get \"",
            "                                     \"the database status for. \"",
            "                                     \"Use 'all' to list the database \"",
            "                                     \"statuses for all of the products.\")",
            "",
            "    database_mgmnt.add_argument('--db-upgrade-schema',",
            "                                type=str,",
            "                                dest='product_to_upgrade',",
            "                                action='store',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Name of the product to upgrade to the \"",
            "                                     \"latest database schema available in \"",
            "                                     \"the package. Use 'all' to upgrade all \"",
            "                                     \"of the products. \"",
            "                                     \"NOTE: Before migration it is advised\"",
            "                                     \" to create a full backup of \"",
            "                                     \"the product databases.\")",
            "",
            "    database_mgmnt.add_argument('--db-force-upgrade',",
            "                                dest='force_upgrade',",
            "                                action='store_true',",
            "                                default=argparse.SUPPRESS,",
            "                                required=False,",
            "                                help=\"Force the server to do database \"",
            "                                     \"migration without user interaction. \"",
            "                                     \"NOTE: Please use with caution and \"",
            "                                     \"before automatic migration it is \"",
            "                                     \"advised to create a full backup of the \"",
            "                                     \"product databases.\")",
            "",
            "    logger.add_verbose_arguments(parser)",
            "",
            "    def __handle(args):",
            "        \"\"\"Custom handler for 'server' so custom error messages can be",
            "        printed without having to capture 'parser' in main.\"\"\"",
            "",
            "        def arg_match(options):",
            "            return util.arg_match(options, sys.argv[1:])",
            "",
            "        # See if there is a \"PostgreSQL argument\" specified in the invocation",
            "        # without '--postgresql' being there. There is no way to distinguish",
            "        # a default argument and a deliberately specified argument without",
            "        # inspecting sys.argv.",
            "        options = ['--dbaddress', '--dbport', '--dbusername', '--dbname',",
            "                   '--db-host', '--db-port', '--db-username', '--db-name']",
            "        psql_args_matching = arg_match(options)",
            "        if any(psql_args_matching) and 'postgresql' not in args:",
            "            parser.error(f\"argument {psql_args_matching[0]}: not allowed \"",
            "                         \"without argument --postgresql\")",
            "            # parser.error() terminates with return code 2.",
            "",
            "        # --not-host-only is a \"shortcut\", actually a to-be-deprecated",
            "        # call which means '--host \"\"'.",
            "        # TODO: Actually deprecate --not-host-only later on.",
            "        options = ['--not-host-only', '--host']",
            "        if set(arg_match(options)) == set(options):",
            "            parser.error(\"argument --not-host-only: not allowed with \"",
            "                         \"argument --host, as it is a shortcut to --host \"",
            "                         \"\\\"::\\\"\")",
            "        else:",
            "            # Apply the shortcut.",
            "            if arg_match(['--not-host-only']):",
            "                args.listen_address = \"::\"  # Listen on every interface.",
            "",
            "            # --not-host-only is just a shortcut optstring, no actual use",
            "            # is intended later on.",
            "            delattr(args, 'not_host_only')",
            "",
            "        # --workspace and --sqlite cannot be specified either, as",
            "        # both point to a database location.",
            "        options = ['--sqlite', '--workspace']",
            "        options_short = ['--sqlite', '-w']",
            "        if set(arg_match(options)) == set(options) or \\",
            "                set(arg_match(options_short)) == set(options_short):",
            "            parser.error(\"argument --sqlite: not allowed with \"",
            "                         \"argument --workspace\")",
            "",
            "        # --workspace and --config-directory also aren't allowed together now,",
            "        # the latter one is expected to replace the earlier.",
            "        options = ['--config-directory', '--workspace']",
            "        options_short = ['--config-directory', '-w']",
            "        if set(arg_match(options)) == set(options) or \\",
            "                set(arg_match(options_short)) == set(options_short):",
            "            parser.error(\"argument --config-directory: not allowed with \"",
            "                         \"argument --workspace\")",
            "",
            "        # If workspace is specified, sqlite is workspace/config.sqlite",
            "        # and config_directory is the workspace directory.",
            "        if arg_match(['--workspace', '-w']):",
            "            args.config_directory = args.workspace",
            "            args.sqlite = os.path.join(args.workspace,",
            "                                       'config.sqlite')",
            "            setattr(args, 'dbdatadir', os.path.join(args.workspace,",
            "                                                    'pgsql_data'))",
            "",
            "        # Workspace should not exist as a Namespace key.",
            "        delattr(args, 'workspace')",
            "",
            "        if '<CONFIG_DIRECTORY>' in args.sqlite:",
            "            # Replace the placeholder variable with the actual value.",
            "            args.sqlite = args.sqlite.replace('<CONFIG_DIRECTORY>',",
            "                                              args.config_directory)",
            "",
            "        # Convert relative sqlite file path to absolute.",
            "        if 'sqlite' in args:",
            "            args.sqlite = os.path.abspath(args.sqlite)",
            "",
            "        if 'postgresql' not in args:",
            "            # Later called database modules need the argument to be actually",
            "            # present, even though the default is suppressed in the optstring.",
            "            setattr(args, 'postgresql', False)",
            "",
            "            # This is not needed by the database starter as we are",
            "            # running SQLite.",
            "            if 'dbdatadir' in args:",
            "                delattr(args, 'dbdatadir')",
            "        else:",
            "            # If --postgresql is given, --sqlite is useless.",
            "            delattr(args, 'sqlite')",
            "",
            "        # Indicate in args that we are in instance manager mode.",
            "        if \"list\" in args or \"stop\" in args or \"stop_all\" in args:",
            "            setattr(args, \"instance_manager\", True)",
            "",
            "        # If everything is fine, do call the handler for the subcommand.",
            "        main(args)",
            "",
            "    parser.set_defaults(",
            "        func=__handle, func_process_config_file=cmd_config.process_config_file)",
            "",
            "",
            "def print_prod_status(prod_status):",
            "    \"\"\"",
            "    Print the database statuses for each of the products.",
            "    \"\"\"",
            "",
            "    header = ['Product endpoint', 'Database status',",
            "              'Database location',",
            "              'Schema version in the database',",
            "              'Schema version in the package']",
            "    rows = []",
            "",
            "    for k, v in prod_status.items():",
            "        db_status, schema_ver, package_ver, db_location = v",
            "        db_status_msg = database_status.db_status_msg.get(db_status)",
            "        if schema_ver == package_ver:",
            "            schema_ver += \" (up to date)\"",
            "        rows.append([k, db_status_msg, db_location, str(schema_ver),",
            "                     package_ver])",
            "",
            "    prod_status = twodim.to_str('table',",
            "                                header,",
            "                                rows,",
            "                                sort_by_column_number=0)",
            "    LOG.info('Status of products:\\n%s', prod_status)",
            "",
            "",
            "def get_schema_version_from_package(migration_root):",
            "    \"\"\"",
            "    Returns the latest schema version in the package.",
            "    \"\"\"",
            "",
            "    cfg = config.Config()",
            "    cfg.set_main_option(\"script_location\", migration_root)",
            "    pckg_schema_ver = script.ScriptDirectory.from_config(cfg)",
            "    return pckg_schema_ver.get_current_head()",
            "",
            "",
            "def check_product_db_status(cfg_sql_server, migration_root, environ):",
            "    \"\"\"",
            "    Check the products for database statuses.",
            "",
            "    :returns: dictionary of product endpoints with database statuses",
            "    \"\"\"",
            "    engine = cfg_sql_server.create_engine()",
            "    config_session = sessionmaker(bind=engine)",
            "    sess = config_session()",
            "",
            "    products: List[ORMProduct] = []",
            "    try:",
            "        products = sess.query(ORMProduct) \\",
            "            .order_by(ORMProduct.endpoint.asc()) \\",
            "            .all()",
            "    except Exception as ex:",
            "        LOG.debug(ex)",
            "        LOG.error(\"Failed to get product configurations from the database.\")",
            "        LOG.error(\"Please check your command arguments.\")",
            "        sys.exit(1)",
            "    finally:",
            "        # sys.exit raises SystemExit, which still performs finally clauses!",
            "        sess.close()",
            "        engine.dispose()",
            "",
            "    package_schema = get_schema_version_from_package(migration_root)",
            "",
            "    db_errors = [DBStatus.FAILED_TO_CONNECT,",
            "                 DBStatus.MISSING,",
            "                 DBStatus.SCHEMA_INIT_ERROR,",
            "                 DBStatus.SCHEMA_MISSING]",
            "",
            "    prod_status = {}",
            "    for pd in products:",
            "        db = database.SQLServer.from_connection_string(pd.connection,",
            "                                                       pd.endpoint,",
            "                                                       RUN_META,",
            "                                                       migration_root,",
            "                                                       interactive=False,",
            "                                                       env=environ)",
            "        db_location = db.get_db_location()",
            "",
            "        try:",
            "            status = db.connect()",
            "            s_ver = db.get_schema_version()",
            "            if s_ver in db_errors:",
            "                s_ver = None",
            "            prod_status[pd.endpoint] = (status, s_ver, package_schema,",
            "                                        db_location)",
            "        except Exception:",
            "            LOG.error(\"Unable to get the status for product '%s', \"",
            "                      \"considering as if the connection failed.\",",
            "                      pd.endpoint)",
            "            prod_status[pd.endpoint] = (DBStatus.FAILED_TO_CONNECT, None,",
            "                                        package_schema, db_location)",
            "",
            "    return prod_status",
            "",
            "",
            "def __db_status_check(cfg_sql_server, migration_root, environ,",
            "                      product_name=None) -> int:",
            "    \"\"\"",
            "    Check and print database statuses for the given product.",
            "    \"\"\"",
            "    if not product_name:",
            "        return 0",
            "",
            "    LOG.debug(\"Checking database status for %s product.\", product_name)",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server, migration_root,",
            "                                            environ)",
            "",
            "    if product_name != \"all\":",
            "        avail = prod_statuses.get(product_name)",
            "        if not avail:",
            "            LOG.error(\"No product was found with this endpoint: %s\",",
            "                      str(product_name))",
            "            return 1",
            "",
            "        prod_statuses = {k: v for k, v in prod_statuses.items()",
            "                         if k == product_name}",
            "",
            "    print_prod_status(prod_statuses)",
            "    return 0",
            "",
            "",
            "class NonExistentProductError(Exception):",
            "    def __init__(self, product_name):",
            "        super().__init__(f\"Non-existent product '{product_name}'\")",
            "        self.product_name = product_name",
            "",
            "",
            "def __db_migration(migration_root,",
            "                   environ,",
            "                   endpoint: str,",
            "                   connection_string: str,",
            "                   init_instead_of_upgrade: bool) -> DBStatus:",
            "    try:",
            "        db = database.SQLServer.from_connection_string(connection_string,",
            "                                                       endpoint,",
            "                                                       RUN_META,",
            "                                                       migration_root,",
            "                                                       interactive=False,",
            "                                                       env=environ)",
            "        if init_instead_of_upgrade:",
            "            LOG.info(\"[%s] Initialising...\", endpoint)",
            "            status = db.connect(init=True)",
            "        else:",
            "            LOG.info(\"[%s] Upgrading...\", endpoint)",
            "            db.connect(init=False)",
            "            status = db.upgrade()",
            "",
            "        status_str = database_status.db_status_msg.get(",
            "            status, \"Unknown database status\")",
            "        LOG.info(\"[%s] Done %s. %s\", endpoint,",
            "                 \"initialising\" if init_instead_of_upgrade else \"upgrading\",",
            "                 status_str)",
            "        return status",
            "    except (CommandError, SQLAlchemyError):",
            "        LOG.error(\"A database error occurred during the init/migration of \"",
            "                  \"'%s'\", endpoint)",
            "        import traceback",
            "        traceback.print_exc()",
            "        return DBStatus.SCHEMA_INIT_ERROR if init_instead_of_upgrade \\",
            "            else DBStatus.SCHEMA_UPGRADE_FAILED",
            "    except Exception as e:",
            "        LOG.error(\"A generic error '%s' occurred during the init/migration \"",
            "                  \"of '%s'\", str(type(e)), endpoint)",
            "        import traceback",
            "        traceback.print_exc()",
            "        return DBStatus.SCHEMA_INIT_ERROR if init_instead_of_upgrade \\",
            "            else DBStatus.SCHEMA_UPGRADE_FAILED",
            "",
            "",
            "def __db_migration_multiple(",
            "    cfg_sql_server, migration_root, environ,",
            "    products_requested_for_upgrade: Optional[List[str]] = None,",
            "    force_upgrade: bool = False",
            ") -> int:",
            "    \"\"\"",
            "    Migrates the schema for the product database",
            "    ``products_requested_for_upgrade`` if specified, or all configured",
            "    products (default).",
            "    \"\"\"",
            "    LOG.info(\"Preparing schema upgrade for '%s'\",",
            "             \"', '\".join(products_requested_for_upgrade)",
            "             if products_requested_for_upgrade else \"<all products>\")",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server,",
            "                                            migration_root,",
            "                                            environ)",
            "    products_to_upgrade: List[str] = []",
            "    for endpoint in (products_requested_for_upgrade or []):",
            "        avail = prod_statuses.get(endpoint)",
            "        if not avail:",
            "            LOG.error(\"No product was found with endpoint '%s'\", endpoint)",
            "            return 1",
            "        products_to_upgrade.append(endpoint)",
            "",
            "    products_to_upgrade = list(prod_statuses.keys())",
            "    products_to_upgrade.sort()",
            "",
            "    def _get_migration_decisions() -> List[Tuple[str, str, bool]]:",
            "        # The lifetime of the CONFIG database connection is scoped to this",
            "        # helper function, as keeping it alive throughout PRODUCT migrations",
            "        # could cause timeouts.",
            "        cfg_engine = cfg_sql_server.create_engine()",
            "        cfg_session_factory = sessionmaker(bind=cfg_engine)",
            "        cfg_session = cfg_session_factory()",
            "",
            "        scheduled_upgrades_or_inits: List[Tuple[str, str, bool]] = []",
            "        for endpoint in products_to_upgrade:",
            "            LOG.info(\"Checking: %s\", endpoint)",
            "            connection_str: Optional[str] = None",
            "",
            "            try:",
            "                product: Optional[ORMProduct] = cfg_session \\",
            "                    .query(ORMProduct.connection) \\",
            "                    .filter(ORMProduct.endpoint == endpoint) \\",
            "                    .one_or_none()",
            "                if product is None:",
            "                    raise NonExistentProductError(endpoint)",
            "",
            "                connection_str = product.connection",
            "            except NonExistentProductError as nepe:",
            "                LOG.error(\"Attempted to upgrade product '%s', but it was not \"",
            "                          \"found in the server's configuration database.\",",
            "                          nepe.product_name)",
            "                continue",
            "            except Exception:",
            "                LOG.error(\"Failed to get the configuration for product '%s'\",",
            "                          endpoint)",
            "                import traceback",
            "                traceback.print_exc()",
            "                continue",
            "",
            "            try:",
            "                db = database.SQLServer.from_connection_string(",
            "                    cast(str, connection_str),",
            "                    endpoint,",
            "                    RUN_META,",
            "                    migration_root,",
            "                    interactive=False,",
            "                    env=environ)",
            "                db_status = db.connect()",
            "",
            "                status_str = database_status.db_status_msg.get(",
            "                    db_status, \"Unknown database status\")",
            "                LOG.info(status_str)",
            "",
            "                if db_status == DBStatus.SCHEMA_MISSING:",
            "                    question = \"Do you want to initialize a new schema for \" \\",
            "                               f\"'{endpoint}'\" \\",
            "                               \"? Y(es)/n(o) \"",
            "                    if force_upgrade or env.get_user_input(question):",
            "                        LOG.info(\"[%s] Schema will be initialised...\",",
            "                                 endpoint)",
            "                        scheduled_upgrades_or_inits.append(",
            "                            (endpoint, cast(str, connection_str), True))",
            "                    else:",
            "                        LOG.info(\"[%s] No schema initialization will be done.\",",
            "                                 endpoint)",
            "                elif db_status == DBStatus.SCHEMA_MISMATCH_OK:",
            "                    question = f\"Do you want to upgrade '{endpoint}' to new \" \\",
            "                               \"schema? Y(es)/n(o) \"",
            "                    if force_upgrade or env.get_user_input(question):",
            "                        LOG.info(\"[%s] Schema will be upgraded...\", endpoint)",
            "                        scheduled_upgrades_or_inits.append(",
            "                            (endpoint, cast(str, connection_str), False))",
            "                    else:",
            "                        LOG.info(\"[%s] No schema migration will be done.\",",
            "                                 endpoint)",
            "            except (CommandError, SQLAlchemyError):",
            "                LOG.error(\"A database error occurred during the preparation \"",
            "                          \"for the init/migration of '%s'\", endpoint)",
            "                import traceback",
            "                traceback.print_exc()",
            "            except Exception as e:",
            "                LOG.error(\"A generic error '%s' occurred during the \"",
            "                          \"preparation for the init/migration of '%s'\",",
            "                          str(type(e)), endpoint)",
            "                import traceback",
            "                traceback.print_exc()",
            "",
            "        cfg_session.close()",
            "        cfg_engine.dispose()",
            "        return scheduled_upgrades_or_inits",
            "",
            "    LOG.warning(\"Please note after migration only newer CodeChecker versions \"",
            "                \"can be used to start the server!\")",
            "    LOG.warning(\"It is advised to make a full backup of your run databases.\")",
            "    LOG.info(\"========================\")",
            "    scheduled_upgrades_or_inits = _get_migration_decisions()",
            "    LOG.info(\"========================\")",
            "",
            "    if scheduled_upgrades_or_inits:",
            "        failed_products: List[Tuple[str, DBStatus]] = []",
            "        thr_count = util.clamp(1, len(scheduled_upgrades_or_inits),",
            "                               cpu_count())",
            "        with Pool(max_workers=thr_count) as executor:",
            "            LOG.info(\"Initialising/upgrading products using %d concurrent \"",
            "                     \"jobs...\", thr_count)",
            "            for product_cfg, return_status in \\",
            "                    zip(scheduled_upgrades_or_inits, executor.map(",
            "                        # Bind the first 2 non-changing arguments of",
            "                        # __db_migration, this is fixed for the execution.",
            "                        partial(__db_migration, migration_root, environ),",
            "                        # Transform List[Tuple[str, str, bool]] into an",
            "                        # Iterable[Tuple[str], Tuple[str], Tuple[bool]],",
            "                        # and immediately unpack it, thus providing the other",
            "                        # 3 arguments of __db_migration as a parameter pack.",
            "                        *zip(*scheduled_upgrades_or_inits))):",
            "                if return_status != DBStatus.OK:",
            "                    failed_products.append((product_cfg[0], return_status))",
            "",
            "        if failed_products:",
            "            prod_status = []",
            "            for p in failed_products:",
            "                status = database_status.db_status_msg.get(",
            "                    p[1], \"Unknown database status\")",
            "                prod_status.append(f\"'{p[0]}' ({status})\")",
            "",
            "            LOG.error(\"The following products failed to upgrade: %s\",",
            "                      ', '.join(prod_status))",
            "        else:",
            "            LOG.info(\"Schema initialisation(s)/upgrade(s) executed \"",
            "                     \"successfully.\")",
            "    LOG.info(\"========================\")",
            "",
            "    # This function always returns 0 if the upgrades were attempted, because",
            "    # the server can start with some products that have failed to init/migrate.",
            "    # It will just simply disallow the connection to those products.",
            "    return 0",
            "",
            "",
            "def kill_process_tree(parent_pid, recursive=False):",
            "    \"\"\"Stop the process tree try it gracefully first.",
            "",
            "    Try to stop the parent and child processes gracefuly",
            "    first if they do not stop in time send a kill signal",
            "    to every member of the process tree.",
            "",
            "    There is a similar function in the analyzer part please",
            "    consider to update that in case of changing this.",
            "    \"\"\"",
            "    proc = psutil.Process(parent_pid)",
            "    children = proc.children(recursive)",
            "",
            "    # Send a SIGTERM (Ctrl-C) to the main process",
            "    proc.terminate()",
            "",
            "    # If children processes don't stop gracefully in time,",
            "    # slaughter them by force.",
            "    _, still_alive = psutil.wait_procs(children, timeout=5)",
            "    for p in still_alive:",
            "        p.kill()",
            "",
            "    # Wait until this process is running.",
            "    n = 0",
            "    timeout = 10",
            "    while proc.is_running():",
            "        if n > timeout:",
            "            LOG.warning(\"Waiting for process %s to stop has been timed out\"",
            "                        \"(timeout = %s)! Process is still running!\",",
            "                        parent_pid, timeout)",
            "            break",
            "",
            "        time.sleep(1)",
            "        n += 1",
            "",
            "",
            "def __instance_management(args):",
            "    \"\"\"Handles the instance-manager commands --list/--stop/--stop-all.\"\"\"",
            "",
            "    # TODO: The server stopping and listing must be revised on its invocation",
            "    # once \"workspace\", as a concept, is removed.",
            "    # QUESTION: What is the bestest way here to identify a server for the user?",
            "    if 'list' in args:",
            "        instances = instance_manager.get_instances()",
            "",
            "        instances_on_multiple_hosts = any(True for inst in instances",
            "                                          if inst['hostname'] !=",
            "                                          socket.gethostname())",
            "        if not instances_on_multiple_hosts:",
            "            head = ['Workspace', 'View port']",
            "        else:",
            "            head = ['Workspace', 'Computer host', 'View port']",
            "",
            "        rows = []",
            "        for instance in instances:",
            "            if not instances_on_multiple_hosts:",
            "                rows.append((instance['workspace'], str(instance['port'])))",
            "            else:",
            "                rows.append((instance['workspace'],",
            "                             instance['hostname']",
            "                             if instance['hostname'] != socket.gethostname()",
            "                             else '',",
            "                             str(instance['port'])))",
            "",
            "        print(\"Your running CodeChecker servers:\")",
            "        print(twodim.to_str('table', head, rows))",
            "    elif 'stop' in args or 'stop_all' in args:",
            "        for i in instance_manager.get_instances():",
            "            if i['hostname'] != socket.gethostname():",
            "                continue",
            "",
            "            # A STOP only stops the server associated with the given workspace",
            "            # and view-port.",
            "            if 'stop' in args and \\",
            "                not (i['port'] == args.view_port and",
            "                     os.path.abspath(i['workspace']) ==",
            "                     os.path.abspath(args.config_directory)):",
            "                continue",
            "",
            "            try:",
            "                kill_process_tree(i['pid'])",
            "                LOG.info(\"Stopped CodeChecker server running on port %s \"",
            "                         \"in workspace %s (PID: %s)\",",
            "                         i['port'], i['workspace'], i['pid'])",
            "            except Exception:",
            "                # Let the exception come out if the commands fail",
            "                LOG.error(\"Couldn't stop process PID #%s\", str(i['pid']))",
            "                raise",
            "",
            "",
            "def __reload_config(args):",
            "    \"\"\"",
            "    Sends the CodeChecker server process a SIGHUP signal, causing it to",
            "    reread it's configuration files.",
            "    \"\"\"",
            "    for i in instance_manager.get_instances():",
            "        if i['hostname'] != socket.gethostname():",
            "            continue",
            "",
            "        # A RELOAD only reloads the server associated with the given workspace",
            "        # and view-port.",
            "        if 'reload' in args and \\",
            "                not (i['port'] == args.view_port and",
            "                     os.path.abspath(i['workspace']) ==",
            "                     os.path.abspath(args.config_directory)):",
            "            continue",
            "",
            "        try:",
            "            if sys.platform != \"win32\":",
            "                os.kill(i['pid'], signal.SIGHUP)",
            "        except Exception:",
            "            LOG.error(\"Couldn't reload configuration file for process PID #%s\",",
            "                      str(i['pid']))",
            "            raise",
            "",
            "",
            "def is_localhost(address):",
            "    \"\"\"",
            "    Check if address is one of the valid values and try to get the",
            "    IP-addresses from the system.",
            "    \"\"\"",
            "",
            "    valid_values = ['localhost', '0.0.0.0', '*', '::1']",
            "",
            "    try:",
            "        valid_values.append(socket.gethostbyname('localhost'))",
            "    except socket.herror:",
            "        LOG.debug(\"Failed to get IP address for localhost.\")",
            "",
            "    try:",
            "        valid_values.append(socket.gethostbyname(socket.gethostname()))",
            "    except (socket.herror, socket.gaierror):",
            "        LOG.debug(\"Failed to get IP address for hostname '%s'\",",
            "                  socket.gethostname())",
            "",
            "    return address in valid_values",
            "",
            "",
            "def server_init_start(args):",
            "    \"\"\"",
            "    Start or manage a CodeChecker report server.",
            "    \"\"\"",
            "",
            "    if 'list' in args or 'stop' in args or 'stop_all' in args:",
            "        # Set the instance manager flag to True to be able watch for it during",
            "        # logger setup.",
            "        setattr(args, \"instance_manager\", True)",
            "        __instance_management(args)",
            "        sys.exit(0)",
            "",
            "    if 'reload' in args:",
            "        __reload_config(args)",
            "        sys.exit(0)",
            "",
            "    # Actual server starting from this point.",
            "    if not host_check.check_zlib():",
            "        raise ModuleNotFoundError(\"zlib is not available on the system!\")",
            "",
            "    # WARNING",
            "    # In case of SQLite args.dbaddress default value is used",
            "    # for which the is_localhost should return true.",
            "    if is_localhost(args.dbaddress) and \\",
            "            not os.path.exists(args.config_directory):",
            "        os.makedirs(args.config_directory)",
            "",
            "    # Make sure the SQLite file can be created if it not exists.",
            "    if 'sqlite' in args and \\",
            "            not os.path.isdir(os.path.dirname(args.sqlite)):",
            "        os.makedirs(os.path.dirname(args.sqlite))",
            "",
            "    if 'force_auth' in args:",
            "        LOG.info(\"'--force-authentication' was passed as a command-line \"",
            "                 \"option. The server will ask for users to authenticate!\")",
            "",
            "    context = webserver_context.get_context()",
            "    context.codechecker_workspace = args.config_directory",
            "    context.db_username = args.dbusername",
            "",
            "    environ = env.extend(context.path_env_extra,",
            "                         context.ld_lib_path_extra)",
            "",
            "    cfg_sql_server = database.SQLServer.from_cmdline_args(",
            "        vars(args), \"config\", CONFIG_META, context.config_migration_root,",
            "        interactive=True, env=environ)",
            "",
            "    LOG.info(\"Checking configuration database ...\")",
            "    db_status = cfg_sql_server.connect()",
            "    db_status_msg = database_status.db_status_msg.get(db_status)",
            "    LOG.info(db_status_msg)",
            "",
            "    if db_status == DBStatus.SCHEMA_MISSING:",
            "        LOG.debug(\"Config database schema is missing, initializing new.\")",
            "        db_status = cfg_sql_server.connect(init=True)",
            "        if db_status != DBStatus.OK:",
            "            LOG.error(\"Config database initialization failed!\")",
            "            LOG.error(\"Please check debug logs.\")",
            "            sys.exit(1)",
            "",
            "    if db_status == DBStatus.SCHEMA_MISMATCH_NO:",
            "        LOG.debug(\"Configuration database schema mismatch.\")",
            "        LOG.debug(\"No schema upgrade is possible.\")",
            "        sys.exit(1)",
            "",
            "    force_upgrade = 'force_upgrade' in args",
            "",
            "    if db_status == DBStatus.SCHEMA_MISMATCH_OK:",
            "        LOG.debug(\"Configuration database schema mismatch!\")",
            "        LOG.debug(\"Schema upgrade is possible.\")",
            "        LOG.warning(\"Please note after migration only newer CodeChecker \"",
            "                    \"versions can be used to start the server!\")",
            "        LOG.warning(\"It is advised to make a full backup of your \"",
            "                    \"configuration database!\")",
            "        LOG.warning(cfg_sql_server.get_db_location())",
            "",
            "        question = \"Do you want to upgrade to the new schema?\" \\",
            "                   \" Y(es)/n(o) \"",
            "        if force_upgrade or env.get_user_input(question):",
            "            LOG.info(\"Upgrading schema ...\")",
            "            new_status = cfg_sql_server.upgrade()",
            "            status_str = database_status.db_status_msg.get(",
            "                new_status, \"Unknown database status\")",
            "            LOG.info(status_str)",
            "            if new_status != DBStatus.OK:",
            "                LOG.error(\"Schema migration failed\")",
            "                sys.exit(new_status)",
            "        else:",
            "            LOG.info(\"No schema migration was done.\")",
            "            sys.exit(0)",
            "",
            "    if db_status == DBStatus.MISSING:",
            "        LOG.error(\"Missing configuration database.\")",
            "        LOG.error(\"Server can not be started.\")",
            "        sys.exit(1)",
            "",
            "    # Configuration database setup and check is needed before database",
            "    # statuses can be checked.",
            "    try:",
            "        if args.status:",
            "            ret = __db_status_check(cfg_sql_server,",
            "                                    context.migration_root,",
            "                                    environ,",
            "                                    args.status)",
            "            sys.exit(ret)",
            "    except AttributeError:",
            "        LOG.debug('Status was not in the arguments.')",
            "",
            "    try:",
            "        if args.product_to_upgrade:",
            "            ret = __db_migration_multiple(",
            "                cfg_sql_server,",
            "                context.migration_root,",
            "                environ,",
            "                [args.product_to_upgrade]",
            "                if args.product_to_upgrade != \"all\" else None,",
            "                force_upgrade)",
            "            sys.exit(ret)",
            "    except AttributeError:",
            "        LOG.debug('Product upgrade was not in the arguments.')",
            "",
            "    # Create the main database link from the arguments passed over the",
            "    # command line.",
            "    cfg_dir = os.path.abspath(args.config_directory)",
            "    default_product_path = os.path.join(cfg_dir, 'Default.sqlite')",
            "    create_default_product = 'sqlite' in args and \\",
            "                             not os.path.exists(default_product_path)",
            "",
            "    if create_default_product:",
            "        # Create a default product and add it to the configuration database.",
            "        LOG.debug(\"Create default product...\")",
            "        LOG.debug(\"Configuring schema and migration...\")",
            "",
            "        prod_server = database.SQLiteDatabase(",
            "            \"Default\", default_product_path, RUN_META,",
            "            context.run_migration_root, environ)",
            "",
            "        LOG.debug(\"Checking 'Default' product database.\")",
            "        db_status = prod_server.connect()",
            "        if db_status != DBStatus.MISSING:",
            "            db_status = prod_server.connect(init=True)",
            "            LOG.debug(database_status.db_status_msg.get(db_status))",
            "            if db_status != DBStatus.OK:",
            "                LOG.error(\"Failed to configure default product\")",
            "                sys.exit(1)",
            "",
            "        product_conn_string = prod_server.get_connection_string()",
            "",
            "        server.add_initial_run_database(",
            "            cfg_sql_server, product_conn_string)",
            "",
            "        LOG.info(\"Product 'Default' at '%s' created and set up.\",",
            "                 default_product_path)",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server,",
            "                                            context.run_migration_root,",
            "                                            environ)",
            "",
            "    upgrade_available = {}",
            "    for k, v in prod_statuses.items():",
            "        db_status, _, _, _ = v",
            "        if db_status in (DBStatus.SCHEMA_MISMATCH_OK, DBStatus.SCHEMA_MISSING):",
            "            upgrade_available[k] = v",
            "",
            "    if upgrade_available:",
            "        print_prod_status(prod_statuses)",
            "        LOG.warning(\"Multiple products can be upgraded, make a backup!\")",
            "        __db_migration_multiple(cfg_sql_server,",
            "                                context.run_migration_root,",
            "                                environ,",
            "                                None,",
            "                                force_upgrade)",
            "",
            "    prod_statuses = check_product_db_status(cfg_sql_server,",
            "                                            context.run_migration_root,",
            "                                            environ)",
            "    print_prod_status(prod_statuses)",
            "",
            "    non_ok_db = False",
            "    for k, v in prod_statuses.items():",
            "        db_status, _, _, _ = v",
            "        if db_status != DBStatus.OK:",
            "            non_ok_db = True",
            "        break",
            "",
            "    if non_ok_db:",
            "        LOG.error(\"There are some database issues.\")",
            "        if not force_upgrade:",
            "            status_str = \"Do you want to start the server? Y(es)/n(o) \"",
            "            if not env.get_user_input(status_str):",
            "                sys.exit(1)",
            "",
            "    # Start database viewer.",
            "    package_data = {'www_root': context.www_root,",
            "                    'doc_root': context.doc_root,",
            "                    'version': context.package_git_tag}",
            "",
            "    try:",
            "        server.start_server(args.config_directory,",
            "                            package_data,",
            "                            args.view_port,",
            "                            cfg_sql_server,",
            "                            args.listen_address,",
            "                            'force_auth' in args,",
            "                            args.skip_db_cleanup,",
            "                            context,",
            "                            environ)",
            "    except socket.error as err:",
            "        if err.errno == errno.EADDRINUSE:",
            "            LOG.error(\"Server can't be started, maybe port number (%s) is \"",
            "                      \"already used. Check the connection parameters. Use \"",
            "                      \"the option '-p 0' to find a free port automatically.\",",
            "                      args.view_port)",
            "            sys.exit(1)",
            "        else:",
            "            raise",
            "",
            "",
            "def main(args):",
            "    \"\"\"",
            "    Setup a logger server based on the configuration and",
            "    manage the CodeChecker server.",
            "    \"\"\"",
            "    workspace = (",
            "        args.config_directory",
            "        if \"config_directory\" in args and not hasattr(args, \"instance_manager\")",
            "        else None",
            "    )",
            "",
            "    # Create workspace directory before logging is initialized.",
            "    if workspace and not os.path.exists(args.config_directory):",
            "        LOG.info(\"Creating non existing config directory: %s\",",
            "                 args.config_directory)",
            "        os.makedirs(args.config_directory)",
            "",
            "    with logger.LogCfgServer(",
            "        args.verbose if \"verbose\" in args else None, workspace=workspace",
            "    ):",
            "        try:",
            "            cmd_config.check_config_file(args)",
            "        except FileNotFoundError as fnerr:",
            "            LOG.error(fnerr)",
            "            sys.exit(1)",
            "        server_init_start(args)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "215": [
                "add_arguments_to_parser"
            ],
            "216": [
                "add_arguments_to_parser"
            ],
            "217": [
                "add_arguments_to_parser"
            ],
            "218": [
                "add_arguments_to_parser"
            ],
            "219": [
                "add_arguments_to_parser"
            ],
            "220": [
                "add_arguments_to_parser"
            ],
            "221": [
                "add_arguments_to_parser"
            ],
            "222": [
                "add_arguments_to_parser"
            ],
            "223": [
                "add_arguments_to_parser"
            ],
            "224": [
                "add_arguments_to_parser"
            ],
            "225": [
                "add_arguments_to_parser"
            ],
            "935": [
                "server_init_start"
            ],
            "936": [
                "server_init_start"
            ],
            "937": [
                "server_init_start"
            ],
            "938": [
                "server_init_start"
            ],
            "939": [
                "server_init_start"
            ],
            "940": [
                "server_init_start"
            ],
            "941": [
                "server_init_start"
            ],
            "942": [
                "server_init_start"
            ],
            "943": [
                "server_init_start"
            ]
        },
        "addLocation": []
    },
    "web/server/codechecker_server/server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " import atexit"
            },
            "1": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " import datetime"
            },
            "2": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " from functools import partial"
            },
            "3": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from hashlib import sha256"
            },
            "4": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " from http.server import HTTPServer, SimpleHTTPRequestHandler"
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " import os"
            },
            "6": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import posixpath"
            },
            "7": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from random import sample"
            },
            "8": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " import shutil"
            },
            "9": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " import signal"
            },
            "10": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " import socket"
            },
            "11": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " import ssl"
            },
            "12": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " import sys"
            },
            "13": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import stat"
            },
            "14": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from typing import List, Optional, Tuple"
            },
            "15": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " import urllib"
            },
            "16": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "     Configuration as ORMConfiguration"
            },
            "18": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " from .database.database import DBSession"
            },
            "19": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " from .database.run_db_model import IDENTIFIER as RUN_META, Run, RunLock"
            },
            "20": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from .tmp import get_tmp_dir_hash"
            },
            "21": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "22": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 68,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " LOG = get_logger('server')"
            },
            "24": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 70,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 991,
                "afterPatchRowNumber": 986,
                "PatchRowcode": "     address_family = socket.AF_INET6"
            },
            "26": {
                "beforePatchRowNumber": 992,
                "afterPatchRowNumber": 987,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 993,
                "afterPatchRowNumber": 988,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 994,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def __make_root_file(root_file):"
            },
            "29": {
                "beforePatchRowNumber": 995,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "30": {
                "beforePatchRowNumber": 996,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Generate a root username and password SHA. This hash is saved to the"
            },
            "31": {
                "beforePatchRowNumber": 997,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    given file path, and is also returned."
            },
            "32": {
                "beforePatchRowNumber": 998,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "33": {
                "beforePatchRowNumber": 999,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "34": {
                "beforePatchRowNumber": 1000,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    LOG.debug(\"Generating initial superuser (root) credentials...\")"
            },
            "35": {
                "beforePatchRowNumber": 1001,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "36": {
                "beforePatchRowNumber": 1002,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    username = ''.join(sample(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", 6))"
            },
            "37": {
                "beforePatchRowNumber": 1003,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    password = get_tmp_dir_hash()[:8]"
            },
            "38": {
                "beforePatchRowNumber": 1004,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "39": {
                "beforePatchRowNumber": 1005,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    LOG.info(\"A NEW superuser credential was generated for the server. \""
            },
            "40": {
                "beforePatchRowNumber": 1006,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-             \"This information IS SAVED, thus subsequent server starts \""
            },
            "41": {
                "beforePatchRowNumber": 1007,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-             \"WILL use these credentials. You WILL NOT get to see \""
            },
            "42": {
                "beforePatchRowNumber": 1008,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-             \"the credentials again, so MAKE SURE YOU REMEMBER THIS \""
            },
            "43": {
                "beforePatchRowNumber": 1009,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-             \"LOGIN!\")"
            },
            "44": {
                "beforePatchRowNumber": 1010,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "45": {
                "beforePatchRowNumber": 1011,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # Highlight the message a bit more, as the server owner configuring the"
            },
            "46": {
                "beforePatchRowNumber": 1012,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # server must know this root access initially."
            },
            "47": {
                "beforePatchRowNumber": 1013,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    credential_msg = f\"The superuser's username is '{username}' with the \" \\"
            },
            "48": {
                "beforePatchRowNumber": 1014,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                     f\"password '{password}'\""
            },
            "49": {
                "beforePatchRowNumber": 1015,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    LOG.info(\"-\" * len(credential_msg))"
            },
            "50": {
                "beforePatchRowNumber": 1016,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    LOG.info(credential_msg)"
            },
            "51": {
                "beforePatchRowNumber": 1017,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    LOG.info(\"-\" * len(credential_msg))"
            },
            "52": {
                "beforePatchRowNumber": 1018,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "53": {
                "beforePatchRowNumber": 1019,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    sha = sha256((username + ':' + password).encode('utf-8')).hexdigest()"
            },
            "54": {
                "beforePatchRowNumber": 1020,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    secret = f\"{username}:{sha}\""
            },
            "55": {
                "beforePatchRowNumber": 1021,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    with open(root_file, 'w', encoding=\"utf-8\", errors=\"ignore\") as f:"
            },
            "56": {
                "beforePatchRowNumber": 1022,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        LOG.debug(\"Save root SHA256 '%s'\", secret)"
            },
            "57": {
                "beforePatchRowNumber": 1023,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        f.write(secret)"
            },
            "58": {
                "beforePatchRowNumber": 1024,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "59": {
                "beforePatchRowNumber": 1025,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # This file should be only readable by the process owner, and noone else."
            },
            "60": {
                "beforePatchRowNumber": 1026,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    os.chmod(root_file, stat.S_IRUSR)"
            },
            "61": {
                "beforePatchRowNumber": 1027,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "62": {
                "beforePatchRowNumber": 1028,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return secret"
            },
            "63": {
                "beforePatchRowNumber": 1029,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "64": {
                "beforePatchRowNumber": 1030,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "65": {
                "beforePatchRowNumber": 1031,
                "afterPatchRowNumber": 989,
                "PatchRowcode": " def start_server(config_directory, package_data, port, config_sql_server,"
            },
            "66": {
                "beforePatchRowNumber": 1032,
                "afterPatchRowNumber": 990,
                "PatchRowcode": "                  listen_address, force_auth, skip_db_cleanup: bool,"
            },
            "67": {
                "beforePatchRowNumber": 1033,
                "afterPatchRowNumber": 991,
                "PatchRowcode": "                  context, check_env):"
            },
            "68": {
                "beforePatchRowNumber": 1038,
                "afterPatchRowNumber": 996,
                "PatchRowcode": " "
            },
            "69": {
                "beforePatchRowNumber": 1039,
                "afterPatchRowNumber": 997,
                "PatchRowcode": "     server_addr = (listen_address, port)"
            },
            "70": {
                "beforePatchRowNumber": 1040,
                "afterPatchRowNumber": 998,
                "PatchRowcode": " "
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 999,
                "PatchRowcode": "+    # The root user file is DEPRECATED AND IGNORED"
            },
            "72": {
                "beforePatchRowNumber": 1041,
                "afterPatchRowNumber": 1000,
                "PatchRowcode": "     root_file = os.path.join(config_directory, 'root.user')"
            },
            "73": {
                "beforePatchRowNumber": 1042,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if not os.path.exists(root_file):"
            },
            "74": {
                "beforePatchRowNumber": 1043,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        LOG.warning(\"Server started without 'root.user' present in \""
            },
            "75": {
                "beforePatchRowNumber": 1044,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    \"CONFIG_DIRECTORY!\")"
            },
            "76": {
                "beforePatchRowNumber": 1045,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        root_sha = __make_root_file(root_file)"
            },
            "77": {
                "beforePatchRowNumber": 1046,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    else:"
            },
            "78": {
                "beforePatchRowNumber": 1047,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        LOG.debug(\"Root file was found. Loading...\")"
            },
            "79": {
                "beforePatchRowNumber": 1048,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "80": {
                "beforePatchRowNumber": 1049,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            with open(root_file, 'r', encoding=\"utf-8\", errors=\"ignore\") as f:"
            },
            "81": {
                "beforePatchRowNumber": 1050,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                root_sha = f.read()"
            },
            "82": {
                "beforePatchRowNumber": 1051,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            LOG.debug(\"Root digest is '%s'\", root_sha)"
            },
            "83": {
                "beforePatchRowNumber": 1052,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except IOError:"
            },
            "84": {
                "beforePatchRowNumber": 1053,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            LOG.info(\"Cannot open root file '%s' even though it exists\","
            },
            "85": {
                "beforePatchRowNumber": 1054,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                     root_file)"
            },
            "86": {
                "beforePatchRowNumber": 1055,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            root_sha = __make_root_file(root_file)"
            },
            "87": {
                "beforePatchRowNumber": 1056,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1001,
                "PatchRowcode": "+    if os.path.exists(root_file):"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1002,
                "PatchRowcode": "+        LOG.warning(\"The 'root.user' file:  %s\""
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1003,
                "PatchRowcode": "+                    \" is deprecated and ignored. If you want to\""
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1004,
                "PatchRowcode": "+                    \" setup an initial user with SUPER_USER permission,\""
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1005,
                "PatchRowcode": "+                    \" configure the super_user field in the server_config.json\""
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1006,
                "PatchRowcode": "+                    \" as described in the documentation.\""
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1007,
                "PatchRowcode": "+                    \" To get rid off this warning,\""
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1008,
                "PatchRowcode": "+                    \" simply delete the root.user file.\","
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1009,
                "PatchRowcode": "+                    root_file)"
            },
            "97": {
                "beforePatchRowNumber": 1057,
                "afterPatchRowNumber": 1010,
                "PatchRowcode": "     # Check whether configuration file exists, create an example if not."
            },
            "98": {
                "beforePatchRowNumber": 1058,
                "afterPatchRowNumber": 1011,
                "PatchRowcode": "     server_cfg_file = os.path.join(config_directory, 'server_config.json')"
            },
            "99": {
                "beforePatchRowNumber": 1059,
                "afterPatchRowNumber": 1012,
                "PatchRowcode": "     if not os.path.exists(server_cfg_file):"
            },
            "100": {
                "beforePatchRowNumber": 1077,
                "afterPatchRowNumber": 1030,
                "PatchRowcode": "     try:"
            },
            "101": {
                "beforePatchRowNumber": 1078,
                "afterPatchRowNumber": 1031,
                "PatchRowcode": "         manager = session_manager.SessionManager("
            },
            "102": {
                "beforePatchRowNumber": 1079,
                "afterPatchRowNumber": 1032,
                "PatchRowcode": "             server_cfg_file,"
            },
            "103": {
                "beforePatchRowNumber": 1080,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            root_sha,"
            },
            "104": {
                "beforePatchRowNumber": 1081,
                "afterPatchRowNumber": 1033,
                "PatchRowcode": "             force_auth)"
            },
            "105": {
                "beforePatchRowNumber": 1082,
                "afterPatchRowNumber": 1034,
                "PatchRowcode": "     except IOError as ioerr:"
            },
            "106": {
                "beforePatchRowNumber": 1083,
                "afterPatchRowNumber": 1035,
                "PatchRowcode": "         LOG.debug(ioerr)"
            },
            "107": {
                "beforePatchRowNumber": 1098,
                "afterPatchRowNumber": 1050,
                "PatchRowcode": "                       \"Earlier logs might contain additional detailed \""
            },
            "108": {
                "beforePatchRowNumber": 1099,
                "afterPatchRowNumber": 1051,
                "PatchRowcode": "                       \"reasoning.\\n\\t* %s\", len(fails),"
            },
            "109": {
                "beforePatchRowNumber": 1100,
                "afterPatchRowNumber": 1052,
                "PatchRowcode": "                       \"\\n\\t* \".join("
            },
            "110": {
                "beforePatchRowNumber": 1101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        (f\"'{ep}' ({reason})\" for (ep, reason) in fails)"
            },
            "111": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1053,
                "PatchRowcode": "+                          (f\"'{ep}' ({reason})\" for (ep, reason) in fails)"
            },
            "112": {
                "beforePatchRowNumber": 1102,
                "afterPatchRowNumber": 1054,
                "PatchRowcode": "                       ))"
            },
            "113": {
                "beforePatchRowNumber": 1103,
                "afterPatchRowNumber": 1055,
                "PatchRowcode": "     else:"
            },
            "114": {
                "beforePatchRowNumber": 1104,
                "afterPatchRowNumber": 1056,
                "PatchRowcode": "         LOG.debug(\"Skipping db_cleanup, as requested.\")"
            }
        },
        "frontPatchFile": [
            "# -------------------------------------------------------------------------",
            "#",
            "#  Part of the CodeChecker project, under the Apache License v2.0 with",
            "#  LLVM Exceptions. See LICENSE for license information.",
            "#  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception",
            "#",
            "# -------------------------------------------------------------------------",
            "\"\"\"",
            "Main server starts a http server which handles Thrift client",
            "and browser requests.",
            "\"\"\"",
            "",
            "",
            "import atexit",
            "import datetime",
            "from functools import partial",
            "from hashlib import sha256",
            "from http.server import HTTPServer, SimpleHTTPRequestHandler",
            "import os",
            "import posixpath",
            "from random import sample",
            "import shutil",
            "import signal",
            "import socket",
            "import ssl",
            "import sys",
            "import stat",
            "from typing import List, Optional, Tuple",
            "import urllib",
            "",
            "import multiprocess",
            "from sqlalchemy.orm import sessionmaker",
            "from sqlalchemy.sql.expression import func",
            "from thrift.protocol import TJSONProtocol",
            "from thrift.transport import TTransport",
            "from thrift.Thrift import TApplicationException",
            "from thrift.Thrift import TMessageType",
            "",
            "from codechecker_api_shared.ttypes import DBStatus",
            "from codechecker_api.Authentication_v6 import \\",
            "    codeCheckerAuthentication as AuthAPI_v6",
            "from codechecker_api.Configuration_v6 import \\",
            "    configurationService as ConfigAPI_v6",
            "from codechecker_api.codeCheckerDBAccess_v6 import \\",
            "    codeCheckerDBAccess as ReportAPI_v6",
            "from codechecker_api.ProductManagement_v6 import \\",
            "    codeCheckerProductService as ProductAPI_v6",
            "from codechecker_api.ServerInfo_v6 import \\",
            "    serverInfoService as ServerInfoAPI_v6",
            "",
            "from codechecker_common import util",
            "from codechecker_common.logger import get_logger",
            "from codechecker_common.compatibility.multiprocessing import \\",
            "    Pool, cpu_count",
            "",
            "from codechecker_web.shared import database_status",
            "from codechecker_web.shared.version import get_version_str",
            "",
            "from . import instance_manager, permissions, routing, session_manager",
            "from .api.authentication import ThriftAuthHandler as AuthHandler_v6",
            "from .api.config_handler import ThriftConfigHandler as ConfigHandler_v6",
            "from .api.product_server import ThriftProductHandler as ProductHandler_v6",
            "from .api.report_server import ThriftRequestHandler as ReportHandler_v6",
            "from .api.server_info_handler import \\",
            "    ThriftServerInfoHandler as ServerInfoHandler_v6",
            "from .database import database, db_cleanup",
            "from .database.config_db_model import Product as ORMProduct, \\",
            "    Configuration as ORMConfiguration",
            "from .database.database import DBSession",
            "from .database.run_db_model import IDENTIFIER as RUN_META, Run, RunLock",
            "from .tmp import get_tmp_dir_hash",
            "",
            "",
            "LOG = get_logger('server')",
            "",
            "",
            "class RequestHandler(SimpleHTTPRequestHandler):",
            "    \"\"\"",
            "    Handle thrift and browser requests",
            "    Simply modified and extended version of SimpleHTTPRequestHandler",
            "    \"\"\"",
            "    auth_session = None",
            "",
            "    def __init__(self, request, client_address, server):",
            "        self.path = None",
            "        super().__init__(request, client_address, server)",
            "",
            "    def log_message(self, *args):",
            "        \"\"\" Silencing http server. \"\"\"",
            "        return",
            "",
            "    def send_thrift_exception(self, error_msg, iprot, oprot, otrans):",
            "        \"\"\"",
            "        Send an exception response to the client in a proper format which can",
            "        be parsed by the Thrift clients expecting JSON responses.",
            "        \"\"\"",
            "        ex = TApplicationException(TApplicationException.INTERNAL_ERROR,",
            "                                   error_msg)",
            "        fname, _, seqid = iprot.readMessageBegin()",
            "        oprot.writeMessageBegin(fname, TMessageType.EXCEPTION, seqid)",
            "        ex.write(oprot)",
            "        oprot.writeMessageEnd()",
            "        oprot.trans.flush()",
            "        result = otrans.getvalue()",
            "        self.send_response(200)",
            "        self.send_header(\"content-type\", \"application/x-thrift\")",
            "        self.send_header(\"Content-Length\", len(result))",
            "        self.end_headers()",
            "        self.wfile.write(result)",
            "",
            "    def __check_session_cookie(self):",
            "        \"\"\"",
            "        Check the CodeChecker privileged access cookie in the request headers.",
            "",
            "        :returns: A session_manager._Session object if a correct, valid session",
            "        cookie was found in the headers. None, otherwise.",
            "        \"\"\"",
            "",
            "        if not self.server.manager.is_enabled:",
            "            return None",
            "",
            "        session = None",
            "        # Check if the user has presented a privileged access cookie.",
            "        cookies = self.headers.get(\"Cookie\")",
            "        if cookies:",
            "            split = cookies.split(\"; \")",
            "            for cookie in split:",
            "                values = cookie.split(\"=\")",
            "                if len(values) == 2 and \\",
            "                        values[0] == session_manager.SESSION_COOKIE_NAME:",
            "                    session = self.server.manager.get_session(values[1])",
            "",
            "        if session and session.is_alive:",
            "            # If a valid session token was found and it can still be used,",
            "            # mark that the user's last access to the server was the",
            "            # request that resulted in the execution of this function.",
            "            session.revalidate()",
            "            return session",
            "        else:",
            "            # If the user's access cookie is no longer usable (invalid),",
            "            # present an error.",
            "            client_host, client_port, is_ipv6 = \\",
            "                RequestHandler._get_client_host_port(self.client_address)",
            "            LOG.debug(",
            "                \"%s:%s Invalid access, credentials not found - \"",
            "                \"session refused\",",
            "                client_host if not is_ipv6 else '[' + client_host + ']',",
            "                str(client_port))",
            "            return None",
            "",
            "    def __handle_readiness(self):",
            "        \"\"\" Handle readiness probe. \"\"\"",
            "        try:",
            "            cfg_sess = self.server.config_session()",
            "            cfg_sess.query(ORMConfiguration).count()",
            "",
            "            self.send_response(200)",
            "            self.end_headers()",
            "            self.wfile.write(b'CODECHECKER_SERVER_IS_READY')",
            "        except Exception:",
            "            self.send_response(500)",
            "            self.end_headers()",
            "            self.wfile.write(b'CODECHECKER_SERVER_IS_NOT_READY')",
            "        finally:",
            "            if cfg_sess:",
            "                cfg_sess.close()",
            "                cfg_sess.commit()",
            "",
            "    def __handle_liveness(self):",
            "        \"\"\" Handle liveness probe. \"\"\"",
            "        self.send_response(200)",
            "        self.end_headers()",
            "        self.wfile.write(b'CODECHECKER_SERVER_IS_LIVE')",
            "",
            "    def end_headers(self):",
            "        # Sending the authentication cookie",
            "        # in every response if any.",
            "        # This will update the the session cookie",
            "        # on the clients to the newest.",
            "        if self.auth_session:",
            "            token = self.auth_session.token",
            "            if token:",
            "                self.send_header(",
            "                    \"Set-Cookie\",",
            "                    f\"{session_manager.SESSION_COOKIE_NAME}={token}; Path=/\")",
            "",
            "            # Set the current user name in the header.",
            "            user_name = self.auth_session.user",
            "            if user_name:",
            "                self.send_header(\"X-User\", user_name)",
            "",
            "        SimpleHTTPRequestHandler.end_headers(self)",
            "",
            "    @staticmethod",
            "    def _get_client_host_port(address):",
            "        \"\"\"",
            "        Returns the host and port of the request's address, and whether it",
            "        was an IPv6 address.",
            "        \"\"\"",
            "        if len(address) == 2:",
            "            return address[0], address[1], False",
            "        if len(address) == 4:",
            "            return address[0], address[1], True",
            "",
            "        raise IndexError(\"Invalid address tuple given.\")",
            "",
            "    def do_GET(self):",
            "        \"\"\" Handles the SPA browser access (GET requests).",
            "",
            "        It will do the following steps:",
            "         - for requests for index.html ('/'), just respond with the file.",
            "         - if the requested path contains a product endpoint name",
            "           ('/prod/app.js', '/prod/runs'), remove the endpoint from the path.",
            "         - if the requested path is a valid file (e.g: 'app.js'), respond with",
            "           the file.",
            "         - otherwise (e.g: 'runs') respond with index.html.",
            "        \"\"\"",
            "        client_host, client_port, is_ipv6 = \\",
            "            RequestHandler._get_client_host_port(self.client_address)",
            "        self.auth_session = self.__check_session_cookie()",
            "",
            "        username = self.auth_session.user if self.auth_session else 'Anonymous'",
            "        LOG.debug(\"%s:%s -- [%s] GET %s\",",
            "                  client_host if not is_ipv6 else '[' + client_host + ']',",
            "                  client_port, username, self.path)",
            "",
            "        if self.path == '/':",
            "            self.path = 'index.html'",
            "            SimpleHTTPRequestHandler.do_GET(self)",
            "            return",
            "",
            "        if self.path == '/live':",
            "            self.__handle_liveness()",
            "            return",
            "",
            "        if self.path == '/ready':",
            "            self.__handle_readiness()",
            "            return",
            "",
            "        product_endpoint, _ = routing.split_client_GET_request(self.path)",
            "",
            "        # Check that path contains a product endpoint.",
            "        if product_endpoint is not None and product_endpoint != '':",
            "            self.path = self.path.replace(f\"{product_endpoint}/\", \"\", 1)",
            "",
            "        if self.path == '/':",
            "            self.path = \"index.html\"",
            "",
            "        # Check that the given path is a file.",
            "        if not os.path.exists(self.translate_path(self.path)):",
            "            self.path = 'index.html'",
            "",
            "        SimpleHTTPRequestHandler.do_GET(self)",
            "",
            "    def __check_prod_db(self, product_endpoint):",
            "        \"\"\"",
            "        Check the product database status.",
            "        Try to reconnect in some cases.",
            "",
            "        Returns if everything is ok with the database or throw an exception",
            "        with the error message if something is wrong with the database.",
            "        \"\"\"",
            "",
            "        product = self.server.get_product(product_endpoint)",
            "        if not product:",
            "            raise ValueError(",
            "                f\"The product with the given endpoint '{product_endpoint}' \"",
            "                \"does not exist!\")",
            "",
            "        if product.db_status == DBStatus.OK:",
            "            # No reconnect needed.",
            "            return product",
            "",
            "        # Try to reconnect in these cases.",
            "        # Do not try to reconnect if there is a schema mismatch.",
            "        # If the product is not connected, try reconnecting...",
            "        if product.db_status in [DBStatus.FAILED_TO_CONNECT,",
            "                                 DBStatus.MISSING,",
            "                                 DBStatus.SCHEMA_INIT_ERROR]:",
            "            LOG.error(\"Request's product '%s' is not connected! \"",
            "                      \"Attempting reconnect...\", product.endpoint)",
            "            product.connect()",
            "            if product.db_status != DBStatus.OK:",
            "                # If the reconnection fails send an error to the user.",
            "                LOG.debug(\"Product reconnection failed.\")",
            "                error_msg = f\"'{product.endpoint}' database connection failed!\"",
            "                LOG.error(error_msg)",
            "                raise ValueError(error_msg)",
            "        else:",
            "            # Send an error to the user.",
            "            db_stat = DBStatus._VALUES_TO_NAMES.get(product.db_status)",
            "            error_msg = f\"'{product.endpoint}' database connection \" \\",
            "                f\"failed. DB status: {str(db_stat)}\"",
            "            LOG.error(error_msg)",
            "            raise ValueError(error_msg)",
            "",
            "        return product",
            "",
            "    # pylint: disable=invalid-name",
            "    def do_POST(self):",
            "        \"\"\"",
            "        Handles POST queries, which are usually Thrift messages.",
            "        \"\"\"",
            "        protocol_factory = TJSONProtocol.TJSONProtocolFactory()",
            "        input_protocol_factory = protocol_factory",
            "        output_protocol_factory = protocol_factory",
            "",
            "        # Get Thrift API function name to print to the log output.",
            "        itrans = TTransport.TFileObjectTransport(self.rfile)",
            "        itrans = TTransport.TBufferedTransport(itrans,",
            "                                               int(self.headers[",
            "                                                   'Content-Length']))",
            "        iprot = input_protocol_factory.getProtocol(itrans)",
            "        fname, _, _ = iprot.readMessageBegin()",
            "",
            "        client_host, client_port, is_ipv6 = \\",
            "            RequestHandler._get_client_host_port(self.client_address)",
            "        self.auth_session = self.__check_session_cookie()",
            "        auth_user = \\",
            "            self.auth_session.user if self.auth_session else \"Anonymous\"",
            "        host_info = client_host if not is_ipv6 else '[' + client_host + ']'",
            "        api_info = f\"{host_info}:{client_port} -- [{auth_user}] POST \" \\",
            "                   f\"{self.path}@{fname}\"",
            "        LOG.info(api_info)",
            "",
            "        # Create new thrift handler.",
            "        version = self.server.version",
            "",
            "        cstringio_buf = itrans.cstringio_buf.getvalue()",
            "        itrans = TTransport.TMemoryBuffer(cstringio_buf)",
            "        iprot = input_protocol_factory.getProtocol(itrans)",
            "",
            "        otrans = TTransport.TMemoryBuffer()",
            "        oprot = output_protocol_factory.getProtocol(otrans)",
            "",
            "        if self.server.manager.is_enabled and \\",
            "                not self.path.endswith(('/Authentication',",
            "                                        '/Configuration',",
            "                                        '/ServerInfo')) and \\",
            "                not self.auth_session:",
            "            # Bail out if the user is not authenticated...",
            "            # This response has the possibility of melting down Thrift clients,",
            "            # but the user is expected to properly authenticate first.",
            "            LOG.debug(\"%s:%s Invalid access, credentials not found \"",
            "                      \"- session refused.\",",
            "                      client_host if not is_ipv6 else '[' + client_host + ']',",
            "                      str(client_port))",
            "",
            "            self.send_thrift_exception(\"Error code 401: Unauthorized!\", iprot,",
            "                                       oprot, otrans)",
            "            return",
            "",
            "        # Authentication is handled, we may now respond to the user.",
            "        try:",
            "            product_endpoint, api_ver, request_endpoint = \\",
            "                routing.split_client_POST_request(self.path)",
            "            if product_endpoint is None and api_ver is None and \\",
            "                    request_endpoint is None:",
            "                raise ValueError(\"Invalid request endpoint path.\")",
            "",
            "            product = None",
            "            if product_endpoint:",
            "                # The current request came through a product route, and not",
            "                # to the main endpoint.",
            "                product = self.__check_prod_db(product_endpoint)",
            "",
            "            version_supported = routing.is_supported_version(api_ver)",
            "            if version_supported:",
            "                major_version, _ = version_supported",
            "",
            "                if major_version == 6:",
            "                    if request_endpoint == 'Authentication':",
            "                        auth_handler = AuthHandler_v6(",
            "                            self.server.manager,",
            "                            self.auth_session,",
            "                            self.server.config_session)",
            "                        processor = AuthAPI_v6.Processor(auth_handler)",
            "                    elif request_endpoint == 'Configuration':",
            "                        conf_handler = ConfigHandler_v6(",
            "                            self.auth_session,",
            "                            self.server.config_session)",
            "                        processor = ConfigAPI_v6.Processor(conf_handler)",
            "                    elif request_endpoint == 'ServerInfo':",
            "                        server_info_handler = ServerInfoHandler_v6(version)",
            "                        processor = ServerInfoAPI_v6.Processor(",
            "                            server_info_handler)",
            "                    elif request_endpoint == 'Products':",
            "                        prod_handler = ProductHandler_v6(",
            "                            self.server,",
            "                            self.auth_session,",
            "                            self.server.config_session,",
            "                            product,",
            "                            version)",
            "                        processor = ProductAPI_v6.Processor(prod_handler)",
            "                    elif request_endpoint == 'CodeCheckerService':",
            "                        # This endpoint is a product's report_server.",
            "                        if not product:",
            "                            error_msg = \\",
            "                                \"Requested CodeCheckerService on a \" \\",
            "                                f\"nonexistent product: '{product_endpoint}'.\"",
            "                            LOG.error(error_msg)",
            "                            raise ValueError(error_msg)",
            "",
            "                        if product_endpoint:",
            "                            # The current request came through a",
            "                            # product route, and not to the main endpoint.",
            "                            product = self.__check_prod_db(product_endpoint)",
            "",
            "                        acc_handler = ReportHandler_v6(",
            "                            self.server.manager,",
            "                            product.session_factory,",
            "                            product,",
            "                            self.auth_session,",
            "                            self.server.config_session,",
            "                            version,",
            "                            api_ver,",
            "                            self.server.context)",
            "                        processor = ReportAPI_v6.Processor(acc_handler)",
            "                    else:",
            "                        LOG.debug(\"This API endpoint does not exist.\")",
            "                        error_msg = f\"No API endpoint named '{self.path}'.\"",
            "                        raise ValueError(error_msg)",
            "                else:",
            "                    raise ValueError(",
            "                        f\"API version {major_version} not supported\")",
            "",
            "            else:",
            "                error_msg = \\",
            "                    \"The API version you are using is not supported \" \\",
            "                    \"by this server (server API version: \" \\",
            "                    f\"{get_version_str()})!\"",
            "                self.send_thrift_exception(error_msg, iprot, oprot, otrans)",
            "                return",
            "",
            "            processor.process(iprot, oprot)",
            "            result = otrans.getvalue()",
            "",
            "            self.send_response(200)",
            "            self.send_header(\"content-type\", \"application/x-thrift\")",
            "            self.send_header(\"Content-Length\", len(result))",
            "            self.end_headers()",
            "            self.wfile.write(result)",
            "            return",
            "",
            "        except BrokenPipeError as ex:",
            "            LOG.warning(\"%s failed with BrokenPipeError: %s\",",
            "                        api_info, str(ex))",
            "            import traceback",
            "            traceback.print_exc()",
            "        except Exception as ex:",
            "            LOG.warning(\"%s failed with Exception: %s\", api_info, str(ex))",
            "            import traceback",
            "            traceback.print_exc()",
            "",
            "            cstringio_buf = itrans.cstringio_buf.getvalue()",
            "            if cstringio_buf:",
            "                itrans = TTransport.TMemoryBuffer(cstringio_buf)",
            "                iprot = input_protocol_factory.getProtocol(itrans)",
            "",
            "            self.send_thrift_exception(str(ex), iprot, oprot, otrans)",
            "",
            "    def list_directory(self, path):",
            "        \"\"\" Disable directory listing. \"\"\"",
            "        self.send_error(405, \"No permission to list directory\")",
            "",
            "    def translate_path(self, path):",
            "        \"\"\"",
            "        Modified version from SimpleHTTPRequestHandler.",
            "        Path is set to www_root.",
            "        \"\"\"",
            "        # Abandon query parameters.",
            "        path = path.split('?', 1)[0]",
            "        path = path.split('#', 1)[0]",
            "        path = posixpath.normpath(urllib.parse.unquote(path))",
            "        words = path.split('/')",
            "        words = [_f for _f in words if _f]",
            "        path = self.server.www_root",
            "        for word in words:",
            "            _, word = os.path.splitdrive(word)",
            "            _, word = os.path.split(word)",
            "            if word in (os.curdir, os.pardir):",
            "                continue",
            "            path = os.path.join(path, word)",
            "        return path",
            "",
            "",
            "class Product:",
            "    \"\"\"",
            "    Represents a product, which is a distinct storage of analysis reports in",
            "    a separate database (and database connection) with its own access control.",
            "    \"\"\"",
            "",
            "    # The amount of SECONDS that need to pass after the last unsuccessful",
            "    # connect() call so the next could be made.",
            "    CONNECT_RETRY_TIMEOUT = 300",
            "",
            "    def __init__(self, id_: int, endpoint: str, display_name: str,",
            "                 connection_string: str, context, check_env):",
            "        \"\"\"",
            "        Set up a new managed product object for the configuration given.",
            "        \"\"\"",
            "        self.__id = id_",
            "        self.__endpoint = endpoint",
            "        self.__display_name = display_name",
            "        self.__connection_string = connection_string",
            "        self.__driver_name = None",
            "        self.__context = context",
            "        self.__check_env = check_env",
            "        self.__engine = None",
            "        self.__session = None",
            "        self.__db_status = DBStatus.MISSING",
            "",
            "        self.__last_connect_attempt = None",
            "",
            "    @property",
            "    def id(self):",
            "        return self.__id",
            "",
            "    @property",
            "    def endpoint(self):",
            "        \"\"\"",
            "        Returns the accessible URL endpoint of the product.",
            "        \"\"\"",
            "        return self.__endpoint",
            "",
            "    @property",
            "    def name(self):",
            "        \"\"\"",
            "        Returns the display name of the product.",
            "        \"\"\"",
            "        return self.__display_name",
            "",
            "    @property",
            "    def session_factory(self):",
            "        \"\"\"",
            "        Returns the session maker on this product's database engine which",
            "        can be used to initiate transactional connections.",
            "        \"\"\"",
            "        return self.__session",
            "",
            "    @property",
            "    def driver_name(self):",
            "        \"\"\"",
            "        Returns the name of the sql driver (sqlite, postgres).",
            "        \"\"\"",
            "        return self.__driver_name",
            "",
            "    @property",
            "    def db_status(self):",
            "        \"\"\"",
            "        Returns the status of the database which belongs to this product.",
            "        Call connect to update it.",
            "        \"\"\"",
            "        return self.__db_status",
            "",
            "    @property",
            "    def last_connection_failure(self):",
            "        \"\"\"",
            "        Returns the reason behind the last executed connection attempt's",
            "        failure.",
            "        \"\"\"",
            "        return self.__last_connect_attempt[1] if self.__last_connect_attempt \\",
            "            else None",
            "",
            "    def connect(self, init_db=False):",
            "        \"\"\"",
            "        Initiates the actual connection to the database configured for the",
            "        product.",
            "",
            "        Each time the connect is called the db_status is updated.",
            "        \"\"\"",
            "        LOG.debug(\"Checking '%s' database.\", self.endpoint)",
            "",
            "        sql_server = database.SQLServer.from_connection_string(",
            "            self.__connection_string,",
            "            self.__endpoint,",
            "            RUN_META,",
            "            self.__context.run_migration_root,",
            "            interactive=False,",
            "            env=self.__check_env)",
            "",
            "        if isinstance(sql_server, database.PostgreSQLServer):",
            "            self.__driver_name = 'postgresql'",
            "        elif isinstance(sql_server, database.SQLiteDatabase):",
            "            self.__driver_name = 'sqlite'",
            "",
            "        try:",
            "            LOG.debug(\"Trying to connect to the database\")",
            "",
            "            # Create the SQLAlchemy engine.",
            "            self.__engine = sql_server.create_engine()",
            "            LOG.debug(self.__engine)",
            "",
            "            self.__session = sessionmaker(bind=self.__engine)",
            "",
            "            self.__engine.execute('SELECT 1')",
            "            self.__db_status = sql_server.check_schema()",
            "            self.__last_connect_attempt = None",
            "",
            "            if self.__db_status == DBStatus.SCHEMA_MISSING and init_db:",
            "                LOG.debug(\"Initializing new database schema.\")",
            "                self.__db_status = sql_server.connect(init_db)",
            "",
            "        except Exception as ex:",
            "            LOG.exception(\"The database for product '%s' cannot be\"",
            "                          \" connected to.\", self.endpoint)",
            "            self.__db_status = DBStatus.FAILED_TO_CONNECT",
            "            self.__last_connect_attempt = (datetime.datetime.now(), str(ex))",
            "",
            "    def get_details(self):",
            "        \"\"\"",
            "        Get details for a product from the database.",
            "",
            "        It may throw different error messages depending on the used SQL driver",
            "        adapter in case of connection error.",
            "        \"\"\"",
            "        with DBSession(self.session_factory) as run_db_session:",
            "            run_locks = run_db_session.query(RunLock.name) \\",
            "                .filter(RunLock.locked_at.isnot(None)) \\",
            "                .all()",
            "",
            "            runs_in_progress = set(run_lock[0] for run_lock in run_locks)",
            "",
            "            num_of_runs = run_db_session.query(Run).count()",
            "",
            "            latest_store_to_product = \"\"",
            "            if num_of_runs:",
            "                last_updated_run = run_db_session.query(Run) \\",
            "                    .order_by(Run.date.desc()) \\",
            "                    .limit(1) \\",
            "                    .one_or_none()",
            "",
            "                latest_store_to_product = last_updated_run.date",
            "",
            "        return num_of_runs, runs_in_progress, latest_store_to_product",
            "",
            "    def teardown(self):",
            "        \"\"\"",
            "        Disposes the database connection to the product's backend.",
            "        \"\"\"",
            "        if self.__db_status == DBStatus.FAILED_TO_CONNECT:",
            "            return",
            "",
            "        self.__engine.dispose()",
            "",
            "        self.__session = None",
            "        self.__engine = None",
            "",
            "    def cleanup_run_db(self):",
            "        \"\"\"",
            "        Cleanup the run database which belongs to this product.",
            "        \"\"\"",
            "        LOG.info(\"[%s] Garbage collection started...\", self.endpoint)",
            "",
            "        db_cleanup.remove_expired_data(self)",
            "        db_cleanup.remove_unused_data(self)",
            "        db_cleanup.update_contextual_data(self, self.__context)",
            "",
            "        LOG.info(\"[%s] Garbage collection finished.\", self.endpoint)",
            "        return True",
            "",
            "",
            "def _do_db_cleanup(context, check_env,",
            "                   id_: int, endpoint: str, display_name: str,",
            "                   connection_str: str) -> Tuple[Optional[bool], str]:",
            "    # This functions is a concurrent job handler!",
            "    try:",
            "        prod = Product(id_, endpoint, display_name, connection_str,",
            "                       context, check_env)",
            "        prod.connect(init_db=False)",
            "        if prod.db_status != DBStatus.OK:",
            "            status_str = database_status.db_status_msg.get(prod.db_status)",
            "            return None, \\",
            "                f\"Cleanup not attempted, database status is \\\"{status_str}\\\"\"",
            "",
            "        prod.cleanup_run_db()",
            "        prod.teardown()",
            "",
            "        # Result is hard-wired to True, because the db_cleanup routines",
            "        # swallow and log the potential errors but do not return them.",
            "        return True, \"\"",
            "    except Exception as e:",
            "        import traceback",
            "        traceback.print_exc()",
            "        return False, str(e)",
            "",
            "",
            "def _do_db_cleanups(config_database, context, check_env) \\",
            "        -> Tuple[bool, List[Tuple[str, str]]]:",
            "    \"\"\"",
            "    Performs on-demand start-up database cleanup on all the products present",
            "    in the ``config_database``.",
            "",
            "    Returns whether database clean-up succeeded for all products, and the",
            "    list of products for which it failed, along with the failure reason.",
            "    \"\"\"",
            "    def _get_products() -> List[Product]:",
            "        products = []",
            "        cfg_engine = config_database.create_engine()",
            "        cfg_session_factory = sessionmaker(bind=cfg_engine)",
            "        with DBSession(cfg_session_factory) as cfg_db:",
            "            for row in cfg_db.query(ORMProduct) \\",
            "                    .order_by(ORMProduct.endpoint.asc()) \\",
            "                    .all():",
            "                products.append((row.id, row.endpoint, row.display_name,",
            "                                 row.connection))",
            "        cfg_engine.dispose()",
            "        return products",
            "",
            "    products = _get_products()",
            "    if not products:",
            "        return True, []",
            "",
            "    thr_count = util.clamp(1, len(products), cpu_count())",
            "    overall_result, failures = True, []",
            "    with Pool(max_workers=thr_count) as executor:",
            "        LOG.info(\"Performing database cleanup using %d concurrent jobs...\",",
            "                 thr_count)",
            "        for product, result in \\",
            "                zip(products, executor.map(",
            "                    partial(_do_db_cleanup, context, check_env),",
            "                    *zip(*products))):",
            "            success, reason = result",
            "            if not success:",
            "                _, endpoint, _, _ = product",
            "                overall_result = False",
            "                failures.append((endpoint, reason))",
            "",
            "    return overall_result, failures",
            "",
            "",
            "class CCSimpleHttpServer(HTTPServer):",
            "    \"\"\"",
            "    Simple http server to handle requests from the clients.",
            "    \"\"\"",
            "",
            "    daemon_threads = False",
            "    address_family = socket.AF_INET  # IPv4",
            "",
            "    def __init__(self,",
            "                 server_address,",
            "                 RequestHandlerClass,",
            "                 config_directory,",
            "                 product_db_sql_server,",
            "                 pckg_data,",
            "                 context,",
            "                 check_env,",
            "                 manager):",
            "",
            "        LOG.debug(\"Initializing HTTP server...\")",
            "",
            "        self.config_directory = config_directory",
            "        self.www_root = pckg_data['www_root']",
            "        self.doc_root = pckg_data['doc_root']",
            "        self.version = pckg_data['version']",
            "        self.context = context",
            "        self.check_env = check_env",
            "        self.manager = manager",
            "        self.__products = {}",
            "",
            "        # Create a database engine for the configuration database.",
            "        LOG.debug(\"Creating database engine for CONFIG DATABASE...\")",
            "        self.__engine = product_db_sql_server.create_engine()",
            "        self.config_session = sessionmaker(bind=self.__engine)",
            "        self.manager.set_database_connection(self.config_session)",
            "",
            "        # Load the initial list of products and set up the server.",
            "        cfg_sess = self.config_session()",
            "        permissions.initialise_defaults('SYSTEM', {",
            "            'config_db_session': cfg_sess",
            "        })",
            "        products = cfg_sess.query(ORMProduct).all()",
            "        for product in products:",
            "            self.add_product(product)",
            "            permissions.initialise_defaults('PRODUCT', {",
            "                'config_db_session': cfg_sess,",
            "                'productID': product.id",
            "            })",
            "        cfg_sess.commit()",
            "        cfg_sess.close()",
            "",
            "        try:",
            "            HTTPServer.__init__(self, server_address,",
            "                                RequestHandlerClass,",
            "                                bind_and_activate=True)",
            "            ssl_key_file = os.path.join(config_directory, \"key.pem\")",
            "            ssl_cert_file = os.path.join(config_directory, \"cert.pem\")",
            "",
            "            self.configure_keepalive()",
            "",
            "            if os.path.isfile(ssl_key_file) and os.path.isfile(ssl_cert_file):",
            "                LOG.info(\"Initiating SSL. Server listening on secure socket.\")",
            "                LOG.debug(\"Using cert file: %s\", ssl_cert_file)",
            "                LOG.debug(\"Using key file: %s\", ssl_key_file)",
            "                ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)",
            "                ssl_context.load_cert_chain(certfile=ssl_cert_file,",
            "                                            keyfile=ssl_key_file)",
            "                # FIXME introduce with python 3.7",
            "                # ssl_context.minimum_version = ssl.TLSVersion.TLSv1_2",
            "",
            "                # TLS1 and TLS1.1 were deprecated in RFC8996",
            "                # https://datatracker.ietf.org/doc/html/rfc8996",
            "                ssl_context.options |= (ssl.OP_NO_TLSv1 | ssl.OP_NO_TLSv1_1)",
            "                self.socket = ssl_context.wrap_socket(self.socket,",
            "                                                      server_side=True)",
            "",
            "            else:",
            "                LOG.info(\"Searching for SSL key at %s, cert at %s, \"",
            "                         \"not found...\", ssl_key_file, ssl_cert_file)",
            "                LOG.info(\"Falling back to simple, insecure HTTP.\")",
            "",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't start the server: %s\", e.__str__())",
            "            raise",
            "",
            "    def configure_keepalive(self):",
            "        \"\"\"",
            "        Enable keepalive on the socket and some TCP keepalive configuration",
            "        option based on the server configuration file.",
            "        \"\"\"",
            "        if not self.manager.is_keepalive_enabled():",
            "            return",
            "",
            "        keepalive_is_on = self.socket.getsockopt(socket.SOL_SOCKET,",
            "                                                 socket.SO_KEEPALIVE)",
            "        if keepalive_is_on != 0:",
            "            LOG.debug('Socket keepalive already on.')",
            "        else:",
            "            LOG.debug('Socket keepalive off, turning on.')",
            "",
            "        ret = self.socket.setsockopt(socket.SOL_SOCKET,",
            "                                     socket.SO_KEEPALIVE, 1)",
            "        if ret:",
            "            LOG.error('Failed to set socket keepalive: %s', ret)",
            "",
            "        idle = self.manager.get_keepalive_idle()",
            "        if idle:",
            "            ret = self.socket.setsockopt(socket.IPPROTO_TCP,",
            "                                         socket.TCP_KEEPIDLE, idle)",
            "            if ret:",
            "                LOG.error('Failed to set TCP keepalive idle: %s', ret)",
            "",
            "        interval = self.manager.get_keepalive_interval()",
            "        if interval:",
            "            ret = self.socket.setsockopt(socket.IPPROTO_TCP,",
            "                                         socket.TCP_KEEPINTVL, interval)",
            "            if ret:",
            "                LOG.error('Failed to set TCP keepalive interval: %s', ret)",
            "",
            "        max_probe = self.manager.get_keepalive_max_probe()",
            "        if max_probe:",
            "            ret = self.socket.setsockopt(socket.IPPROTO_TCP,",
            "                                         socket.TCP_KEEPCNT, max_probe)",
            "            if ret:",
            "                LOG.error('Failed to set TCP max keepalive probe: %s', ret)",
            "",
            "    def terminate(self):",
            "        \"\"\"",
            "        Terminating the server.",
            "        \"\"\"",
            "        try:",
            "            self.server_close()",
            "            self.__engine.dispose()",
            "        except Exception as ex:",
            "            LOG.error(\"Failed to shut down the WEB server!\")",
            "            LOG.error(str(ex))",
            "            sys.exit(1)",
            "",
            "    def add_product(self, orm_product, init_db=False):",
            "        \"\"\"",
            "        Adds a product to the list of product databases connected to",
            "        by the server.",
            "        Checks the database connection for the product databases.",
            "        \"\"\"",
            "        if orm_product.endpoint in self.__products:",
            "            LOG.debug(\"This product is already configured!\")",
            "            return",
            "",
            "        LOG.debug(\"Setting up product '%s'\", orm_product.endpoint)",
            "",
            "        prod = Product(orm_product.id,",
            "                       orm_product.endpoint,",
            "                       orm_product.display_name,",
            "                       orm_product.connection,",
            "                       self.context,",
            "                       self.check_env)",
            "",
            "        # Update the product database status.",
            "        prod.connect()",
            "        if prod.db_status == DBStatus.SCHEMA_MISSING and init_db:",
            "            LOG.debug(\"Schema was missing in the database. Initializing new\")",
            "            prod.connect(init_db=True)",
            "",
            "        # The \"num_of_runs\" column of the config database is shown on the",
            "        # product page of the web interface. This is intentionally redundant",
            "        # with a simple query that would count the number of runs in a product:",
            "        # measurements have proven that this caching significantly improves",
            "        # responsibility.",
            "        # This field is incremented whenever a run is added to a product, and",
            "        # decreased when run(s) are removed. However, if these numbers ever",
            "        # diverge, the product page and the bottom right of the run page would",
            "        # display different run counts. To help on this, the num_of_runs column",
            "        # is updated at every server startup.",
            "        # FIXME: Pylint emits a false positive here, and states that",
            "        # session_factory() is not callable, because it initializes to None.",
            "        # More on this:",
            "        # https://github.com/Ericsson/codechecker/pull/3733#issuecomment-1235304179",
            "        # https://github.com/PyCQA/pylint/issues/6005",
            "        orm_product.num_of_runs = \\",
            "            prod.session_factory().query(func.count(Run.id)).one_or_none()[0] \\",
            "            # pylint: disable=not-callable",
            "",
            "        self.__products[prod.endpoint] = prod",
            "",
            "    @property",
            "    def num_products(self):",
            "        \"\"\"",
            "        Returns the number of products currently mounted by the server.",
            "        \"\"\"",
            "        return len(self.__products)",
            "",
            "    def get_product(self, endpoint):",
            "        \"\"\"",
            "        Get the product connection object for the given endpoint, or None.",
            "        \"\"\"",
            "        if endpoint in self.__products:",
            "            return self.__products.get(endpoint)",
            "",
            "        LOG.debug(\"Product with the given endpoint '%s' does not exist in \"",
            "                  \"the local cache. Try to get it from the database.\",",
            "                  endpoint)",
            "",
            "        # If the product doesn't find in the cache, try to get it from the",
            "        # database.",
            "        try:",
            "            cfg_sess = self.config_session()",
            "            product = cfg_sess.query(ORMProduct) \\",
            "                .filter(ORMProduct.endpoint == endpoint) \\",
            "                .limit(1).one_or_none()",
            "",
            "            if not product:",
            "                return None",
            "",
            "            self.add_product(product)",
            "            permissions.initialise_defaults('PRODUCT', {",
            "                'config_db_session': cfg_sess,",
            "                'productID': product.id",
            "            })",
            "",
            "            return self.__products.get(endpoint, None)",
            "        finally:",
            "            if cfg_sess:",
            "                cfg_sess.close()",
            "                cfg_sess.commit()",
            "",
            "    def get_only_product(self):",
            "        \"\"\"",
            "        Returns the Product object for the only product connected to by the",
            "        server, or None, if there are 0 or >= 2 products managed.",
            "        \"\"\"",
            "        return list(self.__products.items())[0][1] if self.num_products == 1 \\",
            "            else None",
            "",
            "    def remove_product(self, endpoint):",
            "        product = self.get_product(endpoint)",
            "        if not product:",
            "            raise ValueError(",
            "                f\"The product with the given endpoint '{endpoint}' does \"",
            "                \"not exist!\")",
            "",
            "        LOG.info(\"Disconnecting product '%s'\", endpoint)",
            "        product.teardown()",
            "",
            "        del self.__products[endpoint]",
            "",
            "    def remove_products_except(self, endpoints_to_keep):",
            "        \"\"\"",
            "        Removes EVERY product connection from the server except those",
            "        endpoints specified in :endpoints_to_keep.",
            "        \"\"\"",
            "        for ep in list(self.__products):",
            "            if ep not in endpoints_to_keep:",
            "                self.remove_product(ep)",
            "",
            "",
            "class CCSimpleHttpServerIPv6(CCSimpleHttpServer):",
            "    \"\"\"",
            "    CodeChecker HTTP simple server that listens over an IPv6 socket.",
            "    \"\"\"",
            "",
            "    address_family = socket.AF_INET6",
            "",
            "",
            "def __make_root_file(root_file):",
            "    \"\"\"",
            "    Generate a root username and password SHA. This hash is saved to the",
            "    given file path, and is also returned.",
            "    \"\"\"",
            "",
            "    LOG.debug(\"Generating initial superuser (root) credentials...\")",
            "",
            "    username = ''.join(sample(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", 6))",
            "    password = get_tmp_dir_hash()[:8]",
            "",
            "    LOG.info(\"A NEW superuser credential was generated for the server. \"",
            "             \"This information IS SAVED, thus subsequent server starts \"",
            "             \"WILL use these credentials. You WILL NOT get to see \"",
            "             \"the credentials again, so MAKE SURE YOU REMEMBER THIS \"",
            "             \"LOGIN!\")",
            "",
            "    # Highlight the message a bit more, as the server owner configuring the",
            "    # server must know this root access initially.",
            "    credential_msg = f\"The superuser's username is '{username}' with the \" \\",
            "                     f\"password '{password}'\"",
            "    LOG.info(\"-\" * len(credential_msg))",
            "    LOG.info(credential_msg)",
            "    LOG.info(\"-\" * len(credential_msg))",
            "",
            "    sha = sha256((username + ':' + password).encode('utf-8')).hexdigest()",
            "    secret = f\"{username}:{sha}\"",
            "    with open(root_file, 'w', encoding=\"utf-8\", errors=\"ignore\") as f:",
            "        LOG.debug(\"Save root SHA256 '%s'\", secret)",
            "        f.write(secret)",
            "",
            "    # This file should be only readable by the process owner, and noone else.",
            "    os.chmod(root_file, stat.S_IRUSR)",
            "",
            "    return secret",
            "",
            "",
            "def start_server(config_directory, package_data, port, config_sql_server,",
            "                 listen_address, force_auth, skip_db_cleanup: bool,",
            "                 context, check_env):",
            "    \"\"\"",
            "    Start http server to handle web client and thrift requests.",
            "    \"\"\"",
            "    LOG.debug(\"Starting CodeChecker server...\")",
            "",
            "    server_addr = (listen_address, port)",
            "",
            "    root_file = os.path.join(config_directory, 'root.user')",
            "    if not os.path.exists(root_file):",
            "        LOG.warning(\"Server started without 'root.user' present in \"",
            "                    \"CONFIG_DIRECTORY!\")",
            "        root_sha = __make_root_file(root_file)",
            "    else:",
            "        LOG.debug(\"Root file was found. Loading...\")",
            "        try:",
            "            with open(root_file, 'r', encoding=\"utf-8\", errors=\"ignore\") as f:",
            "                root_sha = f.read()",
            "            LOG.debug(\"Root digest is '%s'\", root_sha)",
            "        except IOError:",
            "            LOG.info(\"Cannot open root file '%s' even though it exists\",",
            "                     root_file)",
            "            root_sha = __make_root_file(root_file)",
            "",
            "    # Check whether configuration file exists, create an example if not.",
            "    server_cfg_file = os.path.join(config_directory, 'server_config.json')",
            "    if not os.path.exists(server_cfg_file):",
            "        # For backward compatibility reason if the session_config.json file",
            "        # exists we rename it to server_config.json.",
            "        session_cfg_file = os.path.join(config_directory,",
            "                                        'session_config.json')",
            "        example_cfg_file = os.path.join(os.environ['CC_DATA_FILES_DIR'],",
            "                                        'config', 'server_config.json')",
            "        if os.path.exists(session_cfg_file):",
            "            LOG.info(\"Renaming '%s' to '%s'. Please check the example \"",
            "                     \"configuration file ('%s') or the user guide for more \"",
            "                     \"information.\", session_cfg_file,",
            "                     server_cfg_file, example_cfg_file)",
            "            os.rename(session_cfg_file, server_cfg_file)",
            "        else:",
            "            LOG.info(\"CodeChecker server's example configuration file \"",
            "                     \"created at '%s'\", server_cfg_file)",
            "            shutil.copyfile(example_cfg_file, server_cfg_file)",
            "",
            "    try:",
            "        manager = session_manager.SessionManager(",
            "            server_cfg_file,",
            "            root_sha,",
            "            force_auth)",
            "    except IOError as ioerr:",
            "        LOG.debug(ioerr)",
            "        LOG.error(\"The server's configuration file \"",
            "                  \"is missing or can not be read!\")",
            "        sys.exit(1)",
            "    except ValueError as verr:",
            "        LOG.debug(verr)",
            "        LOG.error(\"The server's configuration file is invalid!\")",
            "        sys.exit(1)",
            "",
            "    if not skip_db_cleanup:",
            "        all_success, fails = _do_db_cleanups(config_sql_server,",
            "                                             context,",
            "                                             check_env)",
            "        if not all_success:",
            "            LOG.error(\"Failed to perform automatic cleanup on %d products! \"",
            "                      \"Earlier logs might contain additional detailed \"",
            "                      \"reasoning.\\n\\t* %s\", len(fails),",
            "                      \"\\n\\t* \".join(",
            "                        (f\"'{ep}' ({reason})\" for (ep, reason) in fails)",
            "                      ))",
            "    else:",
            "        LOG.debug(\"Skipping db_cleanup, as requested.\")",
            "",
            "    server_clazz = CCSimpleHttpServer",
            "    if ':' in server_addr[0]:",
            "        # IPv6 address specified for listening.",
            "        # FIXME: Python>=3.8 automatically handles IPv6 if ':' is in the bind",
            "        # address, see https://bugs.python.org/issue24209.",
            "        server_clazz = CCSimpleHttpServerIPv6",
            "",
            "    http_server = server_clazz(server_addr,",
            "                               RequestHandler,",
            "                               config_directory,",
            "                               config_sql_server,",
            "                               package_data,",
            "                               context,",
            "                               check_env,",
            "                               manager)",
            "",
            "    # If the server was started with the port 0, the OS will pick an available",
            "    # port. For this reason we will update the port variable after server",
            "    # initialization.",
            "    port = http_server.socket.getsockname()[1]",
            "",
            "    processes = []",
            "",
            "    def signal_handler(signum, _):",
            "        \"\"\"",
            "        Handle SIGTERM to stop the server running.",
            "        \"\"\"",
            "        LOG.info(\"Shutting down the WEB server on [%s:%d]\",",
            "                 '[' + listen_address + ']'",
            "                 if server_clazz is CCSimpleHttpServerIPv6 else listen_address,",
            "                 port)",
            "        http_server.terminate()",
            "",
            "        # Terminate child processes.",
            "        for pp in processes:",
            "            pp.terminate()",
            "",
            "        sys.exit(128 + signum)",
            "",
            "    def reload_signal_handler(*_args, **_kwargs):",
            "        \"\"\"",
            "        Reloads server configuration file.",
            "        \"\"\"",
            "        manager.reload_config()",
            "",
            "    try:",
            "        instance_manager.register(os.getpid(),",
            "                                  os.path.abspath(",
            "                                      context.codechecker_workspace),",
            "                                  port)",
            "    except IOError as ex:",
            "        LOG.debug(ex.strerror)",
            "",
            "    LOG.info(\"Server waiting for client requests on [%s:%d]\",",
            "             '[' + listen_address + ']'",
            "             if server_clazz is CCSimpleHttpServerIPv6 else listen_address,",
            "             port)",
            "",
            "    def unregister_handler(pid):",
            "        \"\"\"",
            "        Handle errors during instance unregistration.",
            "        The workspace might be removed so updating the",
            "        config content might fail.",
            "        \"\"\"",
            "        try:",
            "            instance_manager.unregister(pid)",
            "        except IOError as ex:",
            "            LOG.debug(ex.strerror)",
            "",
            "    atexit.register(unregister_handler, os.getpid())",
            "",
            "    for _ in range(manager.worker_processes - 1):",
            "        p = multiprocess.Process(target=http_server.serve_forever)",
            "        processes.append(p)",
            "        p.start()",
            "",
            "    signal.signal(signal.SIGINT, signal_handler)",
            "    signal.signal(signal.SIGTERM, signal_handler)",
            "",
            "    if sys.platform != \"win32\":",
            "        signal.signal(signal.SIGHUP, reload_signal_handler)",
            "",
            "    # Main process also acts as a worker.",
            "    http_server.serve_forever()",
            "",
            "    LOG.info(\"Webserver quit.\")",
            "",
            "",
            "def add_initial_run_database(config_sql_server, product_connection):",
            "    \"\"\"",
            "    Create a default run database as SQLite in the config directory,",
            "    and add it to the list of products in the config database specified by",
            "    db_conn_string.",
            "    \"\"\"",
            "",
            "    # Connect to the configuration database",
            "    LOG.debug(\"Creating database engine for CONFIG DATABASE...\")",
            "    __engine = config_sql_server.create_engine()",
            "    product_session = sessionmaker(bind=__engine)",
            "",
            "    # Load the initial list of products and create the connections.",
            "    sess = product_session()",
            "    products = sess.query(ORMProduct).all()",
            "    if products:",
            "        raise ValueError(\"Called create_initial_run_database on non-empty \"",
            "                         \"config database -- you shouldn't have done this!\")",
            "",
            "    LOG.debug(\"Adding default product to the config db...\")",
            "    product = ORMProduct('Default', product_connection, 'Default',",
            "                         \"Default product created at server start.\")",
            "    sess.add(product)",
            "    sess.commit()",
            "    sess.close()",
            "",
            "    LOG.debug(\"Default product set up.\")"
        ],
        "afterPatchFile": [
            "# -------------------------------------------------------------------------",
            "#",
            "#  Part of the CodeChecker project, under the Apache License v2.0 with",
            "#  LLVM Exceptions. See LICENSE for license information.",
            "#  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception",
            "#",
            "# -------------------------------------------------------------------------",
            "\"\"\"",
            "Main server starts a http server which handles Thrift client",
            "and browser requests.",
            "\"\"\"",
            "",
            "",
            "import atexit",
            "import datetime",
            "from functools import partial",
            "from http.server import HTTPServer, SimpleHTTPRequestHandler",
            "import os",
            "import posixpath",
            "import shutil",
            "import signal",
            "import socket",
            "import ssl",
            "import sys",
            "from typing import List, Optional, Tuple",
            "import urllib",
            "",
            "import multiprocess",
            "from sqlalchemy.orm import sessionmaker",
            "from sqlalchemy.sql.expression import func",
            "from thrift.protocol import TJSONProtocol",
            "from thrift.transport import TTransport",
            "from thrift.Thrift import TApplicationException",
            "from thrift.Thrift import TMessageType",
            "",
            "from codechecker_api_shared.ttypes import DBStatus",
            "from codechecker_api.Authentication_v6 import \\",
            "    codeCheckerAuthentication as AuthAPI_v6",
            "from codechecker_api.Configuration_v6 import \\",
            "    configurationService as ConfigAPI_v6",
            "from codechecker_api.codeCheckerDBAccess_v6 import \\",
            "    codeCheckerDBAccess as ReportAPI_v6",
            "from codechecker_api.ProductManagement_v6 import \\",
            "    codeCheckerProductService as ProductAPI_v6",
            "from codechecker_api.ServerInfo_v6 import \\",
            "    serverInfoService as ServerInfoAPI_v6",
            "",
            "from codechecker_common import util",
            "from codechecker_common.logger import get_logger",
            "from codechecker_common.compatibility.multiprocessing import \\",
            "    Pool, cpu_count",
            "",
            "from codechecker_web.shared import database_status",
            "from codechecker_web.shared.version import get_version_str",
            "",
            "from . import instance_manager, permissions, routing, session_manager",
            "from .api.authentication import ThriftAuthHandler as AuthHandler_v6",
            "from .api.config_handler import ThriftConfigHandler as ConfigHandler_v6",
            "from .api.product_server import ThriftProductHandler as ProductHandler_v6",
            "from .api.report_server import ThriftRequestHandler as ReportHandler_v6",
            "from .api.server_info_handler import \\",
            "    ThriftServerInfoHandler as ServerInfoHandler_v6",
            "from .database import database, db_cleanup",
            "from .database.config_db_model import Product as ORMProduct, \\",
            "    Configuration as ORMConfiguration",
            "from .database.database import DBSession",
            "from .database.run_db_model import IDENTIFIER as RUN_META, Run, RunLock",
            "",
            "LOG = get_logger('server')",
            "",
            "",
            "class RequestHandler(SimpleHTTPRequestHandler):",
            "    \"\"\"",
            "    Handle thrift and browser requests",
            "    Simply modified and extended version of SimpleHTTPRequestHandler",
            "    \"\"\"",
            "    auth_session = None",
            "",
            "    def __init__(self, request, client_address, server):",
            "        self.path = None",
            "        super().__init__(request, client_address, server)",
            "",
            "    def log_message(self, *args):",
            "        \"\"\" Silencing http server. \"\"\"",
            "        return",
            "",
            "    def send_thrift_exception(self, error_msg, iprot, oprot, otrans):",
            "        \"\"\"",
            "        Send an exception response to the client in a proper format which can",
            "        be parsed by the Thrift clients expecting JSON responses.",
            "        \"\"\"",
            "        ex = TApplicationException(TApplicationException.INTERNAL_ERROR,",
            "                                   error_msg)",
            "        fname, _, seqid = iprot.readMessageBegin()",
            "        oprot.writeMessageBegin(fname, TMessageType.EXCEPTION, seqid)",
            "        ex.write(oprot)",
            "        oprot.writeMessageEnd()",
            "        oprot.trans.flush()",
            "        result = otrans.getvalue()",
            "        self.send_response(200)",
            "        self.send_header(\"content-type\", \"application/x-thrift\")",
            "        self.send_header(\"Content-Length\", len(result))",
            "        self.end_headers()",
            "        self.wfile.write(result)",
            "",
            "    def __check_session_cookie(self):",
            "        \"\"\"",
            "        Check the CodeChecker privileged access cookie in the request headers.",
            "",
            "        :returns: A session_manager._Session object if a correct, valid session",
            "        cookie was found in the headers. None, otherwise.",
            "        \"\"\"",
            "",
            "        if not self.server.manager.is_enabled:",
            "            return None",
            "",
            "        session = None",
            "        # Check if the user has presented a privileged access cookie.",
            "        cookies = self.headers.get(\"Cookie\")",
            "        if cookies:",
            "            split = cookies.split(\"; \")",
            "            for cookie in split:",
            "                values = cookie.split(\"=\")",
            "                if len(values) == 2 and \\",
            "                        values[0] == session_manager.SESSION_COOKIE_NAME:",
            "                    session = self.server.manager.get_session(values[1])",
            "",
            "        if session and session.is_alive:",
            "            # If a valid session token was found and it can still be used,",
            "            # mark that the user's last access to the server was the",
            "            # request that resulted in the execution of this function.",
            "            session.revalidate()",
            "            return session",
            "        else:",
            "            # If the user's access cookie is no longer usable (invalid),",
            "            # present an error.",
            "            client_host, client_port, is_ipv6 = \\",
            "                RequestHandler._get_client_host_port(self.client_address)",
            "            LOG.debug(",
            "                \"%s:%s Invalid access, credentials not found - \"",
            "                \"session refused\",",
            "                client_host if not is_ipv6 else '[' + client_host + ']',",
            "                str(client_port))",
            "            return None",
            "",
            "    def __handle_readiness(self):",
            "        \"\"\" Handle readiness probe. \"\"\"",
            "        try:",
            "            cfg_sess = self.server.config_session()",
            "            cfg_sess.query(ORMConfiguration).count()",
            "",
            "            self.send_response(200)",
            "            self.end_headers()",
            "            self.wfile.write(b'CODECHECKER_SERVER_IS_READY')",
            "        except Exception:",
            "            self.send_response(500)",
            "            self.end_headers()",
            "            self.wfile.write(b'CODECHECKER_SERVER_IS_NOT_READY')",
            "        finally:",
            "            if cfg_sess:",
            "                cfg_sess.close()",
            "                cfg_sess.commit()",
            "",
            "    def __handle_liveness(self):",
            "        \"\"\" Handle liveness probe. \"\"\"",
            "        self.send_response(200)",
            "        self.end_headers()",
            "        self.wfile.write(b'CODECHECKER_SERVER_IS_LIVE')",
            "",
            "    def end_headers(self):",
            "        # Sending the authentication cookie",
            "        # in every response if any.",
            "        # This will update the the session cookie",
            "        # on the clients to the newest.",
            "        if self.auth_session:",
            "            token = self.auth_session.token",
            "            if token:",
            "                self.send_header(",
            "                    \"Set-Cookie\",",
            "                    f\"{session_manager.SESSION_COOKIE_NAME}={token}; Path=/\")",
            "",
            "            # Set the current user name in the header.",
            "            user_name = self.auth_session.user",
            "            if user_name:",
            "                self.send_header(\"X-User\", user_name)",
            "",
            "        SimpleHTTPRequestHandler.end_headers(self)",
            "",
            "    @staticmethod",
            "    def _get_client_host_port(address):",
            "        \"\"\"",
            "        Returns the host and port of the request's address, and whether it",
            "        was an IPv6 address.",
            "        \"\"\"",
            "        if len(address) == 2:",
            "            return address[0], address[1], False",
            "        if len(address) == 4:",
            "            return address[0], address[1], True",
            "",
            "        raise IndexError(\"Invalid address tuple given.\")",
            "",
            "    def do_GET(self):",
            "        \"\"\" Handles the SPA browser access (GET requests).",
            "",
            "        It will do the following steps:",
            "         - for requests for index.html ('/'), just respond with the file.",
            "         - if the requested path contains a product endpoint name",
            "           ('/prod/app.js', '/prod/runs'), remove the endpoint from the path.",
            "         - if the requested path is a valid file (e.g: 'app.js'), respond with",
            "           the file.",
            "         - otherwise (e.g: 'runs') respond with index.html.",
            "        \"\"\"",
            "        client_host, client_port, is_ipv6 = \\",
            "            RequestHandler._get_client_host_port(self.client_address)",
            "        self.auth_session = self.__check_session_cookie()",
            "",
            "        username = self.auth_session.user if self.auth_session else 'Anonymous'",
            "        LOG.debug(\"%s:%s -- [%s] GET %s\",",
            "                  client_host if not is_ipv6 else '[' + client_host + ']',",
            "                  client_port, username, self.path)",
            "",
            "        if self.path == '/':",
            "            self.path = 'index.html'",
            "            SimpleHTTPRequestHandler.do_GET(self)",
            "            return",
            "",
            "        if self.path == '/live':",
            "            self.__handle_liveness()",
            "            return",
            "",
            "        if self.path == '/ready':",
            "            self.__handle_readiness()",
            "            return",
            "",
            "        product_endpoint, _ = routing.split_client_GET_request(self.path)",
            "",
            "        # Check that path contains a product endpoint.",
            "        if product_endpoint is not None and product_endpoint != '':",
            "            self.path = self.path.replace(f\"{product_endpoint}/\", \"\", 1)",
            "",
            "        if self.path == '/':",
            "            self.path = \"index.html\"",
            "",
            "        # Check that the given path is a file.",
            "        if not os.path.exists(self.translate_path(self.path)):",
            "            self.path = 'index.html'",
            "",
            "        SimpleHTTPRequestHandler.do_GET(self)",
            "",
            "    def __check_prod_db(self, product_endpoint):",
            "        \"\"\"",
            "        Check the product database status.",
            "        Try to reconnect in some cases.",
            "",
            "        Returns if everything is ok with the database or throw an exception",
            "        with the error message if something is wrong with the database.",
            "        \"\"\"",
            "",
            "        product = self.server.get_product(product_endpoint)",
            "        if not product:",
            "            raise ValueError(",
            "                f\"The product with the given endpoint '{product_endpoint}' \"",
            "                \"does not exist!\")",
            "",
            "        if product.db_status == DBStatus.OK:",
            "            # No reconnect needed.",
            "            return product",
            "",
            "        # Try to reconnect in these cases.",
            "        # Do not try to reconnect if there is a schema mismatch.",
            "        # If the product is not connected, try reconnecting...",
            "        if product.db_status in [DBStatus.FAILED_TO_CONNECT,",
            "                                 DBStatus.MISSING,",
            "                                 DBStatus.SCHEMA_INIT_ERROR]:",
            "            LOG.error(\"Request's product '%s' is not connected! \"",
            "                      \"Attempting reconnect...\", product.endpoint)",
            "            product.connect()",
            "            if product.db_status != DBStatus.OK:",
            "                # If the reconnection fails send an error to the user.",
            "                LOG.debug(\"Product reconnection failed.\")",
            "                error_msg = f\"'{product.endpoint}' database connection failed!\"",
            "                LOG.error(error_msg)",
            "                raise ValueError(error_msg)",
            "        else:",
            "            # Send an error to the user.",
            "            db_stat = DBStatus._VALUES_TO_NAMES.get(product.db_status)",
            "            error_msg = f\"'{product.endpoint}' database connection \" \\",
            "                f\"failed. DB status: {str(db_stat)}\"",
            "            LOG.error(error_msg)",
            "            raise ValueError(error_msg)",
            "",
            "        return product",
            "",
            "    # pylint: disable=invalid-name",
            "    def do_POST(self):",
            "        \"\"\"",
            "        Handles POST queries, which are usually Thrift messages.",
            "        \"\"\"",
            "        protocol_factory = TJSONProtocol.TJSONProtocolFactory()",
            "        input_protocol_factory = protocol_factory",
            "        output_protocol_factory = protocol_factory",
            "",
            "        # Get Thrift API function name to print to the log output.",
            "        itrans = TTransport.TFileObjectTransport(self.rfile)",
            "        itrans = TTransport.TBufferedTransport(itrans,",
            "                                               int(self.headers[",
            "                                                   'Content-Length']))",
            "        iprot = input_protocol_factory.getProtocol(itrans)",
            "        fname, _, _ = iprot.readMessageBegin()",
            "",
            "        client_host, client_port, is_ipv6 = \\",
            "            RequestHandler._get_client_host_port(self.client_address)",
            "        self.auth_session = self.__check_session_cookie()",
            "        auth_user = \\",
            "            self.auth_session.user if self.auth_session else \"Anonymous\"",
            "        host_info = client_host if not is_ipv6 else '[' + client_host + ']'",
            "        api_info = f\"{host_info}:{client_port} -- [{auth_user}] POST \" \\",
            "                   f\"{self.path}@{fname}\"",
            "        LOG.info(api_info)",
            "",
            "        # Create new thrift handler.",
            "        version = self.server.version",
            "",
            "        cstringio_buf = itrans.cstringio_buf.getvalue()",
            "        itrans = TTransport.TMemoryBuffer(cstringio_buf)",
            "        iprot = input_protocol_factory.getProtocol(itrans)",
            "",
            "        otrans = TTransport.TMemoryBuffer()",
            "        oprot = output_protocol_factory.getProtocol(otrans)",
            "",
            "        if self.server.manager.is_enabled and \\",
            "                not self.path.endswith(('/Authentication',",
            "                                        '/Configuration',",
            "                                        '/ServerInfo')) and \\",
            "                not self.auth_session:",
            "            # Bail out if the user is not authenticated...",
            "            # This response has the possibility of melting down Thrift clients,",
            "            # but the user is expected to properly authenticate first.",
            "            LOG.debug(\"%s:%s Invalid access, credentials not found \"",
            "                      \"- session refused.\",",
            "                      client_host if not is_ipv6 else '[' + client_host + ']',",
            "                      str(client_port))",
            "",
            "            self.send_thrift_exception(\"Error code 401: Unauthorized!\", iprot,",
            "                                       oprot, otrans)",
            "            return",
            "",
            "        # Authentication is handled, we may now respond to the user.",
            "        try:",
            "            product_endpoint, api_ver, request_endpoint = \\",
            "                routing.split_client_POST_request(self.path)",
            "            if product_endpoint is None and api_ver is None and \\",
            "                    request_endpoint is None:",
            "                raise ValueError(\"Invalid request endpoint path.\")",
            "",
            "            product = None",
            "            if product_endpoint:",
            "                # The current request came through a product route, and not",
            "                # to the main endpoint.",
            "                product = self.__check_prod_db(product_endpoint)",
            "",
            "            version_supported = routing.is_supported_version(api_ver)",
            "            if version_supported:",
            "                major_version, _ = version_supported",
            "",
            "                if major_version == 6:",
            "                    if request_endpoint == 'Authentication':",
            "                        auth_handler = AuthHandler_v6(",
            "                            self.server.manager,",
            "                            self.auth_session,",
            "                            self.server.config_session)",
            "                        processor = AuthAPI_v6.Processor(auth_handler)",
            "                    elif request_endpoint == 'Configuration':",
            "                        conf_handler = ConfigHandler_v6(",
            "                            self.auth_session,",
            "                            self.server.config_session)",
            "                        processor = ConfigAPI_v6.Processor(conf_handler)",
            "                    elif request_endpoint == 'ServerInfo':",
            "                        server_info_handler = ServerInfoHandler_v6(version)",
            "                        processor = ServerInfoAPI_v6.Processor(",
            "                            server_info_handler)",
            "                    elif request_endpoint == 'Products':",
            "                        prod_handler = ProductHandler_v6(",
            "                            self.server,",
            "                            self.auth_session,",
            "                            self.server.config_session,",
            "                            product,",
            "                            version)",
            "                        processor = ProductAPI_v6.Processor(prod_handler)",
            "                    elif request_endpoint == 'CodeCheckerService':",
            "                        # This endpoint is a product's report_server.",
            "                        if not product:",
            "                            error_msg = \\",
            "                                \"Requested CodeCheckerService on a \" \\",
            "                                f\"nonexistent product: '{product_endpoint}'.\"",
            "                            LOG.error(error_msg)",
            "                            raise ValueError(error_msg)",
            "",
            "                        if product_endpoint:",
            "                            # The current request came through a",
            "                            # product route, and not to the main endpoint.",
            "                            product = self.__check_prod_db(product_endpoint)",
            "",
            "                        acc_handler = ReportHandler_v6(",
            "                            self.server.manager,",
            "                            product.session_factory,",
            "                            product,",
            "                            self.auth_session,",
            "                            self.server.config_session,",
            "                            version,",
            "                            api_ver,",
            "                            self.server.context)",
            "                        processor = ReportAPI_v6.Processor(acc_handler)",
            "                    else:",
            "                        LOG.debug(\"This API endpoint does not exist.\")",
            "                        error_msg = f\"No API endpoint named '{self.path}'.\"",
            "                        raise ValueError(error_msg)",
            "                else:",
            "                    raise ValueError(",
            "                        f\"API version {major_version} not supported\")",
            "",
            "            else:",
            "                error_msg = \\",
            "                    \"The API version you are using is not supported \" \\",
            "                    \"by this server (server API version: \" \\",
            "                    f\"{get_version_str()})!\"",
            "                self.send_thrift_exception(error_msg, iprot, oprot, otrans)",
            "                return",
            "",
            "            processor.process(iprot, oprot)",
            "            result = otrans.getvalue()",
            "",
            "            self.send_response(200)",
            "            self.send_header(\"content-type\", \"application/x-thrift\")",
            "            self.send_header(\"Content-Length\", len(result))",
            "            self.end_headers()",
            "            self.wfile.write(result)",
            "            return",
            "",
            "        except BrokenPipeError as ex:",
            "            LOG.warning(\"%s failed with BrokenPipeError: %s\",",
            "                        api_info, str(ex))",
            "            import traceback",
            "            traceback.print_exc()",
            "        except Exception as ex:",
            "            LOG.warning(\"%s failed with Exception: %s\", api_info, str(ex))",
            "            import traceback",
            "            traceback.print_exc()",
            "",
            "            cstringio_buf = itrans.cstringio_buf.getvalue()",
            "            if cstringio_buf:",
            "                itrans = TTransport.TMemoryBuffer(cstringio_buf)",
            "                iprot = input_protocol_factory.getProtocol(itrans)",
            "",
            "            self.send_thrift_exception(str(ex), iprot, oprot, otrans)",
            "",
            "    def list_directory(self, path):",
            "        \"\"\" Disable directory listing. \"\"\"",
            "        self.send_error(405, \"No permission to list directory\")",
            "",
            "    def translate_path(self, path):",
            "        \"\"\"",
            "        Modified version from SimpleHTTPRequestHandler.",
            "        Path is set to www_root.",
            "        \"\"\"",
            "        # Abandon query parameters.",
            "        path = path.split('?', 1)[0]",
            "        path = path.split('#', 1)[0]",
            "        path = posixpath.normpath(urllib.parse.unquote(path))",
            "        words = path.split('/')",
            "        words = [_f for _f in words if _f]",
            "        path = self.server.www_root",
            "        for word in words:",
            "            _, word = os.path.splitdrive(word)",
            "            _, word = os.path.split(word)",
            "            if word in (os.curdir, os.pardir):",
            "                continue",
            "            path = os.path.join(path, word)",
            "        return path",
            "",
            "",
            "class Product:",
            "    \"\"\"",
            "    Represents a product, which is a distinct storage of analysis reports in",
            "    a separate database (and database connection) with its own access control.",
            "    \"\"\"",
            "",
            "    # The amount of SECONDS that need to pass after the last unsuccessful",
            "    # connect() call so the next could be made.",
            "    CONNECT_RETRY_TIMEOUT = 300",
            "",
            "    def __init__(self, id_: int, endpoint: str, display_name: str,",
            "                 connection_string: str, context, check_env):",
            "        \"\"\"",
            "        Set up a new managed product object for the configuration given.",
            "        \"\"\"",
            "        self.__id = id_",
            "        self.__endpoint = endpoint",
            "        self.__display_name = display_name",
            "        self.__connection_string = connection_string",
            "        self.__driver_name = None",
            "        self.__context = context",
            "        self.__check_env = check_env",
            "        self.__engine = None",
            "        self.__session = None",
            "        self.__db_status = DBStatus.MISSING",
            "",
            "        self.__last_connect_attempt = None",
            "",
            "    @property",
            "    def id(self):",
            "        return self.__id",
            "",
            "    @property",
            "    def endpoint(self):",
            "        \"\"\"",
            "        Returns the accessible URL endpoint of the product.",
            "        \"\"\"",
            "        return self.__endpoint",
            "",
            "    @property",
            "    def name(self):",
            "        \"\"\"",
            "        Returns the display name of the product.",
            "        \"\"\"",
            "        return self.__display_name",
            "",
            "    @property",
            "    def session_factory(self):",
            "        \"\"\"",
            "        Returns the session maker on this product's database engine which",
            "        can be used to initiate transactional connections.",
            "        \"\"\"",
            "        return self.__session",
            "",
            "    @property",
            "    def driver_name(self):",
            "        \"\"\"",
            "        Returns the name of the sql driver (sqlite, postgres).",
            "        \"\"\"",
            "        return self.__driver_name",
            "",
            "    @property",
            "    def db_status(self):",
            "        \"\"\"",
            "        Returns the status of the database which belongs to this product.",
            "        Call connect to update it.",
            "        \"\"\"",
            "        return self.__db_status",
            "",
            "    @property",
            "    def last_connection_failure(self):",
            "        \"\"\"",
            "        Returns the reason behind the last executed connection attempt's",
            "        failure.",
            "        \"\"\"",
            "        return self.__last_connect_attempt[1] if self.__last_connect_attempt \\",
            "            else None",
            "",
            "    def connect(self, init_db=False):",
            "        \"\"\"",
            "        Initiates the actual connection to the database configured for the",
            "        product.",
            "",
            "        Each time the connect is called the db_status is updated.",
            "        \"\"\"",
            "        LOG.debug(\"Checking '%s' database.\", self.endpoint)",
            "",
            "        sql_server = database.SQLServer.from_connection_string(",
            "            self.__connection_string,",
            "            self.__endpoint,",
            "            RUN_META,",
            "            self.__context.run_migration_root,",
            "            interactive=False,",
            "            env=self.__check_env)",
            "",
            "        if isinstance(sql_server, database.PostgreSQLServer):",
            "            self.__driver_name = 'postgresql'",
            "        elif isinstance(sql_server, database.SQLiteDatabase):",
            "            self.__driver_name = 'sqlite'",
            "",
            "        try:",
            "            LOG.debug(\"Trying to connect to the database\")",
            "",
            "            # Create the SQLAlchemy engine.",
            "            self.__engine = sql_server.create_engine()",
            "            LOG.debug(self.__engine)",
            "",
            "            self.__session = sessionmaker(bind=self.__engine)",
            "",
            "            self.__engine.execute('SELECT 1')",
            "            self.__db_status = sql_server.check_schema()",
            "            self.__last_connect_attempt = None",
            "",
            "            if self.__db_status == DBStatus.SCHEMA_MISSING and init_db:",
            "                LOG.debug(\"Initializing new database schema.\")",
            "                self.__db_status = sql_server.connect(init_db)",
            "",
            "        except Exception as ex:",
            "            LOG.exception(\"The database for product '%s' cannot be\"",
            "                          \" connected to.\", self.endpoint)",
            "            self.__db_status = DBStatus.FAILED_TO_CONNECT",
            "            self.__last_connect_attempt = (datetime.datetime.now(), str(ex))",
            "",
            "    def get_details(self):",
            "        \"\"\"",
            "        Get details for a product from the database.",
            "",
            "        It may throw different error messages depending on the used SQL driver",
            "        adapter in case of connection error.",
            "        \"\"\"",
            "        with DBSession(self.session_factory) as run_db_session:",
            "            run_locks = run_db_session.query(RunLock.name) \\",
            "                .filter(RunLock.locked_at.isnot(None)) \\",
            "                .all()",
            "",
            "            runs_in_progress = set(run_lock[0] for run_lock in run_locks)",
            "",
            "            num_of_runs = run_db_session.query(Run).count()",
            "",
            "            latest_store_to_product = \"\"",
            "            if num_of_runs:",
            "                last_updated_run = run_db_session.query(Run) \\",
            "                    .order_by(Run.date.desc()) \\",
            "                    .limit(1) \\",
            "                    .one_or_none()",
            "",
            "                latest_store_to_product = last_updated_run.date",
            "",
            "        return num_of_runs, runs_in_progress, latest_store_to_product",
            "",
            "    def teardown(self):",
            "        \"\"\"",
            "        Disposes the database connection to the product's backend.",
            "        \"\"\"",
            "        if self.__db_status == DBStatus.FAILED_TO_CONNECT:",
            "            return",
            "",
            "        self.__engine.dispose()",
            "",
            "        self.__session = None",
            "        self.__engine = None",
            "",
            "    def cleanup_run_db(self):",
            "        \"\"\"",
            "        Cleanup the run database which belongs to this product.",
            "        \"\"\"",
            "        LOG.info(\"[%s] Garbage collection started...\", self.endpoint)",
            "",
            "        db_cleanup.remove_expired_data(self)",
            "        db_cleanup.remove_unused_data(self)",
            "        db_cleanup.update_contextual_data(self, self.__context)",
            "",
            "        LOG.info(\"[%s] Garbage collection finished.\", self.endpoint)",
            "        return True",
            "",
            "",
            "def _do_db_cleanup(context, check_env,",
            "                   id_: int, endpoint: str, display_name: str,",
            "                   connection_str: str) -> Tuple[Optional[bool], str]:",
            "    # This functions is a concurrent job handler!",
            "    try:",
            "        prod = Product(id_, endpoint, display_name, connection_str,",
            "                       context, check_env)",
            "        prod.connect(init_db=False)",
            "        if prod.db_status != DBStatus.OK:",
            "            status_str = database_status.db_status_msg.get(prod.db_status)",
            "            return None, \\",
            "                f\"Cleanup not attempted, database status is \\\"{status_str}\\\"\"",
            "",
            "        prod.cleanup_run_db()",
            "        prod.teardown()",
            "",
            "        # Result is hard-wired to True, because the db_cleanup routines",
            "        # swallow and log the potential errors but do not return them.",
            "        return True, \"\"",
            "    except Exception as e:",
            "        import traceback",
            "        traceback.print_exc()",
            "        return False, str(e)",
            "",
            "",
            "def _do_db_cleanups(config_database, context, check_env) \\",
            "        -> Tuple[bool, List[Tuple[str, str]]]:",
            "    \"\"\"",
            "    Performs on-demand start-up database cleanup on all the products present",
            "    in the ``config_database``.",
            "",
            "    Returns whether database clean-up succeeded for all products, and the",
            "    list of products for which it failed, along with the failure reason.",
            "    \"\"\"",
            "    def _get_products() -> List[Product]:",
            "        products = []",
            "        cfg_engine = config_database.create_engine()",
            "        cfg_session_factory = sessionmaker(bind=cfg_engine)",
            "        with DBSession(cfg_session_factory) as cfg_db:",
            "            for row in cfg_db.query(ORMProduct) \\",
            "                    .order_by(ORMProduct.endpoint.asc()) \\",
            "                    .all():",
            "                products.append((row.id, row.endpoint, row.display_name,",
            "                                 row.connection))",
            "        cfg_engine.dispose()",
            "        return products",
            "",
            "    products = _get_products()",
            "    if not products:",
            "        return True, []",
            "",
            "    thr_count = util.clamp(1, len(products), cpu_count())",
            "    overall_result, failures = True, []",
            "    with Pool(max_workers=thr_count) as executor:",
            "        LOG.info(\"Performing database cleanup using %d concurrent jobs...\",",
            "                 thr_count)",
            "        for product, result in \\",
            "                zip(products, executor.map(",
            "                    partial(_do_db_cleanup, context, check_env),",
            "                    *zip(*products))):",
            "            success, reason = result",
            "            if not success:",
            "                _, endpoint, _, _ = product",
            "                overall_result = False",
            "                failures.append((endpoint, reason))",
            "",
            "    return overall_result, failures",
            "",
            "",
            "class CCSimpleHttpServer(HTTPServer):",
            "    \"\"\"",
            "    Simple http server to handle requests from the clients.",
            "    \"\"\"",
            "",
            "    daemon_threads = False",
            "    address_family = socket.AF_INET  # IPv4",
            "",
            "    def __init__(self,",
            "                 server_address,",
            "                 RequestHandlerClass,",
            "                 config_directory,",
            "                 product_db_sql_server,",
            "                 pckg_data,",
            "                 context,",
            "                 check_env,",
            "                 manager):",
            "",
            "        LOG.debug(\"Initializing HTTP server...\")",
            "",
            "        self.config_directory = config_directory",
            "        self.www_root = pckg_data['www_root']",
            "        self.doc_root = pckg_data['doc_root']",
            "        self.version = pckg_data['version']",
            "        self.context = context",
            "        self.check_env = check_env",
            "        self.manager = manager",
            "        self.__products = {}",
            "",
            "        # Create a database engine for the configuration database.",
            "        LOG.debug(\"Creating database engine for CONFIG DATABASE...\")",
            "        self.__engine = product_db_sql_server.create_engine()",
            "        self.config_session = sessionmaker(bind=self.__engine)",
            "        self.manager.set_database_connection(self.config_session)",
            "",
            "        # Load the initial list of products and set up the server.",
            "        cfg_sess = self.config_session()",
            "        permissions.initialise_defaults('SYSTEM', {",
            "            'config_db_session': cfg_sess",
            "        })",
            "        products = cfg_sess.query(ORMProduct).all()",
            "        for product in products:",
            "            self.add_product(product)",
            "            permissions.initialise_defaults('PRODUCT', {",
            "                'config_db_session': cfg_sess,",
            "                'productID': product.id",
            "            })",
            "        cfg_sess.commit()",
            "        cfg_sess.close()",
            "",
            "        try:",
            "            HTTPServer.__init__(self, server_address,",
            "                                RequestHandlerClass,",
            "                                bind_and_activate=True)",
            "            ssl_key_file = os.path.join(config_directory, \"key.pem\")",
            "            ssl_cert_file = os.path.join(config_directory, \"cert.pem\")",
            "",
            "            self.configure_keepalive()",
            "",
            "            if os.path.isfile(ssl_key_file) and os.path.isfile(ssl_cert_file):",
            "                LOG.info(\"Initiating SSL. Server listening on secure socket.\")",
            "                LOG.debug(\"Using cert file: %s\", ssl_cert_file)",
            "                LOG.debug(\"Using key file: %s\", ssl_key_file)",
            "                ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)",
            "                ssl_context.load_cert_chain(certfile=ssl_cert_file,",
            "                                            keyfile=ssl_key_file)",
            "                # FIXME introduce with python 3.7",
            "                # ssl_context.minimum_version = ssl.TLSVersion.TLSv1_2",
            "",
            "                # TLS1 and TLS1.1 were deprecated in RFC8996",
            "                # https://datatracker.ietf.org/doc/html/rfc8996",
            "                ssl_context.options |= (ssl.OP_NO_TLSv1 | ssl.OP_NO_TLSv1_1)",
            "                self.socket = ssl_context.wrap_socket(self.socket,",
            "                                                      server_side=True)",
            "",
            "            else:",
            "                LOG.info(\"Searching for SSL key at %s, cert at %s, \"",
            "                         \"not found...\", ssl_key_file, ssl_cert_file)",
            "                LOG.info(\"Falling back to simple, insecure HTTP.\")",
            "",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't start the server: %s\", e.__str__())",
            "            raise",
            "",
            "    def configure_keepalive(self):",
            "        \"\"\"",
            "        Enable keepalive on the socket and some TCP keepalive configuration",
            "        option based on the server configuration file.",
            "        \"\"\"",
            "        if not self.manager.is_keepalive_enabled():",
            "            return",
            "",
            "        keepalive_is_on = self.socket.getsockopt(socket.SOL_SOCKET,",
            "                                                 socket.SO_KEEPALIVE)",
            "        if keepalive_is_on != 0:",
            "            LOG.debug('Socket keepalive already on.')",
            "        else:",
            "            LOG.debug('Socket keepalive off, turning on.')",
            "",
            "        ret = self.socket.setsockopt(socket.SOL_SOCKET,",
            "                                     socket.SO_KEEPALIVE, 1)",
            "        if ret:",
            "            LOG.error('Failed to set socket keepalive: %s', ret)",
            "",
            "        idle = self.manager.get_keepalive_idle()",
            "        if idle:",
            "            ret = self.socket.setsockopt(socket.IPPROTO_TCP,",
            "                                         socket.TCP_KEEPIDLE, idle)",
            "            if ret:",
            "                LOG.error('Failed to set TCP keepalive idle: %s', ret)",
            "",
            "        interval = self.manager.get_keepalive_interval()",
            "        if interval:",
            "            ret = self.socket.setsockopt(socket.IPPROTO_TCP,",
            "                                         socket.TCP_KEEPINTVL, interval)",
            "            if ret:",
            "                LOG.error('Failed to set TCP keepalive interval: %s', ret)",
            "",
            "        max_probe = self.manager.get_keepalive_max_probe()",
            "        if max_probe:",
            "            ret = self.socket.setsockopt(socket.IPPROTO_TCP,",
            "                                         socket.TCP_KEEPCNT, max_probe)",
            "            if ret:",
            "                LOG.error('Failed to set TCP max keepalive probe: %s', ret)",
            "",
            "    def terminate(self):",
            "        \"\"\"",
            "        Terminating the server.",
            "        \"\"\"",
            "        try:",
            "            self.server_close()",
            "            self.__engine.dispose()",
            "        except Exception as ex:",
            "            LOG.error(\"Failed to shut down the WEB server!\")",
            "            LOG.error(str(ex))",
            "            sys.exit(1)",
            "",
            "    def add_product(self, orm_product, init_db=False):",
            "        \"\"\"",
            "        Adds a product to the list of product databases connected to",
            "        by the server.",
            "        Checks the database connection for the product databases.",
            "        \"\"\"",
            "        if orm_product.endpoint in self.__products:",
            "            LOG.debug(\"This product is already configured!\")",
            "            return",
            "",
            "        LOG.debug(\"Setting up product '%s'\", orm_product.endpoint)",
            "",
            "        prod = Product(orm_product.id,",
            "                       orm_product.endpoint,",
            "                       orm_product.display_name,",
            "                       orm_product.connection,",
            "                       self.context,",
            "                       self.check_env)",
            "",
            "        # Update the product database status.",
            "        prod.connect()",
            "        if prod.db_status == DBStatus.SCHEMA_MISSING and init_db:",
            "            LOG.debug(\"Schema was missing in the database. Initializing new\")",
            "            prod.connect(init_db=True)",
            "",
            "        # The \"num_of_runs\" column of the config database is shown on the",
            "        # product page of the web interface. This is intentionally redundant",
            "        # with a simple query that would count the number of runs in a product:",
            "        # measurements have proven that this caching significantly improves",
            "        # responsibility.",
            "        # This field is incremented whenever a run is added to a product, and",
            "        # decreased when run(s) are removed. However, if these numbers ever",
            "        # diverge, the product page and the bottom right of the run page would",
            "        # display different run counts. To help on this, the num_of_runs column",
            "        # is updated at every server startup.",
            "        # FIXME: Pylint emits a false positive here, and states that",
            "        # session_factory() is not callable, because it initializes to None.",
            "        # More on this:",
            "        # https://github.com/Ericsson/codechecker/pull/3733#issuecomment-1235304179",
            "        # https://github.com/PyCQA/pylint/issues/6005",
            "        orm_product.num_of_runs = \\",
            "            prod.session_factory().query(func.count(Run.id)).one_or_none()[0] \\",
            "            # pylint: disable=not-callable",
            "",
            "        self.__products[prod.endpoint] = prod",
            "",
            "    @property",
            "    def num_products(self):",
            "        \"\"\"",
            "        Returns the number of products currently mounted by the server.",
            "        \"\"\"",
            "        return len(self.__products)",
            "",
            "    def get_product(self, endpoint):",
            "        \"\"\"",
            "        Get the product connection object for the given endpoint, or None.",
            "        \"\"\"",
            "        if endpoint in self.__products:",
            "            return self.__products.get(endpoint)",
            "",
            "        LOG.debug(\"Product with the given endpoint '%s' does not exist in \"",
            "                  \"the local cache. Try to get it from the database.\",",
            "                  endpoint)",
            "",
            "        # If the product doesn't find in the cache, try to get it from the",
            "        # database.",
            "        try:",
            "            cfg_sess = self.config_session()",
            "            product = cfg_sess.query(ORMProduct) \\",
            "                .filter(ORMProduct.endpoint == endpoint) \\",
            "                .limit(1).one_or_none()",
            "",
            "            if not product:",
            "                return None",
            "",
            "            self.add_product(product)",
            "            permissions.initialise_defaults('PRODUCT', {",
            "                'config_db_session': cfg_sess,",
            "                'productID': product.id",
            "            })",
            "",
            "            return self.__products.get(endpoint, None)",
            "        finally:",
            "            if cfg_sess:",
            "                cfg_sess.close()",
            "                cfg_sess.commit()",
            "",
            "    def get_only_product(self):",
            "        \"\"\"",
            "        Returns the Product object for the only product connected to by the",
            "        server, or None, if there are 0 or >= 2 products managed.",
            "        \"\"\"",
            "        return list(self.__products.items())[0][1] if self.num_products == 1 \\",
            "            else None",
            "",
            "    def remove_product(self, endpoint):",
            "        product = self.get_product(endpoint)",
            "        if not product:",
            "            raise ValueError(",
            "                f\"The product with the given endpoint '{endpoint}' does \"",
            "                \"not exist!\")",
            "",
            "        LOG.info(\"Disconnecting product '%s'\", endpoint)",
            "        product.teardown()",
            "",
            "        del self.__products[endpoint]",
            "",
            "    def remove_products_except(self, endpoints_to_keep):",
            "        \"\"\"",
            "        Removes EVERY product connection from the server except those",
            "        endpoints specified in :endpoints_to_keep.",
            "        \"\"\"",
            "        for ep in list(self.__products):",
            "            if ep not in endpoints_to_keep:",
            "                self.remove_product(ep)",
            "",
            "",
            "class CCSimpleHttpServerIPv6(CCSimpleHttpServer):",
            "    \"\"\"",
            "    CodeChecker HTTP simple server that listens over an IPv6 socket.",
            "    \"\"\"",
            "",
            "    address_family = socket.AF_INET6",
            "",
            "",
            "def start_server(config_directory, package_data, port, config_sql_server,",
            "                 listen_address, force_auth, skip_db_cleanup: bool,",
            "                 context, check_env):",
            "    \"\"\"",
            "    Start http server to handle web client and thrift requests.",
            "    \"\"\"",
            "    LOG.debug(\"Starting CodeChecker server...\")",
            "",
            "    server_addr = (listen_address, port)",
            "",
            "    # The root user file is DEPRECATED AND IGNORED",
            "    root_file = os.path.join(config_directory, 'root.user')",
            "    if os.path.exists(root_file):",
            "        LOG.warning(\"The 'root.user' file:  %s\"",
            "                    \" is deprecated and ignored. If you want to\"",
            "                    \" setup an initial user with SUPER_USER permission,\"",
            "                    \" configure the super_user field in the server_config.json\"",
            "                    \" as described in the documentation.\"",
            "                    \" To get rid off this warning,\"",
            "                    \" simply delete the root.user file.\",",
            "                    root_file)",
            "    # Check whether configuration file exists, create an example if not.",
            "    server_cfg_file = os.path.join(config_directory, 'server_config.json')",
            "    if not os.path.exists(server_cfg_file):",
            "        # For backward compatibility reason if the session_config.json file",
            "        # exists we rename it to server_config.json.",
            "        session_cfg_file = os.path.join(config_directory,",
            "                                        'session_config.json')",
            "        example_cfg_file = os.path.join(os.environ['CC_DATA_FILES_DIR'],",
            "                                        'config', 'server_config.json')",
            "        if os.path.exists(session_cfg_file):",
            "            LOG.info(\"Renaming '%s' to '%s'. Please check the example \"",
            "                     \"configuration file ('%s') or the user guide for more \"",
            "                     \"information.\", session_cfg_file,",
            "                     server_cfg_file, example_cfg_file)",
            "            os.rename(session_cfg_file, server_cfg_file)",
            "        else:",
            "            LOG.info(\"CodeChecker server's example configuration file \"",
            "                     \"created at '%s'\", server_cfg_file)",
            "            shutil.copyfile(example_cfg_file, server_cfg_file)",
            "",
            "    try:",
            "        manager = session_manager.SessionManager(",
            "            server_cfg_file,",
            "            force_auth)",
            "    except IOError as ioerr:",
            "        LOG.debug(ioerr)",
            "        LOG.error(\"The server's configuration file \"",
            "                  \"is missing or can not be read!\")",
            "        sys.exit(1)",
            "    except ValueError as verr:",
            "        LOG.debug(verr)",
            "        LOG.error(\"The server's configuration file is invalid!\")",
            "        sys.exit(1)",
            "",
            "    if not skip_db_cleanup:",
            "        all_success, fails = _do_db_cleanups(config_sql_server,",
            "                                             context,",
            "                                             check_env)",
            "        if not all_success:",
            "            LOG.error(\"Failed to perform automatic cleanup on %d products! \"",
            "                      \"Earlier logs might contain additional detailed \"",
            "                      \"reasoning.\\n\\t* %s\", len(fails),",
            "                      \"\\n\\t* \".join(",
            "                          (f\"'{ep}' ({reason})\" for (ep, reason) in fails)",
            "                      ))",
            "    else:",
            "        LOG.debug(\"Skipping db_cleanup, as requested.\")",
            "",
            "    server_clazz = CCSimpleHttpServer",
            "    if ':' in server_addr[0]:",
            "        # IPv6 address specified for listening.",
            "        # FIXME: Python>=3.8 automatically handles IPv6 if ':' is in the bind",
            "        # address, see https://bugs.python.org/issue24209.",
            "        server_clazz = CCSimpleHttpServerIPv6",
            "",
            "    http_server = server_clazz(server_addr,",
            "                               RequestHandler,",
            "                               config_directory,",
            "                               config_sql_server,",
            "                               package_data,",
            "                               context,",
            "                               check_env,",
            "                               manager)",
            "",
            "    # If the server was started with the port 0, the OS will pick an available",
            "    # port. For this reason we will update the port variable after server",
            "    # initialization.",
            "    port = http_server.socket.getsockname()[1]",
            "",
            "    processes = []",
            "",
            "    def signal_handler(signum, _):",
            "        \"\"\"",
            "        Handle SIGTERM to stop the server running.",
            "        \"\"\"",
            "        LOG.info(\"Shutting down the WEB server on [%s:%d]\",",
            "                 '[' + listen_address + ']'",
            "                 if server_clazz is CCSimpleHttpServerIPv6 else listen_address,",
            "                 port)",
            "        http_server.terminate()",
            "",
            "        # Terminate child processes.",
            "        for pp in processes:",
            "            pp.terminate()",
            "",
            "        sys.exit(128 + signum)",
            "",
            "    def reload_signal_handler(*_args, **_kwargs):",
            "        \"\"\"",
            "        Reloads server configuration file.",
            "        \"\"\"",
            "        manager.reload_config()",
            "",
            "    try:",
            "        instance_manager.register(os.getpid(),",
            "                                  os.path.abspath(",
            "                                      context.codechecker_workspace),",
            "                                  port)",
            "    except IOError as ex:",
            "        LOG.debug(ex.strerror)",
            "",
            "    LOG.info(\"Server waiting for client requests on [%s:%d]\",",
            "             '[' + listen_address + ']'",
            "             if server_clazz is CCSimpleHttpServerIPv6 else listen_address,",
            "             port)",
            "",
            "    def unregister_handler(pid):",
            "        \"\"\"",
            "        Handle errors during instance unregistration.",
            "        The workspace might be removed so updating the",
            "        config content might fail.",
            "        \"\"\"",
            "        try:",
            "            instance_manager.unregister(pid)",
            "        except IOError as ex:",
            "            LOG.debug(ex.strerror)",
            "",
            "    atexit.register(unregister_handler, os.getpid())",
            "",
            "    for _ in range(manager.worker_processes - 1):",
            "        p = multiprocess.Process(target=http_server.serve_forever)",
            "        processes.append(p)",
            "        p.start()",
            "",
            "    signal.signal(signal.SIGINT, signal_handler)",
            "    signal.signal(signal.SIGTERM, signal_handler)",
            "",
            "    if sys.platform != \"win32\":",
            "        signal.signal(signal.SIGHUP, reload_signal_handler)",
            "",
            "    # Main process also acts as a worker.",
            "    http_server.serve_forever()",
            "",
            "    LOG.info(\"Webserver quit.\")",
            "",
            "",
            "def add_initial_run_database(config_sql_server, product_connection):",
            "    \"\"\"",
            "    Create a default run database as SQLite in the config directory,",
            "    and add it to the list of products in the config database specified by",
            "    db_conn_string.",
            "    \"\"\"",
            "",
            "    # Connect to the configuration database",
            "    LOG.debug(\"Creating database engine for CONFIG DATABASE...\")",
            "    __engine = config_sql_server.create_engine()",
            "    product_session = sessionmaker(bind=__engine)",
            "",
            "    # Load the initial list of products and create the connections.",
            "    sess = product_session()",
            "    products = sess.query(ORMProduct).all()",
            "    if products:",
            "        raise ValueError(\"Called create_initial_run_database on non-empty \"",
            "                         \"config database -- you shouldn't have done this!\")",
            "",
            "    LOG.debug(\"Adding default product to the config db...\")",
            "    product = ORMProduct('Default', product_connection, 'Default',",
            "                         \"Default product created at server start.\")",
            "    sess.add(product)",
            "    sess.commit()",
            "    sess.close()",
            "",
            "    LOG.debug(\"Default product set up.\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "17": [],
            "21": [],
            "27": [],
            "71": [],
            "72": [],
            "994": [
                "__make_root_file"
            ],
            "995": [
                "__make_root_file"
            ],
            "996": [
                "__make_root_file"
            ],
            "997": [
                "__make_root_file"
            ],
            "998": [
                "__make_root_file"
            ],
            "999": [
                "__make_root_file"
            ],
            "1000": [
                "__make_root_file"
            ],
            "1001": [
                "__make_root_file"
            ],
            "1002": [
                "__make_root_file"
            ],
            "1003": [
                "__make_root_file"
            ],
            "1004": [
                "__make_root_file"
            ],
            "1005": [
                "__make_root_file"
            ],
            "1006": [
                "__make_root_file"
            ],
            "1007": [
                "__make_root_file"
            ],
            "1008": [
                "__make_root_file"
            ],
            "1009": [
                "__make_root_file"
            ],
            "1010": [
                "__make_root_file"
            ],
            "1011": [
                "__make_root_file"
            ],
            "1012": [
                "__make_root_file"
            ],
            "1013": [
                "__make_root_file"
            ],
            "1014": [
                "__make_root_file"
            ],
            "1015": [
                "__make_root_file"
            ],
            "1016": [
                "__make_root_file"
            ],
            "1017": [
                "__make_root_file"
            ],
            "1018": [
                "__make_root_file"
            ],
            "1019": [
                "__make_root_file"
            ],
            "1020": [
                "__make_root_file"
            ],
            "1021": [
                "__make_root_file"
            ],
            "1022": [
                "__make_root_file"
            ],
            "1023": [
                "__make_root_file"
            ],
            "1024": [
                "__make_root_file"
            ],
            "1025": [
                "__make_root_file"
            ],
            "1026": [
                "__make_root_file"
            ],
            "1027": [
                "__make_root_file"
            ],
            "1028": [
                "__make_root_file"
            ],
            "1029": [],
            "1030": [],
            "1042": [
                "start_server"
            ],
            "1043": [
                "start_server"
            ],
            "1044": [
                "start_server"
            ],
            "1045": [
                "start_server"
            ],
            "1046": [
                "start_server"
            ],
            "1047": [
                "start_server"
            ],
            "1048": [
                "start_server"
            ],
            "1049": [
                "start_server"
            ],
            "1050": [
                "start_server"
            ],
            "1051": [
                "start_server"
            ],
            "1052": [
                "start_server"
            ],
            "1053": [
                "start_server"
            ],
            "1054": [
                "start_server"
            ],
            "1055": [
                "start_server"
            ],
            "1056": [
                "start_server"
            ],
            "1080": [
                "start_server"
            ],
            "1101": [
                "start_server"
            ]
        },
        "addLocation": []
    },
    "web/server/codechecker_server/session_manager.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " Handles the management of authentication sessions on the server's side."
            },
            "1": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " \"\"\""
            },
            "2": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-import hashlib"
            },
            "4": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " import json"
            },
            "5": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import os"
            },
            "6": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " import re"
            },
            "7": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 160,
                "PatchRowcode": "     CodeChecker server."
            },
            "8": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 161,
                "PatchRowcode": "     \"\"\""
            },
            "9": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 162,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def __init__(self, configuration_file, root_sha, force_auth=False):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 163,
                "PatchRowcode": "+    def __init__(self, configuration_file, force_auth=False):"
            },
            "12": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "         \"\"\""
            },
            "13": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "         Initialise a new Session Manager on the server."
            },
            "14": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 166,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "         :param configuration_file: The configuration file to read"
            },
            "16": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "             authentication backends from."
            },
            "17": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        :param root_sha: The SHA-256 hash of the root user's authentication."
            },
            "18": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 169,
                "PatchRowcode": "         :param force_auth: If True, the manager will be enabled even if the"
            },
            "19": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "             configuration file disables authentication."
            },
            "20": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "         \"\"\""
            },
            "21": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "         self.__refresh_time = self.__auth_config['refresh_time'] \\"
            },
            "22": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "             if 'refresh_time' in self.__auth_config else None"
            },
            "23": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 199,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Save the root SHA into the configuration (but only in memory!)"
            },
            "25": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self.__auth_config['method_root'] = root_sha"
            },
            "26": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "27": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 200,
                "PatchRowcode": "         self.__regex_groups_enabled = False"
            },
            "28": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 201,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 202,
                "PatchRowcode": "         # Pre-compile the regular expressions of 'regex_groups'"
            },
            "30": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 329,
                "PatchRowcode": "             \"error\": self.__auth_config.get('realm_error')"
            },
            "31": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 330,
                "PatchRowcode": "         }"
            },
            "32": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": 331,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 332,
                "PatchRowcode": "+    @property"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 333,
                "PatchRowcode": "+    def get_super_user(self):"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 334,
                "PatchRowcode": "+        return {"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 335,
                "PatchRowcode": "+            \"super_user\": self.__auth_config.get('super_user'),"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 336,
                "PatchRowcode": "+        }"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 337,
                "PatchRowcode": "+"
            },
            "39": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 338,
                "PatchRowcode": "     @property"
            },
            "40": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 339,
                "PatchRowcode": "     def default_superuser_name(self) -> Optional[str]:"
            },
            "41": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 340,
                "PatchRowcode": "         \"\"\" Get default superuser name. \"\"\""
            },
            "42": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        root = self.__auth_config['method_root'].split(\":\")"
            },
            "43": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "44": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Previously the root file doesn't contain the user name. In this case"
            },
            "45": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # we will return with no user name."
            },
            "46": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if len(root) <= 1:"
            },
            "47": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return None"
            },
            "48": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "49": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return root[0]"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+        return self.__auth_config['super_user']"
            },
            "51": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 342,
                "PatchRowcode": " "
            },
            "52": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 343,
                "PatchRowcode": "     def set_database_connection(self, connection):"
            },
            "53": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": 344,
                "PatchRowcode": "         \"\"\""
            },
            "54": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 359,
                "PatchRowcode": " "
            },
            "55": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": 360,
                "PatchRowcode": "         This validation object contains two keys: username and groups."
            },
            "56": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 361,
                "PatchRowcode": "         \"\"\""
            },
            "57": {
                "beforePatchRowNumber": 368,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        validation = self.__try_auth_root(auth_string) \\"
            },
            "58": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            or self.__try_auth_dictionary(auth_string) \\"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 362,
                "PatchRowcode": "+        validation = self.__try_auth_dictionary(auth_string) \\"
            },
            "60": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": 363,
                "PatchRowcode": "             or self.__try_auth_pam(auth_string) \\"
            },
            "61": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": 364,
                "PatchRowcode": "             or self.__try_auth_ldap(auth_string)"
            },
            "62": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": 365,
                "PatchRowcode": "         if not validation:"
            },
            "63": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": 380,
                "PatchRowcode": "             'method_' + method in self.__auth_config and \\"
            },
            "64": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 381,
                "PatchRowcode": "             self.__auth_config['method_' + method].get('enabled')"
            },
            "65": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 382,
                "PatchRowcode": " "
            },
            "66": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def __try_auth_root(self, auth_string):"
            },
            "67": {
                "beforePatchRowNumber": 391,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        \"\"\""
            },
            "68": {
                "beforePatchRowNumber": 392,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        Try to authenticate the user against the root username:password's hash."
            },
            "69": {
                "beforePatchRowNumber": 393,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        \"\"\""
            },
            "70": {
                "beforePatchRowNumber": 394,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        user_name = SessionManager.get_user_name(auth_string)"
            },
            "71": {
                "beforePatchRowNumber": 395,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        sha = hashlib.sha256(auth_string.encode('utf8')).hexdigest()"
            },
            "72": {
                "beforePatchRowNumber": 396,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "73": {
                "beforePatchRowNumber": 397,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if f\"{user_name}:{sha}\" == self.__auth_config['method_root']:"
            },
            "74": {
                "beforePatchRowNumber": 398,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return {"
            },
            "75": {
                "beforePatchRowNumber": 399,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'username': SessionManager.get_user_name(auth_string),"
            },
            "76": {
                "beforePatchRowNumber": 400,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'groups': [],"
            },
            "77": {
                "beforePatchRowNumber": 401,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'root': True"
            },
            "78": {
                "beforePatchRowNumber": 402,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            }"
            },
            "79": {
                "beforePatchRowNumber": 403,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "80": {
                "beforePatchRowNumber": 404,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return False"
            },
            "81": {
                "beforePatchRowNumber": 405,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "82": {
                "beforePatchRowNumber": 406,
                "afterPatchRowNumber": 383,
                "PatchRowcode": "     def __try_auth_token(self, auth_string):"
            },
            "83": {
                "beforePatchRowNumber": 407,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "         if not self.__database_connection:"
            },
            "84": {
                "beforePatchRowNumber": 408,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "             return None"
            },
            "85": {
                "beforePatchRowNumber": 562,
                "afterPatchRowNumber": 539,
                "PatchRowcode": " "
            },
            "86": {
                "beforePatchRowNumber": 563,
                "afterPatchRowNumber": 540,
                "PatchRowcode": "     def __is_root_user(self, user_name):"
            },
            "87": {
                "beforePatchRowNumber": 564,
                "afterPatchRowNumber": 541,
                "PatchRowcode": "         \"\"\" Return True if the given user has system permissions. \"\"\""
            },
            "88": {
                "beforePatchRowNumber": 565,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if self.__auth_config['method_root'].split(\":\")[0] == user_name:"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 542,
                "PatchRowcode": "+        if self.__auth_config['super_user'] == user_name:"
            },
            "90": {
                "beforePatchRowNumber": 566,
                "afterPatchRowNumber": 543,
                "PatchRowcode": "             return True"
            },
            "91": {
                "beforePatchRowNumber": 567,
                "afterPatchRowNumber": 544,
                "PatchRowcode": " "
            },
            "92": {
                "beforePatchRowNumber": 568,
                "afterPatchRowNumber": 545,
                "PatchRowcode": "         transaction = None"
            }
        },
        "frontPatchFile": [
            "# -------------------------------------------------------------------------",
            "#",
            "#  Part of the CodeChecker project, under the Apache License v2.0 with",
            "#  LLVM Exceptions. See LICENSE for license information.",
            "#  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception",
            "#",
            "# -------------------------------------------------------------------------",
            "\"\"\"",
            "Handles the management of authentication sessions on the server's side.",
            "\"\"\"",
            "",
            "import hashlib",
            "import json",
            "import os",
            "import re",
            "import uuid",
            "",
            "from datetime import datetime",
            "from typing import Optional",
            "",
            "from codechecker_common.compatibility.multiprocessing import cpu_count",
            "from codechecker_common.logger import get_logger",
            "from codechecker_common.util import load_json",
            "",
            "from codechecker_web.shared.env import check_file_owner_rw",
            "from codechecker_web.shared.version import SESSION_COOKIE_NAME as _SCN",
            "",
            "from .database.config_db_model import Session as SessionRecord",
            "from .database.config_db_model import SystemPermission",
            "from .permissions import SUPERUSER",
            "",
            "",
            "UNSUPPORTED_METHODS = []",
            "",
            "try:",
            "    from .auth import cc_ldap",
            "except ImportError:",
            "    UNSUPPORTED_METHODS.append('ldap')",
            "",
            "try:",
            "    from .auth import cc_pam",
            "except ImportError:",
            "    UNSUPPORTED_METHODS.append('pam')",
            "",
            "",
            "LOG = get_logger(\"server\")",
            "SESSION_COOKIE_NAME = _SCN",
            "",
            "",
            "def generate_session_token():",
            "    \"\"\"",
            "    Returns a random session token.",
            "    \"\"\"",
            "    return uuid.UUID(bytes=os.urandom(16)).hex",
            "",
            "",
            "def get_worker_processes(scfg_dict):",
            "    \"\"\"",
            "    Return number of worker processes from the config dictionary.",
            "",
            "    Return 'worker_processes' field from the config dictionary or returns the",
            "    default value if this field is not set or the value is negative.",
            "    \"\"\"",
            "    default = cpu_count()",
            "    worker_processes = scfg_dict.get('worker_processes', default)",
            "",
            "    if worker_processes < 0:",
            "        LOG.warning(\"Number of worker processes can not be negative! Default \"",
            "                    \"value will be used: %s\", default)",
            "        worker_processes = default",
            "",
            "    return worker_processes",
            "",
            "",
            "class _Session:",
            "    \"\"\"A session for an authenticated, privileged client connection.\"\"\"",
            "",
            "    def __init__(self, token, username, groups,",
            "                 session_lifetime, refresh_time, is_root=False, database=None,",
            "                 last_access=None, can_expire=True):",
            "",
            "        self.token = token",
            "        self.user = username",
            "        self.groups = groups",
            "",
            "        self.session_lifetime = session_lifetime",
            "        self.refresh_time = refresh_time if refresh_time else None",
            "        self.__root = is_root",
            "        self.__database = database",
            "        self.__can_expire = can_expire",
            "        self.last_access = last_access if last_access else datetime.now()",
            "",
            "    @property",
            "    def is_root(self):",
            "        \"\"\"Returns whether or not the Session was created with the master",
            "        superuser (root) credentials.\"\"\"",
            "        return self.__root",
            "",
            "    @property",
            "    def is_refresh_time_expire(self):",
            "        \"\"\"",
            "        Returns if the refresh time of the session is expired.",
            "        \"\"\"",
            "        if not self.refresh_time:",
            "            return True",
            "",
            "        return (datetime.now() - self.last_access).total_seconds() > \\",
            "            self.refresh_time",
            "",
            "    @property",
            "    def is_alive(self):",
            "        \"\"\"",
            "        Returns if the session is alive and usable, that is, within its",
            "        lifetime.",
            "        \"\"\"",
            "        if not self.__can_expire:",
            "            return True",
            "",
            "        return (datetime.now() - self.last_access).total_seconds() <= \\",
            "            self.session_lifetime",
            "",
            "    def revalidate(self):",
            "        \"\"\"",
            "        A session is only revalidated if it has yet to exceed its",
            "        lifetime. After a session hasn't been used for this interval,",
            "        it can NOT be resurrected at all --- the user needs to log in",
            "        to a brand-new session.",
            "        \"\"\"",
            "",
            "        if not self.is_alive:",
            "            return",
            "",
            "        if self.__database and self.is_refresh_time_expire:",
            "            self.last_access = datetime.now()",
            "",
            "            # Update the timestamp in the database for the session's last",
            "            # access.",
            "            transaction = None",
            "            try:",
            "                transaction = self.__database()",
            "                record = transaction.query(SessionRecord) \\",
            "                    .filter(SessionRecord.user_name == self.user) \\",
            "                    .filter(SessionRecord.token == self.token) \\",
            "                    .limit(1).one_or_none()",
            "",
            "                if record:",
            "                    record.last_access = self.last_access",
            "                    transaction.commit()",
            "            except Exception as e:",
            "                LOG.warning(\"Couldn't update usage timestamp of %s\",",
            "                            self.token)",
            "                LOG.warning(str(e))",
            "            finally:",
            "                if transaction:",
            "                    transaction.close()",
            "",
            "",
            "class SessionManager:",
            "    \"\"\"",
            "    Provides the functionality required to handle user authentication on a",
            "    CodeChecker server.",
            "    \"\"\"",
            "",
            "    def __init__(self, configuration_file, root_sha, force_auth=False):",
            "        \"\"\"",
            "        Initialise a new Session Manager on the server.",
            "",
            "        :param configuration_file: The configuration file to read",
            "            authentication backends from.",
            "        :param root_sha: The SHA-256 hash of the root user's authentication.",
            "        :param force_auth: If True, the manager will be enabled even if the",
            "            configuration file disables authentication.",
            "        \"\"\"",
            "        self.__database_connection = None",
            "        self.__logins_since_prune = 0",
            "        self.__sessions = []",
            "        self.__configuration_file = configuration_file",
            "",
            "        scfg_dict = self.__get_config_dict()",
            "",
            "        # FIXME: Refactor this. This is irrelevant to authentication config,",
            "        # so it should NOT be handled by session_manager. A separate config",
            "        # handler for the server's stuff should be created, that can properly",
            "        # instantiate SessionManager with the found configuration.",
            "        self.__worker_processes = get_worker_processes(scfg_dict)",
            "        self.__max_run_count = scfg_dict.get('max_run_count', None)",
            "        self.__store_config = scfg_dict.get('store', {})",
            "        self.__keepalive_config = scfg_dict.get('keepalive', {})",
            "        self.__auth_config = scfg_dict['authentication']",
            "",
            "        if force_auth:",
            "            LOG.debug(\"Authentication was force-enabled.\")",
            "            self.__auth_config['enabled'] = True",
            "",
            "        if 'soft_expire' in self.__auth_config:",
            "            LOG.debug(\"Found deprecated argument 'soft_expire' in \"",
            "                      \"server_config.authentication.\")",
            "",
            "        self.__refresh_time = self.__auth_config['refresh_time'] \\",
            "            if 'refresh_time' in self.__auth_config else None",
            "",
            "        # Save the root SHA into the configuration (but only in memory!)",
            "        self.__auth_config['method_root'] = root_sha",
            "",
            "        self.__regex_groups_enabled = False",
            "",
            "        # Pre-compile the regular expressions of 'regex_groups'",
            "        if 'regex_groups' in self.__auth_config:",
            "            self.__regex_groups_enabled = self.__auth_config['regex_groups'] \\",
            "                                              .get('enabled', False)",
            "",
            "            regex_groups = self.__auth_config['regex_groups'] \\",
            "                               .get('groups', [])",
            "            d = {}",
            "            for group_name, regex_list in regex_groups.items():",
            "                d[group_name] = [re.compile(r) for r in regex_list]",
            "            self.__group_regexes_compiled = d",
            "",
            "        # If no methods are configured as enabled, disable authentication.",
            "        if scfg_dict['authentication'].get('enabled'):",
            "            found_auth_method = False",
            "",
            "            if 'method_dictionary' in self.__auth_config and \\",
            "                    self.__auth_config['method_dictionary'].get('enabled'):",
            "                found_auth_method = True",
            "",
            "            if 'method_ldap' in self.__auth_config and \\",
            "                    self.__auth_config['method_ldap'].get('enabled'):",
            "                if 'ldap' not in UNSUPPORTED_METHODS:",
            "                    found_auth_method = True",
            "                else:",
            "                    LOG.warning(\"LDAP authentication was enabled but \"",
            "                                \"prerequisites are NOT installed on the system\"",
            "                                \"... Disabling LDAP authentication.\")",
            "                    self.__auth_config['method_ldap']['enabled'] = False",
            "",
            "            if 'method_pam' in self.__auth_config and \\",
            "                    self.__auth_config['method_pam'].get('enabled'):",
            "                if 'pam' not in UNSUPPORTED_METHODS:",
            "                    found_auth_method = True",
            "                else:",
            "                    LOG.warning(\"PAM authentication was enabled but \"",
            "                                \"prerequisites are NOT installed on the system\"",
            "                                \"... Disabling PAM authentication.\")",
            "                    self.__auth_config['method_pam']['enabled'] = False",
            "",
            "            if not found_auth_method:",
            "                if force_auth:",
            "                    LOG.warning(\"Authentication was manually enabled, but no \"",
            "                                \"valid authentication backends are \"",
            "                                \"configured... The server will only allow \"",
            "                                \"the master superuser (root) access.\")",
            "                else:",
            "                    LOG.warning(\"Authentication is enabled but no valid \"",
            "                                \"authentication backends are configured... \"",
            "                                \"Falling back to no authentication.\")",
            "                    self.__auth_config['enabled'] = False",
            "",
            "    def __get_config_dict(self):",
            "        \"\"\"",
            "        Get server config information from the configuration file. Raise",
            "        ValueError if the configuration file is invalid.",
            "        \"\"\"",
            "        LOG.debug(self.__configuration_file)",
            "        cfg_dict = load_json(self.__configuration_file, {})",
            "        if cfg_dict != {}:",
            "            check_file_owner_rw(self.__configuration_file)",
            "        else:",
            "            # If the configuration dict is empty, it means a JSON couldn't",
            "            # have been parsed from it.",
            "            raise ValueError(\"Server configuration file was invalid, or \"",
            "                             \"empty.\")",
            "        return cfg_dict",
            "",
            "    def reload_config(self):",
            "        LOG.info(\"Reload server configuration file...\")",
            "        try:",
            "            cfg_dict = self.__get_config_dict()",
            "",
            "            prev_max_run_count = self.__max_run_count",
            "            new_max_run_count = cfg_dict.get('max_run_count', None)",
            "            if prev_max_run_count != new_max_run_count:",
            "                self.__max_run_count = new_max_run_count",
            "                LOG.debug(\"Changed 'max_run_count' value from %s to %s\",",
            "                          prev_max_run_count, new_max_run_count)",
            "",
            "            prev_store_config = json.dumps(self.__store_config, sort_keys=True,",
            "                                           indent=2)",
            "            new_store_config_val = cfg_dict.get('store', {})",
            "            new_store_config = json.dumps(new_store_config_val, sort_keys=True,",
            "                                          indent=2)",
            "            if prev_store_config != new_store_config:",
            "                self.__store_config = new_store_config_val",
            "                LOG.debug(\"Updating 'store' config from %s to %s\",",
            "                          prev_store_config, new_store_config)",
            "",
            "            update_sessions = False",
            "            auth_fields_to_update = ['session_lifetime', 'refresh_time',",
            "                                     'logins_until_cleanup']",
            "            for field in auth_fields_to_update:",
            "                if field in self.__auth_config:",
            "                    prev_value = self.__auth_config[field]",
            "                    new_value = cfg_dict['authentication'].get(field, 0)",
            "                    if prev_value != new_value:",
            "                        self.__auth_config[field] = new_value",
            "                        LOG.debug(\"Changed '%s' value from %s to %s\",",
            "                                  field, prev_value, new_value)",
            "                        update_sessions = True",
            "",
            "            if update_sessions:",
            "                # Update configuration options of the already existing",
            "                # sessions.",
            "                for session in self.__sessions:",
            "                    session.session_lifetime = \\",
            "                        self.__auth_config['session_lifetime']",
            "                    session.refresh_time = self.__auth_config['refresh_time']",
            "",
            "            LOG.info(\"Done.\")",
            "        except ValueError as ex:",
            "            LOG.error(\"Couldn't reload server configuration file\")",
            "            LOG.error(str(ex))",
            "",
            "    @property",
            "    def is_enabled(self):",
            "        return self.__auth_config.get('enabled')",
            "",
            "    @property",
            "    def worker_processes(self):",
            "        return self.__worker_processes",
            "",
            "    def get_realm(self):",
            "        return {",
            "            \"realm\": self.__auth_config.get('realm_name'),",
            "            \"error\": self.__auth_config.get('realm_error')",
            "        }",
            "",
            "    @property",
            "    def default_superuser_name(self) -> Optional[str]:",
            "        \"\"\" Get default superuser name. \"\"\"",
            "        root = self.__auth_config['method_root'].split(\":\")",
            "",
            "        # Previously the root file doesn't contain the user name. In this case",
            "        # we will return with no user name.",
            "        if len(root) <= 1:",
            "            return None",
            "",
            "        return root[0]",
            "",
            "    def set_database_connection(self, connection):",
            "        \"\"\"",
            "        Set the instance's database connection to use in fetching",
            "        database-stored sessions to the given connection.",
            "",
            "        Use None as connection's value to unset the database.",
            "        \"\"\"",
            "        self.__database_connection = connection",
            "",
            "    def __handle_validation(self, auth_string):",
            "        \"\"\"",
            "        Validate an oncoming authorization request",
            "        against some authority controller.",
            "",
            "        Returns False if no validation was done, or a validation object",
            "        if the user was successfully authenticated.",
            "",
            "        This validation object contains two keys: username and groups.",
            "        \"\"\"",
            "        validation = self.__try_auth_root(auth_string) \\",
            "            or self.__try_auth_dictionary(auth_string) \\",
            "            or self.__try_auth_pam(auth_string) \\",
            "            or self.__try_auth_ldap(auth_string)",
            "        if not validation:",
            "            return False",
            "",
            "        # If a validation method is enabled and regex_groups is enabled too,",
            "        # we will extend the 'groups'.",
            "        extra_groups = self.__try_regex_groups(validation['username'])",
            "        if extra_groups:",
            "            already_groups = set(validation['groups'])",
            "            validation['groups'] = list(already_groups | extra_groups)",
            "",
            "        LOG.debug('User validation details: %s', str(validation))",
            "        return validation",
            "",
            "    def __is_method_enabled(self, method):",
            "        return method not in UNSUPPORTED_METHODS and \\",
            "            'method_' + method in self.__auth_config and \\",
            "            self.__auth_config['method_' + method].get('enabled')",
            "",
            "    def __try_auth_root(self, auth_string):",
            "        \"\"\"",
            "        Try to authenticate the user against the root username:password's hash.",
            "        \"\"\"",
            "        user_name = SessionManager.get_user_name(auth_string)",
            "        sha = hashlib.sha256(auth_string.encode('utf8')).hexdigest()",
            "",
            "        if f\"{user_name}:{sha}\" == self.__auth_config['method_root']:",
            "            return {",
            "                'username': SessionManager.get_user_name(auth_string),",
            "                'groups': [],",
            "                'root': True",
            "            }",
            "",
            "        return False",
            "",
            "    def __try_auth_token(self, auth_string):",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        user_name, token = auth_string.split(':', 1)",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            auth_session = transaction.query(SessionRecord.token) \\",
            "                .filter(SessionRecord.user_name == user_name) \\",
            "                .filter(SessionRecord.token == token) \\",
            "                .filter(SessionRecord.can_expire.is_(False)) \\",
            "                .limit(1).one_or_none()",
            "",
            "            if not auth_session:",
            "                return None",
            "",
            "            return auth_session",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return None",
            "",
            "    def __try_auth_dictionary(self, auth_string):",
            "        \"\"\"",
            "        Try to authenticate the user against the hardcoded credential list.",
            "",
            "        Returns a validation object if successful, which contains the users'",
            "        groups.",
            "        \"\"\"",
            "        method_config = self.__auth_config.get('method_dictionary')",
            "        if not method_config:",
            "            return False",
            "",
            "        valid = self.__is_method_enabled('dictionary') and \\",
            "            auth_string in method_config.get('auths')",
            "        if not valid:",
            "            return False",
            "",
            "        username = SessionManager.get_user_name(auth_string)",
            "        group_list = method_config['groups'][username] if \\",
            "            'groups' in method_config and \\",
            "            username in method_config['groups'] else []",
            "",
            "        return {",
            "            'username': username,",
            "            'groups': group_list",
            "        }",
            "",
            "    def __try_auth_pam(self, auth_string):",
            "        \"\"\"",
            "        Try to authenticate user based on the PAM configuration.",
            "        \"\"\"",
            "        if self.__is_method_enabled('pam'):",
            "            username, password = auth_string.split(':', 1)",
            "            if cc_pam.auth_user(self.__auth_config['method_pam'],",
            "                                username, password):",
            "                # PAM does not hold a group membership list we can reliably",
            "                # query.",
            "                return {'username': username}",
            "",
            "        return False",
            "",
            "    def __try_auth_ldap(self, auth_string):",
            "        \"\"\"",
            "        Try to authenticate user to all the configured authorities.",
            "        \"\"\"",
            "        if self.__is_method_enabled('ldap'):",
            "            username, password = auth_string.split(':', 1)",
            "",
            "            ldap_authorities = self.__auth_config['method_ldap'] \\",
            "                .get('authorities')",
            "            for ldap_conf in ldap_authorities:",
            "                if cc_ldap.auth_user(ldap_conf, username, password):",
            "                    groups = cc_ldap.get_groups(ldap_conf, username, password)",
            "                    self.__update_groups(username, groups)",
            "                    return {'username': username, 'groups': groups}",
            "",
            "        return False",
            "",
            "    def __update_groups(self, user_name, groups):",
            "        \"\"\"",
            "        Updates group field of the users tokens.",
            "        \"\"\"",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            transaction.query(SessionRecord) \\",
            "                .filter(SessionRecord.user_name == user_name) \\",
            "                .update({SessionRecord.groups: ';'.join(groups)})",
            "            transaction.commit()",
            "            return True",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return False",
            "",
            "    def __try_regex_groups(self, username):",
            "        \"\"\"",
            "        Return a set of groups that the user belongs to, depending on whether",
            "        the username matches the regular expression of the group.",
            "",
            "        \"\"\"",
            "        if not self.__regex_groups_enabled:",
            "            return set()",
            "",
            "        matching_groups = set()",
            "        for group_name, regex_list in self.__group_regexes_compiled.items():",
            "            for r in regex_list:",
            "                if re.search(r, username):",
            "                    matching_groups.add(group_name)",
            "",
            "        return matching_groups",
            "",
            "    @staticmethod",
            "    def get_user_name(auth_string):",
            "        return auth_string.split(':')[0]",
            "",
            "    def get_db_auth_session_tokens(self, user_name):",
            "        \"\"\"",
            "        Get authentication session token from the database for the given user.",
            "        \"\"\"",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            session_tokens = transaction.query(SessionRecord) \\",
            "                .filter(SessionRecord.user_name == user_name) \\",
            "                .filter(SessionRecord.can_expire.is_(True)) \\",
            "                .all()",
            "            return session_tokens",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return None",
            "",
            "    def __is_root_user(self, user_name):",
            "        \"\"\" Return True if the given user has system permissions. \"\"\"",
            "        if self.__auth_config['method_root'].split(\":\")[0] == user_name:",
            "            return True",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            system_permission = transaction.query(SystemPermission) \\",
            "                .filter(SystemPermission.name == user_name) \\",
            "                .filter(SystemPermission.permission == SUPERUSER.name) \\",
            "                .limit(1).one_or_none()",
            "            return bool(system_permission)",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't get system permission from database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return False",
            "",
            "    def __create_local_session(self, token, user_name, groups, is_root,",
            "                               last_access=None, can_expire=True):",
            "        \"\"\"",
            "        Returns a new local session object initalized by the given parameters.",
            "        \"\"\"",
            "        if not is_root:",
            "            is_root = self.__is_root_user(user_name)",
            "",
            "        return _Session(",
            "            token, user_name, groups,",
            "            self.__auth_config['session_lifetime'],",
            "            self.__refresh_time, is_root, self.__database_connection,",
            "            last_access, can_expire)",
            "",
            "    def create_session(self, auth_string):",
            "        \"\"\" Creates a new session for the given auth-string. \"\"\"",
            "        if not self.__auth_config['enabled']:",
            "            return None",
            "",
            "        # Perform cleanup of session memory, if neccessary.",
            "        self.__logins_since_prune += 1",
            "        if self.__logins_since_prune >= \\",
            "                self.__auth_config['logins_until_cleanup']:",
            "            self.__cleanup_sessions()",
            "",
            "        # Try authenticate user with personal access token.",
            "        auth_token = self.__try_auth_token(auth_string)",
            "        if auth_token:",
            "            local_session = self.__get_local_session_from_db(auth_token.token)",
            "            local_session.revalidate()",
            "            self.__sessions.append(local_session)",
            "            return local_session",
            "",
            "        # Try to authenticate user with different authentication methods.",
            "        validation = self.__handle_validation(auth_string)",
            "        if not validation:",
            "            return False",
            "",
            "        # Generate a new token and create a local session.",
            "        token = generate_session_token()",
            "        user_name = validation.get('username')",
            "        groups = validation.get('groups', [])",
            "        is_root = validation.get('root', False)",
            "",
            "        local_session = self.__create_local_session(token, user_name,",
            "                                                    groups, is_root)",
            "        self.__sessions.append(local_session)",
            "",
            "        # Store the session in the database.",
            "        transaction = None",
            "        if self.__database_connection:",
            "            try:",
            "                transaction = self.__database_connection()",
            "                record = SessionRecord(token, user_name,",
            "                                       ';'.join(groups))",
            "                transaction.add(record)",
            "                transaction.commit()",
            "            except Exception as e:",
            "                LOG.error(\"Couldn't store or update login record in \"",
            "                          \"database:\")",
            "                LOG.error(str(e))",
            "            finally:",
            "                if transaction:",
            "                    transaction.close()",
            "",
            "        return local_session",
            "",
            "    def get_max_run_count(self):",
            "        \"\"\"",
            "        Returns the maximum storable run count. If the value is None it means",
            "        we can upload unlimited number of runs.",
            "        \"\"\"",
            "        return self.__max_run_count",
            "",
            "    def get_analysis_statistics_dir(self):",
            "        \"\"\"",
            "        Get directory where the compressed analysis statistics files should be",
            "        stored. If the value is None it means we do not want to store",
            "        analysis statistics information on the server.",
            "        \"\"\"",
            "",
            "        return self.__store_config.get('analysis_statistics_dir')",
            "",
            "    def get_failure_zip_size(self):",
            "        \"\"\"",
            "        Maximum size of the collected failed zips which can be store on the",
            "        server.",
            "        \"\"\"",
            "        limit = self.__store_config.get('limit', {})",
            "        return limit.get('failure_zip_size')",
            "",
            "    def get_compilation_database_size(self):",
            "        \"\"\"",
            "        Limit of the compilation database file size.",
            "        \"\"\"",
            "        limit = self.__store_config.get('limit', {})",
            "        return limit.get('compilation_database_size')",
            "",
            "    def is_keepalive_enabled(self):",
            "        \"\"\"",
            "        True if the keepalive functionality is explicitly enabled, otherwise it",
            "        will return False.",
            "        \"\"\"",
            "        return self.__keepalive_config.get('enabled')",
            "",
            "    def get_keepalive_idle(self):",
            "        \"\"\" Get keepalive idle time. \"\"\"",
            "        return self.__keepalive_config.get('idle')",
            "",
            "    def get_keepalive_interval(self):",
            "        \"\"\" Get keepalive interval time. \"\"\"",
            "        return self.__keepalive_config.get('interval')",
            "",
            "    def get_keepalive_max_probe(self):",
            "        \"\"\" Get keepalive max probe count. \"\"\"",
            "        return self.__keepalive_config.get('max_probe')",
            "",
            "    def __get_local_session_from_db(self, token):",
            "        \"\"\"",
            "        Creates a local session if a valid session token can be found in the",
            "        database.",
            "        \"\"\"",
            "",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        transaction = None",
            "        try:",
            "            transaction = self.__database_connection()",
            "            db_record = transaction.query(SessionRecord) \\",
            "                .filter(SessionRecord.token == token) \\",
            "                .limit(1).one_or_none()",
            "",
            "            if db_record:",
            "                user_name = db_record.user_name",
            "                is_root = self.__is_root_user(user_name)",
            "",
            "                groups = db_record.groups.split(';') \\",
            "                    if db_record.groups else []",
            "",
            "                return self.__create_local_session(token, user_name,",
            "                                                   groups,",
            "                                                   is_root,",
            "                                                   db_record.last_access,",
            "                                                   db_record.can_expire)",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return None",
            "",
            "    def get_session(self, token):",
            "        \"\"\"",
            "        Retrieves the session for the given session cookie token from the",
            "        server's memory backend, if such session exists or creates and returns",
            "        a new one if the token exists in the database.",
            "",
            "        :returns: The session object if one was found. None if authentication",
            "        is not enabled, or if the cookie is not valid anymore.",
            "        \"\"\"",
            "",
            "        if not self.is_enabled:",
            "            return None",
            "",
            "        for sess in self.__sessions:",
            "            if sess.is_alive and sess.token == token:",
            "                # If the session is alive but the should be re-validated.",
            "                if sess.is_refresh_time_expire:",
            "                    sess.revalidate()",
            "                return sess",
            "",
            "        # Try to get a local session from the database.",
            "        local_session = self.__get_local_session_from_db(token)",
            "        if local_session and local_session.is_alive:",
            "            self.__sessions.append(local_session)",
            "            if local_session.is_refresh_time_expire:",
            "                local_session.revalidate()",
            "            return local_session",
            "",
            "        self.invalidate(token)",
            "",
            "        return None",
            "",
            "    def invalidate_local_session(self, token):",
            "        \"\"\"",
            "        Remove a user's previous session from the local in memory store.",
            "        \"\"\"",
            "        for session in self.__sessions[:]:",
            "            if session.token == token:",
            "                self.__sessions.remove(session)",
            "                return True",
            "        return False",
            "",
            "    def invalidate(self, token):",
            "        \"\"\"",
            "        Remove a user's previous session from local in memory and the database",
            "        store.",
            "        \"\"\"",
            "        transaction = None",
            "        try:",
            "            self.invalidate_local_session(token)",
            "",
            "            transaction = self.__database_connection() \\",
            "                if self.__database_connection else None",
            "",
            "            # Remove sessions from the database.",
            "            if transaction:",
            "                transaction.query(SessionRecord) \\",
            "                    .filter(SessionRecord.token == token) \\",
            "                    .filter(SessionRecord.can_expire.is_(True)) \\",
            "                    .delete()",
            "                transaction.commit()",
            "",
            "            return True",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't invalidate session for token %s\", token)",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return False",
            "",
            "    def __cleanup_sessions(self):",
            "        self.__logins_since_prune = 0",
            "",
            "        for s in self.__sessions:",
            "            if s.is_refresh_time_expire:",
            "                self.invalidate_local_session(s.token)",
            "",
            "        for s in self.__sessions:",
            "            if not s.is_alive:",
            "                self.invalidate(s.token)"
        ],
        "afterPatchFile": [
            "# -------------------------------------------------------------------------",
            "#",
            "#  Part of the CodeChecker project, under the Apache License v2.0 with",
            "#  LLVM Exceptions. See LICENSE for license information.",
            "#  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception",
            "#",
            "# -------------------------------------------------------------------------",
            "\"\"\"",
            "Handles the management of authentication sessions on the server's side.",
            "\"\"\"",
            "",
            "import json",
            "import os",
            "import re",
            "import uuid",
            "",
            "from datetime import datetime",
            "from typing import Optional",
            "",
            "from codechecker_common.compatibility.multiprocessing import cpu_count",
            "from codechecker_common.logger import get_logger",
            "from codechecker_common.util import load_json",
            "",
            "from codechecker_web.shared.env import check_file_owner_rw",
            "from codechecker_web.shared.version import SESSION_COOKIE_NAME as _SCN",
            "",
            "from .database.config_db_model import Session as SessionRecord",
            "from .database.config_db_model import SystemPermission",
            "from .permissions import SUPERUSER",
            "",
            "",
            "UNSUPPORTED_METHODS = []",
            "",
            "try:",
            "    from .auth import cc_ldap",
            "except ImportError:",
            "    UNSUPPORTED_METHODS.append('ldap')",
            "",
            "try:",
            "    from .auth import cc_pam",
            "except ImportError:",
            "    UNSUPPORTED_METHODS.append('pam')",
            "",
            "",
            "LOG = get_logger(\"server\")",
            "SESSION_COOKIE_NAME = _SCN",
            "",
            "",
            "def generate_session_token():",
            "    \"\"\"",
            "    Returns a random session token.",
            "    \"\"\"",
            "    return uuid.UUID(bytes=os.urandom(16)).hex",
            "",
            "",
            "def get_worker_processes(scfg_dict):",
            "    \"\"\"",
            "    Return number of worker processes from the config dictionary.",
            "",
            "    Return 'worker_processes' field from the config dictionary or returns the",
            "    default value if this field is not set or the value is negative.",
            "    \"\"\"",
            "    default = cpu_count()",
            "    worker_processes = scfg_dict.get('worker_processes', default)",
            "",
            "    if worker_processes < 0:",
            "        LOG.warning(\"Number of worker processes can not be negative! Default \"",
            "                    \"value will be used: %s\", default)",
            "        worker_processes = default",
            "",
            "    return worker_processes",
            "",
            "",
            "class _Session:",
            "    \"\"\"A session for an authenticated, privileged client connection.\"\"\"",
            "",
            "    def __init__(self, token, username, groups,",
            "                 session_lifetime, refresh_time, is_root=False, database=None,",
            "                 last_access=None, can_expire=True):",
            "",
            "        self.token = token",
            "        self.user = username",
            "        self.groups = groups",
            "",
            "        self.session_lifetime = session_lifetime",
            "        self.refresh_time = refresh_time if refresh_time else None",
            "        self.__root = is_root",
            "        self.__database = database",
            "        self.__can_expire = can_expire",
            "        self.last_access = last_access if last_access else datetime.now()",
            "",
            "    @property",
            "    def is_root(self):",
            "        \"\"\"Returns whether or not the Session was created with the master",
            "        superuser (root) credentials.\"\"\"",
            "        return self.__root",
            "",
            "    @property",
            "    def is_refresh_time_expire(self):",
            "        \"\"\"",
            "        Returns if the refresh time of the session is expired.",
            "        \"\"\"",
            "        if not self.refresh_time:",
            "            return True",
            "",
            "        return (datetime.now() - self.last_access).total_seconds() > \\",
            "            self.refresh_time",
            "",
            "    @property",
            "    def is_alive(self):",
            "        \"\"\"",
            "        Returns if the session is alive and usable, that is, within its",
            "        lifetime.",
            "        \"\"\"",
            "        if not self.__can_expire:",
            "            return True",
            "",
            "        return (datetime.now() - self.last_access).total_seconds() <= \\",
            "            self.session_lifetime",
            "",
            "    def revalidate(self):",
            "        \"\"\"",
            "        A session is only revalidated if it has yet to exceed its",
            "        lifetime. After a session hasn't been used for this interval,",
            "        it can NOT be resurrected at all --- the user needs to log in",
            "        to a brand-new session.",
            "        \"\"\"",
            "",
            "        if not self.is_alive:",
            "            return",
            "",
            "        if self.__database and self.is_refresh_time_expire:",
            "            self.last_access = datetime.now()",
            "",
            "            # Update the timestamp in the database for the session's last",
            "            # access.",
            "            transaction = None",
            "            try:",
            "                transaction = self.__database()",
            "                record = transaction.query(SessionRecord) \\",
            "                    .filter(SessionRecord.user_name == self.user) \\",
            "                    .filter(SessionRecord.token == self.token) \\",
            "                    .limit(1).one_or_none()",
            "",
            "                if record:",
            "                    record.last_access = self.last_access",
            "                    transaction.commit()",
            "            except Exception as e:",
            "                LOG.warning(\"Couldn't update usage timestamp of %s\",",
            "                            self.token)",
            "                LOG.warning(str(e))",
            "            finally:",
            "                if transaction:",
            "                    transaction.close()",
            "",
            "",
            "class SessionManager:",
            "    \"\"\"",
            "    Provides the functionality required to handle user authentication on a",
            "    CodeChecker server.",
            "    \"\"\"",
            "",
            "    def __init__(self, configuration_file, force_auth=False):",
            "        \"\"\"",
            "        Initialise a new Session Manager on the server.",
            "",
            "        :param configuration_file: The configuration file to read",
            "            authentication backends from.",
            "        :param force_auth: If True, the manager will be enabled even if the",
            "            configuration file disables authentication.",
            "        \"\"\"",
            "        self.__database_connection = None",
            "        self.__logins_since_prune = 0",
            "        self.__sessions = []",
            "        self.__configuration_file = configuration_file",
            "",
            "        scfg_dict = self.__get_config_dict()",
            "",
            "        # FIXME: Refactor this. This is irrelevant to authentication config,",
            "        # so it should NOT be handled by session_manager. A separate config",
            "        # handler for the server's stuff should be created, that can properly",
            "        # instantiate SessionManager with the found configuration.",
            "        self.__worker_processes = get_worker_processes(scfg_dict)",
            "        self.__max_run_count = scfg_dict.get('max_run_count', None)",
            "        self.__store_config = scfg_dict.get('store', {})",
            "        self.__keepalive_config = scfg_dict.get('keepalive', {})",
            "        self.__auth_config = scfg_dict['authentication']",
            "",
            "        if force_auth:",
            "            LOG.debug(\"Authentication was force-enabled.\")",
            "            self.__auth_config['enabled'] = True",
            "",
            "        if 'soft_expire' in self.__auth_config:",
            "            LOG.debug(\"Found deprecated argument 'soft_expire' in \"",
            "                      \"server_config.authentication.\")",
            "",
            "        self.__refresh_time = self.__auth_config['refresh_time'] \\",
            "            if 'refresh_time' in self.__auth_config else None",
            "",
            "        self.__regex_groups_enabled = False",
            "",
            "        # Pre-compile the regular expressions of 'regex_groups'",
            "        if 'regex_groups' in self.__auth_config:",
            "            self.__regex_groups_enabled = self.__auth_config['regex_groups'] \\",
            "                                              .get('enabled', False)",
            "",
            "            regex_groups = self.__auth_config['regex_groups'] \\",
            "                               .get('groups', [])",
            "            d = {}",
            "            for group_name, regex_list in regex_groups.items():",
            "                d[group_name] = [re.compile(r) for r in regex_list]",
            "            self.__group_regexes_compiled = d",
            "",
            "        # If no methods are configured as enabled, disable authentication.",
            "        if scfg_dict['authentication'].get('enabled'):",
            "            found_auth_method = False",
            "",
            "            if 'method_dictionary' in self.__auth_config and \\",
            "                    self.__auth_config['method_dictionary'].get('enabled'):",
            "                found_auth_method = True",
            "",
            "            if 'method_ldap' in self.__auth_config and \\",
            "                    self.__auth_config['method_ldap'].get('enabled'):",
            "                if 'ldap' not in UNSUPPORTED_METHODS:",
            "                    found_auth_method = True",
            "                else:",
            "                    LOG.warning(\"LDAP authentication was enabled but \"",
            "                                \"prerequisites are NOT installed on the system\"",
            "                                \"... Disabling LDAP authentication.\")",
            "                    self.__auth_config['method_ldap']['enabled'] = False",
            "",
            "            if 'method_pam' in self.__auth_config and \\",
            "                    self.__auth_config['method_pam'].get('enabled'):",
            "                if 'pam' not in UNSUPPORTED_METHODS:",
            "                    found_auth_method = True",
            "                else:",
            "                    LOG.warning(\"PAM authentication was enabled but \"",
            "                                \"prerequisites are NOT installed on the system\"",
            "                                \"... Disabling PAM authentication.\")",
            "                    self.__auth_config['method_pam']['enabled'] = False",
            "",
            "            if not found_auth_method:",
            "                if force_auth:",
            "                    LOG.warning(\"Authentication was manually enabled, but no \"",
            "                                \"valid authentication backends are \"",
            "                                \"configured... The server will only allow \"",
            "                                \"the master superuser (root) access.\")",
            "                else:",
            "                    LOG.warning(\"Authentication is enabled but no valid \"",
            "                                \"authentication backends are configured... \"",
            "                                \"Falling back to no authentication.\")",
            "                    self.__auth_config['enabled'] = False",
            "",
            "    def __get_config_dict(self):",
            "        \"\"\"",
            "        Get server config information from the configuration file. Raise",
            "        ValueError if the configuration file is invalid.",
            "        \"\"\"",
            "        LOG.debug(self.__configuration_file)",
            "        cfg_dict = load_json(self.__configuration_file, {})",
            "        if cfg_dict != {}:",
            "            check_file_owner_rw(self.__configuration_file)",
            "        else:",
            "            # If the configuration dict is empty, it means a JSON couldn't",
            "            # have been parsed from it.",
            "            raise ValueError(\"Server configuration file was invalid, or \"",
            "                             \"empty.\")",
            "        return cfg_dict",
            "",
            "    def reload_config(self):",
            "        LOG.info(\"Reload server configuration file...\")",
            "        try:",
            "            cfg_dict = self.__get_config_dict()",
            "",
            "            prev_max_run_count = self.__max_run_count",
            "            new_max_run_count = cfg_dict.get('max_run_count', None)",
            "            if prev_max_run_count != new_max_run_count:",
            "                self.__max_run_count = new_max_run_count",
            "                LOG.debug(\"Changed 'max_run_count' value from %s to %s\",",
            "                          prev_max_run_count, new_max_run_count)",
            "",
            "            prev_store_config = json.dumps(self.__store_config, sort_keys=True,",
            "                                           indent=2)",
            "            new_store_config_val = cfg_dict.get('store', {})",
            "            new_store_config = json.dumps(new_store_config_val, sort_keys=True,",
            "                                          indent=2)",
            "            if prev_store_config != new_store_config:",
            "                self.__store_config = new_store_config_val",
            "                LOG.debug(\"Updating 'store' config from %s to %s\",",
            "                          prev_store_config, new_store_config)",
            "",
            "            update_sessions = False",
            "            auth_fields_to_update = ['session_lifetime', 'refresh_time',",
            "                                     'logins_until_cleanup']",
            "            for field in auth_fields_to_update:",
            "                if field in self.__auth_config:",
            "                    prev_value = self.__auth_config[field]",
            "                    new_value = cfg_dict['authentication'].get(field, 0)",
            "                    if prev_value != new_value:",
            "                        self.__auth_config[field] = new_value",
            "                        LOG.debug(\"Changed '%s' value from %s to %s\",",
            "                                  field, prev_value, new_value)",
            "                        update_sessions = True",
            "",
            "            if update_sessions:",
            "                # Update configuration options of the already existing",
            "                # sessions.",
            "                for session in self.__sessions:",
            "                    session.session_lifetime = \\",
            "                        self.__auth_config['session_lifetime']",
            "                    session.refresh_time = self.__auth_config['refresh_time']",
            "",
            "            LOG.info(\"Done.\")",
            "        except ValueError as ex:",
            "            LOG.error(\"Couldn't reload server configuration file\")",
            "            LOG.error(str(ex))",
            "",
            "    @property",
            "    def is_enabled(self):",
            "        return self.__auth_config.get('enabled')",
            "",
            "    @property",
            "    def worker_processes(self):",
            "        return self.__worker_processes",
            "",
            "    def get_realm(self):",
            "        return {",
            "            \"realm\": self.__auth_config.get('realm_name'),",
            "            \"error\": self.__auth_config.get('realm_error')",
            "        }",
            "",
            "    @property",
            "    def get_super_user(self):",
            "        return {",
            "            \"super_user\": self.__auth_config.get('super_user'),",
            "        }",
            "",
            "    @property",
            "    def default_superuser_name(self) -> Optional[str]:",
            "        \"\"\" Get default superuser name. \"\"\"",
            "        return self.__auth_config['super_user']",
            "",
            "    def set_database_connection(self, connection):",
            "        \"\"\"",
            "        Set the instance's database connection to use in fetching",
            "        database-stored sessions to the given connection.",
            "",
            "        Use None as connection's value to unset the database.",
            "        \"\"\"",
            "        self.__database_connection = connection",
            "",
            "    def __handle_validation(self, auth_string):",
            "        \"\"\"",
            "        Validate an oncoming authorization request",
            "        against some authority controller.",
            "",
            "        Returns False if no validation was done, or a validation object",
            "        if the user was successfully authenticated.",
            "",
            "        This validation object contains two keys: username and groups.",
            "        \"\"\"",
            "        validation = self.__try_auth_dictionary(auth_string) \\",
            "            or self.__try_auth_pam(auth_string) \\",
            "            or self.__try_auth_ldap(auth_string)",
            "        if not validation:",
            "            return False",
            "",
            "        # If a validation method is enabled and regex_groups is enabled too,",
            "        # we will extend the 'groups'.",
            "        extra_groups = self.__try_regex_groups(validation['username'])",
            "        if extra_groups:",
            "            already_groups = set(validation['groups'])",
            "            validation['groups'] = list(already_groups | extra_groups)",
            "",
            "        LOG.debug('User validation details: %s', str(validation))",
            "        return validation",
            "",
            "    def __is_method_enabled(self, method):",
            "        return method not in UNSUPPORTED_METHODS and \\",
            "            'method_' + method in self.__auth_config and \\",
            "            self.__auth_config['method_' + method].get('enabled')",
            "",
            "    def __try_auth_token(self, auth_string):",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        user_name, token = auth_string.split(':', 1)",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            auth_session = transaction.query(SessionRecord.token) \\",
            "                .filter(SessionRecord.user_name == user_name) \\",
            "                .filter(SessionRecord.token == token) \\",
            "                .filter(SessionRecord.can_expire.is_(False)) \\",
            "                .limit(1).one_or_none()",
            "",
            "            if not auth_session:",
            "                return None",
            "",
            "            return auth_session",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return None",
            "",
            "    def __try_auth_dictionary(self, auth_string):",
            "        \"\"\"",
            "        Try to authenticate the user against the hardcoded credential list.",
            "",
            "        Returns a validation object if successful, which contains the users'",
            "        groups.",
            "        \"\"\"",
            "        method_config = self.__auth_config.get('method_dictionary')",
            "        if not method_config:",
            "            return False",
            "",
            "        valid = self.__is_method_enabled('dictionary') and \\",
            "            auth_string in method_config.get('auths')",
            "        if not valid:",
            "            return False",
            "",
            "        username = SessionManager.get_user_name(auth_string)",
            "        group_list = method_config['groups'][username] if \\",
            "            'groups' in method_config and \\",
            "            username in method_config['groups'] else []",
            "",
            "        return {",
            "            'username': username,",
            "            'groups': group_list",
            "        }",
            "",
            "    def __try_auth_pam(self, auth_string):",
            "        \"\"\"",
            "        Try to authenticate user based on the PAM configuration.",
            "        \"\"\"",
            "        if self.__is_method_enabled('pam'):",
            "            username, password = auth_string.split(':', 1)",
            "            if cc_pam.auth_user(self.__auth_config['method_pam'],",
            "                                username, password):",
            "                # PAM does not hold a group membership list we can reliably",
            "                # query.",
            "                return {'username': username}",
            "",
            "        return False",
            "",
            "    def __try_auth_ldap(self, auth_string):",
            "        \"\"\"",
            "        Try to authenticate user to all the configured authorities.",
            "        \"\"\"",
            "        if self.__is_method_enabled('ldap'):",
            "            username, password = auth_string.split(':', 1)",
            "",
            "            ldap_authorities = self.__auth_config['method_ldap'] \\",
            "                .get('authorities')",
            "            for ldap_conf in ldap_authorities:",
            "                if cc_ldap.auth_user(ldap_conf, username, password):",
            "                    groups = cc_ldap.get_groups(ldap_conf, username, password)",
            "                    self.__update_groups(username, groups)",
            "                    return {'username': username, 'groups': groups}",
            "",
            "        return False",
            "",
            "    def __update_groups(self, user_name, groups):",
            "        \"\"\"",
            "        Updates group field of the users tokens.",
            "        \"\"\"",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            transaction.query(SessionRecord) \\",
            "                .filter(SessionRecord.user_name == user_name) \\",
            "                .update({SessionRecord.groups: ';'.join(groups)})",
            "            transaction.commit()",
            "            return True",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return False",
            "",
            "    def __try_regex_groups(self, username):",
            "        \"\"\"",
            "        Return a set of groups that the user belongs to, depending on whether",
            "        the username matches the regular expression of the group.",
            "",
            "        \"\"\"",
            "        if not self.__regex_groups_enabled:",
            "            return set()",
            "",
            "        matching_groups = set()",
            "        for group_name, regex_list in self.__group_regexes_compiled.items():",
            "            for r in regex_list:",
            "                if re.search(r, username):",
            "                    matching_groups.add(group_name)",
            "",
            "        return matching_groups",
            "",
            "    @staticmethod",
            "    def get_user_name(auth_string):",
            "        return auth_string.split(':')[0]",
            "",
            "    def get_db_auth_session_tokens(self, user_name):",
            "        \"\"\"",
            "        Get authentication session token from the database for the given user.",
            "        \"\"\"",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            session_tokens = transaction.query(SessionRecord) \\",
            "                .filter(SessionRecord.user_name == user_name) \\",
            "                .filter(SessionRecord.can_expire.is_(True)) \\",
            "                .all()",
            "            return session_tokens",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return None",
            "",
            "    def __is_root_user(self, user_name):",
            "        \"\"\" Return True if the given user has system permissions. \"\"\"",
            "        if self.__auth_config['super_user'] == user_name:",
            "            return True",
            "",
            "        transaction = None",
            "        try:",
            "            # Try the database, if it is connected.",
            "            transaction = self.__database_connection()",
            "            system_permission = transaction.query(SystemPermission) \\",
            "                .filter(SystemPermission.name == user_name) \\",
            "                .filter(SystemPermission.permission == SUPERUSER.name) \\",
            "                .limit(1).one_or_none()",
            "            return bool(system_permission)",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't get system permission from database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return False",
            "",
            "    def __create_local_session(self, token, user_name, groups, is_root,",
            "                               last_access=None, can_expire=True):",
            "        \"\"\"",
            "        Returns a new local session object initalized by the given parameters.",
            "        \"\"\"",
            "        if not is_root:",
            "            is_root = self.__is_root_user(user_name)",
            "",
            "        return _Session(",
            "            token, user_name, groups,",
            "            self.__auth_config['session_lifetime'],",
            "            self.__refresh_time, is_root, self.__database_connection,",
            "            last_access, can_expire)",
            "",
            "    def create_session(self, auth_string):",
            "        \"\"\" Creates a new session for the given auth-string. \"\"\"",
            "        if not self.__auth_config['enabled']:",
            "            return None",
            "",
            "        # Perform cleanup of session memory, if neccessary.",
            "        self.__logins_since_prune += 1",
            "        if self.__logins_since_prune >= \\",
            "                self.__auth_config['logins_until_cleanup']:",
            "            self.__cleanup_sessions()",
            "",
            "        # Try authenticate user with personal access token.",
            "        auth_token = self.__try_auth_token(auth_string)",
            "        if auth_token:",
            "            local_session = self.__get_local_session_from_db(auth_token.token)",
            "            local_session.revalidate()",
            "            self.__sessions.append(local_session)",
            "            return local_session",
            "",
            "        # Try to authenticate user with different authentication methods.",
            "        validation = self.__handle_validation(auth_string)",
            "        if not validation:",
            "            return False",
            "",
            "        # Generate a new token and create a local session.",
            "        token = generate_session_token()",
            "        user_name = validation.get('username')",
            "        groups = validation.get('groups', [])",
            "        is_root = validation.get('root', False)",
            "",
            "        local_session = self.__create_local_session(token, user_name,",
            "                                                    groups, is_root)",
            "        self.__sessions.append(local_session)",
            "",
            "        # Store the session in the database.",
            "        transaction = None",
            "        if self.__database_connection:",
            "            try:",
            "                transaction = self.__database_connection()",
            "                record = SessionRecord(token, user_name,",
            "                                       ';'.join(groups))",
            "                transaction.add(record)",
            "                transaction.commit()",
            "            except Exception as e:",
            "                LOG.error(\"Couldn't store or update login record in \"",
            "                          \"database:\")",
            "                LOG.error(str(e))",
            "            finally:",
            "                if transaction:",
            "                    transaction.close()",
            "",
            "        return local_session",
            "",
            "    def get_max_run_count(self):",
            "        \"\"\"",
            "        Returns the maximum storable run count. If the value is None it means",
            "        we can upload unlimited number of runs.",
            "        \"\"\"",
            "        return self.__max_run_count",
            "",
            "    def get_analysis_statistics_dir(self):",
            "        \"\"\"",
            "        Get directory where the compressed analysis statistics files should be",
            "        stored. If the value is None it means we do not want to store",
            "        analysis statistics information on the server.",
            "        \"\"\"",
            "",
            "        return self.__store_config.get('analysis_statistics_dir')",
            "",
            "    def get_failure_zip_size(self):",
            "        \"\"\"",
            "        Maximum size of the collected failed zips which can be store on the",
            "        server.",
            "        \"\"\"",
            "        limit = self.__store_config.get('limit', {})",
            "        return limit.get('failure_zip_size')",
            "",
            "    def get_compilation_database_size(self):",
            "        \"\"\"",
            "        Limit of the compilation database file size.",
            "        \"\"\"",
            "        limit = self.__store_config.get('limit', {})",
            "        return limit.get('compilation_database_size')",
            "",
            "    def is_keepalive_enabled(self):",
            "        \"\"\"",
            "        True if the keepalive functionality is explicitly enabled, otherwise it",
            "        will return False.",
            "        \"\"\"",
            "        return self.__keepalive_config.get('enabled')",
            "",
            "    def get_keepalive_idle(self):",
            "        \"\"\" Get keepalive idle time. \"\"\"",
            "        return self.__keepalive_config.get('idle')",
            "",
            "    def get_keepalive_interval(self):",
            "        \"\"\" Get keepalive interval time. \"\"\"",
            "        return self.__keepalive_config.get('interval')",
            "",
            "    def get_keepalive_max_probe(self):",
            "        \"\"\" Get keepalive max probe count. \"\"\"",
            "        return self.__keepalive_config.get('max_probe')",
            "",
            "    def __get_local_session_from_db(self, token):",
            "        \"\"\"",
            "        Creates a local session if a valid session token can be found in the",
            "        database.",
            "        \"\"\"",
            "",
            "        if not self.__database_connection:",
            "            return None",
            "",
            "        transaction = None",
            "        try:",
            "            transaction = self.__database_connection()",
            "            db_record = transaction.query(SessionRecord) \\",
            "                .filter(SessionRecord.token == token) \\",
            "                .limit(1).one_or_none()",
            "",
            "            if db_record:",
            "                user_name = db_record.user_name",
            "                is_root = self.__is_root_user(user_name)",
            "",
            "                groups = db_record.groups.split(';') \\",
            "                    if db_record.groups else []",
            "",
            "                return self.__create_local_session(token, user_name,",
            "                                                   groups,",
            "                                                   is_root,",
            "                                                   db_record.last_access,",
            "                                                   db_record.can_expire)",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't check login in the database: \")",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return None",
            "",
            "    def get_session(self, token):",
            "        \"\"\"",
            "        Retrieves the session for the given session cookie token from the",
            "        server's memory backend, if such session exists or creates and returns",
            "        a new one if the token exists in the database.",
            "",
            "        :returns: The session object if one was found. None if authentication",
            "        is not enabled, or if the cookie is not valid anymore.",
            "        \"\"\"",
            "",
            "        if not self.is_enabled:",
            "            return None",
            "",
            "        for sess in self.__sessions:",
            "            if sess.is_alive and sess.token == token:",
            "                # If the session is alive but the should be re-validated.",
            "                if sess.is_refresh_time_expire:",
            "                    sess.revalidate()",
            "                return sess",
            "",
            "        # Try to get a local session from the database.",
            "        local_session = self.__get_local_session_from_db(token)",
            "        if local_session and local_session.is_alive:",
            "            self.__sessions.append(local_session)",
            "            if local_session.is_refresh_time_expire:",
            "                local_session.revalidate()",
            "            return local_session",
            "",
            "        self.invalidate(token)",
            "",
            "        return None",
            "",
            "    def invalidate_local_session(self, token):",
            "        \"\"\"",
            "        Remove a user's previous session from the local in memory store.",
            "        \"\"\"",
            "        for session in self.__sessions[:]:",
            "            if session.token == token:",
            "                self.__sessions.remove(session)",
            "                return True",
            "        return False",
            "",
            "    def invalidate(self, token):",
            "        \"\"\"",
            "        Remove a user's previous session from local in memory and the database",
            "        store.",
            "        \"\"\"",
            "        transaction = None",
            "        try:",
            "            self.invalidate_local_session(token)",
            "",
            "            transaction = self.__database_connection() \\",
            "                if self.__database_connection else None",
            "",
            "            # Remove sessions from the database.",
            "            if transaction:",
            "                transaction.query(SessionRecord) \\",
            "                    .filter(SessionRecord.token == token) \\",
            "                    .filter(SessionRecord.can_expire.is_(True)) \\",
            "                    .delete()",
            "                transaction.commit()",
            "",
            "            return True",
            "        except Exception as e:",
            "            LOG.error(\"Couldn't invalidate session for token %s\", token)",
            "            LOG.error(str(e))",
            "        finally:",
            "            if transaction:",
            "                transaction.close()",
            "",
            "        return False",
            "",
            "    def __cleanup_sessions(self):",
            "        self.__logins_since_prune = 0",
            "",
            "        for s in self.__sessions:",
            "            if s.is_refresh_time_expire:",
            "                self.invalidate_local_session(s.token)",
            "",
            "        for s in self.__sessions:",
            "            if not s.is_alive:",
            "                self.invalidate(s.token)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "12": [],
            "164": [
                "SessionManager",
                "__init__"
            ],
            "170": [
                "SessionManager",
                "__init__"
            ],
            "202": [
                "SessionManager",
                "__init__"
            ],
            "203": [
                "SessionManager",
                "__init__"
            ],
            "204": [
                "SessionManager",
                "__init__"
            ],
            "340": [
                "SessionManager",
                "default_superuser_name"
            ],
            "341": [
                "SessionManager",
                "default_superuser_name"
            ],
            "342": [
                "SessionManager",
                "default_superuser_name"
            ],
            "343": [
                "SessionManager",
                "default_superuser_name"
            ],
            "344": [
                "SessionManager",
                "default_superuser_name"
            ],
            "345": [
                "SessionManager",
                "default_superuser_name"
            ],
            "346": [
                "SessionManager",
                "default_superuser_name"
            ],
            "347": [
                "SessionManager",
                "default_superuser_name"
            ],
            "368": [
                "SessionManager",
                "__handle_validation"
            ],
            "369": [
                "SessionManager",
                "__handle_validation"
            ],
            "390": [
                "SessionManager",
                "__try_auth_root"
            ],
            "391": [
                "SessionManager",
                "__try_auth_root"
            ],
            "392": [
                "SessionManager",
                "__try_auth_root"
            ],
            "393": [
                "SessionManager",
                "__try_auth_root"
            ],
            "394": [
                "SessionManager",
                "__try_auth_root"
            ],
            "395": [
                "SessionManager",
                "__try_auth_root"
            ],
            "396": [
                "SessionManager",
                "__try_auth_root"
            ],
            "397": [
                "SessionManager",
                "__try_auth_root"
            ],
            "398": [
                "SessionManager",
                "__try_auth_root"
            ],
            "399": [
                "SessionManager",
                "__try_auth_root"
            ],
            "400": [
                "SessionManager",
                "__try_auth_root"
            ],
            "401": [
                "SessionManager",
                "__try_auth_root"
            ],
            "402": [
                "SessionManager",
                "__try_auth_root"
            ],
            "403": [
                "SessionManager",
                "__try_auth_root"
            ],
            "404": [
                "SessionManager",
                "__try_auth_root"
            ],
            "405": [
                "SessionManager"
            ],
            "565": [
                "SessionManager",
                "__is_root_user"
            ]
        },
        "addLocation": []
    }
}