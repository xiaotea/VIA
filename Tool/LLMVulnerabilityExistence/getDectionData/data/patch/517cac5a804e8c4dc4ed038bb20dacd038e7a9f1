{
    "src/werkzeug/formparser.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "     :param cls: an optional dict class to use.  If this is not specified"
            },
            "1": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 180,
                "PatchRowcode": "                        or `None` the default :class:`MultiDict` is used."
            },
            "2": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "     :param silent: If set to False parsing errors will not be caught."
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+    :param max_form_parts: The maximum number of parts to be parsed. If this is"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 183,
                "PatchRowcode": "+        exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised."
            },
            "5": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "     \"\"\""
            },
            "6": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 185,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 186,
                "PatchRowcode": "     def __init__("
            },
            "8": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "         max_content_length: t.Optional[int] = None,"
            },
            "9": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 193,
                "PatchRowcode": "         cls: t.Optional[t.Type[MultiDict]] = None,"
            },
            "10": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 194,
                "PatchRowcode": "         silent: bool = True,"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+        *,"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 196,
                "PatchRowcode": "+        max_form_parts: t.Optional[int] = None,"
            },
            "13": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "     ) -> None:"
            },
            "14": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "         if stream_factory is None:"
            },
            "15": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": 199,
                "PatchRowcode": "             stream_factory = default_stream_factory"
            },
            "16": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": 203,
                "PatchRowcode": "         self.errors = errors"
            },
            "17": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 204,
                "PatchRowcode": "         self.max_form_memory_size = max_form_memory_size"
            },
            "18": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 205,
                "PatchRowcode": "         self.max_content_length = max_content_length"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 206,
                "PatchRowcode": "+        self.max_form_parts = max_form_parts"
            },
            "20": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": 207,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": 208,
                "PatchRowcode": "         if cls is None:"
            },
            "22": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "             cls = MultiDict"
            },
            "23": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": 286,
                "PatchRowcode": "             self.errors,"
            },
            "24": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": 287,
                "PatchRowcode": "             max_form_memory_size=self.max_form_memory_size,"
            },
            "25": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": 288,
                "PatchRowcode": "             cls=self.cls,"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 289,
                "PatchRowcode": "+            max_form_parts=self.max_form_parts,"
            },
            "27": {
                "beforePatchRowNumber": 284,
                "afterPatchRowNumber": 290,
                "PatchRowcode": "         )"
            },
            "28": {
                "beforePatchRowNumber": 285,
                "afterPatchRowNumber": 291,
                "PatchRowcode": "         boundary = options.get(\"boundary\", \"\").encode(\"ascii\")"
            },
            "29": {
                "beforePatchRowNumber": 286,
                "afterPatchRowNumber": 292,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 352,
                "PatchRowcode": "         max_form_memory_size: t.Optional[int] = None,"
            },
            "31": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": 353,
                "PatchRowcode": "         cls: t.Optional[t.Type[MultiDict]] = None,"
            },
            "32": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 354,
                "PatchRowcode": "         buffer_size: int = 64 * 1024,"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 355,
                "PatchRowcode": "+        max_form_parts: t.Optional[int] = None,"
            },
            "34": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 356,
                "PatchRowcode": "     ) -> None:"
            },
            "35": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": 357,
                "PatchRowcode": "         self.charset = charset"
            },
            "36": {
                "beforePatchRowNumber": 351,
                "afterPatchRowNumber": 358,
                "PatchRowcode": "         self.errors = errors"
            },
            "37": {
                "beforePatchRowNumber": 352,
                "afterPatchRowNumber": 359,
                "PatchRowcode": "         self.max_form_memory_size = max_form_memory_size"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+        self.max_form_parts = max_form_parts"
            },
            "39": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": 361,
                "PatchRowcode": " "
            },
            "40": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": 362,
                "PatchRowcode": "         if stream_factory is None:"
            },
            "41": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": 363,
                "PatchRowcode": "             stream_factory = default_stream_factory"
            },
            "42": {
                "beforePatchRowNumber": 409,
                "afterPatchRowNumber": 417,
                "PatchRowcode": "             [None],"
            },
            "43": {
                "beforePatchRowNumber": 410,
                "afterPatchRowNumber": 418,
                "PatchRowcode": "         )"
            },
            "44": {
                "beforePatchRowNumber": 411,
                "afterPatchRowNumber": 419,
                "PatchRowcode": " "
            },
            "45": {
                "beforePatchRowNumber": 412,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        parser = MultipartDecoder(boundary, self.max_form_memory_size)"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 420,
                "PatchRowcode": "+        parser = MultipartDecoder("
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 421,
                "PatchRowcode": "+            boundary, self.max_form_memory_size, max_parts=self.max_form_parts"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 422,
                "PatchRowcode": "+        )"
            },
            "49": {
                "beforePatchRowNumber": 413,
                "afterPatchRowNumber": 423,
                "PatchRowcode": " "
            },
            "50": {
                "beforePatchRowNumber": 414,
                "afterPatchRowNumber": 424,
                "PatchRowcode": "         fields = []"
            },
            "51": {
                "beforePatchRowNumber": 415,
                "afterPatchRowNumber": 425,
                "PatchRowcode": "         files = []"
            }
        },
        "frontPatchFile": [
            "import typing as t",
            "from functools import update_wrapper",
            "from io import BytesIO",
            "from itertools import chain",
            "from typing import Union",
            "",
            "from . import exceptions",
            "from .datastructures import FileStorage",
            "from .datastructures import Headers",
            "from .datastructures import MultiDict",
            "from .http import parse_options_header",
            "from .sansio.multipart import Data",
            "from .sansio.multipart import Epilogue",
            "from .sansio.multipart import Field",
            "from .sansio.multipart import File",
            "from .sansio.multipart import MultipartDecoder",
            "from .sansio.multipart import NeedData",
            "from .urls import url_decode_stream",
            "from .wsgi import _make_chunk_iter",
            "from .wsgi import get_content_length",
            "from .wsgi import get_input_stream",
            "",
            "# there are some platforms where SpooledTemporaryFile is not available.",
            "# In that case we need to provide a fallback.",
            "try:",
            "    from tempfile import SpooledTemporaryFile",
            "except ImportError:",
            "    from tempfile import TemporaryFile",
            "",
            "    SpooledTemporaryFile = None  # type: ignore",
            "",
            "if t.TYPE_CHECKING:",
            "    import typing as te",
            "    from _typeshed.wsgi import WSGIEnvironment",
            "",
            "    t_parse_result = t.Tuple[t.IO[bytes], MultiDict, MultiDict]",
            "",
            "    class TStreamFactory(te.Protocol):",
            "        def __call__(",
            "            self,",
            "            total_content_length: t.Optional[int],",
            "            content_type: t.Optional[str],",
            "            filename: t.Optional[str],",
            "            content_length: t.Optional[int] = None,",
            "        ) -> t.IO[bytes]:",
            "            ...",
            "",
            "",
            "F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])",
            "",
            "",
            "def _exhaust(stream: t.IO[bytes]) -> None:",
            "    bts = stream.read(64 * 1024)",
            "    while bts:",
            "        bts = stream.read(64 * 1024)",
            "",
            "",
            "def default_stream_factory(",
            "    total_content_length: t.Optional[int],",
            "    content_type: t.Optional[str],",
            "    filename: t.Optional[str],",
            "    content_length: t.Optional[int] = None,",
            ") -> t.IO[bytes]:",
            "    max_size = 1024 * 500",
            "",
            "    if SpooledTemporaryFile is not None:",
            "        return t.cast(t.IO[bytes], SpooledTemporaryFile(max_size=max_size, mode=\"rb+\"))",
            "    elif total_content_length is None or total_content_length > max_size:",
            "        return t.cast(t.IO[bytes], TemporaryFile(\"rb+\"))",
            "",
            "    return BytesIO()",
            "",
            "",
            "def parse_form_data(",
            "    environ: \"WSGIEnvironment\",",
            "    stream_factory: t.Optional[\"TStreamFactory\"] = None,",
            "    charset: str = \"utf-8\",",
            "    errors: str = \"replace\",",
            "    max_form_memory_size: t.Optional[int] = None,",
            "    max_content_length: t.Optional[int] = None,",
            "    cls: t.Optional[t.Type[MultiDict]] = None,",
            "    silent: bool = True,",
            ") -> \"t_parse_result\":",
            "    \"\"\"Parse the form data in the environ and return it as tuple in the form",
            "    ``(stream, form, files)``.  You should only call this method if the",
            "    transport method is `POST`, `PUT`, or `PATCH`.",
            "",
            "    If the mimetype of the data transmitted is `multipart/form-data` the",
            "    files multidict will be filled with `FileStorage` objects.  If the",
            "    mimetype is unknown the input stream is wrapped and returned as first",
            "    argument, else the stream is empty.",
            "",
            "    This is a shortcut for the common usage of :class:`FormDataParser`.",
            "",
            "    Have a look at :doc:`/request_data` for more details.",
            "",
            "    .. versionadded:: 0.5",
            "       The `max_form_memory_size`, `max_content_length` and",
            "       `cls` parameters were added.",
            "",
            "    .. versionadded:: 0.5.1",
            "       The optional `silent` flag was added.",
            "",
            "    :param environ: the WSGI environment to be used for parsing.",
            "    :param stream_factory: An optional callable that returns a new read and",
            "                           writeable file descriptor.  This callable works",
            "                           the same as :meth:`Response._get_file_stream`.",
            "    :param charset: The character set for URL and url encoded form data.",
            "    :param errors: The encoding error behavior.",
            "    :param max_form_memory_size: the maximum number of bytes to be accepted for",
            "                           in-memory stored form data.  If the data",
            "                           exceeds the value specified an",
            "                           :exc:`~exceptions.RequestEntityTooLarge`",
            "                           exception is raised.",
            "    :param max_content_length: If this is provided and the transmitted data",
            "                               is longer than this value an",
            "                               :exc:`~exceptions.RequestEntityTooLarge`",
            "                               exception is raised.",
            "    :param cls: an optional dict class to use.  If this is not specified",
            "                       or `None` the default :class:`MultiDict` is used.",
            "    :param silent: If set to False parsing errors will not be caught.",
            "    :return: A tuple in the form ``(stream, form, files)``.",
            "    \"\"\"",
            "    return FormDataParser(",
            "        stream_factory,",
            "        charset,",
            "        errors,",
            "        max_form_memory_size,",
            "        max_content_length,",
            "        cls,",
            "        silent,",
            "    ).parse_from_environ(environ)",
            "",
            "",
            "def exhaust_stream(f: F) -> F:",
            "    \"\"\"Helper decorator for methods that exhausts the stream on return.\"\"\"",
            "",
            "    def wrapper(self, stream, *args, **kwargs):  # type: ignore",
            "        try:",
            "            return f(self, stream, *args, **kwargs)",
            "        finally:",
            "            exhaust = getattr(stream, \"exhaust\", None)",
            "",
            "            if exhaust is not None:",
            "                exhaust()",
            "            else:",
            "                while True:",
            "                    chunk = stream.read(1024 * 64)",
            "",
            "                    if not chunk:",
            "                        break",
            "",
            "    return update_wrapper(t.cast(F, wrapper), f)",
            "",
            "",
            "class FormDataParser:",
            "    \"\"\"This class implements parsing of form data for Werkzeug.  By itself",
            "    it can parse multipart and url encoded form data.  It can be subclassed",
            "    and extended but for most mimetypes it is a better idea to use the",
            "    untouched stream and expose it as separate attributes on a request",
            "    object.",
            "",
            "    .. versionadded:: 0.8",
            "",
            "    :param stream_factory: An optional callable that returns a new read and",
            "                           writeable file descriptor.  This callable works",
            "                           the same as :meth:`Response._get_file_stream`.",
            "    :param charset: The character set for URL and url encoded form data.",
            "    :param errors: The encoding error behavior.",
            "    :param max_form_memory_size: the maximum number of bytes to be accepted for",
            "                           in-memory stored form data.  If the data",
            "                           exceeds the value specified an",
            "                           :exc:`~exceptions.RequestEntityTooLarge`",
            "                           exception is raised.",
            "    :param max_content_length: If this is provided and the transmitted data",
            "                               is longer than this value an",
            "                               :exc:`~exceptions.RequestEntityTooLarge`",
            "                               exception is raised.",
            "    :param cls: an optional dict class to use.  If this is not specified",
            "                       or `None` the default :class:`MultiDict` is used.",
            "    :param silent: If set to False parsing errors will not be caught.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        stream_factory: t.Optional[\"TStreamFactory\"] = None,",
            "        charset: str = \"utf-8\",",
            "        errors: str = \"replace\",",
            "        max_form_memory_size: t.Optional[int] = None,",
            "        max_content_length: t.Optional[int] = None,",
            "        cls: t.Optional[t.Type[MultiDict]] = None,",
            "        silent: bool = True,",
            "    ) -> None:",
            "        if stream_factory is None:",
            "            stream_factory = default_stream_factory",
            "",
            "        self.stream_factory = stream_factory",
            "        self.charset = charset",
            "        self.errors = errors",
            "        self.max_form_memory_size = max_form_memory_size",
            "        self.max_content_length = max_content_length",
            "",
            "        if cls is None:",
            "            cls = MultiDict",
            "",
            "        self.cls = cls",
            "        self.silent = silent",
            "",
            "    def get_parse_func(",
            "        self, mimetype: str, options: t.Dict[str, str]",
            "    ) -> t.Optional[",
            "        t.Callable[",
            "            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],",
            "            \"t_parse_result\",",
            "        ]",
            "    ]:",
            "        return self.parse_functions.get(mimetype)",
            "",
            "    def parse_from_environ(self, environ: \"WSGIEnvironment\") -> \"t_parse_result\":",
            "        \"\"\"Parses the information from the environment as form data.",
            "",
            "        :param environ: the WSGI environment to be used for parsing.",
            "        :return: A tuple in the form ``(stream, form, files)``.",
            "        \"\"\"",
            "        content_type = environ.get(\"CONTENT_TYPE\", \"\")",
            "        content_length = get_content_length(environ)",
            "        mimetype, options = parse_options_header(content_type)",
            "        return self.parse(get_input_stream(environ), mimetype, content_length, options)",
            "",
            "    def parse(",
            "        self,",
            "        stream: t.IO[bytes],",
            "        mimetype: str,",
            "        content_length: t.Optional[int],",
            "        options: t.Optional[t.Dict[str, str]] = None,",
            "    ) -> \"t_parse_result\":",
            "        \"\"\"Parses the information from the given stream, mimetype,",
            "        content length and mimetype parameters.",
            "",
            "        :param stream: an input stream",
            "        :param mimetype: the mimetype of the data",
            "        :param content_length: the content length of the incoming data",
            "        :param options: optional mimetype parameters (used for",
            "                        the multipart boundary for instance)",
            "        :return: A tuple in the form ``(stream, form, files)``.",
            "        \"\"\"",
            "        if (",
            "            self.max_content_length is not None",
            "            and content_length is not None",
            "            and content_length > self.max_content_length",
            "        ):",
            "            # if the input stream is not exhausted, firefox reports Connection Reset",
            "            _exhaust(stream)",
            "            raise exceptions.RequestEntityTooLarge()",
            "",
            "        if options is None:",
            "            options = {}",
            "",
            "        parse_func = self.get_parse_func(mimetype, options)",
            "",
            "        if parse_func is not None:",
            "            try:",
            "                return parse_func(self, stream, mimetype, content_length, options)",
            "            except ValueError:",
            "                if not self.silent:",
            "                    raise",
            "",
            "        return stream, self.cls(), self.cls()",
            "",
            "    @exhaust_stream",
            "    def _parse_multipart(",
            "        self,",
            "        stream: t.IO[bytes],",
            "        mimetype: str,",
            "        content_length: t.Optional[int],",
            "        options: t.Dict[str, str],",
            "    ) -> \"t_parse_result\":",
            "        parser = MultiPartParser(",
            "            self.stream_factory,",
            "            self.charset,",
            "            self.errors,",
            "            max_form_memory_size=self.max_form_memory_size,",
            "            cls=self.cls,",
            "        )",
            "        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")",
            "",
            "        if not boundary:",
            "            raise ValueError(\"Missing boundary\")",
            "",
            "        form, files = parser.parse(stream, boundary, content_length)",
            "        return stream, form, files",
            "",
            "    @exhaust_stream",
            "    def _parse_urlencoded(",
            "        self,",
            "        stream: t.IO[bytes],",
            "        mimetype: str,",
            "        content_length: t.Optional[int],",
            "        options: t.Dict[str, str],",
            "    ) -> \"t_parse_result\":",
            "        if (",
            "            self.max_form_memory_size is not None",
            "            and content_length is not None",
            "            and content_length > self.max_form_memory_size",
            "        ):",
            "            # if the input stream is not exhausted, firefox reports Connection Reset",
            "            _exhaust(stream)",
            "            raise exceptions.RequestEntityTooLarge()",
            "",
            "        form = url_decode_stream(stream, self.charset, errors=self.errors, cls=self.cls)",
            "        return stream, form, self.cls()",
            "",
            "    #: mapping of mimetypes to parsing functions",
            "    parse_functions: t.Dict[",
            "        str,",
            "        t.Callable[",
            "            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],",
            "            \"t_parse_result\",",
            "        ],",
            "    ] = {",
            "        \"multipart/form-data\": _parse_multipart,",
            "        \"application/x-www-form-urlencoded\": _parse_urlencoded,",
            "        \"application/x-url-encoded\": _parse_urlencoded,",
            "    }",
            "",
            "",
            "def _line_parse(line: str) -> t.Tuple[str, bool]:",
            "    \"\"\"Removes line ending characters and returns a tuple (`stripped_line`,",
            "    `is_terminated`).",
            "    \"\"\"",
            "    if line[-2:] == \"\\r\\n\":",
            "        return line[:-2], True",
            "",
            "    elif line[-1:] in {\"\\r\", \"\\n\"}:",
            "        return line[:-1], True",
            "",
            "    return line, False",
            "",
            "",
            "class MultiPartParser:",
            "    def __init__(",
            "        self,",
            "        stream_factory: t.Optional[\"TStreamFactory\"] = None,",
            "        charset: str = \"utf-8\",",
            "        errors: str = \"replace\",",
            "        max_form_memory_size: t.Optional[int] = None,",
            "        cls: t.Optional[t.Type[MultiDict]] = None,",
            "        buffer_size: int = 64 * 1024,",
            "    ) -> None:",
            "        self.charset = charset",
            "        self.errors = errors",
            "        self.max_form_memory_size = max_form_memory_size",
            "",
            "        if stream_factory is None:",
            "            stream_factory = default_stream_factory",
            "",
            "        self.stream_factory = stream_factory",
            "",
            "        if cls is None:",
            "            cls = MultiDict",
            "",
            "        self.cls = cls",
            "",
            "        self.buffer_size = buffer_size",
            "",
            "    def fail(self, message: str) -> \"te.NoReturn\":",
            "        raise ValueError(message)",
            "",
            "    def get_part_charset(self, headers: Headers) -> str:",
            "        # Figure out input charset for current part",
            "        content_type = headers.get(\"content-type\")",
            "",
            "        if content_type:",
            "            mimetype, ct_params = parse_options_header(content_type)",
            "            return ct_params.get(\"charset\", self.charset)",
            "",
            "        return self.charset",
            "",
            "    def start_file_streaming(",
            "        self, event: File, total_content_length: t.Optional[int]",
            "    ) -> t.IO[bytes]:",
            "        content_type = event.headers.get(\"content-type\")",
            "",
            "        try:",
            "            content_length = int(event.headers[\"content-length\"])",
            "        except (KeyError, ValueError):",
            "            content_length = 0",
            "",
            "        container = self.stream_factory(",
            "            total_content_length=total_content_length,",
            "            filename=event.filename,",
            "            content_type=content_type,",
            "            content_length=content_length,",
            "        )",
            "        return container",
            "",
            "    def parse(",
            "        self, stream: t.IO[bytes], boundary: bytes, content_length: t.Optional[int]",
            "    ) -> t.Tuple[MultiDict, MultiDict]:",
            "        container: t.Union[t.IO[bytes], t.List[bytes]]",
            "        _write: t.Callable[[bytes], t.Any]",
            "",
            "        iterator = chain(",
            "            _make_chunk_iter(",
            "                stream,",
            "                limit=content_length,",
            "                buffer_size=self.buffer_size,",
            "            ),",
            "            [None],",
            "        )",
            "",
            "        parser = MultipartDecoder(boundary, self.max_form_memory_size)",
            "",
            "        fields = []",
            "        files = []",
            "",
            "        current_part: Union[Field, File]",
            "        for data in iterator:",
            "            parser.receive_data(data)",
            "            event = parser.next_event()",
            "            while not isinstance(event, (Epilogue, NeedData)):",
            "                if isinstance(event, Field):",
            "                    current_part = event",
            "                    container = []",
            "                    _write = container.append",
            "                elif isinstance(event, File):",
            "                    current_part = event",
            "                    container = self.start_file_streaming(event, content_length)",
            "                    _write = container.write",
            "                elif isinstance(event, Data):",
            "                    _write(event.data)",
            "                    if not event.more_data:",
            "                        if isinstance(current_part, Field):",
            "                            value = b\"\".join(container).decode(",
            "                                self.get_part_charset(current_part.headers), self.errors",
            "                            )",
            "                            fields.append((current_part.name, value))",
            "                        else:",
            "                            container = t.cast(t.IO[bytes], container)",
            "                            container.seek(0)",
            "                            files.append(",
            "                                (",
            "                                    current_part.name,",
            "                                    FileStorage(",
            "                                        container,",
            "                                        current_part.filename,",
            "                                        current_part.name,",
            "                                        headers=current_part.headers,",
            "                                    ),",
            "                                )",
            "                            )",
            "",
            "                event = parser.next_event()",
            "",
            "        return self.cls(fields), self.cls(files)"
        ],
        "afterPatchFile": [
            "import typing as t",
            "from functools import update_wrapper",
            "from io import BytesIO",
            "from itertools import chain",
            "from typing import Union",
            "",
            "from . import exceptions",
            "from .datastructures import FileStorage",
            "from .datastructures import Headers",
            "from .datastructures import MultiDict",
            "from .http import parse_options_header",
            "from .sansio.multipart import Data",
            "from .sansio.multipart import Epilogue",
            "from .sansio.multipart import Field",
            "from .sansio.multipart import File",
            "from .sansio.multipart import MultipartDecoder",
            "from .sansio.multipart import NeedData",
            "from .urls import url_decode_stream",
            "from .wsgi import _make_chunk_iter",
            "from .wsgi import get_content_length",
            "from .wsgi import get_input_stream",
            "",
            "# there are some platforms where SpooledTemporaryFile is not available.",
            "# In that case we need to provide a fallback.",
            "try:",
            "    from tempfile import SpooledTemporaryFile",
            "except ImportError:",
            "    from tempfile import TemporaryFile",
            "",
            "    SpooledTemporaryFile = None  # type: ignore",
            "",
            "if t.TYPE_CHECKING:",
            "    import typing as te",
            "    from _typeshed.wsgi import WSGIEnvironment",
            "",
            "    t_parse_result = t.Tuple[t.IO[bytes], MultiDict, MultiDict]",
            "",
            "    class TStreamFactory(te.Protocol):",
            "        def __call__(",
            "            self,",
            "            total_content_length: t.Optional[int],",
            "            content_type: t.Optional[str],",
            "            filename: t.Optional[str],",
            "            content_length: t.Optional[int] = None,",
            "        ) -> t.IO[bytes]:",
            "            ...",
            "",
            "",
            "F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])",
            "",
            "",
            "def _exhaust(stream: t.IO[bytes]) -> None:",
            "    bts = stream.read(64 * 1024)",
            "    while bts:",
            "        bts = stream.read(64 * 1024)",
            "",
            "",
            "def default_stream_factory(",
            "    total_content_length: t.Optional[int],",
            "    content_type: t.Optional[str],",
            "    filename: t.Optional[str],",
            "    content_length: t.Optional[int] = None,",
            ") -> t.IO[bytes]:",
            "    max_size = 1024 * 500",
            "",
            "    if SpooledTemporaryFile is not None:",
            "        return t.cast(t.IO[bytes], SpooledTemporaryFile(max_size=max_size, mode=\"rb+\"))",
            "    elif total_content_length is None or total_content_length > max_size:",
            "        return t.cast(t.IO[bytes], TemporaryFile(\"rb+\"))",
            "",
            "    return BytesIO()",
            "",
            "",
            "def parse_form_data(",
            "    environ: \"WSGIEnvironment\",",
            "    stream_factory: t.Optional[\"TStreamFactory\"] = None,",
            "    charset: str = \"utf-8\",",
            "    errors: str = \"replace\",",
            "    max_form_memory_size: t.Optional[int] = None,",
            "    max_content_length: t.Optional[int] = None,",
            "    cls: t.Optional[t.Type[MultiDict]] = None,",
            "    silent: bool = True,",
            ") -> \"t_parse_result\":",
            "    \"\"\"Parse the form data in the environ and return it as tuple in the form",
            "    ``(stream, form, files)``.  You should only call this method if the",
            "    transport method is `POST`, `PUT`, or `PATCH`.",
            "",
            "    If the mimetype of the data transmitted is `multipart/form-data` the",
            "    files multidict will be filled with `FileStorage` objects.  If the",
            "    mimetype is unknown the input stream is wrapped and returned as first",
            "    argument, else the stream is empty.",
            "",
            "    This is a shortcut for the common usage of :class:`FormDataParser`.",
            "",
            "    Have a look at :doc:`/request_data` for more details.",
            "",
            "    .. versionadded:: 0.5",
            "       The `max_form_memory_size`, `max_content_length` and",
            "       `cls` parameters were added.",
            "",
            "    .. versionadded:: 0.5.1",
            "       The optional `silent` flag was added.",
            "",
            "    :param environ: the WSGI environment to be used for parsing.",
            "    :param stream_factory: An optional callable that returns a new read and",
            "                           writeable file descriptor.  This callable works",
            "                           the same as :meth:`Response._get_file_stream`.",
            "    :param charset: The character set for URL and url encoded form data.",
            "    :param errors: The encoding error behavior.",
            "    :param max_form_memory_size: the maximum number of bytes to be accepted for",
            "                           in-memory stored form data.  If the data",
            "                           exceeds the value specified an",
            "                           :exc:`~exceptions.RequestEntityTooLarge`",
            "                           exception is raised.",
            "    :param max_content_length: If this is provided and the transmitted data",
            "                               is longer than this value an",
            "                               :exc:`~exceptions.RequestEntityTooLarge`",
            "                               exception is raised.",
            "    :param cls: an optional dict class to use.  If this is not specified",
            "                       or `None` the default :class:`MultiDict` is used.",
            "    :param silent: If set to False parsing errors will not be caught.",
            "    :return: A tuple in the form ``(stream, form, files)``.",
            "    \"\"\"",
            "    return FormDataParser(",
            "        stream_factory,",
            "        charset,",
            "        errors,",
            "        max_form_memory_size,",
            "        max_content_length,",
            "        cls,",
            "        silent,",
            "    ).parse_from_environ(environ)",
            "",
            "",
            "def exhaust_stream(f: F) -> F:",
            "    \"\"\"Helper decorator for methods that exhausts the stream on return.\"\"\"",
            "",
            "    def wrapper(self, stream, *args, **kwargs):  # type: ignore",
            "        try:",
            "            return f(self, stream, *args, **kwargs)",
            "        finally:",
            "            exhaust = getattr(stream, \"exhaust\", None)",
            "",
            "            if exhaust is not None:",
            "                exhaust()",
            "            else:",
            "                while True:",
            "                    chunk = stream.read(1024 * 64)",
            "",
            "                    if not chunk:",
            "                        break",
            "",
            "    return update_wrapper(t.cast(F, wrapper), f)",
            "",
            "",
            "class FormDataParser:",
            "    \"\"\"This class implements parsing of form data for Werkzeug.  By itself",
            "    it can parse multipart and url encoded form data.  It can be subclassed",
            "    and extended but for most mimetypes it is a better idea to use the",
            "    untouched stream and expose it as separate attributes on a request",
            "    object.",
            "",
            "    .. versionadded:: 0.8",
            "",
            "    :param stream_factory: An optional callable that returns a new read and",
            "                           writeable file descriptor.  This callable works",
            "                           the same as :meth:`Response._get_file_stream`.",
            "    :param charset: The character set for URL and url encoded form data.",
            "    :param errors: The encoding error behavior.",
            "    :param max_form_memory_size: the maximum number of bytes to be accepted for",
            "                           in-memory stored form data.  If the data",
            "                           exceeds the value specified an",
            "                           :exc:`~exceptions.RequestEntityTooLarge`",
            "                           exception is raised.",
            "    :param max_content_length: If this is provided and the transmitted data",
            "                               is longer than this value an",
            "                               :exc:`~exceptions.RequestEntityTooLarge`",
            "                               exception is raised.",
            "    :param cls: an optional dict class to use.  If this is not specified",
            "                       or `None` the default :class:`MultiDict` is used.",
            "    :param silent: If set to False parsing errors will not be caught.",
            "    :param max_form_parts: The maximum number of parts to be parsed. If this is",
            "        exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        stream_factory: t.Optional[\"TStreamFactory\"] = None,",
            "        charset: str = \"utf-8\",",
            "        errors: str = \"replace\",",
            "        max_form_memory_size: t.Optional[int] = None,",
            "        max_content_length: t.Optional[int] = None,",
            "        cls: t.Optional[t.Type[MultiDict]] = None,",
            "        silent: bool = True,",
            "        *,",
            "        max_form_parts: t.Optional[int] = None,",
            "    ) -> None:",
            "        if stream_factory is None:",
            "            stream_factory = default_stream_factory",
            "",
            "        self.stream_factory = stream_factory",
            "        self.charset = charset",
            "        self.errors = errors",
            "        self.max_form_memory_size = max_form_memory_size",
            "        self.max_content_length = max_content_length",
            "        self.max_form_parts = max_form_parts",
            "",
            "        if cls is None:",
            "            cls = MultiDict",
            "",
            "        self.cls = cls",
            "        self.silent = silent",
            "",
            "    def get_parse_func(",
            "        self, mimetype: str, options: t.Dict[str, str]",
            "    ) -> t.Optional[",
            "        t.Callable[",
            "            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],",
            "            \"t_parse_result\",",
            "        ]",
            "    ]:",
            "        return self.parse_functions.get(mimetype)",
            "",
            "    def parse_from_environ(self, environ: \"WSGIEnvironment\") -> \"t_parse_result\":",
            "        \"\"\"Parses the information from the environment as form data.",
            "",
            "        :param environ: the WSGI environment to be used for parsing.",
            "        :return: A tuple in the form ``(stream, form, files)``.",
            "        \"\"\"",
            "        content_type = environ.get(\"CONTENT_TYPE\", \"\")",
            "        content_length = get_content_length(environ)",
            "        mimetype, options = parse_options_header(content_type)",
            "        return self.parse(get_input_stream(environ), mimetype, content_length, options)",
            "",
            "    def parse(",
            "        self,",
            "        stream: t.IO[bytes],",
            "        mimetype: str,",
            "        content_length: t.Optional[int],",
            "        options: t.Optional[t.Dict[str, str]] = None,",
            "    ) -> \"t_parse_result\":",
            "        \"\"\"Parses the information from the given stream, mimetype,",
            "        content length and mimetype parameters.",
            "",
            "        :param stream: an input stream",
            "        :param mimetype: the mimetype of the data",
            "        :param content_length: the content length of the incoming data",
            "        :param options: optional mimetype parameters (used for",
            "                        the multipart boundary for instance)",
            "        :return: A tuple in the form ``(stream, form, files)``.",
            "        \"\"\"",
            "        if (",
            "            self.max_content_length is not None",
            "            and content_length is not None",
            "            and content_length > self.max_content_length",
            "        ):",
            "            # if the input stream is not exhausted, firefox reports Connection Reset",
            "            _exhaust(stream)",
            "            raise exceptions.RequestEntityTooLarge()",
            "",
            "        if options is None:",
            "            options = {}",
            "",
            "        parse_func = self.get_parse_func(mimetype, options)",
            "",
            "        if parse_func is not None:",
            "            try:",
            "                return parse_func(self, stream, mimetype, content_length, options)",
            "            except ValueError:",
            "                if not self.silent:",
            "                    raise",
            "",
            "        return stream, self.cls(), self.cls()",
            "",
            "    @exhaust_stream",
            "    def _parse_multipart(",
            "        self,",
            "        stream: t.IO[bytes],",
            "        mimetype: str,",
            "        content_length: t.Optional[int],",
            "        options: t.Dict[str, str],",
            "    ) -> \"t_parse_result\":",
            "        parser = MultiPartParser(",
            "            self.stream_factory,",
            "            self.charset,",
            "            self.errors,",
            "            max_form_memory_size=self.max_form_memory_size,",
            "            cls=self.cls,",
            "            max_form_parts=self.max_form_parts,",
            "        )",
            "        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")",
            "",
            "        if not boundary:",
            "            raise ValueError(\"Missing boundary\")",
            "",
            "        form, files = parser.parse(stream, boundary, content_length)",
            "        return stream, form, files",
            "",
            "    @exhaust_stream",
            "    def _parse_urlencoded(",
            "        self,",
            "        stream: t.IO[bytes],",
            "        mimetype: str,",
            "        content_length: t.Optional[int],",
            "        options: t.Dict[str, str],",
            "    ) -> \"t_parse_result\":",
            "        if (",
            "            self.max_form_memory_size is not None",
            "            and content_length is not None",
            "            and content_length > self.max_form_memory_size",
            "        ):",
            "            # if the input stream is not exhausted, firefox reports Connection Reset",
            "            _exhaust(stream)",
            "            raise exceptions.RequestEntityTooLarge()",
            "",
            "        form = url_decode_stream(stream, self.charset, errors=self.errors, cls=self.cls)",
            "        return stream, form, self.cls()",
            "",
            "    #: mapping of mimetypes to parsing functions",
            "    parse_functions: t.Dict[",
            "        str,",
            "        t.Callable[",
            "            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],",
            "            \"t_parse_result\",",
            "        ],",
            "    ] = {",
            "        \"multipart/form-data\": _parse_multipart,",
            "        \"application/x-www-form-urlencoded\": _parse_urlencoded,",
            "        \"application/x-url-encoded\": _parse_urlencoded,",
            "    }",
            "",
            "",
            "def _line_parse(line: str) -> t.Tuple[str, bool]:",
            "    \"\"\"Removes line ending characters and returns a tuple (`stripped_line`,",
            "    `is_terminated`).",
            "    \"\"\"",
            "    if line[-2:] == \"\\r\\n\":",
            "        return line[:-2], True",
            "",
            "    elif line[-1:] in {\"\\r\", \"\\n\"}:",
            "        return line[:-1], True",
            "",
            "    return line, False",
            "",
            "",
            "class MultiPartParser:",
            "    def __init__(",
            "        self,",
            "        stream_factory: t.Optional[\"TStreamFactory\"] = None,",
            "        charset: str = \"utf-8\",",
            "        errors: str = \"replace\",",
            "        max_form_memory_size: t.Optional[int] = None,",
            "        cls: t.Optional[t.Type[MultiDict]] = None,",
            "        buffer_size: int = 64 * 1024,",
            "        max_form_parts: t.Optional[int] = None,",
            "    ) -> None:",
            "        self.charset = charset",
            "        self.errors = errors",
            "        self.max_form_memory_size = max_form_memory_size",
            "        self.max_form_parts = max_form_parts",
            "",
            "        if stream_factory is None:",
            "            stream_factory = default_stream_factory",
            "",
            "        self.stream_factory = stream_factory",
            "",
            "        if cls is None:",
            "            cls = MultiDict",
            "",
            "        self.cls = cls",
            "",
            "        self.buffer_size = buffer_size",
            "",
            "    def fail(self, message: str) -> \"te.NoReturn\":",
            "        raise ValueError(message)",
            "",
            "    def get_part_charset(self, headers: Headers) -> str:",
            "        # Figure out input charset for current part",
            "        content_type = headers.get(\"content-type\")",
            "",
            "        if content_type:",
            "            mimetype, ct_params = parse_options_header(content_type)",
            "            return ct_params.get(\"charset\", self.charset)",
            "",
            "        return self.charset",
            "",
            "    def start_file_streaming(",
            "        self, event: File, total_content_length: t.Optional[int]",
            "    ) -> t.IO[bytes]:",
            "        content_type = event.headers.get(\"content-type\")",
            "",
            "        try:",
            "            content_length = int(event.headers[\"content-length\"])",
            "        except (KeyError, ValueError):",
            "            content_length = 0",
            "",
            "        container = self.stream_factory(",
            "            total_content_length=total_content_length,",
            "            filename=event.filename,",
            "            content_type=content_type,",
            "            content_length=content_length,",
            "        )",
            "        return container",
            "",
            "    def parse(",
            "        self, stream: t.IO[bytes], boundary: bytes, content_length: t.Optional[int]",
            "    ) -> t.Tuple[MultiDict, MultiDict]:",
            "        container: t.Union[t.IO[bytes], t.List[bytes]]",
            "        _write: t.Callable[[bytes], t.Any]",
            "",
            "        iterator = chain(",
            "            _make_chunk_iter(",
            "                stream,",
            "                limit=content_length,",
            "                buffer_size=self.buffer_size,",
            "            ),",
            "            [None],",
            "        )",
            "",
            "        parser = MultipartDecoder(",
            "            boundary, self.max_form_memory_size, max_parts=self.max_form_parts",
            "        )",
            "",
            "        fields = []",
            "        files = []",
            "",
            "        current_part: Union[Field, File]",
            "        for data in iterator:",
            "            parser.receive_data(data)",
            "            event = parser.next_event()",
            "            while not isinstance(event, (Epilogue, NeedData)):",
            "                if isinstance(event, Field):",
            "                    current_part = event",
            "                    container = []",
            "                    _write = container.append",
            "                elif isinstance(event, File):",
            "                    current_part = event",
            "                    container = self.start_file_streaming(event, content_length)",
            "                    _write = container.write",
            "                elif isinstance(event, Data):",
            "                    _write(event.data)",
            "                    if not event.more_data:",
            "                        if isinstance(current_part, Field):",
            "                            value = b\"\".join(container).decode(",
            "                                self.get_part_charset(current_part.headers), self.errors",
            "                            )",
            "                            fields.append((current_part.name, value))",
            "                        else:",
            "                            container = t.cast(t.IO[bytes], container)",
            "                            container.seek(0)",
            "                            files.append(",
            "                                (",
            "                                    current_part.name,",
            "                                    FileStorage(",
            "                                        container,",
            "                                        current_part.filename,",
            "                                        current_part.name,",
            "                                        headers=current_part.headers,",
            "                                    ),",
            "                                )",
            "                            )",
            "",
            "                event = parser.next_event()",
            "",
            "        return self.cls(fields), self.cls(files)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "412": [
                "MultiPartParser",
                "parse"
            ]
        },
        "addLocation": [
            "src.werkzeug.formparser.MultiPartParser",
            "src.werkzeug.formparser.FormDataParser"
        ]
    },
    "src/werkzeug/sansio/multipart.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "         self,"
            },
            "1": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "         boundary: bytes,"
            },
            "2": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "         max_form_memory_size: Optional[int] = None,"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+        *,"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+        max_parts: Optional[int] = None,"
            },
            "5": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 92,
                "PatchRowcode": "     ) -> None:"
            },
            "6": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "         self.buffer = bytearray()"
            },
            "7": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "         self.complete = False"
            },
            "8": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "         self.max_form_memory_size = max_form_memory_size"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+        self.max_parts = max_parts"
            },
            "10": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 97,
                "PatchRowcode": "         self.state = State.PREAMBLE"
            },
            "11": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "         self.boundary = boundary"
            },
            "12": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 99,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 121,
                "PatchRowcode": "             re.MULTILINE,"
            },
            "14": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "         )"
            },
            "15": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "         self._search_position = 0"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+        self._parts_decoded = 0"
            },
            "17": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": 125,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "     def last_newline(self) -> int:"
            },
            "19": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "         try:"
            },
            "20": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "                     )"
            },
            "21": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 196,
                "PatchRowcode": "                 self.state = State.DATA"
            },
            "22": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "                 self._search_position = 0"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 198,
                "PatchRowcode": "+                self._parts_decoded += 1"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 199,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 200,
                "PatchRowcode": "+                if self.max_parts is not None and self._parts_decoded > self.max_parts:"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 201,
                "PatchRowcode": "+                    raise RequestEntityTooLarge()"
            },
            "27": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": 202,
                "PatchRowcode": "             else:"
            },
            "28": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": 203,
                "PatchRowcode": "                 # Update the search start position to be equal to the"
            },
            "29": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": 204,
                "PatchRowcode": "                 # current buffer length (already searched) minus a"
            }
        },
        "frontPatchFile": [
            "import re",
            "from dataclasses import dataclass",
            "from enum import auto",
            "from enum import Enum",
            "from typing import cast",
            "from typing import List",
            "from typing import Optional",
            "from typing import Tuple",
            "",
            "from .._internal import _to_bytes",
            "from .._internal import _to_str",
            "from ..datastructures import Headers",
            "from ..exceptions import RequestEntityTooLarge",
            "from ..http import parse_options_header",
            "",
            "",
            "class Event:",
            "    pass",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Preamble(Event):",
            "    data: bytes",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Field(Event):",
            "    name: str",
            "    headers: Headers",
            "",
            "",
            "@dataclass(frozen=True)",
            "class File(Event):",
            "    name: str",
            "    filename: str",
            "    headers: Headers",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Data(Event):",
            "    data: bytes",
            "    more_data: bool",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Epilogue(Event):",
            "    data: bytes",
            "",
            "",
            "class NeedData(Event):",
            "    pass",
            "",
            "",
            "NEED_DATA = NeedData()",
            "",
            "",
            "class State(Enum):",
            "    PREAMBLE = auto()",
            "    PART = auto()",
            "    DATA = auto()",
            "    EPILOGUE = auto()",
            "    COMPLETE = auto()",
            "",
            "",
            "# Multipart line breaks MUST be CRLF (\\r\\n) by RFC-7578, except that",
            "# many implementations break this and either use CR or LF alone.",
            "LINE_BREAK = b\"(?:\\r\\n|\\n|\\r)\"",
            "BLANK_LINE_RE = re.compile(b\"(?:\\r\\n\\r\\n|\\r\\r|\\n\\n)\", re.MULTILINE)",
            "LINE_BREAK_RE = re.compile(LINE_BREAK, re.MULTILINE)",
            "# Header values can be continued via a space or tab after the linebreak, as",
            "# per RFC2231",
            "HEADER_CONTINUATION_RE = re.compile(b\"%s[ \\t]\" % LINE_BREAK, re.MULTILINE)",
            "# This must be long enough to contain any line breaks plus any",
            "# additional boundary markers (--) such that they will be found in a",
            "# subsequent search",
            "SEARCH_EXTRA_LENGTH = 8",
            "",
            "",
            "class MultipartDecoder:",
            "    \"\"\"Decodes a multipart message as bytes into Python events.",
            "",
            "    The part data is returned as available to allow the caller to save",
            "    the data from memory to disk, if desired.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        boundary: bytes,",
            "        max_form_memory_size: Optional[int] = None,",
            "    ) -> None:",
            "        self.buffer = bytearray()",
            "        self.complete = False",
            "        self.max_form_memory_size = max_form_memory_size",
            "        self.state = State.PREAMBLE",
            "        self.boundary = boundary",
            "",
            "        # Note in the below \\h i.e. horizontal whitespace is used",
            "        # as [^\\S\\n\\r] as \\h isn't supported in python.",
            "",
            "        # The preamble must end with a boundary where the boundary is",
            "        # prefixed by a line break, RFC2046. Except that many",
            "        # implementations including Werkzeug's tests omit the line",
            "        # break prefix. In addition the first boundary could be the",
            "        # epilogue boundary (for empty form-data) hence the matching",
            "        # group to understand if it is an epilogue boundary.",
            "        self.preamble_re = re.compile(",
            "            rb\"%s?--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"",
            "            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),",
            "            re.MULTILINE,",
            "        )",
            "        # A boundary must include a line break prefix and suffix, and",
            "        # may include trailing whitespace. In addition the boundary",
            "        # could be the epilogue boundary hence the matching group to",
            "        # understand if it is an epilogue boundary.",
            "        self.boundary_re = re.compile(",
            "            rb\"%s--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"",
            "            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),",
            "            re.MULTILINE,",
            "        )",
            "        self._search_position = 0",
            "",
            "    def last_newline(self) -> int:",
            "        try:",
            "            last_nl = self.buffer.rindex(b\"\\n\")",
            "        except ValueError:",
            "            last_nl = len(self.buffer)",
            "        try:",
            "            last_cr = self.buffer.rindex(b\"\\r\")",
            "        except ValueError:",
            "            last_cr = len(self.buffer)",
            "",
            "        return min(last_nl, last_cr)",
            "",
            "    def receive_data(self, data: Optional[bytes]) -> None:",
            "        if data is None:",
            "            self.complete = True",
            "        elif (",
            "            self.max_form_memory_size is not None",
            "            and len(self.buffer) + len(data) > self.max_form_memory_size",
            "        ):",
            "            raise RequestEntityTooLarge()",
            "        else:",
            "            self.buffer.extend(data)",
            "",
            "    def next_event(self) -> Event:",
            "        event: Event = NEED_DATA",
            "",
            "        if self.state == State.PREAMBLE:",
            "            match = self.preamble_re.search(self.buffer, self._search_position)",
            "            if match is not None:",
            "                if match.group(1).startswith(b\"--\"):",
            "                    self.state = State.EPILOGUE",
            "                else:",
            "                    self.state = State.PART",
            "                data = bytes(self.buffer[: match.start()])",
            "                del self.buffer[: match.end()]",
            "                event = Preamble(data=data)",
            "                self._search_position = 0",
            "            else:",
            "                # Update the search start position to be equal to the",
            "                # current buffer length (already searched) minus a",
            "                # safe buffer for part of the search target.",
            "                self._search_position = max(",
            "                    0, len(self.buffer) - len(self.boundary) - SEARCH_EXTRA_LENGTH",
            "                )",
            "",
            "        elif self.state == State.PART:",
            "            match = BLANK_LINE_RE.search(self.buffer, self._search_position)",
            "            if match is not None:",
            "                headers = self._parse_headers(self.buffer[: match.start()])",
            "                del self.buffer[: match.end()]",
            "",
            "                if \"content-disposition\" not in headers:",
            "                    raise ValueError(\"Missing Content-Disposition header\")",
            "",
            "                disposition, extra = parse_options_header(",
            "                    headers[\"content-disposition\"]",
            "                )",
            "                name = cast(str, extra.get(\"name\"))",
            "                filename = extra.get(\"filename\")",
            "                if filename is not None:",
            "                    event = File(",
            "                        filename=filename,",
            "                        headers=headers,",
            "                        name=name,",
            "                    )",
            "                else:",
            "                    event = Field(",
            "                        headers=headers,",
            "                        name=name,",
            "                    )",
            "                self.state = State.DATA",
            "                self._search_position = 0",
            "            else:",
            "                # Update the search start position to be equal to the",
            "                # current buffer length (already searched) minus a",
            "                # safe buffer for part of the search target.",
            "                self._search_position = max(0, len(self.buffer) - SEARCH_EXTRA_LENGTH)",
            "",
            "        elif self.state == State.DATA:",
            "            if self.buffer.find(b\"--\" + self.boundary) == -1:",
            "                # No complete boundary in the buffer, but there may be",
            "                # a partial boundary at the end. As the boundary",
            "                # starts with either a nl or cr find the earliest and",
            "                # return up to that as data.",
            "                data_length = del_index = self.last_newline()",
            "                more_data = True",
            "            else:",
            "                match = self.boundary_re.search(self.buffer)",
            "                if match is not None:",
            "                    if match.group(1).startswith(b\"--\"):",
            "                        self.state = State.EPILOGUE",
            "                    else:",
            "                        self.state = State.PART",
            "                    data_length = match.start()",
            "                    del_index = match.end()",
            "                else:",
            "                    data_length = del_index = self.last_newline()",
            "                more_data = match is None",
            "",
            "            data = bytes(self.buffer[:data_length])",
            "            del self.buffer[:del_index]",
            "            if data or not more_data:",
            "                event = Data(data=data, more_data=more_data)",
            "",
            "        elif self.state == State.EPILOGUE and self.complete:",
            "            event = Epilogue(data=bytes(self.buffer))",
            "            del self.buffer[:]",
            "            self.state = State.COMPLETE",
            "",
            "        if self.complete and isinstance(event, NeedData):",
            "            raise ValueError(f\"Invalid form-data cannot parse beyond {self.state}\")",
            "",
            "        return event",
            "",
            "    def _parse_headers(self, data: bytes) -> Headers:",
            "        headers: List[Tuple[str, str]] = []",
            "        # Merge the continued headers into one line",
            "        data = HEADER_CONTINUATION_RE.sub(b\" \", data)",
            "        # Now there is one header per line",
            "        for line in data.splitlines():",
            "            if line.strip() != b\"\":",
            "                name, value = _to_str(line).strip().split(\":\", 1)",
            "                headers.append((name.strip(), value.strip()))",
            "        return Headers(headers)",
            "",
            "",
            "class MultipartEncoder:",
            "    def __init__(self, boundary: bytes) -> None:",
            "        self.boundary = boundary",
            "        self.state = State.PREAMBLE",
            "",
            "    def send_event(self, event: Event) -> bytes:",
            "        if isinstance(event, Preamble) and self.state == State.PREAMBLE:",
            "            self.state = State.PART",
            "            return event.data",
            "        elif isinstance(event, (Field, File)) and self.state in {",
            "            State.PREAMBLE,",
            "            State.PART,",
            "            State.DATA,",
            "        }:",
            "            self.state = State.DATA",
            "            data = b\"\\r\\n--\" + self.boundary + b\"\\r\\n\"",
            "            data += b'Content-Disposition: form-data; name=\"%s\"' % _to_bytes(event.name)",
            "            if isinstance(event, File):",
            "                data += b'; filename=\"%s\"' % _to_bytes(event.filename)",
            "            data += b\"\\r\\n\"",
            "            for name, value in cast(Field, event).headers:",
            "                if name.lower() != \"content-disposition\":",
            "                    data += _to_bytes(f\"{name}: {value}\\r\\n\")",
            "            data += b\"\\r\\n\"",
            "            return data",
            "        elif isinstance(event, Data) and self.state == State.DATA:",
            "            return event.data",
            "        elif isinstance(event, Epilogue):",
            "            self.state = State.COMPLETE",
            "            return b\"\\r\\n--\" + self.boundary + b\"--\\r\\n\" + event.data",
            "        else:",
            "            raise ValueError(f\"Cannot generate {event} in state: {self.state}\")"
        ],
        "afterPatchFile": [
            "import re",
            "from dataclasses import dataclass",
            "from enum import auto",
            "from enum import Enum",
            "from typing import cast",
            "from typing import List",
            "from typing import Optional",
            "from typing import Tuple",
            "",
            "from .._internal import _to_bytes",
            "from .._internal import _to_str",
            "from ..datastructures import Headers",
            "from ..exceptions import RequestEntityTooLarge",
            "from ..http import parse_options_header",
            "",
            "",
            "class Event:",
            "    pass",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Preamble(Event):",
            "    data: bytes",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Field(Event):",
            "    name: str",
            "    headers: Headers",
            "",
            "",
            "@dataclass(frozen=True)",
            "class File(Event):",
            "    name: str",
            "    filename: str",
            "    headers: Headers",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Data(Event):",
            "    data: bytes",
            "    more_data: bool",
            "",
            "",
            "@dataclass(frozen=True)",
            "class Epilogue(Event):",
            "    data: bytes",
            "",
            "",
            "class NeedData(Event):",
            "    pass",
            "",
            "",
            "NEED_DATA = NeedData()",
            "",
            "",
            "class State(Enum):",
            "    PREAMBLE = auto()",
            "    PART = auto()",
            "    DATA = auto()",
            "    EPILOGUE = auto()",
            "    COMPLETE = auto()",
            "",
            "",
            "# Multipart line breaks MUST be CRLF (\\r\\n) by RFC-7578, except that",
            "# many implementations break this and either use CR or LF alone.",
            "LINE_BREAK = b\"(?:\\r\\n|\\n|\\r)\"",
            "BLANK_LINE_RE = re.compile(b\"(?:\\r\\n\\r\\n|\\r\\r|\\n\\n)\", re.MULTILINE)",
            "LINE_BREAK_RE = re.compile(LINE_BREAK, re.MULTILINE)",
            "# Header values can be continued via a space or tab after the linebreak, as",
            "# per RFC2231",
            "HEADER_CONTINUATION_RE = re.compile(b\"%s[ \\t]\" % LINE_BREAK, re.MULTILINE)",
            "# This must be long enough to contain any line breaks plus any",
            "# additional boundary markers (--) such that they will be found in a",
            "# subsequent search",
            "SEARCH_EXTRA_LENGTH = 8",
            "",
            "",
            "class MultipartDecoder:",
            "    \"\"\"Decodes a multipart message as bytes into Python events.",
            "",
            "    The part data is returned as available to allow the caller to save",
            "    the data from memory to disk, if desired.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        boundary: bytes,",
            "        max_form_memory_size: Optional[int] = None,",
            "        *,",
            "        max_parts: Optional[int] = None,",
            "    ) -> None:",
            "        self.buffer = bytearray()",
            "        self.complete = False",
            "        self.max_form_memory_size = max_form_memory_size",
            "        self.max_parts = max_parts",
            "        self.state = State.PREAMBLE",
            "        self.boundary = boundary",
            "",
            "        # Note in the below \\h i.e. horizontal whitespace is used",
            "        # as [^\\S\\n\\r] as \\h isn't supported in python.",
            "",
            "        # The preamble must end with a boundary where the boundary is",
            "        # prefixed by a line break, RFC2046. Except that many",
            "        # implementations including Werkzeug's tests omit the line",
            "        # break prefix. In addition the first boundary could be the",
            "        # epilogue boundary (for empty form-data) hence the matching",
            "        # group to understand if it is an epilogue boundary.",
            "        self.preamble_re = re.compile(",
            "            rb\"%s?--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"",
            "            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),",
            "            re.MULTILINE,",
            "        )",
            "        # A boundary must include a line break prefix and suffix, and",
            "        # may include trailing whitespace. In addition the boundary",
            "        # could be the epilogue boundary hence the matching group to",
            "        # understand if it is an epilogue boundary.",
            "        self.boundary_re = re.compile(",
            "            rb\"%s--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"",
            "            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),",
            "            re.MULTILINE,",
            "        )",
            "        self._search_position = 0",
            "        self._parts_decoded = 0",
            "",
            "    def last_newline(self) -> int:",
            "        try:",
            "            last_nl = self.buffer.rindex(b\"\\n\")",
            "        except ValueError:",
            "            last_nl = len(self.buffer)",
            "        try:",
            "            last_cr = self.buffer.rindex(b\"\\r\")",
            "        except ValueError:",
            "            last_cr = len(self.buffer)",
            "",
            "        return min(last_nl, last_cr)",
            "",
            "    def receive_data(self, data: Optional[bytes]) -> None:",
            "        if data is None:",
            "            self.complete = True",
            "        elif (",
            "            self.max_form_memory_size is not None",
            "            and len(self.buffer) + len(data) > self.max_form_memory_size",
            "        ):",
            "            raise RequestEntityTooLarge()",
            "        else:",
            "            self.buffer.extend(data)",
            "",
            "    def next_event(self) -> Event:",
            "        event: Event = NEED_DATA",
            "",
            "        if self.state == State.PREAMBLE:",
            "            match = self.preamble_re.search(self.buffer, self._search_position)",
            "            if match is not None:",
            "                if match.group(1).startswith(b\"--\"):",
            "                    self.state = State.EPILOGUE",
            "                else:",
            "                    self.state = State.PART",
            "                data = bytes(self.buffer[: match.start()])",
            "                del self.buffer[: match.end()]",
            "                event = Preamble(data=data)",
            "                self._search_position = 0",
            "            else:",
            "                # Update the search start position to be equal to the",
            "                # current buffer length (already searched) minus a",
            "                # safe buffer for part of the search target.",
            "                self._search_position = max(",
            "                    0, len(self.buffer) - len(self.boundary) - SEARCH_EXTRA_LENGTH",
            "                )",
            "",
            "        elif self.state == State.PART:",
            "            match = BLANK_LINE_RE.search(self.buffer, self._search_position)",
            "            if match is not None:",
            "                headers = self._parse_headers(self.buffer[: match.start()])",
            "                del self.buffer[: match.end()]",
            "",
            "                if \"content-disposition\" not in headers:",
            "                    raise ValueError(\"Missing Content-Disposition header\")",
            "",
            "                disposition, extra = parse_options_header(",
            "                    headers[\"content-disposition\"]",
            "                )",
            "                name = cast(str, extra.get(\"name\"))",
            "                filename = extra.get(\"filename\")",
            "                if filename is not None:",
            "                    event = File(",
            "                        filename=filename,",
            "                        headers=headers,",
            "                        name=name,",
            "                    )",
            "                else:",
            "                    event = Field(",
            "                        headers=headers,",
            "                        name=name,",
            "                    )",
            "                self.state = State.DATA",
            "                self._search_position = 0",
            "                self._parts_decoded += 1",
            "",
            "                if self.max_parts is not None and self._parts_decoded > self.max_parts:",
            "                    raise RequestEntityTooLarge()",
            "            else:",
            "                # Update the search start position to be equal to the",
            "                # current buffer length (already searched) minus a",
            "                # safe buffer for part of the search target.",
            "                self._search_position = max(0, len(self.buffer) - SEARCH_EXTRA_LENGTH)",
            "",
            "        elif self.state == State.DATA:",
            "            if self.buffer.find(b\"--\" + self.boundary) == -1:",
            "                # No complete boundary in the buffer, but there may be",
            "                # a partial boundary at the end. As the boundary",
            "                # starts with either a nl or cr find the earliest and",
            "                # return up to that as data.",
            "                data_length = del_index = self.last_newline()",
            "                more_data = True",
            "            else:",
            "                match = self.boundary_re.search(self.buffer)",
            "                if match is not None:",
            "                    if match.group(1).startswith(b\"--\"):",
            "                        self.state = State.EPILOGUE",
            "                    else:",
            "                        self.state = State.PART",
            "                    data_length = match.start()",
            "                    del_index = match.end()",
            "                else:",
            "                    data_length = del_index = self.last_newline()",
            "                more_data = match is None",
            "",
            "            data = bytes(self.buffer[:data_length])",
            "            del self.buffer[:del_index]",
            "            if data or not more_data:",
            "                event = Data(data=data, more_data=more_data)",
            "",
            "        elif self.state == State.EPILOGUE and self.complete:",
            "            event = Epilogue(data=bytes(self.buffer))",
            "            del self.buffer[:]",
            "            self.state = State.COMPLETE",
            "",
            "        if self.complete and isinstance(event, NeedData):",
            "            raise ValueError(f\"Invalid form-data cannot parse beyond {self.state}\")",
            "",
            "        return event",
            "",
            "    def _parse_headers(self, data: bytes) -> Headers:",
            "        headers: List[Tuple[str, str]] = []",
            "        # Merge the continued headers into one line",
            "        data = HEADER_CONTINUATION_RE.sub(b\" \", data)",
            "        # Now there is one header per line",
            "        for line in data.splitlines():",
            "            if line.strip() != b\"\":",
            "                name, value = _to_str(line).strip().split(\":\", 1)",
            "                headers.append((name.strip(), value.strip()))",
            "        return Headers(headers)",
            "",
            "",
            "class MultipartEncoder:",
            "    def __init__(self, boundary: bytes) -> None:",
            "        self.boundary = boundary",
            "        self.state = State.PREAMBLE",
            "",
            "    def send_event(self, event: Event) -> bytes:",
            "        if isinstance(event, Preamble) and self.state == State.PREAMBLE:",
            "            self.state = State.PART",
            "            return event.data",
            "        elif isinstance(event, (Field, File)) and self.state in {",
            "            State.PREAMBLE,",
            "            State.PART,",
            "            State.DATA,",
            "        }:",
            "            self.state = State.DATA",
            "            data = b\"\\r\\n--\" + self.boundary + b\"\\r\\n\"",
            "            data += b'Content-Disposition: form-data; name=\"%s\"' % _to_bytes(event.name)",
            "            if isinstance(event, File):",
            "                data += b'; filename=\"%s\"' % _to_bytes(event.filename)",
            "            data += b\"\\r\\n\"",
            "            for name, value in cast(Field, event).headers:",
            "                if name.lower() != \"content-disposition\":",
            "                    data += _to_bytes(f\"{name}: {value}\\r\\n\")",
            "            data += b\"\\r\\n\"",
            "            return data",
            "        elif isinstance(event, Data) and self.state == State.DATA:",
            "            return event.data",
            "        elif isinstance(event, Epilogue):",
            "            self.state = State.COMPLETE",
            "            return b\"\\r\\n--\" + self.boundary + b\"--\\r\\n\" + event.data",
            "        else:",
            "            raise ValueError(f\"Cannot generate {event} in state: {self.state}\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.werkzeug.sansio.multipart.MultipartDecoder",
            "knowledge_repo.app.routes.comment"
        ]
    },
    "src/werkzeug/wrappers/request.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "     #: .. versionadded:: 0.5"
            },
            "1": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "     max_form_memory_size: t.Optional[int] = None"
            },
            "2": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 85,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 86,
                "PatchRowcode": "+    #: The maximum number of multipart parts to parse, passed to"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 87,
                "PatchRowcode": "+    #: :attr:`form_data_parser_class`. Parsing form data with more than this"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+    #: many parts will raise :exc:`~.RequestEntityTooLarge`."
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+    #:"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+    #: .. versionadded:: 2.2.3"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+    max_form_parts = 1000"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+"
            },
            "10": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "     #: The form data parser that should be used.  Can be replaced to customize"
            },
            "11": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "     #: the form date parsing."
            },
            "12": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "     form_data_parser_class: t.Type[FormDataParser] = FormDataParser"
            },
            "13": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": 253,
                "PatchRowcode": "             self.max_form_memory_size,"
            },
            "14": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": 254,
                "PatchRowcode": "             self.max_content_length,"
            },
            "15": {
                "beforePatchRowNumber": 248,
                "afterPatchRowNumber": 255,
                "PatchRowcode": "             self.parameter_storage_class,"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+            max_form_parts=self.max_form_parts,"
            },
            "17": {
                "beforePatchRowNumber": 249,
                "afterPatchRowNumber": 257,
                "PatchRowcode": "         )"
            },
            "18": {
                "beforePatchRowNumber": 250,
                "afterPatchRowNumber": 258,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 251,
                "afterPatchRowNumber": 259,
                "PatchRowcode": "     def _load_form_data(self) -> None:"
            }
        },
        "frontPatchFile": [
            "import functools",
            "import json",
            "import typing",
            "import typing as t",
            "from io import BytesIO",
            "",
            "from .._internal import _wsgi_decoding_dance",
            "from ..datastructures import CombinedMultiDict",
            "from ..datastructures import EnvironHeaders",
            "from ..datastructures import FileStorage",
            "from ..datastructures import ImmutableMultiDict",
            "from ..datastructures import iter_multi_items",
            "from ..datastructures import MultiDict",
            "from ..formparser import default_stream_factory",
            "from ..formparser import FormDataParser",
            "from ..sansio.request import Request as _SansIORequest",
            "from ..utils import cached_property",
            "from ..utils import environ_property",
            "from ..wsgi import _get_server",
            "from ..wsgi import get_input_stream",
            "from werkzeug.exceptions import BadRequest",
            "",
            "if t.TYPE_CHECKING:",
            "    import typing_extensions as te",
            "    from _typeshed.wsgi import WSGIApplication",
            "    from _typeshed.wsgi import WSGIEnvironment",
            "",
            "",
            "class Request(_SansIORequest):",
            "    \"\"\"Represents an incoming WSGI HTTP request, with headers and body",
            "    taken from the WSGI environment. Has properties and methods for",
            "    using the functionality defined by various HTTP specs. The data in",
            "    requests object is read-only.",
            "",
            "    Text data is assumed to use UTF-8 encoding, which should be true for",
            "    the vast majority of modern clients. Using an encoding set by the",
            "    client is unsafe in Python due to extra encodings it provides, such",
            "    as ``zip``. To change the assumed encoding, subclass and replace",
            "    :attr:`charset`.",
            "",
            "    :param environ: The WSGI environ is generated by the WSGI server and",
            "        contains information about the server configuration and client",
            "        request.",
            "    :param populate_request: Add this request object to the WSGI environ",
            "        as ``environ['werkzeug.request']``. Can be useful when",
            "        debugging.",
            "    :param shallow: Makes reading from :attr:`stream` (and any method",
            "        that would read from it) raise a :exc:`RuntimeError`. Useful to",
            "        prevent consuming the form data in middleware, which would make",
            "        it unavailable to the final application.",
            "",
            "    .. versionchanged:: 2.1",
            "        Remove the ``disable_data_descriptor`` attribute.",
            "",
            "    .. versionchanged:: 2.0",
            "        Combine ``BaseRequest`` and mixins into a single ``Request``",
            "        class. Using the old classes is deprecated and will be removed",
            "        in Werkzeug 2.1.",
            "",
            "    .. versionchanged:: 0.5",
            "        Read-only mode is enforced with immutable classes for all data.",
            "    \"\"\"",
            "",
            "    #: the maximum content length.  This is forwarded to the form data",
            "    #: parsing function (:func:`parse_form_data`).  When set and the",
            "    #: :attr:`form` or :attr:`files` attribute is accessed and the",
            "    #: parsing fails because more than the specified value is transmitted",
            "    #: a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.",
            "    #:",
            "    #: Have a look at :doc:`/request_data` for more details.",
            "    #:",
            "    #: .. versionadded:: 0.5",
            "    max_content_length: t.Optional[int] = None",
            "",
            "    #: the maximum form field size.  This is forwarded to the form data",
            "    #: parsing function (:func:`parse_form_data`).  When set and the",
            "    #: :attr:`form` or :attr:`files` attribute is accessed and the",
            "    #: data in memory for post data is longer than the specified value a",
            "    #: :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.",
            "    #:",
            "    #: Have a look at :doc:`/request_data` for more details.",
            "    #:",
            "    #: .. versionadded:: 0.5",
            "    max_form_memory_size: t.Optional[int] = None",
            "",
            "    #: The form data parser that should be used.  Can be replaced to customize",
            "    #: the form date parsing.",
            "    form_data_parser_class: t.Type[FormDataParser] = FormDataParser",
            "",
            "    #: The WSGI environment containing HTTP headers and information from",
            "    #: the WSGI server.",
            "    environ: \"WSGIEnvironment\"",
            "",
            "    #: Set when creating the request object. If ``True``, reading from",
            "    #: the request body will cause a ``RuntimeException``. Useful to",
            "    #: prevent modifying the stream from middleware.",
            "    shallow: bool",
            "",
            "    def __init__(",
            "        self,",
            "        environ: \"WSGIEnvironment\",",
            "        populate_request: bool = True,",
            "        shallow: bool = False,",
            "    ) -> None:",
            "        super().__init__(",
            "            method=environ.get(\"REQUEST_METHOD\", \"GET\"),",
            "            scheme=environ.get(\"wsgi.url_scheme\", \"http\"),",
            "            server=_get_server(environ),",
            "            root_path=_wsgi_decoding_dance(",
            "                environ.get(\"SCRIPT_NAME\") or \"\", self.charset, self.encoding_errors",
            "            ),",
            "            path=_wsgi_decoding_dance(",
            "                environ.get(\"PATH_INFO\") or \"\", self.charset, self.encoding_errors",
            "            ),",
            "            query_string=environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\"),",
            "            headers=EnvironHeaders(environ),",
            "            remote_addr=environ.get(\"REMOTE_ADDR\"),",
            "        )",
            "        self.environ = environ",
            "        self.shallow = shallow",
            "",
            "        if populate_request and not shallow:",
            "            self.environ[\"werkzeug.request\"] = self",
            "",
            "    @classmethod",
            "    def from_values(cls, *args: t.Any, **kwargs: t.Any) -> \"Request\":",
            "        \"\"\"Create a new request object based on the values provided.  If",
            "        environ is given missing values are filled from there.  This method is",
            "        useful for small scripts when you need to simulate a request from an URL.",
            "        Do not use this method for unittesting, there is a full featured client",
            "        object (:class:`Client`) that allows to create multipart requests,",
            "        support for cookies etc.",
            "",
            "        This accepts the same options as the",
            "        :class:`~werkzeug.test.EnvironBuilder`.",
            "",
            "        .. versionchanged:: 0.5",
            "           This method now accepts the same arguments as",
            "           :class:`~werkzeug.test.EnvironBuilder`.  Because of this the",
            "           `environ` parameter is now called `environ_overrides`.",
            "",
            "        :return: request object",
            "        \"\"\"",
            "        from ..test import EnvironBuilder",
            "",
            "        charset = kwargs.pop(\"charset\", cls.charset)",
            "        kwargs[\"charset\"] = charset",
            "        builder = EnvironBuilder(*args, **kwargs)",
            "        try:",
            "            return builder.get_request(cls)",
            "        finally:",
            "            builder.close()",
            "",
            "    @classmethod",
            "    def application(",
            "        cls, f: t.Callable[[\"Request\"], \"WSGIApplication\"]",
            "    ) -> \"WSGIApplication\":",
            "        \"\"\"Decorate a function as responder that accepts the request as",
            "        the last argument.  This works like the :func:`responder`",
            "        decorator but the function is passed the request object as the",
            "        last argument and the request object will be closed",
            "        automatically::",
            "",
            "            @Request.application",
            "            def my_wsgi_app(request):",
            "                return Response('Hello World!')",
            "",
            "        As of Werkzeug 0.14 HTTP exceptions are automatically caught and",
            "        converted to responses instead of failing.",
            "",
            "        :param f: the WSGI callable to decorate",
            "        :return: a new WSGI callable",
            "        \"\"\"",
            "        #: return a callable that wraps the -2nd argument with the request",
            "        #: and calls the function with all the arguments up to that one and",
            "        #: the request.  The return value is then called with the latest",
            "        #: two arguments.  This makes it possible to use this decorator for",
            "        #: both standalone WSGI functions as well as bound methods and",
            "        #: partially applied functions.",
            "        from ..exceptions import HTTPException",
            "",
            "        @functools.wraps(f)",
            "        def application(*args):  # type: ignore",
            "            request = cls(args[-2])",
            "            with request:",
            "                try:",
            "                    resp = f(*args[:-2] + (request,))",
            "                except HTTPException as e:",
            "                    resp = e.get_response(args[-2])",
            "                return resp(*args[-2:])",
            "",
            "        return t.cast(\"WSGIApplication\", application)",
            "",
            "    def _get_file_stream(",
            "        self,",
            "        total_content_length: t.Optional[int],",
            "        content_type: t.Optional[str],",
            "        filename: t.Optional[str] = None,",
            "        content_length: t.Optional[int] = None,",
            "    ) -> t.IO[bytes]:",
            "        \"\"\"Called to get a stream for the file upload.",
            "",
            "        This must provide a file-like class with `read()`, `readline()`",
            "        and `seek()` methods that is both writeable and readable.",
            "",
            "        The default implementation returns a temporary file if the total",
            "        content length is higher than 500KB.  Because many browsers do not",
            "        provide a content length for the files only the total content",
            "        length matters.",
            "",
            "        :param total_content_length: the total content length of all the",
            "                                     data in the request combined.  This value",
            "                                     is guaranteed to be there.",
            "        :param content_type: the mimetype of the uploaded file.",
            "        :param filename: the filename of the uploaded file.  May be `None`.",
            "        :param content_length: the length of this file.  This value is usually",
            "                               not provided because webbrowsers do not provide",
            "                               this value.",
            "        \"\"\"",
            "        return default_stream_factory(",
            "            total_content_length=total_content_length,",
            "            filename=filename,",
            "            content_type=content_type,",
            "            content_length=content_length,",
            "        )",
            "",
            "    @property",
            "    def want_form_data_parsed(self) -> bool:",
            "        \"\"\"``True`` if the request method carries content. By default",
            "        this is true if a ``Content-Type`` is sent.",
            "",
            "        .. versionadded:: 0.8",
            "        \"\"\"",
            "        return bool(self.environ.get(\"CONTENT_TYPE\"))",
            "",
            "    def make_form_data_parser(self) -> FormDataParser:",
            "        \"\"\"Creates the form data parser. Instantiates the",
            "        :attr:`form_data_parser_class` with some parameters.",
            "",
            "        .. versionadded:: 0.8",
            "        \"\"\"",
            "        return self.form_data_parser_class(",
            "            self._get_file_stream,",
            "            self.charset,",
            "            self.encoding_errors,",
            "            self.max_form_memory_size,",
            "            self.max_content_length,",
            "            self.parameter_storage_class,",
            "        )",
            "",
            "    def _load_form_data(self) -> None:",
            "        \"\"\"Method used internally to retrieve submitted data.  After calling",
            "        this sets `form` and `files` on the request object to multi dicts",
            "        filled with the incoming form data.  As a matter of fact the input",
            "        stream will be empty afterwards.  You can also call this method to",
            "        force the parsing of the form data.",
            "",
            "        .. versionadded:: 0.8",
            "        \"\"\"",
            "        # abort early if we have already consumed the stream",
            "        if \"form\" in self.__dict__:",
            "            return",
            "",
            "        if self.want_form_data_parsed:",
            "            parser = self.make_form_data_parser()",
            "            data = parser.parse(",
            "                self._get_stream_for_parsing(),",
            "                self.mimetype,",
            "                self.content_length,",
            "                self.mimetype_params,",
            "            )",
            "        else:",
            "            data = (",
            "                self.stream,",
            "                self.parameter_storage_class(),",
            "                self.parameter_storage_class(),",
            "            )",
            "",
            "        # inject the values into the instance dict so that we bypass",
            "        # our cached_property non-data descriptor.",
            "        d = self.__dict__",
            "        d[\"stream\"], d[\"form\"], d[\"files\"] = data",
            "",
            "    def _get_stream_for_parsing(self) -> t.IO[bytes]:",
            "        \"\"\"This is the same as accessing :attr:`stream` with the difference",
            "        that if it finds cached data from calling :meth:`get_data` first it",
            "        will create a new stream out of the cached data.",
            "",
            "        .. versionadded:: 0.9.3",
            "        \"\"\"",
            "        cached_data = getattr(self, \"_cached_data\", None)",
            "        if cached_data is not None:",
            "            return BytesIO(cached_data)",
            "        return self.stream",
            "",
            "    def close(self) -> None:",
            "        \"\"\"Closes associated resources of this request object.  This",
            "        closes all file handles explicitly.  You can also use the request",
            "        object in a with statement which will automatically close it.",
            "",
            "        .. versionadded:: 0.9",
            "        \"\"\"",
            "        files = self.__dict__.get(\"files\")",
            "        for _key, value in iter_multi_items(files or ()):",
            "            value.close()",
            "",
            "    def __enter__(self) -> \"Request\":",
            "        return self",
            "",
            "    def __exit__(self, exc_type, exc_value, tb) -> None:  # type: ignore",
            "        self.close()",
            "",
            "    @cached_property",
            "    def stream(self) -> t.IO[bytes]:",
            "        \"\"\"",
            "        If the incoming form data was not encoded with a known mimetype",
            "        the data is stored unmodified in this stream for consumption.  Most",
            "        of the time it is a better idea to use :attr:`data` which will give",
            "        you that data as a string.  The stream only returns the data once.",
            "",
            "        Unlike :attr:`input_stream` this stream is properly guarded that you",
            "        can't accidentally read past the length of the input.  Werkzeug will",
            "        internally always refer to this stream to read data which makes it",
            "        possible to wrap this object with a stream that does filtering.",
            "",
            "        .. versionchanged:: 0.9",
            "           This stream is now always available but might be consumed by the",
            "           form parser later on.  Previously the stream was only set if no",
            "           parsing happened.",
            "        \"\"\"",
            "        if self.shallow:",
            "            raise RuntimeError(",
            "                \"This request was created with 'shallow=True', reading\"",
            "                \" from the input stream is disabled.\"",
            "            )",
            "",
            "        return get_input_stream(self.environ)",
            "",
            "    input_stream = environ_property[t.IO[bytes]](",
            "        \"wsgi.input\",",
            "        doc=\"\"\"The WSGI input stream.",
            "",
            "        In general it's a bad idea to use this one because you can",
            "        easily read past the boundary.  Use the :attr:`stream`",
            "        instead.\"\"\",",
            "    )",
            "",
            "    @cached_property",
            "    def data(self) -> bytes:",
            "        \"\"\"",
            "        Contains the incoming request data as string in case it came with",
            "        a mimetype Werkzeug does not handle.",
            "        \"\"\"",
            "        return self.get_data(parse_form_data=True)",
            "",
            "    @typing.overload",
            "    def get_data(  # type: ignore",
            "        self,",
            "        cache: bool = True,",
            "        as_text: \"te.Literal[False]\" = False,",
            "        parse_form_data: bool = False,",
            "    ) -> bytes:",
            "        ...",
            "",
            "    @typing.overload",
            "    def get_data(",
            "        self,",
            "        cache: bool = True,",
            "        as_text: \"te.Literal[True]\" = ...,",
            "        parse_form_data: bool = False,",
            "    ) -> str:",
            "        ...",
            "",
            "    def get_data(",
            "        self, cache: bool = True, as_text: bool = False, parse_form_data: bool = False",
            "    ) -> t.Union[bytes, str]:",
            "        \"\"\"This reads the buffered incoming data from the client into one",
            "        bytes object.  By default this is cached but that behavior can be",
            "        changed by setting `cache` to `False`.",
            "",
            "        Usually it's a bad idea to call this method without checking the",
            "        content length first as a client could send dozens of megabytes or more",
            "        to cause memory problems on the server.",
            "",
            "        Note that if the form data was already parsed this method will not",
            "        return anything as form data parsing does not cache the data like",
            "        this method does.  To implicitly invoke form data parsing function",
            "        set `parse_form_data` to `True`.  When this is done the return value",
            "        of this method will be an empty string if the form parser handles",
            "        the data.  This generally is not necessary as if the whole data is",
            "        cached (which is the default) the form parser will used the cached",
            "        data to parse the form data.  Please be generally aware of checking",
            "        the content length first in any case before calling this method",
            "        to avoid exhausting server memory.",
            "",
            "        If `as_text` is set to `True` the return value will be a decoded",
            "        string.",
            "",
            "        .. versionadded:: 0.9",
            "        \"\"\"",
            "        rv = getattr(self, \"_cached_data\", None)",
            "        if rv is None:",
            "            if parse_form_data:",
            "                self._load_form_data()",
            "            rv = self.stream.read()",
            "            if cache:",
            "                self._cached_data = rv",
            "        if as_text:",
            "            rv = rv.decode(self.charset, self.encoding_errors)",
            "        return rv",
            "",
            "    @cached_property",
            "    def form(self) -> \"ImmutableMultiDict[str, str]\":",
            "        \"\"\"The form parameters.  By default an",
            "        :class:`~werkzeug.datastructures.ImmutableMultiDict`",
            "        is returned from this function.  This can be changed by setting",
            "        :attr:`parameter_storage_class` to a different type.  This might",
            "        be necessary if the order of the form data is important.",
            "",
            "        Please keep in mind that file uploads will not end up here, but instead",
            "        in the :attr:`files` attribute.",
            "",
            "        .. versionchanged:: 0.9",
            "",
            "            Previous to Werkzeug 0.9 this would only contain form data for POST",
            "            and PUT requests.",
            "        \"\"\"",
            "        self._load_form_data()",
            "        return self.form",
            "",
            "    @cached_property",
            "    def values(self) -> \"CombinedMultiDict[str, str]\":",
            "        \"\"\"A :class:`werkzeug.datastructures.CombinedMultiDict` that",
            "        combines :attr:`args` and :attr:`form`.",
            "",
            "        For GET requests, only ``args`` are present, not ``form``.",
            "",
            "        .. versionchanged:: 2.0",
            "            For GET requests, only ``args`` are present, not ``form``.",
            "        \"\"\"",
            "        sources = [self.args]",
            "",
            "        if self.method != \"GET\":",
            "            # GET requests can have a body, and some caching proxies",
            "            # might not treat that differently than a normal GET",
            "            # request, allowing form data to \"invisibly\" affect the",
            "            # cache without indication in the query string / URL.",
            "            sources.append(self.form)",
            "",
            "        args = []",
            "",
            "        for d in sources:",
            "            if not isinstance(d, MultiDict):",
            "                d = MultiDict(d)",
            "",
            "            args.append(d)",
            "",
            "        return CombinedMultiDict(args)",
            "",
            "    @cached_property",
            "    def files(self) -> \"ImmutableMultiDict[str, FileStorage]\":",
            "        \"\"\":class:`~werkzeug.datastructures.MultiDict` object containing",
            "        all uploaded files.  Each key in :attr:`files` is the name from the",
            "        ``<input type=\"file\" name=\"\">``.  Each value in :attr:`files` is a",
            "        Werkzeug :class:`~werkzeug.datastructures.FileStorage` object.",
            "",
            "        It basically behaves like a standard file object you know from Python,",
            "        with the difference that it also has a",
            "        :meth:`~werkzeug.datastructures.FileStorage.save` function that can",
            "        store the file on the filesystem.",
            "",
            "        Note that :attr:`files` will only contain data if the request method was",
            "        POST, PUT or PATCH and the ``<form>`` that posted to the request had",
            "        ``enctype=\"multipart/form-data\"``.  It will be empty otherwise.",
            "",
            "        See the :class:`~werkzeug.datastructures.MultiDict` /",
            "        :class:`~werkzeug.datastructures.FileStorage` documentation for",
            "        more details about the used data structure.",
            "        \"\"\"",
            "        self._load_form_data()",
            "        return self.files",
            "",
            "    @property",
            "    def script_root(self) -> str:",
            "        \"\"\"Alias for :attr:`self.root_path`. ``environ[\"SCRIPT_ROOT\"]``",
            "        without a trailing slash.",
            "        \"\"\"",
            "        return self.root_path",
            "",
            "    @cached_property",
            "    def url_root(self) -> str:",
            "        \"\"\"Alias for :attr:`root_url`. The URL with scheme, host, and",
            "        root path. For example, ``https://example.com/app/``.",
            "        \"\"\"",
            "        return self.root_url",
            "",
            "    remote_user = environ_property[str](",
            "        \"REMOTE_USER\",",
            "        doc=\"\"\"If the server supports user authentication, and the",
            "        script is protected, this attribute contains the username the",
            "        user has authenticated as.\"\"\",",
            "    )",
            "    is_multithread = environ_property[bool](",
            "        \"wsgi.multithread\",",
            "        doc=\"\"\"boolean that is `True` if the application is served by a",
            "        multithreaded WSGI server.\"\"\",",
            "    )",
            "    is_multiprocess = environ_property[bool](",
            "        \"wsgi.multiprocess\",",
            "        doc=\"\"\"boolean that is `True` if the application is served by a",
            "        WSGI server that spawns multiple processes.\"\"\",",
            "    )",
            "    is_run_once = environ_property[bool](",
            "        \"wsgi.run_once\",",
            "        doc=\"\"\"boolean that is `True` if the application will be",
            "        executed only once in a process lifetime.  This is the case for",
            "        CGI for example, but it's not guaranteed that the execution only",
            "        happens one time.\"\"\",",
            "    )",
            "",
            "    # JSON",
            "",
            "    #: A module or other object that has ``dumps`` and ``loads``",
            "    #: functions that match the API of the built-in :mod:`json` module.",
            "    json_module = json",
            "",
            "    @property",
            "    def json(self) -> t.Optional[t.Any]:",
            "        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON",
            "        (:mimetype:`application/json`, see :attr:`is_json`).",
            "",
            "        Calls :meth:`get_json` with default arguments.",
            "",
            "        If the request content type is not ``application/json``, this",
            "        will raise a 400 Bad Request error.",
            "",
            "        .. versionchanged:: 2.1",
            "            Raise a 400 error if the content type is incorrect.",
            "        \"\"\"",
            "        return self.get_json()",
            "",
            "    # Cached values for ``(silent=False, silent=True)``. Initialized",
            "    # with sentinel values.",
            "    _cached_json: t.Tuple[t.Any, t.Any] = (Ellipsis, Ellipsis)",
            "",
            "    @t.overload",
            "    def get_json(",
            "        self, force: bool = ..., silent: \"te.Literal[False]\" = ..., cache: bool = ...",
            "    ) -> t.Any:",
            "        ...",
            "",
            "    @t.overload",
            "    def get_json(",
            "        self, force: bool = ..., silent: bool = ..., cache: bool = ...",
            "    ) -> t.Optional[t.Any]:",
            "        ...",
            "",
            "    def get_json(",
            "        self, force: bool = False, silent: bool = False, cache: bool = True",
            "    ) -> t.Optional[t.Any]:",
            "        \"\"\"Parse :attr:`data` as JSON.",
            "",
            "        If the mimetype does not indicate JSON",
            "        (:mimetype:`application/json`, see :attr:`is_json`), or parsing",
            "        fails, :meth:`on_json_loading_failed` is called and",
            "        its return value is used as the return value. By default this",
            "        raises a 400 Bad Request error.",
            "",
            "        :param force: Ignore the mimetype and always try to parse JSON.",
            "        :param silent: Silence mimetype and parsing errors, and",
            "            return ``None`` instead.",
            "        :param cache: Store the parsed JSON to return for subsequent",
            "            calls.",
            "",
            "        .. versionchanged:: 2.1",
            "            Raise a 400 error if the content type is incorrect.",
            "        \"\"\"",
            "        if cache and self._cached_json[silent] is not Ellipsis:",
            "            return self._cached_json[silent]",
            "",
            "        if not (force or self.is_json):",
            "            if not silent:",
            "                return self.on_json_loading_failed(None)",
            "            else:",
            "                return None",
            "",
            "        data = self.get_data(cache=cache)",
            "",
            "        try:",
            "            rv = self.json_module.loads(data)",
            "        except ValueError as e:",
            "            if silent:",
            "                rv = None",
            "",
            "                if cache:",
            "                    normal_rv, _ = self._cached_json",
            "                    self._cached_json = (normal_rv, rv)",
            "            else:",
            "                rv = self.on_json_loading_failed(e)",
            "",
            "                if cache:",
            "                    _, silent_rv = self._cached_json",
            "                    self._cached_json = (rv, silent_rv)",
            "        else:",
            "            if cache:",
            "                self._cached_json = (rv, rv)",
            "",
            "        return rv",
            "",
            "    def on_json_loading_failed(self, e: t.Optional[ValueError]) -> t.Any:",
            "        \"\"\"Called if :meth:`get_json` fails and isn't silenced.",
            "",
            "        If this method returns a value, it is used as the return value",
            "        for :meth:`get_json`. The default implementation raises",
            "        :exc:`~werkzeug.exceptions.BadRequest`.",
            "",
            "        :param e: If parsing failed, this is the exception. It will be",
            "            ``None`` if the content type wasn't ``application/json``.",
            "        \"\"\"",
            "        if e is not None:",
            "            raise BadRequest(f\"Failed to decode JSON object: {e}\")",
            "",
            "        raise BadRequest(",
            "            \"Did not attempt to load JSON data because the request\"",
            "            \" Content-Type was not 'application/json'.\"",
            "        )"
        ],
        "afterPatchFile": [
            "import functools",
            "import json",
            "import typing",
            "import typing as t",
            "from io import BytesIO",
            "",
            "from .._internal import _wsgi_decoding_dance",
            "from ..datastructures import CombinedMultiDict",
            "from ..datastructures import EnvironHeaders",
            "from ..datastructures import FileStorage",
            "from ..datastructures import ImmutableMultiDict",
            "from ..datastructures import iter_multi_items",
            "from ..datastructures import MultiDict",
            "from ..formparser import default_stream_factory",
            "from ..formparser import FormDataParser",
            "from ..sansio.request import Request as _SansIORequest",
            "from ..utils import cached_property",
            "from ..utils import environ_property",
            "from ..wsgi import _get_server",
            "from ..wsgi import get_input_stream",
            "from werkzeug.exceptions import BadRequest",
            "",
            "if t.TYPE_CHECKING:",
            "    import typing_extensions as te",
            "    from _typeshed.wsgi import WSGIApplication",
            "    from _typeshed.wsgi import WSGIEnvironment",
            "",
            "",
            "class Request(_SansIORequest):",
            "    \"\"\"Represents an incoming WSGI HTTP request, with headers and body",
            "    taken from the WSGI environment. Has properties and methods for",
            "    using the functionality defined by various HTTP specs. The data in",
            "    requests object is read-only.",
            "",
            "    Text data is assumed to use UTF-8 encoding, which should be true for",
            "    the vast majority of modern clients. Using an encoding set by the",
            "    client is unsafe in Python due to extra encodings it provides, such",
            "    as ``zip``. To change the assumed encoding, subclass and replace",
            "    :attr:`charset`.",
            "",
            "    :param environ: The WSGI environ is generated by the WSGI server and",
            "        contains information about the server configuration and client",
            "        request.",
            "    :param populate_request: Add this request object to the WSGI environ",
            "        as ``environ['werkzeug.request']``. Can be useful when",
            "        debugging.",
            "    :param shallow: Makes reading from :attr:`stream` (and any method",
            "        that would read from it) raise a :exc:`RuntimeError`. Useful to",
            "        prevent consuming the form data in middleware, which would make",
            "        it unavailable to the final application.",
            "",
            "    .. versionchanged:: 2.1",
            "        Remove the ``disable_data_descriptor`` attribute.",
            "",
            "    .. versionchanged:: 2.0",
            "        Combine ``BaseRequest`` and mixins into a single ``Request``",
            "        class. Using the old classes is deprecated and will be removed",
            "        in Werkzeug 2.1.",
            "",
            "    .. versionchanged:: 0.5",
            "        Read-only mode is enforced with immutable classes for all data.",
            "    \"\"\"",
            "",
            "    #: the maximum content length.  This is forwarded to the form data",
            "    #: parsing function (:func:`parse_form_data`).  When set and the",
            "    #: :attr:`form` or :attr:`files` attribute is accessed and the",
            "    #: parsing fails because more than the specified value is transmitted",
            "    #: a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.",
            "    #:",
            "    #: Have a look at :doc:`/request_data` for more details.",
            "    #:",
            "    #: .. versionadded:: 0.5",
            "    max_content_length: t.Optional[int] = None",
            "",
            "    #: the maximum form field size.  This is forwarded to the form data",
            "    #: parsing function (:func:`parse_form_data`).  When set and the",
            "    #: :attr:`form` or :attr:`files` attribute is accessed and the",
            "    #: data in memory for post data is longer than the specified value a",
            "    #: :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.",
            "    #:",
            "    #: Have a look at :doc:`/request_data` for more details.",
            "    #:",
            "    #: .. versionadded:: 0.5",
            "    max_form_memory_size: t.Optional[int] = None",
            "",
            "    #: The maximum number of multipart parts to parse, passed to",
            "    #: :attr:`form_data_parser_class`. Parsing form data with more than this",
            "    #: many parts will raise :exc:`~.RequestEntityTooLarge`.",
            "    #:",
            "    #: .. versionadded:: 2.2.3",
            "    max_form_parts = 1000",
            "",
            "    #: The form data parser that should be used.  Can be replaced to customize",
            "    #: the form date parsing.",
            "    form_data_parser_class: t.Type[FormDataParser] = FormDataParser",
            "",
            "    #: The WSGI environment containing HTTP headers and information from",
            "    #: the WSGI server.",
            "    environ: \"WSGIEnvironment\"",
            "",
            "    #: Set when creating the request object. If ``True``, reading from",
            "    #: the request body will cause a ``RuntimeException``. Useful to",
            "    #: prevent modifying the stream from middleware.",
            "    shallow: bool",
            "",
            "    def __init__(",
            "        self,",
            "        environ: \"WSGIEnvironment\",",
            "        populate_request: bool = True,",
            "        shallow: bool = False,",
            "    ) -> None:",
            "        super().__init__(",
            "            method=environ.get(\"REQUEST_METHOD\", \"GET\"),",
            "            scheme=environ.get(\"wsgi.url_scheme\", \"http\"),",
            "            server=_get_server(environ),",
            "            root_path=_wsgi_decoding_dance(",
            "                environ.get(\"SCRIPT_NAME\") or \"\", self.charset, self.encoding_errors",
            "            ),",
            "            path=_wsgi_decoding_dance(",
            "                environ.get(\"PATH_INFO\") or \"\", self.charset, self.encoding_errors",
            "            ),",
            "            query_string=environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\"),",
            "            headers=EnvironHeaders(environ),",
            "            remote_addr=environ.get(\"REMOTE_ADDR\"),",
            "        )",
            "        self.environ = environ",
            "        self.shallow = shallow",
            "",
            "        if populate_request and not shallow:",
            "            self.environ[\"werkzeug.request\"] = self",
            "",
            "    @classmethod",
            "    def from_values(cls, *args: t.Any, **kwargs: t.Any) -> \"Request\":",
            "        \"\"\"Create a new request object based on the values provided.  If",
            "        environ is given missing values are filled from there.  This method is",
            "        useful for small scripts when you need to simulate a request from an URL.",
            "        Do not use this method for unittesting, there is a full featured client",
            "        object (:class:`Client`) that allows to create multipart requests,",
            "        support for cookies etc.",
            "",
            "        This accepts the same options as the",
            "        :class:`~werkzeug.test.EnvironBuilder`.",
            "",
            "        .. versionchanged:: 0.5",
            "           This method now accepts the same arguments as",
            "           :class:`~werkzeug.test.EnvironBuilder`.  Because of this the",
            "           `environ` parameter is now called `environ_overrides`.",
            "",
            "        :return: request object",
            "        \"\"\"",
            "        from ..test import EnvironBuilder",
            "",
            "        charset = kwargs.pop(\"charset\", cls.charset)",
            "        kwargs[\"charset\"] = charset",
            "        builder = EnvironBuilder(*args, **kwargs)",
            "        try:",
            "            return builder.get_request(cls)",
            "        finally:",
            "            builder.close()",
            "",
            "    @classmethod",
            "    def application(",
            "        cls, f: t.Callable[[\"Request\"], \"WSGIApplication\"]",
            "    ) -> \"WSGIApplication\":",
            "        \"\"\"Decorate a function as responder that accepts the request as",
            "        the last argument.  This works like the :func:`responder`",
            "        decorator but the function is passed the request object as the",
            "        last argument and the request object will be closed",
            "        automatically::",
            "",
            "            @Request.application",
            "            def my_wsgi_app(request):",
            "                return Response('Hello World!')",
            "",
            "        As of Werkzeug 0.14 HTTP exceptions are automatically caught and",
            "        converted to responses instead of failing.",
            "",
            "        :param f: the WSGI callable to decorate",
            "        :return: a new WSGI callable",
            "        \"\"\"",
            "        #: return a callable that wraps the -2nd argument with the request",
            "        #: and calls the function with all the arguments up to that one and",
            "        #: the request.  The return value is then called with the latest",
            "        #: two arguments.  This makes it possible to use this decorator for",
            "        #: both standalone WSGI functions as well as bound methods and",
            "        #: partially applied functions.",
            "        from ..exceptions import HTTPException",
            "",
            "        @functools.wraps(f)",
            "        def application(*args):  # type: ignore",
            "            request = cls(args[-2])",
            "            with request:",
            "                try:",
            "                    resp = f(*args[:-2] + (request,))",
            "                except HTTPException as e:",
            "                    resp = e.get_response(args[-2])",
            "                return resp(*args[-2:])",
            "",
            "        return t.cast(\"WSGIApplication\", application)",
            "",
            "    def _get_file_stream(",
            "        self,",
            "        total_content_length: t.Optional[int],",
            "        content_type: t.Optional[str],",
            "        filename: t.Optional[str] = None,",
            "        content_length: t.Optional[int] = None,",
            "    ) -> t.IO[bytes]:",
            "        \"\"\"Called to get a stream for the file upload.",
            "",
            "        This must provide a file-like class with `read()`, `readline()`",
            "        and `seek()` methods that is both writeable and readable.",
            "",
            "        The default implementation returns a temporary file if the total",
            "        content length is higher than 500KB.  Because many browsers do not",
            "        provide a content length for the files only the total content",
            "        length matters.",
            "",
            "        :param total_content_length: the total content length of all the",
            "                                     data in the request combined.  This value",
            "                                     is guaranteed to be there.",
            "        :param content_type: the mimetype of the uploaded file.",
            "        :param filename: the filename of the uploaded file.  May be `None`.",
            "        :param content_length: the length of this file.  This value is usually",
            "                               not provided because webbrowsers do not provide",
            "                               this value.",
            "        \"\"\"",
            "        return default_stream_factory(",
            "            total_content_length=total_content_length,",
            "            filename=filename,",
            "            content_type=content_type,",
            "            content_length=content_length,",
            "        )",
            "",
            "    @property",
            "    def want_form_data_parsed(self) -> bool:",
            "        \"\"\"``True`` if the request method carries content. By default",
            "        this is true if a ``Content-Type`` is sent.",
            "",
            "        .. versionadded:: 0.8",
            "        \"\"\"",
            "        return bool(self.environ.get(\"CONTENT_TYPE\"))",
            "",
            "    def make_form_data_parser(self) -> FormDataParser:",
            "        \"\"\"Creates the form data parser. Instantiates the",
            "        :attr:`form_data_parser_class` with some parameters.",
            "",
            "        .. versionadded:: 0.8",
            "        \"\"\"",
            "        return self.form_data_parser_class(",
            "            self._get_file_stream,",
            "            self.charset,",
            "            self.encoding_errors,",
            "            self.max_form_memory_size,",
            "            self.max_content_length,",
            "            self.parameter_storage_class,",
            "            max_form_parts=self.max_form_parts,",
            "        )",
            "",
            "    def _load_form_data(self) -> None:",
            "        \"\"\"Method used internally to retrieve submitted data.  After calling",
            "        this sets `form` and `files` on the request object to multi dicts",
            "        filled with the incoming form data.  As a matter of fact the input",
            "        stream will be empty afterwards.  You can also call this method to",
            "        force the parsing of the form data.",
            "",
            "        .. versionadded:: 0.8",
            "        \"\"\"",
            "        # abort early if we have already consumed the stream",
            "        if \"form\" in self.__dict__:",
            "            return",
            "",
            "        if self.want_form_data_parsed:",
            "            parser = self.make_form_data_parser()",
            "            data = parser.parse(",
            "                self._get_stream_for_parsing(),",
            "                self.mimetype,",
            "                self.content_length,",
            "                self.mimetype_params,",
            "            )",
            "        else:",
            "            data = (",
            "                self.stream,",
            "                self.parameter_storage_class(),",
            "                self.parameter_storage_class(),",
            "            )",
            "",
            "        # inject the values into the instance dict so that we bypass",
            "        # our cached_property non-data descriptor.",
            "        d = self.__dict__",
            "        d[\"stream\"], d[\"form\"], d[\"files\"] = data",
            "",
            "    def _get_stream_for_parsing(self) -> t.IO[bytes]:",
            "        \"\"\"This is the same as accessing :attr:`stream` with the difference",
            "        that if it finds cached data from calling :meth:`get_data` first it",
            "        will create a new stream out of the cached data.",
            "",
            "        .. versionadded:: 0.9.3",
            "        \"\"\"",
            "        cached_data = getattr(self, \"_cached_data\", None)",
            "        if cached_data is not None:",
            "            return BytesIO(cached_data)",
            "        return self.stream",
            "",
            "    def close(self) -> None:",
            "        \"\"\"Closes associated resources of this request object.  This",
            "        closes all file handles explicitly.  You can also use the request",
            "        object in a with statement which will automatically close it.",
            "",
            "        .. versionadded:: 0.9",
            "        \"\"\"",
            "        files = self.__dict__.get(\"files\")",
            "        for _key, value in iter_multi_items(files or ()):",
            "            value.close()",
            "",
            "    def __enter__(self) -> \"Request\":",
            "        return self",
            "",
            "    def __exit__(self, exc_type, exc_value, tb) -> None:  # type: ignore",
            "        self.close()",
            "",
            "    @cached_property",
            "    def stream(self) -> t.IO[bytes]:",
            "        \"\"\"",
            "        If the incoming form data was not encoded with a known mimetype",
            "        the data is stored unmodified in this stream for consumption.  Most",
            "        of the time it is a better idea to use :attr:`data` which will give",
            "        you that data as a string.  The stream only returns the data once.",
            "",
            "        Unlike :attr:`input_stream` this stream is properly guarded that you",
            "        can't accidentally read past the length of the input.  Werkzeug will",
            "        internally always refer to this stream to read data which makes it",
            "        possible to wrap this object with a stream that does filtering.",
            "",
            "        .. versionchanged:: 0.9",
            "           This stream is now always available but might be consumed by the",
            "           form parser later on.  Previously the stream was only set if no",
            "           parsing happened.",
            "        \"\"\"",
            "        if self.shallow:",
            "            raise RuntimeError(",
            "                \"This request was created with 'shallow=True', reading\"",
            "                \" from the input stream is disabled.\"",
            "            )",
            "",
            "        return get_input_stream(self.environ)",
            "",
            "    input_stream = environ_property[t.IO[bytes]](",
            "        \"wsgi.input\",",
            "        doc=\"\"\"The WSGI input stream.",
            "",
            "        In general it's a bad idea to use this one because you can",
            "        easily read past the boundary.  Use the :attr:`stream`",
            "        instead.\"\"\",",
            "    )",
            "",
            "    @cached_property",
            "    def data(self) -> bytes:",
            "        \"\"\"",
            "        Contains the incoming request data as string in case it came with",
            "        a mimetype Werkzeug does not handle.",
            "        \"\"\"",
            "        return self.get_data(parse_form_data=True)",
            "",
            "    @typing.overload",
            "    def get_data(  # type: ignore",
            "        self,",
            "        cache: bool = True,",
            "        as_text: \"te.Literal[False]\" = False,",
            "        parse_form_data: bool = False,",
            "    ) -> bytes:",
            "        ...",
            "",
            "    @typing.overload",
            "    def get_data(",
            "        self,",
            "        cache: bool = True,",
            "        as_text: \"te.Literal[True]\" = ...,",
            "        parse_form_data: bool = False,",
            "    ) -> str:",
            "        ...",
            "",
            "    def get_data(",
            "        self, cache: bool = True, as_text: bool = False, parse_form_data: bool = False",
            "    ) -> t.Union[bytes, str]:",
            "        \"\"\"This reads the buffered incoming data from the client into one",
            "        bytes object.  By default this is cached but that behavior can be",
            "        changed by setting `cache` to `False`.",
            "",
            "        Usually it's a bad idea to call this method without checking the",
            "        content length first as a client could send dozens of megabytes or more",
            "        to cause memory problems on the server.",
            "",
            "        Note that if the form data was already parsed this method will not",
            "        return anything as form data parsing does not cache the data like",
            "        this method does.  To implicitly invoke form data parsing function",
            "        set `parse_form_data` to `True`.  When this is done the return value",
            "        of this method will be an empty string if the form parser handles",
            "        the data.  This generally is not necessary as if the whole data is",
            "        cached (which is the default) the form parser will used the cached",
            "        data to parse the form data.  Please be generally aware of checking",
            "        the content length first in any case before calling this method",
            "        to avoid exhausting server memory.",
            "",
            "        If `as_text` is set to `True` the return value will be a decoded",
            "        string.",
            "",
            "        .. versionadded:: 0.9",
            "        \"\"\"",
            "        rv = getattr(self, \"_cached_data\", None)",
            "        if rv is None:",
            "            if parse_form_data:",
            "                self._load_form_data()",
            "            rv = self.stream.read()",
            "            if cache:",
            "                self._cached_data = rv",
            "        if as_text:",
            "            rv = rv.decode(self.charset, self.encoding_errors)",
            "        return rv",
            "",
            "    @cached_property",
            "    def form(self) -> \"ImmutableMultiDict[str, str]\":",
            "        \"\"\"The form parameters.  By default an",
            "        :class:`~werkzeug.datastructures.ImmutableMultiDict`",
            "        is returned from this function.  This can be changed by setting",
            "        :attr:`parameter_storage_class` to a different type.  This might",
            "        be necessary if the order of the form data is important.",
            "",
            "        Please keep in mind that file uploads will not end up here, but instead",
            "        in the :attr:`files` attribute.",
            "",
            "        .. versionchanged:: 0.9",
            "",
            "            Previous to Werkzeug 0.9 this would only contain form data for POST",
            "            and PUT requests.",
            "        \"\"\"",
            "        self._load_form_data()",
            "        return self.form",
            "",
            "    @cached_property",
            "    def values(self) -> \"CombinedMultiDict[str, str]\":",
            "        \"\"\"A :class:`werkzeug.datastructures.CombinedMultiDict` that",
            "        combines :attr:`args` and :attr:`form`.",
            "",
            "        For GET requests, only ``args`` are present, not ``form``.",
            "",
            "        .. versionchanged:: 2.0",
            "            For GET requests, only ``args`` are present, not ``form``.",
            "        \"\"\"",
            "        sources = [self.args]",
            "",
            "        if self.method != \"GET\":",
            "            # GET requests can have a body, and some caching proxies",
            "            # might not treat that differently than a normal GET",
            "            # request, allowing form data to \"invisibly\" affect the",
            "            # cache without indication in the query string / URL.",
            "            sources.append(self.form)",
            "",
            "        args = []",
            "",
            "        for d in sources:",
            "            if not isinstance(d, MultiDict):",
            "                d = MultiDict(d)",
            "",
            "            args.append(d)",
            "",
            "        return CombinedMultiDict(args)",
            "",
            "    @cached_property",
            "    def files(self) -> \"ImmutableMultiDict[str, FileStorage]\":",
            "        \"\"\":class:`~werkzeug.datastructures.MultiDict` object containing",
            "        all uploaded files.  Each key in :attr:`files` is the name from the",
            "        ``<input type=\"file\" name=\"\">``.  Each value in :attr:`files` is a",
            "        Werkzeug :class:`~werkzeug.datastructures.FileStorage` object.",
            "",
            "        It basically behaves like a standard file object you know from Python,",
            "        with the difference that it also has a",
            "        :meth:`~werkzeug.datastructures.FileStorage.save` function that can",
            "        store the file on the filesystem.",
            "",
            "        Note that :attr:`files` will only contain data if the request method was",
            "        POST, PUT or PATCH and the ``<form>`` that posted to the request had",
            "        ``enctype=\"multipart/form-data\"``.  It will be empty otherwise.",
            "",
            "        See the :class:`~werkzeug.datastructures.MultiDict` /",
            "        :class:`~werkzeug.datastructures.FileStorage` documentation for",
            "        more details about the used data structure.",
            "        \"\"\"",
            "        self._load_form_data()",
            "        return self.files",
            "",
            "    @property",
            "    def script_root(self) -> str:",
            "        \"\"\"Alias for :attr:`self.root_path`. ``environ[\"SCRIPT_ROOT\"]``",
            "        without a trailing slash.",
            "        \"\"\"",
            "        return self.root_path",
            "",
            "    @cached_property",
            "    def url_root(self) -> str:",
            "        \"\"\"Alias for :attr:`root_url`. The URL with scheme, host, and",
            "        root path. For example, ``https://example.com/app/``.",
            "        \"\"\"",
            "        return self.root_url",
            "",
            "    remote_user = environ_property[str](",
            "        \"REMOTE_USER\",",
            "        doc=\"\"\"If the server supports user authentication, and the",
            "        script is protected, this attribute contains the username the",
            "        user has authenticated as.\"\"\",",
            "    )",
            "    is_multithread = environ_property[bool](",
            "        \"wsgi.multithread\",",
            "        doc=\"\"\"boolean that is `True` if the application is served by a",
            "        multithreaded WSGI server.\"\"\",",
            "    )",
            "    is_multiprocess = environ_property[bool](",
            "        \"wsgi.multiprocess\",",
            "        doc=\"\"\"boolean that is `True` if the application is served by a",
            "        WSGI server that spawns multiple processes.\"\"\",",
            "    )",
            "    is_run_once = environ_property[bool](",
            "        \"wsgi.run_once\",",
            "        doc=\"\"\"boolean that is `True` if the application will be",
            "        executed only once in a process lifetime.  This is the case for",
            "        CGI for example, but it's not guaranteed that the execution only",
            "        happens one time.\"\"\",",
            "    )",
            "",
            "    # JSON",
            "",
            "    #: A module or other object that has ``dumps`` and ``loads``",
            "    #: functions that match the API of the built-in :mod:`json` module.",
            "    json_module = json",
            "",
            "    @property",
            "    def json(self) -> t.Optional[t.Any]:",
            "        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON",
            "        (:mimetype:`application/json`, see :attr:`is_json`).",
            "",
            "        Calls :meth:`get_json` with default arguments.",
            "",
            "        If the request content type is not ``application/json``, this",
            "        will raise a 400 Bad Request error.",
            "",
            "        .. versionchanged:: 2.1",
            "            Raise a 400 error if the content type is incorrect.",
            "        \"\"\"",
            "        return self.get_json()",
            "",
            "    # Cached values for ``(silent=False, silent=True)``. Initialized",
            "    # with sentinel values.",
            "    _cached_json: t.Tuple[t.Any, t.Any] = (Ellipsis, Ellipsis)",
            "",
            "    @t.overload",
            "    def get_json(",
            "        self, force: bool = ..., silent: \"te.Literal[False]\" = ..., cache: bool = ...",
            "    ) -> t.Any:",
            "        ...",
            "",
            "    @t.overload",
            "    def get_json(",
            "        self, force: bool = ..., silent: bool = ..., cache: bool = ...",
            "    ) -> t.Optional[t.Any]:",
            "        ...",
            "",
            "    def get_json(",
            "        self, force: bool = False, silent: bool = False, cache: bool = True",
            "    ) -> t.Optional[t.Any]:",
            "        \"\"\"Parse :attr:`data` as JSON.",
            "",
            "        If the mimetype does not indicate JSON",
            "        (:mimetype:`application/json`, see :attr:`is_json`), or parsing",
            "        fails, :meth:`on_json_loading_failed` is called and",
            "        its return value is used as the return value. By default this",
            "        raises a 400 Bad Request error.",
            "",
            "        :param force: Ignore the mimetype and always try to parse JSON.",
            "        :param silent: Silence mimetype and parsing errors, and",
            "            return ``None`` instead.",
            "        :param cache: Store the parsed JSON to return for subsequent",
            "            calls.",
            "",
            "        .. versionchanged:: 2.1",
            "            Raise a 400 error if the content type is incorrect.",
            "        \"\"\"",
            "        if cache and self._cached_json[silent] is not Ellipsis:",
            "            return self._cached_json[silent]",
            "",
            "        if not (force or self.is_json):",
            "            if not silent:",
            "                return self.on_json_loading_failed(None)",
            "            else:",
            "                return None",
            "",
            "        data = self.get_data(cache=cache)",
            "",
            "        try:",
            "            rv = self.json_module.loads(data)",
            "        except ValueError as e:",
            "            if silent:",
            "                rv = None",
            "",
            "                if cache:",
            "                    normal_rv, _ = self._cached_json",
            "                    self._cached_json = (normal_rv, rv)",
            "            else:",
            "                rv = self.on_json_loading_failed(e)",
            "",
            "                if cache:",
            "                    _, silent_rv = self._cached_json",
            "                    self._cached_json = (rv, silent_rv)",
            "        else:",
            "            if cache:",
            "                self._cached_json = (rv, rv)",
            "",
            "        return rv",
            "",
            "    def on_json_loading_failed(self, e: t.Optional[ValueError]) -> t.Any:",
            "        \"\"\"Called if :meth:`get_json` fails and isn't silenced.",
            "",
            "        If this method returns a value, it is used as the return value",
            "        for :meth:`get_json`. The default implementation raises",
            "        :exc:`~werkzeug.exceptions.BadRequest`.",
            "",
            "        :param e: If parsing failed, this is the exception. It will be",
            "            ``None`` if the content type wasn't ``application/json``.",
            "        \"\"\"",
            "        if e is not None:",
            "            raise BadRequest(f\"Failed to decode JSON object: {e}\")",
            "",
            "        raise BadRequest(",
            "            \"Did not attempt to load JSON data because the request\"",
            "            \" Content-Type was not 'application/json'.\"",
            "        )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.werkzeug.wrappers.request._SansIORequest",
            "src.werkzeug.wrappers.request",
            "src.werkzeug.wrappers.request.Request._load_form_data",
            "src.werkzeug.wrappers.request.Request.self",
            "knowledge_repo.app.routes.comment",
            "src.werkzeug.wrappers.request.Request",
            "src.werkzeug.wrappers.request.Request.__enter__"
        ]
    }
}