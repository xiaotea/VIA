{
    "indy_common/test/test_util.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1,
                "PatchRowcode": "+import pytest"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+"
            },
            "2": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from operator import itemgetter"
            },
            "3": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from indy_common.util import getIndex"
            },
            "4": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 5,
                "PatchRowcode": "+from indy_common.util import compose_cmd"
            },
            "6": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " def test_getIndex():"
            },
            "8": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 8,
                "PatchRowcode": "     items = [('a', {'key1': 1}), ('b', {'key2': 2})]"
            },
            "9": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 14,
                "PatchRowcode": "     assert 0 == getIndex(containsKey('key1'), items)"
            },
            "10": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 15,
                "PatchRowcode": "     assert 1 == getIndex(containsKey('key2'), items)"
            },
            "11": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 16,
                "PatchRowcode": "     assert -1 == getIndex(containsKey('key3'), items)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 17,
                "PatchRowcode": "+"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+@pytest.mark.parametrize("
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+    'pkg_name,package',"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+    ["
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+        pytest.param('some_package', 'some_package', id='some_package'),"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+        pytest.param('package_1', 'package_1;echo \"hi\"&&echo \"hello\"\\necho \"hello world!\"', id='strips mixed cmd concat'),"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+        pytest.param('package_3', 'package_3;echo \"hey\"', id='strips semi-colon cmd concat'),"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+        pytest.param('package_4', 'package_4&&echo \"hey\"', id='strips and cmd concat'),"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+        pytest.param('package_5', 'package_5\\necho \"hey\"', id='strips Cr cmd concat'),"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+    ]"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+def test_compose_cmd(pkg_name, package):"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+    expected_cmd = f'dpkg -s {pkg_name}'"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+    cmd = compose_cmd(['dpkg', '-s', package])"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+    assert expected_cmd == cmd"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+def test_compose_cmd_allows_whitespace():"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+    pkg_name = 'package_7 some_other_package'"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+    expected_cmd = f'dpkg -s {pkg_name}'"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+    cmd = compose_cmd(['dpkg', '-s', pkg_name])"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+    assert expected_cmd == cmd"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+def test_compose_cmd_allows_pipe():"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+    expected_cmd = 'dpkg --get-selections | grep -v deinstall | cut -f1'"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+    cmd = compose_cmd("
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+        ['dpkg', '--get-selections', '|', 'grep', '-v', 'deinstall', '|', 'cut', '-f1']"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+    )"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+    assert expected_cmd == cmd"
            }
        },
        "frontPatchFile": [
            "from operator import itemgetter",
            "from indy_common.util import getIndex",
            "",
            "",
            "def test_getIndex():",
            "    items = [('a', {'key1': 1}), ('b', {'key2': 2})]",
            "    getDict = itemgetter(1)",
            "",
            "    def containsKey(key):",
            "        return lambda x: key in getDict(x)",
            "",
            "    assert 0 == getIndex(containsKey('key1'), items)",
            "    assert 1 == getIndex(containsKey('key2'), items)",
            "    assert -1 == getIndex(containsKey('key3'), items)"
        ],
        "afterPatchFile": [
            "import pytest",
            "",
            "from operator import itemgetter",
            "from indy_common.util import getIndex",
            "from indy_common.util import compose_cmd",
            "",
            "def test_getIndex():",
            "    items = [('a', {'key1': 1}), ('b', {'key2': 2})]",
            "    getDict = itemgetter(1)",
            "",
            "    def containsKey(key):",
            "        return lambda x: key in getDict(x)",
            "",
            "    assert 0 == getIndex(containsKey('key1'), items)",
            "    assert 1 == getIndex(containsKey('key2'), items)",
            "    assert -1 == getIndex(containsKey('key3'), items)",
            "",
            "@pytest.mark.parametrize(",
            "    'pkg_name,package',",
            "    [",
            "        pytest.param('some_package', 'some_package', id='some_package'),",
            "        pytest.param('package_1', 'package_1;echo \"hi\"&&echo \"hello\"\\necho \"hello world!\"', id='strips mixed cmd concat'),",
            "        pytest.param('package_3', 'package_3;echo \"hey\"', id='strips semi-colon cmd concat'),",
            "        pytest.param('package_4', 'package_4&&echo \"hey\"', id='strips and cmd concat'),",
            "        pytest.param('package_5', 'package_5\\necho \"hey\"', id='strips Cr cmd concat'),",
            "    ]",
            ")",
            "def test_compose_cmd(pkg_name, package):",
            "    expected_cmd = f'dpkg -s {pkg_name}'",
            "",
            "    cmd = compose_cmd(['dpkg', '-s', package])",
            "    assert expected_cmd == cmd",
            "",
            "def test_compose_cmd_allows_whitespace():",
            "    pkg_name = 'package_7 some_other_package'",
            "    expected_cmd = f'dpkg -s {pkg_name}'",
            "    cmd = compose_cmd(['dpkg', '-s', pkg_name])",
            "    assert expected_cmd == cmd",
            "",
            "def test_compose_cmd_allows_pipe():",
            "    expected_cmd = 'dpkg --get-selections | grep -v deinstall | cut -f1'",
            "    cmd = compose_cmd(",
            "        ['dpkg', '--get-selections', '|', 'grep', '-v', 'deinstall', '|', 'cut', '-f1']",
            "    )",
            "    assert expected_cmd == cmd"
        ],
        "action": [
            "-1",
            "-1",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "3": []
        },
        "addLocation": []
    },
    "indy_common/util.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import datetime"
            },
            "1": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " import os"
            },
            "2": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import random"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 4,
                "PatchRowcode": "+import re"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from typing import Tuple, Union, TypeVar, List, Callable"
            },
            "5": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " import libnacl.secret"
            },
            "7": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 144,
                "PatchRowcode": " def compose_cmd(cmd):"
            },
            "8": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 145,
                "PatchRowcode": "     if os.name != 'nt':"
            },
            "9": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "         cmd = ' '.join(cmd)"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+        cmd = re.split(\";|&&\", cmd.splitlines()[0], 1)[0].rstrip()"
            },
            "11": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "     return cmd"
            },
            "12": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 149,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "import datetime",
            "import os",
            "import random",
            "from typing import Tuple, Union, TypeVar, List, Callable",
            "",
            "import libnacl.secret",
            "from base58 import b58decode",
            "from common.serializers.serialization import serialize_msg_for_signing",
            "from plenum.common.types import f",
            "from plenum.common.util import isHex, cryptonymToHex",
            "from common.error import error",
            "from stp_core.crypto.nacl_wrappers import Verifier",
            "",
            "",
            "def getMsgWithoutSig(msg, sigFieldName=f.SIG.nm):",
            "    msgWithoutSig = {}",
            "    for k, v in msg.items():",
            "        if k != sigFieldName:",
            "            msgWithoutSig[k] = v",
            "    return msgWithoutSig",
            "",
            "",
            "def verifySig(identifier, signature, msg) -> bool:",
            "    key = cryptonymToHex(identifier) if not isHex(",
            "        identifier) else identifier",
            "    ser = serialize_msg_for_signing(msg)",
            "    b64sig = signature.encode('utf-8')",
            "    sig = b58decode(b64sig)",
            "    vr = Verifier(key)",
            "    return vr.verify(sig, ser)",
            "",
            "",
            "def getSymmetricallyEncryptedVal(val, secretKey: Union[str, bytes] = None) -> \\",
            "        Tuple[str, str]:",
            "    \"\"\"",
            "    Encrypt the provided value with symmetric encryption",
            "",
            "    :param val: the value to encrypt",
            "    :param secretKey: Optional key, if provided should be either in hex or bytes",
            "    :return: Tuple of the encrypted value and secret key encoded in hex",
            "    \"\"\"",
            "",
            "    if isinstance(val, str):",
            "        val = val.encode(\"utf-8\")",
            "    if secretKey:",
            "        if isHex(secretKey):",
            "            secretKey = bytes(bytearray.fromhex(secretKey))",
            "        elif not isinstance(secretKey, bytes):",
            "            error(\"Secret key must be either in hex or bytes\")",
            "        box = libnacl.secret.SecretBox(secretKey)",
            "    else:",
            "        box = libnacl.secret.SecretBox()",
            "",
            "    return box.encrypt(val).hex(), box.sk.hex()",
            "",
            "",
            "def getSymmetricallyDecryptedVal(val, secretKey: Union[str, bytes]) -> str:",
            "    if isHex(val):",
            "        val = bytes(bytearray.fromhex(val))",
            "    elif isinstance(val, str):",
            "        val = val.encode(\"utf-8\")",
            "    if isHex(secretKey):",
            "        secretKey = bytes(bytearray.fromhex(secretKey))",
            "    elif isinstance(secretKey, str):",
            "        secretKey = secretKey.encode()",
            "    box = libnacl.secret.SecretBox(secretKey)",
            "    return box.decrypt(val).decode()",
            "",
            "",
            "def dateTimeEncoding(obj):",
            "    if isinstance(obj, datetime.datetime):",
            "        return int(obj.strftime('%s'))",
            "    raise TypeError('Not sure how to serialize %s' % (obj,))",
            "",
            "",
            "def getNonce(length=32):",
            "    hexChars = [hex(i)[2:] for i in range(0, 16)]",
            "    return \"\".join([random.choice(hexChars) for i in range(length)])",
            "",
            "",
            "def get_reply_if_confirmed(client, identifier, request_id: int):",
            "    reply, status = client.getReply(identifier, request_id)",
            "    if status == 'CONFIRMED':",
            "        return reply, None",
            "    _, errors = \\",
            "        client.reqRepStore.getAllReplies(identifier, request_id)",
            "    if not errors:",
            "        return None, None",
            "    sender, error_reason = errors.popitem()",
            "    return reply, error_reason",
            "",
            "",
            "# TODO: Should have a timeout, should not have kwargs",
            "def ensureReqCompleted(",
            "        loop,",
            "        reqKey,",
            "        client,",
            "        clbk=None,",
            "        pargs=None,",
            "        kwargs=None,",
            "        cond=None):",
            "",
            "    reply, err = get_reply_if_confirmed(client, *reqKey)",
            "",
            "    if err is None and reply is None and (cond is None or not cond()):",
            "        loop.call_later(.2, ensureReqCompleted, loop,",
            "                        reqKey, client, clbk, pargs, kwargs, cond)",
            "    elif clbk:",
            "        # TODO: Do something which makes reply and error optional in the",
            "        # callback.",
            "        # TODO: This is kludgy, but will be resolved once we move away from",
            "        # this callback pattern",
            "        if pargs is not None and kwargs is not None:",
            "            clbk(reply, err, *pargs, **kwargs)",
            "        elif pargs is not None and kwargs is None:",
            "            clbk(reply, err, *pargs)",
            "        elif pargs is None and kwargs is not None:",
            "            clbk(reply, err, **kwargs)",
            "        else:",
            "            clbk(reply, err)",
            "",
            "",
            "def getNonceForProof(nonce):",
            "    return int(nonce, 16)",
            "",
            "",
            "T = TypeVar('T')",
            "",
            "",
            "def getIndex(predicateFn: Callable[[T], bool], items: List[T]) -> int:",
            "    \"\"\"",
            "    Finds the index of an item in list, which satisfies predicate",
            "    :param predicateFn: predicate function to run on items of list",
            "    :param items: list of tuples",
            "    :return: first index for which predicate function returns True",
            "    \"\"\"",
            "    try:",
            "        return next(i for i, v in enumerate(items) if predicateFn(v))",
            "    except StopIteration:",
            "        return -1",
            "",
            "",
            "def compose_cmd(cmd):",
            "    if os.name != 'nt':",
            "        cmd = ' '.join(cmd)",
            "    return cmd",
            "",
            "",
            "def invalidate_config_caches():",
            "    import stp_core.common.config.util",
            "    import plenum.common.config_util",
            "    import indy_common.config_util",
            "",
            "    # All 3 references must be nullified because all they reference",
            "    # the same object due to specific logic of getConfig methods",
            "    stp_core.common.config.util.CONFIG = None",
            "    plenum.common.config_util.CONFIG = None",
            "    indy_common.config_util.CONFIG = None"
        ],
        "afterPatchFile": [
            "import datetime",
            "import os",
            "import random",
            "import re",
            "from typing import Tuple, Union, TypeVar, List, Callable",
            "",
            "import libnacl.secret",
            "from base58 import b58decode",
            "from common.serializers.serialization import serialize_msg_for_signing",
            "from plenum.common.types import f",
            "from plenum.common.util import isHex, cryptonymToHex",
            "from common.error import error",
            "from stp_core.crypto.nacl_wrappers import Verifier",
            "",
            "",
            "def getMsgWithoutSig(msg, sigFieldName=f.SIG.nm):",
            "    msgWithoutSig = {}",
            "    for k, v in msg.items():",
            "        if k != sigFieldName:",
            "            msgWithoutSig[k] = v",
            "    return msgWithoutSig",
            "",
            "",
            "def verifySig(identifier, signature, msg) -> bool:",
            "    key = cryptonymToHex(identifier) if not isHex(",
            "        identifier) else identifier",
            "    ser = serialize_msg_for_signing(msg)",
            "    b64sig = signature.encode('utf-8')",
            "    sig = b58decode(b64sig)",
            "    vr = Verifier(key)",
            "    return vr.verify(sig, ser)",
            "",
            "",
            "def getSymmetricallyEncryptedVal(val, secretKey: Union[str, bytes] = None) -> \\",
            "        Tuple[str, str]:",
            "    \"\"\"",
            "    Encrypt the provided value with symmetric encryption",
            "",
            "    :param val: the value to encrypt",
            "    :param secretKey: Optional key, if provided should be either in hex or bytes",
            "    :return: Tuple of the encrypted value and secret key encoded in hex",
            "    \"\"\"",
            "",
            "    if isinstance(val, str):",
            "        val = val.encode(\"utf-8\")",
            "    if secretKey:",
            "        if isHex(secretKey):",
            "            secretKey = bytes(bytearray.fromhex(secretKey))",
            "        elif not isinstance(secretKey, bytes):",
            "            error(\"Secret key must be either in hex or bytes\")",
            "        box = libnacl.secret.SecretBox(secretKey)",
            "    else:",
            "        box = libnacl.secret.SecretBox()",
            "",
            "    return box.encrypt(val).hex(), box.sk.hex()",
            "",
            "",
            "def getSymmetricallyDecryptedVal(val, secretKey: Union[str, bytes]) -> str:",
            "    if isHex(val):",
            "        val = bytes(bytearray.fromhex(val))",
            "    elif isinstance(val, str):",
            "        val = val.encode(\"utf-8\")",
            "    if isHex(secretKey):",
            "        secretKey = bytes(bytearray.fromhex(secretKey))",
            "    elif isinstance(secretKey, str):",
            "        secretKey = secretKey.encode()",
            "    box = libnacl.secret.SecretBox(secretKey)",
            "    return box.decrypt(val).decode()",
            "",
            "",
            "def dateTimeEncoding(obj):",
            "    if isinstance(obj, datetime.datetime):",
            "        return int(obj.strftime('%s'))",
            "    raise TypeError('Not sure how to serialize %s' % (obj,))",
            "",
            "",
            "def getNonce(length=32):",
            "    hexChars = [hex(i)[2:] for i in range(0, 16)]",
            "    return \"\".join([random.choice(hexChars) for i in range(length)])",
            "",
            "",
            "def get_reply_if_confirmed(client, identifier, request_id: int):",
            "    reply, status = client.getReply(identifier, request_id)",
            "    if status == 'CONFIRMED':",
            "        return reply, None",
            "    _, errors = \\",
            "        client.reqRepStore.getAllReplies(identifier, request_id)",
            "    if not errors:",
            "        return None, None",
            "    sender, error_reason = errors.popitem()",
            "    return reply, error_reason",
            "",
            "",
            "# TODO: Should have a timeout, should not have kwargs",
            "def ensureReqCompleted(",
            "        loop,",
            "        reqKey,",
            "        client,",
            "        clbk=None,",
            "        pargs=None,",
            "        kwargs=None,",
            "        cond=None):",
            "",
            "    reply, err = get_reply_if_confirmed(client, *reqKey)",
            "",
            "    if err is None and reply is None and (cond is None or not cond()):",
            "        loop.call_later(.2, ensureReqCompleted, loop,",
            "                        reqKey, client, clbk, pargs, kwargs, cond)",
            "    elif clbk:",
            "        # TODO: Do something which makes reply and error optional in the",
            "        # callback.",
            "        # TODO: This is kludgy, but will be resolved once we move away from",
            "        # this callback pattern",
            "        if pargs is not None and kwargs is not None:",
            "            clbk(reply, err, *pargs, **kwargs)",
            "        elif pargs is not None and kwargs is None:",
            "            clbk(reply, err, *pargs)",
            "        elif pargs is None and kwargs is not None:",
            "            clbk(reply, err, **kwargs)",
            "        else:",
            "            clbk(reply, err)",
            "",
            "",
            "def getNonceForProof(nonce):",
            "    return int(nonce, 16)",
            "",
            "",
            "T = TypeVar('T')",
            "",
            "",
            "def getIndex(predicateFn: Callable[[T], bool], items: List[T]) -> int:",
            "    \"\"\"",
            "    Finds the index of an item in list, which satisfies predicate",
            "    :param predicateFn: predicate function to run on items of list",
            "    :param items: list of tuples",
            "    :return: first index for which predicate function returns True",
            "    \"\"\"",
            "    try:",
            "        return next(i for i, v in enumerate(items) if predicateFn(v))",
            "    except StopIteration:",
            "        return -1",
            "",
            "",
            "def compose_cmd(cmd):",
            "    if os.name != 'nt':",
            "        cmd = ' '.join(cmd)",
            "        cmd = re.split(\";|&&\", cmd.splitlines()[0], 1)[0].rstrip()",
            "    return cmd",
            "",
            "",
            "def invalidate_config_caches():",
            "    import stp_core.common.config.util",
            "    import plenum.common.config_util",
            "    import indy_common.config_util",
            "",
            "    # All 3 references must be nullified because all they reference",
            "    # the same object due to specific logic of getConfig methods",
            "    stp_core.common.config.util.CONFIG = None",
            "    plenum.common.config_util.CONFIG = None",
            "    indy_common.config_util.CONFIG = None"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "jupyter_server.base.handlers.APIHandler.content_security_policy"
        ]
    },
    "indy_node/server/request_handlers/config_req_handlers/pool_upgrade_handler.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1,
                "PatchRowcode": "+import re"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+"
            },
            "2": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from typing import Optional"
            },
            "3": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " "
            },
            "4": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit"
            },
            "5": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "         self._validate_request_type(request)"
            },
            "6": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "         identifier, req_id, operation = get_request_data(request)"
            },
            "7": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "         status = '*'"
            },
            "8": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "9": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pkg_to_upgrade = operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)"
            },
            "10": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        targetVersion = operation[VERSION]"
            },
            "11": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        reinstall = operation.get(REINSTALL, False)"
            },
            "12": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "13": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if not pkg_to_upgrade:"
            },
            "14": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise InvalidClientRequest(identifier, req_id, \"Upgrade package name is empty\")"
            },
            "15": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "16": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "17": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            res = self.upgrader.check_upgrade_possible(pkg_to_upgrade, targetVersion, reinstall)"
            },
            "18": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except Exception as exc:"
            },
            "19": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            res = str(exc)"
            },
            "20": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "21": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if res:"
            },
            "22": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise InvalidClientRequest(identifier, req_id, res)"
            },
            "23": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "24": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "         action = operation.get(ACTION)"
            },
            "25": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "         # TODO: Some validation needed for making sure name and version"
            },
            "26": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "         # present"
            },
            "27": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "         self.write_req_validator.validate(request,"
            },
            "28": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 86,
                "PatchRowcode": "                                           [auth_action])"
            },
            "29": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 87,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+        pkg_to_upgrade = operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+        if not pkg_to_upgrade:"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+            raise InvalidClientRequest(identifier, req_id, \"Upgrade package name is empty\")"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+        # Only allow processing of a single package"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+        pkg_to_upgrade = re.split(\"\\s+|;|&&|\\|\", pkg_to_upgrade.splitlines()[0], 1)[0].rstrip()"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+        targetVersion = operation[VERSION]"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+        reinstall = operation.get(REINSTALL, False)"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+        try:"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+            res = self.upgrader.check_upgrade_possible(pkg_to_upgrade, targetVersion, reinstall)"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+        except Exception as exc:"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+            res = str(exc)"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+        if res:"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+            raise InvalidClientRequest(identifier, req_id, res)"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+"
            },
            "46": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "     def apply_forced_request(self, req: Request):"
            },
            "47": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "         super().apply_forced_request(req)"
            },
            "48": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 106,
                "PatchRowcode": "         txn = self._req_to_txn(req)"
            }
        },
        "frontPatchFile": [
            "from typing import Optional",
            "",
            "from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit",
            "",
            "from indy_common.config_util import getConfig",
            "",
            "from indy_common.constants import CONFIG_LEDGER_ID, POOL_UPGRADE, \\",
            "    ACTION, CANCEL, START, SCHEDULE, PACKAGE, REINSTALL",
            "",
            "from indy_common.authorize.auth_request_validator import WriteRequestValidator",
            "from indy_node.server.upgrader import Upgrader",
            "from plenum.common.constants import FORCE, VERSION, NAME",
            "from plenum.common.exceptions import InvalidClientRequest",
            "from plenum.common.request import Request",
            "from plenum.common.txn_util import get_request_data, get_payload_data",
            "from plenum.server.database_manager import DatabaseManager",
            "from plenum.server.pool_manager import TxnPoolManager",
            "from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler",
            "",
            "",
            "class PoolUpgradeHandler(WriteRequestHandler):",
            "",
            "    def __init__(self, database_manager: DatabaseManager,",
            "                 upgrader: Upgrader,",
            "                 write_req_validator: WriteRequestValidator,",
            "                 pool_manager: TxnPoolManager):",
            "        super().__init__(database_manager, POOL_UPGRADE, CONFIG_LEDGER_ID)",
            "        self.upgrader = upgrader",
            "        self.write_req_validator = write_req_validator",
            "        self.pool_manager = pool_manager",
            "",
            "    def static_validation(self, request: Request):",
            "        self._validate_request_type(request)",
            "        identifier, req_id, operation = get_request_data(request)",
            "        action = operation.get(ACTION)",
            "        if action not in (START, CANCEL):",
            "            raise InvalidClientRequest(identifier, req_id,",
            "                                       \"{} not a valid action\".",
            "                                       format(action))",
            "        if action == START:",
            "            schedule = operation.get(SCHEDULE, {})",
            "            force = operation.get(FORCE)",
            "            force = str(force) == 'True'",
            "            isValid, msg = self.upgrader.isScheduleValid(",
            "                schedule, self.pool_manager.getNodesServices(), force)",
            "            if not isValid:",
            "                raise InvalidClientRequest(identifier, req_id,",
            "                                           \"{} not a valid schedule since {}\".",
            "                                           format(schedule, msg))",
            "",
            "    def additional_dynamic_validation(self, request: Request, req_pp_time: Optional[int]):",
            "        self._validate_request_type(request)",
            "        identifier, req_id, operation = get_request_data(request)",
            "        status = '*'",
            "",
            "        pkg_to_upgrade = operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)",
            "        targetVersion = operation[VERSION]",
            "        reinstall = operation.get(REINSTALL, False)",
            "",
            "        if not pkg_to_upgrade:",
            "            raise InvalidClientRequest(identifier, req_id, \"Upgrade package name is empty\")",
            "",
            "        try:",
            "            res = self.upgrader.check_upgrade_possible(pkg_to_upgrade, targetVersion, reinstall)",
            "        except Exception as exc:",
            "            res = str(exc)",
            "",
            "        if res:",
            "            raise InvalidClientRequest(identifier, req_id, res)",
            "",
            "        action = operation.get(ACTION)",
            "        # TODO: Some validation needed for making sure name and version",
            "        # present",
            "        txn = self.upgrader.get_upgrade_txn(",
            "            lambda txn: get_payload_data(txn).get(",
            "                NAME,",
            "                None) == operation.get(",
            "                NAME,",
            "                None) and get_payload_data(txn).get(VERSION) == operation.get(VERSION),",
            "            reverse=True)",
            "        if txn:",
            "            status = get_payload_data(txn).get(ACTION, '*')",
            "",
            "        if status == START and action == START:",
            "            raise InvalidClientRequest(",
            "                identifier,",
            "                req_id,",
            "                \"Upgrade '{}' is already scheduled\".format(",
            "                    operation.get(NAME)))",
            "        if status == '*':",
            "            auth_action = AuthActionAdd(txn_type=POOL_UPGRADE,",
            "                                        field=ACTION,",
            "                                        value=action)",
            "        else:",
            "            auth_action = AuthActionEdit(txn_type=POOL_UPGRADE,",
            "                                         field=ACTION,",
            "                                         old_value=status,",
            "                                         new_value=action)",
            "        self.write_req_validator.validate(request,",
            "                                          [auth_action])",
            "",
            "    def apply_forced_request(self, req: Request):",
            "        super().apply_forced_request(req)",
            "        txn = self._req_to_txn(req)",
            "        self.upgrader.handleUpgradeTxn(txn)",
            "",
            "    # Config handler don't use state for any validation for now",
            "    def update_state(self, txn, prev_result, request, is_committed=False):",
            "        pass"
        ],
        "afterPatchFile": [
            "import re",
            "",
            "from typing import Optional",
            "",
            "from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit",
            "",
            "from indy_common.config_util import getConfig",
            "",
            "from indy_common.constants import CONFIG_LEDGER_ID, POOL_UPGRADE, \\",
            "    ACTION, CANCEL, START, SCHEDULE, PACKAGE, REINSTALL",
            "",
            "from indy_common.authorize.auth_request_validator import WriteRequestValidator",
            "from indy_node.server.upgrader import Upgrader",
            "from plenum.common.constants import FORCE, VERSION, NAME",
            "from plenum.common.exceptions import InvalidClientRequest",
            "from plenum.common.request import Request",
            "from plenum.common.txn_util import get_request_data, get_payload_data",
            "from plenum.server.database_manager import DatabaseManager",
            "from plenum.server.pool_manager import TxnPoolManager",
            "from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler",
            "",
            "",
            "class PoolUpgradeHandler(WriteRequestHandler):",
            "",
            "    def __init__(self, database_manager: DatabaseManager,",
            "                 upgrader: Upgrader,",
            "                 write_req_validator: WriteRequestValidator,",
            "                 pool_manager: TxnPoolManager):",
            "        super().__init__(database_manager, POOL_UPGRADE, CONFIG_LEDGER_ID)",
            "        self.upgrader = upgrader",
            "        self.write_req_validator = write_req_validator",
            "        self.pool_manager = pool_manager",
            "",
            "    def static_validation(self, request: Request):",
            "        self._validate_request_type(request)",
            "        identifier, req_id, operation = get_request_data(request)",
            "        action = operation.get(ACTION)",
            "        if action not in (START, CANCEL):",
            "            raise InvalidClientRequest(identifier, req_id,",
            "                                       \"{} not a valid action\".",
            "                                       format(action))",
            "        if action == START:",
            "            schedule = operation.get(SCHEDULE, {})",
            "            force = operation.get(FORCE)",
            "            force = str(force) == 'True'",
            "            isValid, msg = self.upgrader.isScheduleValid(",
            "                schedule, self.pool_manager.getNodesServices(), force)",
            "            if not isValid:",
            "                raise InvalidClientRequest(identifier, req_id,",
            "                                           \"{} not a valid schedule since {}\".",
            "                                           format(schedule, msg))",
            "",
            "    def additional_dynamic_validation(self, request: Request, req_pp_time: Optional[int]):",
            "        self._validate_request_type(request)",
            "        identifier, req_id, operation = get_request_data(request)",
            "        status = '*'",
            "        action = operation.get(ACTION)",
            "        # TODO: Some validation needed for making sure name and version",
            "        # present",
            "        txn = self.upgrader.get_upgrade_txn(",
            "            lambda txn: get_payload_data(txn).get(",
            "                NAME,",
            "                None) == operation.get(",
            "                NAME,",
            "                None) and get_payload_data(txn).get(VERSION) == operation.get(VERSION),",
            "            reverse=True)",
            "        if txn:",
            "            status = get_payload_data(txn).get(ACTION, '*')",
            "",
            "        if status == START and action == START:",
            "            raise InvalidClientRequest(",
            "                identifier,",
            "                req_id,",
            "                \"Upgrade '{}' is already scheduled\".format(",
            "                    operation.get(NAME)))",
            "        if status == '*':",
            "            auth_action = AuthActionAdd(txn_type=POOL_UPGRADE,",
            "                                        field=ACTION,",
            "                                        value=action)",
            "        else:",
            "            auth_action = AuthActionEdit(txn_type=POOL_UPGRADE,",
            "                                         field=ACTION,",
            "                                         old_value=status,",
            "                                         new_value=action)",
            "        self.write_req_validator.validate(request,",
            "                                          [auth_action])",
            "",
            "        pkg_to_upgrade = operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)",
            "        if not pkg_to_upgrade:",
            "            raise InvalidClientRequest(identifier, req_id, \"Upgrade package name is empty\")",
            "",
            "        # Only allow processing of a single package",
            "        pkg_to_upgrade = re.split(\"\\s+|;|&&|\\|\", pkg_to_upgrade.splitlines()[0], 1)[0].rstrip()",
            "        targetVersion = operation[VERSION]",
            "        reinstall = operation.get(REINSTALL, False)",
            "        try:",
            "            res = self.upgrader.check_upgrade_possible(pkg_to_upgrade, targetVersion, reinstall)",
            "        except Exception as exc:",
            "            res = str(exc)",
            "",
            "        if res:",
            "            raise InvalidClientRequest(identifier, req_id, res)",
            "",
            "    def apply_forced_request(self, req: Request):",
            "        super().apply_forced_request(req)",
            "        txn = self._req_to_txn(req)",
            "        self.upgrader.handleUpgradeTxn(txn)",
            "",
            "    # Config handler don't use state for any validation for now",
            "    def update_state(self, txn, prev_result, request, is_committed=False):",
            "        pass"
        ],
        "action": [
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "55": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "56": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "57": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "58": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "59": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "60": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "61": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "62": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "63": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "64": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "65": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "66": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "67": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "68": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "69": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ],
            "70": [
                "PoolUpgradeHandler",
                "additional_dynamic_validation"
            ]
        },
        "addLocation": []
    }
}