{
    "libs/langchain/langchain/prompts/base.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " def jinja2_formatter(template: str, **kwargs: Any) -> str:"
            },
            "3": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"Format a template using jinja2.\"\"\""
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 15,
                "PatchRowcode": "+    \"\"\"Format a template using jinja2."
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 17,
                "PatchRowcode": "+    *Security warning*: jinja2 templates are not sandboxed and may lead"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+    to arbitrary Python code execution. Do not expand jinja2 templates"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+    using unverified or user-controlled inputs!"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+    \"\"\""
            },
            "10": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     try:"
            },
            "11": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 22,
                "PatchRowcode": "         from jinja2 import Template"
            },
            "12": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 23,
                "PatchRowcode": "     except ImportError:"
            }
        },
        "frontPatchFile": [
            "\"\"\"BasePrompt schema definition.\"\"\"",
            "from __future__ import annotations",
            "",
            "import warnings",
            "from abc import ABC",
            "from typing import Any, Callable, Dict, List, Set",
            "",
            "from langchain.schema.messages import BaseMessage, HumanMessage",
            "from langchain.schema.prompt import PromptValue",
            "from langchain.schema.prompt_template import BasePromptTemplate",
            "from langchain.utils.formatting import formatter",
            "",
            "",
            "def jinja2_formatter(template: str, **kwargs: Any) -> str:",
            "    \"\"\"Format a template using jinja2.\"\"\"",
            "    try:",
            "        from jinja2 import Template",
            "    except ImportError:",
            "        raise ImportError(",
            "            \"jinja2 not installed, which is needed to use the jinja2_formatter. \"",
            "            \"Please install it with `pip install jinja2`.\"",
            "        )",
            "",
            "    return Template(template).render(**kwargs)",
            "",
            "",
            "def validate_jinja2(template: str, input_variables: List[str]) -> None:",
            "    \"\"\"",
            "    Validate that the input variables are valid for the template.",
            "    Issues a warning if missing or extra variables are found.",
            "",
            "    Args:",
            "        template: The template string.",
            "        input_variables: The input variables.",
            "    \"\"\"",
            "    input_variables_set = set(input_variables)",
            "    valid_variables = _get_jinja2_variables_from_template(template)",
            "    missing_variables = valid_variables - input_variables_set",
            "    extra_variables = input_variables_set - valid_variables",
            "",
            "    warning_message = \"\"",
            "    if missing_variables:",
            "        warning_message += f\"Missing variables: {missing_variables} \"",
            "",
            "    if extra_variables:",
            "        warning_message += f\"Extra variables: {extra_variables}\"",
            "",
            "    if warning_message:",
            "        warnings.warn(warning_message.strip())",
            "",
            "",
            "def _get_jinja2_variables_from_template(template: str) -> Set[str]:",
            "    try:",
            "        from jinja2 import Environment, meta",
            "    except ImportError:",
            "        raise ImportError(",
            "            \"jinja2 not installed, which is needed to use the jinja2_formatter. \"",
            "            \"Please install it with `pip install jinja2`.\"",
            "        )",
            "    env = Environment()",
            "    ast = env.parse(template)",
            "    variables = meta.find_undeclared_variables(ast)",
            "    return variables",
            "",
            "",
            "DEFAULT_FORMATTER_MAPPING: Dict[str, Callable] = {",
            "    \"f-string\": formatter.format,",
            "    \"jinja2\": jinja2_formatter,",
            "}",
            "",
            "DEFAULT_VALIDATOR_MAPPING: Dict[str, Callable] = {",
            "    \"f-string\": formatter.validate_input_variables,",
            "    \"jinja2\": validate_jinja2,",
            "}",
            "",
            "",
            "def check_valid_template(",
            "    template: str, template_format: str, input_variables: List[str]",
            ") -> None:",
            "    \"\"\"Check that template string is valid.\"\"\"",
            "    if template_format not in DEFAULT_FORMATTER_MAPPING:",
            "        valid_formats = list(DEFAULT_FORMATTER_MAPPING)",
            "        raise ValueError(",
            "            f\"Invalid template format. Got `{template_format}`;\"",
            "            f\" should be one of {valid_formats}\"",
            "        )",
            "    try:",
            "        validator_func = DEFAULT_VALIDATOR_MAPPING[template_format]",
            "        validator_func(template, input_variables)",
            "    except KeyError as e:",
            "        raise ValueError(",
            "            \"Invalid prompt schema; check for mismatched or missing input parameters. \"",
            "            + str(e)",
            "        )",
            "",
            "",
            "class StringPromptValue(PromptValue):",
            "    \"\"\"String prompt value.\"\"\"",
            "",
            "    text: str",
            "    \"\"\"Prompt text.\"\"\"",
            "",
            "    def to_string(self) -> str:",
            "        \"\"\"Return prompt as string.\"\"\"",
            "        return self.text",
            "",
            "    def to_messages(self) -> List[BaseMessage]:",
            "        \"\"\"Return prompt as messages.\"\"\"",
            "        return [HumanMessage(content=self.text)]",
            "",
            "",
            "class StringPromptTemplate(BasePromptTemplate, ABC):",
            "    \"\"\"String prompt that exposes the format method, returning a prompt.\"\"\"",
            "",
            "    def format_prompt(self, **kwargs: Any) -> PromptValue:",
            "        \"\"\"Create Chat Messages.\"\"\"",
            "        return StringPromptValue(text=self.format(**kwargs))"
        ],
        "afterPatchFile": [
            "\"\"\"BasePrompt schema definition.\"\"\"",
            "from __future__ import annotations",
            "",
            "import warnings",
            "from abc import ABC",
            "from typing import Any, Callable, Dict, List, Set",
            "",
            "from langchain.schema.messages import BaseMessage, HumanMessage",
            "from langchain.schema.prompt import PromptValue",
            "from langchain.schema.prompt_template import BasePromptTemplate",
            "from langchain.utils.formatting import formatter",
            "",
            "",
            "def jinja2_formatter(template: str, **kwargs: Any) -> str:",
            "    \"\"\"Format a template using jinja2.",
            "",
            "    *Security warning*: jinja2 templates are not sandboxed and may lead",
            "    to arbitrary Python code execution. Do not expand jinja2 templates",
            "    using unverified or user-controlled inputs!",
            "    \"\"\"",
            "    try:",
            "        from jinja2 import Template",
            "    except ImportError:",
            "        raise ImportError(",
            "            \"jinja2 not installed, which is needed to use the jinja2_formatter. \"",
            "            \"Please install it with `pip install jinja2`.\"",
            "        )",
            "",
            "    return Template(template).render(**kwargs)",
            "",
            "",
            "def validate_jinja2(template: str, input_variables: List[str]) -> None:",
            "    \"\"\"",
            "    Validate that the input variables are valid for the template.",
            "    Issues a warning if missing or extra variables are found.",
            "",
            "    Args:",
            "        template: The template string.",
            "        input_variables: The input variables.",
            "    \"\"\"",
            "    input_variables_set = set(input_variables)",
            "    valid_variables = _get_jinja2_variables_from_template(template)",
            "    missing_variables = valid_variables - input_variables_set",
            "    extra_variables = input_variables_set - valid_variables",
            "",
            "    warning_message = \"\"",
            "    if missing_variables:",
            "        warning_message += f\"Missing variables: {missing_variables} \"",
            "",
            "    if extra_variables:",
            "        warning_message += f\"Extra variables: {extra_variables}\"",
            "",
            "    if warning_message:",
            "        warnings.warn(warning_message.strip())",
            "",
            "",
            "def _get_jinja2_variables_from_template(template: str) -> Set[str]:",
            "    try:",
            "        from jinja2 import Environment, meta",
            "    except ImportError:",
            "        raise ImportError(",
            "            \"jinja2 not installed, which is needed to use the jinja2_formatter. \"",
            "            \"Please install it with `pip install jinja2`.\"",
            "        )",
            "    env = Environment()",
            "    ast = env.parse(template)",
            "    variables = meta.find_undeclared_variables(ast)",
            "    return variables",
            "",
            "",
            "DEFAULT_FORMATTER_MAPPING: Dict[str, Callable] = {",
            "    \"f-string\": formatter.format,",
            "    \"jinja2\": jinja2_formatter,",
            "}",
            "",
            "DEFAULT_VALIDATOR_MAPPING: Dict[str, Callable] = {",
            "    \"f-string\": formatter.validate_input_variables,",
            "    \"jinja2\": validate_jinja2,",
            "}",
            "",
            "",
            "def check_valid_template(",
            "    template: str, template_format: str, input_variables: List[str]",
            ") -> None:",
            "    \"\"\"Check that template string is valid.\"\"\"",
            "    if template_format not in DEFAULT_FORMATTER_MAPPING:",
            "        valid_formats = list(DEFAULT_FORMATTER_MAPPING)",
            "        raise ValueError(",
            "            f\"Invalid template format. Got `{template_format}`;\"",
            "            f\" should be one of {valid_formats}\"",
            "        )",
            "    try:",
            "        validator_func = DEFAULT_VALIDATOR_MAPPING[template_format]",
            "        validator_func(template, input_variables)",
            "    except KeyError as e:",
            "        raise ValueError(",
            "            \"Invalid prompt schema; check for mismatched or missing input parameters. \"",
            "            + str(e)",
            "        )",
            "",
            "",
            "class StringPromptValue(PromptValue):",
            "    \"\"\"String prompt value.\"\"\"",
            "",
            "    text: str",
            "    \"\"\"Prompt text.\"\"\"",
            "",
            "    def to_string(self) -> str:",
            "        \"\"\"Return prompt as string.\"\"\"",
            "        return self.text",
            "",
            "    def to_messages(self) -> List[BaseMessage]:",
            "        \"\"\"Return prompt as messages.\"\"\"",
            "        return [HumanMessage(content=self.text)]",
            "",
            "",
            "class StringPromptTemplate(BasePromptTemplate, ABC):",
            "    \"\"\"String prompt that exposes the format method, returning a prompt.\"\"\"",
            "",
            "    def format_prompt(self, **kwargs: Any) -> PromptValue:",
            "        \"\"\"Create Chat Messages.\"\"\"",
            "        return StringPromptValue(text=self.format(**kwargs))"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "15": [
                "jinja2_formatter"
            ]
        },
        "addLocation": []
    },
    "libs/langchain/langchain/prompts/loading.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 113,
                "PatchRowcode": "     # Load the template from disk if necessary."
            },
            "1": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "     config = _load_template(\"template\", config)"
            },
            "2": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "     config = _load_output_parser(config)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+    template_format = config.get(\"template_format\", \"f-string\")"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 118,
                "PatchRowcode": "+    if template_format == \"jinja2\":"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+        # Disabled due to:"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+        # https://github.com/langchain-ai/langchain/issues/4394"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+        raise ValueError("
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 122,
                "PatchRowcode": "+            f\"Loading templates with '{template_format}' format is no longer supported \""
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 123,
                "PatchRowcode": "+            f\"since it can lead to arbitrary code execution. Please migrate to using \""
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+            f\"the 'f-string' template format, which does not suffer from this issue.\""
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+        )"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "     return PromptTemplate(**config)"
            },
            "15": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 128,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 129,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "\"\"\"Load prompts.\"\"\"",
            "import json",
            "import logging",
            "from pathlib import Path",
            "from typing import Callable, Dict, Union",
            "",
            "import yaml",
            "",
            "from langchain.prompts.few_shot import FewShotPromptTemplate",
            "from langchain.prompts.prompt import PromptTemplate",
            "from langchain.schema import BaseLLMOutputParser, BasePromptTemplate, StrOutputParser",
            "from langchain.utils.loading import try_load_from_hub",
            "",
            "URL_BASE = \"https://raw.githubusercontent.com/hwchase17/langchain-hub/master/prompts/\"",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def load_prompt_from_config(config: dict) -> BasePromptTemplate:",
            "    \"\"\"Load prompt from Config Dict.\"\"\"",
            "    if \"_type\" not in config:",
            "        logger.warning(\"No `_type` key found, defaulting to `prompt`.\")",
            "    config_type = config.pop(\"_type\", \"prompt\")",
            "",
            "    if config_type not in type_to_loader_dict:",
            "        raise ValueError(f\"Loading {config_type} prompt not supported\")",
            "",
            "    prompt_loader = type_to_loader_dict[config_type]",
            "    return prompt_loader(config)",
            "",
            "",
            "def _load_template(var_name: str, config: dict) -> dict:",
            "    \"\"\"Load template from the path if applicable.\"\"\"",
            "    # Check if template_path exists in config.",
            "    if f\"{var_name}_path\" in config:",
            "        # If it does, make sure template variable doesn't also exist.",
            "        if var_name in config:",
            "            raise ValueError(",
            "                f\"Both `{var_name}_path` and `{var_name}` cannot be provided.\"",
            "            )",
            "        # Pop the template path from the config.",
            "        template_path = Path(config.pop(f\"{var_name}_path\"))",
            "        # Load the template.",
            "        if template_path.suffix == \".txt\":",
            "            with open(template_path) as f:",
            "                template = f.read()",
            "        else:",
            "            raise ValueError",
            "        # Set the template variable to the extracted variable.",
            "        config[var_name] = template",
            "    return config",
            "",
            "",
            "def _load_examples(config: dict) -> dict:",
            "    \"\"\"Load examples if necessary.\"\"\"",
            "    if isinstance(config[\"examples\"], list):",
            "        pass",
            "    elif isinstance(config[\"examples\"], str):",
            "        with open(config[\"examples\"]) as f:",
            "            if config[\"examples\"].endswith(\".json\"):",
            "                examples = json.load(f)",
            "            elif config[\"examples\"].endswith((\".yaml\", \".yml\")):",
            "                examples = yaml.safe_load(f)",
            "            else:",
            "                raise ValueError(",
            "                    \"Invalid file format. Only json or yaml formats are supported.\"",
            "                )",
            "        config[\"examples\"] = examples",
            "    else:",
            "        raise ValueError(\"Invalid examples format. Only list or string are supported.\")",
            "    return config",
            "",
            "",
            "def _load_output_parser(config: dict) -> dict:",
            "    \"\"\"Load output parser.\"\"\"",
            "    if \"output_parser\" in config and config[\"output_parser\"]:",
            "        _config = config.pop(\"output_parser\")",
            "        output_parser_type = _config.pop(\"_type\")",
            "        if output_parser_type == \"regex_parser\":",
            "            from langchain.output_parsers.regex import RegexParser",
            "",
            "            output_parser: BaseLLMOutputParser = RegexParser(**_config)",
            "        elif output_parser_type == \"default\":",
            "            output_parser = StrOutputParser(**_config)",
            "        else:",
            "            raise ValueError(f\"Unsupported output parser {output_parser_type}\")",
            "        config[\"output_parser\"] = output_parser",
            "    return config",
            "",
            "",
            "def _load_few_shot_prompt(config: dict) -> FewShotPromptTemplate:",
            "    \"\"\"Load the \"few shot\" prompt from the config.\"\"\"",
            "    # Load the suffix and prefix templates.",
            "    config = _load_template(\"suffix\", config)",
            "    config = _load_template(\"prefix\", config)",
            "    # Load the example prompt.",
            "    if \"example_prompt_path\" in config:",
            "        if \"example_prompt\" in config:",
            "            raise ValueError(",
            "                \"Only one of example_prompt and example_prompt_path should \"",
            "                \"be specified.\"",
            "            )",
            "        config[\"example_prompt\"] = load_prompt(config.pop(\"example_prompt_path\"))",
            "    else:",
            "        config[\"example_prompt\"] = load_prompt_from_config(config[\"example_prompt\"])",
            "    # Load the examples.",
            "    config = _load_examples(config)",
            "    config = _load_output_parser(config)",
            "    return FewShotPromptTemplate(**config)",
            "",
            "",
            "def _load_prompt(config: dict) -> PromptTemplate:",
            "    \"\"\"Load the prompt template from config.\"\"\"",
            "    # Load the template from disk if necessary.",
            "    config = _load_template(\"template\", config)",
            "    config = _load_output_parser(config)",
            "    return PromptTemplate(**config)",
            "",
            "",
            "def load_prompt(path: Union[str, Path]) -> BasePromptTemplate:",
            "    \"\"\"Unified method for loading a prompt from LangChainHub or local fs.\"\"\"",
            "    if hub_result := try_load_from_hub(",
            "        path, _load_prompt_from_file, \"prompts\", {\"py\", \"json\", \"yaml\"}",
            "    ):",
            "        return hub_result",
            "    else:",
            "        return _load_prompt_from_file(path)",
            "",
            "",
            "def _load_prompt_from_file(file: Union[str, Path]) -> BasePromptTemplate:",
            "    \"\"\"Load prompt from file.\"\"\"",
            "    # Convert file to a Path object.",
            "    if isinstance(file, str):",
            "        file_path = Path(file)",
            "    else:",
            "        file_path = file",
            "    # Load from either json or yaml.",
            "    if file_path.suffix == \".json\":",
            "        with open(file_path) as f:",
            "            config = json.load(f)",
            "    elif file_path.suffix == \".yaml\":",
            "        with open(file_path, \"r\") as f:",
            "            config = yaml.safe_load(f)",
            "    else:",
            "        raise ValueError(f\"Got unsupported file type {file_path.suffix}\")",
            "    # Load the prompt from the config now.",
            "    return load_prompt_from_config(config)",
            "",
            "",
            "type_to_loader_dict: Dict[str, Callable[[dict], BasePromptTemplate]] = {",
            "    \"prompt\": _load_prompt,",
            "    \"few_shot\": _load_few_shot_prompt,",
            "}"
        ],
        "afterPatchFile": [
            "\"\"\"Load prompts.\"\"\"",
            "import json",
            "import logging",
            "from pathlib import Path",
            "from typing import Callable, Dict, Union",
            "",
            "import yaml",
            "",
            "from langchain.prompts.few_shot import FewShotPromptTemplate",
            "from langchain.prompts.prompt import PromptTemplate",
            "from langchain.schema import BaseLLMOutputParser, BasePromptTemplate, StrOutputParser",
            "from langchain.utils.loading import try_load_from_hub",
            "",
            "URL_BASE = \"https://raw.githubusercontent.com/hwchase17/langchain-hub/master/prompts/\"",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "def load_prompt_from_config(config: dict) -> BasePromptTemplate:",
            "    \"\"\"Load prompt from Config Dict.\"\"\"",
            "    if \"_type\" not in config:",
            "        logger.warning(\"No `_type` key found, defaulting to `prompt`.\")",
            "    config_type = config.pop(\"_type\", \"prompt\")",
            "",
            "    if config_type not in type_to_loader_dict:",
            "        raise ValueError(f\"Loading {config_type} prompt not supported\")",
            "",
            "    prompt_loader = type_to_loader_dict[config_type]",
            "    return prompt_loader(config)",
            "",
            "",
            "def _load_template(var_name: str, config: dict) -> dict:",
            "    \"\"\"Load template from the path if applicable.\"\"\"",
            "    # Check if template_path exists in config.",
            "    if f\"{var_name}_path\" in config:",
            "        # If it does, make sure template variable doesn't also exist.",
            "        if var_name in config:",
            "            raise ValueError(",
            "                f\"Both `{var_name}_path` and `{var_name}` cannot be provided.\"",
            "            )",
            "        # Pop the template path from the config.",
            "        template_path = Path(config.pop(f\"{var_name}_path\"))",
            "        # Load the template.",
            "        if template_path.suffix == \".txt\":",
            "            with open(template_path) as f:",
            "                template = f.read()",
            "        else:",
            "            raise ValueError",
            "        # Set the template variable to the extracted variable.",
            "        config[var_name] = template",
            "    return config",
            "",
            "",
            "def _load_examples(config: dict) -> dict:",
            "    \"\"\"Load examples if necessary.\"\"\"",
            "    if isinstance(config[\"examples\"], list):",
            "        pass",
            "    elif isinstance(config[\"examples\"], str):",
            "        with open(config[\"examples\"]) as f:",
            "            if config[\"examples\"].endswith(\".json\"):",
            "                examples = json.load(f)",
            "            elif config[\"examples\"].endswith((\".yaml\", \".yml\")):",
            "                examples = yaml.safe_load(f)",
            "            else:",
            "                raise ValueError(",
            "                    \"Invalid file format. Only json or yaml formats are supported.\"",
            "                )",
            "        config[\"examples\"] = examples",
            "    else:",
            "        raise ValueError(\"Invalid examples format. Only list or string are supported.\")",
            "    return config",
            "",
            "",
            "def _load_output_parser(config: dict) -> dict:",
            "    \"\"\"Load output parser.\"\"\"",
            "    if \"output_parser\" in config and config[\"output_parser\"]:",
            "        _config = config.pop(\"output_parser\")",
            "        output_parser_type = _config.pop(\"_type\")",
            "        if output_parser_type == \"regex_parser\":",
            "            from langchain.output_parsers.regex import RegexParser",
            "",
            "            output_parser: BaseLLMOutputParser = RegexParser(**_config)",
            "        elif output_parser_type == \"default\":",
            "            output_parser = StrOutputParser(**_config)",
            "        else:",
            "            raise ValueError(f\"Unsupported output parser {output_parser_type}\")",
            "        config[\"output_parser\"] = output_parser",
            "    return config",
            "",
            "",
            "def _load_few_shot_prompt(config: dict) -> FewShotPromptTemplate:",
            "    \"\"\"Load the \"few shot\" prompt from the config.\"\"\"",
            "    # Load the suffix and prefix templates.",
            "    config = _load_template(\"suffix\", config)",
            "    config = _load_template(\"prefix\", config)",
            "    # Load the example prompt.",
            "    if \"example_prompt_path\" in config:",
            "        if \"example_prompt\" in config:",
            "            raise ValueError(",
            "                \"Only one of example_prompt and example_prompt_path should \"",
            "                \"be specified.\"",
            "            )",
            "        config[\"example_prompt\"] = load_prompt(config.pop(\"example_prompt_path\"))",
            "    else:",
            "        config[\"example_prompt\"] = load_prompt_from_config(config[\"example_prompt\"])",
            "    # Load the examples.",
            "    config = _load_examples(config)",
            "    config = _load_output_parser(config)",
            "    return FewShotPromptTemplate(**config)",
            "",
            "",
            "def _load_prompt(config: dict) -> PromptTemplate:",
            "    \"\"\"Load the prompt template from config.\"\"\"",
            "    # Load the template from disk if necessary.",
            "    config = _load_template(\"template\", config)",
            "    config = _load_output_parser(config)",
            "",
            "    template_format = config.get(\"template_format\", \"f-string\")",
            "    if template_format == \"jinja2\":",
            "        # Disabled due to:",
            "        # https://github.com/langchain-ai/langchain/issues/4394",
            "        raise ValueError(",
            "            f\"Loading templates with '{template_format}' format is no longer supported \"",
            "            f\"since it can lead to arbitrary code execution. Please migrate to using \"",
            "            f\"the 'f-string' template format, which does not suffer from this issue.\"",
            "        )",
            "",
            "    return PromptTemplate(**config)",
            "",
            "",
            "def load_prompt(path: Union[str, Path]) -> BasePromptTemplate:",
            "    \"\"\"Unified method for loading a prompt from LangChainHub or local fs.\"\"\"",
            "    if hub_result := try_load_from_hub(",
            "        path, _load_prompt_from_file, \"prompts\", {\"py\", \"json\", \"yaml\"}",
            "    ):",
            "        return hub_result",
            "    else:",
            "        return _load_prompt_from_file(path)",
            "",
            "",
            "def _load_prompt_from_file(file: Union[str, Path]) -> BasePromptTemplate:",
            "    \"\"\"Load prompt from file.\"\"\"",
            "    # Convert file to a Path object.",
            "    if isinstance(file, str):",
            "        file_path = Path(file)",
            "    else:",
            "        file_path = file",
            "    # Load from either json or yaml.",
            "    if file_path.suffix == \".json\":",
            "        with open(file_path) as f:",
            "            config = json.load(f)",
            "    elif file_path.suffix == \".yaml\":",
            "        with open(file_path, \"r\") as f:",
            "            config = yaml.safe_load(f)",
            "    else:",
            "        raise ValueError(f\"Got unsupported file type {file_path.suffix}\")",
            "    # Load the prompt from the config now.",
            "    return load_prompt_from_config(config)",
            "",
            "",
            "type_to_loader_dict: Dict[str, Callable[[dict], BasePromptTemplate]] = {",
            "    \"prompt\": _load_prompt,",
            "    \"few_shot\": _load_few_shot_prompt,",
            "}"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "yt_dlp.YoutubeDL"
        ]
    },
    "libs/langchain/langchain/prompts/prompt.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": "     The template can be formatted using either f-strings (default) or jinja2 syntax."
            },
            "2": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+    *Security warning*: Prefer using `template_format=\"f-string\"` instead of"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+    `template_format=\"jinja2\"`, since jinja2 templates are not sandboxed and may"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+    lead to arbitrary Python code execution. Do not construct a jinja2 `PromptTemplate`"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+    from unverified or user-controlled inputs!"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 30,
                "PatchRowcode": "     Example:"
            },
            "9": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 32,
                "PatchRowcode": "         .. code-block:: python"
            }
        },
        "frontPatchFile": [
            "\"\"\"Prompt schema definition.\"\"\"",
            "from __future__ import annotations",
            "",
            "from pathlib import Path",
            "from string import Formatter",
            "from typing import Any, Dict, List, Optional, Union",
            "",
            "from langchain.prompts.base import (",
            "    DEFAULT_FORMATTER_MAPPING,",
            "    StringPromptTemplate,",
            "    _get_jinja2_variables_from_template,",
            "    check_valid_template,",
            ")",
            "from langchain.pydantic_v1 import root_validator",
            "",
            "",
            "class PromptTemplate(StringPromptTemplate):",
            "    \"\"\"A prompt template for a language model.",
            "",
            "    A prompt template consists of a string template. It accepts a set of parameters",
            "    from the user that can be used to generate a prompt for a language model.",
            "",
            "    The template can be formatted using either f-strings (default) or jinja2 syntax.",
            "",
            "    Example:",
            "",
            "        .. code-block:: python",
            "",
            "            from langchain.prompts import PromptTemplate",
            "",
            "            # Instantiation using from_template (recommended)",
            "            prompt = PromptTemplate.from_template(\"Say {foo}\")",
            "            prompt.format(foo=\"bar\")",
            "",
            "            # Instantiation using initializer",
            "            prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")",
            "    \"\"\"",
            "",
            "    @property",
            "    def lc_attributes(self) -> Dict[str, Any]:",
            "        return {",
            "            \"template_format\": self.template_format,",
            "        }",
            "",
            "    input_variables: List[str]",
            "    \"\"\"A list of the names of the variables the prompt template expects.\"\"\"",
            "",
            "    template: str",
            "    \"\"\"The prompt template.\"\"\"",
            "",
            "    template_format: str = \"f-string\"",
            "    \"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"",
            "",
            "    validate_template: bool = True",
            "    \"\"\"Whether or not to try validating the template.\"\"\"",
            "",
            "    def __add__(self, other: Any) -> PromptTemplate:",
            "        \"\"\"Override the + operator to allow for combining prompt templates.\"\"\"",
            "        # Allow for easy combining",
            "        if isinstance(other, PromptTemplate):",
            "            if self.template_format != \"f-string\":",
            "                raise ValueError(",
            "                    \"Adding prompt templates only supported for f-strings.\"",
            "                )",
            "            if other.template_format != \"f-string\":",
            "                raise ValueError(",
            "                    \"Adding prompt templates only supported for f-strings.\"",
            "                )",
            "            input_variables = list(",
            "                set(self.input_variables) | set(other.input_variables)",
            "            )",
            "            template = self.template + other.template",
            "            # If any do not want to validate, then don't",
            "            validate_template = self.validate_template and other.validate_template",
            "            partial_variables = {k: v for k, v in self.partial_variables.items()}",
            "            for k, v in other.partial_variables.items():",
            "                if k in partial_variables:",
            "                    raise ValueError(\"Cannot have same variable partialed twice.\")",
            "                else:",
            "                    partial_variables[k] = v",
            "            return PromptTemplate(",
            "                template=template,",
            "                input_variables=input_variables,",
            "                partial_variables=partial_variables,",
            "                template_format=\"f-string\",",
            "                validate_template=validate_template,",
            "            )",
            "        elif isinstance(other, str):",
            "            prompt = PromptTemplate.from_template(other)",
            "            return self + prompt",
            "        else:",
            "            raise NotImplementedError(f\"Unsupported operand type for +: {type(other)}\")",
            "",
            "    @property",
            "    def _prompt_type(self) -> str:",
            "        \"\"\"Return the prompt type key.\"\"\"",
            "        return \"prompt\"",
            "",
            "    def format(self, **kwargs: Any) -> str:",
            "        \"\"\"Format the prompt with the inputs.",
            "",
            "        Args:",
            "            kwargs: Any arguments to be passed to the prompt template.",
            "",
            "        Returns:",
            "            A formatted string.",
            "",
            "        Example:",
            "",
            "            .. code-block:: python",
            "",
            "                prompt.format(variable1=\"foo\")",
            "        \"\"\"",
            "        kwargs = self._merge_partial_and_user_variables(**kwargs)",
            "        return DEFAULT_FORMATTER_MAPPING[self.template_format](self.template, **kwargs)",
            "",
            "    @root_validator()",
            "    def template_is_valid(cls, values: Dict) -> Dict:",
            "        \"\"\"Check that template and input variables are consistent.\"\"\"",
            "        if values[\"validate_template\"]:",
            "            all_inputs = values[\"input_variables\"] + list(values[\"partial_variables\"])",
            "            check_valid_template(",
            "                values[\"template\"], values[\"template_format\"], all_inputs",
            "            )",
            "        return values",
            "",
            "    @classmethod",
            "    def from_examples(",
            "        cls,",
            "        examples: List[str],",
            "        suffix: str,",
            "        input_variables: List[str],",
            "        example_separator: str = \"\\n\\n\",",
            "        prefix: str = \"\",",
            "        **kwargs: Any,",
            "    ) -> PromptTemplate:",
            "        \"\"\"Take examples in list format with prefix and suffix to create a prompt.",
            "",
            "        Intended to be used as a way to dynamically create a prompt from examples.",
            "",
            "        Args:",
            "            examples: List of examples to use in the prompt.",
            "            suffix: String to go after the list of examples. Should generally",
            "                set up the user's input.",
            "            input_variables: A list of variable names the final prompt template",
            "                will expect.",
            "            example_separator: The separator to use in between examples. Defaults",
            "                to two new line characters.",
            "            prefix: String that should go before any examples. Generally includes",
            "                examples. Default to an empty string.",
            "",
            "        Returns:",
            "            The final prompt generated.",
            "        \"\"\"",
            "        template = example_separator.join([prefix, *examples, suffix])",
            "        return cls(input_variables=input_variables, template=template, **kwargs)",
            "",
            "    @classmethod",
            "    def from_file(",
            "        cls, template_file: Union[str, Path], input_variables: List[str], **kwargs: Any",
            "    ) -> PromptTemplate:",
            "        \"\"\"Load a prompt from a file.",
            "",
            "        Args:",
            "            template_file: The path to the file containing the prompt template.",
            "            input_variables: A list of variable names the final prompt template",
            "                will expect.",
            "",
            "        Returns:",
            "            The prompt loaded from the file.",
            "        \"\"\"",
            "        with open(str(template_file), \"r\") as f:",
            "            template = f.read()",
            "        return cls(input_variables=input_variables, template=template, **kwargs)",
            "",
            "    @classmethod",
            "    def from_template(",
            "        cls,",
            "        template: str,",
            "        *,",
            "        template_format: str = \"f-string\",",
            "        partial_variables: Optional[Dict[str, Any]] = None,",
            "        **kwargs: Any,",
            "    ) -> PromptTemplate:",
            "        \"\"\"Load a prompt template from a template.",
            "",
            "        Args:",
            "            template: The template to load.",
            "            template_format: The format of the template. Use `jinja2` for jinja2,",
            "                             and `f-string` or None for f-strings.",
            "            partial_variables: A dictionary of variables that can be used to partially",
            "                               fill in the template. For example, if the template is",
            "                              `\"{variable1} {variable2}\"`, and `partial_variables` is",
            "                              `{\"variable1\": \"foo\"}`, then the final prompt will be",
            "                              `\"foo {variable2}\"`.",
            "",
            "        Returns:",
            "            The prompt template loaded from the template.",
            "        \"\"\"",
            "        if template_format == \"jinja2\":",
            "            # Get the variables for the template",
            "            input_variables = _get_jinja2_variables_from_template(template)",
            "        elif template_format == \"f-string\":",
            "            input_variables = {",
            "                v for _, v, _, _ in Formatter().parse(template) if v is not None",
            "            }",
            "        else:",
            "            raise ValueError(f\"Unsupported template format: {template_format}\")",
            "",
            "        _partial_variables = partial_variables or {}",
            "",
            "        if _partial_variables:",
            "            input_variables = {",
            "                var for var in input_variables if var not in _partial_variables",
            "            }",
            "",
            "        return cls(",
            "            input_variables=sorted(input_variables),",
            "            template=template,",
            "            template_format=template_format,",
            "            partial_variables=_partial_variables,",
            "            **kwargs,",
            "        )",
            "",
            "",
            "# For backwards compatibility.",
            "Prompt = PromptTemplate"
        ],
        "afterPatchFile": [
            "\"\"\"Prompt schema definition.\"\"\"",
            "from __future__ import annotations",
            "",
            "from pathlib import Path",
            "from string import Formatter",
            "from typing import Any, Dict, List, Optional, Union",
            "",
            "from langchain.prompts.base import (",
            "    DEFAULT_FORMATTER_MAPPING,",
            "    StringPromptTemplate,",
            "    _get_jinja2_variables_from_template,",
            "    check_valid_template,",
            ")",
            "from langchain.pydantic_v1 import root_validator",
            "",
            "",
            "class PromptTemplate(StringPromptTemplate):",
            "    \"\"\"A prompt template for a language model.",
            "",
            "    A prompt template consists of a string template. It accepts a set of parameters",
            "    from the user that can be used to generate a prompt for a language model.",
            "",
            "    The template can be formatted using either f-strings (default) or jinja2 syntax.",
            "",
            "    *Security warning*: Prefer using `template_format=\"f-string\"` instead of",
            "    `template_format=\"jinja2\"`, since jinja2 templates are not sandboxed and may",
            "    lead to arbitrary Python code execution. Do not construct a jinja2 `PromptTemplate`",
            "    from unverified or user-controlled inputs!",
            "",
            "    Example:",
            "",
            "        .. code-block:: python",
            "",
            "            from langchain.prompts import PromptTemplate",
            "",
            "            # Instantiation using from_template (recommended)",
            "            prompt = PromptTemplate.from_template(\"Say {foo}\")",
            "            prompt.format(foo=\"bar\")",
            "",
            "            # Instantiation using initializer",
            "            prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")",
            "    \"\"\"",
            "",
            "    @property",
            "    def lc_attributes(self) -> Dict[str, Any]:",
            "        return {",
            "            \"template_format\": self.template_format,",
            "        }",
            "",
            "    input_variables: List[str]",
            "    \"\"\"A list of the names of the variables the prompt template expects.\"\"\"",
            "",
            "    template: str",
            "    \"\"\"The prompt template.\"\"\"",
            "",
            "    template_format: str = \"f-string\"",
            "    \"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"",
            "",
            "    validate_template: bool = True",
            "    \"\"\"Whether or not to try validating the template.\"\"\"",
            "",
            "    def __add__(self, other: Any) -> PromptTemplate:",
            "        \"\"\"Override the + operator to allow for combining prompt templates.\"\"\"",
            "        # Allow for easy combining",
            "        if isinstance(other, PromptTemplate):",
            "            if self.template_format != \"f-string\":",
            "                raise ValueError(",
            "                    \"Adding prompt templates only supported for f-strings.\"",
            "                )",
            "            if other.template_format != \"f-string\":",
            "                raise ValueError(",
            "                    \"Adding prompt templates only supported for f-strings.\"",
            "                )",
            "            input_variables = list(",
            "                set(self.input_variables) | set(other.input_variables)",
            "            )",
            "            template = self.template + other.template",
            "            # If any do not want to validate, then don't",
            "            validate_template = self.validate_template and other.validate_template",
            "            partial_variables = {k: v for k, v in self.partial_variables.items()}",
            "            for k, v in other.partial_variables.items():",
            "                if k in partial_variables:",
            "                    raise ValueError(\"Cannot have same variable partialed twice.\")",
            "                else:",
            "                    partial_variables[k] = v",
            "            return PromptTemplate(",
            "                template=template,",
            "                input_variables=input_variables,",
            "                partial_variables=partial_variables,",
            "                template_format=\"f-string\",",
            "                validate_template=validate_template,",
            "            )",
            "        elif isinstance(other, str):",
            "            prompt = PromptTemplate.from_template(other)",
            "            return self + prompt",
            "        else:",
            "            raise NotImplementedError(f\"Unsupported operand type for +: {type(other)}\")",
            "",
            "    @property",
            "    def _prompt_type(self) -> str:",
            "        \"\"\"Return the prompt type key.\"\"\"",
            "        return \"prompt\"",
            "",
            "    def format(self, **kwargs: Any) -> str:",
            "        \"\"\"Format the prompt with the inputs.",
            "",
            "        Args:",
            "            kwargs: Any arguments to be passed to the prompt template.",
            "",
            "        Returns:",
            "            A formatted string.",
            "",
            "        Example:",
            "",
            "            .. code-block:: python",
            "",
            "                prompt.format(variable1=\"foo\")",
            "        \"\"\"",
            "        kwargs = self._merge_partial_and_user_variables(**kwargs)",
            "        return DEFAULT_FORMATTER_MAPPING[self.template_format](self.template, **kwargs)",
            "",
            "    @root_validator()",
            "    def template_is_valid(cls, values: Dict) -> Dict:",
            "        \"\"\"Check that template and input variables are consistent.\"\"\"",
            "        if values[\"validate_template\"]:",
            "            all_inputs = values[\"input_variables\"] + list(values[\"partial_variables\"])",
            "            check_valid_template(",
            "                values[\"template\"], values[\"template_format\"], all_inputs",
            "            )",
            "        return values",
            "",
            "    @classmethod",
            "    def from_examples(",
            "        cls,",
            "        examples: List[str],",
            "        suffix: str,",
            "        input_variables: List[str],",
            "        example_separator: str = \"\\n\\n\",",
            "        prefix: str = \"\",",
            "        **kwargs: Any,",
            "    ) -> PromptTemplate:",
            "        \"\"\"Take examples in list format with prefix and suffix to create a prompt.",
            "",
            "        Intended to be used as a way to dynamically create a prompt from examples.",
            "",
            "        Args:",
            "            examples: List of examples to use in the prompt.",
            "            suffix: String to go after the list of examples. Should generally",
            "                set up the user's input.",
            "            input_variables: A list of variable names the final prompt template",
            "                will expect.",
            "            example_separator: The separator to use in between examples. Defaults",
            "                to two new line characters.",
            "            prefix: String that should go before any examples. Generally includes",
            "                examples. Default to an empty string.",
            "",
            "        Returns:",
            "            The final prompt generated.",
            "        \"\"\"",
            "        template = example_separator.join([prefix, *examples, suffix])",
            "        return cls(input_variables=input_variables, template=template, **kwargs)",
            "",
            "    @classmethod",
            "    def from_file(",
            "        cls, template_file: Union[str, Path], input_variables: List[str], **kwargs: Any",
            "    ) -> PromptTemplate:",
            "        \"\"\"Load a prompt from a file.",
            "",
            "        Args:",
            "            template_file: The path to the file containing the prompt template.",
            "            input_variables: A list of variable names the final prompt template",
            "                will expect.",
            "",
            "        Returns:",
            "            The prompt loaded from the file.",
            "        \"\"\"",
            "        with open(str(template_file), \"r\") as f:",
            "            template = f.read()",
            "        return cls(input_variables=input_variables, template=template, **kwargs)",
            "",
            "    @classmethod",
            "    def from_template(",
            "        cls,",
            "        template: str,",
            "        *,",
            "        template_format: str = \"f-string\",",
            "        partial_variables: Optional[Dict[str, Any]] = None,",
            "        **kwargs: Any,",
            "    ) -> PromptTemplate:",
            "        \"\"\"Load a prompt template from a template.",
            "",
            "        Args:",
            "            template: The template to load.",
            "            template_format: The format of the template. Use `jinja2` for jinja2,",
            "                             and `f-string` or None for f-strings.",
            "            partial_variables: A dictionary of variables that can be used to partially",
            "                               fill in the template. For example, if the template is",
            "                              `\"{variable1} {variable2}\"`, and `partial_variables` is",
            "                              `{\"variable1\": \"foo\"}`, then the final prompt will be",
            "                              `\"foo {variable2}\"`.",
            "",
            "        Returns:",
            "            The prompt template loaded from the template.",
            "        \"\"\"",
            "        if template_format == \"jinja2\":",
            "            # Get the variables for the template",
            "            input_variables = _get_jinja2_variables_from_template(template)",
            "        elif template_format == \"f-string\":",
            "            input_variables = {",
            "                v for _, v, _, _ in Formatter().parse(template) if v is not None",
            "            }",
            "        else:",
            "            raise ValueError(f\"Unsupported template format: {template_format}\")",
            "",
            "        _partial_variables = partial_variables or {}",
            "",
            "        if _partial_variables:",
            "            input_variables = {",
            "                var for var in input_variables if var not in _partial_variables",
            "            }",
            "",
            "        return cls(",
            "            input_variables=sorted(input_variables),",
            "            template=template,",
            "            template_format=template_format,",
            "            partial_variables=_partial_variables,",
            "            **kwargs,",
            "        )",
            "",
            "",
            "# For backwards compatibility.",
            "Prompt = PromptTemplate"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "libs.langchain.langchain.prompts.prompt.PromptTemplate.from_file",
            "libs.langchain.langchain.prompts.prompt.PromptTemplate.from_examples",
            "libs.langchain.langchain.prompts.prompt.Prompt",
            "libs.langchain.langchain.prompts.prompt.PromptTemplate.from_template",
            "libs.langchain.langchain.prompts.prompt.PromptTemplate.__add__",
            "libs.langchain.langchain.prompts.prompt.PromptTemplate.self"
        ]
    },
    "libs/langchain/tests/unit_tests/prompts/test_loading.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from pathlib import Path"
            },
            "1": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " from typing import Iterator"
            },
            "2": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 7,
                "PatchRowcode": "+import pytest"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from langchain.output_parsers import RegexParser"
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from langchain.prompts.few_shot import FewShotPromptTemplate"
            },
            "7": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from langchain.prompts.loading import load_prompt"
            },
            "8": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 45,
                "PatchRowcode": "     assert prompt == expected_prompt"
            },
            "9": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+def test_loading_jinja_from_JSON() -> None:"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+    \"\"\"Test that loading jinja2 format prompts from JSON raises ValueError.\"\"\""
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+    prompt_path = EXAMPLE_DIR / \"jinja_injection_prompt.json\""
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+    with pytest.raises(ValueError, match=\".*can lead to arbitrary code execution.*\"):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+        load_prompt(prompt_path)"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+def test_loading_jinja_from_YAML() -> None:"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+    \"\"\"Test that loading jinja2 format prompts from YAML raises ValueError.\"\"\""
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+    prompt_path = EXAMPLE_DIR / \"jinja_injection_prompt.yaml\""
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+    with pytest.raises(ValueError, match=\".*can lead to arbitrary code execution.*\"):"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+        load_prompt(prompt_path)"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 62,
                "PatchRowcode": " def test_saving_loading_round_trip(tmp_path: Path) -> None:"
            },
            "26": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "     \"\"\"Test equality when saving and loading a prompt.\"\"\""
            },
            "27": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 64,
                "PatchRowcode": "     simple_prompt = PromptTemplate("
            }
        },
        "frontPatchFile": [
            "\"\"\"Test loading functionality.\"\"\"",
            "import os",
            "from contextlib import contextmanager",
            "from pathlib import Path",
            "from typing import Iterator",
            "",
            "from langchain.output_parsers import RegexParser",
            "from langchain.prompts.few_shot import FewShotPromptTemplate",
            "from langchain.prompts.loading import load_prompt",
            "from langchain.prompts.prompt import PromptTemplate",
            "",
            "EXAMPLE_DIR = Path(\"tests/unit_tests/examples\").absolute()",
            "",
            "",
            "@contextmanager",
            "def change_directory(dir: Path) -> Iterator:",
            "    \"\"\"Change the working directory to the right folder.\"\"\"",
            "    origin = Path().absolute()",
            "    try:",
            "        os.chdir(dir)",
            "        yield",
            "    finally:",
            "        os.chdir(origin)",
            "",
            "",
            "def test_loading_from_YAML() -> None:",
            "    \"\"\"Test loading from yaml file.\"\"\"",
            "    prompt = load_prompt(EXAMPLE_DIR / \"simple_prompt.yaml\")",
            "    expected_prompt = PromptTemplate(",
            "        input_variables=[\"adjective\", \"content\"],",
            "        template=\"Tell me a {adjective} joke about {content}.\",",
            "    )",
            "    assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_from_JSON() -> None:",
            "    \"\"\"Test loading from json file.\"\"\"",
            "    prompt = load_prompt(EXAMPLE_DIR / \"simple_prompt.json\")",
            "    expected_prompt = PromptTemplate(",
            "        input_variables=[\"adjective\", \"content\"],",
            "        template=\"Tell me a {adjective} joke about {content}.\",",
            "    )",
            "    assert prompt == expected_prompt",
            "",
            "",
            "def test_saving_loading_round_trip(tmp_path: Path) -> None:",
            "    \"\"\"Test equality when saving and loading a prompt.\"\"\"",
            "    simple_prompt = PromptTemplate(",
            "        input_variables=[\"adjective\", \"content\"],",
            "        template=\"Tell me a {adjective} joke about {content}.\",",
            "    )",
            "    simple_prompt.save(file_path=tmp_path / \"prompt.yaml\")",
            "    loaded_prompt = load_prompt(tmp_path / \"prompt.yaml\")",
            "    assert loaded_prompt == simple_prompt",
            "",
            "    few_shot_prompt = FewShotPromptTemplate(",
            "        input_variables=[\"adjective\"],",
            "        prefix=\"Write antonyms for the following words.\",",
            "        example_prompt=PromptTemplate(",
            "            input_variables=[\"input\", \"output\"],",
            "            template=\"Input: {input}\\nOutput: {output}\",",
            "        ),",
            "        examples=[",
            "            {\"input\": \"happy\", \"output\": \"sad\"},",
            "            {\"input\": \"tall\", \"output\": \"short\"},",
            "        ],",
            "        suffix=\"Input: {adjective}\\nOutput:\",",
            "    )",
            "    few_shot_prompt.save(file_path=tmp_path / \"few_shot.yaml\")",
            "    loaded_prompt = load_prompt(tmp_path / \"few_shot.yaml\")",
            "    assert loaded_prompt == few_shot_prompt",
            "",
            "",
            "def test_loading_with_template_as_file() -> None:",
            "    \"\"\"Test loading when the template is a file.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"simple_prompt_with_template_file.json\")",
            "        expected_prompt = PromptTemplate(",
            "            input_variables=[\"adjective\", \"content\"],",
            "            template=\"Tell me a {adjective} joke about {content}.\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_from_yaml() -> None:",
            "    \"\"\"Test loading few shot prompt from yaml.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt.yaml\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_from_json() -> None:",
            "    \"\"\"Test loading few shot prompt from json.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt.json\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_when_examples_in_config() -> None:",
            "    \"\"\"Test loading few shot prompt when the examples are in the config.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt_examples_in.json\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_example_prompt() -> None:",
            "    \"\"\"Test loading few shot when the example prompt is in its own file.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt_example_prompt.json\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_with_output_parser() -> None:",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"prompt_with_output_parser.json\")",
            "        expected_template = \"Given the following question and student answer, provide a correct answer and score the student answer.\\nQuestion: {question}\\nStudent Answer: {student_answer}\\nCorrect Answer:\"  # noqa: E501",
            "        expected_prompt = PromptTemplate(",
            "            input_variables=[\"question\", \"student_answer\"],",
            "            output_parser=RegexParser(",
            "                regex=\"(.*?)\\nScore: (.*)\",",
            "                output_keys=[\"answer\", \"score\"],",
            "            ),",
            "            template=expected_template,",
            "        )",
            "        assert prompt == expected_prompt"
        ],
        "afterPatchFile": [
            "\"\"\"Test loading functionality.\"\"\"",
            "import os",
            "from contextlib import contextmanager",
            "from pathlib import Path",
            "from typing import Iterator",
            "",
            "import pytest",
            "",
            "from langchain.output_parsers import RegexParser",
            "from langchain.prompts.few_shot import FewShotPromptTemplate",
            "from langchain.prompts.loading import load_prompt",
            "from langchain.prompts.prompt import PromptTemplate",
            "",
            "EXAMPLE_DIR = Path(\"tests/unit_tests/examples\").absolute()",
            "",
            "",
            "@contextmanager",
            "def change_directory(dir: Path) -> Iterator:",
            "    \"\"\"Change the working directory to the right folder.\"\"\"",
            "    origin = Path().absolute()",
            "    try:",
            "        os.chdir(dir)",
            "        yield",
            "    finally:",
            "        os.chdir(origin)",
            "",
            "",
            "def test_loading_from_YAML() -> None:",
            "    \"\"\"Test loading from yaml file.\"\"\"",
            "    prompt = load_prompt(EXAMPLE_DIR / \"simple_prompt.yaml\")",
            "    expected_prompt = PromptTemplate(",
            "        input_variables=[\"adjective\", \"content\"],",
            "        template=\"Tell me a {adjective} joke about {content}.\",",
            "    )",
            "    assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_from_JSON() -> None:",
            "    \"\"\"Test loading from json file.\"\"\"",
            "    prompt = load_prompt(EXAMPLE_DIR / \"simple_prompt.json\")",
            "    expected_prompt = PromptTemplate(",
            "        input_variables=[\"adjective\", \"content\"],",
            "        template=\"Tell me a {adjective} joke about {content}.\",",
            "    )",
            "    assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_jinja_from_JSON() -> None:",
            "    \"\"\"Test that loading jinja2 format prompts from JSON raises ValueError.\"\"\"",
            "    prompt_path = EXAMPLE_DIR / \"jinja_injection_prompt.json\"",
            "    with pytest.raises(ValueError, match=\".*can lead to arbitrary code execution.*\"):",
            "        load_prompt(prompt_path)",
            "",
            "",
            "def test_loading_jinja_from_YAML() -> None:",
            "    \"\"\"Test that loading jinja2 format prompts from YAML raises ValueError.\"\"\"",
            "    prompt_path = EXAMPLE_DIR / \"jinja_injection_prompt.yaml\"",
            "    with pytest.raises(ValueError, match=\".*can lead to arbitrary code execution.*\"):",
            "        load_prompt(prompt_path)",
            "",
            "",
            "def test_saving_loading_round_trip(tmp_path: Path) -> None:",
            "    \"\"\"Test equality when saving and loading a prompt.\"\"\"",
            "    simple_prompt = PromptTemplate(",
            "        input_variables=[\"adjective\", \"content\"],",
            "        template=\"Tell me a {adjective} joke about {content}.\",",
            "    )",
            "    simple_prompt.save(file_path=tmp_path / \"prompt.yaml\")",
            "    loaded_prompt = load_prompt(tmp_path / \"prompt.yaml\")",
            "    assert loaded_prompt == simple_prompt",
            "",
            "    few_shot_prompt = FewShotPromptTemplate(",
            "        input_variables=[\"adjective\"],",
            "        prefix=\"Write antonyms for the following words.\",",
            "        example_prompt=PromptTemplate(",
            "            input_variables=[\"input\", \"output\"],",
            "            template=\"Input: {input}\\nOutput: {output}\",",
            "        ),",
            "        examples=[",
            "            {\"input\": \"happy\", \"output\": \"sad\"},",
            "            {\"input\": \"tall\", \"output\": \"short\"},",
            "        ],",
            "        suffix=\"Input: {adjective}\\nOutput:\",",
            "    )",
            "    few_shot_prompt.save(file_path=tmp_path / \"few_shot.yaml\")",
            "    loaded_prompt = load_prompt(tmp_path / \"few_shot.yaml\")",
            "    assert loaded_prompt == few_shot_prompt",
            "",
            "",
            "def test_loading_with_template_as_file() -> None:",
            "    \"\"\"Test loading when the template is a file.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"simple_prompt_with_template_file.json\")",
            "        expected_prompt = PromptTemplate(",
            "            input_variables=[\"adjective\", \"content\"],",
            "            template=\"Tell me a {adjective} joke about {content}.\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_from_yaml() -> None:",
            "    \"\"\"Test loading few shot prompt from yaml.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt.yaml\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_from_json() -> None:",
            "    \"\"\"Test loading few shot prompt from json.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt.json\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_when_examples_in_config() -> None:",
            "    \"\"\"Test loading few shot prompt when the examples are in the config.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt_examples_in.json\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_few_shot_prompt_example_prompt() -> None:",
            "    \"\"\"Test loading few shot when the example prompt is in its own file.\"\"\"",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"few_shot_prompt_example_prompt.json\")",
            "        expected_prompt = FewShotPromptTemplate(",
            "            input_variables=[\"adjective\"],",
            "            prefix=\"Write antonyms for the following words.\",",
            "            example_prompt=PromptTemplate(",
            "                input_variables=[\"input\", \"output\"],",
            "                template=\"Input: {input}\\nOutput: {output}\",",
            "            ),",
            "            examples=[",
            "                {\"input\": \"happy\", \"output\": \"sad\"},",
            "                {\"input\": \"tall\", \"output\": \"short\"},",
            "            ],",
            "            suffix=\"Input: {adjective}\\nOutput:\",",
            "        )",
            "        assert prompt == expected_prompt",
            "",
            "",
            "def test_loading_with_output_parser() -> None:",
            "    with change_directory(EXAMPLE_DIR):",
            "        prompt = load_prompt(\"prompt_with_output_parser.json\")",
            "        expected_template = \"Given the following question and student answer, provide a correct answer and score the student answer.\\nQuestion: {question}\\nStudent Answer: {student_answer}\\nCorrect Answer:\"  # noqa: E501",
            "        expected_prompt = PromptTemplate(",
            "            input_variables=[\"question\", \"student_answer\"],",
            "            output_parser=RegexParser(",
            "                regex=\"(.*?)\\nScore: (.*)\",",
            "                output_keys=[\"answer\", \"score\"],",
            "            ),",
            "            template=expected_template,",
            "        )",
            "        assert prompt == expected_prompt"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "yt_dlp.YoutubeDL"
        ]
    }
}