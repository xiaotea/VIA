{
    "aiohttp/http_parser.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 60,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 61,
                "PatchRowcode": " ASCIISET: Final[Set[str]] = set(string.printable)"
            },
            "2": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 62,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-# See https://tools.ietf.org/html/rfc7230#section-3.1.1"
            },
            "4": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-# and https://tools.ietf.org/html/rfc7230#appendix-B"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+# See https://www.rfc-editor.org/rfc/rfc9110.html#name-overview"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+# and https://www.rfc-editor.org/rfc/rfc9110.html#name-tokens"
            },
            "7": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 65,
                "PatchRowcode": " #"
            },
            "8": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " #     method = token"
            },
            "9": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " #     tchar = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" /"
            },
            "10": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": " #             \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / DIGIT / ALPHA"
            },
            "11": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " #     token = 1*tchar"
            },
            "12": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 70,
                "PatchRowcode": " METHRE: Final[Pattern[str]] = re.compile(r\"[!#$%&'*+\\-.^_`|~0-9A-Za-z]+\")"
            },
            "13": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-VERSRE: Final[Pattern[str]] = re.compile(r\"HTTP/(\\d+).(\\d+)\")"
            },
            "14": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-HDRRE: Final[Pattern[bytes]] = re.compile(rb\"[\\x00-\\x1F\\x7F()<>@,;:\\[\\]={} \\t\\\\\\\\\\\"]\")"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+VERSRE: Final[Pattern[str]] = re.compile(r\"HTTP/(\\d).(\\d)\")"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+HDRRE: Final[Pattern[bytes]] = re.compile(rb\"[\\x00-\\x1F\\x7F()<>@,;:\\[\\]={} \\t\\\"\\\\]\")"
            },
            "17": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 73,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 74,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 75,
                "PatchRowcode": " class RawRequestMessage(NamedTuple):"
            },
            "20": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "             except ValueError:"
            },
            "21": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "                 raise InvalidHeader(line) from None"
            },
            "22": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            bname = bname.strip(b\" \\t\")"
            },
            "24": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            bvalue = bvalue.lstrip()"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+            # https://www.rfc-editor.org/rfc/rfc9112.html#section-5.1-2"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+            if {bname[0], bname[-1]} & {32, 9}:  # {\" \", \"\\t\"}"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+                raise InvalidHeader(line)"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 154,
                "PatchRowcode": "+"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+            bvalue = bvalue.lstrip(b\" \\t\")"
            },
            "30": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "             if HDRRE.search(bname):"
            },
            "31": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "                 raise InvalidHeader(bname)"
            },
            "32": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 158,
                "PatchRowcode": "             if len(bname) > self.max_field_size:"
            },
            "33": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "             # consume continuation lines"
            },
            "34": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "             continuation = line and line[0] in (32, 9)  # (' ', '\\t')"
            },
            "35": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 175,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 176,
                "PatchRowcode": "+            # Deprecated: https://www.rfc-editor.org/rfc/rfc9112.html#name-obsolete-line-folding"
            },
            "37": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 177,
                "PatchRowcode": "             if continuation:"
            },
            "38": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 178,
                "PatchRowcode": "                 bvalue_lst = [bvalue]"
            },
            "39": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "                 while continuation:"
            },
            "40": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 208,
                "PatchRowcode": "                         str(header_length),"
            },
            "41": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "                     )"
            },
            "42": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 210,
                "PatchRowcode": " "
            },
            "43": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            bvalue = bvalue.strip()"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+            bvalue = bvalue.strip(b\" \\t\")"
            },
            "45": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 212,
                "PatchRowcode": "             name = bname.decode(\"utf-8\", \"surrogateescape\")"
            },
            "46": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 213,
                "PatchRowcode": "             value = bvalue.decode(\"utf-8\", \"surrogateescape\")"
            },
            "47": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": 214,
                "PatchRowcode": " "
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 215,
                "PatchRowcode": "+            # https://www.rfc-editor.org/rfc/rfc9110.html#section-5.5-5"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 216,
                "PatchRowcode": "+            if \"\\n\" in value or \"\\r\" in value or \"\\x00\" in value:"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 217,
                "PatchRowcode": "+                raise InvalidHeader(bvalue)"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 218,
                "PatchRowcode": "+"
            },
            "52": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": 219,
                "PatchRowcode": "             headers.add(name, value)"
            },
            "53": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": 220,
                "PatchRowcode": "             raw_headers.append((bname, bvalue))"
            },
            "54": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": 221,
                "PatchRowcode": " "
            },
            "55": {
                "beforePatchRowNumber": 322,
                "afterPatchRowNumber": 330,
                "PatchRowcode": "                             if length_hdr is None:"
            },
            "56": {
                "beforePatchRowNumber": 323,
                "afterPatchRowNumber": 331,
                "PatchRowcode": "                                 return None"
            },
            "57": {
                "beforePatchRowNumber": 324,
                "afterPatchRowNumber": 332,
                "PatchRowcode": " "
            },
            "58": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            try:"
            },
            "59": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                length = int(length_hdr)"
            },
            "60": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            except ValueError:"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 333,
                "PatchRowcode": "+                            # Shouldn't allow +/- or other number formats."
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 334,
                "PatchRowcode": "+                            # https://www.rfc-editor.org/rfc/rfc9110#section-8.6-2"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 335,
                "PatchRowcode": "+                            if not length_hdr.strip(\" \\t\").isdigit():"
            },
            "64": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 336,
                "PatchRowcode": "                                 raise InvalidHeader(CONTENT_LENGTH)"
            },
            "65": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": 337,
                "PatchRowcode": " "
            },
            "66": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            if length < 0:"
            },
            "67": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                raise InvalidHeader(CONTENT_LENGTH)"
            },
            "68": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "69": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            return length"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 338,
                "PatchRowcode": "+                            return int(length_hdr)"
            },
            "71": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 339,
                "PatchRowcode": " "
            },
            "72": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 340,
                "PatchRowcode": "                         length = get_content_length()"
            },
            "73": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": 341,
                "PatchRowcode": "                         # do not support old websocket spec"
            },
            "74": {
                "beforePatchRowNumber": 470,
                "afterPatchRowNumber": 475,
                "PatchRowcode": "         upgrade = False"
            },
            "75": {
                "beforePatchRowNumber": 471,
                "afterPatchRowNumber": 476,
                "PatchRowcode": "         chunked = False"
            },
            "76": {
                "beforePatchRowNumber": 472,
                "afterPatchRowNumber": 477,
                "PatchRowcode": " "
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 478,
                "PatchRowcode": "+        # https://www.rfc-editor.org/rfc/rfc9110.html#section-5.5-6"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 479,
                "PatchRowcode": "+        # https://www.rfc-editor.org/rfc/rfc9110.html#name-collected-abnf"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 480,
                "PatchRowcode": "+        singletons = ("
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 481,
                "PatchRowcode": "+            hdrs.CONTENT_LENGTH,"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 482,
                "PatchRowcode": "+            hdrs.CONTENT_LOCATION,"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 483,
                "PatchRowcode": "+            hdrs.CONTENT_RANGE,"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 484,
                "PatchRowcode": "+            hdrs.CONTENT_TYPE,"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 485,
                "PatchRowcode": "+            hdrs.ETAG,"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 486,
                "PatchRowcode": "+            hdrs.HOST,"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 487,
                "PatchRowcode": "+            hdrs.MAX_FORWARDS,"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 488,
                "PatchRowcode": "+            hdrs.SERVER,"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 489,
                "PatchRowcode": "+            hdrs.TRANSFER_ENCODING,"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 490,
                "PatchRowcode": "+            hdrs.USER_AGENT,"
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 491,
                "PatchRowcode": "+        )"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 492,
                "PatchRowcode": "+        bad_hdr = next((h for h in singletons if len(headers.getall(h, ())) > 1), None)"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 493,
                "PatchRowcode": "+        if bad_hdr is not None:"
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 494,
                "PatchRowcode": "+            raise BadHttpMessage(f\"Duplicate '{bad_hdr}' header found.\")"
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 495,
                "PatchRowcode": "+"
            },
            "95": {
                "beforePatchRowNumber": 473,
                "afterPatchRowNumber": 496,
                "PatchRowcode": "         # keep-alive"
            },
            "96": {
                "beforePatchRowNumber": 474,
                "afterPatchRowNumber": 497,
                "PatchRowcode": "         conn = headers.get(hdrs.CONNECTION)"
            },
            "97": {
                "beforePatchRowNumber": 475,
                "afterPatchRowNumber": 498,
                "PatchRowcode": "         if conn:"
            },
            "98": {
                "beforePatchRowNumber": 523,
                "afterPatchRowNumber": 546,
                "PatchRowcode": "         # request line"
            },
            "99": {
                "beforePatchRowNumber": 524,
                "afterPatchRowNumber": 547,
                "PatchRowcode": "         line = lines[0].decode(\"utf-8\", \"surrogateescape\")"
            },
            "100": {
                "beforePatchRowNumber": 525,
                "afterPatchRowNumber": 548,
                "PatchRowcode": "         try:"
            },
            "101": {
                "beforePatchRowNumber": 526,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            method, path, version = line.split(None, 2)"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 549,
                "PatchRowcode": "+            method, path, version = line.split(maxsplit=2)"
            },
            "103": {
                "beforePatchRowNumber": 527,
                "afterPatchRowNumber": 550,
                "PatchRowcode": "         except ValueError:"
            },
            "104": {
                "beforePatchRowNumber": 528,
                "afterPatchRowNumber": 551,
                "PatchRowcode": "             raise BadStatusLine(line) from None"
            },
            "105": {
                "beforePatchRowNumber": 529,
                "afterPatchRowNumber": 552,
                "PatchRowcode": " "
            },
            "106": {
                "beforePatchRowNumber": 537,
                "afterPatchRowNumber": 560,
                "PatchRowcode": "             raise BadStatusLine(method)"
            },
            "107": {
                "beforePatchRowNumber": 538,
                "afterPatchRowNumber": 561,
                "PatchRowcode": " "
            },
            "108": {
                "beforePatchRowNumber": 539,
                "afterPatchRowNumber": 562,
                "PatchRowcode": "         # version"
            },
            "109": {
                "beforePatchRowNumber": 540,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "110": {
                "beforePatchRowNumber": 541,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if version.startswith(\"HTTP/\"):"
            },
            "111": {
                "beforePatchRowNumber": 542,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                n1, n2 = version[5:].split(\".\", 1)"
            },
            "112": {
                "beforePatchRowNumber": 543,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                version_o = HttpVersion(int(n1), int(n2))"
            },
            "113": {
                "beforePatchRowNumber": 544,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            else:"
            },
            "114": {
                "beforePatchRowNumber": 545,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                raise BadStatusLine(version)"
            },
            "115": {
                "beforePatchRowNumber": 546,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except Exception:"
            },
            "116": {
                "beforePatchRowNumber": 547,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise BadStatusLine(version)"
            },
            "117": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 563,
                "PatchRowcode": "+        match = VERSRE.match(version)"
            },
            "118": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 564,
                "PatchRowcode": "+        if match is None:"
            },
            "119": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 565,
                "PatchRowcode": "+            raise BadStatusLine(line)"
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 566,
                "PatchRowcode": "+        version_o = HttpVersion(int(match.group(1)), int(match.group(2)))"
            },
            "121": {
                "beforePatchRowNumber": 548,
                "afterPatchRowNumber": 567,
                "PatchRowcode": " "
            },
            "122": {
                "beforePatchRowNumber": 549,
                "afterPatchRowNumber": 568,
                "PatchRowcode": "         if method == \"CONNECT\":"
            },
            "123": {
                "beforePatchRowNumber": 550,
                "afterPatchRowNumber": 569,
                "PatchRowcode": "             # authority-form,"
            },
            "124": {
                "beforePatchRowNumber": 611,
                "afterPatchRowNumber": 630,
                "PatchRowcode": "     def parse_message(self, lines: List[bytes]) -> RawResponseMessage:"
            },
            "125": {
                "beforePatchRowNumber": 612,
                "afterPatchRowNumber": 631,
                "PatchRowcode": "         line = lines[0].decode(\"utf-8\", \"surrogateescape\")"
            },
            "126": {
                "beforePatchRowNumber": 613,
                "afterPatchRowNumber": 632,
                "PatchRowcode": "         try:"
            },
            "127": {
                "beforePatchRowNumber": 614,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            version, status = line.split(None, 1)"
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 633,
                "PatchRowcode": "+            version, status = line.split(maxsplit=1)"
            },
            "129": {
                "beforePatchRowNumber": 615,
                "afterPatchRowNumber": 634,
                "PatchRowcode": "         except ValueError:"
            },
            "130": {
                "beforePatchRowNumber": 616,
                "afterPatchRowNumber": 635,
                "PatchRowcode": "             raise BadStatusLine(line) from None"
            },
            "131": {
                "beforePatchRowNumber": 617,
                "afterPatchRowNumber": 636,
                "PatchRowcode": " "
            },
            "132": {
                "beforePatchRowNumber": 618,
                "afterPatchRowNumber": 637,
                "PatchRowcode": "         try:"
            },
            "133": {
                "beforePatchRowNumber": 619,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            status, reason = status.split(None, 1)"
            },
            "134": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 638,
                "PatchRowcode": "+            status, reason = status.split(maxsplit=1)"
            },
            "135": {
                "beforePatchRowNumber": 620,
                "afterPatchRowNumber": 639,
                "PatchRowcode": "         except ValueError:"
            },
            "136": {
                "beforePatchRowNumber": 621,
                "afterPatchRowNumber": 640,
                "PatchRowcode": "             reason = \"\""
            },
            "137": {
                "beforePatchRowNumber": 622,
                "afterPatchRowNumber": 641,
                "PatchRowcode": " "
            },
            "138": {
                "beforePatchRowNumber": 632,
                "afterPatchRowNumber": 651,
                "PatchRowcode": "         version_o = HttpVersion(int(match.group(1)), int(match.group(2)))"
            },
            "139": {
                "beforePatchRowNumber": 633,
                "afterPatchRowNumber": 652,
                "PatchRowcode": " "
            },
            "140": {
                "beforePatchRowNumber": 634,
                "afterPatchRowNumber": 653,
                "PatchRowcode": "         # The status code is a three-digit number"
            },
            "141": {
                "beforePatchRowNumber": 635,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        try:"
            },
            "142": {
                "beforePatchRowNumber": 636,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            status_i = int(status)"
            },
            "143": {
                "beforePatchRowNumber": 637,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        except ValueError:"
            },
            "144": {
                "beforePatchRowNumber": 638,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise BadStatusLine(line) from None"
            },
            "145": {
                "beforePatchRowNumber": 639,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "146": {
                "beforePatchRowNumber": 640,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if status_i > 999:"
            },
            "147": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 654,
                "PatchRowcode": "+        if len(status) != 3 or not status.isdigit():"
            },
            "148": {
                "beforePatchRowNumber": 641,
                "afterPatchRowNumber": 655,
                "PatchRowcode": "             raise BadStatusLine(line)"
            },
            "149": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 656,
                "PatchRowcode": "+        status_i = int(status)"
            },
            "150": {
                "beforePatchRowNumber": 642,
                "afterPatchRowNumber": 657,
                "PatchRowcode": " "
            },
            "151": {
                "beforePatchRowNumber": 643,
                "afterPatchRowNumber": 658,
                "PatchRowcode": "         # read headers"
            },
            "152": {
                "beforePatchRowNumber": 644,
                "afterPatchRowNumber": 659,
                "PatchRowcode": "         ("
            },
            "153": {
                "beforePatchRowNumber": 773,
                "afterPatchRowNumber": 788,
                "PatchRowcode": "                         else:"
            },
            "154": {
                "beforePatchRowNumber": 774,
                "afterPatchRowNumber": 789,
                "PatchRowcode": "                             size_b = chunk[:pos]"
            },
            "155": {
                "beforePatchRowNumber": 775,
                "afterPatchRowNumber": 790,
                "PatchRowcode": " "
            },
            "156": {
                "beforePatchRowNumber": 776,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        try:"
            },
            "157": {
                "beforePatchRowNumber": 777,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            size = int(bytes(size_b), 16)"
            },
            "158": {
                "beforePatchRowNumber": 778,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        except ValueError:"
            },
            "159": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 791,
                "PatchRowcode": "+                        if not size_b.isdigit():"
            },
            "160": {
                "beforePatchRowNumber": 779,
                "afterPatchRowNumber": 792,
                "PatchRowcode": "                             exc = TransferEncodingError("
            },
            "161": {
                "beforePatchRowNumber": 780,
                "afterPatchRowNumber": 793,
                "PatchRowcode": "                                 chunk[:pos].decode(\"ascii\", \"surrogateescape\")"
            },
            "162": {
                "beforePatchRowNumber": 781,
                "afterPatchRowNumber": 794,
                "PatchRowcode": "                             )"
            },
            "163": {
                "beforePatchRowNumber": 782,
                "afterPatchRowNumber": 795,
                "PatchRowcode": "                             self.payload.set_exception(exc)"
            },
            "164": {
                "beforePatchRowNumber": 783,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            raise exc from None"
            },
            "165": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 796,
                "PatchRowcode": "+                            raise exc"
            },
            "166": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 797,
                "PatchRowcode": "+                        size = int(bytes(size_b), 16)"
            },
            "167": {
                "beforePatchRowNumber": 784,
                "afterPatchRowNumber": 798,
                "PatchRowcode": " "
            },
            "168": {
                "beforePatchRowNumber": 785,
                "afterPatchRowNumber": 799,
                "PatchRowcode": "                         chunk = chunk[pos + 2 :]"
            },
            "169": {
                "beforePatchRowNumber": 786,
                "afterPatchRowNumber": 800,
                "PatchRowcode": "                         if size == 0:  # eof marker"
            }
        },
        "frontPatchFile": [
            "import abc",
            "import asyncio",
            "import collections",
            "import re",
            "import string",
            "import zlib",
            "from contextlib import suppress",
            "from enum import IntEnum",
            "from typing import (",
            "    Any,",
            "    Generic,",
            "    List,",
            "    NamedTuple,",
            "    Optional,",
            "    Pattern,",
            "    Set,",
            "    Tuple,",
            "    Type,",
            "    TypeVar,",
            "    Union,",
            "    cast,",
            ")",
            "",
            "from multidict import CIMultiDict, CIMultiDictProxy, istr",
            "from yarl import URL",
            "",
            "from . import hdrs",
            "from .base_protocol import BaseProtocol",
            "from .helpers import NO_EXTENSIONS, BaseTimerContext",
            "from .http_exceptions import (",
            "    BadHttpMessage,",
            "    BadStatusLine,",
            "    ContentEncodingError,",
            "    ContentLengthError,",
            "    InvalidHeader,",
            "    LineTooLong,",
            "    TransferEncodingError,",
            ")",
            "from .http_writer import HttpVersion, HttpVersion10",
            "from .log import internal_logger",
            "from .streams import EMPTY_PAYLOAD, StreamReader",
            "from .typedefs import Final, RawHeaders",
            "",
            "try:",
            "    import brotli",
            "",
            "    HAS_BROTLI = True",
            "except ImportError:  # pragma: no cover",
            "    HAS_BROTLI = False",
            "",
            "",
            "__all__ = (",
            "    \"HeadersParser\",",
            "    \"HttpParser\",",
            "    \"HttpRequestParser\",",
            "    \"HttpResponseParser\",",
            "    \"RawRequestMessage\",",
            "    \"RawResponseMessage\",",
            ")",
            "",
            "ASCIISET: Final[Set[str]] = set(string.printable)",
            "",
            "# See https://tools.ietf.org/html/rfc7230#section-3.1.1",
            "# and https://tools.ietf.org/html/rfc7230#appendix-B",
            "#",
            "#     method = token",
            "#     tchar = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" /",
            "#             \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / DIGIT / ALPHA",
            "#     token = 1*tchar",
            "METHRE: Final[Pattern[str]] = re.compile(r\"[!#$%&'*+\\-.^_`|~0-9A-Za-z]+\")",
            "VERSRE: Final[Pattern[str]] = re.compile(r\"HTTP/(\\d+).(\\d+)\")",
            "HDRRE: Final[Pattern[bytes]] = re.compile(rb\"[\\x00-\\x1F\\x7F()<>@,;:\\[\\]={} \\t\\\\\\\\\\\"]\")",
            "",
            "",
            "class RawRequestMessage(NamedTuple):",
            "    method: str",
            "    path: str",
            "    version: HttpVersion",
            "    headers: \"CIMultiDictProxy[str]\"",
            "    raw_headers: RawHeaders",
            "    should_close: bool",
            "    compression: Optional[str]",
            "    upgrade: bool",
            "    chunked: bool",
            "    url: URL",
            "",
            "",
            "RawResponseMessage = collections.namedtuple(",
            "    \"RawResponseMessage\",",
            "    [",
            "        \"version\",",
            "        \"code\",",
            "        \"reason\",",
            "        \"headers\",",
            "        \"raw_headers\",",
            "        \"should_close\",",
            "        \"compression\",",
            "        \"upgrade\",",
            "        \"chunked\",",
            "    ],",
            ")",
            "",
            "",
            "_MsgT = TypeVar(\"_MsgT\", RawRequestMessage, RawResponseMessage)",
            "",
            "",
            "class ParseState(IntEnum):",
            "",
            "    PARSE_NONE = 0",
            "    PARSE_LENGTH = 1",
            "    PARSE_CHUNKED = 2",
            "    PARSE_UNTIL_EOF = 3",
            "",
            "",
            "class ChunkState(IntEnum):",
            "    PARSE_CHUNKED_SIZE = 0",
            "    PARSE_CHUNKED_CHUNK = 1",
            "    PARSE_CHUNKED_CHUNK_EOF = 2",
            "    PARSE_MAYBE_TRAILERS = 3",
            "    PARSE_TRAILERS = 4",
            "",
            "",
            "class HeadersParser:",
            "    def __init__(",
            "        self,",
            "        max_line_size: int = 8190,",
            "        max_headers: int = 32768,",
            "        max_field_size: int = 8190,",
            "    ) -> None:",
            "        self.max_line_size = max_line_size",
            "        self.max_headers = max_headers",
            "        self.max_field_size = max_field_size",
            "",
            "    def parse_headers(",
            "        self, lines: List[bytes]",
            "    ) -> Tuple[\"CIMultiDictProxy[str]\", RawHeaders]:",
            "        headers: CIMultiDict[str] = CIMultiDict()",
            "        raw_headers = []",
            "",
            "        lines_idx = 1",
            "        line = lines[1]",
            "        line_count = len(lines)",
            "",
            "        while line:",
            "            # Parse initial header name : value pair.",
            "            try:",
            "                bname, bvalue = line.split(b\":\", 1)",
            "            except ValueError:",
            "                raise InvalidHeader(line) from None",
            "",
            "            bname = bname.strip(b\" \\t\")",
            "            bvalue = bvalue.lstrip()",
            "            if HDRRE.search(bname):",
            "                raise InvalidHeader(bname)",
            "            if len(bname) > self.max_field_size:",
            "                raise LineTooLong(",
            "                    \"request header name {}\".format(",
            "                        bname.decode(\"utf8\", \"xmlcharrefreplace\")",
            "                    ),",
            "                    str(self.max_field_size),",
            "                    str(len(bname)),",
            "                )",
            "",
            "            header_length = len(bvalue)",
            "",
            "            # next line",
            "            lines_idx += 1",
            "            line = lines[lines_idx]",
            "",
            "            # consume continuation lines",
            "            continuation = line and line[0] in (32, 9)  # (' ', '\\t')",
            "",
            "            if continuation:",
            "                bvalue_lst = [bvalue]",
            "                while continuation:",
            "                    header_length += len(line)",
            "                    if header_length > self.max_field_size:",
            "                        raise LineTooLong(",
            "                            \"request header field {}\".format(",
            "                                bname.decode(\"utf8\", \"xmlcharrefreplace\")",
            "                            ),",
            "                            str(self.max_field_size),",
            "                            str(header_length),",
            "                        )",
            "                    bvalue_lst.append(line)",
            "",
            "                    # next line",
            "                    lines_idx += 1",
            "                    if lines_idx < line_count:",
            "                        line = lines[lines_idx]",
            "                        if line:",
            "                            continuation = line[0] in (32, 9)  # (' ', '\\t')",
            "                    else:",
            "                        line = b\"\"",
            "                        break",
            "                bvalue = b\"\".join(bvalue_lst)",
            "            else:",
            "                if header_length > self.max_field_size:",
            "                    raise LineTooLong(",
            "                        \"request header field {}\".format(",
            "                            bname.decode(\"utf8\", \"xmlcharrefreplace\")",
            "                        ),",
            "                        str(self.max_field_size),",
            "                        str(header_length),",
            "                    )",
            "",
            "            bvalue = bvalue.strip()",
            "            name = bname.decode(\"utf-8\", \"surrogateescape\")",
            "            value = bvalue.decode(\"utf-8\", \"surrogateescape\")",
            "",
            "            headers.add(name, value)",
            "            raw_headers.append((bname, bvalue))",
            "",
            "        return (CIMultiDictProxy(headers), tuple(raw_headers))",
            "",
            "",
            "class HttpParser(abc.ABC, Generic[_MsgT]):",
            "    def __init__(",
            "        self,",
            "        protocol: Optional[BaseProtocol] = None,",
            "        loop: Optional[asyncio.AbstractEventLoop] = None,",
            "        limit: int = 2**16,",
            "        max_line_size: int = 8190,",
            "        max_headers: int = 32768,",
            "        max_field_size: int = 8190,",
            "        timer: Optional[BaseTimerContext] = None,",
            "        code: Optional[int] = None,",
            "        method: Optional[str] = None,",
            "        readall: bool = False,",
            "        payload_exception: Optional[Type[BaseException]] = None,",
            "        response_with_body: bool = True,",
            "        read_until_eof: bool = False,",
            "        auto_decompress: bool = True,",
            "    ) -> None:",
            "        self.protocol = protocol",
            "        self.loop = loop",
            "        self.max_line_size = max_line_size",
            "        self.max_headers = max_headers",
            "        self.max_field_size = max_field_size",
            "        self.timer = timer",
            "        self.code = code",
            "        self.method = method",
            "        self.readall = readall",
            "        self.payload_exception = payload_exception",
            "        self.response_with_body = response_with_body",
            "        self.read_until_eof = read_until_eof",
            "",
            "        self._lines: List[bytes] = []",
            "        self._tail = b\"\"",
            "        self._upgraded = False",
            "        self._payload = None",
            "        self._payload_parser: Optional[HttpPayloadParser] = None",
            "        self._auto_decompress = auto_decompress",
            "        self._limit = limit",
            "        self._headers_parser = HeadersParser(max_line_size, max_headers, max_field_size)",
            "",
            "    @abc.abstractmethod",
            "    def parse_message(self, lines: List[bytes]) -> _MsgT:",
            "        pass",
            "",
            "    def feed_eof(self) -> Optional[_MsgT]:",
            "        if self._payload_parser is not None:",
            "            self._payload_parser.feed_eof()",
            "            self._payload_parser = None",
            "        else:",
            "            # try to extract partial message",
            "            if self._tail:",
            "                self._lines.append(self._tail)",
            "",
            "            if self._lines:",
            "                if self._lines[-1] != \"\\r\\n\":",
            "                    self._lines.append(b\"\")",
            "                with suppress(Exception):",
            "                    return self.parse_message(self._lines)",
            "        return None",
            "",
            "    def feed_data(",
            "        self,",
            "        data: bytes,",
            "        SEP: bytes = b\"\\r\\n\",",
            "        EMPTY: bytes = b\"\",",
            "        CONTENT_LENGTH: istr = hdrs.CONTENT_LENGTH,",
            "        METH_CONNECT: str = hdrs.METH_CONNECT,",
            "        SEC_WEBSOCKET_KEY1: istr = hdrs.SEC_WEBSOCKET_KEY1,",
            "    ) -> Tuple[List[Tuple[_MsgT, StreamReader]], bool, bytes]:",
            "",
            "        messages = []",
            "",
            "        if self._tail:",
            "            data, self._tail = self._tail + data, b\"\"",
            "",
            "        data_len = len(data)",
            "        start_pos = 0",
            "        loop = self.loop",
            "",
            "        while start_pos < data_len:",
            "",
            "            # read HTTP message (request/response line + headers), \\r\\n\\r\\n",
            "            # and split by lines",
            "            if self._payload_parser is None and not self._upgraded:",
            "                pos = data.find(SEP, start_pos)",
            "                # consume \\r\\n",
            "                if pos == start_pos and not self._lines:",
            "                    start_pos = pos + 2",
            "                    continue",
            "",
            "                if pos >= start_pos:",
            "                    # line found",
            "                    self._lines.append(data[start_pos:pos])",
            "                    start_pos = pos + 2",
            "",
            "                    # \\r\\n\\r\\n found",
            "                    if self._lines[-1] == EMPTY:",
            "                        try:",
            "                            msg: _MsgT = self.parse_message(self._lines)",
            "                        finally:",
            "                            self._lines.clear()",
            "",
            "                        def get_content_length() -> Optional[int]:",
            "                            # payload length",
            "                            length_hdr = msg.headers.get(CONTENT_LENGTH)",
            "                            if length_hdr is None:",
            "                                return None",
            "",
            "                            try:",
            "                                length = int(length_hdr)",
            "                            except ValueError:",
            "                                raise InvalidHeader(CONTENT_LENGTH)",
            "",
            "                            if length < 0:",
            "                                raise InvalidHeader(CONTENT_LENGTH)",
            "",
            "                            return length",
            "",
            "                        length = get_content_length()",
            "                        # do not support old websocket spec",
            "                        if SEC_WEBSOCKET_KEY1 in msg.headers:",
            "                            raise InvalidHeader(SEC_WEBSOCKET_KEY1)",
            "",
            "                        self._upgraded = msg.upgrade",
            "",
            "                        method = getattr(msg, \"method\", self.method)",
            "",
            "                        assert self.protocol is not None",
            "                        # calculate payload",
            "                        if (",
            "                            (length is not None and length > 0)",
            "                            or msg.chunked",
            "                            and not msg.upgrade",
            "                        ):",
            "                            payload = StreamReader(",
            "                                self.protocol,",
            "                                timer=self.timer,",
            "                                loop=loop,",
            "                                limit=self._limit,",
            "                            )",
            "                            payload_parser = HttpPayloadParser(",
            "                                payload,",
            "                                length=length,",
            "                                chunked=msg.chunked,",
            "                                method=method,",
            "                                compression=msg.compression,",
            "                                code=self.code,",
            "                                readall=self.readall,",
            "                                response_with_body=self.response_with_body,",
            "                                auto_decompress=self._auto_decompress,",
            "                            )",
            "                            if not payload_parser.done:",
            "                                self._payload_parser = payload_parser",
            "                        elif method == METH_CONNECT:",
            "                            assert isinstance(msg, RawRequestMessage)",
            "                            payload = StreamReader(",
            "                                self.protocol,",
            "                                timer=self.timer,",
            "                                loop=loop,",
            "                                limit=self._limit,",
            "                            )",
            "                            self._upgraded = True",
            "                            self._payload_parser = HttpPayloadParser(",
            "                                payload,",
            "                                method=msg.method,",
            "                                compression=msg.compression,",
            "                                readall=True,",
            "                                auto_decompress=self._auto_decompress,",
            "                            )",
            "                        else:",
            "                            if (",
            "                                getattr(msg, \"code\", 100) >= 199",
            "                                and length is None",
            "                                and self.read_until_eof",
            "                            ):",
            "                                payload = StreamReader(",
            "                                    self.protocol,",
            "                                    timer=self.timer,",
            "                                    loop=loop,",
            "                                    limit=self._limit,",
            "                                )",
            "                                payload_parser = HttpPayloadParser(",
            "                                    payload,",
            "                                    length=length,",
            "                                    chunked=msg.chunked,",
            "                                    method=method,",
            "                                    compression=msg.compression,",
            "                                    code=self.code,",
            "                                    readall=True,",
            "                                    response_with_body=self.response_with_body,",
            "                                    auto_decompress=self._auto_decompress,",
            "                                )",
            "                                if not payload_parser.done:",
            "                                    self._payload_parser = payload_parser",
            "                            else:",
            "                                payload = EMPTY_PAYLOAD",
            "",
            "                        messages.append((msg, payload))",
            "                else:",
            "                    self._tail = data[start_pos:]",
            "                    data = EMPTY",
            "                    break",
            "",
            "            # no parser, just store",
            "            elif self._payload_parser is None and self._upgraded:",
            "                assert not self._lines",
            "                break",
            "",
            "            # feed payload",
            "            elif data and start_pos < data_len:",
            "                assert not self._lines",
            "                assert self._payload_parser is not None",
            "                try:",
            "                    eof, data = self._payload_parser.feed_data(data[start_pos:])",
            "                except BaseException as exc:",
            "                    if self.payload_exception is not None:",
            "                        self._payload_parser.payload.set_exception(",
            "                            self.payload_exception(str(exc))",
            "                        )",
            "                    else:",
            "                        self._payload_parser.payload.set_exception(exc)",
            "",
            "                    eof = True",
            "                    data = b\"\"",
            "",
            "                if eof:",
            "                    start_pos = 0",
            "                    data_len = len(data)",
            "                    self._payload_parser = None",
            "                    continue",
            "            else:",
            "                break",
            "",
            "        if data and start_pos < data_len:",
            "            data = data[start_pos:]",
            "        else:",
            "            data = EMPTY",
            "",
            "        return messages, self._upgraded, data",
            "",
            "    def parse_headers(",
            "        self, lines: List[bytes]",
            "    ) -> Tuple[",
            "        \"CIMultiDictProxy[str]\", RawHeaders, Optional[bool], Optional[str], bool, bool",
            "    ]:",
            "        \"\"\"Parses RFC 5322 headers from a stream.",
            "",
            "        Line continuations are supported. Returns list of header name",
            "        and value pairs. Header name is in upper case.",
            "        \"\"\"",
            "        headers, raw_headers = self._headers_parser.parse_headers(lines)",
            "        close_conn = None",
            "        encoding = None",
            "        upgrade = False",
            "        chunked = False",
            "",
            "        # keep-alive",
            "        conn = headers.get(hdrs.CONNECTION)",
            "        if conn:",
            "            v = conn.lower()",
            "            if v == \"close\":",
            "                close_conn = True",
            "            elif v == \"keep-alive\":",
            "                close_conn = False",
            "            elif v == \"upgrade\":",
            "                upgrade = True",
            "",
            "        # encoding",
            "        enc = headers.get(hdrs.CONTENT_ENCODING)",
            "        if enc:",
            "            enc = enc.lower()",
            "            if enc in (\"gzip\", \"deflate\", \"br\"):",
            "                encoding = enc",
            "",
            "        # chunking",
            "        te = headers.get(hdrs.TRANSFER_ENCODING)",
            "        if te is not None:",
            "            if \"chunked\" == te.lower():",
            "                chunked = True",
            "            else:",
            "                raise BadHttpMessage(\"Request has invalid `Transfer-Encoding`\")",
            "",
            "            if hdrs.CONTENT_LENGTH in headers:",
            "                raise BadHttpMessage(",
            "                    \"Transfer-Encoding can't be present with Content-Length\",",
            "                )",
            "",
            "        return (headers, raw_headers, close_conn, encoding, upgrade, chunked)",
            "",
            "    def set_upgraded(self, val: bool) -> None:",
            "        \"\"\"Set connection upgraded (to websocket) mode.",
            "",
            "        :param bool val: new state.",
            "        \"\"\"",
            "        self._upgraded = val",
            "",
            "",
            "class HttpRequestParser(HttpParser[RawRequestMessage]):",
            "    \"\"\"Read request status line.",
            "",
            "    Exception .http_exceptions.BadStatusLine",
            "    could be raised in case of any errors in status line.",
            "    Returns RawRequestMessage.",
            "    \"\"\"",
            "",
            "    def parse_message(self, lines: List[bytes]) -> RawRequestMessage:",
            "        # request line",
            "        line = lines[0].decode(\"utf-8\", \"surrogateescape\")",
            "        try:",
            "            method, path, version = line.split(None, 2)",
            "        except ValueError:",
            "            raise BadStatusLine(line) from None",
            "",
            "        if len(path) > self.max_line_size:",
            "            raise LineTooLong(",
            "                \"Status line is too long\", str(self.max_line_size), str(len(path))",
            "            )",
            "",
            "        # method",
            "        if not METHRE.match(method):",
            "            raise BadStatusLine(method)",
            "",
            "        # version",
            "        try:",
            "            if version.startswith(\"HTTP/\"):",
            "                n1, n2 = version[5:].split(\".\", 1)",
            "                version_o = HttpVersion(int(n1), int(n2))",
            "            else:",
            "                raise BadStatusLine(version)",
            "        except Exception:",
            "            raise BadStatusLine(version)",
            "",
            "        if method == \"CONNECT\":",
            "            # authority-form,",
            "            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.3",
            "            url = URL.build(authority=path, encoded=True)",
            "        elif path.startswith(\"/\"):",
            "            # origin-form,",
            "            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.1",
            "            path_part, _hash_separator, url_fragment = path.partition(\"#\")",
            "            path_part, _question_mark_separator, qs_part = path_part.partition(\"?\")",
            "",
            "            # NOTE: `yarl.URL.build()` is used to mimic what the Cython-based",
            "            # NOTE: parser does, otherwise it results into the same",
            "            # NOTE: HTTP Request-Line input producing different",
            "            # NOTE: `yarl.URL()` objects",
            "            url = URL.build(",
            "                path=path_part,",
            "                query_string=qs_part,",
            "                fragment=url_fragment,",
            "                encoded=True,",
            "            )",
            "        else:",
            "            # absolute-form for proxy maybe,",
            "            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.2",
            "            url = URL(path, encoded=True)",
            "",
            "        # read headers",
            "        (",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "        ) = self.parse_headers(lines)",
            "",
            "        if close is None:  # then the headers weren't set in the request",
            "            if version_o <= HttpVersion10:  # HTTP 1.0 must asks to not close",
            "                close = True",
            "            else:  # HTTP 1.1 must ask to close.",
            "                close = False",
            "",
            "        return RawRequestMessage(",
            "            method,",
            "            path,",
            "            version_o,",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "            url,",
            "        )",
            "",
            "",
            "class HttpResponseParser(HttpParser[RawResponseMessage]):",
            "    \"\"\"Read response status line and headers.",
            "",
            "    BadStatusLine could be raised in case of any errors in status line.",
            "    Returns RawResponseMessage.",
            "    \"\"\"",
            "",
            "    def parse_message(self, lines: List[bytes]) -> RawResponseMessage:",
            "        line = lines[0].decode(\"utf-8\", \"surrogateescape\")",
            "        try:",
            "            version, status = line.split(None, 1)",
            "        except ValueError:",
            "            raise BadStatusLine(line) from None",
            "",
            "        try:",
            "            status, reason = status.split(None, 1)",
            "        except ValueError:",
            "            reason = \"\"",
            "",
            "        if len(reason) > self.max_line_size:",
            "            raise LineTooLong(",
            "                \"Status line is too long\", str(self.max_line_size), str(len(reason))",
            "            )",
            "",
            "        # version",
            "        match = VERSRE.match(version)",
            "        if match is None:",
            "            raise BadStatusLine(line)",
            "        version_o = HttpVersion(int(match.group(1)), int(match.group(2)))",
            "",
            "        # The status code is a three-digit number",
            "        try:",
            "            status_i = int(status)",
            "        except ValueError:",
            "            raise BadStatusLine(line) from None",
            "",
            "        if status_i > 999:",
            "            raise BadStatusLine(line)",
            "",
            "        # read headers",
            "        (",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "        ) = self.parse_headers(lines)",
            "",
            "        if close is None:",
            "            close = version_o <= HttpVersion10",
            "",
            "        return RawResponseMessage(",
            "            version_o,",
            "            status_i,",
            "            reason.strip(),",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "        )",
            "",
            "",
            "class HttpPayloadParser:",
            "    def __init__(",
            "        self,",
            "        payload: StreamReader,",
            "        length: Optional[int] = None,",
            "        chunked: bool = False,",
            "        compression: Optional[str] = None,",
            "        code: Optional[int] = None,",
            "        method: Optional[str] = None,",
            "        readall: bool = False,",
            "        response_with_body: bool = True,",
            "        auto_decompress: bool = True,",
            "    ) -> None:",
            "        self._length = 0",
            "        self._type = ParseState.PARSE_NONE",
            "        self._chunk = ChunkState.PARSE_CHUNKED_SIZE",
            "        self._chunk_size = 0",
            "        self._chunk_tail = b\"\"",
            "        self._auto_decompress = auto_decompress",
            "        self.done = False",
            "",
            "        # payload decompression wrapper",
            "        if response_with_body and compression and self._auto_decompress:",
            "            real_payload: Union[StreamReader, DeflateBuffer] = DeflateBuffer(",
            "                payload, compression",
            "            )",
            "        else:",
            "            real_payload = payload",
            "",
            "        # payload parser",
            "        if not response_with_body:",
            "            # don't parse payload if it's not expected to be received",
            "            self._type = ParseState.PARSE_NONE",
            "            real_payload.feed_eof()",
            "            self.done = True",
            "",
            "        elif chunked:",
            "            self._type = ParseState.PARSE_CHUNKED",
            "        elif length is not None:",
            "            self._type = ParseState.PARSE_LENGTH",
            "            self._length = length",
            "            if self._length == 0:",
            "                real_payload.feed_eof()",
            "                self.done = True",
            "        else:",
            "            if readall and code != 204:",
            "                self._type = ParseState.PARSE_UNTIL_EOF",
            "            elif method in (\"PUT\", \"POST\"):",
            "                internal_logger.warning(  # pragma: no cover",
            "                    \"Content-Length or Transfer-Encoding header is required\"",
            "                )",
            "                self._type = ParseState.PARSE_NONE",
            "                real_payload.feed_eof()",
            "                self.done = True",
            "",
            "        self.payload = real_payload",
            "",
            "    def feed_eof(self) -> None:",
            "        if self._type == ParseState.PARSE_UNTIL_EOF:",
            "            self.payload.feed_eof()",
            "        elif self._type == ParseState.PARSE_LENGTH:",
            "            raise ContentLengthError(",
            "                \"Not enough data for satisfy content length header.\"",
            "            )",
            "        elif self._type == ParseState.PARSE_CHUNKED:",
            "            raise TransferEncodingError(",
            "                \"Not enough data for satisfy transfer length header.\"",
            "            )",
            "",
            "    def feed_data(",
            "        self, chunk: bytes, SEP: bytes = b\"\\r\\n\", CHUNK_EXT: bytes = b\";\"",
            "    ) -> Tuple[bool, bytes]:",
            "        # Read specified amount of bytes",
            "        if self._type == ParseState.PARSE_LENGTH:",
            "            required = self._length",
            "            chunk_len = len(chunk)",
            "",
            "            if required >= chunk_len:",
            "                self._length = required - chunk_len",
            "                self.payload.feed_data(chunk, chunk_len)",
            "                if self._length == 0:",
            "                    self.payload.feed_eof()",
            "                    return True, b\"\"",
            "            else:",
            "                self._length = 0",
            "                self.payload.feed_data(chunk[:required], required)",
            "                self.payload.feed_eof()",
            "                return True, chunk[required:]",
            "",
            "        # Chunked transfer encoding parser",
            "        elif self._type == ParseState.PARSE_CHUNKED:",
            "            if self._chunk_tail:",
            "                chunk = self._chunk_tail + chunk",
            "                self._chunk_tail = b\"\"",
            "",
            "            while chunk:",
            "",
            "                # read next chunk size",
            "                if self._chunk == ChunkState.PARSE_CHUNKED_SIZE:",
            "                    pos = chunk.find(SEP)",
            "                    if pos >= 0:",
            "                        i = chunk.find(CHUNK_EXT, 0, pos)",
            "                        if i >= 0:",
            "                            size_b = chunk[:i]  # strip chunk-extensions",
            "                        else:",
            "                            size_b = chunk[:pos]",
            "",
            "                        try:",
            "                            size = int(bytes(size_b), 16)",
            "                        except ValueError:",
            "                            exc = TransferEncodingError(",
            "                                chunk[:pos].decode(\"ascii\", \"surrogateescape\")",
            "                            )",
            "                            self.payload.set_exception(exc)",
            "                            raise exc from None",
            "",
            "                        chunk = chunk[pos + 2 :]",
            "                        if size == 0:  # eof marker",
            "                            self._chunk = ChunkState.PARSE_MAYBE_TRAILERS",
            "                        else:",
            "                            self._chunk = ChunkState.PARSE_CHUNKED_CHUNK",
            "                            self._chunk_size = size",
            "                            self.payload.begin_http_chunk_receiving()",
            "                    else:",
            "                        self._chunk_tail = chunk",
            "                        return False, b\"\"",
            "",
            "                # read chunk and feed buffer",
            "                if self._chunk == ChunkState.PARSE_CHUNKED_CHUNK:",
            "                    required = self._chunk_size",
            "                    chunk_len = len(chunk)",
            "",
            "                    if required > chunk_len:",
            "                        self._chunk_size = required - chunk_len",
            "                        self.payload.feed_data(chunk, chunk_len)",
            "                        return False, b\"\"",
            "                    else:",
            "                        self._chunk_size = 0",
            "                        self.payload.feed_data(chunk[:required], required)",
            "                        chunk = chunk[required:]",
            "                        self._chunk = ChunkState.PARSE_CHUNKED_CHUNK_EOF",
            "                        self.payload.end_http_chunk_receiving()",
            "",
            "                # toss the CRLF at the end of the chunk",
            "                if self._chunk == ChunkState.PARSE_CHUNKED_CHUNK_EOF:",
            "                    if chunk[:2] == SEP:",
            "                        chunk = chunk[2:]",
            "                        self._chunk = ChunkState.PARSE_CHUNKED_SIZE",
            "                    else:",
            "                        self._chunk_tail = chunk",
            "                        return False, b\"\"",
            "",
            "                # if stream does not contain trailer, after 0\\r\\n",
            "                # we should get another \\r\\n otherwise",
            "                # trailers needs to be skiped until \\r\\n\\r\\n",
            "                if self._chunk == ChunkState.PARSE_MAYBE_TRAILERS:",
            "                    head = chunk[:2]",
            "                    if head == SEP:",
            "                        # end of stream",
            "                        self.payload.feed_eof()",
            "                        return True, chunk[2:]",
            "                    # Both CR and LF, or only LF may not be received yet. It is",
            "                    # expected that CRLF or LF will be shown at the very first",
            "                    # byte next time, otherwise trailers should come. The last",
            "                    # CRLF which marks the end of response might not be",
            "                    # contained in the same TCP segment which delivered the",
            "                    # size indicator.",
            "                    if not head:",
            "                        return False, b\"\"",
            "                    if head == SEP[:1]:",
            "                        self._chunk_tail = head",
            "                        return False, b\"\"",
            "                    self._chunk = ChunkState.PARSE_TRAILERS",
            "",
            "                # read and discard trailer up to the CRLF terminator",
            "                if self._chunk == ChunkState.PARSE_TRAILERS:",
            "                    pos = chunk.find(SEP)",
            "                    if pos >= 0:",
            "                        chunk = chunk[pos + 2 :]",
            "                        self._chunk = ChunkState.PARSE_MAYBE_TRAILERS",
            "                    else:",
            "                        self._chunk_tail = chunk",
            "                        return False, b\"\"",
            "",
            "        # Read all bytes until eof",
            "        elif self._type == ParseState.PARSE_UNTIL_EOF:",
            "            self.payload.feed_data(chunk, len(chunk))",
            "",
            "        return False, b\"\"",
            "",
            "",
            "class DeflateBuffer:",
            "    \"\"\"DeflateStream decompress stream and feed data into specified stream.\"\"\"",
            "",
            "    decompressor: Any",
            "",
            "    def __init__(self, out: StreamReader, encoding: Optional[str]) -> None:",
            "        self.out = out",
            "        self.size = 0",
            "        self.encoding = encoding",
            "        self._started_decoding = False",
            "",
            "        if encoding == \"br\":",
            "            if not HAS_BROTLI:  # pragma: no cover",
            "                raise ContentEncodingError(",
            "                    \"Can not decode content-encoding: brotli (br). \"",
            "                    \"Please install `Brotli`\"",
            "                )",
            "",
            "            class BrotliDecoder:",
            "                # Supports both 'brotlipy' and 'Brotli' packages",
            "                # since they share an import name. The top branches",
            "                # are for 'brotlipy' and bottom branches for 'Brotli'",
            "                def __init__(self) -> None:",
            "                    self._obj = brotli.Decompressor()",
            "",
            "                def decompress(self, data: bytes) -> bytes:",
            "                    if hasattr(self._obj, \"decompress\"):",
            "                        return cast(bytes, self._obj.decompress(data))",
            "                    return cast(bytes, self._obj.process(data))",
            "",
            "                def flush(self) -> bytes:",
            "                    if hasattr(self._obj, \"flush\"):",
            "                        return cast(bytes, self._obj.flush())",
            "                    return b\"\"",
            "",
            "            self.decompressor = BrotliDecoder()",
            "        else:",
            "            zlib_mode = 16 + zlib.MAX_WBITS if encoding == \"gzip\" else zlib.MAX_WBITS",
            "            self.decompressor = zlib.decompressobj(wbits=zlib_mode)",
            "",
            "    def set_exception(self, exc: BaseException) -> None:",
            "        self.out.set_exception(exc)",
            "",
            "    def feed_data(self, chunk: bytes, size: int) -> None:",
            "        if not size:",
            "            return",
            "",
            "        self.size += size",
            "",
            "        # RFC1950",
            "        # bits 0..3 = CM = 0b1000 = 8 = \"deflate\"",
            "        # bits 4..7 = CINFO = 1..7 = windows size.",
            "        if (",
            "            not self._started_decoding",
            "            and self.encoding == \"deflate\"",
            "            and chunk[0] & 0xF != 8",
            "        ):",
            "            # Change the decoder to decompress incorrectly compressed data",
            "            # Actually we should issue a warning about non-RFC-compliant data.",
            "            self.decompressor = zlib.decompressobj(wbits=-zlib.MAX_WBITS)",
            "",
            "        try:",
            "            chunk = self.decompressor.decompress(chunk)",
            "        except Exception:",
            "            raise ContentEncodingError(",
            "                \"Can not decode content-encoding: %s\" % self.encoding",
            "            )",
            "",
            "        self._started_decoding = True",
            "",
            "        if chunk:",
            "            self.out.feed_data(chunk, len(chunk))",
            "",
            "    def feed_eof(self) -> None:",
            "        chunk = self.decompressor.flush()",
            "",
            "        if chunk or self.size > 0:",
            "            self.out.feed_data(chunk, len(chunk))",
            "            if self.encoding == \"deflate\" and not self.decompressor.eof:",
            "                raise ContentEncodingError(\"deflate\")",
            "",
            "        self.out.feed_eof()",
            "",
            "    def begin_http_chunk_receiving(self) -> None:",
            "        self.out.begin_http_chunk_receiving()",
            "",
            "    def end_http_chunk_receiving(self) -> None:",
            "        self.out.end_http_chunk_receiving()",
            "",
            "",
            "HttpRequestParserPy = HttpRequestParser",
            "HttpResponseParserPy = HttpResponseParser",
            "RawRequestMessagePy = RawRequestMessage",
            "RawResponseMessagePy = RawResponseMessage",
            "",
            "try:",
            "    if not NO_EXTENSIONS:",
            "        from ._http_parser import (  # type: ignore[import,no-redef]",
            "            HttpRequestParser,",
            "            HttpResponseParser,",
            "            RawRequestMessage,",
            "            RawResponseMessage,",
            "        )",
            "",
            "        HttpRequestParserC = HttpRequestParser",
            "        HttpResponseParserC = HttpResponseParser",
            "        RawRequestMessageC = RawRequestMessage",
            "        RawResponseMessageC = RawResponseMessage",
            "except ImportError:  # pragma: no cover",
            "    pass"
        ],
        "afterPatchFile": [
            "import abc",
            "import asyncio",
            "import collections",
            "import re",
            "import string",
            "import zlib",
            "from contextlib import suppress",
            "from enum import IntEnum",
            "from typing import (",
            "    Any,",
            "    Generic,",
            "    List,",
            "    NamedTuple,",
            "    Optional,",
            "    Pattern,",
            "    Set,",
            "    Tuple,",
            "    Type,",
            "    TypeVar,",
            "    Union,",
            "    cast,",
            ")",
            "",
            "from multidict import CIMultiDict, CIMultiDictProxy, istr",
            "from yarl import URL",
            "",
            "from . import hdrs",
            "from .base_protocol import BaseProtocol",
            "from .helpers import NO_EXTENSIONS, BaseTimerContext",
            "from .http_exceptions import (",
            "    BadHttpMessage,",
            "    BadStatusLine,",
            "    ContentEncodingError,",
            "    ContentLengthError,",
            "    InvalidHeader,",
            "    LineTooLong,",
            "    TransferEncodingError,",
            ")",
            "from .http_writer import HttpVersion, HttpVersion10",
            "from .log import internal_logger",
            "from .streams import EMPTY_PAYLOAD, StreamReader",
            "from .typedefs import Final, RawHeaders",
            "",
            "try:",
            "    import brotli",
            "",
            "    HAS_BROTLI = True",
            "except ImportError:  # pragma: no cover",
            "    HAS_BROTLI = False",
            "",
            "",
            "__all__ = (",
            "    \"HeadersParser\",",
            "    \"HttpParser\",",
            "    \"HttpRequestParser\",",
            "    \"HttpResponseParser\",",
            "    \"RawRequestMessage\",",
            "    \"RawResponseMessage\",",
            ")",
            "",
            "ASCIISET: Final[Set[str]] = set(string.printable)",
            "",
            "# See https://www.rfc-editor.org/rfc/rfc9110.html#name-overview",
            "# and https://www.rfc-editor.org/rfc/rfc9110.html#name-tokens",
            "#",
            "#     method = token",
            "#     tchar = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\" / \"+\" / \"-\" / \".\" /",
            "#             \"^\" / \"_\" / \"`\" / \"|\" / \"~\" / DIGIT / ALPHA",
            "#     token = 1*tchar",
            "METHRE: Final[Pattern[str]] = re.compile(r\"[!#$%&'*+\\-.^_`|~0-9A-Za-z]+\")",
            "VERSRE: Final[Pattern[str]] = re.compile(r\"HTTP/(\\d).(\\d)\")",
            "HDRRE: Final[Pattern[bytes]] = re.compile(rb\"[\\x00-\\x1F\\x7F()<>@,;:\\[\\]={} \\t\\\"\\\\]\")",
            "",
            "",
            "class RawRequestMessage(NamedTuple):",
            "    method: str",
            "    path: str",
            "    version: HttpVersion",
            "    headers: \"CIMultiDictProxy[str]\"",
            "    raw_headers: RawHeaders",
            "    should_close: bool",
            "    compression: Optional[str]",
            "    upgrade: bool",
            "    chunked: bool",
            "    url: URL",
            "",
            "",
            "RawResponseMessage = collections.namedtuple(",
            "    \"RawResponseMessage\",",
            "    [",
            "        \"version\",",
            "        \"code\",",
            "        \"reason\",",
            "        \"headers\",",
            "        \"raw_headers\",",
            "        \"should_close\",",
            "        \"compression\",",
            "        \"upgrade\",",
            "        \"chunked\",",
            "    ],",
            ")",
            "",
            "",
            "_MsgT = TypeVar(\"_MsgT\", RawRequestMessage, RawResponseMessage)",
            "",
            "",
            "class ParseState(IntEnum):",
            "",
            "    PARSE_NONE = 0",
            "    PARSE_LENGTH = 1",
            "    PARSE_CHUNKED = 2",
            "    PARSE_UNTIL_EOF = 3",
            "",
            "",
            "class ChunkState(IntEnum):",
            "    PARSE_CHUNKED_SIZE = 0",
            "    PARSE_CHUNKED_CHUNK = 1",
            "    PARSE_CHUNKED_CHUNK_EOF = 2",
            "    PARSE_MAYBE_TRAILERS = 3",
            "    PARSE_TRAILERS = 4",
            "",
            "",
            "class HeadersParser:",
            "    def __init__(",
            "        self,",
            "        max_line_size: int = 8190,",
            "        max_headers: int = 32768,",
            "        max_field_size: int = 8190,",
            "    ) -> None:",
            "        self.max_line_size = max_line_size",
            "        self.max_headers = max_headers",
            "        self.max_field_size = max_field_size",
            "",
            "    def parse_headers(",
            "        self, lines: List[bytes]",
            "    ) -> Tuple[\"CIMultiDictProxy[str]\", RawHeaders]:",
            "        headers: CIMultiDict[str] = CIMultiDict()",
            "        raw_headers = []",
            "",
            "        lines_idx = 1",
            "        line = lines[1]",
            "        line_count = len(lines)",
            "",
            "        while line:",
            "            # Parse initial header name : value pair.",
            "            try:",
            "                bname, bvalue = line.split(b\":\", 1)",
            "            except ValueError:",
            "                raise InvalidHeader(line) from None",
            "",
            "            # https://www.rfc-editor.org/rfc/rfc9112.html#section-5.1-2",
            "            if {bname[0], bname[-1]} & {32, 9}:  # {\" \", \"\\t\"}",
            "                raise InvalidHeader(line)",
            "",
            "            bvalue = bvalue.lstrip(b\" \\t\")",
            "            if HDRRE.search(bname):",
            "                raise InvalidHeader(bname)",
            "            if len(bname) > self.max_field_size:",
            "                raise LineTooLong(",
            "                    \"request header name {}\".format(",
            "                        bname.decode(\"utf8\", \"xmlcharrefreplace\")",
            "                    ),",
            "                    str(self.max_field_size),",
            "                    str(len(bname)),",
            "                )",
            "",
            "            header_length = len(bvalue)",
            "",
            "            # next line",
            "            lines_idx += 1",
            "            line = lines[lines_idx]",
            "",
            "            # consume continuation lines",
            "            continuation = line and line[0] in (32, 9)  # (' ', '\\t')",
            "",
            "            # Deprecated: https://www.rfc-editor.org/rfc/rfc9112.html#name-obsolete-line-folding",
            "            if continuation:",
            "                bvalue_lst = [bvalue]",
            "                while continuation:",
            "                    header_length += len(line)",
            "                    if header_length > self.max_field_size:",
            "                        raise LineTooLong(",
            "                            \"request header field {}\".format(",
            "                                bname.decode(\"utf8\", \"xmlcharrefreplace\")",
            "                            ),",
            "                            str(self.max_field_size),",
            "                            str(header_length),",
            "                        )",
            "                    bvalue_lst.append(line)",
            "",
            "                    # next line",
            "                    lines_idx += 1",
            "                    if lines_idx < line_count:",
            "                        line = lines[lines_idx]",
            "                        if line:",
            "                            continuation = line[0] in (32, 9)  # (' ', '\\t')",
            "                    else:",
            "                        line = b\"\"",
            "                        break",
            "                bvalue = b\"\".join(bvalue_lst)",
            "            else:",
            "                if header_length > self.max_field_size:",
            "                    raise LineTooLong(",
            "                        \"request header field {}\".format(",
            "                            bname.decode(\"utf8\", \"xmlcharrefreplace\")",
            "                        ),",
            "                        str(self.max_field_size),",
            "                        str(header_length),",
            "                    )",
            "",
            "            bvalue = bvalue.strip(b\" \\t\")",
            "            name = bname.decode(\"utf-8\", \"surrogateescape\")",
            "            value = bvalue.decode(\"utf-8\", \"surrogateescape\")",
            "",
            "            # https://www.rfc-editor.org/rfc/rfc9110.html#section-5.5-5",
            "            if \"\\n\" in value or \"\\r\" in value or \"\\x00\" in value:",
            "                raise InvalidHeader(bvalue)",
            "",
            "            headers.add(name, value)",
            "            raw_headers.append((bname, bvalue))",
            "",
            "        return (CIMultiDictProxy(headers), tuple(raw_headers))",
            "",
            "",
            "class HttpParser(abc.ABC, Generic[_MsgT]):",
            "    def __init__(",
            "        self,",
            "        protocol: Optional[BaseProtocol] = None,",
            "        loop: Optional[asyncio.AbstractEventLoop] = None,",
            "        limit: int = 2**16,",
            "        max_line_size: int = 8190,",
            "        max_headers: int = 32768,",
            "        max_field_size: int = 8190,",
            "        timer: Optional[BaseTimerContext] = None,",
            "        code: Optional[int] = None,",
            "        method: Optional[str] = None,",
            "        readall: bool = False,",
            "        payload_exception: Optional[Type[BaseException]] = None,",
            "        response_with_body: bool = True,",
            "        read_until_eof: bool = False,",
            "        auto_decompress: bool = True,",
            "    ) -> None:",
            "        self.protocol = protocol",
            "        self.loop = loop",
            "        self.max_line_size = max_line_size",
            "        self.max_headers = max_headers",
            "        self.max_field_size = max_field_size",
            "        self.timer = timer",
            "        self.code = code",
            "        self.method = method",
            "        self.readall = readall",
            "        self.payload_exception = payload_exception",
            "        self.response_with_body = response_with_body",
            "        self.read_until_eof = read_until_eof",
            "",
            "        self._lines: List[bytes] = []",
            "        self._tail = b\"\"",
            "        self._upgraded = False",
            "        self._payload = None",
            "        self._payload_parser: Optional[HttpPayloadParser] = None",
            "        self._auto_decompress = auto_decompress",
            "        self._limit = limit",
            "        self._headers_parser = HeadersParser(max_line_size, max_headers, max_field_size)",
            "",
            "    @abc.abstractmethod",
            "    def parse_message(self, lines: List[bytes]) -> _MsgT:",
            "        pass",
            "",
            "    def feed_eof(self) -> Optional[_MsgT]:",
            "        if self._payload_parser is not None:",
            "            self._payload_parser.feed_eof()",
            "            self._payload_parser = None",
            "        else:",
            "            # try to extract partial message",
            "            if self._tail:",
            "                self._lines.append(self._tail)",
            "",
            "            if self._lines:",
            "                if self._lines[-1] != \"\\r\\n\":",
            "                    self._lines.append(b\"\")",
            "                with suppress(Exception):",
            "                    return self.parse_message(self._lines)",
            "        return None",
            "",
            "    def feed_data(",
            "        self,",
            "        data: bytes,",
            "        SEP: bytes = b\"\\r\\n\",",
            "        EMPTY: bytes = b\"\",",
            "        CONTENT_LENGTH: istr = hdrs.CONTENT_LENGTH,",
            "        METH_CONNECT: str = hdrs.METH_CONNECT,",
            "        SEC_WEBSOCKET_KEY1: istr = hdrs.SEC_WEBSOCKET_KEY1,",
            "    ) -> Tuple[List[Tuple[_MsgT, StreamReader]], bool, bytes]:",
            "",
            "        messages = []",
            "",
            "        if self._tail:",
            "            data, self._tail = self._tail + data, b\"\"",
            "",
            "        data_len = len(data)",
            "        start_pos = 0",
            "        loop = self.loop",
            "",
            "        while start_pos < data_len:",
            "",
            "            # read HTTP message (request/response line + headers), \\r\\n\\r\\n",
            "            # and split by lines",
            "            if self._payload_parser is None and not self._upgraded:",
            "                pos = data.find(SEP, start_pos)",
            "                # consume \\r\\n",
            "                if pos == start_pos and not self._lines:",
            "                    start_pos = pos + 2",
            "                    continue",
            "",
            "                if pos >= start_pos:",
            "                    # line found",
            "                    self._lines.append(data[start_pos:pos])",
            "                    start_pos = pos + 2",
            "",
            "                    # \\r\\n\\r\\n found",
            "                    if self._lines[-1] == EMPTY:",
            "                        try:",
            "                            msg: _MsgT = self.parse_message(self._lines)",
            "                        finally:",
            "                            self._lines.clear()",
            "",
            "                        def get_content_length() -> Optional[int]:",
            "                            # payload length",
            "                            length_hdr = msg.headers.get(CONTENT_LENGTH)",
            "                            if length_hdr is None:",
            "                                return None",
            "",
            "                            # Shouldn't allow +/- or other number formats.",
            "                            # https://www.rfc-editor.org/rfc/rfc9110#section-8.6-2",
            "                            if not length_hdr.strip(\" \\t\").isdigit():",
            "                                raise InvalidHeader(CONTENT_LENGTH)",
            "",
            "                            return int(length_hdr)",
            "",
            "                        length = get_content_length()",
            "                        # do not support old websocket spec",
            "                        if SEC_WEBSOCKET_KEY1 in msg.headers:",
            "                            raise InvalidHeader(SEC_WEBSOCKET_KEY1)",
            "",
            "                        self._upgraded = msg.upgrade",
            "",
            "                        method = getattr(msg, \"method\", self.method)",
            "",
            "                        assert self.protocol is not None",
            "                        # calculate payload",
            "                        if (",
            "                            (length is not None and length > 0)",
            "                            or msg.chunked",
            "                            and not msg.upgrade",
            "                        ):",
            "                            payload = StreamReader(",
            "                                self.protocol,",
            "                                timer=self.timer,",
            "                                loop=loop,",
            "                                limit=self._limit,",
            "                            )",
            "                            payload_parser = HttpPayloadParser(",
            "                                payload,",
            "                                length=length,",
            "                                chunked=msg.chunked,",
            "                                method=method,",
            "                                compression=msg.compression,",
            "                                code=self.code,",
            "                                readall=self.readall,",
            "                                response_with_body=self.response_with_body,",
            "                                auto_decompress=self._auto_decompress,",
            "                            )",
            "                            if not payload_parser.done:",
            "                                self._payload_parser = payload_parser",
            "                        elif method == METH_CONNECT:",
            "                            assert isinstance(msg, RawRequestMessage)",
            "                            payload = StreamReader(",
            "                                self.protocol,",
            "                                timer=self.timer,",
            "                                loop=loop,",
            "                                limit=self._limit,",
            "                            )",
            "                            self._upgraded = True",
            "                            self._payload_parser = HttpPayloadParser(",
            "                                payload,",
            "                                method=msg.method,",
            "                                compression=msg.compression,",
            "                                readall=True,",
            "                                auto_decompress=self._auto_decompress,",
            "                            )",
            "                        else:",
            "                            if (",
            "                                getattr(msg, \"code\", 100) >= 199",
            "                                and length is None",
            "                                and self.read_until_eof",
            "                            ):",
            "                                payload = StreamReader(",
            "                                    self.protocol,",
            "                                    timer=self.timer,",
            "                                    loop=loop,",
            "                                    limit=self._limit,",
            "                                )",
            "                                payload_parser = HttpPayloadParser(",
            "                                    payload,",
            "                                    length=length,",
            "                                    chunked=msg.chunked,",
            "                                    method=method,",
            "                                    compression=msg.compression,",
            "                                    code=self.code,",
            "                                    readall=True,",
            "                                    response_with_body=self.response_with_body,",
            "                                    auto_decompress=self._auto_decompress,",
            "                                )",
            "                                if not payload_parser.done:",
            "                                    self._payload_parser = payload_parser",
            "                            else:",
            "                                payload = EMPTY_PAYLOAD",
            "",
            "                        messages.append((msg, payload))",
            "                else:",
            "                    self._tail = data[start_pos:]",
            "                    data = EMPTY",
            "                    break",
            "",
            "            # no parser, just store",
            "            elif self._payload_parser is None and self._upgraded:",
            "                assert not self._lines",
            "                break",
            "",
            "            # feed payload",
            "            elif data and start_pos < data_len:",
            "                assert not self._lines",
            "                assert self._payload_parser is not None",
            "                try:",
            "                    eof, data = self._payload_parser.feed_data(data[start_pos:])",
            "                except BaseException as exc:",
            "                    if self.payload_exception is not None:",
            "                        self._payload_parser.payload.set_exception(",
            "                            self.payload_exception(str(exc))",
            "                        )",
            "                    else:",
            "                        self._payload_parser.payload.set_exception(exc)",
            "",
            "                    eof = True",
            "                    data = b\"\"",
            "",
            "                if eof:",
            "                    start_pos = 0",
            "                    data_len = len(data)",
            "                    self._payload_parser = None",
            "                    continue",
            "            else:",
            "                break",
            "",
            "        if data and start_pos < data_len:",
            "            data = data[start_pos:]",
            "        else:",
            "            data = EMPTY",
            "",
            "        return messages, self._upgraded, data",
            "",
            "    def parse_headers(",
            "        self, lines: List[bytes]",
            "    ) -> Tuple[",
            "        \"CIMultiDictProxy[str]\", RawHeaders, Optional[bool], Optional[str], bool, bool",
            "    ]:",
            "        \"\"\"Parses RFC 5322 headers from a stream.",
            "",
            "        Line continuations are supported. Returns list of header name",
            "        and value pairs. Header name is in upper case.",
            "        \"\"\"",
            "        headers, raw_headers = self._headers_parser.parse_headers(lines)",
            "        close_conn = None",
            "        encoding = None",
            "        upgrade = False",
            "        chunked = False",
            "",
            "        # https://www.rfc-editor.org/rfc/rfc9110.html#section-5.5-6",
            "        # https://www.rfc-editor.org/rfc/rfc9110.html#name-collected-abnf",
            "        singletons = (",
            "            hdrs.CONTENT_LENGTH,",
            "            hdrs.CONTENT_LOCATION,",
            "            hdrs.CONTENT_RANGE,",
            "            hdrs.CONTENT_TYPE,",
            "            hdrs.ETAG,",
            "            hdrs.HOST,",
            "            hdrs.MAX_FORWARDS,",
            "            hdrs.SERVER,",
            "            hdrs.TRANSFER_ENCODING,",
            "            hdrs.USER_AGENT,",
            "        )",
            "        bad_hdr = next((h for h in singletons if len(headers.getall(h, ())) > 1), None)",
            "        if bad_hdr is not None:",
            "            raise BadHttpMessage(f\"Duplicate '{bad_hdr}' header found.\")",
            "",
            "        # keep-alive",
            "        conn = headers.get(hdrs.CONNECTION)",
            "        if conn:",
            "            v = conn.lower()",
            "            if v == \"close\":",
            "                close_conn = True",
            "            elif v == \"keep-alive\":",
            "                close_conn = False",
            "            elif v == \"upgrade\":",
            "                upgrade = True",
            "",
            "        # encoding",
            "        enc = headers.get(hdrs.CONTENT_ENCODING)",
            "        if enc:",
            "            enc = enc.lower()",
            "            if enc in (\"gzip\", \"deflate\", \"br\"):",
            "                encoding = enc",
            "",
            "        # chunking",
            "        te = headers.get(hdrs.TRANSFER_ENCODING)",
            "        if te is not None:",
            "            if \"chunked\" == te.lower():",
            "                chunked = True",
            "            else:",
            "                raise BadHttpMessage(\"Request has invalid `Transfer-Encoding`\")",
            "",
            "            if hdrs.CONTENT_LENGTH in headers:",
            "                raise BadHttpMessage(",
            "                    \"Transfer-Encoding can't be present with Content-Length\",",
            "                )",
            "",
            "        return (headers, raw_headers, close_conn, encoding, upgrade, chunked)",
            "",
            "    def set_upgraded(self, val: bool) -> None:",
            "        \"\"\"Set connection upgraded (to websocket) mode.",
            "",
            "        :param bool val: new state.",
            "        \"\"\"",
            "        self._upgraded = val",
            "",
            "",
            "class HttpRequestParser(HttpParser[RawRequestMessage]):",
            "    \"\"\"Read request status line.",
            "",
            "    Exception .http_exceptions.BadStatusLine",
            "    could be raised in case of any errors in status line.",
            "    Returns RawRequestMessage.",
            "    \"\"\"",
            "",
            "    def parse_message(self, lines: List[bytes]) -> RawRequestMessage:",
            "        # request line",
            "        line = lines[0].decode(\"utf-8\", \"surrogateescape\")",
            "        try:",
            "            method, path, version = line.split(maxsplit=2)",
            "        except ValueError:",
            "            raise BadStatusLine(line) from None",
            "",
            "        if len(path) > self.max_line_size:",
            "            raise LineTooLong(",
            "                \"Status line is too long\", str(self.max_line_size), str(len(path))",
            "            )",
            "",
            "        # method",
            "        if not METHRE.match(method):",
            "            raise BadStatusLine(method)",
            "",
            "        # version",
            "        match = VERSRE.match(version)",
            "        if match is None:",
            "            raise BadStatusLine(line)",
            "        version_o = HttpVersion(int(match.group(1)), int(match.group(2)))",
            "",
            "        if method == \"CONNECT\":",
            "            # authority-form,",
            "            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.3",
            "            url = URL.build(authority=path, encoded=True)",
            "        elif path.startswith(\"/\"):",
            "            # origin-form,",
            "            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.1",
            "            path_part, _hash_separator, url_fragment = path.partition(\"#\")",
            "            path_part, _question_mark_separator, qs_part = path_part.partition(\"?\")",
            "",
            "            # NOTE: `yarl.URL.build()` is used to mimic what the Cython-based",
            "            # NOTE: parser does, otherwise it results into the same",
            "            # NOTE: HTTP Request-Line input producing different",
            "            # NOTE: `yarl.URL()` objects",
            "            url = URL.build(",
            "                path=path_part,",
            "                query_string=qs_part,",
            "                fragment=url_fragment,",
            "                encoded=True,",
            "            )",
            "        else:",
            "            # absolute-form for proxy maybe,",
            "            # https://datatracker.ietf.org/doc/html/rfc7230#section-5.3.2",
            "            url = URL(path, encoded=True)",
            "",
            "        # read headers",
            "        (",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "        ) = self.parse_headers(lines)",
            "",
            "        if close is None:  # then the headers weren't set in the request",
            "            if version_o <= HttpVersion10:  # HTTP 1.0 must asks to not close",
            "                close = True",
            "            else:  # HTTP 1.1 must ask to close.",
            "                close = False",
            "",
            "        return RawRequestMessage(",
            "            method,",
            "            path,",
            "            version_o,",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "            url,",
            "        )",
            "",
            "",
            "class HttpResponseParser(HttpParser[RawResponseMessage]):",
            "    \"\"\"Read response status line and headers.",
            "",
            "    BadStatusLine could be raised in case of any errors in status line.",
            "    Returns RawResponseMessage.",
            "    \"\"\"",
            "",
            "    def parse_message(self, lines: List[bytes]) -> RawResponseMessage:",
            "        line = lines[0].decode(\"utf-8\", \"surrogateescape\")",
            "        try:",
            "            version, status = line.split(maxsplit=1)",
            "        except ValueError:",
            "            raise BadStatusLine(line) from None",
            "",
            "        try:",
            "            status, reason = status.split(maxsplit=1)",
            "        except ValueError:",
            "            reason = \"\"",
            "",
            "        if len(reason) > self.max_line_size:",
            "            raise LineTooLong(",
            "                \"Status line is too long\", str(self.max_line_size), str(len(reason))",
            "            )",
            "",
            "        # version",
            "        match = VERSRE.match(version)",
            "        if match is None:",
            "            raise BadStatusLine(line)",
            "        version_o = HttpVersion(int(match.group(1)), int(match.group(2)))",
            "",
            "        # The status code is a three-digit number",
            "        if len(status) != 3 or not status.isdigit():",
            "            raise BadStatusLine(line)",
            "        status_i = int(status)",
            "",
            "        # read headers",
            "        (",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "        ) = self.parse_headers(lines)",
            "",
            "        if close is None:",
            "            close = version_o <= HttpVersion10",
            "",
            "        return RawResponseMessage(",
            "            version_o,",
            "            status_i,",
            "            reason.strip(),",
            "            headers,",
            "            raw_headers,",
            "            close,",
            "            compression,",
            "            upgrade,",
            "            chunked,",
            "        )",
            "",
            "",
            "class HttpPayloadParser:",
            "    def __init__(",
            "        self,",
            "        payload: StreamReader,",
            "        length: Optional[int] = None,",
            "        chunked: bool = False,",
            "        compression: Optional[str] = None,",
            "        code: Optional[int] = None,",
            "        method: Optional[str] = None,",
            "        readall: bool = False,",
            "        response_with_body: bool = True,",
            "        auto_decompress: bool = True,",
            "    ) -> None:",
            "        self._length = 0",
            "        self._type = ParseState.PARSE_NONE",
            "        self._chunk = ChunkState.PARSE_CHUNKED_SIZE",
            "        self._chunk_size = 0",
            "        self._chunk_tail = b\"\"",
            "        self._auto_decompress = auto_decompress",
            "        self.done = False",
            "",
            "        # payload decompression wrapper",
            "        if response_with_body and compression and self._auto_decompress:",
            "            real_payload: Union[StreamReader, DeflateBuffer] = DeflateBuffer(",
            "                payload, compression",
            "            )",
            "        else:",
            "            real_payload = payload",
            "",
            "        # payload parser",
            "        if not response_with_body:",
            "            # don't parse payload if it's not expected to be received",
            "            self._type = ParseState.PARSE_NONE",
            "            real_payload.feed_eof()",
            "            self.done = True",
            "",
            "        elif chunked:",
            "            self._type = ParseState.PARSE_CHUNKED",
            "        elif length is not None:",
            "            self._type = ParseState.PARSE_LENGTH",
            "            self._length = length",
            "            if self._length == 0:",
            "                real_payload.feed_eof()",
            "                self.done = True",
            "        else:",
            "            if readall and code != 204:",
            "                self._type = ParseState.PARSE_UNTIL_EOF",
            "            elif method in (\"PUT\", \"POST\"):",
            "                internal_logger.warning(  # pragma: no cover",
            "                    \"Content-Length or Transfer-Encoding header is required\"",
            "                )",
            "                self._type = ParseState.PARSE_NONE",
            "                real_payload.feed_eof()",
            "                self.done = True",
            "",
            "        self.payload = real_payload",
            "",
            "    def feed_eof(self) -> None:",
            "        if self._type == ParseState.PARSE_UNTIL_EOF:",
            "            self.payload.feed_eof()",
            "        elif self._type == ParseState.PARSE_LENGTH:",
            "            raise ContentLengthError(",
            "                \"Not enough data for satisfy content length header.\"",
            "            )",
            "        elif self._type == ParseState.PARSE_CHUNKED:",
            "            raise TransferEncodingError(",
            "                \"Not enough data for satisfy transfer length header.\"",
            "            )",
            "",
            "    def feed_data(",
            "        self, chunk: bytes, SEP: bytes = b\"\\r\\n\", CHUNK_EXT: bytes = b\";\"",
            "    ) -> Tuple[bool, bytes]:",
            "        # Read specified amount of bytes",
            "        if self._type == ParseState.PARSE_LENGTH:",
            "            required = self._length",
            "            chunk_len = len(chunk)",
            "",
            "            if required >= chunk_len:",
            "                self._length = required - chunk_len",
            "                self.payload.feed_data(chunk, chunk_len)",
            "                if self._length == 0:",
            "                    self.payload.feed_eof()",
            "                    return True, b\"\"",
            "            else:",
            "                self._length = 0",
            "                self.payload.feed_data(chunk[:required], required)",
            "                self.payload.feed_eof()",
            "                return True, chunk[required:]",
            "",
            "        # Chunked transfer encoding parser",
            "        elif self._type == ParseState.PARSE_CHUNKED:",
            "            if self._chunk_tail:",
            "                chunk = self._chunk_tail + chunk",
            "                self._chunk_tail = b\"\"",
            "",
            "            while chunk:",
            "",
            "                # read next chunk size",
            "                if self._chunk == ChunkState.PARSE_CHUNKED_SIZE:",
            "                    pos = chunk.find(SEP)",
            "                    if pos >= 0:",
            "                        i = chunk.find(CHUNK_EXT, 0, pos)",
            "                        if i >= 0:",
            "                            size_b = chunk[:i]  # strip chunk-extensions",
            "                        else:",
            "                            size_b = chunk[:pos]",
            "",
            "                        if not size_b.isdigit():",
            "                            exc = TransferEncodingError(",
            "                                chunk[:pos].decode(\"ascii\", \"surrogateescape\")",
            "                            )",
            "                            self.payload.set_exception(exc)",
            "                            raise exc",
            "                        size = int(bytes(size_b), 16)",
            "",
            "                        chunk = chunk[pos + 2 :]",
            "                        if size == 0:  # eof marker",
            "                            self._chunk = ChunkState.PARSE_MAYBE_TRAILERS",
            "                        else:",
            "                            self._chunk = ChunkState.PARSE_CHUNKED_CHUNK",
            "                            self._chunk_size = size",
            "                            self.payload.begin_http_chunk_receiving()",
            "                    else:",
            "                        self._chunk_tail = chunk",
            "                        return False, b\"\"",
            "",
            "                # read chunk and feed buffer",
            "                if self._chunk == ChunkState.PARSE_CHUNKED_CHUNK:",
            "                    required = self._chunk_size",
            "                    chunk_len = len(chunk)",
            "",
            "                    if required > chunk_len:",
            "                        self._chunk_size = required - chunk_len",
            "                        self.payload.feed_data(chunk, chunk_len)",
            "                        return False, b\"\"",
            "                    else:",
            "                        self._chunk_size = 0",
            "                        self.payload.feed_data(chunk[:required], required)",
            "                        chunk = chunk[required:]",
            "                        self._chunk = ChunkState.PARSE_CHUNKED_CHUNK_EOF",
            "                        self.payload.end_http_chunk_receiving()",
            "",
            "                # toss the CRLF at the end of the chunk",
            "                if self._chunk == ChunkState.PARSE_CHUNKED_CHUNK_EOF:",
            "                    if chunk[:2] == SEP:",
            "                        chunk = chunk[2:]",
            "                        self._chunk = ChunkState.PARSE_CHUNKED_SIZE",
            "                    else:",
            "                        self._chunk_tail = chunk",
            "                        return False, b\"\"",
            "",
            "                # if stream does not contain trailer, after 0\\r\\n",
            "                # we should get another \\r\\n otherwise",
            "                # trailers needs to be skiped until \\r\\n\\r\\n",
            "                if self._chunk == ChunkState.PARSE_MAYBE_TRAILERS:",
            "                    head = chunk[:2]",
            "                    if head == SEP:",
            "                        # end of stream",
            "                        self.payload.feed_eof()",
            "                        return True, chunk[2:]",
            "                    # Both CR and LF, or only LF may not be received yet. It is",
            "                    # expected that CRLF or LF will be shown at the very first",
            "                    # byte next time, otherwise trailers should come. The last",
            "                    # CRLF which marks the end of response might not be",
            "                    # contained in the same TCP segment which delivered the",
            "                    # size indicator.",
            "                    if not head:",
            "                        return False, b\"\"",
            "                    if head == SEP[:1]:",
            "                        self._chunk_tail = head",
            "                        return False, b\"\"",
            "                    self._chunk = ChunkState.PARSE_TRAILERS",
            "",
            "                # read and discard trailer up to the CRLF terminator",
            "                if self._chunk == ChunkState.PARSE_TRAILERS:",
            "                    pos = chunk.find(SEP)",
            "                    if pos >= 0:",
            "                        chunk = chunk[pos + 2 :]",
            "                        self._chunk = ChunkState.PARSE_MAYBE_TRAILERS",
            "                    else:",
            "                        self._chunk_tail = chunk",
            "                        return False, b\"\"",
            "",
            "        # Read all bytes until eof",
            "        elif self._type == ParseState.PARSE_UNTIL_EOF:",
            "            self.payload.feed_data(chunk, len(chunk))",
            "",
            "        return False, b\"\"",
            "",
            "",
            "class DeflateBuffer:",
            "    \"\"\"DeflateStream decompress stream and feed data into specified stream.\"\"\"",
            "",
            "    decompressor: Any",
            "",
            "    def __init__(self, out: StreamReader, encoding: Optional[str]) -> None:",
            "        self.out = out",
            "        self.size = 0",
            "        self.encoding = encoding",
            "        self._started_decoding = False",
            "",
            "        if encoding == \"br\":",
            "            if not HAS_BROTLI:  # pragma: no cover",
            "                raise ContentEncodingError(",
            "                    \"Can not decode content-encoding: brotli (br). \"",
            "                    \"Please install `Brotli`\"",
            "                )",
            "",
            "            class BrotliDecoder:",
            "                # Supports both 'brotlipy' and 'Brotli' packages",
            "                # since they share an import name. The top branches",
            "                # are for 'brotlipy' and bottom branches for 'Brotli'",
            "                def __init__(self) -> None:",
            "                    self._obj = brotli.Decompressor()",
            "",
            "                def decompress(self, data: bytes) -> bytes:",
            "                    if hasattr(self._obj, \"decompress\"):",
            "                        return cast(bytes, self._obj.decompress(data))",
            "                    return cast(bytes, self._obj.process(data))",
            "",
            "                def flush(self) -> bytes:",
            "                    if hasattr(self._obj, \"flush\"):",
            "                        return cast(bytes, self._obj.flush())",
            "                    return b\"\"",
            "",
            "            self.decompressor = BrotliDecoder()",
            "        else:",
            "            zlib_mode = 16 + zlib.MAX_WBITS if encoding == \"gzip\" else zlib.MAX_WBITS",
            "            self.decompressor = zlib.decompressobj(wbits=zlib_mode)",
            "",
            "    def set_exception(self, exc: BaseException) -> None:",
            "        self.out.set_exception(exc)",
            "",
            "    def feed_data(self, chunk: bytes, size: int) -> None:",
            "        if not size:",
            "            return",
            "",
            "        self.size += size",
            "",
            "        # RFC1950",
            "        # bits 0..3 = CM = 0b1000 = 8 = \"deflate\"",
            "        # bits 4..7 = CINFO = 1..7 = windows size.",
            "        if (",
            "            not self._started_decoding",
            "            and self.encoding == \"deflate\"",
            "            and chunk[0] & 0xF != 8",
            "        ):",
            "            # Change the decoder to decompress incorrectly compressed data",
            "            # Actually we should issue a warning about non-RFC-compliant data.",
            "            self.decompressor = zlib.decompressobj(wbits=-zlib.MAX_WBITS)",
            "",
            "        try:",
            "            chunk = self.decompressor.decompress(chunk)",
            "        except Exception:",
            "            raise ContentEncodingError(",
            "                \"Can not decode content-encoding: %s\" % self.encoding",
            "            )",
            "",
            "        self._started_decoding = True",
            "",
            "        if chunk:",
            "            self.out.feed_data(chunk, len(chunk))",
            "",
            "    def feed_eof(self) -> None:",
            "        chunk = self.decompressor.flush()",
            "",
            "        if chunk or self.size > 0:",
            "            self.out.feed_data(chunk, len(chunk))",
            "            if self.encoding == \"deflate\" and not self.decompressor.eof:",
            "                raise ContentEncodingError(\"deflate\")",
            "",
            "        self.out.feed_eof()",
            "",
            "    def begin_http_chunk_receiving(self) -> None:",
            "        self.out.begin_http_chunk_receiving()",
            "",
            "    def end_http_chunk_receiving(self) -> None:",
            "        self.out.end_http_chunk_receiving()",
            "",
            "",
            "HttpRequestParserPy = HttpRequestParser",
            "HttpResponseParserPy = HttpResponseParser",
            "RawRequestMessagePy = RawRequestMessage",
            "RawResponseMessagePy = RawResponseMessage",
            "",
            "try:",
            "    if not NO_EXTENSIONS:",
            "        from ._http_parser import (  # type: ignore[import,no-redef]",
            "            HttpRequestParser,",
            "            HttpResponseParser,",
            "            RawRequestMessage,",
            "            RawResponseMessage,",
            "        )",
            "",
            "        HttpRequestParserC = HttpRequestParser",
            "        HttpResponseParserC = HttpResponseParser",
            "        RawRequestMessageC = RawRequestMessage",
            "        RawResponseMessageC = RawResponseMessage",
            "except ImportError:  # pragma: no cover",
            "    pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "63": [],
            "64": [],
            "71": [],
            "72": [],
            "151": [
                "HeadersParser",
                "parse_headers"
            ],
            "152": [
                "HeadersParser",
                "parse_headers"
            ],
            "207": [
                "HeadersParser",
                "parse_headers"
            ],
            "325": [
                "HttpParser",
                "feed_data",
                "get_content_length"
            ],
            "326": [
                "HttpParser",
                "feed_data",
                "get_content_length"
            ],
            "327": [
                "HttpParser",
                "feed_data",
                "get_content_length"
            ],
            "330": [
                "HttpParser",
                "feed_data",
                "get_content_length"
            ],
            "331": [
                "HttpParser",
                "feed_data",
                "get_content_length"
            ],
            "332": [
                "HttpParser",
                "feed_data",
                "get_content_length"
            ],
            "333": [
                "HttpParser",
                "feed_data",
                "get_content_length"
            ],
            "526": [
                "HttpRequestParser",
                "parse_message"
            ],
            "540": [
                "HttpRequestParser",
                "parse_message"
            ],
            "541": [
                "HttpRequestParser",
                "parse_message"
            ],
            "542": [
                "HttpRequestParser",
                "parse_message"
            ],
            "543": [
                "HttpRequestParser",
                "parse_message"
            ],
            "544": [
                "HttpRequestParser",
                "parse_message"
            ],
            "545": [
                "HttpRequestParser",
                "parse_message"
            ],
            "546": [
                "HttpRequestParser",
                "parse_message"
            ],
            "547": [
                "HttpRequestParser",
                "parse_message"
            ],
            "614": [
                "HttpResponseParser",
                "parse_message"
            ],
            "619": [
                "HttpResponseParser",
                "parse_message"
            ],
            "635": [
                "HttpResponseParser",
                "parse_message"
            ],
            "636": [
                "HttpResponseParser",
                "parse_message"
            ],
            "637": [
                "HttpResponseParser",
                "parse_message"
            ],
            "638": [
                "HttpResponseParser",
                "parse_message"
            ],
            "639": [
                "HttpResponseParser",
                "parse_message"
            ],
            "640": [
                "HttpResponseParser",
                "parse_message"
            ],
            "776": [
                "HttpPayloadParser",
                "feed_data"
            ],
            "777": [
                "HttpPayloadParser",
                "feed_data"
            ],
            "778": [
                "HttpPayloadParser",
                "feed_data"
            ],
            "783": [
                "HttpPayloadParser",
                "feed_data"
            ]
        },
        "addLocation": []
    }
}