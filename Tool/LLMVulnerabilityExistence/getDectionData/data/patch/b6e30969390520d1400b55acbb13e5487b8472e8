{
    "dtale/dash_application/layout/layout.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1709,
                "afterPatchRowNumber": 1709,
                "PatchRowcode": "             ),"
            },
            "1": {
                "beforePatchRowNumber": 1710,
                "afterPatchRowNumber": 1710,
                "PatchRowcode": "             className=\"row pt-3 pb-3 charts-filters\","
            },
            "2": {
                "beforePatchRowNumber": 1711,
                "afterPatchRowNumber": 1711,
                "PatchRowcode": "         ),"
            },
            "3": {
                "beforePatchRowNumber": 1712,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        html.Div("
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1712,
                "PatchRowcode": "+        ("
            },
            "5": {
                "beforePatchRowNumber": 1713,
                "afterPatchRowNumber": 1713,
                "PatchRowcode": "             html.Div("
            },
            "6": {
                "beforePatchRowNumber": 1714,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                ["
            },
            "7": {
                "beforePatchRowNumber": 1715,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    html.Div("
            },
            "8": {
                "beforePatchRowNumber": 1716,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        ["
            },
            "9": {
                "beforePatchRowNumber": 1717,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            query_label,"
            },
            "10": {
                "beforePatchRowNumber": 1718,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            dcc.Input("
            },
            "11": {
                "beforePatchRowNumber": 1719,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                id=\"query-input\","
            },
            "12": {
                "beforePatchRowNumber": 1720,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                type=\"text\","
            },
            "13": {
                "beforePatchRowNumber": 1721,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                placeholder=query_placeholder,"
            },
            "14": {
                "beforePatchRowNumber": 1722,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                className=\"form-control\","
            },
            "15": {
                "beforePatchRowNumber": 1723,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                value=query_value,"
            },
            "16": {
                "beforePatchRowNumber": 1724,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                style={\"lineHeight\": \"inherit\"},"
            },
            "17": {
                "beforePatchRowNumber": 1725,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            ),"
            },
            "18": {
                "beforePatchRowNumber": 1726,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        ],"
            },
            "19": {
                "beforePatchRowNumber": 1727,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        className=\"input-group mr-3\","
            },
            "20": {
                "beforePatchRowNumber": 1728,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    )"
            },
            "21": {
                "beforePatchRowNumber": 1729,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                ],"
            },
            "22": {
                "beforePatchRowNumber": 1730,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                className=\"col\","
            },
            "23": {
                "beforePatchRowNumber": 1731,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            ),"
            },
            "24": {
                "beforePatchRowNumber": 1732,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            className=\"row pt-3 pb-3 charts-filters\","
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1714,
                "PatchRowcode": "+                html.Div("
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1715,
                "PatchRowcode": "+                    ["
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1716,
                "PatchRowcode": "+                        html.Div("
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1717,
                "PatchRowcode": "+                            ["
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1718,
                "PatchRowcode": "+                                query_label,"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1719,
                "PatchRowcode": "+                                dcc.Input("
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1720,
                "PatchRowcode": "+                                    id=\"query-input\","
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1721,
                "PatchRowcode": "+                                    type=\"text\","
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1722,
                "PatchRowcode": "+                                    placeholder=query_placeholder,"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1723,
                "PatchRowcode": "+                                    className=\"form-control\","
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1724,
                "PatchRowcode": "+                                    value=query_value,"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1725,
                "PatchRowcode": "+                                    style={\"lineHeight\": \"inherit\"},"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1726,
                "PatchRowcode": "+                                ),"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1727,
                "PatchRowcode": "+                            ],"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1728,
                "PatchRowcode": "+                            className=\"input-group mr-3\","
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1729,
                "PatchRowcode": "+                        )"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1730,
                "PatchRowcode": "+                    ],"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1731,
                "PatchRowcode": "+                    className=\"col\","
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1732,
                "PatchRowcode": "+                ),"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1733,
                "PatchRowcode": "+                className=\"row pt-3 pb-3 charts-filters\","
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1734,
                "PatchRowcode": "+            )"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1735,
                "PatchRowcode": "+            if global_state.load_flag(inputs[\"data_id\"], \"enable_custom_filters\", False)"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1736,
                "PatchRowcode": "+            else None"
            },
            "48": {
                "beforePatchRowNumber": 1733,
                "afterPatchRowNumber": 1737,
                "PatchRowcode": "         ),"
            },
            "49": {
                "beforePatchRowNumber": 1734,
                "afterPatchRowNumber": 1738,
                "PatchRowcode": "         html.Div("
            },
            "50": {
                "beforePatchRowNumber": 1735,
                "afterPatchRowNumber": 1739,
                "PatchRowcode": "             html.Div("
            }
        },
        "frontPatchFile": [
            "import json",
            "",
            "import dash_bootstrap_components as dbc",
            "import dash_colorscales as dcs",
            "import dash_daq as daq",
            "import os",
            "import plotly",
            "from pkg_resources import parse_version",
            "from six import PY3",
            "",
            "from dtale.dash_application import dcc, html",
            "import dtale.dash_application.custom_geojson as custom_geojson",
            "import dtale.dash_application.extended_aggregations as extended_aggregations",
            "import dtale.global_state as global_state",
            "from dtale.charts.utils import (",
            "    AGGS,",
            "    ANIMATION_CHARTS,",
            "    ANIMATE_BY_CHARTS,",
            "    YAXIS_CHARTS,",
            "    ZAXIS_CHARTS,",
            "    NON_EXT_AGGREGATION,",
            "    build_final_cols,",
            "    find_group_vals,",
            ")",
            "from dtale.column_builders import get_cleaner_configs",
            "from dtale.constants import CHART_JOINER_CHAR",
            "from dtale.dash_application.layout.utils import (",
            "    build_input,",
            "    build_option,",
            "    build_tab,",
            "    build_cols,",
            "    build_hoverable,",
            "    build_selections,",
            "    show_style,",
            "    FREQS,",
            "    FREQ_LABELS,",
            ")",
            "from dtale.translations import text",
            "from dtale.query import build_query, handle_predefined, inner_build_query, run_query",
            "from dtale.utils import (",
            "    ChartBuildingError,",
            "    classify_type,",
            "    coord_type,",
            "    get_dtypes,",
            "    is_app_root_defined,",
            "    make_list,",
            ")",
            "",
            "",
            "def test_plotly_version(version_num):",
            "    if \"unknown\" in plotly.__version__:",
            "        return True",
            "    return parse_version(plotly.__version__) >= parse_version(version_num)",
            "",
            "",
            "def get_dashbio():",
            "    import dash_bio as dashbio  # noqa: F401",
            "",
            "    return dashbio",
            "",
            "",
            "def has_dashbio():",
            "    try:",
            "        get_dashbio()",
            "        return True",
            "    except ImportError:",
            "        return False",
            "",
            "",
            "def base_layout(app_root, **kwargs):",
            "    \"\"\"",
            "    Base layout to be returned by :meth:`dtale.dash_application.views.DtaleDash.interpolate_index`",
            "",
            "    :param kwargs: Optional keyword arguments to be passed to 'dash.Dash.interplolate_index'",
            "    :type kwargs: dict",
            "    :return: HTML",
            "    :rtype: str",
            "    \"\"\"",
            "    webroot_html = \"\"",
            "    favicon_path = \"../../dtale/static/images/favicon.png\"",
            "    if is_app_root_defined(app_root):",
            "        webroot_html = \"\"\"",
            "        <script type=\"text/javascript\">",
            "            window.resourceBaseUrl = '{app_root}';",
            "        </script>",
            "        \"\"\".format(",
            "            app_root=app_root",
            "        )",
            "        favicon_path = \"{}/dtale/static/images/favicon.png\".format(app_root)",
            "    grid_links = []",
            "    for id in global_state.keys():",
            "        label = global_state.get_name(id)",
            "        if label:",
            "            label = \" ({})\".format(label)",
            "        else:",
            "            label = \"\"",
            "        grid_links.append(",
            "            (",
            "                \"\"\"<a href=\"../main/{id}\" class=\"dropdown-item data-grid-link\" target=\"{target}\">\"\"\"",
            "                \"\"\"<span class=\"ml-3\">{id}{label}</span>\"\"\"",
            "                \"\"\"</a>\"\"\"",
            "            ).format(",
            "                id=id,",
            "                label=label,",
            "                target=(",
            "                    \"_self\" if os.environ.get(\"VSCODE_PID\") is not None else \"_blank\"",
            "                ),",
            "            )",
            "        )",
            "    language = global_state.get_app_settings()[\"language\"]",
            "    language_links = []",
            "    for value, label in [(\"en\", \"English\"), (\"cn\", \"Chinese\"), (\"pt\", \"Portuguese\")]:",
            "        if value == language:",
            "            language_links.append(",
            "                \"\"\"<span class=\"dropdown-item active\">{}</span>\"\"\".format(",
            "                    \"&#10003; {}\".format(text(label))",
            "                )",
            "            )",
            "        else:",
            "            language_links.append(",
            "                \"\"\"<a href=\"{}\" class=\"dropdown-item lang-link\">{}</a>\"\"\".format(",
            "                    value, text(label)",
            "                )",
            "            )",
            "",
            "    main_title = global_state.get_app_settings().get(\"main_title\") or \"D-TALE\"",
            "    main_title_font = global_state.get_app_settings().get(\"main_title_font\")",
            "    main_title_class = \"title-font-base\"",
            "    main_title_style = \"\"",
            "    if main_title_font:",
            "        main_title_style = \"font-family: {main_title_font}\".format(",
            "            main_title_font=main_title_font",
            "        )",
            "    else:",
            "        main_title_class = \"title-font title-font-base\"",
            "    page_title = global_state.get_app_settings().get(\"main_title\") or \"D-Tale\"",
            "",
            "    return \"\"\"",
            "        <!DOCTYPE html>",
            "        <html>",
            "            <head>",
            "                {webroot_html}",
            "                {metas}",
            "                <title>{page_title} Charts</title>",
            "                <link rel=\"shortcut icon\" href=\"{favicon_path}\">",
            "                {css}",
            "            </head>",
            "            <body class=\"{theme}-mode\">",
            "                <header class=\"app-header\">",
            "                    <span class=\"{main_title_class}\" style=\"{main_title_style}\">{main_title}</span>",
            "                    <span style=\"font-size: 16px\" class=\"pl-5 mt-4\">{title}</span>",
            "                    <nav class=\"app-header__nav--secondary\">",
            "                        <ul class=\"nav-menus\">",
            "                            <li>",
            "                                <div class=\"dropdown\">",
            "                                    <span class=\"dropbtn nav-link dropdown-toggle\">",
            "                                        {back_to_data}",
            "                                    </span>",
            "                                    <div class=\"dropdown-content\">{grid_links}</div>",
            "                                </div>",
            "                            </li>",
            "                            <li>",
            "                                <div class=\"dropdown\">",
            "                                    <span class=\"dropbtn nav-link dropdown-toggle\">",
            "                                        {languages}",
            "                                    </span>",
            "                                    <div class=\"dropdown-content\">{language_links}</div>",
            "                                </div>",
            "                            </li>",
            "                        </ul>",
            "                    </nav>",
            "                </header>",
            "                <div class=\"container-fluid charts\">",
            "                    {app_entry}",
            "                </div>",
            "                <footer>",
            "                    {config}",
            "                    {scripts}",
            "                    <script type=\"text/javascript\">",
            "                        const pathSegs = window.location.pathname.split('/');",
            "                        const dataId = pathSegs[pathSegs.length - 1];",
            "                        const backToData = () => window.open('{app_root}/dtale/main/' + dataId);",
            "                    </script>",
            "                    {renderer}",
            "                    {css}",
            "                </footer>",
            "            </body>",
            "        </html>",
            "    \"\"\".format(",
            "        metas=kwargs[\"metas\"],",
            "        css=kwargs[\"css\"],",
            "        app_entry=kwargs[\"app_entry\"],",
            "        config=kwargs[\"config\"],",
            "        scripts=kwargs[\"scripts\"],",
            "        renderer=kwargs[\"renderer\"],",
            "        webroot_html=webroot_html,",
            "        app_root=app_root if is_app_root_defined(app_root) else \"\",",
            "        favicon_path=favicon_path,",
            "        title=text(\"Charts\"),",
            "        back_to_data=text(\"Back To Data\"),",
            "        grid_links=\"\".join(grid_links),",
            "        languages=text(\"Languages\"),",
            "        language_links=\"\".join(language_links),",
            "        main_title=main_title,",
            "        main_title_class=main_title_class,",
            "        main_title_style=main_title_style,",
            "        page_title=page_title,",
            "        theme=global_state.get_app_settings()[\"theme\"],",
            "    )",
            "",
            "",
            "CHARTS = [",
            "    dict(value=\"line\"),",
            "    dict(value=\"bar\"),",
            "    dict(value=\"scatter\"),",
            "    dict(value=\"pie\"),",
            "    dict(value=\"wordcloud\"),",
            "    dict(value=\"heatmap\"),",
            "    dict(value=\"3d_scatter\", label=\"3D Scatter\"),",
            "    dict(value=\"surface\"),",
            "    dict(value=\"maps\"),",
            "    dict(value=\"candlestick\"),",
            "    dict(value=\"treemap\"),",
            "    dict(value=\"funnel\"),",
            "]",
            "if has_dashbio():",
            "    CHARTS.append(dict(value=\"clustergram\"))",
            "CHARTS.append(dict(value=\"pareto\"))",
            "CHARTS.append(dict(value=\"histogram\"))",
            "",
            "CHART_INPUT_SETTINGS = {",
            "    \"line\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"bar\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"scatter\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"pie\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"wordcloud\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"heatmap\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"single\"),",
            "        z=dict(display=True, type=\"single\"),",
            "        group=dict(display=False),",
            "    ),",
            "    \"3d_scatter\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"single\"),",
            "        z=dict(display=True, type=\"single\"),",
            "        group=dict(display=True),",
            "    ),",
            "    \"surface\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"single\"),",
            "        z=dict(display=True, type=\"single\"),",
            "        group=dict(display=False),",
            "    ),",
            "    \"maps\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=True),",
            "    ),",
            "    \"candlestick\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=True),",
            "    ),",
            "    \"treemap\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=True),",
            "    ),",
            "    \"funnel\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=True),",
            "    ),",
            "    \"clustermap\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=False),",
            "        clustergram_group=dict(display=True),",
            "    ),",
            "    \"pareto\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=False),",
            "        clustergram_group=dict(display=False),",
            "    ),",
            "    \"histogram\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=False),",
            "        clustergram_group=dict(display=False),",
            "        histogram_group=dict(display=True),",
            "    ),",
            "}",
            "LOAD_TYPES = [\"random\", \"head\", \"tail\", \"stratified\"]",
            "MAP_TYPES = [",
            "    dict(value=\"choropleth\", image=True),",
            "    dict(value=\"scattergeo\", label=\"ScatterGeo\", image=True),",
            "    dict(value=\"mapbox\", label=\"Detailed\", image=True),",
            "]",
            "SCOPES = [\"world\", \"usa\", \"europe\", \"asia\", \"africa\", \"north america\", \"south america\"]",
            "PROJECTIONS = [",
            "    \"equirectangular\",",
            "    \"mercator\",",
            "    \"orthographic\",",
            "    \"natural earth\",",
            "    \"kavrayskiy7\",",
            "    \"miller\",",
            "    \"robinson\",",
            "    \"eckert4\",",
            "    \"azimuthal equal area\",",
            "    \"azimuthal equidistant\",",
            "    \"conic equal area\",",
            "    \"conic conformal\",",
            "    \"conic equidistant\",",
            "    \"gnomonic\",",
            "    \"stereographic\",",
            "    \"mollweide\",",
            "    \"hammer\",",
            "    \"transverse mercator\",",
            "    \"albers usa\",",
            "    \"winkel tripel\",",
            "    \"aitoff\",",
            "    \"sinusoidal\",",
            "]",
            "",
            "",
            "def auto_load_msg():",
            "    return text(\"auto_load_msg\")",
            "",
            "",
            "def load_type_msg():",
            "    return [",
            "        html.Div(",
            "            [",
            "                html.H3(",
            "                    text(\"Load Types\"), style=dict(display=\"inline\"), className=\"pr-3\"",
            "                )",
            "            ]",
            "        ),",
            "        html.Ul(",
            "            [",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Random\")),",
            "                        html.Span(\": {}\".format(text(\"load_random\"))),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [html.B(text(\"Head\")), html.Span(\": {}\".format(text(\"load_head\")))],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [html.B(text(\"Tail\")), html.Span(\": {}\".format(text(\"load_tail\")))],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Stratified\")),",
            "                        html.Span(\": {}\".format(text(\"load_stratified\"))),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "            ],",
            "            className=\"mb-0\",",
            "        ),",
            "    ]",
            "",
            "",
            "def bin_type_msg():",
            "    return [",
            "        html.Div(",
            "            [",
            "                html.H3(",
            "                    text(\"Bin Types\"), style=dict(display=\"inline\"), className=\"pr-3\"",
            "                ),",
            "                html.A(",
            "                    \"({})\".format(text(\"Binning in Data Mining\")),",
            "                    href=\"https://www.geeksforgeeks.org/binning-in-data-mining/\",",
            "                ),",
            "                html.Br(),",
            "            ]",
            "        ),",
            "        html.Ul(",
            "            [",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Equal Width\")),",
            "                        html.Span(",
            "                            \": {}\".format(text(\"the bins are of equal sized ranges\"))",
            "                        ),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Equal Frequency\")),",
            "                        html.Span(",
            "                            \": {}\".format(",
            "                                text(\"the bins contain an equal amount of values\")",
            "                            )",
            "                        ),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "            ],",
            "            className=\"mb-0\",",
            "        ),",
            "    ]",
            "",
            "",
            "def build_img_src(proj, img_type=\"projections\"):",
            "    return \"../static/images/{}/{}.png\".format(img_type, \"_\".join(proj.split(\" \")))",
            "",
            "",
            "def build_proj_hover_children(proj):",
            "    if proj is None:",
            "        return None",
            "    return [",
            "        html.I(className=\"ico-help-outline\", style=dict(color=\"white\")),",
            "        html.Div(",
            "            [html.Div(proj), html.Img(src=build_img_src(proj))],",
            "            className=\"hoverable__content\",",
            "            style=dict(width=\"auto\"),",
            "        ),",
            "    ]",
            "",
            "",
            "def build_proj_hover(proj):",
            "    return html.Span(",
            "        [",
            "            text(\"Projection\"),",
            "            html.Div(",
            "                build_proj_hover_children(proj),",
            "                className=\"ml-3 hoverable\",",
            "                style=(",
            "                    dict(display=\"none\") if proj is None else dict(borderBottom=\"none\")",
            "                ),",
            "                id=\"proj-hover\",",
            "            ),",
            "        ],",
            "        className=\"input-group-addon\",",
            "    )",
            "",
            "",
            "def build_mapbox_token_children():",
            "    from dtale.charts.utils import get_mapbox_token",
            "",
            "    msg = text(\"To access additional styles enter a token here...\")",
            "    if get_mapbox_token() is None:",
            "        msg = text(\"Change your token here...\")",
            "    return [",
            "        html.I(className=\"ico-help-outline\", style=dict(color=\"white\")),",
            "        html.Div(",
            "            [",
            "                html.Span(\"{}:\".format(\"Mapbox Access Token\")),",
            "                dcc.Input(",
            "                    id=\"mapbox-token-input\",",
            "                    type=\"text\",",
            "                    placeholder=msg,",
            "                    className=\"form-control\",",
            "                    value=\"\",",
            "                    style={\"lineHeight\": \"inherit\"},",
            "                ),",
            "            ],",
            "            className=\"hoverable__content\",",
            "            style=dict(width=\"20em\", right=\"-1.45em\"),",
            "        ),",
            "    ]",
            "",
            "",
            "def build_mapbox_token_hover():",
            "    return html.Span(",
            "        [",
            "            text(\"Style\"),",
            "            html.Div(",
            "                build_mapbox_token_children(),",
            "                className=\"ml-3 hoverable\",",
            "                style=dict(borderBottom=\"none\"),",
            "                id=\"token-hover\",",
            "            ),",
            "        ],",
            "        className=\"input-group-addon\",",
            "    )",
            "",
            "",
            "def loc_mode_info():",
            "    return {",
            "        \"ISO-3\": dict(",
            "            url=html.A(",
            "                text(\"ISO-3\"),",
            "                href=\"https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3\",",
            "                target=\"_blank\",",
            "            ),",
            "            examples=[\"USA (United States)\", \"CAN (Canada)\", \"GBR (United Kingdom)\"],",
            "        ),",
            "        \"USA-states\": dict(",
            "            url=html.A(",
            "                text(\"USA-states (use ISO)\"),",
            "                href=\"https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations\",",
            "                target=\"_blank\",",
            "            ),",
            "            examples=[\"NY (New York)\", \"CA (California)\", \"MA (Massachusetts)\"],",
            "        ),",
            "        \"country names\": dict(",
            "            url=html.A(",
            "                text(\"country names (case-insensitive)\"),",
            "                href=\"https://simple.wikipedia.org/wiki/List_of_countries\",",
            "                target=\"_blank\",",
            "            ),",
            "            examples=[\"United States\", \"United Kingdom\", \"Germany\"],",
            "        ),",
            "        \"geojson-id\": dict(",
            "            label=\"Custom GeoJSON\", desc=text(\"Load custom geojson into D-Tale\")",
            "        ),",
            "    }",
            "",
            "",
            "def build_loc_mode_hover_children(loc_mode):",
            "    if loc_mode is None:",
            "        return None",
            "    loc_modes = loc_mode_info()",
            "    loc_mode_cfg = loc_modes[loc_mode]",
            "    url, examples, desc = (loc_mode_cfg.get(p) for p in [\"url\", \"examples\", \"desc\"])",
            "    body = []",
            "    if url is not None:",
            "        body.append(",
            "            html.Div([html.Span(text(\"View\"), className=\"mr-3\"), loc_mode_cfg[\"url\"]])",
            "        )",
            "    if examples is not None:",
            "        body.append(",
            "            html.Ul(",
            "                [",
            "                    html.Li(e, style={\"listStyleType\": \"disc\"}, className=\"mb-3\")",
            "                    for e in loc_mode_cfg[\"examples\"]",
            "                ],",
            "                className=\"pt-3 mb-0\",",
            "            )",
            "        )",
            "    if desc is not None:",
            "        body.append(html.Span(desc))",
            "    return [",
            "        html.I(className=\"ico-help-outline\", style=dict(color=\"white\")),",
            "        html.Div(",
            "            body,",
            "            className=\"hoverable__content build-code\",",
            "            style=dict(width=\"auto\", whiteSpace=\"nowrap\", left=\"-2em\", top=\"auto\"),",
            "        ),",
            "    ]",
            "",
            "",
            "def build_loc_mode_hover(loc_mode):",
            "    return html.Span(",
            "        [",
            "            html.Span(text(\"Location Mode\"), style=dict(whiteSpace=\"pre-line\")),",
            "            html.Div(",
            "                build_loc_mode_hover_children(loc_mode),",
            "                className=\"ml-3 hoverable\",",
            "                style=(",
            "                    dict(display=\"none\")",
            "                    if loc_mode is None",
            "                    else dict(borderBottom=\"none\")",
            "                ),",
            "                id=\"loc-mode-hover\",",
            "            ),",
            "        ],",
            "        className=\"input-group-addon pt-1 pb-0\",",
            "    )",
            "",
            "",
            "JET = [\"#000083\", \"#003CAA\", \"#05FFFF\", \"#FFFF00\", \"#FA0000\", \"#800000\"]",
            "REDS = [\"#fff5f0\", \"#fdcab4\", \"#fc8a6a\", \"#f24632\", \"#bc141a\", \"#67000d\"]",
            "YLORRD = [",
            "    \"#ffffcc\",",
            "    \"#ffeda0\",",
            "    \"#fed976\",",
            "    \"#feb24c\",",
            "    \"#fd8d3c\",",
            "    \"#fc4e2a\",",
            "    \"#e31a1c\",",
            "    \"#bd0026\",",
            "    \"#800026\",",
            "]",
            "YLGRBL = [\"#ffffd9\", \"#d5efb3\", \"#73c9bc\", \"#1b99c2\", \"#1c4ea2\", \"#081d58\"]",
            "DEFAULT_CSALES = {\"heatmap\": JET, \"maps\": REDS, \"3d_Scatter\": YLORRD, \"surface\": YLGRBL}",
            "",
            "",
            "def show_input_handler(chart_type):",
            "    settings = CHART_INPUT_SETTINGS.get(chart_type or \"line\") or {}",
            "",
            "    def _show_input(input_id, input_type=\"single\"):",
            "        cfg = settings.get(input_id, {})",
            "        return cfg.get(\"display\", True) and cfg.get(\"type\", \"single\") == input_type",
            "",
            "    return _show_input",
            "",
            "",
            "def get_group_types(inputs, group_cols=None):",
            "    def _flags(group_prop):",
            "        final_group_cols = group_cols or make_list(inputs.get(group_prop))",
            "        if len(final_group_cols):",
            "            dtypes = global_state.get_dtypes(inputs[\"data_id\"])",
            "            for dtype_info in dtypes:",
            "                if dtype_info[\"name\"] in final_group_cols:",
            "                    classifier = classify_type(dtype_info[\"dtype\"])",
            "                    if classifier == \"F\":",
            "                        return [\"bins\"]",
            "                    if classifier == \"I\":",
            "                        return [\"groups\", \"bins\"]",
            "                    return [\"groups\"]",
            "            for fgc in final_group_cols:",
            "                col, freq = fgc.split(CHART_JOINER_CHAR)",
            "                col_exists = (",
            "                    next(",
            "                        (",
            "                            dtype_info",
            "                            for dtype_info in dtypes",
            "                            if dtype_info[\"name\"] == col",
            "                        ),",
            "                        None,",
            "                    )",
            "                    is not None",
            "                )",
            "                if col_exists and freq in FREQS:",
            "                    return [\"groups\"]",
            "        return []",
            "",
            "    chart_type = inputs.get(\"chart_type\")",
            "",
            "    if show_input_handler(chart_type)(\"group\"):",
            "        return _flags(\"group\")",
            "    elif show_input_handler(chart_type)(\"map_group\"):",
            "        return _flags(\"map_group\")",
            "    elif show_input_handler(chart_type)(\"cs_group\"):",
            "        return _flags(\"cs_group\")",
            "    elif show_input_handler(chart_type)(\"treemap_group\"):",
            "        return _flags(\"treemap_group\")",
            "    elif show_input_handler(chart_type)(\"funnel_group\"):",
            "        return _flags(\"funnel_group\")",
            "    elif show_input_handler(chart_type)(\"clustergram_group\"):",
            "        return _flags(\"clustergram_group\")",
            "    elif show_input_handler(chart_type)(\"pareto_group\"):",
            "        return _flags(\"pareto_group\")",
            "    return False, False",
            "",
            "",
            "def update_label_for_freq_and_agg(val):",
            "    \"\"\"",
            "    Formats sub-values contained within 'val' to display date frequencies & aggregatioms if included.",
            "        - (val=['a', 'b', 'c']) => 'a, b, c'",
            "        - (val=['a||H', 'b||mean', 'c']) => 'a (Hour), Mean of b, c'",
            "    \"\"\"",
            "",
            "    def _freq_handler(sub_val):",
            "        selected_agg = None",
            "        for agg in AGGS:",
            "            if sub_val.endswith(\"{}{}\".format(CHART_JOINER_CHAR, agg)):",
            "                selected_agg = \"{} of\".format(text(AGGS[agg]))",
            "                sub_val = sub_val.split(\"{}{}\".format(CHART_JOINER_CHAR, agg))[0]",
            "                break",
            "",
            "        selected_freq = None",
            "        for freq in FREQS:",
            "            if sub_val.endswith(\"{}{}\".format(CHART_JOINER_CHAR, freq)):",
            "                col, freq = sub_val.split(CHART_JOINER_CHAR)",
            "                if freq in FREQS:",
            "                    sub_val = sub_val.split(\"{}{}\".format(CHART_JOINER_CHAR, freq))[0]",
            "                    if freq in FREQ_LABELS:",
            "                        selected_freq = \"({})\".format(text(FREQ_LABELS[freq]))",
            "                    break",
            "",
            "        return \" \".join(list(filter(None, [selected_agg, sub_val, selected_freq])))",
            "",
            "    return \", \".join([_freq_handler(sub_val) for sub_val in make_list(val)])",
            "",
            "",
            "def build_error(error, tb):",
            "    \"\"\"",
            "    Returns error/traceback information in standard component with styling",
            "",
            "    :param error: execption message",
            "    :type error: str",
            "    :param tb: tracebackF",
            "    :type tb: str",
            "    :return: error component",
            "    :rtype: :dash:`dash_html_components.Div <dash-html-components/div>`",
            "    \"\"\"",
            "    if isinstance(error, ChartBuildingError):",
            "        if error.details:",
            "            tb = error.details",
            "        error = error.error",
            "    return html.Div(",
            "        [",
            "            html.I(className=\"ico-error\"),",
            "            html.Span(str(error)),",
            "            html.Div(html.Pre(str(tb)), className=\"traceback\"),",
            "        ],",
            "        className=\"dtale-alert alert alert-danger\",",
            "    )",
            "",
            "",
            "def build_input_options(df, extended_aggregation=[], **inputs):",
            "    \"\"\"",
            "    Builds dropdown options for (X, Y, Z, Group, Barsort & Y-Axis Ranges) with filtering based on currently selected",
            "    values for the following inputs: x, y, z, group.",
            "    \"\"\"",
            "    chart_type, x, y, z, group = (",
            "        inputs.get(p) for p in [\"chart_type\", \"x\", \"y\", \"z\", \"group\"]",
            "    )",
            "    col_opts = list(build_cols(df.columns, get_dtypes(df)))",
            "    group_val, z_val = (None, z) if chart_type in ZAXIS_CHARTS else (group, None)",
            "    x_options = [",
            "        build_option(c, l)",
            "        for c, l in col_opts",
            "        if c not in build_selections(y, z_val, group_val)",
            "    ]",
            "    y_filter = build_selections(x, group_val, z_val)",
            "    y_multi_options = [build_option(c, l) for c, l in col_opts if c not in y_filter]",
            "    y_single_options = [build_option(c, l) for c, l in col_opts if c not in y_filter]",
            "    z_options = [",
            "        build_option(c)",
            "        for c in df.columns",
            "        if c not in build_selections(x, y, group_val)",
            "    ]",
            "    group_options = [",
            "        build_option(c, l)",
            "        for c, l in col_opts",
            "        if c not in build_selections(x, y, z_val)",
            "    ]",
            "    final_cols = build_final_cols(",
            "        y,",
            "        z,",
            "        inputs.get(\"agg\"),",
            "        extended_aggregation if chart_type not in NON_EXT_AGGREGATION else [],",
            "    )",
            "    barsort_options = [build_option(o) for o in build_selections(x, final_cols)]",
            "    yaxis_options = [build_option(y2) for y2 in final_cols or []]",
            "    return (",
            "        x_options,",
            "        y_multi_options,",
            "        y_single_options,",
            "        z_options,",
            "        group_options,",
            "        barsort_options,",
            "        yaxis_options,",
            "        [build_option(c, l) for c, l in col_opts],",
            "    )",
            "",
            "",
            "def build_map_options(",
            "    df, type=\"choropleth\", loc=None, lat=None, lon=None, map_val=None",
            "):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    lat_cols, lon_cols, str_cols, num_cols = [], [], [], []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification == \"S\":",
            "            str_cols.append(c)",
            "            continue",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "            coord = coord_type(df[c])",
            "            if coord == \"lat\":",
            "                lat_cols.append(c)",
            "            elif coord == \"lon\":",
            "                lon_cols.append(c)",
            "",
            "    lat_options = [",
            "        build_option(c) for c in lat_cols if c not in build_selections(lon, map_val)",
            "    ]",
            "    lon_options = [",
            "        build_option(c) for c in lon_cols if c not in build_selections(lat, map_val)",
            "    ]",
            "    loc_options = [",
            "        build_option(c) for c in str_cols if c not in build_selections(map_val)",
            "    ]",
            "",
            "    if type == \"choropleth\":",
            "        val_options = [",
            "            build_option(c) for c in num_cols if c not in build_selections(loc)",
            "        ]",
            "    else:",
            "        val_options = [",
            "            build_option(c) for c in num_cols if c not in build_selections(lon, lat)",
            "        ]",
            "    return loc_options, lat_options, lon_options, val_options",
            "",
            "",
            "def build_candlestick_options(",
            "    df, cs_x=None, cs_open=None, cs_close=None, cs_high=None, cs_low=None",
            "):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols, x_cols = [], []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification in [\"S\", \"D\"]:",
            "            x_cols.append(c)",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "",
            "    x_options = [build_option(c) for c in x_cols]",
            "    close_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_open, cs_low, cs_high)",
            "    ]",
            "    open_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_close, cs_low, cs_high)",
            "    ]",
            "    low_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_open, cs_close, cs_high)",
            "    ]",
            "    high_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_open, cs_close, cs_low)",
            "    ]",
            "    return x_options, close_options, open_options, low_options, high_options",
            "",
            "",
            "def build_label_value_options(",
            "    df, selected_value=None, selected_label=None, all_value=False",
            "):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols = []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "",
            "    value_options = [",
            "        build_option(c) for c in num_cols if c not in build_selections(selected_label)",
            "    ]",
            "    if all_value:",
            "        value_options = [build_option(\"_all_columns_\", \"All Columns\")] + value_options",
            "    label_options = [",
            "        build_option(c) for c in cols if c not in build_selections(selected_value)",
            "    ]",
            "    return value_options, label_options",
            "",
            "",
            "def build_label_value_store(prop, inputs):",
            "    return dcc.Store(",
            "        id=\"{}-input-data\".format(prop),",
            "        data={",
            "            k: v",
            "            for k, v in inputs.items()",
            "            if k",
            "            in [",
            "                \"{}_value\".format(prop),",
            "                \"{}_label\".format(prop),",
            "                \"{}_group\".format(prop),",
            "            ]",
            "        },",
            "    )",
            "",
            "",
            "def bootstrap_checkbox_prop():",
            "    if parse_version(dbc.__version__) >= parse_version(\"1.0.0\"):",
            "        return \"value\"",
            "    return \"checked\"",
            "",
            "",
            "def build_dropna(dropna, prop=None):",
            "    if PY3:",
            "        checkbox_kwargs = dict(",
            "            id=(",
            "                \"{}-dropna-checkbox\".format(prop)",
            "                if prop is not None",
            "                else \"dropna-checkbox\"",
            "            ),",
            "            style=dict(width=\"inherit\"),",
            "        )",
            "        checkbox_kwargs[bootstrap_checkbox_prop()] = True if dropna is None else dropna",
            "        return build_input(",
            "            text(\"Dropna\"),",
            "            html.Div(dbc.Checkbox(**checkbox_kwargs), className=\"checkbox-wrapper\"),",
            "            className=\"col-auto\",",
            "            id=\"{}-dropna-input\".format(prop) if prop is not None else \"dropna-input\",",
            "        )",
            "    return build_input(",
            "        text(\"Dropna\"),",
            "        dcc.Input(",
            "            id=(",
            "                \"{}-dropna-checkbox\".format(prop)",
            "                if prop is not None",
            "                else \"dropna-checkbox\"",
            "            ),",
            "            type=\"hidden\",",
            "            value=True if dropna is None else dropna,",
            "        ),",
            "        id=\"{}-dropna-input\".format(prop) if prop is not None else \"dropna-input\",",
            "        style={\"display\": \"none\"},",
            "    )",
            "",
            "",
            "def build_label_value_inputs(",
            "    prop,",
            "    inputs,",
            "    df,",
            "    group_options,",
            "    additional_inputs=[],",
            "    multi_value=False,",
            "    all_option=False,",
            "):",
            "    show_inputs = inputs.get(\"chart_type\") == prop",
            "    props = [\"{}_value\", \"{}_label\", \"{}_group\", \"{}_dropna\"]",
            "    selected_value, selected_label, selected_group, dropna = (",
            "        inputs.get(p.format(prop)) for p in props",
            "    )",
            "    all_options = build_label_value_options(",
            "        df,",
            "        selected_value=selected_value,",
            "        selected_label=selected_label,",
            "        all_value=multi_value and all_option,",
            "    )",
            "    value_options, label_options = all_options",
            "    return html.Div(",
            "        [",
            "            build_input(",
            "                text(\"Value(s)\" if multi_value else \"Value\"),",
            "                dcc.Dropdown(",
            "                    id=\"{}-value-dropdown\".format(prop),",
            "                    options=value_options,",
            "                    placeholder=text(",
            "                        \"Select Column(s)\" if multi_value else \"Select Column\"",
            "                    ),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=selected_value,",
            "                    multi=multi_value,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Labels\"),",
            "                dcc.Dropdown(",
            "                    id=\"{}-label-dropdown\".format(prop),",
            "                    options=label_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=selected_label,",
            "                ),",
            "            ),",
            "        ]",
            "        + additional_inputs",
            "        + [",
            "            build_input(",
            "                text(\"Group\"),",
            "                dcc.Dropdown(",
            "                    id=\"{}-group-dropdown\".format(prop),",
            "                    options=group_options,",
            "                    multi=True,",
            "                    placeholder=text(\"Select Group(s)\"),",
            "                    value=selected_group,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                className=\"col\",",
            "                id=\"{}-group-input\".format(prop),",
            "            ),",
            "            build_dropna(dropna, prop),",
            "        ],",
            "        id=\"{}-inputs\".format(prop),",
            "        className=\"row charts-filters\",",
            "        style={} if show_inputs else {\"display\": \"none\"},",
            "    )",
            "",
            "",
            "def build_funnel_inputs(inputs, df, group_options):",
            "    stacked_toggle = build_input(",
            "        \"{}?\".format(text(\"Stack\")),",
            "        html.Div(",
            "            daq.BooleanSwitch(id=\"funnel-stack-toggle\", on=False),",
            "            className=\"toggle-wrapper\",",
            "        ),",
            "        id=\"funnel-stack-input\",",
            "        style=show_style(inputs.get(\"funnel_group\") is not None),",
            "        className=\"col-auto\",",
            "    )",
            "",
            "    return build_label_value_inputs(",
            "        \"funnel\", inputs, df, group_options, additional_inputs=[stacked_toggle]",
            "    )",
            "",
            "",
            "def get_num_cols(df):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols = []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "    return num_cols",
            "",
            "",
            "def build_pareto_options(df, x=None, bars=None, line=None):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols = get_num_cols(df)",
            "",
            "    x_options = [build_option(c) for c in cols if c not in [bars, line]]",
            "    bars_options = [build_option(c) for c in num_cols if c not in [x, line]]",
            "    line_options = [build_option(c) for c in num_cols if c not in [x, bars]]",
            "    sort_options = [build_option(c) for c in cols]",
            "    return x_options, bars_options, line_options, sort_options",
            "",
            "",
            "def build_pareto_inputs(inputs, df, group_options):",
            "    show_inputs = inputs.get(\"chart_type\") == \"pareto\"",
            "    x, bars, line, sort, sort_dir, group, dropna = (",
            "        inputs.get(\"pareto_{}\".format(prop))",
            "        for prop in [\"x\", \"bars\", \"line\", \"sort\", \"dir\", \"group\", \"dropna\"]",
            "    )",
            "    x_options, bar_options, line_options, sort_options = build_pareto_options(",
            "        df, x, bars, line",
            "    )",
            "",
            "    return html.Div(",
            "        [",
            "            build_input(",
            "                [html.Div(text(\"X\")), html.Small(\"({})\".format(text(\"Agg By\")))],",
            "                dcc.Dropdown(",
            "                    id=\"pareto-x-dropdown\",",
            "                    options=x_options,",
            "                    placeholder=\"{} (1, 2, ..., N)\".format(text(\"Default Index\")),",
            "                    value=x,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "            ),",
            "            build_input(",
            "                text(\"Bars\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-bars-dropdown\",",
            "                    options=bar_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=bars,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Line\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-line-dropdown\",",
            "                    options=line_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=line,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Sort\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-sort-dropdown\",",
            "                    options=sort_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=sort,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Dir\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-dir-dropdown\",",
            "                    options=[build_option(d, d.capitalize()) for d in [\"ASC\", \"DESC\"]],",
            "                    style=dict(width=\"inherit\"),",
            "                    value=sort_dir or \"DESC\",",
            "                    placeholder=None,",
            "                    clearable=False,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Group\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-group-dropdown\",",
            "                    options=group_options,",
            "                    multi=True,",
            "                    placeholder=text(\"Select Group(s)\"),",
            "                    value=group,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                className=\"col\",",
            "                id=\"pareto-group-input\",",
            "            ),",
            "            build_dropna(dropna, \"pareto\"),",
            "        ],",
            "        id=\"pareto-inputs\",",
            "        style={} if show_inputs else {\"display\": \"none\"},",
            "        className=\"row p-0 charts-filters\",",
            "    )",
            "",
            "",
            "def build_histogram_inputs(inputs, df, group_options):",
            "    show_inputs = inputs.get(\"chart_type\") == \"histogram\"",
            "    col, histogram_type, bins, group = (",
            "        inputs.get(\"histogram_{}\".format(prop))",
            "        for prop in [\"col\", \"type\", \"bins\", \"group\"]",
            "    )",
            "    col_options = get_num_cols(df)",
            "",
            "    return html.Div(",
            "        [",
            "            build_input(",
            "                text(\"Col\"),",
            "                dcc.Dropdown(",
            "                    id=\"histogram-col-dropdown\",",
            "                    options=col_options,",
            "                    value=col,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "            ),",
            "            dcc.Tabs(",
            "                id=\"histogram-type-tabs\",",
            "                value=histogram_type or \"bins\",",
            "                children=[",
            "                    build_tab(text(\"Bins\"), \"bins\"),",
            "                    build_tab(text(\"Density\"), \"density\"),",
            "                ],",
            "                style=dict(height=\"36px\", width=\"10em\"),",
            "            ),",
            "            build_input(",
            "                text(\"Bins\"),",
            "                dcc.Input(",
            "                    id=\"histogram-bins-input\",",
            "                    type=\"number\",",
            "                    placeholder=text(\"Enter Bins\"),",
            "                    className=\"form-control text-center\",",
            "                    style={\"lineHeight\": \"inherit\"},",
            "                    value=bins or 5,",
            "                ),",
            "                id=\"histogram-bins-div\",",
            "                className=\"col-md-1 pr-0\",",
            "                style={} if histogram_type == \"bins\" else {\"display\": \"none\"},",
            "            ),",
            "            build_input(",
            "                text(\"Group\"),",
            "                dcc.Dropdown(",
            "                    id=\"histogram-group-dropdown\",",
            "                    options=group_options,",
            "                    multi=True,",
            "                    placeholder=text(\"Select Group(s)\"),",
            "                    value=group,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                className=\"col\",",
            "                id=\"histogram-group-input\",",
            "            ),",
            "        ],",
            "        id=\"histogram-inputs\",",
            "        style={} if show_inputs else {\"display\": \"none\"},",
            "        className=\"row p-0 charts-filters\",",
            "    )",
            "",
            "",
            "def build_mapbox_style_options():",
            "    from dtale.charts.utils import get_mapbox_token",
            "",
            "    free_styles = [",
            "        \"open-street-map\",",
            "        \"carto-positron\",",
            "        \"carto-darkmatter\",",
            "        \"stamen-terrain\",",
            "        \"stamen-toner\",",
            "        \"stamen-watercolor\",",
            "    ]",
            "    token_styles = [",
            "        \"basic\",",
            "        \"streets\",",
            "        \"outdoors\",",
            "        \"light\",",
            "        \"dark\",",
            "        \"satellite\",",
            "        \"satellite-streets\",",
            "    ]",
            "    styles = free_styles",
            "    if get_mapbox_token() is not None:",
            "        styles += token_styles",
            "    return [build_option(v) for v in styles]",
            "",
            "",
            "def bar_input_style(**inputs):",
            "    \"\"\"",
            "    Sets display CSS property for bar chart inputs",
            "    \"\"\"",
            "    chart_type, group_col = (inputs.get(p) for p in [\"chart_type\", \"group\"])",
            "    show_bar = chart_type == \"bar\"",
            "    show_barsort = show_bar and group_col is None",
            "    return (",
            "        dict(display=\"block\" if show_bar else \"none\"),",
            "        dict(display=\"block\" if show_barsort else \"none\"),",
            "    )",
            "",
            "",
            "def colorscale_input_style(**inputs):",
            "    return dict(",
            "        display=(",
            "            \"block\"",
            "            if inputs.get(\"chart_type\")",
            "            in [\"heatmap\", \"maps\", \"3d_scatter\", \"surface\", \"clustergram\"]",
            "            else \"none\"",
            "        )",
            "    )",
            "",
            "",
            "def animate_styles(df, **inputs):",
            "    chart_type, agg, cpg, cpy = (",
            "        inputs.get(p) for p in [\"chart_type\", \"agg\", \"cpg\", \"cpy\"]",
            "    )",
            "    opts = []",
            "    if cpg or cpy or agg in [\"pctsum\", \"pctct\"]:",
            "        return dict(display=\"none\"), dict(display=\"none\"), opts",
            "    if chart_type in ANIMATION_CHARTS:",
            "        return dict(display=\"block\"), dict(display=\"none\"), opts",
            "    if chart_type in ANIMATE_BY_CHARTS:",
            "        opts = [build_option(v, l) for v, l in build_cols(df.columns, get_dtypes(df))]",
            "    if len(opts):",
            "        return dict(display=\"none\"), dict(display=\"block\"), opts",
            "    return dict(display=\"none\"), dict(display=\"none\"), []",
            "",
            "",
            "def lock_zoom_style(chart_type):",
            "    return (",
            "        dict(display=\"block\", textTransform=\"none\")",
            "        if chart_type in [\"3d_scatter\", \"surface\"]",
            "        else dict(display=\"none\")",
            "    )",
            "",
            "",
            "def show_chart_per_group(**inputs):",
            "    \"\"\"",
            "    Boolean function to determine whether \"Chart Per Group\" toggle should be displayed or not",
            "    \"\"\"",
            "    chart_type, group = (inputs.get(p) for p in [\"chart_type\", \"group\"])",
            "    invalid_type = chart_type in [\"pie\", \"wordcloud\", \"maps\", \"funnel\", \"clustergram\"]",
            "    return (",
            "        show_input_handler(chart_type)(\"group\")",
            "        and len(group or [])",
            "        and not invalid_type",
            "    )",
            "",
            "",
            "def show_chart_per_y(**inputs):",
            "    \"\"\"",
            "    Boolean function to determine whether \"Chart Per Y-Axis\" toggle should be displayed or not",
            "    \"\"\"",
            "    chart_type, y = (inputs.get(p) for p in [\"chart_type\", \"y\"])",
            "    return show_input_handler(chart_type)(\"y\", \"multi\") and len(y or []) > 1",
            "",
            "",
            "def show_yaxis_ranges(**inputs):",
            "    \"\"\"",
            "    Boolean function to determine whether \"Y-Axis Range\" inputs should be displayed or not",
            "    \"\"\"",
            "    chart_type, y = (inputs.get(p) for p in [\"chart_type\", \"y\"])",
            "    return chart_type in YAXIS_CHARTS and len(y or [])",
            "",
            "",
            "def get_yaxis_type_tabs(y):",
            "    tabs = [",
            "        build_tab(text(\"Default\"), \"default\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "        build_tab(text(\"Single\"), \"single\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "    ]",
            "    if len(y) <= 1:",
            "        return tabs",
            "    return tabs + [",
            "        build_tab(text(\"Multi\"), \"multi\", {\"padding\": \"2px\", \"minWidth\": \"4em\"})",
            "    ]",
            "",
            "",
            "def get_yaxis_scale_tabs():",
            "    return [",
            "        build_tab(text(\"Linear\"), \"linear\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "        build_tab(text(\"Log\"), \"log\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "    ]",
            "",
            "",
            "def build_group_val_options(df, group_cols):",
            "    group_vals = find_group_vals(df, group_cols)",
            "    return [",
            "        build_option(",
            "            json.dumps(gv),",
            "            CHART_JOINER_CHAR.join([str(gv.get(p, \"NaN\")) for p in group_cols]),",
            "        )",
            "        for gv in group_vals",
            "    ]",
            "",
            "",
            "def build_map_type_tabs(map_type):",
            "    def _build_map_type_hoverable():",
            "        for t in MAP_TYPES:",
            "            if t.get(\"image\", False):",
            "                yield html.Div(",
            "                    [",
            "                        html.Span(text(t.get(\"label\", t[\"value\"].capitalize()))),",
            "                        html.Img(src=build_img_src(t[\"value\"], img_type=\"map_type\")),",
            "                    ],",
            "                    className=\"col-md-4\",",
            "                )",
            "",
            "    return html.Div(",
            "        [",
            "            dcc.Tabs(",
            "                id=\"map-type-tabs\",",
            "                value=map_type or \"choropleth\",",
            "                children=[",
            "                    build_tab(text(t.get(\"label\", t[\"value\"].capitalize())), t[\"value\"])",
            "                    for t in MAP_TYPES",
            "                ],",
            "                style=dict(height=\"36px\"),",
            "            ),",
            "            html.Div(",
            "                html.Div(list(_build_map_type_hoverable()), className=\"row\"),",
            "                className=\"hoverable__content map-types\",",
            "            ),",
            "        ],",
            "        style=dict(paddingLeft=15, borderBottom=\"none\", width=\"20em\"),",
            "        className=\"hoverable\",",
            "    )",
            "",
            "",
            "def main_inputs_and_group_val_display(inputs):",
            "    group_types = get_group_types(inputs)",
            "    if len(group_types):",
            "        is_groups = [\"groups\"] == group_types or (",
            "            \"groups\" in group_types and inputs.get(\"group_type\") == \"groups\"",
            "        )",
            "        is_bins = [\"bins\"] == group_types or (",
            "            \"bins\" in group_types and inputs.get(\"group_type\") == \"bins\"",
            "        )",
            "        return (",
            "            dict(display=\"block\" if len(group_types) > 1 else \"none\"),",
            "            dict(display=\"block\" if is_groups else \"none\"),",
            "            dict(display=\"block\" if is_bins else \"none\"),",
            "            \"col-md-8\",",
            "            dict(display=\"block\"),",
            "        )",
            "    return (",
            "        dict(display=\"none\"),",
            "        dict(display=\"none\"),",
            "        dict(display=\"none\"),",
            "        \"col-md-12\",",
            "        dict(display=\"none\"),",
            "    )",
            "",
            "",
            "def build_slider_counts(df, data_id, query_value):",
            "    record_ct = len(",
            "        run_query(",
            "            handle_predefined(data_id, df=df),",
            "            build_query(data_id, query_value),",
            "            global_state.get_context_variables(data_id),",
            "        )",
            "    )",
            "    slider_counts = {",
            "        \"{}\".format(v * 20): {",
            "            \"label\": \"{}% ({:,.0f})\".format(v * 20, (v * 2) / 10 * record_ct)",
            "        }",
            "        for v in range(1, 6)",
            "    }",
            "    slider_counts[\"100\"][\"style\"] = {\"white-space\": \"nowrap\"}",
            "    return slider_counts",
            "",
            "",
            "def collapse_btn_text(is_open, label):",
            "    return \"{} {}\".format(\"\\u25BC\" if is_open else \"\\u25B6\", label)",
            "",
            "",
            "def charts_layout(df, settings, **inputs):",
            "    \"\"\"",
            "    Builds main dash inputs with dropdown options populated with the columns of the dataframe associated with the",
            "    page. Inputs included are: chart tabs, query, x, y, z, group, aggregation, rolling window/computation,",
            "    chart per group toggle, bar sort, bar mode, y-axis range editors",
            "",
            "    :param df: dataframe to drive the charts built on page",
            "    :type df: :class:`pandas:pandas.DataFrame`",
            "    :param settings: global settings associated with this dataframe (contains properties like \"query\")",
            "    :type param: dict",
            "    :return: dash markup",
            "    \"\"\"",
            "    chart_type, x, y, z, group, dropna, agg, load, load_type, stratified_group = (",
            "        inputs.get(p)",
            "        for p in [",
            "            \"chart_type\",",
            "            \"x\",",
            "            \"y\",",
            "            \"z\",",
            "            \"group\",",
            "            \"dropna\",",
            "            \"agg\",",
            "            \"load\",",
            "            \"load_type\",",
            "            \"stratified_group\",",
            "        ]",
            "    )",
            "    loc_modes = loc_mode_info()",
            "    y = y or []",
            "    show_input = show_input_handler(chart_type)",
            "    show_cpg = show_chart_per_group(**inputs)",
            "    show_cpy = show_chart_per_y(**inputs)",
            "    show_yaxis = show_yaxis_ranges(**inputs)",
            "    scatter_input = dict(display=\"block\" if chart_type == \"scatter\" else \"none\")",
            "    bar_style, barsort_input_style = bar_input_style(**inputs)",
            "    animate_style, animate_by_style, animate_opts = animate_styles(df, **inputs)",
            "",
            "    options = build_input_options(df, **inputs)",
            "    (",
            "        x_options,",
            "        y_multi_options,",
            "        y_single_options,",
            "        z_options,",
            "        group_options,",
            "        barsort_options,",
            "        yaxis_options,",
            "        stratified_groups,",
            "    ) = options",
            "    query_placeholder = \"{} (ex: col1 == 1)\".format(text(\"Enter pandas query\"))",
            "    query_value = inputs.get(\"query\") or inner_build_query(",
            "        settings, settings.get(\"query\")",
            "    )",
            "",
            "    query_label = html.Div(",
            "        [",
            "            html.Span(text(\"Query\")),",
            "            html.A(",
            "                html.I(className=\"fa fa-info-circle ml-4\"),",
            "                href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-query\",",
            "                target=\"_blank\",",
            "                style={\"color\": \"white\"},",
            "            ),",
            "        ],",
            "        className=\"input-group-addon\",",
            "        style={\"minWidth\": \"7em\"},",
            "    )",
            "    yaxis_type = (inputs.get(\"yaxis\") or {}).get(\"type\") or \"default\"",
            "    yaxis_type_style = (",
            "        {\"borderRadius\": \"0 0.25rem 0.25rem 0\"} if yaxis_type == \"default\" else None",
            "    )",
            "    show_map = chart_type == \"maps\"",
            "    map_props = [\"map_type\", \"loc_mode\", \"loc\", \"lat\", \"lon\", \"map_val\"]",
            "    map_type, loc_mode, loc, lat, lon, map_val = (inputs.get(p) for p in map_props)",
            "    map_scope, proj, mapbox_style = (",
            "        inputs.get(p) for p in [\"scope\", \"proj\", \"mapbox_style\"]",
            "    )",
            "    loc_options, lat_options, lon_options, map_val_options = build_map_options(",
            "        df, type=map_type, loc=loc, lat=lat, lon=lon, map_val=map_val",
            "    )",
            "    show_candlestick = chart_type == \"candlestick\"",
            "    cs_props = [",
            "        \"cs_x\",",
            "        \"cs_open\",",
            "        \"cs_close\",",
            "        \"cs_high\",",
            "        \"cs_low\",",
            "        \"cs_group\",",
            "        \"cs_dropna\",",
            "    ]",
            "    cs_x, cs_open, cs_close, cs_high, cs_low, cs_group, cs_dropna = (",
            "        inputs.get(p) for p in cs_props",
            "    )",
            "    (",
            "        cs_x_options,",
            "        open_options,",
            "        close_options,",
            "        high_options,",
            "        low_options,",
            "    ) = build_candlestick_options(",
            "        df,",
            "        cs_x=cs_x,",
            "        cs_open=cs_open,",
            "        cs_close=cs_close,",
            "        cs_high=cs_high,",
            "        cs_low=cs_low,",
            "    )",
            "    cscale_style = colorscale_input_style(**inputs)",
            "    default_cscale = DEFAULT_CSALES.get(chart_type, REDS)",
            "",
            "    (",
            "        group_type_style,",
            "        group_val_style,",
            "        bins_style,",
            "        main_input_class,",
            "        show_groups,",
            "    ) = main_inputs_and_group_val_display(inputs)",
            "    group_val = [json.dumps(gv) for gv in inputs.get(\"group_val\") or []]",
            "",
            "    def show_map_style(show):",
            "        return {} if show else {\"display\": \"none\"}",
            "",
            "    body_items = [",
            "        dcc.Store(id=\"query-data\", data=query_value),",
            "        dcc.Store(",
            "            id=\"input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k not in [\"cpg\", \"cpy\", \"barmode\", \"barsort\"]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"chart-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k in [\"cpg\", \"cpy\", \"barmode\", \"barsort\"]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"map-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k",
            "                in [",
            "                    \"map_type\",",
            "                    \"map_code\",",
            "                    \"loc_mode\",",
            "                    \"lat\",",
            "                    \"lon\",",
            "                    \"map_val\",",
            "                    \"scope\",",
            "                    \"proj\",",
            "                ]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"candlestick-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k in [\"cs_x\", \"cs_open\", \"cs_close\", \"cs_high\", \"cs_low\", \"cs_group\"]",
            "            },",
            "        ),",
            "        build_label_value_store(\"treemap\", inputs),",
            "        build_label_value_store(\"funnel\", inputs),",
            "        build_label_value_store(\"clustergram\", inputs),",
            "        dcc.Store(",
            "            id=\"pareto-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k",
            "                in [",
            "                    \"pareto_x\",",
            "                    \"pareto_bars\",",
            "                    \"pareto_line\",",
            "                    \"pareto_sort\",",
            "                    \"pareto_dir\",",
            "                    \"pareto_group\",",
            "                ]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"histogram-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k",
            "                in [",
            "                    \"histogram_col\",",
            "                    \"histogram_type\",",
            "                    \"histogram_bins\",",
            "                    \"histogram_group\",",
            "                ]",
            "            },",
            "        ),",
            "        dcc.Store(id=\"range-data\"),",
            "        dcc.Store(id=\"yaxis-data\", data=inputs.get(\"yaxis\")),",
            "        dcc.Store(id=\"last-chart-input-data\", data=inputs),",
            "        dcc.Store(id=\"load-clicks\", data=0),",
            "        dcc.Store(id=\"save-clicks\", data=0),",
            "        dcc.Store(id=\"y-all-clicks\", data=0),",
            "        dcc.Store(id=\"z-all-clicks\", data=0),",
            "        dcc.Input(id=\"chart-code\", type=\"hidden\"),",
            "        html.Div(",
            "            [",
            "                html.Div(",
            "                    dbc.Button(",
            "                        collapse_btn_text(False, text(\"Data Selection\")),",
            "                        id=\"collapse-data-btn\",",
            "                    ),",
            "                    className=\"col-auto pr-0\",",
            "                ),",
            "                html.Div(",
            "                    dbc.Collapse(",
            "                        dbc.Card(",
            "                            dbc.CardBody(",
            "                                [",
            "                                    dcc.Tabs(",
            "                                        id=\"data-tabs\",",
            "                                        value=inputs[\"data_id\"],",
            "                                        children=[",
            "                                            build_tab(",
            "                                                global_state.get_name(k) or k,",
            "                                                str(k),",
            "                                                id=\"data-tab-{}\".format(k),",
            "                                            )",
            "                                            for k in global_state.keys()",
            "                                        ],",
            "                                        style=dict(height=\"36px\"),",
            "                                    )",
            "                                ]",
            "                                + [",
            "                                    dbc.Tooltip(",
            "                                        global_state.get_name(k) or k,",
            "                                        target=\"data-tab-{}\".format(k),",
            "                                    )",
            "                                    for k in global_state.keys()",
            "                                ]",
            "                            )",
            "                        ),",
            "                        id=\"collapse-data\",",
            "                    ),",
            "                    className=\"col\",",
            "                ),",
            "            ],",
            "            className=\"row pb-3 charts-filters\",",
            "            style=dict(display=\"none\" if len(global_state.keys()) < 2 else \"block\"),",
            "        ),",
            "        html.Div(",
            "            html.Div(",
            "                [",
            "                    dcc.Tabs(",
            "                        id=\"chart-tabs\",",
            "                        value=chart_type or \"line\",",
            "                        children=[",
            "                            build_tab(",
            "                                text(t.get(\"label\", t[\"value\"].capitalize())),",
            "                                t[\"value\"],",
            "                                id=\"chart-type-tab-{}\".format(i),",
            "                            )",
            "                            for i, t in enumerate(CHARTS)",
            "                        ],",
            "                        style=dict(height=\"36px\"),",
            "                    )",
            "                ]",
            "                + [",
            "                    dbc.Tooltip(",
            "                        text(t.get(\"label\", t[\"value\"].capitalize())),",
            "                        target=\"chart-type-tab-{}\".format(i),",
            "                    )",
            "                    for i, t in enumerate(CHARTS)",
            "                ],",
            "                className=\"col-md-12\",",
            "            ),",
            "            className=\"row pt-3 pb-3 charts-filters\",",
            "        ),",
            "        html.Div(",
            "            html.Div(",
            "                [",
            "                    html.Div(",
            "                        [",
            "                            query_label,",
            "                            dcc.Input(",
            "                                id=\"query-input\",",
            "                                type=\"text\",",
            "                                placeholder=query_placeholder,",
            "                                className=\"form-control\",",
            "                                value=query_value,",
            "                                style={\"lineHeight\": \"inherit\"},",
            "                            ),",
            "                        ],",
            "                        className=\"input-group mr-3\",",
            "                    )",
            "                ],",
            "                className=\"col\",",
            "            ),",
            "            className=\"row pt-3 pb-3 charts-filters\",",
            "        ),",
            "        html.Div(",
            "            html.Div(",
            "                [",
            "                    html.Div(",
            "                        [",
            "                            build_hoverable(",
            "                                html.Span(text(\"Load\")),",
            "                                load_type_msg(),",
            "                                additional_classes=\"load-types-tooltip mb-auto mt-auto\",",
            "                                top=\"100%\",",
            "                            ),",
            "                            dcc.Dropdown(",
            "                                id=\"load-type-dropdown\",",
            "                                options=[",
            "                                    build_option(v, v.capitalize()) for v in LOAD_TYPES",
            "                                ],",
            "                                className=\"pl-5\",",
            "                                value=load_type or \"random\",",
            "                                clearable=False,",
            "                            ),",
            "                            dcc.Dropdown(",
            "                                id=\"stratified-group-dropdown\",",
            "                                options=stratified_groups,",
            "                                value=stratified_group,",
            "                                clearable=False,",
            "                                style=(",
            "                                    {}",
            "                                    if load_type == \"stratified\"",
            "                                    else {\"display\": \"none\"}",
            "                                ),",
            "                            ),",
            "                            dcc.Slider(",
            "                                id=\"load-input\",",
            "                                min=10,",
            "                                max=100,",
            "                                step=10,",
            "                                value=100 if load is None else load,",
            "                                className=\"w-100\",",
            "                                marks=build_slider_counts(",
            "                                    df, inputs[\"data_id\"], query_value",
            "                                ),",
            "                                tooltip={\"always_visible\": False, \"placement\": \"left\"},",
            "                            ),",
            "                        ],",
            "                        className=\"input-group mr-3\",",
            "                    )",
            "                ],",
            "                className=\"col\",",
            "            ),",
            "            className=\"row pt-3 pb-0 charts-filters\",",
            "        ),",
            "        html.Div(",
            "            [",
            "                html.Div(",
            "                    [",
            "                        dbc.Button(",
            "                            collapse_btn_text(False, text(\"Cleaners\")),",
            "                            id=\"collapse-cleaners-btn\",",
            "                        ),",
            "                        html.Span(",
            "                            \"\",",
            "                            id=\"selected-cleaners\",",
            "                            className=\"pl-3\",",
            "                            style=dict(fontSize=\"85%\"),",
            "                        ),",
            "                    ],",
            "                    className=\"col-auto pr-0\",",
            "                ),",
            "                html.Div(",
            "                    dbc.Collapse(",
            "                        dbc.Card(",
            "                            dbc.CardBody(",
            "                                dcc.Dropdown(",
            "                                    id=\"cleaners-dropdown\",",
            "                                    options=[",
            "                                        build_option(c[\"value\"], c[\"label\"])",
            "                                        for c in get_cleaner_configs()",
            "                                    ],",
            "                                    multi=True,",
            "                                    placeholder=text(\"Select Cleaner(s)\"),",
            "                                    value=group,",
            "                                    style=dict(width=\"inherit\"),",
            "                                )",
            "                            )",
            "                        ),",
            "                        id=\"collapse-cleaners\",",
            "                    ),",
            "                    className=\"col\",",
            "                ),",
            "            ],",
            "            className=\"row pb-3 charts-filters\",",
            "            style=dict(display=\"block\"),",
            "        ),",
            "        html.Div(",
            "            [",
            "                html.Div(",
            "                    [",
            "                        html.Div(",
            "                            [",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"X\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"x-dropdown\",",
            "                                        options=x_options,",
            "                                        placeholder=\"{} (1, 2, ..., N)\".format(",
            "                                            text(\"Default Index\")",
            "                                        ),",
            "                                        value=x,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_style(show_input(\"x\")),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Y\"),",
            "                                    [",
            "                                        dcc.Dropdown(",
            "                                            id=\"y-multi-dropdown\",",
            "                                            options=y_multi_options,",
            "                                            multi=True,",
            "                                            placeholder=text(\"Select Column(s)\"),",
            "                                            style=dict(width=\"inherit\"),",
            "                                            value=(",
            "                                                y if show_input(\"y\", \"multi\") else None",
            "                                            ),",
            "                                        ),",
            "                                        dbc.Button(",
            "                                            html.I(",
            "                                                className=\"fa-solid fa-check-double\"",
            "                                            ),",
            "                                            id=\"y-select-all-btn\",",
            "                                            className=\"ml-3\",",
            "                                            color=\"secondary\",",
            "                                            style=dict(",
            "                                                height=\"24px\",",
            "                                                padding=\".25rem .2rem\",",
            "                                                marginTop=\"auto\",",
            "                                                marginBottom=\"auto\",",
            "                                            ),",
            "                                        ),",
            "                                        dbc.Tooltip(",
            "                                            \"Select All Y\", target=\"y-select-all-btn\"",
            "                                        ),",
            "                                    ],",
            "                                    className=\"col\",",
            "                                    id=\"y-multi-input\",",
            "                                    style=show_style(show_input(\"y\", \"multi\")),",
            "                                ),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Y\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"y-single-dropdown\",",
            "                                        options=y_single_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=(",
            "                                            y[0] if show_input(\"y\") and len(y) else None",
            "                                        ),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    id=\"y-single-input\",",
            "                                    style=show_style(show_input(\"y\")),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Z\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"z-dropdown\",",
            "                                        options=z_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=z,",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"z-input\",",
            "                                    style=show_style(show_input(\"z\")),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Group\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"group-dropdown\",",
            "                                        options=group_options,",
            "                                        multi=True,",
            "                                        placeholder=text(\"Select Group(s)\"),",
            "                                        value=group,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"group-input\",",
            "                                    style=show_style(show_input(\"group\")),",
            "                                ),",
            "                                build_dropna(dropna),",
            "                            ],",
            "                            id=\"standard-inputs\",",
            "                            style=(",
            "                                {}",
            "                                if not show_map",
            "                                and not show_candlestick",
            "                                and chart_type",
            "                                not in [\"treemap\", \"funnel\", \"clustergram\"]",
            "                                else {\"display\": \"none\"}",
            "                            ),",
            "                            className=\"row p-0 charts-filters\",",
            "                        ),",
            "                        html.Div(",
            "                            [",
            "                                build_map_type_tabs(map_type),",
            "                                html.Div(",
            "                                    [",
            "                                        html.Div(",
            "                                            [",
            "                                                build_loc_mode_hover(loc_mode),",
            "                                                dcc.Dropdown(",
            "                                                    id=\"map-loc-mode-dropdown\",",
            "                                                    options=[",
            "                                                        build_option(",
            "                                                            v, loc_modes[v].get(\"label\")",
            "                                                        )",
            "                                                        for v in [",
            "                                                            \"ISO-3\",",
            "                                                            \"USA-states\",",
            "                                                            \"country names\",",
            "                                                            \"geojson-id\",",
            "                                                        ]",
            "                                                    ],",
            "                                                    style=dict(width=\"inherit\"),",
            "                                                    value=loc_mode,",
            "                                                ),",
            "                                            ],",
            "                                            className=\"input-group mr-3\",",
            "                                        )",
            "                                    ],",
            "                                    id=\"map-loc-mode-input\",",
            "                                    style=show_map_style(map_type == \"choropleth\"),",
            "                                    className=\"col-auto\",",
            "                                ),",
            "                                custom_geojson.build_modal(map_type, loc_mode),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Locations\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-loc-dropdown\",",
            "                                        options=loc_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        value=loc,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    id=\"map-loc-input\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_map_style(map_type == \"choropleth\"),",
            "                                ),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Lat\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-lat-dropdown\",",
            "                                        options=lat_options,",
            "                                        placeholder=\"Select a column\",",
            "                                        value=lat,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    id=\"map-lat-input\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_map_style(",
            "                                        map_type in [\"scattergeo\", \"mapbox\"]",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Lon\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-lon-dropdown\",",
            "                                        options=lon_options,",
            "                                        placeholder=\"Select a column\",",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=lon,",
            "                                    ),",
            "                                    id=\"map-lon-input\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_map_style(",
            "                                        map_type in [\"scattergeo\", \"mapbox\"]",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Scope\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-scope-dropdown\",",
            "                                        options=[build_option(v) for v in SCOPES],",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=map_scope or \"world\",",
            "                                    ),",
            "                                    id=\"map-scope-input\",",
            "                                    style=show_map_style(map_type == \"scattergeo\"),",
            "                                ),",
            "                                html.Div(",
            "                                    [",
            "                                        html.Div(",
            "                                            [",
            "                                                build_mapbox_token_hover(),",
            "                                                dcc.Dropdown(",
            "                                                    id=\"map-mapbox-style-dropdown\",",
            "                                                    options=build_mapbox_style_options(),",
            "                                                    style=dict(width=\"inherit\"),",
            "                                                    value=mapbox_style",
            "                                                    or \"open-street-map\",",
            "                                                ),",
            "                                            ],",
            "                                            className=\"input-group mr-3\",",
            "                                        )",
            "                                    ],",
            "                                    id=\"map-mapbox-style-input\",",
            "                                    className=\"col-auto\",",
            "                                    style=show_map_style(map_type == \"mapbox\"),",
            "                                ),",
            "                                html.Div(",
            "                                    [",
            "                                        html.Div(",
            "                                            [",
            "                                                build_proj_hover(proj),",
            "                                                dcc.Dropdown(",
            "                                                    id=\"map-proj-dropdown\",",
            "                                                    options=[",
            "                                                        build_option(v)",
            "                                                        for v in PROJECTIONS",
            "                                                    ],",
            "                                                    style=dict(width=\"inherit\"),",
            "                                                    value=proj,",
            "                                                ),",
            "                                            ],",
            "                                            className=\"input-group mr-3\",",
            "                                        )",
            "                                    ],",
            "                                    id=\"map-proj-input\",",
            "                                    style=show_map_style(map_type == \"scattergeo\"),",
            "                                    className=\"col-auto\",",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Value\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-val-dropdown\",",
            "                                        options=map_val_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=map_val,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Group\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-group-dropdown\",",
            "                                        options=group_options,",
            "                                        multi=True,",
            "                                        placeholder=text(\"Select Group(s)\"),",
            "                                        value=inputs.get(\"map_group\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"map-group-input\",",
            "                                ),",
            "                                build_dropna(inputs.get(\"map_dropna\", True), \"map\"),",
            "                            ],",
            "                            id=\"map-inputs\",",
            "                            className=\"row charts-filters\",",
            "                            style={} if show_map else {\"display\": \"none\"},",
            "                        ),",
            "                        html.Div(",
            "                            [",
            "                                build_input(",
            "                                    text(\"X\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-x-dropdown\",",
            "                                        options=cs_x_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_x,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Open\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-open-dropdown\",",
            "                                        options=open_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_open,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"High\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-high-dropdown\",",
            "                                        options=high_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_high,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Low\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-low-dropdown\",",
            "                                        options=low_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_low,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Close\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-close-dropdown\",",
            "                                        options=close_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_close,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Group\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-group-dropdown\",",
            "                                        options=group_options,",
            "                                        multi=True,",
            "                                        placeholder=text(\"Select Group(s)\"),",
            "                                        value=inputs.get(\"cs_group\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"candlestick-group-input\",",
            "                                ),",
            "                                build_dropna(",
            "                                    inputs.get(\"cs_dropna\", True), \"candlestick\"",
            "                                ),",
            "                            ],",
            "                            id=\"candlestick-inputs\",",
            "                            className=\"row charts-filters\",",
            "                            style={} if show_candlestick else {\"display\": \"none\"},",
            "                        ),",
            "                        build_label_value_inputs(\"treemap\", inputs, df, group_options),",
            "                        build_funnel_inputs(inputs, df, group_options),",
            "                        build_label_value_inputs(",
            "                            \"clustergram\",",
            "                            inputs,",
            "                            df,",
            "                            group_options,",
            "                            multi_value=True,",
            "                            all_option=True,",
            "                        ),",
            "                        build_pareto_inputs(inputs, df, group_options),",
            "                        build_histogram_inputs(inputs, df, group_options),",
            "                        html.Div(",
            "                            [",
            "                                html.Div(",
            "                                    [",
            "                                        build_input(",
            "                                            text(\"Aggregation\"),",
            "                                            dcc.Dropdown(",
            "                                                id=\"agg-dropdown\",",
            "                                                options=[",
            "                                                    build_option(v, text(AGGS[v]))",
            "                                                    for v in [",
            "                                                        \"count\",",
            "                                                        \"pctct\",",
            "                                                        \"nunique\",",
            "                                                        \"sum\",",
            "                                                        \"mean\",",
            "                                                        \"rolling\",",
            "                                                        \"corr\",",
            "                                                        \"first\",",
            "                                                        \"last\",",
            "                                                        \"drop_duplicates\",",
            "                                                        \"median\",",
            "                                                        \"min\",",
            "                                                        \"max\",",
            "                                                        \"std\",",
            "                                                        \"var\",",
            "                                                        \"mad\",",
            "                                                        \"prod\",",
            "                                                        \"pctsum\",",
            "                                                    ]",
            "                                                ],",
            "                                                placeholder=text(\"No Aggregation\"),",
            "                                                style=dict(width=\"inherit\"),",
            "                                                value=agg or \"raw\",",
            "                                                disabled=len(",
            "                                                    inputs.get(",
            "                                                        \"extended_aggregation\", []",
            "                                                    )",
            "                                                )",
            "                                                > 0,",
            "                                            ),",
            "                                        ),",
            "                                        html.Span(",
            "                                            \"* {}\".format(",
            "                                                text(",
            "                                                    \"Extended Aggregation is currently populated.\"",
            "                                                )",
            "                                            ),",
            "                                            id=\"ext-agg-warning\",",
            "                                            style=show_style(",
            "                                                len(",
            "                                                    inputs.get(",
            "                                                        \"extended_aggreation\", []",
            "                                                    )",
            "                                                )",
            "                                                > 0",
            "                                            ),",
            "                                            className=\"ext-agg-warning\",",
            "                                        ),",
            "                                    ]",
            "                                )",
            "                            ]",
            "                            + extended_aggregations.build_modal(",
            "                                inputs.get(\"extended_aggregation\", []), chart_type, y",
            "                            )",
            "                            + [",
            "                                html.Div(",
            "                                    [",
            "                                        build_input(",
            "                                            text(\"Window\"),",
            "                                            dcc.Input(",
            "                                                id=\"window-input\",",
            "                                                type=\"number\",",
            "                                                placeholder=text(\"Enter Days\"),",
            "                                                className=\"form-control text-center\",",
            "                                                style={\"lineHeight\": \"inherit\"},",
            "                                                value=inputs.get(\"window\"),",
            "                                            ),",
            "                                        ),",
            "                                        build_input(",
            "                                            text(\"Computation\"),",
            "                                            dcc.Dropdown(",
            "                                                id=\"rolling-comp-dropdown\",",
            "                                                options=[",
            "                                                    build_option(",
            "                                                        \"corr\", text(\"Correlation\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"count\", text(\"Count\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"cov\", text(\"Covariance\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"kurt\", text(\"Kurtosis\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"max\", text(\"Maximum\")",
            "                                                    ),",
            "                                                    build_option(\"mean\", text(\"Mean\")),",
            "                                                    build_option(",
            "                                                        \"median\", text(\"Median\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"min\", text(\"Minimum\")",
            "                                                    ),",
            "                                                    build_option(\"skew\", text(\"Skew\")),",
            "                                                    build_option(",
            "                                                        \"std\",",
            "                                                        text(\"Standard Deviation\"),",
            "                                                    ),",
            "                                                    build_option(\"sum\", text(\"Sum\")),",
            "                                                    build_option(",
            "                                                        \"var\", text(\"Variance\")",
            "                                                    ),",
            "                                                ],",
            "                                                placeholder=text(\"Select Computation\"),",
            "                                                style=dict(width=\"inherit\"),",
            "                                                value=inputs.get(\"rolling_comp\"),",
            "                                            ),",
            "                                        ),",
            "                                    ],",
            "                                    id=\"rolling-inputs\",",
            "                                    style=show_style(agg == \"rolling\"),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Drilldowns\"),",
            "                                    html.Div(",
            "                                        daq.BooleanSwitch(",
            "                                            id=\"drilldown-toggle\", on=False",
            "                                        ),",
            "                                        className=\"toggle-wrapper\",",
            "                                    ),",
            "                                    id=\"drilldown-input\",",
            "                                    style=show_style((agg or \"raw\") != \"raw\"),",
            "                                    className=\"col-auto\",",
            "                                ),",
            "                            ],",
            "                            className=\"row pt-3 pb-3 charts-filters\",",
            "                            id=\"charts-filters-div\",",
            "                            style=(",
            "                                {\"display\": \"none\"} if chart_type == \"histogram\" else {}",
            "                            ),",
            "                        ),",
            "                    ],",
            "                    id=\"main-inputs\",",
            "                    className=main_input_class,",
            "                ),",
            "                html.Div(",
            "                    [",
            "                        html.Div(",
            "                            html.Div(",
            "                                html.Div(",
            "                                    [",
            "                                        html.Span(",
            "                                            text(\"Group Type\"),",
            "                                            className=\"input-group-addon\",",
            "                                        ),",
            "                                        html.Div(",
            "                                            dcc.Tabs(",
            "                                                id=\"group-type\",",
            "                                                value=inputs.get(\"group_type\")",
            "                                                or \"groups\",",
            "                                                children=[",
            "                                                    build_tab(",
            "                                                        text(\"Values\"),",
            "                                                        \"groups\",",
            "                                                        {",
            "                                                            \"padding\": \"2px\",",
            "                                                            \"minWidth\": \"4em\",",
            "                                                        },",
            "                                                    ),",
            "                                                    build_tab(",
            "                                                        text(\"Bins\"),",
            "                                                        \"bins\",",
            "                                                        {",
            "                                                            \"padding\": \"2px\",",
            "                                                            \"minWidth\": \"4em\",",
            "                                                        },",
            "                                                    ),",
            "                                                ],",
            "                                            ),",
            "                                            id=\"group-type-div\",",
            "                                            className=\"form-control col-auto pt-3\",",
            "                                        ),",
            "                                    ],",
            "                                    className=\"input-group\",",
            "                                ),",
            "                                className=\"addon-min-width\",",
            "                            ),",
            "                            className=\"col-md-12 p-0 pb-5\",",
            "                            id=\"group-type-input\",",
            "                            style=group_type_style,",
            "                        ),",
            "                        build_input(",
            "                            text(\"Group(s)\"),",
            "                            dcc.Dropdown(",
            "                                id=\"group-val-dropdown\",",
            "                                multi=True,",
            "                                placeholder=text(\"Select Group Value(s)\"),",
            "                                value=group_val,",
            "                                style=dict(width=\"inherit\"),",
            "                            ),",
            "                            className=\"col-md-12 p-0 pb-5\",",
            "                            id=\"group-val-input\",",
            "                            style=group_val_style,",
            "                        ),",
            "                        build_input(",
            "                            text(\"Bins\"),",
            "                            [",
            "                                daq.NumericInput(",
            "                                    id=\"bins-val-input\",",
            "                                    min=1,",
            "                                    max=30,",
            "                                    value=inputs.get(\"bins_val\") or 5,",
            "                                ),",
            "                                html.Div(",
            "                                    html.Div(",
            "                                        [",
            "                                            html.Span(",
            "                                                text(\"Binning\"),",
            "                                                className=\"input-group-addon\",",
            "                                            ),",
            "                                            html.Div(",
            "                                                build_hoverable(",
            "                                                    dcc.Tabs(",
            "                                                        id=\"bin-type\",",
            "                                                        value=inputs.get(\"bin_type\")",
            "                                                        or \"width\",",
            "                                                        children=[",
            "                                                            build_tab(",
            "                                                                text(\"Width\"),",
            "                                                                \"width\",",
            "                                                                {",
            "                                                                    \"padding\": \"2px\",",
            "                                                                    \"minWidth\": \"4em\",",
            "                                                                },",
            "                                                            ),",
            "                                                            build_tab(",
            "                                                                text(\"Freq\"),",
            "                                                                \"freq\",",
            "                                                                {",
            "                                                                    \"padding\": \"2px\",",
            "                                                                    \"minWidth\": \"4em\",",
            "                                                                },",
            "                                                            ),",
            "                                                        ],",
            "                                                    ),",
            "                                                    bin_type_msg(),",
            "                                                    \"\",",
            "                                                    top=\"120%\",",
            "                                                ),",
            "                                                id=\"bin-type-div\",",
            "                                                className=\"form-control col-auto pt-3\",",
            "                                            ),",
            "                                        ],",
            "                                        className=\"input-group\",",
            "                                    ),",
            "                                    className=\"col-auto addon-min-width\",",
            "                                    id=\"bin-type-input\",",
            "                                ),",
            "                            ],",
            "                            className=\"col-md-12 p-0\",",
            "                            id=\"bins-input\",",
            "                            style=bins_style,",
            "                        ),",
            "                    ],",
            "                    id=\"group-inputs-row\",",
            "                    className=\"col-md-4 row pt-3 pb-5\",",
            "                    style=show_groups,",
            "                ),",
            "            ],",
            "            className=\"row\",",
            "        ),",
            "        html.Div(",
            "            [",
            "                build_input(",
            "                    text(\"Chart Per\\nGroup\"),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"cpg-toggle\", on=inputs.get(\"cpg\") or False",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"cpg-input\",",
            "                    style=show_style(show_cpg),",
            "                    className=\"col-auto\",",
            "                ),",
            "                build_input(",
            "                    text(\"Chart Per\\nY\"),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"cpy-toggle\", on=inputs.get(\"cpy\") or False",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"cpy-input\",",
            "                    style=show_style(show_cpy),",
            "                    className=\"col-auto\",",
            "                ),",
            "                build_input(",
            "                    text(\"Trendline\"),",
            "                    dcc.Dropdown(",
            "                        id=\"trendline-dropdown\",",
            "                        options=[build_option(\"ols\"), build_option(\"lowess\")],",
            "                        value=inputs.get(\"trendline\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=scatter_input,",
            "                    id=\"trendline-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Barmode\"),",
            "                    dcc.Dropdown(",
            "                        id=\"barmode-dropdown\",",
            "                        options=[",
            "                            build_option(\"group\", text(\"Group\")),",
            "                            build_option(\"stack\", text(\"Stack\")),",
            "                            build_option(\"relative\", text(\"Relative\")),",
            "                        ],",
            "                        value=inputs.get(\"barmode\") or \"group\",",
            "                        placeholder=text(\"Select Mode\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=bar_style,",
            "                    id=\"barmode-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Barsort\"),",
            "                    dcc.Dropdown(",
            "                        id=\"barsort-dropdown\",",
            "                        options=barsort_options,",
            "                        value=inputs.get(\"barsort\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=barsort_input_style,",
            "                    id=\"barsort-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Top\"),",
            "                    dcc.Dropdown(",
            "                        id=\"top-bars\",",
            "                        options=[build_option(v) for v in [5, 10, 20, 50]],",
            "                        value=inputs.get(\"top_bars\"),",
            "                        placeholder=None,",
            "                    ),",
            "                    className=\"col-auto\",",
            "                    style=barsort_input_style,",
            "                    id=\"top-bars-input\",",
            "                ),",
            "                html.Div(",
            "                    html.Div(",
            "                        [",
            "                            html.Span(text(\"Y-Axis\"), className=\"input-group-addon\"),",
            "                            html.Div(",
            "                                [",
            "                                    dcc.Tabs(",
            "                                        id=\"yaxis-scale\",",
            "                                        value=inputs.get(\"scale\") or \"linear\",",
            "                                        children=get_yaxis_scale_tabs(),",
            "                                        className=\"pr-5\",",
            "                                    ),",
            "                                    dcc.Tabs(",
            "                                        id=\"yaxis-type\",",
            "                                        value=yaxis_type,",
            "                                        children=get_yaxis_type_tabs(y),",
            "                                    ),",
            "                                ],",
            "                                id=\"yaxis-type-div\",",
            "                                className=\"form-control col-auto pt-3\",",
            "                                style=yaxis_type_style,",
            "                            ),",
            "                            dcc.Dropdown(id=\"yaxis-dropdown\", options=yaxis_options),",
            "                            html.Span(",
            "                                \"{}:\".format(text(\"Min\")),",
            "                                className=\"input-group-addon col-auto\",",
            "                                id=\"yaxis-min-label\",",
            "                            ),",
            "                            dcc.Input(",
            "                                id=\"yaxis-min-input\",",
            "                                type=\"number\",",
            "                                className=\"form-control col-auto\",",
            "                                style={\"lineHeight\": \"inherit\"},",
            "                            ),",
            "                            html.Span(",
            "                                \"{}:\".format(text(\"Max\")),",
            "                                className=\"input-group-addon col-auto\",",
            "                                id=\"yaxis-max-label\",",
            "                            ),",
            "                            dcc.Input(",
            "                                id=\"yaxis-max-input\",",
            "                                type=\"number\",",
            "                                className=\"form-control col-auto\",",
            "                                style={\"lineHeight\": \"inherit\"},",
            "                            ),",
            "                        ],",
            "                        className=\"input-group\",",
            "                        id=\"yaxis-min-max-options\",",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    id=\"yaxis-input\",",
            "                    style=show_style(show_yaxis),",
            "                ),",
            "                build_input(",
            "                    text(\"Colorscale\"),",
            "                    dcs.DashColorscales(",
            "                        id=\"colorscale-picker\",",
            "                        colorscale=inputs.get(\"colorscale\") or default_cscale,",
            "                    ),",
            "                    className=\"col-auto addon-min-width pr-0\",",
            "                    style=cscale_style,",
            "                    id=\"colorscale-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Animate\"),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"animate-toggle\", on=inputs.get(\"animate\") or False",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"animate-input\",",
            "                    style=animate_style,",
            "                    className=\"col-auto\",",
            "                ),",
            "                build_input(",
            "                    text(\"Animate By\"),",
            "                    dcc.Dropdown(",
            "                        id=\"animate-by-dropdown\",",
            "                        options=animate_opts,",
            "                        value=inputs.get(\"animate_by\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=animate_by_style,",
            "                    id=\"animate-by-input\",",
            "                ),",
            "                dbc.Button(",
            "                    text(\"Lock Zoom\"),",
            "                    id=\"lock-zoom-btn\",",
            "                    className=\"ml-auto\",",
            "                    style=lock_zoom_style(chart_type),",
            "                ),",
            "                build_input(",
            "                    build_hoverable(",
            "                        html.Div(text(\"Auto-Load\"), style=dict(color=\"white\")),",
            "                        auto_load_msg(),",
            "                        \"\",",
            "                        top=\"120%\",",
            "                    ),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"auto-load-toggle\", on=True, color=\"green\"",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"auto-load-input\",",
            "                    className=\"ml-auto col-auto\",",
            "                ),",
            "                dbc.Button(",
            "                    text(\"Load\"),",
            "                    id=\"load-btn\",",
            "                    color=\"primary\",",
            "                    style=dict(display=\"none\"),",
            "                ),",
            "                build_hoverable(",
            "                    dbc.Button(",
            "                        text(\"Save\"),",
            "                        id=\"save-btn\",",
            "                        color=\"primary\",",
            "                        style=dict(display=\"none\"),",
            "                    ),",
            "                    text(\"save_msg\"),",
            "                    \"\",",
            "                    top=\"120%\",",
            "                ),",
            "                build_hoverable(",
            "                    html.A(",
            "                        html.I(className=\"fas fa-file-code fa-xl\"),",
            "                        id=\"export-all-chart-btn\",",
            "                        href=\"\",",
            "                        className=\"export-chart-btn\",",
            "                        style=dict(display=\"none\"),",
            "                    ),",
            "                    \"Export Charts\",",
            "                    additional_classes=\"mt-auto mb-auto\",",
            "                    hover_class=\"export-charts\",",
            "                ),",
            "            ],",
            "            className=\"row pt-3 pb-5 charts-filters\",",
            "            id=\"chart-inputs\",",
            "        ),",
            "        dcc.Loading(",
            "            html.Div(id=\"chart-content\", style={\"height\": \"calc(100vh - 380px\"}),",
            "            type=\"circle\",",
            "        ),",
            "        dcc.Textarea(id=\"copy-text\", style=dict(position=\"absolute\", left=\"-110%\")),",
            "    ]",
            "    if settings.get(\"github_fork\", False):",
            "        body_items.append(",
            "            html.Span(",
            "                html.A(",
            "                    text(\"Fork me on Github\"), href=\"https://github.com/man-group/dtale\"",
            "                ),",
            "                id=\"forkongithub\",",
            "            )",
            "        )",
            "    return body_items"
        ],
        "afterPatchFile": [
            "import json",
            "",
            "import dash_bootstrap_components as dbc",
            "import dash_colorscales as dcs",
            "import dash_daq as daq",
            "import os",
            "import plotly",
            "from pkg_resources import parse_version",
            "from six import PY3",
            "",
            "from dtale.dash_application import dcc, html",
            "import dtale.dash_application.custom_geojson as custom_geojson",
            "import dtale.dash_application.extended_aggregations as extended_aggregations",
            "import dtale.global_state as global_state",
            "from dtale.charts.utils import (",
            "    AGGS,",
            "    ANIMATION_CHARTS,",
            "    ANIMATE_BY_CHARTS,",
            "    YAXIS_CHARTS,",
            "    ZAXIS_CHARTS,",
            "    NON_EXT_AGGREGATION,",
            "    build_final_cols,",
            "    find_group_vals,",
            ")",
            "from dtale.column_builders import get_cleaner_configs",
            "from dtale.constants import CHART_JOINER_CHAR",
            "from dtale.dash_application.layout.utils import (",
            "    build_input,",
            "    build_option,",
            "    build_tab,",
            "    build_cols,",
            "    build_hoverable,",
            "    build_selections,",
            "    show_style,",
            "    FREQS,",
            "    FREQ_LABELS,",
            ")",
            "from dtale.translations import text",
            "from dtale.query import build_query, handle_predefined, inner_build_query, run_query",
            "from dtale.utils import (",
            "    ChartBuildingError,",
            "    classify_type,",
            "    coord_type,",
            "    get_dtypes,",
            "    is_app_root_defined,",
            "    make_list,",
            ")",
            "",
            "",
            "def test_plotly_version(version_num):",
            "    if \"unknown\" in plotly.__version__:",
            "        return True",
            "    return parse_version(plotly.__version__) >= parse_version(version_num)",
            "",
            "",
            "def get_dashbio():",
            "    import dash_bio as dashbio  # noqa: F401",
            "",
            "    return dashbio",
            "",
            "",
            "def has_dashbio():",
            "    try:",
            "        get_dashbio()",
            "        return True",
            "    except ImportError:",
            "        return False",
            "",
            "",
            "def base_layout(app_root, **kwargs):",
            "    \"\"\"",
            "    Base layout to be returned by :meth:`dtale.dash_application.views.DtaleDash.interpolate_index`",
            "",
            "    :param kwargs: Optional keyword arguments to be passed to 'dash.Dash.interplolate_index'",
            "    :type kwargs: dict",
            "    :return: HTML",
            "    :rtype: str",
            "    \"\"\"",
            "    webroot_html = \"\"",
            "    favicon_path = \"../../dtale/static/images/favicon.png\"",
            "    if is_app_root_defined(app_root):",
            "        webroot_html = \"\"\"",
            "        <script type=\"text/javascript\">",
            "            window.resourceBaseUrl = '{app_root}';",
            "        </script>",
            "        \"\"\".format(",
            "            app_root=app_root",
            "        )",
            "        favicon_path = \"{}/dtale/static/images/favicon.png\".format(app_root)",
            "    grid_links = []",
            "    for id in global_state.keys():",
            "        label = global_state.get_name(id)",
            "        if label:",
            "            label = \" ({})\".format(label)",
            "        else:",
            "            label = \"\"",
            "        grid_links.append(",
            "            (",
            "                \"\"\"<a href=\"../main/{id}\" class=\"dropdown-item data-grid-link\" target=\"{target}\">\"\"\"",
            "                \"\"\"<span class=\"ml-3\">{id}{label}</span>\"\"\"",
            "                \"\"\"</a>\"\"\"",
            "            ).format(",
            "                id=id,",
            "                label=label,",
            "                target=(",
            "                    \"_self\" if os.environ.get(\"VSCODE_PID\") is not None else \"_blank\"",
            "                ),",
            "            )",
            "        )",
            "    language = global_state.get_app_settings()[\"language\"]",
            "    language_links = []",
            "    for value, label in [(\"en\", \"English\"), (\"cn\", \"Chinese\"), (\"pt\", \"Portuguese\")]:",
            "        if value == language:",
            "            language_links.append(",
            "                \"\"\"<span class=\"dropdown-item active\">{}</span>\"\"\".format(",
            "                    \"&#10003; {}\".format(text(label))",
            "                )",
            "            )",
            "        else:",
            "            language_links.append(",
            "                \"\"\"<a href=\"{}\" class=\"dropdown-item lang-link\">{}</a>\"\"\".format(",
            "                    value, text(label)",
            "                )",
            "            )",
            "",
            "    main_title = global_state.get_app_settings().get(\"main_title\") or \"D-TALE\"",
            "    main_title_font = global_state.get_app_settings().get(\"main_title_font\")",
            "    main_title_class = \"title-font-base\"",
            "    main_title_style = \"\"",
            "    if main_title_font:",
            "        main_title_style = \"font-family: {main_title_font}\".format(",
            "            main_title_font=main_title_font",
            "        )",
            "    else:",
            "        main_title_class = \"title-font title-font-base\"",
            "    page_title = global_state.get_app_settings().get(\"main_title\") or \"D-Tale\"",
            "",
            "    return \"\"\"",
            "        <!DOCTYPE html>",
            "        <html>",
            "            <head>",
            "                {webroot_html}",
            "                {metas}",
            "                <title>{page_title} Charts</title>",
            "                <link rel=\"shortcut icon\" href=\"{favicon_path}\">",
            "                {css}",
            "            </head>",
            "            <body class=\"{theme}-mode\">",
            "                <header class=\"app-header\">",
            "                    <span class=\"{main_title_class}\" style=\"{main_title_style}\">{main_title}</span>",
            "                    <span style=\"font-size: 16px\" class=\"pl-5 mt-4\">{title}</span>",
            "                    <nav class=\"app-header__nav--secondary\">",
            "                        <ul class=\"nav-menus\">",
            "                            <li>",
            "                                <div class=\"dropdown\">",
            "                                    <span class=\"dropbtn nav-link dropdown-toggle\">",
            "                                        {back_to_data}",
            "                                    </span>",
            "                                    <div class=\"dropdown-content\">{grid_links}</div>",
            "                                </div>",
            "                            </li>",
            "                            <li>",
            "                                <div class=\"dropdown\">",
            "                                    <span class=\"dropbtn nav-link dropdown-toggle\">",
            "                                        {languages}",
            "                                    </span>",
            "                                    <div class=\"dropdown-content\">{language_links}</div>",
            "                                </div>",
            "                            </li>",
            "                        </ul>",
            "                    </nav>",
            "                </header>",
            "                <div class=\"container-fluid charts\">",
            "                    {app_entry}",
            "                </div>",
            "                <footer>",
            "                    {config}",
            "                    {scripts}",
            "                    <script type=\"text/javascript\">",
            "                        const pathSegs = window.location.pathname.split('/');",
            "                        const dataId = pathSegs[pathSegs.length - 1];",
            "                        const backToData = () => window.open('{app_root}/dtale/main/' + dataId);",
            "                    </script>",
            "                    {renderer}",
            "                    {css}",
            "                </footer>",
            "            </body>",
            "        </html>",
            "    \"\"\".format(",
            "        metas=kwargs[\"metas\"],",
            "        css=kwargs[\"css\"],",
            "        app_entry=kwargs[\"app_entry\"],",
            "        config=kwargs[\"config\"],",
            "        scripts=kwargs[\"scripts\"],",
            "        renderer=kwargs[\"renderer\"],",
            "        webroot_html=webroot_html,",
            "        app_root=app_root if is_app_root_defined(app_root) else \"\",",
            "        favicon_path=favicon_path,",
            "        title=text(\"Charts\"),",
            "        back_to_data=text(\"Back To Data\"),",
            "        grid_links=\"\".join(grid_links),",
            "        languages=text(\"Languages\"),",
            "        language_links=\"\".join(language_links),",
            "        main_title=main_title,",
            "        main_title_class=main_title_class,",
            "        main_title_style=main_title_style,",
            "        page_title=page_title,",
            "        theme=global_state.get_app_settings()[\"theme\"],",
            "    )",
            "",
            "",
            "CHARTS = [",
            "    dict(value=\"line\"),",
            "    dict(value=\"bar\"),",
            "    dict(value=\"scatter\"),",
            "    dict(value=\"pie\"),",
            "    dict(value=\"wordcloud\"),",
            "    dict(value=\"heatmap\"),",
            "    dict(value=\"3d_scatter\", label=\"3D Scatter\"),",
            "    dict(value=\"surface\"),",
            "    dict(value=\"maps\"),",
            "    dict(value=\"candlestick\"),",
            "    dict(value=\"treemap\"),",
            "    dict(value=\"funnel\"),",
            "]",
            "if has_dashbio():",
            "    CHARTS.append(dict(value=\"clustergram\"))",
            "CHARTS.append(dict(value=\"pareto\"))",
            "CHARTS.append(dict(value=\"histogram\"))",
            "",
            "CHART_INPUT_SETTINGS = {",
            "    \"line\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"bar\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"scatter\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"pie\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"wordcloud\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"multi\"),",
            "        z=dict(display=False),",
            "        group=dict(display=True, type=\"single\"),",
            "    ),",
            "    \"heatmap\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"single\"),",
            "        z=dict(display=True, type=\"single\"),",
            "        group=dict(display=False),",
            "    ),",
            "    \"3d_scatter\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"single\"),",
            "        z=dict(display=True, type=\"single\"),",
            "        group=dict(display=True),",
            "    ),",
            "    \"surface\": dict(",
            "        x=dict(type=\"single\"),",
            "        y=dict(type=\"single\"),",
            "        z=dict(display=True, type=\"single\"),",
            "        group=dict(display=False),",
            "    ),",
            "    \"maps\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=True),",
            "    ),",
            "    \"candlestick\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=True),",
            "    ),",
            "    \"treemap\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=True),",
            "    ),",
            "    \"funnel\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=True),",
            "    ),",
            "    \"clustermap\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=False),",
            "        clustergram_group=dict(display=True),",
            "    ),",
            "    \"pareto\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=False),",
            "        clustergram_group=dict(display=False),",
            "    ),",
            "    \"histogram\": dict(",
            "        x=dict(display=False),",
            "        y=dict(display=False),",
            "        z=dict(display=False),",
            "        group=dict(display=False),",
            "        map_group=dict(display=False),",
            "        cs_group=dict(display=False),",
            "        treemap_group=dict(display=False),",
            "        funnel_group=dict(display=False),",
            "        clustergram_group=dict(display=False),",
            "        histogram_group=dict(display=True),",
            "    ),",
            "}",
            "LOAD_TYPES = [\"random\", \"head\", \"tail\", \"stratified\"]",
            "MAP_TYPES = [",
            "    dict(value=\"choropleth\", image=True),",
            "    dict(value=\"scattergeo\", label=\"ScatterGeo\", image=True),",
            "    dict(value=\"mapbox\", label=\"Detailed\", image=True),",
            "]",
            "SCOPES = [\"world\", \"usa\", \"europe\", \"asia\", \"africa\", \"north america\", \"south america\"]",
            "PROJECTIONS = [",
            "    \"equirectangular\",",
            "    \"mercator\",",
            "    \"orthographic\",",
            "    \"natural earth\",",
            "    \"kavrayskiy7\",",
            "    \"miller\",",
            "    \"robinson\",",
            "    \"eckert4\",",
            "    \"azimuthal equal area\",",
            "    \"azimuthal equidistant\",",
            "    \"conic equal area\",",
            "    \"conic conformal\",",
            "    \"conic equidistant\",",
            "    \"gnomonic\",",
            "    \"stereographic\",",
            "    \"mollweide\",",
            "    \"hammer\",",
            "    \"transverse mercator\",",
            "    \"albers usa\",",
            "    \"winkel tripel\",",
            "    \"aitoff\",",
            "    \"sinusoidal\",",
            "]",
            "",
            "",
            "def auto_load_msg():",
            "    return text(\"auto_load_msg\")",
            "",
            "",
            "def load_type_msg():",
            "    return [",
            "        html.Div(",
            "            [",
            "                html.H3(",
            "                    text(\"Load Types\"), style=dict(display=\"inline\"), className=\"pr-3\"",
            "                )",
            "            ]",
            "        ),",
            "        html.Ul(",
            "            [",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Random\")),",
            "                        html.Span(\": {}\".format(text(\"load_random\"))),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [html.B(text(\"Head\")), html.Span(\": {}\".format(text(\"load_head\")))],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [html.B(text(\"Tail\")), html.Span(\": {}\".format(text(\"load_tail\")))],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Stratified\")),",
            "                        html.Span(\": {}\".format(text(\"load_stratified\"))),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "            ],",
            "            className=\"mb-0\",",
            "        ),",
            "    ]",
            "",
            "",
            "def bin_type_msg():",
            "    return [",
            "        html.Div(",
            "            [",
            "                html.H3(",
            "                    text(\"Bin Types\"), style=dict(display=\"inline\"), className=\"pr-3\"",
            "                ),",
            "                html.A(",
            "                    \"({})\".format(text(\"Binning in Data Mining\")),",
            "                    href=\"https://www.geeksforgeeks.org/binning-in-data-mining/\",",
            "                ),",
            "                html.Br(),",
            "            ]",
            "        ),",
            "        html.Ul(",
            "            [",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Equal Width\")),",
            "                        html.Span(",
            "                            \": {}\".format(text(\"the bins are of equal sized ranges\"))",
            "                        ),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "                html.Li(",
            "                    [",
            "                        html.B(text(\"Equal Frequency\")),",
            "                        html.Span(",
            "                            \": {}\".format(",
            "                                text(\"the bins contain an equal amount of values\")",
            "                            )",
            "                        ),",
            "                    ],",
            "                    className=\"mb-0\",",
            "                ),",
            "            ],",
            "            className=\"mb-0\",",
            "        ),",
            "    ]",
            "",
            "",
            "def build_img_src(proj, img_type=\"projections\"):",
            "    return \"../static/images/{}/{}.png\".format(img_type, \"_\".join(proj.split(\" \")))",
            "",
            "",
            "def build_proj_hover_children(proj):",
            "    if proj is None:",
            "        return None",
            "    return [",
            "        html.I(className=\"ico-help-outline\", style=dict(color=\"white\")),",
            "        html.Div(",
            "            [html.Div(proj), html.Img(src=build_img_src(proj))],",
            "            className=\"hoverable__content\",",
            "            style=dict(width=\"auto\"),",
            "        ),",
            "    ]",
            "",
            "",
            "def build_proj_hover(proj):",
            "    return html.Span(",
            "        [",
            "            text(\"Projection\"),",
            "            html.Div(",
            "                build_proj_hover_children(proj),",
            "                className=\"ml-3 hoverable\",",
            "                style=(",
            "                    dict(display=\"none\") if proj is None else dict(borderBottom=\"none\")",
            "                ),",
            "                id=\"proj-hover\",",
            "            ),",
            "        ],",
            "        className=\"input-group-addon\",",
            "    )",
            "",
            "",
            "def build_mapbox_token_children():",
            "    from dtale.charts.utils import get_mapbox_token",
            "",
            "    msg = text(\"To access additional styles enter a token here...\")",
            "    if get_mapbox_token() is None:",
            "        msg = text(\"Change your token here...\")",
            "    return [",
            "        html.I(className=\"ico-help-outline\", style=dict(color=\"white\")),",
            "        html.Div(",
            "            [",
            "                html.Span(\"{}:\".format(\"Mapbox Access Token\")),",
            "                dcc.Input(",
            "                    id=\"mapbox-token-input\",",
            "                    type=\"text\",",
            "                    placeholder=msg,",
            "                    className=\"form-control\",",
            "                    value=\"\",",
            "                    style={\"lineHeight\": \"inherit\"},",
            "                ),",
            "            ],",
            "            className=\"hoverable__content\",",
            "            style=dict(width=\"20em\", right=\"-1.45em\"),",
            "        ),",
            "    ]",
            "",
            "",
            "def build_mapbox_token_hover():",
            "    return html.Span(",
            "        [",
            "            text(\"Style\"),",
            "            html.Div(",
            "                build_mapbox_token_children(),",
            "                className=\"ml-3 hoverable\",",
            "                style=dict(borderBottom=\"none\"),",
            "                id=\"token-hover\",",
            "            ),",
            "        ],",
            "        className=\"input-group-addon\",",
            "    )",
            "",
            "",
            "def loc_mode_info():",
            "    return {",
            "        \"ISO-3\": dict(",
            "            url=html.A(",
            "                text(\"ISO-3\"),",
            "                href=\"https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3\",",
            "                target=\"_blank\",",
            "            ),",
            "            examples=[\"USA (United States)\", \"CAN (Canada)\", \"GBR (United Kingdom)\"],",
            "        ),",
            "        \"USA-states\": dict(",
            "            url=html.A(",
            "                text(\"USA-states (use ISO)\"),",
            "                href=\"https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations\",",
            "                target=\"_blank\",",
            "            ),",
            "            examples=[\"NY (New York)\", \"CA (California)\", \"MA (Massachusetts)\"],",
            "        ),",
            "        \"country names\": dict(",
            "            url=html.A(",
            "                text(\"country names (case-insensitive)\"),",
            "                href=\"https://simple.wikipedia.org/wiki/List_of_countries\",",
            "                target=\"_blank\",",
            "            ),",
            "            examples=[\"United States\", \"United Kingdom\", \"Germany\"],",
            "        ),",
            "        \"geojson-id\": dict(",
            "            label=\"Custom GeoJSON\", desc=text(\"Load custom geojson into D-Tale\")",
            "        ),",
            "    }",
            "",
            "",
            "def build_loc_mode_hover_children(loc_mode):",
            "    if loc_mode is None:",
            "        return None",
            "    loc_modes = loc_mode_info()",
            "    loc_mode_cfg = loc_modes[loc_mode]",
            "    url, examples, desc = (loc_mode_cfg.get(p) for p in [\"url\", \"examples\", \"desc\"])",
            "    body = []",
            "    if url is not None:",
            "        body.append(",
            "            html.Div([html.Span(text(\"View\"), className=\"mr-3\"), loc_mode_cfg[\"url\"]])",
            "        )",
            "    if examples is not None:",
            "        body.append(",
            "            html.Ul(",
            "                [",
            "                    html.Li(e, style={\"listStyleType\": \"disc\"}, className=\"mb-3\")",
            "                    for e in loc_mode_cfg[\"examples\"]",
            "                ],",
            "                className=\"pt-3 mb-0\",",
            "            )",
            "        )",
            "    if desc is not None:",
            "        body.append(html.Span(desc))",
            "    return [",
            "        html.I(className=\"ico-help-outline\", style=dict(color=\"white\")),",
            "        html.Div(",
            "            body,",
            "            className=\"hoverable__content build-code\",",
            "            style=dict(width=\"auto\", whiteSpace=\"nowrap\", left=\"-2em\", top=\"auto\"),",
            "        ),",
            "    ]",
            "",
            "",
            "def build_loc_mode_hover(loc_mode):",
            "    return html.Span(",
            "        [",
            "            html.Span(text(\"Location Mode\"), style=dict(whiteSpace=\"pre-line\")),",
            "            html.Div(",
            "                build_loc_mode_hover_children(loc_mode),",
            "                className=\"ml-3 hoverable\",",
            "                style=(",
            "                    dict(display=\"none\")",
            "                    if loc_mode is None",
            "                    else dict(borderBottom=\"none\")",
            "                ),",
            "                id=\"loc-mode-hover\",",
            "            ),",
            "        ],",
            "        className=\"input-group-addon pt-1 pb-0\",",
            "    )",
            "",
            "",
            "JET = [\"#000083\", \"#003CAA\", \"#05FFFF\", \"#FFFF00\", \"#FA0000\", \"#800000\"]",
            "REDS = [\"#fff5f0\", \"#fdcab4\", \"#fc8a6a\", \"#f24632\", \"#bc141a\", \"#67000d\"]",
            "YLORRD = [",
            "    \"#ffffcc\",",
            "    \"#ffeda0\",",
            "    \"#fed976\",",
            "    \"#feb24c\",",
            "    \"#fd8d3c\",",
            "    \"#fc4e2a\",",
            "    \"#e31a1c\",",
            "    \"#bd0026\",",
            "    \"#800026\",",
            "]",
            "YLGRBL = [\"#ffffd9\", \"#d5efb3\", \"#73c9bc\", \"#1b99c2\", \"#1c4ea2\", \"#081d58\"]",
            "DEFAULT_CSALES = {\"heatmap\": JET, \"maps\": REDS, \"3d_Scatter\": YLORRD, \"surface\": YLGRBL}",
            "",
            "",
            "def show_input_handler(chart_type):",
            "    settings = CHART_INPUT_SETTINGS.get(chart_type or \"line\") or {}",
            "",
            "    def _show_input(input_id, input_type=\"single\"):",
            "        cfg = settings.get(input_id, {})",
            "        return cfg.get(\"display\", True) and cfg.get(\"type\", \"single\") == input_type",
            "",
            "    return _show_input",
            "",
            "",
            "def get_group_types(inputs, group_cols=None):",
            "    def _flags(group_prop):",
            "        final_group_cols = group_cols or make_list(inputs.get(group_prop))",
            "        if len(final_group_cols):",
            "            dtypes = global_state.get_dtypes(inputs[\"data_id\"])",
            "            for dtype_info in dtypes:",
            "                if dtype_info[\"name\"] in final_group_cols:",
            "                    classifier = classify_type(dtype_info[\"dtype\"])",
            "                    if classifier == \"F\":",
            "                        return [\"bins\"]",
            "                    if classifier == \"I\":",
            "                        return [\"groups\", \"bins\"]",
            "                    return [\"groups\"]",
            "            for fgc in final_group_cols:",
            "                col, freq = fgc.split(CHART_JOINER_CHAR)",
            "                col_exists = (",
            "                    next(",
            "                        (",
            "                            dtype_info",
            "                            for dtype_info in dtypes",
            "                            if dtype_info[\"name\"] == col",
            "                        ),",
            "                        None,",
            "                    )",
            "                    is not None",
            "                )",
            "                if col_exists and freq in FREQS:",
            "                    return [\"groups\"]",
            "        return []",
            "",
            "    chart_type = inputs.get(\"chart_type\")",
            "",
            "    if show_input_handler(chart_type)(\"group\"):",
            "        return _flags(\"group\")",
            "    elif show_input_handler(chart_type)(\"map_group\"):",
            "        return _flags(\"map_group\")",
            "    elif show_input_handler(chart_type)(\"cs_group\"):",
            "        return _flags(\"cs_group\")",
            "    elif show_input_handler(chart_type)(\"treemap_group\"):",
            "        return _flags(\"treemap_group\")",
            "    elif show_input_handler(chart_type)(\"funnel_group\"):",
            "        return _flags(\"funnel_group\")",
            "    elif show_input_handler(chart_type)(\"clustergram_group\"):",
            "        return _flags(\"clustergram_group\")",
            "    elif show_input_handler(chart_type)(\"pareto_group\"):",
            "        return _flags(\"pareto_group\")",
            "    return False, False",
            "",
            "",
            "def update_label_for_freq_and_agg(val):",
            "    \"\"\"",
            "    Formats sub-values contained within 'val' to display date frequencies & aggregatioms if included.",
            "        - (val=['a', 'b', 'c']) => 'a, b, c'",
            "        - (val=['a||H', 'b||mean', 'c']) => 'a (Hour), Mean of b, c'",
            "    \"\"\"",
            "",
            "    def _freq_handler(sub_val):",
            "        selected_agg = None",
            "        for agg in AGGS:",
            "            if sub_val.endswith(\"{}{}\".format(CHART_JOINER_CHAR, agg)):",
            "                selected_agg = \"{} of\".format(text(AGGS[agg]))",
            "                sub_val = sub_val.split(\"{}{}\".format(CHART_JOINER_CHAR, agg))[0]",
            "                break",
            "",
            "        selected_freq = None",
            "        for freq in FREQS:",
            "            if sub_val.endswith(\"{}{}\".format(CHART_JOINER_CHAR, freq)):",
            "                col, freq = sub_val.split(CHART_JOINER_CHAR)",
            "                if freq in FREQS:",
            "                    sub_val = sub_val.split(\"{}{}\".format(CHART_JOINER_CHAR, freq))[0]",
            "                    if freq in FREQ_LABELS:",
            "                        selected_freq = \"({})\".format(text(FREQ_LABELS[freq]))",
            "                    break",
            "",
            "        return \" \".join(list(filter(None, [selected_agg, sub_val, selected_freq])))",
            "",
            "    return \", \".join([_freq_handler(sub_val) for sub_val in make_list(val)])",
            "",
            "",
            "def build_error(error, tb):",
            "    \"\"\"",
            "    Returns error/traceback information in standard component with styling",
            "",
            "    :param error: execption message",
            "    :type error: str",
            "    :param tb: tracebackF",
            "    :type tb: str",
            "    :return: error component",
            "    :rtype: :dash:`dash_html_components.Div <dash-html-components/div>`",
            "    \"\"\"",
            "    if isinstance(error, ChartBuildingError):",
            "        if error.details:",
            "            tb = error.details",
            "        error = error.error",
            "    return html.Div(",
            "        [",
            "            html.I(className=\"ico-error\"),",
            "            html.Span(str(error)),",
            "            html.Div(html.Pre(str(tb)), className=\"traceback\"),",
            "        ],",
            "        className=\"dtale-alert alert alert-danger\",",
            "    )",
            "",
            "",
            "def build_input_options(df, extended_aggregation=[], **inputs):",
            "    \"\"\"",
            "    Builds dropdown options for (X, Y, Z, Group, Barsort & Y-Axis Ranges) with filtering based on currently selected",
            "    values for the following inputs: x, y, z, group.",
            "    \"\"\"",
            "    chart_type, x, y, z, group = (",
            "        inputs.get(p) for p in [\"chart_type\", \"x\", \"y\", \"z\", \"group\"]",
            "    )",
            "    col_opts = list(build_cols(df.columns, get_dtypes(df)))",
            "    group_val, z_val = (None, z) if chart_type in ZAXIS_CHARTS else (group, None)",
            "    x_options = [",
            "        build_option(c, l)",
            "        for c, l in col_opts",
            "        if c not in build_selections(y, z_val, group_val)",
            "    ]",
            "    y_filter = build_selections(x, group_val, z_val)",
            "    y_multi_options = [build_option(c, l) for c, l in col_opts if c not in y_filter]",
            "    y_single_options = [build_option(c, l) for c, l in col_opts if c not in y_filter]",
            "    z_options = [",
            "        build_option(c)",
            "        for c in df.columns",
            "        if c not in build_selections(x, y, group_val)",
            "    ]",
            "    group_options = [",
            "        build_option(c, l)",
            "        for c, l in col_opts",
            "        if c not in build_selections(x, y, z_val)",
            "    ]",
            "    final_cols = build_final_cols(",
            "        y,",
            "        z,",
            "        inputs.get(\"agg\"),",
            "        extended_aggregation if chart_type not in NON_EXT_AGGREGATION else [],",
            "    )",
            "    barsort_options = [build_option(o) for o in build_selections(x, final_cols)]",
            "    yaxis_options = [build_option(y2) for y2 in final_cols or []]",
            "    return (",
            "        x_options,",
            "        y_multi_options,",
            "        y_single_options,",
            "        z_options,",
            "        group_options,",
            "        barsort_options,",
            "        yaxis_options,",
            "        [build_option(c, l) for c, l in col_opts],",
            "    )",
            "",
            "",
            "def build_map_options(",
            "    df, type=\"choropleth\", loc=None, lat=None, lon=None, map_val=None",
            "):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    lat_cols, lon_cols, str_cols, num_cols = [], [], [], []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification == \"S\":",
            "            str_cols.append(c)",
            "            continue",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "            coord = coord_type(df[c])",
            "            if coord == \"lat\":",
            "                lat_cols.append(c)",
            "            elif coord == \"lon\":",
            "                lon_cols.append(c)",
            "",
            "    lat_options = [",
            "        build_option(c) for c in lat_cols if c not in build_selections(lon, map_val)",
            "    ]",
            "    lon_options = [",
            "        build_option(c) for c in lon_cols if c not in build_selections(lat, map_val)",
            "    ]",
            "    loc_options = [",
            "        build_option(c) for c in str_cols if c not in build_selections(map_val)",
            "    ]",
            "",
            "    if type == \"choropleth\":",
            "        val_options = [",
            "            build_option(c) for c in num_cols if c not in build_selections(loc)",
            "        ]",
            "    else:",
            "        val_options = [",
            "            build_option(c) for c in num_cols if c not in build_selections(lon, lat)",
            "        ]",
            "    return loc_options, lat_options, lon_options, val_options",
            "",
            "",
            "def build_candlestick_options(",
            "    df, cs_x=None, cs_open=None, cs_close=None, cs_high=None, cs_low=None",
            "):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols, x_cols = [], []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification in [\"S\", \"D\"]:",
            "            x_cols.append(c)",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "",
            "    x_options = [build_option(c) for c in x_cols]",
            "    close_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_open, cs_low, cs_high)",
            "    ]",
            "    open_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_close, cs_low, cs_high)",
            "    ]",
            "    low_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_open, cs_close, cs_high)",
            "    ]",
            "    high_options = [",
            "        build_option(c)",
            "        for c in num_cols",
            "        if c not in build_selections(cs_x, cs_open, cs_close, cs_low)",
            "    ]",
            "    return x_options, close_options, open_options, low_options, high_options",
            "",
            "",
            "def build_label_value_options(",
            "    df, selected_value=None, selected_label=None, all_value=False",
            "):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols = []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "",
            "    value_options = [",
            "        build_option(c) for c in num_cols if c not in build_selections(selected_label)",
            "    ]",
            "    if all_value:",
            "        value_options = [build_option(\"_all_columns_\", \"All Columns\")] + value_options",
            "    label_options = [",
            "        build_option(c) for c in cols if c not in build_selections(selected_value)",
            "    ]",
            "    return value_options, label_options",
            "",
            "",
            "def build_label_value_store(prop, inputs):",
            "    return dcc.Store(",
            "        id=\"{}-input-data\".format(prop),",
            "        data={",
            "            k: v",
            "            for k, v in inputs.items()",
            "            if k",
            "            in [",
            "                \"{}_value\".format(prop),",
            "                \"{}_label\".format(prop),",
            "                \"{}_group\".format(prop),",
            "            ]",
            "        },",
            "    )",
            "",
            "",
            "def bootstrap_checkbox_prop():",
            "    if parse_version(dbc.__version__) >= parse_version(\"1.0.0\"):",
            "        return \"value\"",
            "    return \"checked\"",
            "",
            "",
            "def build_dropna(dropna, prop=None):",
            "    if PY3:",
            "        checkbox_kwargs = dict(",
            "            id=(",
            "                \"{}-dropna-checkbox\".format(prop)",
            "                if prop is not None",
            "                else \"dropna-checkbox\"",
            "            ),",
            "            style=dict(width=\"inherit\"),",
            "        )",
            "        checkbox_kwargs[bootstrap_checkbox_prop()] = True if dropna is None else dropna",
            "        return build_input(",
            "            text(\"Dropna\"),",
            "            html.Div(dbc.Checkbox(**checkbox_kwargs), className=\"checkbox-wrapper\"),",
            "            className=\"col-auto\",",
            "            id=\"{}-dropna-input\".format(prop) if prop is not None else \"dropna-input\",",
            "        )",
            "    return build_input(",
            "        text(\"Dropna\"),",
            "        dcc.Input(",
            "            id=(",
            "                \"{}-dropna-checkbox\".format(prop)",
            "                if prop is not None",
            "                else \"dropna-checkbox\"",
            "            ),",
            "            type=\"hidden\",",
            "            value=True if dropna is None else dropna,",
            "        ),",
            "        id=\"{}-dropna-input\".format(prop) if prop is not None else \"dropna-input\",",
            "        style={\"display\": \"none\"},",
            "    )",
            "",
            "",
            "def build_label_value_inputs(",
            "    prop,",
            "    inputs,",
            "    df,",
            "    group_options,",
            "    additional_inputs=[],",
            "    multi_value=False,",
            "    all_option=False,",
            "):",
            "    show_inputs = inputs.get(\"chart_type\") == prop",
            "    props = [\"{}_value\", \"{}_label\", \"{}_group\", \"{}_dropna\"]",
            "    selected_value, selected_label, selected_group, dropna = (",
            "        inputs.get(p.format(prop)) for p in props",
            "    )",
            "    all_options = build_label_value_options(",
            "        df,",
            "        selected_value=selected_value,",
            "        selected_label=selected_label,",
            "        all_value=multi_value and all_option,",
            "    )",
            "    value_options, label_options = all_options",
            "    return html.Div(",
            "        [",
            "            build_input(",
            "                text(\"Value(s)\" if multi_value else \"Value\"),",
            "                dcc.Dropdown(",
            "                    id=\"{}-value-dropdown\".format(prop),",
            "                    options=value_options,",
            "                    placeholder=text(",
            "                        \"Select Column(s)\" if multi_value else \"Select Column\"",
            "                    ),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=selected_value,",
            "                    multi=multi_value,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Labels\"),",
            "                dcc.Dropdown(",
            "                    id=\"{}-label-dropdown\".format(prop),",
            "                    options=label_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=selected_label,",
            "                ),",
            "            ),",
            "        ]",
            "        + additional_inputs",
            "        + [",
            "            build_input(",
            "                text(\"Group\"),",
            "                dcc.Dropdown(",
            "                    id=\"{}-group-dropdown\".format(prop),",
            "                    options=group_options,",
            "                    multi=True,",
            "                    placeholder=text(\"Select Group(s)\"),",
            "                    value=selected_group,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                className=\"col\",",
            "                id=\"{}-group-input\".format(prop),",
            "            ),",
            "            build_dropna(dropna, prop),",
            "        ],",
            "        id=\"{}-inputs\".format(prop),",
            "        className=\"row charts-filters\",",
            "        style={} if show_inputs else {\"display\": \"none\"},",
            "    )",
            "",
            "",
            "def build_funnel_inputs(inputs, df, group_options):",
            "    stacked_toggle = build_input(",
            "        \"{}?\".format(text(\"Stack\")),",
            "        html.Div(",
            "            daq.BooleanSwitch(id=\"funnel-stack-toggle\", on=False),",
            "            className=\"toggle-wrapper\",",
            "        ),",
            "        id=\"funnel-stack-input\",",
            "        style=show_style(inputs.get(\"funnel_group\") is not None),",
            "        className=\"col-auto\",",
            "    )",
            "",
            "    return build_label_value_inputs(",
            "        \"funnel\", inputs, df, group_options, additional_inputs=[stacked_toggle]",
            "    )",
            "",
            "",
            "def get_num_cols(df):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols = []",
            "    for c in cols:",
            "        dtype = dtypes[c]",
            "        classification = classify_type(dtype)",
            "        if classification in [\"F\", \"I\"]:",
            "            num_cols.append(c)",
            "    return num_cols",
            "",
            "",
            "def build_pareto_options(df, x=None, bars=None, line=None):",
            "    dtypes = get_dtypes(df)",
            "    cols = sorted(dtypes.keys())",
            "    num_cols = get_num_cols(df)",
            "",
            "    x_options = [build_option(c) for c in cols if c not in [bars, line]]",
            "    bars_options = [build_option(c) for c in num_cols if c not in [x, line]]",
            "    line_options = [build_option(c) for c in num_cols if c not in [x, bars]]",
            "    sort_options = [build_option(c) for c in cols]",
            "    return x_options, bars_options, line_options, sort_options",
            "",
            "",
            "def build_pareto_inputs(inputs, df, group_options):",
            "    show_inputs = inputs.get(\"chart_type\") == \"pareto\"",
            "    x, bars, line, sort, sort_dir, group, dropna = (",
            "        inputs.get(\"pareto_{}\".format(prop))",
            "        for prop in [\"x\", \"bars\", \"line\", \"sort\", \"dir\", \"group\", \"dropna\"]",
            "    )",
            "    x_options, bar_options, line_options, sort_options = build_pareto_options(",
            "        df, x, bars, line",
            "    )",
            "",
            "    return html.Div(",
            "        [",
            "            build_input(",
            "                [html.Div(text(\"X\")), html.Small(\"({})\".format(text(\"Agg By\")))],",
            "                dcc.Dropdown(",
            "                    id=\"pareto-x-dropdown\",",
            "                    options=x_options,",
            "                    placeholder=\"{} (1, 2, ..., N)\".format(text(\"Default Index\")),",
            "                    value=x,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "            ),",
            "            build_input(",
            "                text(\"Bars\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-bars-dropdown\",",
            "                    options=bar_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=bars,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Line\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-line-dropdown\",",
            "                    options=line_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=line,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Sort\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-sort-dropdown\",",
            "                    options=sort_options,",
            "                    placeholder=text(\"Select Column\"),",
            "                    style=dict(width=\"inherit\"),",
            "                    value=sort,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Dir\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-dir-dropdown\",",
            "                    options=[build_option(d, d.capitalize()) for d in [\"ASC\", \"DESC\"]],",
            "                    style=dict(width=\"inherit\"),",
            "                    value=sort_dir or \"DESC\",",
            "                    placeholder=None,",
            "                    clearable=False,",
            "                ),",
            "            ),",
            "            build_input(",
            "                text(\"Group\"),",
            "                dcc.Dropdown(",
            "                    id=\"pareto-group-dropdown\",",
            "                    options=group_options,",
            "                    multi=True,",
            "                    placeholder=text(\"Select Group(s)\"),",
            "                    value=group,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                className=\"col\",",
            "                id=\"pareto-group-input\",",
            "            ),",
            "            build_dropna(dropna, \"pareto\"),",
            "        ],",
            "        id=\"pareto-inputs\",",
            "        style={} if show_inputs else {\"display\": \"none\"},",
            "        className=\"row p-0 charts-filters\",",
            "    )",
            "",
            "",
            "def build_histogram_inputs(inputs, df, group_options):",
            "    show_inputs = inputs.get(\"chart_type\") == \"histogram\"",
            "    col, histogram_type, bins, group = (",
            "        inputs.get(\"histogram_{}\".format(prop))",
            "        for prop in [\"col\", \"type\", \"bins\", \"group\"]",
            "    )",
            "    col_options = get_num_cols(df)",
            "",
            "    return html.Div(",
            "        [",
            "            build_input(",
            "                text(\"Col\"),",
            "                dcc.Dropdown(",
            "                    id=\"histogram-col-dropdown\",",
            "                    options=col_options,",
            "                    value=col,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "            ),",
            "            dcc.Tabs(",
            "                id=\"histogram-type-tabs\",",
            "                value=histogram_type or \"bins\",",
            "                children=[",
            "                    build_tab(text(\"Bins\"), \"bins\"),",
            "                    build_tab(text(\"Density\"), \"density\"),",
            "                ],",
            "                style=dict(height=\"36px\", width=\"10em\"),",
            "            ),",
            "            build_input(",
            "                text(\"Bins\"),",
            "                dcc.Input(",
            "                    id=\"histogram-bins-input\",",
            "                    type=\"number\",",
            "                    placeholder=text(\"Enter Bins\"),",
            "                    className=\"form-control text-center\",",
            "                    style={\"lineHeight\": \"inherit\"},",
            "                    value=bins or 5,",
            "                ),",
            "                id=\"histogram-bins-div\",",
            "                className=\"col-md-1 pr-0\",",
            "                style={} if histogram_type == \"bins\" else {\"display\": \"none\"},",
            "            ),",
            "            build_input(",
            "                text(\"Group\"),",
            "                dcc.Dropdown(",
            "                    id=\"histogram-group-dropdown\",",
            "                    options=group_options,",
            "                    multi=True,",
            "                    placeholder=text(\"Select Group(s)\"),",
            "                    value=group,",
            "                    style=dict(width=\"inherit\"),",
            "                ),",
            "                className=\"col\",",
            "                id=\"histogram-group-input\",",
            "            ),",
            "        ],",
            "        id=\"histogram-inputs\",",
            "        style={} if show_inputs else {\"display\": \"none\"},",
            "        className=\"row p-0 charts-filters\",",
            "    )",
            "",
            "",
            "def build_mapbox_style_options():",
            "    from dtale.charts.utils import get_mapbox_token",
            "",
            "    free_styles = [",
            "        \"open-street-map\",",
            "        \"carto-positron\",",
            "        \"carto-darkmatter\",",
            "        \"stamen-terrain\",",
            "        \"stamen-toner\",",
            "        \"stamen-watercolor\",",
            "    ]",
            "    token_styles = [",
            "        \"basic\",",
            "        \"streets\",",
            "        \"outdoors\",",
            "        \"light\",",
            "        \"dark\",",
            "        \"satellite\",",
            "        \"satellite-streets\",",
            "    ]",
            "    styles = free_styles",
            "    if get_mapbox_token() is not None:",
            "        styles += token_styles",
            "    return [build_option(v) for v in styles]",
            "",
            "",
            "def bar_input_style(**inputs):",
            "    \"\"\"",
            "    Sets display CSS property for bar chart inputs",
            "    \"\"\"",
            "    chart_type, group_col = (inputs.get(p) for p in [\"chart_type\", \"group\"])",
            "    show_bar = chart_type == \"bar\"",
            "    show_barsort = show_bar and group_col is None",
            "    return (",
            "        dict(display=\"block\" if show_bar else \"none\"),",
            "        dict(display=\"block\" if show_barsort else \"none\"),",
            "    )",
            "",
            "",
            "def colorscale_input_style(**inputs):",
            "    return dict(",
            "        display=(",
            "            \"block\"",
            "            if inputs.get(\"chart_type\")",
            "            in [\"heatmap\", \"maps\", \"3d_scatter\", \"surface\", \"clustergram\"]",
            "            else \"none\"",
            "        )",
            "    )",
            "",
            "",
            "def animate_styles(df, **inputs):",
            "    chart_type, agg, cpg, cpy = (",
            "        inputs.get(p) for p in [\"chart_type\", \"agg\", \"cpg\", \"cpy\"]",
            "    )",
            "    opts = []",
            "    if cpg or cpy or agg in [\"pctsum\", \"pctct\"]:",
            "        return dict(display=\"none\"), dict(display=\"none\"), opts",
            "    if chart_type in ANIMATION_CHARTS:",
            "        return dict(display=\"block\"), dict(display=\"none\"), opts",
            "    if chart_type in ANIMATE_BY_CHARTS:",
            "        opts = [build_option(v, l) for v, l in build_cols(df.columns, get_dtypes(df))]",
            "    if len(opts):",
            "        return dict(display=\"none\"), dict(display=\"block\"), opts",
            "    return dict(display=\"none\"), dict(display=\"none\"), []",
            "",
            "",
            "def lock_zoom_style(chart_type):",
            "    return (",
            "        dict(display=\"block\", textTransform=\"none\")",
            "        if chart_type in [\"3d_scatter\", \"surface\"]",
            "        else dict(display=\"none\")",
            "    )",
            "",
            "",
            "def show_chart_per_group(**inputs):",
            "    \"\"\"",
            "    Boolean function to determine whether \"Chart Per Group\" toggle should be displayed or not",
            "    \"\"\"",
            "    chart_type, group = (inputs.get(p) for p in [\"chart_type\", \"group\"])",
            "    invalid_type = chart_type in [\"pie\", \"wordcloud\", \"maps\", \"funnel\", \"clustergram\"]",
            "    return (",
            "        show_input_handler(chart_type)(\"group\")",
            "        and len(group or [])",
            "        and not invalid_type",
            "    )",
            "",
            "",
            "def show_chart_per_y(**inputs):",
            "    \"\"\"",
            "    Boolean function to determine whether \"Chart Per Y-Axis\" toggle should be displayed or not",
            "    \"\"\"",
            "    chart_type, y = (inputs.get(p) for p in [\"chart_type\", \"y\"])",
            "    return show_input_handler(chart_type)(\"y\", \"multi\") and len(y or []) > 1",
            "",
            "",
            "def show_yaxis_ranges(**inputs):",
            "    \"\"\"",
            "    Boolean function to determine whether \"Y-Axis Range\" inputs should be displayed or not",
            "    \"\"\"",
            "    chart_type, y = (inputs.get(p) for p in [\"chart_type\", \"y\"])",
            "    return chart_type in YAXIS_CHARTS and len(y or [])",
            "",
            "",
            "def get_yaxis_type_tabs(y):",
            "    tabs = [",
            "        build_tab(text(\"Default\"), \"default\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "        build_tab(text(\"Single\"), \"single\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "    ]",
            "    if len(y) <= 1:",
            "        return tabs",
            "    return tabs + [",
            "        build_tab(text(\"Multi\"), \"multi\", {\"padding\": \"2px\", \"minWidth\": \"4em\"})",
            "    ]",
            "",
            "",
            "def get_yaxis_scale_tabs():",
            "    return [",
            "        build_tab(text(\"Linear\"), \"linear\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "        build_tab(text(\"Log\"), \"log\", {\"padding\": \"2px\", \"minWidth\": \"4em\"}),",
            "    ]",
            "",
            "",
            "def build_group_val_options(df, group_cols):",
            "    group_vals = find_group_vals(df, group_cols)",
            "    return [",
            "        build_option(",
            "            json.dumps(gv),",
            "            CHART_JOINER_CHAR.join([str(gv.get(p, \"NaN\")) for p in group_cols]),",
            "        )",
            "        for gv in group_vals",
            "    ]",
            "",
            "",
            "def build_map_type_tabs(map_type):",
            "    def _build_map_type_hoverable():",
            "        for t in MAP_TYPES:",
            "            if t.get(\"image\", False):",
            "                yield html.Div(",
            "                    [",
            "                        html.Span(text(t.get(\"label\", t[\"value\"].capitalize()))),",
            "                        html.Img(src=build_img_src(t[\"value\"], img_type=\"map_type\")),",
            "                    ],",
            "                    className=\"col-md-4\",",
            "                )",
            "",
            "    return html.Div(",
            "        [",
            "            dcc.Tabs(",
            "                id=\"map-type-tabs\",",
            "                value=map_type or \"choropleth\",",
            "                children=[",
            "                    build_tab(text(t.get(\"label\", t[\"value\"].capitalize())), t[\"value\"])",
            "                    for t in MAP_TYPES",
            "                ],",
            "                style=dict(height=\"36px\"),",
            "            ),",
            "            html.Div(",
            "                html.Div(list(_build_map_type_hoverable()), className=\"row\"),",
            "                className=\"hoverable__content map-types\",",
            "            ),",
            "        ],",
            "        style=dict(paddingLeft=15, borderBottom=\"none\", width=\"20em\"),",
            "        className=\"hoverable\",",
            "    )",
            "",
            "",
            "def main_inputs_and_group_val_display(inputs):",
            "    group_types = get_group_types(inputs)",
            "    if len(group_types):",
            "        is_groups = [\"groups\"] == group_types or (",
            "            \"groups\" in group_types and inputs.get(\"group_type\") == \"groups\"",
            "        )",
            "        is_bins = [\"bins\"] == group_types or (",
            "            \"bins\" in group_types and inputs.get(\"group_type\") == \"bins\"",
            "        )",
            "        return (",
            "            dict(display=\"block\" if len(group_types) > 1 else \"none\"),",
            "            dict(display=\"block\" if is_groups else \"none\"),",
            "            dict(display=\"block\" if is_bins else \"none\"),",
            "            \"col-md-8\",",
            "            dict(display=\"block\"),",
            "        )",
            "    return (",
            "        dict(display=\"none\"),",
            "        dict(display=\"none\"),",
            "        dict(display=\"none\"),",
            "        \"col-md-12\",",
            "        dict(display=\"none\"),",
            "    )",
            "",
            "",
            "def build_slider_counts(df, data_id, query_value):",
            "    record_ct = len(",
            "        run_query(",
            "            handle_predefined(data_id, df=df),",
            "            build_query(data_id, query_value),",
            "            global_state.get_context_variables(data_id),",
            "        )",
            "    )",
            "    slider_counts = {",
            "        \"{}\".format(v * 20): {",
            "            \"label\": \"{}% ({:,.0f})\".format(v * 20, (v * 2) / 10 * record_ct)",
            "        }",
            "        for v in range(1, 6)",
            "    }",
            "    slider_counts[\"100\"][\"style\"] = {\"white-space\": \"nowrap\"}",
            "    return slider_counts",
            "",
            "",
            "def collapse_btn_text(is_open, label):",
            "    return \"{} {}\".format(\"\\u25BC\" if is_open else \"\\u25B6\", label)",
            "",
            "",
            "def charts_layout(df, settings, **inputs):",
            "    \"\"\"",
            "    Builds main dash inputs with dropdown options populated with the columns of the dataframe associated with the",
            "    page. Inputs included are: chart tabs, query, x, y, z, group, aggregation, rolling window/computation,",
            "    chart per group toggle, bar sort, bar mode, y-axis range editors",
            "",
            "    :param df: dataframe to drive the charts built on page",
            "    :type df: :class:`pandas:pandas.DataFrame`",
            "    :param settings: global settings associated with this dataframe (contains properties like \"query\")",
            "    :type param: dict",
            "    :return: dash markup",
            "    \"\"\"",
            "    chart_type, x, y, z, group, dropna, agg, load, load_type, stratified_group = (",
            "        inputs.get(p)",
            "        for p in [",
            "            \"chart_type\",",
            "            \"x\",",
            "            \"y\",",
            "            \"z\",",
            "            \"group\",",
            "            \"dropna\",",
            "            \"agg\",",
            "            \"load\",",
            "            \"load_type\",",
            "            \"stratified_group\",",
            "        ]",
            "    )",
            "    loc_modes = loc_mode_info()",
            "    y = y or []",
            "    show_input = show_input_handler(chart_type)",
            "    show_cpg = show_chart_per_group(**inputs)",
            "    show_cpy = show_chart_per_y(**inputs)",
            "    show_yaxis = show_yaxis_ranges(**inputs)",
            "    scatter_input = dict(display=\"block\" if chart_type == \"scatter\" else \"none\")",
            "    bar_style, barsort_input_style = bar_input_style(**inputs)",
            "    animate_style, animate_by_style, animate_opts = animate_styles(df, **inputs)",
            "",
            "    options = build_input_options(df, **inputs)",
            "    (",
            "        x_options,",
            "        y_multi_options,",
            "        y_single_options,",
            "        z_options,",
            "        group_options,",
            "        barsort_options,",
            "        yaxis_options,",
            "        stratified_groups,",
            "    ) = options",
            "    query_placeholder = \"{} (ex: col1 == 1)\".format(text(\"Enter pandas query\"))",
            "    query_value = inputs.get(\"query\") or inner_build_query(",
            "        settings, settings.get(\"query\")",
            "    )",
            "",
            "    query_label = html.Div(",
            "        [",
            "            html.Span(text(\"Query\")),",
            "            html.A(",
            "                html.I(className=\"fa fa-info-circle ml-4\"),",
            "                href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-query\",",
            "                target=\"_blank\",",
            "                style={\"color\": \"white\"},",
            "            ),",
            "        ],",
            "        className=\"input-group-addon\",",
            "        style={\"minWidth\": \"7em\"},",
            "    )",
            "    yaxis_type = (inputs.get(\"yaxis\") or {}).get(\"type\") or \"default\"",
            "    yaxis_type_style = (",
            "        {\"borderRadius\": \"0 0.25rem 0.25rem 0\"} if yaxis_type == \"default\" else None",
            "    )",
            "    show_map = chart_type == \"maps\"",
            "    map_props = [\"map_type\", \"loc_mode\", \"loc\", \"lat\", \"lon\", \"map_val\"]",
            "    map_type, loc_mode, loc, lat, lon, map_val = (inputs.get(p) for p in map_props)",
            "    map_scope, proj, mapbox_style = (",
            "        inputs.get(p) for p in [\"scope\", \"proj\", \"mapbox_style\"]",
            "    )",
            "    loc_options, lat_options, lon_options, map_val_options = build_map_options(",
            "        df, type=map_type, loc=loc, lat=lat, lon=lon, map_val=map_val",
            "    )",
            "    show_candlestick = chart_type == \"candlestick\"",
            "    cs_props = [",
            "        \"cs_x\",",
            "        \"cs_open\",",
            "        \"cs_close\",",
            "        \"cs_high\",",
            "        \"cs_low\",",
            "        \"cs_group\",",
            "        \"cs_dropna\",",
            "    ]",
            "    cs_x, cs_open, cs_close, cs_high, cs_low, cs_group, cs_dropna = (",
            "        inputs.get(p) for p in cs_props",
            "    )",
            "    (",
            "        cs_x_options,",
            "        open_options,",
            "        close_options,",
            "        high_options,",
            "        low_options,",
            "    ) = build_candlestick_options(",
            "        df,",
            "        cs_x=cs_x,",
            "        cs_open=cs_open,",
            "        cs_close=cs_close,",
            "        cs_high=cs_high,",
            "        cs_low=cs_low,",
            "    )",
            "    cscale_style = colorscale_input_style(**inputs)",
            "    default_cscale = DEFAULT_CSALES.get(chart_type, REDS)",
            "",
            "    (",
            "        group_type_style,",
            "        group_val_style,",
            "        bins_style,",
            "        main_input_class,",
            "        show_groups,",
            "    ) = main_inputs_and_group_val_display(inputs)",
            "    group_val = [json.dumps(gv) for gv in inputs.get(\"group_val\") or []]",
            "",
            "    def show_map_style(show):",
            "        return {} if show else {\"display\": \"none\"}",
            "",
            "    body_items = [",
            "        dcc.Store(id=\"query-data\", data=query_value),",
            "        dcc.Store(",
            "            id=\"input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k not in [\"cpg\", \"cpy\", \"barmode\", \"barsort\"]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"chart-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k in [\"cpg\", \"cpy\", \"barmode\", \"barsort\"]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"map-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k",
            "                in [",
            "                    \"map_type\",",
            "                    \"map_code\",",
            "                    \"loc_mode\",",
            "                    \"lat\",",
            "                    \"lon\",",
            "                    \"map_val\",",
            "                    \"scope\",",
            "                    \"proj\",",
            "                ]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"candlestick-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k in [\"cs_x\", \"cs_open\", \"cs_close\", \"cs_high\", \"cs_low\", \"cs_group\"]",
            "            },",
            "        ),",
            "        build_label_value_store(\"treemap\", inputs),",
            "        build_label_value_store(\"funnel\", inputs),",
            "        build_label_value_store(\"clustergram\", inputs),",
            "        dcc.Store(",
            "            id=\"pareto-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k",
            "                in [",
            "                    \"pareto_x\",",
            "                    \"pareto_bars\",",
            "                    \"pareto_line\",",
            "                    \"pareto_sort\",",
            "                    \"pareto_dir\",",
            "                    \"pareto_group\",",
            "                ]",
            "            },",
            "        ),",
            "        dcc.Store(",
            "            id=\"histogram-input-data\",",
            "            data={",
            "                k: v",
            "                for k, v in inputs.items()",
            "                if k",
            "                in [",
            "                    \"histogram_col\",",
            "                    \"histogram_type\",",
            "                    \"histogram_bins\",",
            "                    \"histogram_group\",",
            "                ]",
            "            },",
            "        ),",
            "        dcc.Store(id=\"range-data\"),",
            "        dcc.Store(id=\"yaxis-data\", data=inputs.get(\"yaxis\")),",
            "        dcc.Store(id=\"last-chart-input-data\", data=inputs),",
            "        dcc.Store(id=\"load-clicks\", data=0),",
            "        dcc.Store(id=\"save-clicks\", data=0),",
            "        dcc.Store(id=\"y-all-clicks\", data=0),",
            "        dcc.Store(id=\"z-all-clicks\", data=0),",
            "        dcc.Input(id=\"chart-code\", type=\"hidden\"),",
            "        html.Div(",
            "            [",
            "                html.Div(",
            "                    dbc.Button(",
            "                        collapse_btn_text(False, text(\"Data Selection\")),",
            "                        id=\"collapse-data-btn\",",
            "                    ),",
            "                    className=\"col-auto pr-0\",",
            "                ),",
            "                html.Div(",
            "                    dbc.Collapse(",
            "                        dbc.Card(",
            "                            dbc.CardBody(",
            "                                [",
            "                                    dcc.Tabs(",
            "                                        id=\"data-tabs\",",
            "                                        value=inputs[\"data_id\"],",
            "                                        children=[",
            "                                            build_tab(",
            "                                                global_state.get_name(k) or k,",
            "                                                str(k),",
            "                                                id=\"data-tab-{}\".format(k),",
            "                                            )",
            "                                            for k in global_state.keys()",
            "                                        ],",
            "                                        style=dict(height=\"36px\"),",
            "                                    )",
            "                                ]",
            "                                + [",
            "                                    dbc.Tooltip(",
            "                                        global_state.get_name(k) or k,",
            "                                        target=\"data-tab-{}\".format(k),",
            "                                    )",
            "                                    for k in global_state.keys()",
            "                                ]",
            "                            )",
            "                        ),",
            "                        id=\"collapse-data\",",
            "                    ),",
            "                    className=\"col\",",
            "                ),",
            "            ],",
            "            className=\"row pb-3 charts-filters\",",
            "            style=dict(display=\"none\" if len(global_state.keys()) < 2 else \"block\"),",
            "        ),",
            "        html.Div(",
            "            html.Div(",
            "                [",
            "                    dcc.Tabs(",
            "                        id=\"chart-tabs\",",
            "                        value=chart_type or \"line\",",
            "                        children=[",
            "                            build_tab(",
            "                                text(t.get(\"label\", t[\"value\"].capitalize())),",
            "                                t[\"value\"],",
            "                                id=\"chart-type-tab-{}\".format(i),",
            "                            )",
            "                            for i, t in enumerate(CHARTS)",
            "                        ],",
            "                        style=dict(height=\"36px\"),",
            "                    )",
            "                ]",
            "                + [",
            "                    dbc.Tooltip(",
            "                        text(t.get(\"label\", t[\"value\"].capitalize())),",
            "                        target=\"chart-type-tab-{}\".format(i),",
            "                    )",
            "                    for i, t in enumerate(CHARTS)",
            "                ],",
            "                className=\"col-md-12\",",
            "            ),",
            "            className=\"row pt-3 pb-3 charts-filters\",",
            "        ),",
            "        (",
            "            html.Div(",
            "                html.Div(",
            "                    [",
            "                        html.Div(",
            "                            [",
            "                                query_label,",
            "                                dcc.Input(",
            "                                    id=\"query-input\",",
            "                                    type=\"text\",",
            "                                    placeholder=query_placeholder,",
            "                                    className=\"form-control\",",
            "                                    value=query_value,",
            "                                    style={\"lineHeight\": \"inherit\"},",
            "                                ),",
            "                            ],",
            "                            className=\"input-group mr-3\",",
            "                        )",
            "                    ],",
            "                    className=\"col\",",
            "                ),",
            "                className=\"row pt-3 pb-3 charts-filters\",",
            "            )",
            "            if global_state.load_flag(inputs[\"data_id\"], \"enable_custom_filters\", False)",
            "            else None",
            "        ),",
            "        html.Div(",
            "            html.Div(",
            "                [",
            "                    html.Div(",
            "                        [",
            "                            build_hoverable(",
            "                                html.Span(text(\"Load\")),",
            "                                load_type_msg(),",
            "                                additional_classes=\"load-types-tooltip mb-auto mt-auto\",",
            "                                top=\"100%\",",
            "                            ),",
            "                            dcc.Dropdown(",
            "                                id=\"load-type-dropdown\",",
            "                                options=[",
            "                                    build_option(v, v.capitalize()) for v in LOAD_TYPES",
            "                                ],",
            "                                className=\"pl-5\",",
            "                                value=load_type or \"random\",",
            "                                clearable=False,",
            "                            ),",
            "                            dcc.Dropdown(",
            "                                id=\"stratified-group-dropdown\",",
            "                                options=stratified_groups,",
            "                                value=stratified_group,",
            "                                clearable=False,",
            "                                style=(",
            "                                    {}",
            "                                    if load_type == \"stratified\"",
            "                                    else {\"display\": \"none\"}",
            "                                ),",
            "                            ),",
            "                            dcc.Slider(",
            "                                id=\"load-input\",",
            "                                min=10,",
            "                                max=100,",
            "                                step=10,",
            "                                value=100 if load is None else load,",
            "                                className=\"w-100\",",
            "                                marks=build_slider_counts(",
            "                                    df, inputs[\"data_id\"], query_value",
            "                                ),",
            "                                tooltip={\"always_visible\": False, \"placement\": \"left\"},",
            "                            ),",
            "                        ],",
            "                        className=\"input-group mr-3\",",
            "                    )",
            "                ],",
            "                className=\"col\",",
            "            ),",
            "            className=\"row pt-3 pb-0 charts-filters\",",
            "        ),",
            "        html.Div(",
            "            [",
            "                html.Div(",
            "                    [",
            "                        dbc.Button(",
            "                            collapse_btn_text(False, text(\"Cleaners\")),",
            "                            id=\"collapse-cleaners-btn\",",
            "                        ),",
            "                        html.Span(",
            "                            \"\",",
            "                            id=\"selected-cleaners\",",
            "                            className=\"pl-3\",",
            "                            style=dict(fontSize=\"85%\"),",
            "                        ),",
            "                    ],",
            "                    className=\"col-auto pr-0\",",
            "                ),",
            "                html.Div(",
            "                    dbc.Collapse(",
            "                        dbc.Card(",
            "                            dbc.CardBody(",
            "                                dcc.Dropdown(",
            "                                    id=\"cleaners-dropdown\",",
            "                                    options=[",
            "                                        build_option(c[\"value\"], c[\"label\"])",
            "                                        for c in get_cleaner_configs()",
            "                                    ],",
            "                                    multi=True,",
            "                                    placeholder=text(\"Select Cleaner(s)\"),",
            "                                    value=group,",
            "                                    style=dict(width=\"inherit\"),",
            "                                )",
            "                            )",
            "                        ),",
            "                        id=\"collapse-cleaners\",",
            "                    ),",
            "                    className=\"col\",",
            "                ),",
            "            ],",
            "            className=\"row pb-3 charts-filters\",",
            "            style=dict(display=\"block\"),",
            "        ),",
            "        html.Div(",
            "            [",
            "                html.Div(",
            "                    [",
            "                        html.Div(",
            "                            [",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"X\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"x-dropdown\",",
            "                                        options=x_options,",
            "                                        placeholder=\"{} (1, 2, ..., N)\".format(",
            "                                            text(\"Default Index\")",
            "                                        ),",
            "                                        value=x,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_style(show_input(\"x\")),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Y\"),",
            "                                    [",
            "                                        dcc.Dropdown(",
            "                                            id=\"y-multi-dropdown\",",
            "                                            options=y_multi_options,",
            "                                            multi=True,",
            "                                            placeholder=text(\"Select Column(s)\"),",
            "                                            style=dict(width=\"inherit\"),",
            "                                            value=(",
            "                                                y if show_input(\"y\", \"multi\") else None",
            "                                            ),",
            "                                        ),",
            "                                        dbc.Button(",
            "                                            html.I(",
            "                                                className=\"fa-solid fa-check-double\"",
            "                                            ),",
            "                                            id=\"y-select-all-btn\",",
            "                                            className=\"ml-3\",",
            "                                            color=\"secondary\",",
            "                                            style=dict(",
            "                                                height=\"24px\",",
            "                                                padding=\".25rem .2rem\",",
            "                                                marginTop=\"auto\",",
            "                                                marginBottom=\"auto\",",
            "                                            ),",
            "                                        ),",
            "                                        dbc.Tooltip(",
            "                                            \"Select All Y\", target=\"y-select-all-btn\"",
            "                                        ),",
            "                                    ],",
            "                                    className=\"col\",",
            "                                    id=\"y-multi-input\",",
            "                                    style=show_style(show_input(\"y\", \"multi\")),",
            "                                ),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Y\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"y-single-dropdown\",",
            "                                        options=y_single_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=(",
            "                                            y[0] if show_input(\"y\") and len(y) else None",
            "                                        ),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    id=\"y-single-input\",",
            "                                    style=show_style(show_input(\"y\")),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Z\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"z-dropdown\",",
            "                                        options=z_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=z,",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"z-input\",",
            "                                    style=show_style(show_input(\"z\")),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Group\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"group-dropdown\",",
            "                                        options=group_options,",
            "                                        multi=True,",
            "                                        placeholder=text(\"Select Group(s)\"),",
            "                                        value=group,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"group-input\",",
            "                                    style=show_style(show_input(\"group\")),",
            "                                ),",
            "                                build_dropna(dropna),",
            "                            ],",
            "                            id=\"standard-inputs\",",
            "                            style=(",
            "                                {}",
            "                                if not show_map",
            "                                and not show_candlestick",
            "                                and chart_type",
            "                                not in [\"treemap\", \"funnel\", \"clustergram\"]",
            "                                else {\"display\": \"none\"}",
            "                            ),",
            "                            className=\"row p-0 charts-filters\",",
            "                        ),",
            "                        html.Div(",
            "                            [",
            "                                build_map_type_tabs(map_type),",
            "                                html.Div(",
            "                                    [",
            "                                        html.Div(",
            "                                            [",
            "                                                build_loc_mode_hover(loc_mode),",
            "                                                dcc.Dropdown(",
            "                                                    id=\"map-loc-mode-dropdown\",",
            "                                                    options=[",
            "                                                        build_option(",
            "                                                            v, loc_modes[v].get(\"label\")",
            "                                                        )",
            "                                                        for v in [",
            "                                                            \"ISO-3\",",
            "                                                            \"USA-states\",",
            "                                                            \"country names\",",
            "                                                            \"geojson-id\",",
            "                                                        ]",
            "                                                    ],",
            "                                                    style=dict(width=\"inherit\"),",
            "                                                    value=loc_mode,",
            "                                                ),",
            "                                            ],",
            "                                            className=\"input-group mr-3\",",
            "                                        )",
            "                                    ],",
            "                                    id=\"map-loc-mode-input\",",
            "                                    style=show_map_style(map_type == \"choropleth\"),",
            "                                    className=\"col-auto\",",
            "                                ),",
            "                                custom_geojson.build_modal(map_type, loc_mode),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Locations\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-loc-dropdown\",",
            "                                        options=loc_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        value=loc,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    id=\"map-loc-input\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_map_style(map_type == \"choropleth\"),",
            "                                ),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Lat\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-lat-dropdown\",",
            "                                        options=lat_options,",
            "                                        placeholder=\"Select a column\",",
            "                                        value=lat,",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    id=\"map-lat-input\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_map_style(",
            "                                        map_type in [\"scattergeo\", \"mapbox\"]",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    [",
            "                                        html.Div(text(\"Lon\")),",
            "                                        html.Small(\"({})\".format(text(\"Agg By\"))),",
            "                                    ],",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-lon-dropdown\",",
            "                                        options=lon_options,",
            "                                        placeholder=\"Select a column\",",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=lon,",
            "                                    ),",
            "                                    id=\"map-lon-input\",",
            "                                    label_class=\"input-group-addon d-block pt-1 pb-0\",",
            "                                    style=show_map_style(",
            "                                        map_type in [\"scattergeo\", \"mapbox\"]",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Scope\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-scope-dropdown\",",
            "                                        options=[build_option(v) for v in SCOPES],",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=map_scope or \"world\",",
            "                                    ),",
            "                                    id=\"map-scope-input\",",
            "                                    style=show_map_style(map_type == \"scattergeo\"),",
            "                                ),",
            "                                html.Div(",
            "                                    [",
            "                                        html.Div(",
            "                                            [",
            "                                                build_mapbox_token_hover(),",
            "                                                dcc.Dropdown(",
            "                                                    id=\"map-mapbox-style-dropdown\",",
            "                                                    options=build_mapbox_style_options(),",
            "                                                    style=dict(width=\"inherit\"),",
            "                                                    value=mapbox_style",
            "                                                    or \"open-street-map\",",
            "                                                ),",
            "                                            ],",
            "                                            className=\"input-group mr-3\",",
            "                                        )",
            "                                    ],",
            "                                    id=\"map-mapbox-style-input\",",
            "                                    className=\"col-auto\",",
            "                                    style=show_map_style(map_type == \"mapbox\"),",
            "                                ),",
            "                                html.Div(",
            "                                    [",
            "                                        html.Div(",
            "                                            [",
            "                                                build_proj_hover(proj),",
            "                                                dcc.Dropdown(",
            "                                                    id=\"map-proj-dropdown\",",
            "                                                    options=[",
            "                                                        build_option(v)",
            "                                                        for v in PROJECTIONS",
            "                                                    ],",
            "                                                    style=dict(width=\"inherit\"),",
            "                                                    value=proj,",
            "                                                ),",
            "                                            ],",
            "                                            className=\"input-group mr-3\",",
            "                                        )",
            "                                    ],",
            "                                    id=\"map-proj-input\",",
            "                                    style=show_map_style(map_type == \"scattergeo\"),",
            "                                    className=\"col-auto\",",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Value\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-val-dropdown\",",
            "                                        options=map_val_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=map_val,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Group\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"map-group-dropdown\",",
            "                                        options=group_options,",
            "                                        multi=True,",
            "                                        placeholder=text(\"Select Group(s)\"),",
            "                                        value=inputs.get(\"map_group\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"map-group-input\",",
            "                                ),",
            "                                build_dropna(inputs.get(\"map_dropna\", True), \"map\"),",
            "                            ],",
            "                            id=\"map-inputs\",",
            "                            className=\"row charts-filters\",",
            "                            style={} if show_map else {\"display\": \"none\"},",
            "                        ),",
            "                        html.Div(",
            "                            [",
            "                                build_input(",
            "                                    text(\"X\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-x-dropdown\",",
            "                                        options=cs_x_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_x,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Open\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-open-dropdown\",",
            "                                        options=open_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_open,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"High\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-high-dropdown\",",
            "                                        options=high_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_high,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Low\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-low-dropdown\",",
            "                                        options=low_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_low,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Close\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-close-dropdown\",",
            "                                        options=close_options,",
            "                                        placeholder=text(\"Select Column\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                        value=cs_close,",
            "                                    ),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Group\"),",
            "                                    dcc.Dropdown(",
            "                                        id=\"candlestick-group-dropdown\",",
            "                                        options=group_options,",
            "                                        multi=True,",
            "                                        placeholder=text(\"Select Group(s)\"),",
            "                                        value=inputs.get(\"cs_group\"),",
            "                                        style=dict(width=\"inherit\"),",
            "                                    ),",
            "                                    className=\"col\",",
            "                                    id=\"candlestick-group-input\",",
            "                                ),",
            "                                build_dropna(",
            "                                    inputs.get(\"cs_dropna\", True), \"candlestick\"",
            "                                ),",
            "                            ],",
            "                            id=\"candlestick-inputs\",",
            "                            className=\"row charts-filters\",",
            "                            style={} if show_candlestick else {\"display\": \"none\"},",
            "                        ),",
            "                        build_label_value_inputs(\"treemap\", inputs, df, group_options),",
            "                        build_funnel_inputs(inputs, df, group_options),",
            "                        build_label_value_inputs(",
            "                            \"clustergram\",",
            "                            inputs,",
            "                            df,",
            "                            group_options,",
            "                            multi_value=True,",
            "                            all_option=True,",
            "                        ),",
            "                        build_pareto_inputs(inputs, df, group_options),",
            "                        build_histogram_inputs(inputs, df, group_options),",
            "                        html.Div(",
            "                            [",
            "                                html.Div(",
            "                                    [",
            "                                        build_input(",
            "                                            text(\"Aggregation\"),",
            "                                            dcc.Dropdown(",
            "                                                id=\"agg-dropdown\",",
            "                                                options=[",
            "                                                    build_option(v, text(AGGS[v]))",
            "                                                    for v in [",
            "                                                        \"count\",",
            "                                                        \"pctct\",",
            "                                                        \"nunique\",",
            "                                                        \"sum\",",
            "                                                        \"mean\",",
            "                                                        \"rolling\",",
            "                                                        \"corr\",",
            "                                                        \"first\",",
            "                                                        \"last\",",
            "                                                        \"drop_duplicates\",",
            "                                                        \"median\",",
            "                                                        \"min\",",
            "                                                        \"max\",",
            "                                                        \"std\",",
            "                                                        \"var\",",
            "                                                        \"mad\",",
            "                                                        \"prod\",",
            "                                                        \"pctsum\",",
            "                                                    ]",
            "                                                ],",
            "                                                placeholder=text(\"No Aggregation\"),",
            "                                                style=dict(width=\"inherit\"),",
            "                                                value=agg or \"raw\",",
            "                                                disabled=len(",
            "                                                    inputs.get(",
            "                                                        \"extended_aggregation\", []",
            "                                                    )",
            "                                                )",
            "                                                > 0,",
            "                                            ),",
            "                                        ),",
            "                                        html.Span(",
            "                                            \"* {}\".format(",
            "                                                text(",
            "                                                    \"Extended Aggregation is currently populated.\"",
            "                                                )",
            "                                            ),",
            "                                            id=\"ext-agg-warning\",",
            "                                            style=show_style(",
            "                                                len(",
            "                                                    inputs.get(",
            "                                                        \"extended_aggreation\", []",
            "                                                    )",
            "                                                )",
            "                                                > 0",
            "                                            ),",
            "                                            className=\"ext-agg-warning\",",
            "                                        ),",
            "                                    ]",
            "                                )",
            "                            ]",
            "                            + extended_aggregations.build_modal(",
            "                                inputs.get(\"extended_aggregation\", []), chart_type, y",
            "                            )",
            "                            + [",
            "                                html.Div(",
            "                                    [",
            "                                        build_input(",
            "                                            text(\"Window\"),",
            "                                            dcc.Input(",
            "                                                id=\"window-input\",",
            "                                                type=\"number\",",
            "                                                placeholder=text(\"Enter Days\"),",
            "                                                className=\"form-control text-center\",",
            "                                                style={\"lineHeight\": \"inherit\"},",
            "                                                value=inputs.get(\"window\"),",
            "                                            ),",
            "                                        ),",
            "                                        build_input(",
            "                                            text(\"Computation\"),",
            "                                            dcc.Dropdown(",
            "                                                id=\"rolling-comp-dropdown\",",
            "                                                options=[",
            "                                                    build_option(",
            "                                                        \"corr\", text(\"Correlation\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"count\", text(\"Count\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"cov\", text(\"Covariance\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"kurt\", text(\"Kurtosis\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"max\", text(\"Maximum\")",
            "                                                    ),",
            "                                                    build_option(\"mean\", text(\"Mean\")),",
            "                                                    build_option(",
            "                                                        \"median\", text(\"Median\")",
            "                                                    ),",
            "                                                    build_option(",
            "                                                        \"min\", text(\"Minimum\")",
            "                                                    ),",
            "                                                    build_option(\"skew\", text(\"Skew\")),",
            "                                                    build_option(",
            "                                                        \"std\",",
            "                                                        text(\"Standard Deviation\"),",
            "                                                    ),",
            "                                                    build_option(\"sum\", text(\"Sum\")),",
            "                                                    build_option(",
            "                                                        \"var\", text(\"Variance\")",
            "                                                    ),",
            "                                                ],",
            "                                                placeholder=text(\"Select Computation\"),",
            "                                                style=dict(width=\"inherit\"),",
            "                                                value=inputs.get(\"rolling_comp\"),",
            "                                            ),",
            "                                        ),",
            "                                    ],",
            "                                    id=\"rolling-inputs\",",
            "                                    style=show_style(agg == \"rolling\"),",
            "                                ),",
            "                                build_input(",
            "                                    text(\"Drilldowns\"),",
            "                                    html.Div(",
            "                                        daq.BooleanSwitch(",
            "                                            id=\"drilldown-toggle\", on=False",
            "                                        ),",
            "                                        className=\"toggle-wrapper\",",
            "                                    ),",
            "                                    id=\"drilldown-input\",",
            "                                    style=show_style((agg or \"raw\") != \"raw\"),",
            "                                    className=\"col-auto\",",
            "                                ),",
            "                            ],",
            "                            className=\"row pt-3 pb-3 charts-filters\",",
            "                            id=\"charts-filters-div\",",
            "                            style=(",
            "                                {\"display\": \"none\"} if chart_type == \"histogram\" else {}",
            "                            ),",
            "                        ),",
            "                    ],",
            "                    id=\"main-inputs\",",
            "                    className=main_input_class,",
            "                ),",
            "                html.Div(",
            "                    [",
            "                        html.Div(",
            "                            html.Div(",
            "                                html.Div(",
            "                                    [",
            "                                        html.Span(",
            "                                            text(\"Group Type\"),",
            "                                            className=\"input-group-addon\",",
            "                                        ),",
            "                                        html.Div(",
            "                                            dcc.Tabs(",
            "                                                id=\"group-type\",",
            "                                                value=inputs.get(\"group_type\")",
            "                                                or \"groups\",",
            "                                                children=[",
            "                                                    build_tab(",
            "                                                        text(\"Values\"),",
            "                                                        \"groups\",",
            "                                                        {",
            "                                                            \"padding\": \"2px\",",
            "                                                            \"minWidth\": \"4em\",",
            "                                                        },",
            "                                                    ),",
            "                                                    build_tab(",
            "                                                        text(\"Bins\"),",
            "                                                        \"bins\",",
            "                                                        {",
            "                                                            \"padding\": \"2px\",",
            "                                                            \"minWidth\": \"4em\",",
            "                                                        },",
            "                                                    ),",
            "                                                ],",
            "                                            ),",
            "                                            id=\"group-type-div\",",
            "                                            className=\"form-control col-auto pt-3\",",
            "                                        ),",
            "                                    ],",
            "                                    className=\"input-group\",",
            "                                ),",
            "                                className=\"addon-min-width\",",
            "                            ),",
            "                            className=\"col-md-12 p-0 pb-5\",",
            "                            id=\"group-type-input\",",
            "                            style=group_type_style,",
            "                        ),",
            "                        build_input(",
            "                            text(\"Group(s)\"),",
            "                            dcc.Dropdown(",
            "                                id=\"group-val-dropdown\",",
            "                                multi=True,",
            "                                placeholder=text(\"Select Group Value(s)\"),",
            "                                value=group_val,",
            "                                style=dict(width=\"inherit\"),",
            "                            ),",
            "                            className=\"col-md-12 p-0 pb-5\",",
            "                            id=\"group-val-input\",",
            "                            style=group_val_style,",
            "                        ),",
            "                        build_input(",
            "                            text(\"Bins\"),",
            "                            [",
            "                                daq.NumericInput(",
            "                                    id=\"bins-val-input\",",
            "                                    min=1,",
            "                                    max=30,",
            "                                    value=inputs.get(\"bins_val\") or 5,",
            "                                ),",
            "                                html.Div(",
            "                                    html.Div(",
            "                                        [",
            "                                            html.Span(",
            "                                                text(\"Binning\"),",
            "                                                className=\"input-group-addon\",",
            "                                            ),",
            "                                            html.Div(",
            "                                                build_hoverable(",
            "                                                    dcc.Tabs(",
            "                                                        id=\"bin-type\",",
            "                                                        value=inputs.get(\"bin_type\")",
            "                                                        or \"width\",",
            "                                                        children=[",
            "                                                            build_tab(",
            "                                                                text(\"Width\"),",
            "                                                                \"width\",",
            "                                                                {",
            "                                                                    \"padding\": \"2px\",",
            "                                                                    \"minWidth\": \"4em\",",
            "                                                                },",
            "                                                            ),",
            "                                                            build_tab(",
            "                                                                text(\"Freq\"),",
            "                                                                \"freq\",",
            "                                                                {",
            "                                                                    \"padding\": \"2px\",",
            "                                                                    \"minWidth\": \"4em\",",
            "                                                                },",
            "                                                            ),",
            "                                                        ],",
            "                                                    ),",
            "                                                    bin_type_msg(),",
            "                                                    \"\",",
            "                                                    top=\"120%\",",
            "                                                ),",
            "                                                id=\"bin-type-div\",",
            "                                                className=\"form-control col-auto pt-3\",",
            "                                            ),",
            "                                        ],",
            "                                        className=\"input-group\",",
            "                                    ),",
            "                                    className=\"col-auto addon-min-width\",",
            "                                    id=\"bin-type-input\",",
            "                                ),",
            "                            ],",
            "                            className=\"col-md-12 p-0\",",
            "                            id=\"bins-input\",",
            "                            style=bins_style,",
            "                        ),",
            "                    ],",
            "                    id=\"group-inputs-row\",",
            "                    className=\"col-md-4 row pt-3 pb-5\",",
            "                    style=show_groups,",
            "                ),",
            "            ],",
            "            className=\"row\",",
            "        ),",
            "        html.Div(",
            "            [",
            "                build_input(",
            "                    text(\"Chart Per\\nGroup\"),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"cpg-toggle\", on=inputs.get(\"cpg\") or False",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"cpg-input\",",
            "                    style=show_style(show_cpg),",
            "                    className=\"col-auto\",",
            "                ),",
            "                build_input(",
            "                    text(\"Chart Per\\nY\"),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"cpy-toggle\", on=inputs.get(\"cpy\") or False",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"cpy-input\",",
            "                    style=show_style(show_cpy),",
            "                    className=\"col-auto\",",
            "                ),",
            "                build_input(",
            "                    text(\"Trendline\"),",
            "                    dcc.Dropdown(",
            "                        id=\"trendline-dropdown\",",
            "                        options=[build_option(\"ols\"), build_option(\"lowess\")],",
            "                        value=inputs.get(\"trendline\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=scatter_input,",
            "                    id=\"trendline-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Barmode\"),",
            "                    dcc.Dropdown(",
            "                        id=\"barmode-dropdown\",",
            "                        options=[",
            "                            build_option(\"group\", text(\"Group\")),",
            "                            build_option(\"stack\", text(\"Stack\")),",
            "                            build_option(\"relative\", text(\"Relative\")),",
            "                        ],",
            "                        value=inputs.get(\"barmode\") or \"group\",",
            "                        placeholder=text(\"Select Mode\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=bar_style,",
            "                    id=\"barmode-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Barsort\"),",
            "                    dcc.Dropdown(",
            "                        id=\"barsort-dropdown\",",
            "                        options=barsort_options,",
            "                        value=inputs.get(\"barsort\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=barsort_input_style,",
            "                    id=\"barsort-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Top\"),",
            "                    dcc.Dropdown(",
            "                        id=\"top-bars\",",
            "                        options=[build_option(v) for v in [5, 10, 20, 50]],",
            "                        value=inputs.get(\"top_bars\"),",
            "                        placeholder=None,",
            "                    ),",
            "                    className=\"col-auto\",",
            "                    style=barsort_input_style,",
            "                    id=\"top-bars-input\",",
            "                ),",
            "                html.Div(",
            "                    html.Div(",
            "                        [",
            "                            html.Span(text(\"Y-Axis\"), className=\"input-group-addon\"),",
            "                            html.Div(",
            "                                [",
            "                                    dcc.Tabs(",
            "                                        id=\"yaxis-scale\",",
            "                                        value=inputs.get(\"scale\") or \"linear\",",
            "                                        children=get_yaxis_scale_tabs(),",
            "                                        className=\"pr-5\",",
            "                                    ),",
            "                                    dcc.Tabs(",
            "                                        id=\"yaxis-type\",",
            "                                        value=yaxis_type,",
            "                                        children=get_yaxis_type_tabs(y),",
            "                                    ),",
            "                                ],",
            "                                id=\"yaxis-type-div\",",
            "                                className=\"form-control col-auto pt-3\",",
            "                                style=yaxis_type_style,",
            "                            ),",
            "                            dcc.Dropdown(id=\"yaxis-dropdown\", options=yaxis_options),",
            "                            html.Span(",
            "                                \"{}:\".format(text(\"Min\")),",
            "                                className=\"input-group-addon col-auto\",",
            "                                id=\"yaxis-min-label\",",
            "                            ),",
            "                            dcc.Input(",
            "                                id=\"yaxis-min-input\",",
            "                                type=\"number\",",
            "                                className=\"form-control col-auto\",",
            "                                style={\"lineHeight\": \"inherit\"},",
            "                            ),",
            "                            html.Span(",
            "                                \"{}:\".format(text(\"Max\")),",
            "                                className=\"input-group-addon col-auto\",",
            "                                id=\"yaxis-max-label\",",
            "                            ),",
            "                            dcc.Input(",
            "                                id=\"yaxis-max-input\",",
            "                                type=\"number\",",
            "                                className=\"form-control col-auto\",",
            "                                style={\"lineHeight\": \"inherit\"},",
            "                            ),",
            "                        ],",
            "                        className=\"input-group\",",
            "                        id=\"yaxis-min-max-options\",",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    id=\"yaxis-input\",",
            "                    style=show_style(show_yaxis),",
            "                ),",
            "                build_input(",
            "                    text(\"Colorscale\"),",
            "                    dcs.DashColorscales(",
            "                        id=\"colorscale-picker\",",
            "                        colorscale=inputs.get(\"colorscale\") or default_cscale,",
            "                    ),",
            "                    className=\"col-auto addon-min-width pr-0\",",
            "                    style=cscale_style,",
            "                    id=\"colorscale-input\",",
            "                ),",
            "                build_input(",
            "                    text(\"Animate\"),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"animate-toggle\", on=inputs.get(\"animate\") or False",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"animate-input\",",
            "                    style=animate_style,",
            "                    className=\"col-auto\",",
            "                ),",
            "                build_input(",
            "                    text(\"Animate By\"),",
            "                    dcc.Dropdown(",
            "                        id=\"animate-by-dropdown\",",
            "                        options=animate_opts,",
            "                        value=inputs.get(\"animate_by\"),",
            "                    ),",
            "                    className=\"col-auto addon-min-width\",",
            "                    style=animate_by_style,",
            "                    id=\"animate-by-input\",",
            "                ),",
            "                dbc.Button(",
            "                    text(\"Lock Zoom\"),",
            "                    id=\"lock-zoom-btn\",",
            "                    className=\"ml-auto\",",
            "                    style=lock_zoom_style(chart_type),",
            "                ),",
            "                build_input(",
            "                    build_hoverable(",
            "                        html.Div(text(\"Auto-Load\"), style=dict(color=\"white\")),",
            "                        auto_load_msg(),",
            "                        \"\",",
            "                        top=\"120%\",",
            "                    ),",
            "                    html.Div(",
            "                        daq.BooleanSwitch(",
            "                            id=\"auto-load-toggle\", on=True, color=\"green\"",
            "                        ),",
            "                        className=\"toggle-wrapper\",",
            "                    ),",
            "                    id=\"auto-load-input\",",
            "                    className=\"ml-auto col-auto\",",
            "                ),",
            "                dbc.Button(",
            "                    text(\"Load\"),",
            "                    id=\"load-btn\",",
            "                    color=\"primary\",",
            "                    style=dict(display=\"none\"),",
            "                ),",
            "                build_hoverable(",
            "                    dbc.Button(",
            "                        text(\"Save\"),",
            "                        id=\"save-btn\",",
            "                        color=\"primary\",",
            "                        style=dict(display=\"none\"),",
            "                    ),",
            "                    text(\"save_msg\"),",
            "                    \"\",",
            "                    top=\"120%\",",
            "                ),",
            "                build_hoverable(",
            "                    html.A(",
            "                        html.I(className=\"fas fa-file-code fa-xl\"),",
            "                        id=\"export-all-chart-btn\",",
            "                        href=\"\",",
            "                        className=\"export-chart-btn\",",
            "                        style=dict(display=\"none\"),",
            "                    ),",
            "                    \"Export Charts\",",
            "                    additional_classes=\"mt-auto mb-auto\",",
            "                    hover_class=\"export-charts\",",
            "                ),",
            "            ],",
            "            className=\"row pt-3 pb-5 charts-filters\",",
            "            id=\"chart-inputs\",",
            "        ),",
            "        dcc.Loading(",
            "            html.Div(id=\"chart-content\", style={\"height\": \"calc(100vh - 380px\"}),",
            "            type=\"circle\",",
            "        ),",
            "        dcc.Textarea(id=\"copy-text\", style=dict(position=\"absolute\", left=\"-110%\")),",
            "    ]",
            "    if settings.get(\"github_fork\", False):",
            "        body_items.append(",
            "            html.Span(",
            "                html.A(",
            "                    text(\"Fork me on Github\"), href=\"https://github.com/man-group/dtale\"",
            "                ),",
            "                id=\"forkongithub\",",
            "            )",
            "        )",
            "    return body_items"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1712": [
                "charts_layout"
            ],
            "1714": [
                "charts_layout"
            ],
            "1715": [
                "charts_layout"
            ],
            "1716": [
                "charts_layout"
            ],
            "1717": [
                "charts_layout"
            ],
            "1718": [
                "charts_layout"
            ],
            "1719": [
                "charts_layout"
            ],
            "1720": [
                "charts_layout"
            ],
            "1721": [
                "charts_layout"
            ],
            "1722": [
                "charts_layout"
            ],
            "1723": [
                "charts_layout"
            ],
            "1724": [
                "charts_layout"
            ],
            "1725": [
                "charts_layout"
            ],
            "1726": [
                "charts_layout"
            ],
            "1727": [
                "charts_layout"
            ],
            "1728": [
                "charts_layout"
            ],
            "1729": [
                "charts_layout"
            ],
            "1730": [
                "charts_layout"
            ],
            "1731": [
                "charts_layout"
            ],
            "1732": [
                "charts_layout"
            ]
        },
        "addLocation": []
    },
    "dtale/views.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 3380,
                "afterPatchRowNumber": 3380,
                "PatchRowcode": "         max: maxY,"
            },
            "1": {
                "beforePatchRowNumber": 3381,
                "afterPatchRowNumber": 3381,
                "PatchRowcode": "     } or {error: 'Exception message', traceback: 'Exception stacktrace'}"
            },
            "2": {
                "beforePatchRowNumber": 3382,
                "afterPatchRowNumber": 3382,
                "PatchRowcode": "     \"\"\""
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3383,
                "PatchRowcode": "+    custom_query = None"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3384,
                "PatchRowcode": "+    if global_state.load_flag(data_id, \"enable_custom_filters\", False):"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3385,
                "PatchRowcode": "+        custom_query = get_str_arg(request, \"query\")"
            },
            "6": {
                "beforePatchRowNumber": 3383,
                "afterPatchRowNumber": 3386,
                "PatchRowcode": "     data = run_query("
            },
            "7": {
                "beforePatchRowNumber": 3384,
                "afterPatchRowNumber": 3387,
                "PatchRowcode": "         handle_predefined(data_id),"
            },
            "8": {
                "beforePatchRowNumber": 3385,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        build_query(data_id, get_str_arg(request, \"query\")),"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 3388,
                "PatchRowcode": "+        build_query(data_id, custom_query),"
            },
            "10": {
                "beforePatchRowNumber": 3386,
                "afterPatchRowNumber": 3389,
                "PatchRowcode": "         global_state.get_context_variables(data_id),"
            },
            "11": {
                "beforePatchRowNumber": 3387,
                "afterPatchRowNumber": 3390,
                "PatchRowcode": "     )"
            },
            "12": {
                "beforePatchRowNumber": 3388,
                "afterPatchRowNumber": 3391,
                "PatchRowcode": "     x = get_str_arg(request, \"x\")"
            }
        },
        "frontPatchFile": [
            "# coding=utf-8",
            "from __future__ import absolute_import, division",
            "",
            "import os",
            "import time",
            "from builtins import map, range, str, zip",
            "from collections import namedtuple",
            "from functools import wraps",
            "from logging import getLogger",
            "",
            "from flask import (",
            "    current_app,",
            "    json,",
            "    make_response,",
            "    redirect,",
            "    render_template,",
            "    request,",
            "    Response,",
            ")",
            "",
            "import itertools",
            "import missingno as msno",
            "import networkx as nx",
            "import numpy as np",
            "import pandas as pd",
            "import platform",
            "import requests",
            "import scipy.stats as sts",
            "import seaborn as sns",
            "import xarray as xr",
            "from six import BytesIO, PY3, string_types, StringIO",
            "",
            "import dtale.correlations as correlations",
            "import dtale.datasets as datasets",
            "import dtale.env_util as env_util",
            "import dtale.gage_rnr as gage_rnr",
            "import dtale.global_state as global_state",
            "import dtale.pandas_util as pandas_util",
            "import dtale.predefined_filters as predefined_filters",
            "from dtale import dtale",
            "from dtale.charts.utils import build_base_chart, CHART_POINTS_LIMIT",
            "from dtale.cli.clickutils import retrieve_meta_info_and_version",
            "from dtale.column_analysis import ColumnAnalysis",
            "from dtale.column_builders import ColumnBuilder, printable",
            "from dtale.column_filters import ColumnFilter",
            "from dtale.column_replacements import ColumnReplacement",
            "from dtale.combine_data import CombineData",
            "from dtale.describe import load_describe",
            "from dtale.duplicate_checks import DuplicateCheck",
            "from dtale.dash_application.charts import (",
            "    build_raw_chart,",
            "    chart_url_params,",
            "    chart_url_querystring,",
            "    export_chart,",
            "    export_png,",
            "    export_chart_data,",
            "    url_encode_func,",
            ")",
            "from dtale.data_reshapers import DataReshaper",
            "from dtale.code_export import build_code_export",
            "from dtale.query import (",
            "    build_col_key,",
            "    build_query,",
            "    build_query_builder,",
            "    handle_predefined,",
            "    load_filterable_data,",
            "    load_index_filter,",
            "    run_query,",
            ")",
            "from dtale.timeseries_analysis import TimeseriesAnalysis",
            "from dtale.utils import (",
            "    DuplicateDataError,",
            "    apply,",
            "    build_formatters,",
            "    build_shutdown_url,",
            "    build_url,",
            "    classify_type,",
            "    coord_type,",
            "    dict_merge,",
            "    divide_chunks,",
            "    export_to_csv_buffer,",
            "    find_dtype,",
            "    find_dtype_formatter,",
            "    format_data,",
            "    format_grid,",
            "    get_bool_arg,",
            "    get_dtypes,",
            "    get_int_arg,",
            "    get_json_arg,",
            "    get_str_arg,",
            "    get_url_quote,",
            "    grid_columns,",
            "    grid_formatter,",
            "    json_date,",
            "    json_float,",
            "    json_int,",
            "    json_timestamp,",
            "    jsonify,",
            "    jsonify_error,",
            "    read_file,",
            "    make_list,",
            "    optimize_df,",
            "    option,",
            "    retrieve_grid_params,",
            "    running_with_flask_debug,",
            "    running_with_pytest,",
            "    sort_df_for_grid,",
            "    unique_count,",
            ")",
            "from dtale.translations import text",
            "",
            "logger = getLogger(__name__)",
            "IDX_COL = str(\"dtale_index\")",
            "",
            "",
            "def exception_decorator(func):",
            "    @wraps(func)",
            "    def _handle_exceptions(*args, **kwargs):",
            "        try:",
            "            return func(*args, **kwargs)",
            "        except BaseException as e:",
            "            return jsonify_error(e)",
            "",
            "    return _handle_exceptions",
            "",
            "",
            "def matplotlib_decorator(func):",
            "    @wraps(func)",
            "    def _handle_matplotlib(*args, **kwargs):",
            "        try:",
            "            import matplotlib",
            "",
            "            current_backend = matplotlib.get_backend()",
            "",
            "            matplotlib.use(\"agg\")  # noqa: E261",
            "",
            "            import matplotlib.pyplot as plt",
            "",
            "            plt.rcParams[\"font.sans-serif\"] = [",
            "                \"SimHei\"",
            "            ]  # Or any other Chinese characters",
            "            matplotlib.rcParams[\"font.family\"] = [\"Heiti TC\"]",
            "",
            "            return func(*args, **kwargs)",
            "        except BaseException as e:",
            "            raise e",
            "        finally:",
            "            try:",
            "                matplotlib.pyplot.switch_backend(current_backend)",
            "            except BaseException:",
            "                pass",
            "",
            "    return _handle_matplotlib",
            "",
            "",
            "class NoDataLoadedException(Exception):",
            "    \"\"\"Container class for any scenario where no data has been loaded into D-Tale.",
            "",
            "    This will usually force the user to load data using the CSV/TSV loader UI.",
            "    \"\"\"",
            "",
            "",
            "def head_endpoint(popup_type=None):",
            "    data_keys = global_state.keys()",
            "    if not len(data_keys):",
            "        return \"popup/{}\".format(\"arcticdb\" if global_state.is_arcticdb else \"upload\")",
            "    head_id = sorted(data_keys)[0]",
            "    head_id = get_url_quote()(get_url_quote()(head_id, safe=\"\"))",
            "    if popup_type:",
            "        return \"popup/{}/{}\".format(popup_type, head_id)",
            "    return \"main/{}\".format(head_id)",
            "",
            "",
            "def in_ipython_frontend():",
            "    \"\"\"",
            "    Helper function which is variation of :meth:`pandas:pandas.io.formats.console.in_ipython_frontend` which",
            "    checks to see if we are inside an IPython zmq frontend",
            "",
            "    :return: `True` if D-Tale is being invoked within ipython notebook, `False` otherwise",
            "    \"\"\"",
            "    try:",
            "        from IPython import get_ipython",
            "",
            "        ip = get_ipython()",
            "        return \"zmq\" in str(type(ip)).lower()",
            "    except BaseException:",
            "        pass",
            "    return False",
            "",
            "",
            "def kill(base):",
            "    \"\"\"",
            "    This function fires a request to this instance's 'shutdown' route to kill it",
            "",
            "    \"\"\"",
            "    try:",
            "        requests.get(build_shutdown_url(base))",
            "    except BaseException:",
            "        logger.info(\"Shutdown complete\")",
            "",
            "",
            "def is_up(base):",
            "    \"\"\"",
            "    This function checks to see if instance's :mod:`flask:flask.Flask` process is up by hitting 'health' route.",
            "",
            "    Using `verify=False` will allow us to validate instances being served up over SSL",
            "",
            "    :return: `True` if :mod:`flask:flask.Flask` process is up and running, `False` otherwise",
            "    \"\"\"",
            "    try:",
            "        return requests.get(\"{}/health\".format(base), verify=False, timeout=10).ok",
            "    except BaseException:",
            "        return False",
            "",
            "",
            "class DtaleData(object):",
            "    \"\"\"",
            "    Wrapper class to abstract the global state of a D-Tale process while allowing",
            "    a user to programatically interact with a running D-Tale instance",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param url: endpoint for instances :class:`flask:flask.Flask` process",
            "    :type url: str",
            "",
            "    Attributes:",
            "        _data_id            data identifier",
            "        _url                :class:`flask:flask.Flask` endpoint",
            "        _notebook_handle    reference to the most recent :class:`ipython:IPython.display.DisplayHandle` created",
            "",
            "    :Example:",
            "",
            "        >>> import dtale",
            "        >>> import pandas as pd",
            "        >>> df = pd.DataFrame([dict(a=1,b=2,c=3)])",
            "        >>> d = dtale.show(df)",
            "        >>> tmp = d.data.copy()",
            "        >>> tmp['d'] = 4",
            "        >>> d.data = tmp",
            "        >>> d.kill()",
            "    \"\"\"",
            "",
            "    def __init__(self, data_id, url, is_proxy=False, app_root=None):",
            "        self._data_id = data_id",
            "        self._url = url",
            "        self._notebook_handle = None",
            "        self.started_with_open_browser = False",
            "        self.is_proxy = is_proxy",
            "        self.app_root = app_root",
            "",
            "    def build_main_url(self, name=None):",
            "        data_keys = global_state.keys()",
            "        if (name or self._data_id) and len(data_keys):",
            "            quoted_data_id = get_url_quote()(",
            "                get_url_quote()(name or self._data_id, safe=\"\")",
            "            )",
            "            return \"{}/dtale/main/{}\".format(",
            "                self.app_root if self.is_proxy else self._url, quoted_data_id",
            "            )",
            "        return (",
            "            self.app_root if self.is_proxy else self._url",
            "        )  # \"load data\" or \"library/symbol selection\" screens",
            "",
            "    @property",
            "    def _main_url(self):",
            "        data_keys = global_state.keys()",
            "        if not len(data_keys):",
            "            return self.build_main_url()",
            "        suffix = self._data_id",
            "        name = global_state.get_name(suffix)",
            "        if name:",
            "            suffix = global_state.convert_name_to_url_path(name)",
            "        return self.build_main_url(name=suffix)",
            "",
            "    @property",
            "    def data(self):",
            "        \"\"\"",
            "        Property which is a reference to the globally stored data associated with this instance",
            "",
            "        \"\"\"",
            "        return global_state.get_data(self._data_id)",
            "",
            "    @property",
            "    def view_data(self):",
            "        \"\"\"",
            "        Property which returns the data associated with this instance as well as any sorting or filtering applied",
            "        from the UI",
            "",
            "        \"\"\"",
            "        req = namedtuple(\"req\", \"args\")",
            "        return load_filterable_data(self._data_id, req(dict(filtered=\"true\")))",
            "",
            "    @data.setter",
            "    def data(self, data):",
            "        \"\"\"",
            "        Setter which will go through all standard formatting to make sure changes will be handled correctly by D-Tale",
            "",
            "        \"\"\"",
            "        startup(self._url, data=data, data_id=self._data_id)",
            "",
            "    def get_corr_matrix(self, encode_strings=False, as_df=False):",
            "        \"\"\"Helper function to build correlation matrix from data (can be an image or dataframe).\"\"\"",
            "        matrix_data = build_correlations_matrix(",
            "            self._data_id, is_pps=False, encode_strings=encode_strings, image=not as_df",
            "        )",
            "        _, _, _, _, _, _, df_or_image = matrix_data",
            "        return df_or_image",
            "",
            "    def get_pps_matrix(self, encode_strings=False, as_df=False):",
            "        \"\"\"Helper function to build correlation matrix from data (can be an image or dataframe).\"\"\"",
            "        matrix_data = build_correlations_matrix(",
            "            self._data_id, is_pps=True, encode_strings=encode_strings, image=not as_df",
            "        )",
            "        _, _, _, _, _, _, df_or_image = matrix_data",
            "        return df_or_image",
            "",
            "    def update_id(self, new_data_id):",
            "        \"\"\"",
            "        Update current data_id to new data_id",
            "",
            "        :param new_data_id: the data_id to update to",
            "        \"\"\"",
            "        self._data_id = global_state.update_id(self._data_id, new_data_id)",
            "",
            "    def main_url(self):",
            "        \"\"\"",
            "        Helper function creating main :class:`flask:flask.Flask` route using instance's url & data_id",
            "        :return: str",
            "        \"\"\"",
            "        if in_ipython_frontend():",
            "            print(self._main_url)",
            "            return None",
            "        return self._main_url",
            "",
            "    def kill(self):",
            "        \"\"\"Helper function to pass instance's endpoint to :meth:`dtale.views.kill`\"\"\"",
            "        kill_url = self._url",
            "        if in_ipython_frontend() and not kill_url.startswith(\"http\"):",
            "            from dtale.app import ACTIVE_PORT, ACTIVE_HOST",
            "",
            "            kill_url = build_url(ACTIVE_PORT, ACTIVE_HOST)",
            "        kill(kill_url)",
            "",
            "    def cleanup(self):",
            "        \"\"\"Helper function to clean up data associated with this instance from global state.\"\"\"",
            "        global_state.cleanup(self._data_id)",
            "",
            "    def update_settings(self, **updates):",
            "        \"\"\"",
            "        Helper function for updating instance-specific settings. For example:",
            "        * allow_cell_edits - whether cells can be edited",
            "        * locked - which columns are locked to the left of the grid",
            "        * sort - The sort to apply to the data on startup (EX: [(\"col1\", \"ASC\"), (\"col2\", \"DESC\"),...])",
            "        * custom_formats - display formatting for specific columns",
            "        * background_mode - different background displays in grid",
            "        * range_highlights - specify background colors for ranges of values in the grid",
            "        * vertical_headers - if True, then rotate column headers vertically",
            "        * column_edit_options - the options to allow on the front-end when editing a cell for the columns specified",
            "        * highlight_filter - if True, then highlight rows on the frontend which will be filtered when applying a filter",
            "                             rather than hiding them from the dataframe",
            "        * hide_shutdown - if true, this will hide the \"Shutdown\" button from users",
            "        * nan_display - if value in dataframe is :attr:`numpy:numpy.nan` then return this value on the frontend",
            "        * hide_header_editor - if true, this will hide header editor when editing cells on the frontend",
            "        * lock_header_menu - if true, this will always the display the header menu which usually only displays when you",
            "                             hover over the top",
            "        * hide_header_menu - if true, this will hide the header menu from the screen",
            "        * hide_main_menu - if true, this will hide the main menu from the screen",
            "        * hide_column_menus - if true, this will hide the column menus from the screen",
            "        * enable_custom_filters - if True, allow users to specify custom filters from the UI using pandas.query strings",
            "        * enable_web_uploads - if True, allow users to upload files using URLs from the UI",
            "",
            "        After applying please refresh any open browsers!",
            "        \"\"\"",
            "        name_updates = dict(",
            "            range_highlights=\"rangeHighlight\",",
            "            column_formats=\"columnFormats\",",
            "            background_mode=\"backgroundMode\",",
            "            vertical_headers=\"verticalHeaders\",",
            "            highlight_filter=\"highlightFilter\",",
            "        )",
            "        settings = {name_updates.get(k, k): v for k, v in updates.items()}",
            "        global_state.update_settings(self._data_id, settings)",
            "",
            "    def get_settings(self):",
            "        \"\"\"Helper function for retrieving any instance-specific settings.\"\"\"",
            "        return global_state.get_settings(self._data_id) or {}",
            "",
            "    def open_browser(self):",
            "        \"\"\"",
            "        This function uses the :mod:`python:webbrowser` library to try and automatically open server's default browser",
            "        to this D-Tale instance",
            "        \"\"\"",
            "        env_util.open_browser(self._main_url)",
            "",
            "    def is_up(self):",
            "        \"\"\"",
            "        Helper function to pass instance's endpoint to :meth:`dtale.views.is_up`",
            "        \"\"\"",
            "        return is_up(self._url)",
            "",
            "    def __str__(self):",
            "        \"\"\"",
            "        Will try to create an :class:`ipython:IPython.display.IFrame` if being invoked from within ipython notebook",
            "        otherwise simply returns the output of running :meth:`pandas:pandas.DataFrame.__str__` on the data associated",
            "        with this instance",
            "",
            "        \"\"\"",
            "        if in_ipython_frontend():",
            "            if self.started_with_open_browser:",
            "                self.started_with_open_browser = False",
            "                return \"\"",
            "            self.notebook()",
            "            return \"\"",
            "",
            "        if global_state.is_arcticdb and global_state.store.get(self._data_id).is_large:",
            "            return self.main_url()",
            "",
            "        return self.data.__str__()",
            "",
            "    def __repr__(self):",
            "        \"\"\"",
            "        Will try to create an :class:`ipython:IPython.display.IFrame` if being invoked from within ipython notebook",
            "        otherwise simply returns the output of running :meth:`pandas:pandas.DataFrame.__repr__` on the data for",
            "        this instance",
            "",
            "        \"\"\"",
            "        if in_ipython_frontend():",
            "            if self.started_with_open_browser:",
            "                self.started_with_open_browser = False",
            "                return \"\"",
            "            self.notebook()",
            "            if self._notebook_handle is not None:",
            "                return \"\"",
            "        return self.main_url()",
            "",
            "    def _build_iframe(",
            "        self, route=\"/dtale/iframe/\", params=None, width=\"100%\", height=475",
            "    ):",
            "        \"\"\"",
            "        Helper function to build an :class:`ipython:IPython.display.IFrame` if that module exists within",
            "        your environment",
            "",
            "        :param route: the :class:`flask:flask.Flask` route to hit on D-Tale",
            "        :type route: str, optional",
            "        :param params: properties & values passed as query parameters to the route",
            "        :type params: dict, optional",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        :return: :class:`ipython:IPython.display.IFrame`",
            "        \"\"\"",
            "        try:",
            "            from IPython.display import IFrame",
            "        except ImportError:",
            "            logger.info(\"in order to use this function, please install IPython\")",
            "            return None",
            "        iframe_url = \"{}{}{}\".format(",
            "            self.app_root if self.is_proxy else self._url, route, self._data_id",
            "        )",
            "        if params is not None:",
            "            if isinstance(params, string_types):  # has this already been encoded?",
            "                iframe_url = \"{}?{}\".format(iframe_url, params)",
            "            else:",
            "                iframe_url = \"{}?{}\".format(iframe_url, url_encode_func()(params))",
            "",
            "        return IFrame(iframe_url, width=width, height=height)",
            "",
            "    def notebook(self, route=\"/dtale/iframe/\", params=None, width=\"100%\", height=475):",
            "        \"\"\"",
            "        Helper function which checks to see if :mod:`flask:flask.Flask` process is up and running and then tries to",
            "        build an :class:`ipython:IPython.display.IFrame` and run :meth:`ipython:IPython.display.display` on it so",
            "        it will be displayed in the ipython notebook which invoked it.",
            "",
            "        A reference to the :class:`ipython:IPython.display.DisplayHandle` is stored in _notebook_handle for",
            "        updating if you are running ipython>=5.0",
            "",
            "        :param route: the :class:`flask:flask.Flask` route to hit on D-Tale",
            "        :type route: str, optional",
            "        :param params: properties & values passed as query parameters to the route",
            "        :type params: dict, optional",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        \"\"\"",
            "        try:",
            "            from IPython.display import display",
            "        except ImportError:",
            "            logger.info(\"in order to use this function, please install IPython\")",
            "            return self.data.__repr__()",
            "",
            "        retries = 0",
            "        while not self.is_up() and retries < 10:",
            "            time.sleep(0.01)",
            "            retries += 1",
            "",
            "        self._notebook_handle = display(",
            "            self._build_iframe(route=route, params=params, width=width, height=height),",
            "            display_id=True,",
            "        )",
            "        if self._notebook_handle is None:",
            "            self._notebook_handle = True",
            "",
            "    def notebook_correlations(self, col1, col2, width=\"100%\", height=475):",
            "        \"\"\"",
            "        Helper function to build an `ipython:IPython.display.IFrame` pointing at the correlations popup",
            "",
            "        :param col1: column on left side of correlation",
            "        :type col1: str",
            "        :param col2: column on right side of correlation",
            "        :type col2: str",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        :return: :class:`ipython:IPython.display.IFrame`",
            "        \"\"\"",
            "        self.notebook(",
            "            \"/dtale/popup/correlations/\",",
            "            params=dict(col1=col1, col2=col2),",
            "            width=width,",
            "            height=height,",
            "        )",
            "",
            "    def notebook_charts(",
            "        self,",
            "        chart_type=\"line\",",
            "        query=None,",
            "        x=None,",
            "        y=None,",
            "        z=None,",
            "        group=None,",
            "        agg=None,",
            "        window=None,",
            "        rolling_comp=None,",
            "        barmode=None,",
            "        barsort=None,",
            "        width=\"100%\",",
            "        height=800,",
            "    ):",
            "        \"\"\"",
            "        Helper function to build an `ipython:IPython.display.IFrame` pointing at the charts popup",
            "",
            "        :param chart_type: type of chart, possible options are line|bar|pie|scatter|3d_scatter|surface|heatmap",
            "        :type chart_type: str",
            "        :param query: pandas dataframe query string",
            "        :type query: str, optional",
            "        :param x: column to use for the X-Axis",
            "        :type x: str",
            "        :param y: columns to use for the Y-Axes",
            "        :type y: list of str",
            "        :param z: column to use for the Z-Axis",
            "        :type z: str, optional",
            "        :param group: column(s) to use for grouping",
            "        :type group: list of str or str, optional",
            "        :param agg: specific aggregation that can be applied to y or z axes.  Possible values are: count, first, last,",
            "                    mean, median, min, max, std, var, mad, prod, sum.  This is included in label of axis it is being",
            "                    applied to.",
            "        :type agg: str, optional",
            "        :param window: number of days to include in rolling aggregations",
            "        :type window: int, optional",
            "        :param rolling_comp: computation to use in rolling aggregations",
            "        :type rolling_comp: str, optional",
            "        :param barmode: mode to use for bar chart display. possible values are stack|group(default)|overlay|relative",
            "        :type barmode: str, optional",
            "        :param barsort: axis name to sort the bars in a bar chart by (default is the 'x', but other options are any of",
            "                        columns names used in the 'y' parameter",
            "        :type barsort: str, optional",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        :return: :class:`ipython:IPython.display.IFrame`",
            "        \"\"\"",
            "        params = dict(",
            "            chart_type=chart_type,",
            "            query=query,",
            "            x=x,",
            "            y=make_list(y),",
            "            z=z,",
            "            group=make_list(group),",
            "            agg=agg,",
            "            window=window,",
            "            rolling_comp=rolling_comp,",
            "            barmode=barmode,",
            "            barsort=barsort,",
            "        )",
            "        self.notebook(",
            "            route=\"/dtale/charts/\",",
            "            params=chart_url_querystring(params),",
            "            width=width,",
            "            height=height,",
            "        )",
            "",
            "    def offline_chart(",
            "        self,",
            "        return_object=False,",
            "        chart_type=None,",
            "        query=None,",
            "        x=None,",
            "        y=None,",
            "        z=None,",
            "        group=None,",
            "        agg=None,",
            "        window=None,",
            "        rolling_comp=None,",
            "        barmode=None,",
            "        barsort=None,",
            "        yaxis=None,",
            "        filepath=None,",
            "        title=None,",
            "        # fmt: off",
            "        **kwargs",
            "        # fmt: on",
            "    ):",
            "        \"\"\"",
            "        Builds the HTML for a plotly chart figure to saved to a file or output to a jupyter notebook",
            "",
            "        :param return_object: if True, return the plotly graph object for this chart",
            "        :type return_object: bool",
            "        :param chart_type: type of chart, possible options are line|bar|pie|scatter|3d_scatter|surface|heatmap",
            "        :type chart_type: str",
            "        :param query: pandas dataframe query string",
            "        :type query: str, optional",
            "        :param x: column to use for the X-Axis",
            "        :type x: str",
            "        :param y: columns to use for the Y-Axes",
            "        :type y: list of str",
            "        :param z: column to use for the Z-Axis",
            "        :type z: str, optional",
            "        :param group: column(s) to use for grouping",
            "        :type group: list of str or str, optional",
            "        :param agg: specific aggregation that can be applied to y or z axes.  Possible values are: count, first, last,",
            "                    mean, median, min, max, std, var, mad, prod, sum.  This is included in label of axis it is being",
            "                    applied to.",
            "        :type agg: str, optional",
            "        :param window: number of days to include in rolling aggregations",
            "        :type window: int, optional",
            "        :param rolling_comp: computation to use in rolling aggregations",
            "        :type rolling_comp: str, optional",
            "        :param barmode: mode to use for bar chart display. possible values are stack|group(default)|overlay|relative",
            "        :type barmode: str, optional",
            "        :param barsort: axis name to sort the bars in a bar chart by (default is the 'x', but other options are any of",
            "                        columns names used in the 'y' parameter",
            "        :type barsort: str, optional",
            "        :param yaxis: dictionary specifying the min/max for each y-axis in your chart",
            "        :type yaxis: dict, optional",
            "        :param filepath: location to save HTML output",
            "        :type filepath: str, optional",
            "        :param title: Title of your chart",
            "        :type title: str, optional",
            "        :param kwargs: optional keyword arguments, here in case invalid arguments are passed to this function",
            "        :type kwargs: dict",
            "        :return: possible outcomes are:",
            "                 - if run within a jupyter notebook and no 'filepath' is specified it will print the resulting HTML",
            "                   within a cell in your notebook",
            "                 - if 'filepath' is specified it will save the chart to the path specified",
            "                 - otherwise it will return the HTML output as a string",
            "        \"\"\"",
            "        params = dict(",
            "            return_object=return_object,",
            "            chart_type=chart_type,",
            "            query=query,",
            "            x=x,",
            "            y=make_list(y),",
            "            z=z,",
            "            group=make_list(group),",
            "            agg=agg,",
            "            window=window,",
            "            rolling_comp=rolling_comp,",
            "            barmode=barmode,",
            "            barsort=barsort,",
            "            yaxis=yaxis,",
            "            title=title,",
            "        )",
            "        params = dict_merge(params, kwargs)",
            "",
            "        if filepath is None and in_ipython_frontend():",
            "            from plotly.offline import iplot, init_notebook_mode",
            "",
            "            init_notebook_mode(connected=True)",
            "            chart = build_raw_chart(self._data_id, export=True, **params)",
            "            chart.pop(",
            "                \"id\", None",
            "            )  # for some reason iplot does not like when the 'id' property is populated",
            "            iplot(chart)",
            "            return",
            "",
            "        if return_object:",
            "            return build_raw_chart(self._data_id, export=True, **params)",
            "",
            "        html_str = export_chart(self._data_id, params)",
            "        if filepath is None:",
            "            return html_str",
            "",
            "        if not filepath.endswith(\".html\"):",
            "            filepath = \"{}.html\".format(filepath)",
            "",
            "        with open(filepath, \"w\") as f:",
            "            f.write(html_str)",
            "",
            "    def adjust_cell_dimensions(self, width=\"100%\", height=350):",
            "        \"\"\"",
            "        If you are running ipython>=5.0 then this will update the most recent notebook cell you displayed D-Tale in",
            "        for this instance with the height/width properties you have passed in as input",
            "",
            "        :param width: width of the ipython cell",
            "        :param height: height of the ipython cell",
            "        \"\"\"",
            "        if self._notebook_handle is not None and hasattr(",
            "            self._notebook_handle, \"update\"",
            "        ):",
            "            self._notebook_handle.update(self._build_iframe(width=width, height=height))",
            "        else:",
            "            logger.debug(\"You must ipython>=5.0 installed to use this functionality\")",
            "",
            "",
            "def dtype_formatter(data, dtypes, data_ranges, prev_dtypes=None):",
            "    \"\"\"",
            "    Helper function to build formatter for the descriptive information about each column in the dataframe you",
            "    are viewing in D-Tale.  This data is later returned to the browser to help with controlling inputs to functions",
            "    which are heavily tied to specific data types.",
            "",
            "    :param data: dataframe",
            "    :type data: :class:`pandas:pandas.DataFrame`",
            "    :param dtypes: column data type",
            "    :type dtypes: dict",
            "    :param data_ranges: dictionary containing minimum and maximum value for column (if applicable)",
            "    :type data_ranges: dict, optional",
            "    :param prev_dtypes: previous column information for syncing updates to pre-existing columns",
            "    :type prev_dtypes: dict, optional",
            "    :return: formatter function which takes column indexes and names",
            "    :rtype: func",
            "    \"\"\"",
            "",
            "    def _formatter(col_index, col):",
            "        visible = True",
            "        dtype = dtypes.get(col)",
            "        if prev_dtypes and col in prev_dtypes:",
            "            visible = prev_dtypes[col].get(\"visible\", True)",
            "        s = data[col]",
            "        dtype_data = dict(",
            "            name=col,",
            "            dtype=dtype,",
            "            index=col_index,",
            "            visible=visible,",
            "            hasOutliers=0,",
            "            hasMissing=1,",
            "        )",
            "        if global_state.is_arcticdb:",
            "            return dtype_data",
            "",
            "        dtype_data[\"unique_ct\"] = unique_count(s)",
            "        dtype_data[\"hasMissing\"] = int(s.isnull().sum())",
            "        classification = classify_type(dtype)",
            "        if (",
            "            classification in [\"F\", \"I\"] and not s.isnull().all() and col in data_ranges",
            "        ):  # floats/ints",
            "            col_ranges = data_ranges[col]",
            "            if not any((np.isnan(v) or np.isinf(v) for v in col_ranges.values())):",
            "                dtype_data = dict_merge(col_ranges, dtype_data)",
            "",
            "            # load outlier information",
            "            o_s, o_e = calc_outlier_range(s)",
            "            if not any((np.isnan(v) or np.isinf(v) for v in [o_s, o_e])):",
            "                dtype_data[\"hasOutliers\"] += int(((s < o_s) | (s > o_e)).sum())",
            "                dtype_data[\"outlierRange\"] = dict(lower=o_s, upper=o_e)",
            "            skew_val = pandas_util.run_function(s, \"skew\")",
            "            if skew_val is not None:",
            "                dtype_data[\"skew\"] = json_float(skew_val)",
            "            kurt_val = pandas_util.run_function(s, \"kurt\")",
            "            if kurt_val is not None:",
            "                dtype_data[\"kurt\"] = json_float(kurt_val)",
            "",
            "        if classification in [\"F\", \"I\"] and not s.isnull().all():",
            "            # build variance flag",
            "            unique_ct = dtype_data[\"unique_ct\"]",
            "            check1 = (unique_ct / len(data[col])) < 0.1",
            "            check2 = False",
            "            if check1 and unique_ct >= 2:",
            "                val_counts = s.value_counts()",
            "                check2 = (val_counts.values[0] / val_counts.values[1]) > 20",
            "            dtype_data[\"lowVariance\"] = bool(check1 and check2)",
            "            dtype_data[\"coord\"] = coord_type(s)",
            "",
            "        if classification in [\"D\"] and not s.isnull().all():",
            "            timestamps = apply(s, lambda x: json_timestamp(x, np.nan))",
            "            skew_val = pandas_util.run_function(timestamps, \"skew\")",
            "            if skew_val is not None:",
            "                dtype_data[\"skew\"] = json_float(skew_val)",
            "            kurt_val = pandas_util.run_function(timestamps, \"kurt\")",
            "            if kurt_val is not None:",
            "                dtype_data[\"kurt\"] = json_float(kurt_val)",
            "",
            "        if classification == \"S\" and not dtype_data[\"hasMissing\"]:",
            "            if (",
            "                dtype.startswith(\"category\")",
            "                and classify_type(s.dtype.categories.dtype.name) == \"S\"",
            "            ):",
            "                dtype_data[\"hasMissing\"] += int(",
            "                    (apply(s, lambda x: str(x).strip()) == \"\").sum()",
            "                )",
            "            else:",
            "                dtype_data[\"hasMissing\"] += int(",
            "                    (s.astype(\"str\").str.strip() == \"\").sum()",
            "                )",
            "",
            "        return dtype_data",
            "",
            "    return _formatter",
            "",
            "",
            "def calc_data_ranges(data, dtypes={}):",
            "    try:",
            "        return data.agg([\"min\", \"max\"]).to_dict()",
            "    except ValueError:",
            "        # I've seen when transposing data and data types get combined into one column this exception emerges",
            "        # when calling 'agg' on the new data",
            "        return {}",
            "    except TypeError:",
            "        non_str_cols = [",
            "            c for c in data.columns if classify_type(dtypes.get(c, \"\")) != \"S\"",
            "        ]",
            "        if not len(non_str_cols):",
            "            return {}",
            "        try:",
            "            return data[non_str_cols].agg([\"min\", \"max\"]).to_dict()",
            "        except BaseException:",
            "            return {}",
            "",
            "",
            "def build_dtypes_state(data, prev_state=None, ranges=None):",
            "    \"\"\"",
            "    Helper function to build globally managed state pertaining to a D-Tale instances columns & data types",
            "",
            "    :param data: dataframe to build data type information for",
            "    :type data: :class:`pandas:pandas.DataFrame`",
            "    :return: a list of dictionaries containing column names, indexes and data types",
            "    \"\"\"",
            "    prev_dtypes = {c[\"name\"]: c for c in prev_state or []}",
            "    dtypes = get_dtypes(data)",
            "    loaded_ranges = ranges or calc_data_ranges(data, dtypes)",
            "    dtype_f = dtype_formatter(data, dtypes, loaded_ranges, prev_dtypes)",
            "    return [dtype_f(i, c) for i, c in enumerate(data.columns)]",
            "",
            "",
            "def check_duplicate_data(data):",
            "    \"\"\"",
            "    This function will do a rough check to see if a user has already loaded this piece of data to D-Tale to avoid",
            "    duplicated state.  The checks that take place are:",
            "     - shape (# of rows & # of columns",
            "     - column names and ordering of columns (eventually might add dtype checking as well...)",
            "",
            "    :param data: dataframe to validate",
            "    :type data: :class:`pandas:pandas.DataFrame`",
            "    :raises :class:`dtale.utils.DuplicateDataError`: if duplicate data exists",
            "    \"\"\"",
            "    cols = [str(col) for col in data.columns]",
            "",
            "    for d_id, datainst in global_state.items():",
            "        d_cols = [str(col) for col in datainst.data.columns]",
            "        if datainst.data.shape == data.shape and cols == d_cols:",
            "            raise DuplicateDataError(d_id)",
            "",
            "",
            "def convert_xarray_to_dataset(dataset, **indexers):",
            "    def _convert_zero_dim_dataset(dataset):",
            "        ds_dict = dataset.to_dict()",
            "        data = {}",
            "        for coord, coord_data in ds_dict[\"coords\"].items():",
            "            data[coord] = coord_data[\"data\"]",
            "        for col, col_data in ds_dict[\"data_vars\"].items():",
            "            data[col] = col_data[\"data\"]",
            "        return pd.DataFrame([data]).set_index(list(ds_dict[\"coords\"].keys()))",
            "",
            "    ds_sel = dataset.sel(**indexers)",
            "    try:",
            "        df = ds_sel.to_dataframe()",
            "        df = df.reset_index().drop(\"index\", axis=1, errors=\"ignore\")",
            "        return df.set_index(list(dataset.dims.keys()))",
            "    except ValueError:",
            "        return _convert_zero_dim_dataset(ds_sel)",
            "",
            "",
            "def handle_koalas(data):",
            "    \"\"\"",
            "    Helper function to check if koalas is installed and also if incoming data is a koalas dataframe, if so convert it",
            "    to :class:`pandas:pandas.DataFrame`, otherwise simply return the original data structure.",
            "",
            "    :param data: data we want to check if its a koalas dataframe and if so convert to :class:`pandas:pandas.DataFrame`",
            "    :return: :class:`pandas:pandas.DataFrame`",
            "    \"\"\"",
            "    if is_koalas(data):",
            "        return data.to_pandas()",
            "    return data",
            "",
            "",
            "def is_koalas(data):",
            "    try:",
            "        from databricks.koalas import frame",
            "",
            "        return isinstance(data, frame.DataFrame)",
            "    except BaseException:",
            "        return False",
            "",
            "",
            "def startup(",
            "    url=\"\",",
            "    data=None,",
            "    data_loader=None,",
            "    name=None,",
            "    data_id=None,",
            "    context_vars=None,",
            "    ignore_duplicate=True,",
            "    allow_cell_edits=True,",
            "    inplace=False,",
            "    drop_index=False,",
            "    precision=2,",
            "    show_columns=None,",
            "    hide_columns=None,",
            "    optimize_dataframe=False,",
            "    column_formats=None,",
            "    nan_display=None,",
            "    sort=None,",
            "    locked=None,",
            "    background_mode=None,",
            "    range_highlights=None,",
            "    app_root=None,",
            "    is_proxy=None,",
            "    vertical_headers=False,",
            "    hide_shutdown=None,",
            "    column_edit_options=None,",
            "    auto_hide_empty_columns=False,",
            "    highlight_filter=False,",
            "    hide_header_editor=None,",
            "    lock_header_menu=None,",
            "    hide_header_menu=None,",
            "    hide_main_menu=None,",
            "    hide_column_menus=None,",
            "    enable_custom_filters=None,",
            "    enable_web_uploads=None,",
            "    force_save=True,",
            "    main_title=None,",
            "    main_title_font=None,",
            "):",
            "    \"\"\"",
            "    Loads and stores data globally",
            "     - If data has indexes then it will lock save those columns as locked on the front-end",
            "     - If data has column named index it will be dropped so that it won't collide with row numbering (dtale_index)",
            "     - Create location in memory for storing settings which can be manipulated from the front-end (sorts, filter, ...)",
            "",
            "    :param url: the base URL that D-Tale is running from to be referenced in redirects to shutdown",
            "    :param data: :class:`pandas:pandas.DataFrame` or :class:`pandas:pandas.Series`",
            "    :param data_loader: function which returns :class:`pandas:pandas.DataFrame`",
            "    :param name: string label to apply to your session",
            "    :param data_id: integer id assigned to a piece of data viewable in D-Tale, if this is populated then it will",
            "                    override the data at that id",
            "    :param context_vars: a dictionary of the variables that will be available for use in user-defined expressions,",
            "                         such as filters",
            "    :type context_vars: dict, optional",
            "    :param ignore_duplicate: if set to True this will not test whether this data matches any previously loaded to D-Tale",
            "    :param allow_cell_edits: If false, this will not allow users to edit cells directly in their D-Tale grid",
            "    :type allow_cell_edits: bool, optional",
            "    :param inplace: If true, this will call `reset_index(inplace=True)` on the dataframe used as a way to save memory.",
            "                    Otherwise this will create a brand new dataframe, thus doubling memory but leaving the dataframe",
            "                    input unchanged.",
            "    :type inplace: bool, optional",
            "    :param drop_index: If true, this will drop any pre-existing index on the dataframe input.",
            "    :type drop_index: bool, optional",
            "    :param precision: The default precision to display for float data in D-Tale grid",
            "    :type precision: int, optional",
            "    :param show_columns: Columns to show on load, hide all others",
            "    :type show_columns: list, optional",
            "    :param hide_columns: Columns to hide on load",
            "    :type hide_columns: list, optional",
            "    :param optimize_dataframe: this will convert string columns with less certain then a certain number of distinct",
            "                              values into categories",
            "    :type optimize_dataframe: boolean",
            "    :param column_formats: The formatting to apply to certain columns on the front-end",
            "    :type column_formats: dict, optional",
            "    :param sort: The sort to apply to the data on startup (EX: [(\"col1\", \"ASC\"), (\"col2\", \"DESC\"),...])",
            "    :type sort: list[tuple], optional",
            "    :param locked: Columns to lock to the left of your grid on load",
            "    :type locked: list, optional",
            "    :param background_mode: Different background highlighting modes available on the frontend. Possible values are:",
            "                            - heatmap-all: turn on heatmap for all numeric columns where the colors are determined by",
            "                                           the range of values over all numeric columns combined",
            "                            - heatmap-col: turn on heatmap for all numeric columns where the colors are determined by",
            "                                           the range of values in the column",
            "                            - heatmap-col-[column name]: turn on heatmap highlighting for a specific column",
            "                            - dtypes: highlight columns based on it's data type",
            "                            - missing: highlight any missing values (np.nan, empty strings, strings of all spaces)",
            "                            - outliers: highlight any outliers",
            "                            - range: highlight values for any matchers entered in the \"range_highlights\" option",
            "                            - lowVariance: highlight values with a low variance",
            "    :type background_mode: string, optional",
            "    :param range_highlights: Definitions for equals, less-than or greater-than ranges for individual (or all) columns",
            "                             which apply different background colors to cells which fall in those ranges.",
            "    :type range_highlights: dict, optional",
            "    :param vertical_headers: if True, then rotate column headers vertically",
            "    :type vertical_headers: boolean, optional",
            "    :param column_edit_options: The options to allow on the front-end when editing a cell for the columns specified",
            "    :type column_edit_options: dict, optional",
            "    :param auto_hide_empty_columns: if True, then auto-hide any columns on the front-end that are comprised entirely of",
            "                                    NaN values",
            "    :type auto_hide_empty_columns: boolean, optional",
            "    :param highlight_filter: if True, then highlight rows on the frontend which will be filtered when applying a filter",
            "                             rather than hiding them from the dataframe",
            "    :type highlight_filter: boolean, optional",
            "    \"\"\"",
            "",
            "    if (",
            "        data_loader is None and data is None",
            "    ):  # scenario where we'll force users to upload a CSV/TSV",
            "        return DtaleData(\"1\", url, is_proxy=is_proxy, app_root=app_root)",
            "",
            "    if data_loader is not None:",
            "        data = data_loader()",
            "        if isinstance(data, string_types) and global_state.contains(data):",
            "            return DtaleData(data, url, is_proxy=is_proxy, app_root=app_root)",
            "        elif (",
            "            data is None and global_state.is_arcticdb",
            "        ):  # send user to the library/symbol selection screen",
            "            return DtaleData(None, url, is_proxy=is_proxy, app_root=app_root)",
            "",
            "    if global_state.is_arcticdb and isinstance(data, string_types):",
            "        data_id = data",
            "        data_id_segs = data_id.split(\"|\")",
            "        if len(data_id_segs) < 2:",
            "            if not global_state.store.lib:",
            "                raise ValueError(",
            "                    (",
            "                        \"When specifying a data identifier for ArcticDB it must be comprised of a library and a symbol.\"",
            "                        \"Use the following format: [library]|[symbol]\"",
            "                    )",
            "                )",
            "            data_id = \"{}|{}\".format(global_state.store.lib.name, data_id)",
            "        global_state.new_data_inst(data_id)",
            "        instance = global_state.store.get(data_id)",
            "        data = instance.base_df",
            "        ret_data = startup(",
            "            url=url,",
            "            data=data,",
            "            data_id=data_id,",
            "            force_save=False,",
            "            name=name,",
            "            context_vars=context_vars,",
            "            ignore_duplicate=ignore_duplicate,",
            "            allow_cell_edits=allow_cell_edits,",
            "            precision=precision,",
            "            show_columns=show_columns,",
            "            hide_columns=hide_columns,",
            "            column_formats=column_formats,",
            "            nan_display=nan_display,",
            "            sort=sort,",
            "            locked=locked,",
            "            background_mode=background_mode,",
            "            range_highlights=range_highlights,",
            "            app_root=app_root,",
            "            is_proxy=is_proxy,",
            "            vertical_headers=vertical_headers,",
            "            hide_shutdown=hide_shutdown,",
            "            column_edit_options=column_edit_options,",
            "            auto_hide_empty_columns=auto_hide_empty_columns,",
            "            highlight_filter=highlight_filter,",
            "            hide_header_editor=hide_header_editor,",
            "            lock_header_menu=lock_header_menu,",
            "            hide_header_menu=hide_header_menu,",
            "            hide_main_menu=hide_main_menu,",
            "            hide_column_menus=hide_column_menus,",
            "            enable_custom_filters=enable_custom_filters,",
            "            enable_web_uploads=enable_web_uploads,",
            "            main_title=main_title,",
            "            main_title_font=main_title_font,",
            "        )",
            "        startup_code = (",
            "            \"from arcticdb import Arctic\\n\"",
            "            \"from arcticdb.version_store._store import VersionedItem\\n\\n\"",
            "            \"conn = Arctic('{uri}')\\n\"",
            "            \"lib = conn.get_library('{library}')\\n\"",
            "            \"df = lib.read('{symbol}')\\n\"",
            "            \"if isinstance(data, VersionedItem):\\n\"",
            "            \"\\tdf = df.data\\n\"",
            "        ).format(",
            "            uri=global_state.store.uri,",
            "            library=global_state.store.lib.name,",
            "            symbol=data_id,",
            "        )",
            "        curr_settings = global_state.get_settings(data_id)",
            "        global_state.set_settings(",
            "            data_id, dict_merge(curr_settings, dict(startup_code=startup_code))",
            "        )",
            "        return ret_data",
            "",
            "    if data is not None:",
            "        data = handle_koalas(data)",
            "        valid_types = (",
            "            pd.DataFrame,",
            "            pd.Series,",
            "            pd.DatetimeIndex,",
            "            pd.MultiIndex,",
            "            xr.Dataset,",
            "            np.ndarray,",
            "            list,",
            "            dict,",
            "        )",
            "        if not isinstance(data, valid_types):",
            "            raise Exception(",
            "                (",
            "                    \"data loaded must be one of the following types: pandas.DataFrame, pandas.Series, \"",
            "                    \"pandas.DatetimeIndex, pandas.MultiIndex, xarray.Dataset, numpy.array, numpy.ndarray, list, dict\"",
            "                )",
            "            )",
            "",
            "        if isinstance(data, xr.Dataset):",
            "            df = convert_xarray_to_dataset(data)",
            "            instance = startup(",
            "                url,",
            "                df,",
            "                name=name,",
            "                data_id=data_id,",
            "                context_vars=context_vars,",
            "                ignore_duplicate=ignore_duplicate,",
            "                allow_cell_edits=allow_cell_edits,",
            "                precision=precision,",
            "                show_columns=show_columns,",
            "                hide_columns=hide_columns,",
            "                column_formats=column_formats,",
            "                nan_display=nan_display,",
            "                sort=sort,",
            "                locked=locked,",
            "                background_mode=background_mode,",
            "                range_highlights=range_highlights,",
            "                app_root=app_root,",
            "                is_proxy=is_proxy,",
            "                vertical_headers=vertical_headers,",
            "                hide_shutdown=hide_shutdown,",
            "                column_edit_options=column_edit_options,",
            "                auto_hide_empty_columns=auto_hide_empty_columns,",
            "                highlight_filter=highlight_filter,",
            "                hide_header_editor=hide_header_editor,",
            "                lock_header_menu=lock_header_menu,",
            "                hide_header_menu=hide_header_menu,",
            "                hide_main_menu=hide_main_menu,",
            "                hide_column_menus=hide_column_menus,",
            "                enable_custom_filters=enable_custom_filters,",
            "                enable_web_uploads=enable_web_uploads,",
            "                main_title=main_title,",
            "                main_title_font=main_title_font,",
            "            )",
            "",
            "            global_state.set_dataset(instance._data_id, data)",
            "            global_state.set_dataset_dim(instance._data_id, {})",
            "            return instance",
            "",
            "        data, curr_index = format_data(data, inplace=inplace, drop_index=drop_index)",
            "        # check to see if this dataframe has already been loaded to D-Tale",
            "        if data_id is None and not ignore_duplicate and not global_state.is_arcticdb:",
            "            check_duplicate_data(data)",
            "",
            "        logger.debug(",
            "            \"pytest: {}, flask-debug: {}\".format(",
            "                running_with_pytest(), running_with_flask_debug()",
            "            )",
            "        )",
            "",
            "        if data_id is None:",
            "            data_id = global_state.new_data_inst()",
            "        if global_state.get_settings(data_id) is not None:",
            "            curr_settings = global_state.get_settings(data_id)",
            "            curr_locked = curr_settings.get(\"locked\", [])",
            "            # filter out previous locked columns that don't exist",
            "            curr_locked = [c for c in curr_locked if c in data.columns]",
            "            # add any new columns in index",
            "            curr_locked += [c for c in curr_index if c not in curr_locked]",
            "        else:",
            "            logger.debug(",
            "                \"pre-locking index columns ({}) to settings[{}]\".format(",
            "                    curr_index, data_id",
            "                )",
            "            )",
            "            curr_locked = locked or curr_index",
            "            global_state.set_metadata(data_id, dict(start=pd.Timestamp(\"now\")))",
            "        global_state.set_name(data_id, name)",
            "        # in the case that data has been updated we will drop any sorts or filter for ease of use",
            "        base_settings = dict(",
            "            indexes=curr_index,",
            "            locked=curr_locked,",
            "            allow_cell_edits=True if allow_cell_edits is None else allow_cell_edits,",
            "            precision=precision,",
            "            columnFormats=column_formats or {},",
            "            backgroundMode=background_mode,",
            "            rangeHighlight=range_highlights,",
            "            verticalHeaders=vertical_headers,",
            "            highlightFilter=highlight_filter,",
            "        )",
            "        base_predefined = predefined_filters.init_filters()",
            "        if base_predefined:",
            "            base_settings[\"predefinedFilters\"] = base_predefined",
            "        if sort:",
            "            base_settings[\"sortInfo\"] = sort",
            "            data = sort_df_for_grid(data, dict(sort=sort))",
            "        if nan_display is not None:",
            "            base_settings[\"nanDisplay\"] = nan_display",
            "        if hide_shutdown is not None:",
            "            base_settings[\"hide_shutdown\"] = hide_shutdown",
            "        if hide_header_editor is not None:",
            "            base_settings[\"hide_header_editor\"] = hide_header_editor",
            "        if lock_header_menu is not None:",
            "            base_settings[\"lock_header_menu\"] = lock_header_menu",
            "        if hide_header_menu is not None:",
            "            base_settings[\"hide_header_menu\"] = hide_header_menu",
            "        if hide_main_menu is not None:",
            "            base_settings[\"hide_main_menu\"] = hide_main_menu",
            "        if hide_column_menus is not None:",
            "            base_settings[\"hide_column_menus\"] = hide_column_menus",
            "        if enable_custom_filters is not None:",
            "            base_settings[\"enable_custom_filters\"] = enable_custom_filters",
            "        if enable_web_uploads is not None:",
            "            base_settings[\"enable_web_uploads\"] = enable_web_uploads",
            "        if column_edit_options is not None:",
            "            base_settings[\"column_edit_options\"] = column_edit_options",
            "        if main_title is not None:",
            "            base_settings[\"main_title\"] = main_title",
            "        if main_title_font is not None:",
            "            base_settings[\"main_title_font\"] = main_title_font",
            "        global_state.set_settings(data_id, base_settings)",
            "        if optimize_dataframe and not global_state.is_arcticdb:",
            "            data = optimize_df(data)",
            "        if force_save or (",
            "            global_state.is_arcticdb and not global_state.contains(data_id)",
            "        ):",
            "            data = data[curr_locked + [c for c in data.columns if c not in curr_locked]]",
            "            global_state.set_data(data_id, data)",
            "        dtypes_data = data",
            "        ranges = None",
            "        if global_state.is_arcticdb:",
            "            instance = global_state.store.get(data_id)",
            "            if not instance.is_large:",
            "                dtypes_data = instance.load_data()",
            "                dtypes_data, _ = format_data(",
            "                    dtypes_data, inplace=inplace, drop_index=drop_index",
            "                )",
            "                ranges = calc_data_ranges(dtypes_data)",
            "                dtypes_data = dtypes_data[",
            "                    curr_locked",
            "                    + [c for c in dtypes_data.columns if c not in curr_locked]",
            "                ]",
            "        dtypes_state = build_dtypes_state(",
            "            dtypes_data, global_state.get_dtypes(data_id) or [], ranges=ranges",
            "        )",
            "",
            "        for col in dtypes_state:",
            "            if show_columns and col[\"name\"] not in show_columns:",
            "                col[\"visible\"] = False",
            "                continue",
            "            if hide_columns and col[\"name\"] in hide_columns:",
            "                col[\"visible\"] = False",
            "                continue",
            "            if col[\"index\"] >= 100:",
            "                col[\"visible\"] = False",
            "        if auto_hide_empty_columns and not global_state.is_arcticdb:",
            "            is_empty = data.isnull().all()",
            "            is_empty = list(is_empty[is_empty].index.values)",
            "            for col in dtypes_state:",
            "                if col[\"name\"] in is_empty:",
            "                    col[\"visible\"] = False",
            "        global_state.set_dtypes(data_id, dtypes_state)",
            "        global_state.set_context_variables(",
            "            data_id, build_context_variables(data_id, context_vars)",
            "        )",
            "        if global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "            logger.warning(",
            "                (",
            "                    \"Custom filtering enabled. Custom filters are vulnerable to code injection attacks, please only \"",
            "                    \"use in trusted environments.\"",
            "                )",
            "            )",
            "        if global_state.load_flag(data_id, \"enable_web_uploads\", False):",
            "            logger.warning(",
            "                (",
            "                    \"Web uploads enabled. Web uploads are vulnerable to blind server side request forgery, please \"",
            "                    \"only use in trusted environments.\"",
            "                )",
            "            )",
            "        return DtaleData(data_id, url, is_proxy=is_proxy, app_root=app_root)",
            "    else:",
            "        raise NoDataLoadedException(\"No data has been loaded into this D-Tale session!\")",
            "",
            "",
            "def is_vscode():",
            "    if os.environ.get(\"VSCODE_PID\") is not None:",
            "        return True",
            "    if \"1\" == os.environ.get(\"VSCODE_INJECTION\"):",
            "        return True",
            "    return False",
            "",
            "",
            "def base_render_template(template, data_id, **kwargs):",
            "    \"\"\"",
            "    Overriden version of Flask.render_template which will also include vital instance information",
            "     - settings",
            "     - version",
            "     - processes",
            "    \"\"\"",
            "    if not len(os.listdir(\"{}/static/dist\".format(os.path.dirname(__file__)))):",
            "        return redirect(current_app.url_for(\"missing_js\"))",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    curr_app_settings = global_state.get_app_settings()",
            "    _, version = retrieve_meta_info_and_version(\"dtale\")",
            "    hide_shutdown = global_state.load_flag(data_id, \"hide_shutdown\", False)",
            "    allow_cell_edits = global_state.load_flag(data_id, \"allow_cell_edits\", True)",
            "    github_fork = global_state.load_flag(data_id, \"github_fork\", False)",
            "    hide_header_editor = global_state.load_flag(data_id, \"hide_header_editor\", False)",
            "    lock_header_menu = global_state.load_flag(data_id, \"lock_header_menu\", False)",
            "    hide_header_menu = global_state.load_flag(data_id, \"hide_header_menu\", False)",
            "    hide_main_menu = global_state.load_flag(data_id, \"hide_main_menu\", False)",
            "    hide_column_menus = global_state.load_flag(data_id, \"hide_column_menus\", False)",
            "    main_title = global_state.load_flag(data_id, \"main_title\", None)",
            "    main_title_font = global_state.load_flag(data_id, \"main_title_font\", None)",
            "    enable_custom_filters = global_state.load_flag(",
            "        data_id, \"enable_custom_filters\", False",
            "    )",
            "    enable_web_uploads = global_state.load_flag(data_id, \"enable_web_uploads\", False)",
            "    app_overrides = dict(",
            "        allow_cell_edits=json.dumps(allow_cell_edits),",
            "        hide_shutdown=hide_shutdown,",
            "        hide_header_editor=hide_header_editor,",
            "        lock_header_menu=lock_header_menu,",
            "        hide_header_menu=hide_header_menu,",
            "        hide_main_menu=hide_main_menu,",
            "        hide_column_menus=hide_column_menus,",
            "        enable_custom_filters=enable_custom_filters,",
            "        enable_web_uploads=enable_web_uploads,",
            "        github_fork=github_fork,",
            "        main_title=main_title,",
            "        main_title_font=main_title_font,",
            "    )",
            "    is_arcticdb = 0",
            "    arctic_conn = \"\"",
            "    if global_state.is_arcticdb:",
            "        instance = global_state.store.get(data_id)",
            "        is_arcticdb = instance.rows()",
            "        arctic_conn = global_state.store.uri",
            "    return render_template(",
            "        template,",
            "        data_id=(",
            "            get_url_quote()(get_url_quote()(data_id, safe=\"\"))",
            "            if data_id is not None",
            "            else \"\"",
            "        ),",
            "        xarray=global_state.get_data_inst(data_id).is_xarray_dataset,",
            "        xarray_dim=json.dumps(global_state.get_dataset_dim(data_id)),",
            "        settings=json.dumps(curr_settings),",
            "        version=str(version),",
            "        processes=global_state.size(),",
            "        python_version=platform.python_version(),",
            "        predefined_filters=json.dumps(",
            "            [f.asdict() for f in predefined_filters.get_filters()]",
            "        ),",
            "        is_vscode=is_vscode(),",
            "        is_arcticdb=is_arcticdb,",
            "        arctic_conn=arctic_conn,",
            "        column_count=len(global_state.get_dtypes(data_id) or []),",
            "        # fmt: off",
            "        **dict_merge(kwargs, curr_app_settings, app_overrides)",
            "        # fmt: on",
            "    )",
            "",
            "",
            "def _view_main(data_id, iframe=False):",
            "    \"\"\"",
            "    Helper function rendering main HTML which will also build title and store whether we are viewing from an <iframe>",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param iframe: boolean flag indicating whether this is being viewed from an <iframe> (usually means ipython)",
            "    :type iframe: bool, optional",
            "    :return: HTML",
            "    \"\"\"",
            "    title = global_state.load_flag(data_id, \"main_title\", None) or \"D-Tale\"",
            "    name = global_state.get_name(data_id)",
            "    if name:",
            "        title = \"{} ({})\".format(title, name)",
            "    return base_render_template(\"dtale/main.html\", data_id, title=title, iframe=iframe)",
            "",
            "",
            "@dtale.route(\"/main\")",
            "@dtale.route(\"/main/<data_id>\")",
            "def view_main(data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if not global_state.contains(data_id):",
            "        if global_state.is_arcticdb:",
            "            try:",
            "                startup(data=data_id)",
            "                return _view_main(data_id)",
            "            except BaseException as ex:",
            "                logger.exception(ex)",
            "        return redirect(\"/dtale/{}\".format(head_endpoint()))",
            "    return _view_main(data_id)",
            "",
            "",
            "@dtale.route(\"/main/name/<data_name>\")",
            "def view_main_by_name(data_name=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_name: integer string identifier for a D-Tale process's data",
            "    :type data_name: str",
            "    :return: HTML",
            "    \"\"\"",
            "    data_id = global_state.get_data_id_by_name(data_name)",
            "    return view_main(data_id)",
            "",
            "",
            "@dtale.route(\"/iframe\")",
            "@dtale.route(\"/iframe/<data_id>\")",
            "def view_iframe(data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if data_id is None:",
            "        return redirect(\"/dtale/iframe/{}\".format(head_endpoint()))",
            "    return _view_main(data_id, iframe=True)",
            "",
            "",
            "@dtale.route(\"/iframe/popup/<popup_type>\")",
            "@dtale.route(\"/iframe/popup/<popup_type>/<data_id>\")",
            "def iframe_popup(popup_type, data_id=None):",
            "    route = \"/dtale/popup/{}\".format(popup_type)",
            "    if data_id:",
            "        return redirect(\"{}/{}\".format(route, data_id))",
            "    return redirect(route)",
            "",
            "",
            "POPUP_TITLES = {",
            "    \"reshape\": \"Summarize Data\",",
            "    \"filter\": \"Custom Filter\",",
            "    \"upload\": \"Load Data\",",
            "    \"pps\": \"Predictive Power Score\",",
            "    \"merge\": \"Merge & Stack\",",
            "    \"arcticdb\": \"Load ArcticDB Data\",",
            "    \"raw-pandas\": \"Raw Pandas Output\",",
            "}",
            "",
            "",
            "@dtale.route(\"/popup/<popup_type>\")",
            "@dtale.route(\"/popup/<popup_type>/<data_id>\")",
            "def view_popup(popup_type, data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up a base jinja template for any popup, additionally forwards any",
            "    request parameters as input to template.",
            "",
            "    :param popup_type: type of popup to be opened. Possible values: charts, correlations, describe, histogram, instances",
            "    :type popup_type: str",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if data_id is None and popup_type not in [\"upload\", \"merge\", \"arcticdb\"]:",
            "        return redirect(\"/dtale/{}\".format(head_endpoint(popup_type)))",
            "    main_title = global_state.load_flag(data_id, \"main_title\", None)",
            "    title = main_title or \"D-Tale\"",
            "    name = global_state.get_name(data_id)",
            "    if name:",
            "        title = \"{} ({})\".format(title, name)",
            "    popup_title = text(",
            "        POPUP_TITLES.get(popup_type)",
            "        or \" \".join([pt.capitalize() for pt in popup_type.split(\"-\")])",
            "    )",
            "    title = \"{} - {}\".format(title, popup_title)",
            "    params = request.args.to_dict()",
            "    if len(params):",
            "",
            "        def pretty_print(obj):",
            "            return \", \".join([\"{}: {}\".format(k, str(v)) for k, v in obj.items()])",
            "",
            "        title = \"{} ({})\".format(title, pretty_print(params))",
            "",
            "    grid_links = []",
            "    for id in global_state.keys():",
            "        label = global_state.get_name(id)",
            "        if label:",
            "            label = \" ({})\".format(label)",
            "        else:",
            "            label = \"\"",
            "        grid_links.append((id, \"{}{}\".format(id, label)))",
            "    return base_render_template(",
            "        \"dtale/popup.html\",",
            "        data_id,",
            "        title=title,",
            "        popup_title=popup_title,",
            "        js_prefix=popup_type,",
            "        grid_links=grid_links,",
            "        back_to_data=text(\"Back To Data\"),",
            "    )",
            "",
            "",
            "@dtale.route(\"/calculation/<calc_type>\")",
            "def view_calculation(calc_type=\"skew\"):",
            "    return render_template(\"dtale/{}.html\".format(calc_type))",
            "",
            "",
            "@dtale.route(\"/network\")",
            "@dtale.route(\"/network/<data_id>\")",
            "def view_network(data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if not global_state.contains(data_id):",
            "        return redirect(\"/dtale/network/{}\".format(head_endpoint()))",
            "    return base_render_template(",
            "        \"dtale/network.html\", data_id, title=\"Network Viewer\", iframe=False",
            "    )",
            "",
            "",
            "@dtale.route(\"/code-popup\")",
            "def view_code_popup():",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up a base jinja template for code snippets",
            "",
            "    :return: HTML",
            "    \"\"\"",
            "    return render_template(\"dtale/code_popup.html\", **global_state.get_app_settings())",
            "",
            "",
            "@dtale.route(\"/processes\")",
            "@exception_decorator",
            "def get_processes():",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns list of running D-Tale processes within current python process",
            "",
            "    :return: JSON {",
            "        data: [",
            "            {",
            "                port: 1, name: 'name1', rows: 5, columns: 5, names: 'col1,...,col5', start: '2018-04-30 12:36:44',",
            "                ts: 1525106204000",
            "            },",
            "            ...,",
            "            {",
            "                port: N, name: 'nameN', rows: 5, columns: 5, names: 'col1,...,col5', start: '2018-04-30 12:36:44',",
            "                ts: 1525106204000",
            "            }",
            "        ],",
            "        success: True/False",
            "    }",
            "    \"\"\"",
            "",
            "    load_dtypes = get_bool_arg(request, \"dtypes\")",
            "",
            "    def _load_process(data_id):",
            "        data = global_state.get_data(data_id)",
            "        dtypes = global_state.get_dtypes(data_id)",
            "        mdata = global_state.get_metadata(data_id)",
            "        return dict(",
            "            data_id=str(data_id),",
            "            rows=len(data),",
            "            columns=len(dtypes),",
            "            names=dtypes if load_dtypes else \",\".join([c[\"name\"] for c in dtypes]),",
            "            start=json_date(mdata[\"start\"], fmt=\"%-I:%M:%S %p\"),",
            "            ts=json_timestamp(mdata[\"start\"]),",
            "            name=global_state.get_name(data_id),",
            "            # mem usage in MB",
            "            mem_usage=int(",
            "                global_state.get_data(data_id)",
            "                .memory_usage(index=False, deep=True)",
            "                .sum()",
            "            ),",
            "        )",
            "",
            "    processes = sorted(",
            "        [_load_process(data_id) for data_id in global_state.keys()],",
            "        key=lambda p: p[\"ts\"],",
            "    )",
            "    return jsonify(dict(data=processes, success=True))",
            "",
            "",
            "@dtale.route(\"/process-keys\")",
            "@exception_decorator",
            "def process_keys():",
            "    return jsonify(",
            "        dict(",
            "            data=[",
            "                dict(id=str(data_id), name=global_state.get_name(data_id))",
            "                for data_id in global_state.keys()",
            "            ],",
            "            success=True,",
            "        )",
            "    )",
            "",
            "",
            "@dtale.route(\"/update-settings/<data_id>\")",
            "@exception_decorator",
            "def update_settings(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which updates global SETTINGS for current port",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param settings: JSON string from flask.request.args['settings'] which gets decoded and stored in SETTINGS variable",
            "    :return: JSON",
            "    \"\"\"",
            "",
            "    updated_settings = get_json_arg(request, \"settings\", {})",
            "    if not global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "        updated_settings.pop(\"query\", None)",
            "",
            "    global_state.update_settings(data_id, updated_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-theme\")",
            "@exception_decorator",
            "def update_theme():",
            "    theme = get_str_arg(request, \"theme\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"theme\"] = theme",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-pin-menu\")",
            "@exception_decorator",
            "def update_pin_menu():",
            "    pinned = get_bool_arg(request, \"pinned\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"pin_menu\"] = pinned",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-language\")",
            "@exception_decorator",
            "def update_language():",
            "    language = get_str_arg(request, \"language\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"language\"] = language",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-maximum-column-width\")",
            "@exception_decorator",
            "def update_maximum_column_width():",
            "    width = get_str_arg(request, \"width\")",
            "    if width:",
            "        width = int(width)",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"max_column_width\"] = width",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-maximum-row-height\")",
            "@exception_decorator",
            "def update_maximum_row_height():",
            "    height = get_str_arg(request, \"height\")",
            "    if height:",
            "        height = int(height)",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"max_row_height\"] = height",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-query-engine\")",
            "@exception_decorator",
            "def update_query_engine():",
            "    engine = get_str_arg(request, \"engine\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"query_engine\"] = engine",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-formats/<data_id>\")",
            "@exception_decorator",
            "def update_formats(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which updates the \"columnFormats\" property for global SETTINGS associated w/ the",
            "    current port",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param all: boolean flag which, if true, tells us we should apply this formatting to all columns with the same",
            "                data type as our selected column",
            "    :param col: selected column",
            "    :param format: JSON string for the formatting configuration we want applied to either the selected column of all",
            "                   columns with the selected column's data type",
            "    :return: JSON",
            "    \"\"\"",
            "    update_all_dtype = get_bool_arg(request, \"all\")",
            "    nan_display = get_str_arg(request, \"nanDisplay\")",
            "    if nan_display is None:",
            "        nan_display = \"nan\"",
            "    col = get_str_arg(request, \"col\")",
            "    col_format = get_json_arg(request, \"format\")",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    updated_formats = {col: col_format}",
            "    if update_all_dtype:",
            "        col_dtype = global_state.get_dtype_info(data_id, col)[\"dtype\"]",
            "        updated_formats = {",
            "            c[\"name\"]: col_format",
            "            for c in global_state.get_dtypes(data_id)",
            "            if c[\"dtype\"] == col_dtype",
            "        }",
            "    updated_formats = dict_merge(",
            "        curr_settings.get(\"columnFormats\") or {}, updated_formats",
            "    )",
            "    updated_settings = dict_merge(",
            "        curr_settings, dict(columnFormats=updated_formats, nanDisplay=nan_display)",
            "    )",
            "    global_state.set_settings(data_id, updated_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/save-range-highlights/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def save_range_highlights(data_id):",
            "    ranges = json.loads(request.json.get(\"ranges\", \"{}\"))",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    updated_settings = dict_merge(curr_settings, dict(rangeHighlight=ranges))",
            "    global_state.set_settings(data_id, updated_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "def refresh_col_indexes(data_id):",
            "    \"\"\"",
            "    Helper function to sync column indexes to current state of dataframe for data_id.",
            "    \"\"\"",
            "    curr_dtypes = {c[\"name\"]: c for c in global_state.get_dtypes(data_id)}",
            "    curr_data = global_state.get_data(data_id)",
            "    global_state.set_dtypes(",
            "        data_id,",
            "        [",
            "            dict_merge(curr_dtypes[c], dict(index=idx))",
            "            for idx, c in enumerate(curr_data.columns)",
            "        ],",
            "    )",
            "",
            "",
            "@dtale.route(\"/update-column-position/<data_id>\")",
            "@exception_decorator",
            "def update_column_position(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle moving of columns within a :class:`pandas:pandas.DataFrame`. Columns can",
            "    be moved in one of these 4 directions: front, back, left, right",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param action: string from flask.request.args['action'] of direction to move column",
            "    :param col: string from flask.request.args['col'] of column name to move",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    action = get_str_arg(request, \"action\")",
            "    col = get_str_arg(request, \"col\")",
            "",
            "    curr_cols = global_state.get_data(data_id).columns.tolist()",
            "    if action == \"front\":",
            "        curr_cols = [col] + [c for c in curr_cols if c != col]",
            "    elif action == \"back\":",
            "        curr_cols = [c for c in curr_cols if c != col] + [col]",
            "    elif action == \"left\":",
            "        if curr_cols[0] != col:",
            "            col_idx = next((idx for idx, c in enumerate(curr_cols) if c == col), None)",
            "            col_to_shift = curr_cols[col_idx - 1]",
            "            curr_cols[col_idx - 1] = col",
            "            curr_cols[col_idx] = col_to_shift",
            "    elif action == \"right\":",
            "        if curr_cols[-1] != col:",
            "            col_idx = next((idx for idx, c in enumerate(curr_cols) if c == col), None)",
            "            col_to_shift = curr_cols[col_idx + 1]",
            "            curr_cols[col_idx + 1] = col",
            "            curr_cols[col_idx] = col_to_shift",
            "",
            "    global_state.set_data(data_id, global_state.get_data(data_id)[curr_cols])",
            "    refresh_col_indexes(data_id)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/update-locked/<data_id>\")",
            "@exception_decorator",
            "def update_locked(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle saving state associated with locking and unlocking columns",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param action: string from flask.request.args['action'] of action to perform (lock or unlock)",
            "    :param col: string from flask.request.args['col'] of column name to lock/unlock",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    action = get_str_arg(request, \"action\")",
            "    col = get_str_arg(request, \"col\")",
            "    curr_settings = global_state.get_settings(data_id)",
            "    curr_data = global_state.get_data(data_id)",
            "    curr_settings[\"locked\"] = curr_settings.get(\"locked\") or []",
            "    if action == \"lock\" and col not in curr_settings[\"locked\"]:",
            "        curr_settings[\"locked\"] = curr_settings[\"locked\"] + [col]",
            "    elif action == \"unlock\":",
            "        curr_settings[\"locked\"] = [c for c in curr_settings[\"locked\"] if c != col]",
            "",
            "    final_cols = curr_settings[\"locked\"] + [",
            "        c for c in curr_data.columns if c not in curr_settings[\"locked\"]",
            "    ]",
            "    global_state.set_data(data_id, curr_data[final_cols])",
            "    global_state.set_settings(data_id, curr_settings)",
            "    refresh_col_indexes(data_id)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/update-visibility/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def update_visibility(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle saving state associated visiblity of columns on the front-end",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param visibility: string from flask.request.args['action'] of dictionary of visibility of all columns in a",
            "                       dataframe",
            "    :type visibility: dict, optional",
            "    :param toggle: string from flask.request.args['col'] of column name whose visibility should be toggled",
            "    :type toggle: str, optional",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    curr_dtypes = global_state.get_dtypes(data_id)",
            "    if request.json.get(\"visibility\"):",
            "        visibility = json.loads(request.json.get(\"visibility\", \"{}\"))",
            "        global_state.set_dtypes(",
            "            data_id,",
            "            [dict_merge(d, dict(visible=visibility[d[\"name\"]])) for d in curr_dtypes],",
            "        )",
            "    elif request.json.get(\"toggle\"):",
            "        toggle_col = request.json.get(\"toggle\")",
            "        toggle_idx = next(",
            "            (idx for idx, d in enumerate(curr_dtypes) if d[\"name\"] == toggle_col), None",
            "        )",
            "        toggle_cfg = curr_dtypes[toggle_idx]",
            "        curr_dtypes[toggle_idx] = dict_merge(",
            "            toggle_cfg, dict(visible=not toggle_cfg[\"visible\"])",
            "        )",
            "        global_state.set_dtypes(data_id, curr_dtypes)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/build-column/<data_id>\")",
            "@exception_decorator",
            "def build_column(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle the building of new columns in a dataframe. Some of the operations the",
            "    are available are:",
            "     - numeric: sum/difference/multiply/divide any combination of two columns or static values",
            "     - datetime: retrieving date properties (hour, minute, month, year...) or conversions of dates (month start, month",
            "                 end, quarter start...)",
            "     - bins: bucketing numeric data into bins using :meth:`pandas:pandas.cut` & :meth:`pandas:pandas.qcut`",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param name: string from flask.request.args['name'] of new column to create",
            "    :param type: string from flask.request.args['type'] of the type of column to build (numeric/datetime/bins)",
            "    :param cfg: dict from flask.request.args['cfg'] of how to calculate the new column",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    data = global_state.get_data(data_id)",
            "    col_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    save_as = get_str_arg(request, \"saveAs\", \"new\")",
            "    if save_as == \"inplace\":",
            "        name = cfg[\"col\"]",
            "    else:",
            "        name = get_str_arg(request, \"name\")",
            "        if not name and col_type != \"type_conversion\":",
            "            raise Exception(\"'name' is required for new column!\")",
            "        # non-type conversions cannot be done inplace and thus need a name and the name needs to be checked that it",
            "        # won't overwrite something else",
            "        name = str(name)",
            "        data = global_state.get_data(data_id)",
            "        if name in data.columns:",
            "            raise Exception(\"A column named '{}' already exists!\".format(name))",
            "",
            "    def _build_column():",
            "        builder = ColumnBuilder(data_id, col_type, name, cfg)",
            "        new_col_data = builder.build_column()",
            "        new_cols = []",
            "        if isinstance(new_col_data, pd.Series):",
            "            if pandas_util.is_pandas2():",
            "                data[name] = new_col_data",
            "            else:",
            "                data.loc[:, name] = new_col_data",
            "            new_cols.append(name)",
            "        else:",
            "            for i in range(len(new_col_data.columns)):",
            "                new_col = new_col_data.iloc[:, i]",
            "                if pandas_util.is_pandas2():",
            "                    data[str(new_col.name)] = new_col",
            "                else:",
            "                    data.loc[:, str(new_col.name)] = new_col",
            "",
            "        new_types = {}",
            "        data_ranges = {}",
            "        for new_col in new_cols:",
            "            dtype = find_dtype(data[new_col])",
            "            if classify_type(dtype) == \"F\" and not data[new_col].isnull().all():",
            "                new_ranges = calc_data_ranges(data[[new_col]])",
            "                data_ranges[new_col] = new_ranges.get(new_col, data_ranges.get(new_col))",
            "            new_types[new_col] = dtype",
            "        dtype_f = dtype_formatter(data, new_types, data_ranges)",
            "        global_state.set_data(data_id, data)",
            "        curr_dtypes = global_state.get_dtypes(data_id)",
            "        if next((cdt for cdt in curr_dtypes if cdt[\"name\"] in new_cols), None):",
            "            curr_dtypes = [",
            "                (",
            "                    dtype_f(len(curr_dtypes), cdt[\"name\"])",
            "                    if cdt[\"name\"] in new_cols",
            "                    else cdt",
            "                )",
            "                for cdt in curr_dtypes",
            "            ]",
            "        else:",
            "            curr_dtypes += [dtype_f(len(curr_dtypes), new_col) for new_col in new_cols]",
            "        global_state.set_dtypes(data_id, curr_dtypes)",
            "        curr_history = global_state.get_history(data_id) or []",
            "        curr_history += make_list(builder.build_code())",
            "        global_state.set_history(data_id, curr_history)",
            "",
            "    if cfg.get(\"applyAllType\", False):",
            "        cols = [",
            "            dtype[\"name\"]",
            "            for dtype in global_state.get_dtypes(data_id)",
            "            if dtype[\"dtype\"] == cfg[\"from\"]",
            "        ]",
            "        for col in cols:",
            "            cfg = dict_merge(cfg, dict(col=col))",
            "            name = col",
            "            _build_column()",
            "    else:",
            "        _build_column()",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/bins-tester/<data_id>\")",
            "@exception_decorator",
            "def build_column_bins_tester(data_id):",
            "    col_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    builder = ColumnBuilder(data_id, col_type, cfg[\"col\"], cfg)",
            "    data = global_state.get_data(data_id)",
            "    data, labels = builder.builder.build_test(data)",
            "    return jsonify(dict(data=data, labels=labels, timestamp=round(time.time() * 1000)))",
            "",
            "",
            "@dtale.route(\"/duplicates/<data_id>\")",
            "@exception_decorator",
            "def get_duplicates(data_id):",
            "    dupe_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    action = get_str_arg(request, \"action\")",
            "    duplicate_check = DuplicateCheck(data_id, dupe_type, cfg)",
            "    if action == \"test\":",
            "        return jsonify(results=duplicate_check.test())",
            "    updated_data_id = duplicate_check.execute()",
            "    return jsonify(success=True, data_id=updated_data_id)",
            "",
            "",
            "@dtale.route(\"/reshape/<data_id>\")",
            "@exception_decorator",
            "def reshape_data(data_id):",
            "    output = get_str_arg(request, \"output\")",
            "    shape_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    builder = DataReshaper(data_id, shape_type, cfg)",
            "    if output == \"new\":",
            "        instance = startup(data=builder.reshape(), ignore_duplicate=True)",
            "    else:",
            "        instance = startup(",
            "            data=builder.reshape(), data_id=data_id, ignore_duplicate=True",
            "        )",
            "    curr_settings = global_state.get_settings(instance._data_id)",
            "    global_state.set_settings(",
            "        instance._data_id,",
            "        dict_merge(curr_settings, dict(startup_code=builder.build_code())),",
            "    )",
            "    return jsonify(success=True, data_id=instance._data_id)",
            "",
            "",
            "@dtale.route(\"/build-replacement/<data_id>\")",
            "@exception_decorator",
            "def build_replacement(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle the replacement of specific values within a column in a dataframe. Some",
            "    of the operations the are available are:",
            "     - spaces: replace values consisting of only spaces with a specific value",
            "     - value: replace specific values with a specific value or aggregation",
            "     - strings: replace values which contain a specific character or string (case-insensitive or not) with a",
            "                       specific value",
            "     - imputer: replace nan values using sklearn imputers iterative, knn or simple",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param col: string from flask.request.args['col'] of the column to perform replacements upon",
            "    :param type: string from flask.request.args['type'] of the type of replacement to perform",
            "                 (spaces/fillna/strings/imputer)",
            "    :param cfg: dict from flask.request.args['cfg'] of how to calculate the replacements",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "",
            "    def _build_data_ranges(data, col, dtype):",
            "        data_ranges = {}",
            "        if classify_type(dtype) == \"F\" and not data[col].isnull().all():",
            "            col_ranges = calc_data_ranges(data[[col]])",
            "            if col_ranges:",
            "                data_ranges[col] = col_ranges[col]",
            "        return data_ranges",
            "",
            "    data = global_state.get_data(data_id)",
            "    name = get_str_arg(request, \"name\")",
            "    if name is not None:",
            "        name = str(name)",
            "        if name in data.columns:",
            "            raise Exception(\"A column named '{}' already exists!\".format(name))",
            "    col = get_str_arg(request, \"col\")",
            "    replacement_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "",
            "    builder = ColumnReplacement(data_id, col, replacement_type, cfg, name)",
            "    output = builder.build_replacements()",
            "    dtype = find_dtype(output)",
            "    curr_dtypes = global_state.get_dtypes(data_id)",
            "",
            "    if name is not None:",
            "        data.loc[:, name] = output",
            "        dtype_f = dtype_formatter(",
            "            data, {name: dtype}, _build_data_ranges(data, name, dtype)",
            "        )",
            "        curr_dtypes.append(dtype_f(len(curr_dtypes), name))",
            "    else:",
            "        data.loc[:, col] = output",
            "        dtype_f = dtype_formatter(",
            "            data, {col: dtype}, _build_data_ranges(data, col, dtype)",
            "        )",
            "        col_index = next(",
            "            (i for i, d in enumerate(curr_dtypes) if d[\"name\"] == col), None",
            "        )",
            "        curr_col_dtype = dtype_f(col_index, col)",
            "        curr_dtypes = [curr_col_dtype if d[\"name\"] == col else d for d in curr_dtypes]",
            "",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, curr_dtypes)",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [builder.build_code()]",
            "    global_state.set_history(data_id, curr_history)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/test-filter/<data_id>\")",
            "@exception_decorator",
            "def test_filter(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which will test out pandas query before it gets applied to DATA and return",
            "    exception information to the screen if there is any",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    query = get_str_arg(request, \"query\")",
            "    if query and not global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Custom Filters not enabled! Custom filters are vulnerable to code injection attacks, please only \"",
            "                    \"use in trusted environments.\"",
            "                ),",
            "            )",
            "        )",
            "    run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, query),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    if get_str_arg(request, \"save\"):",
            "        curr_settings = global_state.get_settings(data_id) or {}",
            "        if query is not None:",
            "            curr_settings = dict_merge(curr_settings, dict(query=query))",
            "        else:",
            "            curr_settings = {k: v for k, v in curr_settings.items() if k != \"query\"}",
            "        global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/dtypes/<data_id>\")",
            "@exception_decorator",
            "def dtypes(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns a list of column names and dtypes to the front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "",
            "    :return: JSON {",
            "        dtypes: [",
            "            {index: 1, name: col1, dtype: int64},",
            "            ...,",
            "            {index: N, name: colN, dtype: float64}",
            "        ],",
            "        success: True/False",
            "    }",
            "    \"\"\"",
            "    return jsonify(dtypes=global_state.get_dtypes(data_id), success=True)",
            "",
            "",
            "def build_sequential_diffs(s, col, sort=None):",
            "    if sort is not None:",
            "        s = s.sort_values(ascending=sort == \"ASC\")",
            "    diff = s.diff()",
            "    diff = diff[diff == diff]  # remove nan or nat values",
            "    min_diff = diff.min()",
            "    max_diff = diff.max()",
            "    avg_diff = diff.mean()",
            "    diff_vals = diff.value_counts().sort_values(ascending=False)",
            "    diff_vals.index.name = \"value\"",
            "    diff_vals.name = \"count\"",
            "    diff_vals = diff_vals.reset_index()",
            "",
            "    diff_vals_f = grid_formatter(grid_columns(diff_vals), as_string=True)",
            "    diff_fmt = next((f[2] for f in diff_vals_f.fmts if f[1] == \"value\"), None)",
            "    diff_ct = len(diff_vals)",
            "",
            "    code = (",
            "        \"sequential_diffs = data['{}'].diff()\\n\"",
            "        \"diff = diff[diff == diff]\\n\"",
            "        \"min_diff = sequential_diffs.min()\\n\"",
            "        \"max_diff = sequential_diffs.max()\\n\"",
            "        \"avg_diff = sequential_diffs.mean()\\n\"",
            "        \"diff_vals = sequential_diffs.value_counts().sort_values(ascending=False)\"",
            "    ).format(col)",
            "",
            "    metrics = {",
            "        \"diffs\": {",
            "            \"data\": diff_vals_f.format_dicts(diff_vals.head(100).itertuples()),",
            "            \"top\": diff_ct > 100,",
            "            \"total\": diff_ct,",
            "        },",
            "        \"min\": diff_fmt(min_diff, \"N/A\"),",
            "        \"max\": diff_fmt(max_diff, \"N/A\"),",
            "        \"avg\": diff_fmt(avg_diff, \"N/A\"),",
            "    }",
            "    return metrics, code",
            "",
            "",
            "def build_string_metrics(s, col):",
            "    char_len = s.len()",
            "",
            "    def calc_len(x):",
            "        try:",
            "            return len(x)",
            "        except BaseException:",
            "            return 0",
            "",
            "    word_len = apply(s.replace(r\"[\\s]+\", \" \").str.split(\" \"), calc_len)",
            "",
            "    def txt_count(r):",
            "        return s.count(r).astype(bool).sum()",
            "",
            "    string_metrics = dict(",
            "        char_min=int(char_len.min()),",
            "        char_max=int(char_len.max()),",
            "        char_mean=json_float(char_len.mean()),",
            "        char_std=json_float(char_len.std()),",
            "        with_space=int(txt_count(r\"\\s\")),",
            "        with_accent=int(txt_count(r\"[\u00c0-\u00d6\u00d9-\u00f6\u00f9-\u00ff\u0100-\u017e\u1e00-\u1eff]\")),",
            "        with_num=int(txt_count(r\"[\\d]\")),",
            "        with_upper=int(txt_count(r\"[A-Z]\")),",
            "        with_lower=int(txt_count(r\"[a-z]\")),",
            "        with_punc=int(",
            "            txt_count(",
            "                r'(\\!|\"|\\#|\\$|%|&|\\'|\\(|\\)|\\*|\\+|,|\\-|\\.|/|\\:|\\;|\\<|\\=|\\>|\\?|@|\\[|\\\\|\\]|\\^|_|\\`|\\{|\\||\\}|\\~)'",
            "            )",
            "        ),",
            "        space_at_the_first=int(txt_count(r\"^ \")),",
            "        space_at_the_end=int(txt_count(r\" $\")),",
            "        multi_space_after_each_other=int(txt_count(r\"\\s{2,}\")),",
            "        with_hidden=int(txt_count(r\"[^{}]+\".format(printable))),",
            "        word_min=int(word_len.min()),",
            "        word_max=int(word_len.max()),",
            "        word_mean=json_float(word_len.mean()),",
            "        word_std=json_float(word_len.std()),",
            "    )",
            "",
            "    punc_reg = (",
            "        \"\"\"\\tr'(\\\\!|\"|\\\\#|\\\\$|%|&|\\\\'|\\\\(|\\\\)|\\\\*|\\\\+|,|\\\\-|\\\\.|/|\\\\:|\\\\;|\\\\<|\\\\=|\"\"\"",
            "        \"\"\"\\\\>|\\\\?|@|\\\\[|\\\\\\\\|\\\\]|\\\\^|_|\\\\`|\\\\{|\\\\||\\\\}|\\\\~)'\"\"\"",
            "    )",
            "    code = [",
            "        \"s = data['{}']\".format(col),",
            "        \"s = s[~s.isnull()].str\",",
            "        \"char_len = s.len()\\n\",",
            "        \"def calc_len(x):\",",
            "        \"\\ttry:\",",
            "        \"\\t\\treturn len(x)\",",
            "        \"\\texcept:\",",
            "        \"\\t\\treturn 0\\n\",",
            "        \"word_len = s.replace(r'[\\\\s]+', ' ').str.split(' ').apply(calc_len)\\n\",",
            "        \"def txt_count(r):\",",
            "        \"\\treturn s.count(r).astype(bool).sum()\\n\",",
            "        \"char_min=char_len.min()\",",
            "        \"char_max = char_len.max()\",",
            "        \"char_mean = char_len.mean()\",",
            "        \"char_std = char_len.std()\",",
            "        \"with_space = txt_count(r'\\\\s')\",",
            "        \"with_accent = txt_count(r'[\u00c0-\u00d6\u00d9-\u00f6\u00f9-\u00ff\u0100-\u017e\u1e00-\u1eff]')\",",
            "        \"with_num = txt_count(r'[\\\\d]')\",",
            "        \"with_upper = txt_count(r'[A-Z]')\",",
            "        \"with_lower = txt_count(r'[a-z]')\",",
            "        \"with_punc = txt_count(\",",
            "        \"\\t{}\".format(punc_reg),",
            "        \")\",",
            "        \"space_at_the_first = txt_count(r'^ ')\",",
            "        \"space_at_the_end = txt_count(r' $')\",",
            "        \"multi_space_after_each_other = txt_count(r'\\\\s{2,}')\",",
            "        \"printable = r'\\\\w \\\\!\\\"#\\\\$%&'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<\u00bb\u00ab\u061b\u060c\u0640\\\\=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}~'\",",
            "        \"with_hidden = txt_count(r'[^{}]+'.format(printable))\",",
            "        \"word_min = word_len.min()\",",
            "        \"word_max = word_len.max()\",",
            "        \"word_mean = word_len.mean()\",",
            "        \"word_std = word_len.std()\",",
            "    ]",
            "",
            "    return string_metrics, code",
            "",
            "",
            "@dtale.route(\"/describe/<data_id>\")",
            "@exception_decorator",
            "def describe(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns standard details about column data using",
            "    :meth:`pandas:pandas.DataFrame.describe` to the front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param column: required dash separated string \"START-END\" stating a range of row indexes to be returned",
            "                   to the screen",
            "    :return: JSON {",
            "        describe: object representing output from :meth:`pandas:pandas.Series.describe`,",
            "        unique_data: array of unique values when data has <= 100 unique values",
            "        success: True/False",
            "    }",
            "",
            "    \"\"\"",
            "    column = get_str_arg(request, \"col\")",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    columns_to_load = [column]",
            "    indexes = curr_settings.get(\"indexes\", [])",
            "    # TODO: update this to use arcticdb's index function once it becomes available",
            "    if global_state.is_arcticdb and column in indexes:",
            "        column_to_load = next(",
            "            (",
            "                c",
            "                for c in global_state.get_dtypes(data_id) or []",
            "                if c[\"name\"] not in indexes",
            "            ),",
            "            None,",
            "        )",
            "        columns_to_load = [column_to_load[\"name\"]] if column_to_load else None",
            "    data = load_filterable_data(data_id, request, columns=columns_to_load)",
            "    data = data[[column]]",
            "    additional_aggs = None",
            "    dtype = global_state.get_dtype_info(data_id, column)",
            "    classification = classify_type(dtype[\"dtype\"])",
            "    if classification == \"I\":",
            "        additional_aggs = [\"sum\", \"median\", \"mode\", \"var\", \"sem\"]",
            "    elif classification == \"F\":",
            "        additional_aggs = [\"sum\", \"median\", \"var\", \"sem\"]",
            "    code = build_code_export(data_id)",
            "    desc, desc_code = load_describe(data[column], additional_aggs=additional_aggs)",
            "    code += desc_code",
            "    return_data = dict(describe=desc, success=True)",
            "    if \"unique\" not in return_data[\"describe\"] and \"unique_ct\" in dtype:",
            "        return_data[\"describe\"][\"unique\"] = json_int(dtype[\"unique_ct\"], as_string=True)",
            "    for p in [\"skew\", \"kurt\"]:",
            "        if p in dtype:",
            "            return_data[\"describe\"][p] = dtype[p]",
            "",
            "    if classification != \"F\" and not global_state.store.get(data_id).is_large:",
            "        uniq_vals = data[column].value_counts().sort_values(ascending=False)",
            "        uniq_vals.index.name = \"value\"",
            "        uniq_vals.name = \"count\"",
            "        uniq_vals = uniq_vals.reset_index()",
            "",
            "        # build top",
            "        top_freq = uniq_vals[\"count\"].values[0]",
            "        top_freq_pct = (top_freq / uniq_vals[\"count\"].sum()) * 100",
            "        top_vals = (",
            "            uniq_vals[uniq_vals[\"count\"] == top_freq].sort_values(\"value\").head(5)",
            "        )",
            "        top_vals_f = grid_formatter(grid_columns(top_vals), as_string=True)",
            "        top_vals = top_vals_f.format_lists(top_vals)",
            "        return_data[\"describe\"][\"top\"] = \"{} ({}%)\".format(",
            "            \", \".join(top_vals[\"value\"]), json_float(top_freq_pct, as_string=True)",
            "        )",
            "        return_data[\"describe\"][\"freq\"] = int(top_freq)",
            "",
            "        code.append(",
            "            (",
            "                \"uniq_vals = data['{}'].value_counts().sort_values(ascending=False)\\n\"",
            "                \"uniq_vals.index.name = 'value'\\n\"",
            "                \"uniq_vals.name = 'count'\\n\"",
            "                \"uniq_vals = uniq_vals.reset_index()\"",
            "            ).format(column)",
            "        )",
            "",
            "        if dtype[\"dtype\"].startswith(\"mixed\"):",
            "            uniq_vals[\"type\"] = apply(uniq_vals[\"value\"], lambda i: type(i).__name__)",
            "            dtype_counts = uniq_vals.groupby(\"type\")[\"count\"].sum().reset_index()",
            "            dtype_counts.columns = [\"dtype\", \"count\"]",
            "            return_data[\"dtype_counts\"] = dtype_counts.to_dict(orient=\"records\")",
            "            code.append(",
            "                (",
            "                    \"uniq_vals['type'] = uniq_vals['value'].apply( lambda i: type(i).__name__)\\n\"",
            "                    \"dtype_counts = uniq_vals.groupby('type')['count'].sum().reset_index()\\n\"",
            "                    \"dtype_counts.columns = ['dtype', 'count']\"",
            "                )",
            "            )",
            "        else:",
            "            uniq_vals.loc[:, \"type\"] = find_dtype(uniq_vals[\"value\"])",
            "            code.append(",
            "                \"uniq_vals.loc[:, 'type'] = '{}'\".format(uniq_vals[\"type\"].values[0])",
            "            )",
            "",
            "        return_data[\"uniques\"] = {}",
            "        for uniq_type, uniq_grp in uniq_vals.groupby(\"type\"):",
            "            total = len(uniq_grp)",
            "            top = total > 100",
            "            uniq_grp = (",
            "                uniq_grp[[\"value\", \"count\"]]",
            "                .sort_values([\"count\", \"value\"], ascending=[False, True])",
            "                .head(100)",
            "            )",
            "            # pandas started supporting string dtypes in 1.1.0",
            "            conversion_type = (",
            "                uniq_type",
            "                if pandas_util.check_pandas_version(\"1.1.0\") and uniq_type == \"string\"",
            "                else \"object\"",
            "            )",
            "            uniq_grp[\"value\"] = uniq_grp[\"value\"].astype(conversion_type)",
            "            uniq_f, _ = build_formatters(uniq_grp)",
            "            return_data[\"uniques\"][uniq_type] = dict(",
            "                data=uniq_f.format_dicts(uniq_grp.itertuples()), total=total, top=top",
            "            )",
            "",
            "    if (",
            "        classification in [\"I\", \"F\", \"D\"]",
            "        and not global_state.store.get(data_id).is_large",
            "    ):",
            "        sd_metrics, sd_code = build_sequential_diffs(data[column], column)",
            "        return_data[\"sequential_diffs\"] = sd_metrics",
            "        code.append(sd_code)",
            "",
            "    if classification == \"S\":",
            "        str_col = data[column]",
            "        sm_metrics, sm_code = build_string_metrics(",
            "            str_col[~str_col.isnull()].astype(\"str\").str, column",
            "        )",
            "        return_data[\"string_metrics\"] = sm_metrics",
            "        code += sm_code",
            "",
            "    return_data[\"code\"] = \"\\n\".join(code)",
            "    return jsonify(return_data)",
            "",
            "",
            "@dtale.route(\"/variance/<data_id>\")",
            "@exception_decorator",
            "def variance(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns standard details about column data using",
            "    :meth:`pandas:pandas.DataFrame.describe` to the front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param column: required dash separated string \"START-END\" stating a range of row indexes to be returned",
            "                   to the screen",
            "    :return: JSON {",
            "        describe: object representing output from :meth:`pandas:pandas.Series.describe`,",
            "        unique_data: array of unique values when data has <= 100 unique values",
            "        success: True/False",
            "    }",
            "",
            "    \"\"\"",
            "    column = get_str_arg(request, \"col\")",
            "    data = load_filterable_data(data_id, request)",
            "    s = data[column]",
            "    code = [\"s = df['{}']\".format(column)]",
            "    unique_ct = unique_count(s)",
            "    code.append(\"unique_ct = s.unique().size\")",
            "    s_size = len(s)",
            "    code.append(\"s_size = len(s)\")",
            "    check1 = bool((unique_ct / s_size) < 0.1)",
            "    code.append(\"check1 = (unique_ct / s_size) < 0.1\")",
            "    return_data = dict(check1=dict(unique=unique_ct, size=s_size, result=check1))",
            "    dtype = global_state.get_dtype_info(data_id, column)",
            "    if unique_ct >= 2:",
            "        val_counts = s.value_counts()",
            "        check2 = bool((val_counts.values[0] / val_counts.values[1]) > 20)",
            "        fmt = find_dtype_formatter(dtype[\"dtype\"])",
            "        return_data[\"check2\"] = dict(",
            "            val1=dict(val=fmt(val_counts.index[0]), ct=int(val_counts.values[0])),",
            "            val2=dict(val=fmt(val_counts.index[1]), ct=int(val_counts.values[1])),",
            "            result=check2,",
            "        )",
            "    code += [",
            "        \"check2 = False\",",
            "        \"if unique_ct > 1:\",",
            "        \"\\tval_counts = s.value_counts()\",",
            "        \"\\tcheck2 = (val_counts.values[0] / val_counts.values[1]) > 20\",",
            "        \"low_variance = check1 and check2\",",
            "    ]",
            "",
            "    return_data[\"size\"] = len(s)",
            "    return_data[\"outlierCt\"] = dtype[\"hasOutliers\"]",
            "    return_data[\"missingCt\"] = int(s.isnull().sum())",
            "",
            "    jb_stat, jb_p = sts.jarque_bera(s)",
            "    return_data[\"jarqueBera\"] = dict(statistic=float(jb_stat), pvalue=float(jb_p))",
            "    sw_stat, sw_p = sts.shapiro(s)",
            "    return_data[\"shapiroWilk\"] = dict(statistic=float(sw_stat), pvalue=float(sw_p))",
            "    code += [",
            "        \"\\nimport scipy.stats as sts\\n\",",
            "        \"jb_stat, jb_p = sts.jarque_bera(s)\",",
            "        \"sw_stat, sw_p = sts.shapiro(s)\",",
            "    ]",
            "    return_data[\"code\"] = \"\\n\".join(code)",
            "    return jsonify(return_data)",
            "",
            "",
            "def calc_outlier_range(s):",
            "    try:",
            "        q1 = s.quantile(0.25)",
            "        q3 = s.quantile(0.75)",
            "    except BaseException:  # this covers the case when a series contains pd.NA",
            "        return np.nan, np.nan",
            "    iqr = q3 - q1",
            "    iqr_lower = q1 - 1.5 * iqr",
            "    iqr_upper = q3 + 1.5 * iqr",
            "    return iqr_lower, iqr_upper",
            "",
            "",
            "def build_outlier_query(iqr_lower, iqr_upper, min_val, max_val, column):",
            "    queries = []",
            "    if iqr_lower > min_val:",
            "        queries.append(",
            "            \"{column} < {lower}\".format(",
            "                column=build_col_key(column), lower=json_float(iqr_lower)",
            "            )",
            "        )",
            "    if iqr_upper < max_val:",
            "        queries.append(",
            "            \"{column} > {upper}\".format(",
            "                column=build_col_key(column), upper=json_float(iqr_upper)",
            "            )",
            "        )",
            "    return \"(({}))\".format(\") or (\".join(queries)) if len(queries) > 1 else queries[0]",
            "",
            "",
            "@dtale.route(\"/outliers/<data_id>\")",
            "@exception_decorator",
            "def outliers(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    df = global_state.get_data(data_id)",
            "    s = df[column]",
            "    iqr_lower, iqr_upper = calc_outlier_range(s)",
            "    formatter = find_dtype_formatter(find_dtype(s))",
            "",
            "    df = load_filterable_data(data_id, request)",
            "    s = df[column]",
            "    outliers = sorted(s[(s < iqr_lower) | (s > iqr_upper)].unique())",
            "    if not len(outliers):",
            "        return jsonify(outliers=[])",
            "",
            "    top = len(outliers) > 100",
            "    outliers = [formatter(v) for v in outliers[:100]]",
            "    query = build_outlier_query(iqr_lower, iqr_upper, s.min(), s.max(), column)",
            "    code = (",
            "        \"s = df['{column}']\\n\"",
            "        \"q1 = s.quantile(0.25)\\n\"",
            "        \"q3 = s.quantile(0.75)\\n\"",
            "        \"iqr = q3 - q1\\n\"",
            "        \"iqr_lower = q1 - 1.5 * iqr\\n\"",
            "        \"iqr_upper = q3 + 1.5 * iqr\\n\"",
            "        \"outliers = dict(s[(s < iqr_lower) | (s > iqr_upper)])\"",
            "    ).format(column=column)",
            "    queryApplied = column in (",
            "        (global_state.get_settings(data_id) or {}).get(\"outlierFilters\") or {}",
            "    )",
            "    return jsonify(",
            "        outliers=outliers, query=query, code=code, queryApplied=queryApplied, top=top",
            "    )",
            "",
            "",
            "@dtale.route(\"/toggle-outlier-filter/<data_id>\")",
            "@exception_decorator",
            "def toggle_outlier_filter(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    settings = global_state.get_settings(data_id) or {}",
            "    outlierFilters = settings.get(\"outlierFilters\") or {}",
            "    if column in outlierFilters:",
            "        settings[\"outlierFilters\"] = {",
            "            k: v for k, v in outlierFilters.items() if k != column",
            "        }",
            "    else:",
            "        dtype_info = global_state.get_dtype_info(data_id, column)",
            "        outlier_range, min_val, max_val = (",
            "            dtype_info.get(p) for p in [\"outlierRange\", \"min\", \"max\"]",
            "        )",
            "        iqr_lower, iqr_upper = (outlier_range.get(p) for p in [\"lower\", \"upper\"])",
            "        query = build_outlier_query(iqr_lower, iqr_upper, min_val, max_val, column)",
            "        settings[\"outlierFilters\"] = dict_merge(",
            "            outlierFilters, {column: {\"query\": query}}",
            "        )",
            "    global_state.set_settings(data_id, settings)",
            "    return jsonify(dict(success=True, outlierFilters=settings[\"outlierFilters\"]))",
            "",
            "",
            "@dtale.route(\"/delete-col/<data_id>\")",
            "@exception_decorator",
            "def delete_col(data_id):",
            "    columns = get_json_arg(request, \"cols\")",
            "    data = global_state.get_data(data_id)",
            "    data = data[[c for c in data.columns if c not in columns]]",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [\"df = df.drop(columns=['{}'])\".format(\"','\".join(columns))]",
            "    global_state.set_history(data_id, curr_history)",
            "    dtypes = global_state.get_dtypes(data_id)",
            "    dtypes = [dt for dt in dtypes if dt[\"name\"] not in columns]",
            "    curr_settings = global_state.get_settings(data_id)",
            "    curr_settings[\"locked\"] = [",
            "        c for c in curr_settings.get(\"locked\", []) if c not in columns",
            "    ]",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/rename-col/<data_id>\")",
            "@exception_decorator",
            "def rename_col(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    rename = get_str_arg(request, \"rename\")",
            "    data = global_state.get_data(data_id)",
            "    if column != rename and rename in data.columns:",
            "        return jsonify(error='Column name \"{}\" already exists!')",
            "",
            "    data = data.rename(columns={column: rename})",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [\"df = df.rename(columns={'%s': '%s'})\" % (column, rename)]",
            "    global_state.set_history(data_id, curr_history)",
            "    dtypes = global_state.get_dtypes(data_id)",
            "    dtypes = [",
            "        dict_merge(dt, {\"name\": rename}) if dt[\"name\"] == column else dt",
            "        for dt in dtypes",
            "    ]",
            "    curr_settings = global_state.get_settings(data_id)",
            "    curr_settings[\"locked\"] = [",
            "        rename if c == column else c for c in curr_settings.get(\"locked\", [])",
            "    ]",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/duplicate-col/<data_id>\")",
            "@exception_decorator",
            "def duplicate_col(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    data = global_state.get_data(data_id)",
            "    dupe_idx = 2",
            "    new_col = \"{}_{}\".format(column, dupe_idx)",
            "    while new_col in data.columns:",
            "        dupe_idx += 1",
            "        new_col = \"{}_{}\".format(column, dupe_idx)",
            "",
            "    data.loc[:, new_col] = data[column]",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [\"df.loc[:, '%s'] = df['%s']\" % (new_col, column)]",
            "    global_state.set_history(data_id, curr_history)",
            "    dtypes = []",
            "    cols = []",
            "    idx = 0",
            "    for dt in global_state.get_dtypes(data_id):",
            "        dt[\"index\"] = idx",
            "        dtypes.append(dt)",
            "        cols.append(dt[\"name\"])",
            "        idx += 1",
            "        if dt[\"name\"] == column:",
            "            dtypes.append(dict_merge(dt, dict(name=new_col, index=idx)))",
            "            cols.append(new_col)",
            "            idx += 1",
            "",
            "    global_state.set_data(data_id, data[cols])",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    return jsonify(success=True, col=new_col)",
            "",
            "",
            "@dtale.route(\"/edit-cell/<data_id>\")",
            "@exception_decorator",
            "def edit_cell(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    row_index = get_int_arg(request, \"rowIndex\")",
            "    updated = get_str_arg(request, \"updated\")",
            "    updated_str = updated",
            "",
            "    # make sure to load filtered data in order to get correct row index",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    row_index_val = data.iloc[[row_index]].index[0]",
            "    data = global_state.get_data(data_id)",
            "    dtype = find_dtype(data[column])",
            "",
            "    code = []",
            "    if updated in [\"nan\", \"inf\"]:",
            "        updated_str = \"np.{}\".format(updated)",
            "        updated = getattr(np, updated)",
            "        data.loc[row_index_val, column] = updated",
            "        code.append(",
            "            \"df.loc[{row_index}, '{column}'] = {updated}\".format(",
            "                row_index=row_index_val, column=column, updated=updated_str",
            "            )",
            "        )",
            "    else:",
            "        classification = classify_type(dtype)",
            "        if classification == \"B\":",
            "            updated = updated.lower() == \"true\"",
            "            updated_str = str(updated)",
            "        elif classification == \"I\":",
            "            updated = int(updated)",
            "        elif classification == \"F\":",
            "            updated = float(updated)",
            "        elif classification == \"D\":",
            "            updated_str = \"pd.Timestamp({})\".format(updated)",
            "            updated = pd.Timestamp(updated)",
            "        elif classification == \"TD\":",
            "            updated_str = \"pd.Timedelta({})\".format(updated)",
            "            updated = pd.Timedelta(updated)",
            "        else:",
            "            if dtype.startswith(\"category\") and updated not in data[column].unique():",
            "                if pandas_util.is_pandas2():",
            "                    data.loc[:, column] = pd.Categorical(",
            "                        data[column],",
            "                        categories=data[column].cat.add_categories(updated),",
            "                        ordered=True,",
            "                    )",
            "                    code.append(",
            "                        (",
            "                            \"data.loc[:, '{column}'] = pd.Categorical(\\n\"",
            "                            \"\\tdata['{column}'],\\n\"",
            "                            \"\\tcategories=data['{column}'].cat.add_categories('{updated}'),\\n\"",
            "                            \"\\tordered=True\\n\"",
            "                            \")\"",
            "                        ).format(column=column, updated=updated)",
            "                    )",
            "                else:",
            "                    data[column].cat.add_categories(updated, inplace=True)",
            "                    code.append(",
            "                        \"data['{column}'].cat.add_categories('{updated}', inplace=True)\".format(",
            "                            column=column, updated=updated",
            "                        )",
            "                    )",
            "            updated_str = \"'{}'\".format(updated)",
            "        data.at[row_index_val, column] = updated",
            "        code.append(",
            "            \"df.at[{row_index}, '{column}'] = {updated}\".format(",
            "                row_index=row_index_val, column=column, updated=updated_str",
            "            )",
            "        )",
            "    global_state.set_data(data_id, data)",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += code",
            "    global_state.set_history(data_id, curr_history)",
            "",
            "    data = global_state.get_data(data_id)",
            "    dtypes = global_state.get_dtypes(data_id)",
            "    ranges = calc_data_ranges(data[[column]])",
            "    dtype_f = dtype_formatter(data, {column: dtype}, ranges)",
            "    dtypes = [",
            "        dtype_f(dt[\"index\"], column) if dt[\"name\"] == column else dt for dt in dtypes",
            "    ]",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    return jsonify(success=True)",
            "",
            "",
            "def build_filter_vals(series, data_id, column, fmt):",
            "    dtype_info = global_state.get_dtype_info(data_id, column)",
            "    vals = list(series.dropna().unique())",
            "    try:",
            "        vals = sorted(vals)",
            "    except BaseException:",
            "        pass  # if there are mixed values (EX: strings with ints) this fails",
            "    if dtype_info.get(\"unique_ct\", 0) > 500:",
            "        # columns with too many unique values will need to use asynchronous loading, so for now we'll give the",
            "        # first 5 values",
            "        vals = vals[:5]",
            "    vals = [fmt(v) for v in vals]",
            "    return vals",
            "",
            "",
            "@dtale.route(\"/column-filter-data/<data_id>\")",
            "@exception_decorator",
            "def get_column_filter_data(data_id):",
            "    if global_state.is_arcticdb and global_state.store.get(data_id).is_large:",
            "        return jsonify(dict(success=True, hasMissing=True))",
            "    column = get_str_arg(request, \"col\")",
            "    s = global_state.get_data(data_id)[column]",
            "    dtype = find_dtype(s)",
            "    fmt = find_dtype_formatter(dtype)",
            "    classification = classify_type(dtype)",
            "    ret = dict(success=True, hasMissing=bool(s.isnull().any()))",
            "    if classification not in [\"S\", \"B\"]:",
            "        data_range = s.agg([\"min\", \"max\"]).to_dict()",
            "        data_range = {k: fmt(v) for k, v in data_range.items()}",
            "        ret = dict_merge(ret, data_range)",
            "    if classification in [\"S\", \"I\", \"B\"]:",
            "        ret[\"uniques\"] = build_filter_vals(s, data_id, column, fmt)",
            "    return jsonify(ret)",
            "",
            "",
            "@dtale.route(\"/async-column-filter-data/<data_id>\")",
            "@exception_decorator",
            "def get_async_column_filter_data(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    input = get_str_arg(request, \"input\")",
            "    s = global_state.get_data(data_id)[column]",
            "    dtype = find_dtype(s)",
            "    fmt = find_dtype_formatter(dtype)",
            "    vals = s[s.astype(\"str\").str.startswith(input)]",
            "    vals = [option(fmt(v)) for v in sorted(vals.unique())[:5]]",
            "    return jsonify(vals)",
            "",
            "",
            "@dtale.route(\"/save-column-filter/<data_id>\")",
            "@exception_decorator",
            "def save_column_filter(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    curr_filters = ColumnFilter(",
            "        data_id, column, get_str_arg(request, \"cfg\")",
            "    ).save_filter()",
            "    return jsonify(success=True, currFilters=curr_filters)",
            "",
            "",
            "@dtale.route(\"/data/<data_id>\")",
            "@exception_decorator",
            "def get_data(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns current rows from DATA (based on scrollbar specs and saved settings)",
            "    to front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param ids: required dash separated string \"START-END\" stating a range of row indexes to be returned to the screen",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :param sort: JSON string from flask.request.args['sort'] which is applied to DATA using the sort_values() or",
            "                 sort_index() function.  Here is the JSON structure: [col1,dir1],[col2,dir2],....[coln,dirn]",
            "    :return: JSON {",
            "        results: [",
            "            {dtale_index: 1, col1: val1_1, ...,colN: valN_1},",
            "            ...,",
            "            {dtale_index: N2, col1: val1_N2, ...,colN: valN_N2}",
            "        ],",
            "        columns: [{name: col1, dtype: 'int64'},...,{name: colN, dtype: 'datetime'}],",
            "        total: N2,",
            "        success: True/False",
            "    }",
            "    \"\"\"",
            "",
            "    # handling for gunicorn-hosted instances w/ ArcticDB",
            "    if global_state.is_arcticdb and not len(global_state.get_dtypes(data_id) or []):",
            "        global_state.store.build_instance(data_id)",
            "        startup(data=data_id)",
            "",
            "    params = retrieve_grid_params(request)",
            "    export = get_bool_arg(request, \"export\")",
            "    ids = get_json_arg(request, \"ids\")",
            "    if not export and ids is None:",
            "        return jsonify({})",
            "",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    curr_locked = curr_settings.get(\"locked\", [])",
            "    final_query = build_query(data_id, global_state.get_query(data_id))",
            "    highlight_filter = curr_settings.get(\"highlightFilter\") or False",
            "",
            "    if global_state.is_arcticdb:",
            "        col_types = global_state.get_dtypes(data_id) or []",
            "        columns_to_load = [c[\"name\"] for c in col_types if c[\"visible\"]]",
            "        f = grid_formatter(",
            "            [c for c in col_types if c[\"visible\"]],",
            "            nan_display=curr_settings.get(\"nanDisplay\", \"nan\"),",
            "        )",
            "",
            "        query_builder = build_query_builder(data_id)",
            "        date_range = load_index_filter(data_id)",
            "        instance = global_state.store.get(data_id)",
            "        total = instance.rows()",
            "        results = {}",
            "        if total:",
            "            if export:",
            "                export_rows = get_int_arg(request, \"export_rows\")",
            "                if export_rows:",
            "                    if query_builder:",
            "                        data = instance.load_data(",
            "                            query_builder=query_builder, **date_range",
            "                        )",
            "                        data = data.head(export_rows)",
            "                    elif len(date_range):",
            "                        data = instance.load_data(**date_range)",
            "                        data = data.head(export_rows)",
            "                    else:",
            "                        data = instance.load_data(row_range=[0, export_rows])",
            "                data, _ = format_data(data)",
            "                data = data[",
            "                    curr_locked + [c for c in data.columns if c not in curr_locked]",
            "                ]",
            "                results = f.format_dicts(data.itertuples())",
            "                results = [dict_merge({IDX_COL: i}, r) for i, r in enumerate(results)]",
            "            elif query_builder:",
            "                df = instance.load_data(",
            "                    query_builder=query_builder,",
            "                    columns=columns_to_load,",
            "                    # fmt: off",
            "                    **date_range",
            "                    # fmt: on",
            "                )",
            "                total = len(df)",
            "                df, _ = format_data(df)",
            "                df = df[curr_locked + [c for c in df.columns if c not in curr_locked]]",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = df.iloc[sub_range[0] : sub_range[0] + 1]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = (",
            "                            df.iloc[start:]",
            "                            if end >= total - 1",
            "                            else df.iloc[start : end + 1]",
            "                        )",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "            elif len(date_range):",
            "                df = instance.load_data(columns=columns_to_load, **date_range)",
            "                total = len(df)",
            "                df, _ = format_data(df)",
            "                df = df[curr_locked + [c for c in df.columns if c not in curr_locked]]",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = df.iloc[sub_range[0] : sub_range[0] + 1]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = (",
            "                            df.iloc[start:]",
            "                            if end >= total - 1",
            "                            else df.iloc[start : end + 1]",
            "                        )",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "            else:",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = instance.load_data(",
            "                            row_range=[sub_range[0], sub_range[0] + 1],",
            "                            columns=columns_to_load,",
            "                        )",
            "                        sub_df, _ = format_data(sub_df)",
            "                        sub_df = sub_df[",
            "                            curr_locked",
            "                            + [c for c in sub_df.columns if c not in curr_locked]",
            "                        ]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = instance.load_data(",
            "                            row_range=[start, total if end >= total else end + 1],",
            "                            columns=columns_to_load,",
            "                        )",
            "                        sub_df, _ = format_data(sub_df)",
            "                        sub_df = sub_df[",
            "                            curr_locked",
            "                            + [c for c in sub_df.columns if c not in curr_locked]",
            "                        ]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "    else:",
            "        data = global_state.get_data(data_id)",
            "",
            "        # this will check for when someone instantiates D-Tale programmatically and directly alters the internal",
            "        # state of the dataframe (EX: d.data['new_col'] = 'foo')",
            "        curr_dtypes = [c[\"name\"] for c in global_state.get_dtypes(data_id)]",
            "        if any(c not in curr_dtypes for c in data.columns):",
            "            data, _ = format_data(data)",
            "            data = data[curr_locked + [c for c in data.columns if c not in curr_locked]]",
            "            global_state.set_data(data_id, data)",
            "            global_state.set_dtypes(",
            "                data_id,",
            "                build_dtypes_state(data, global_state.get_dtypes(data_id) or []),",
            "            )",
            "",
            "        col_types = global_state.get_dtypes(data_id)",
            "        f = grid_formatter(",
            "            col_types, nan_display=curr_settings.get(\"nanDisplay\", \"nan\")",
            "        )",
            "        if curr_settings.get(\"sortInfo\") != params.get(\"sort\"):",
            "            data = sort_df_for_grid(data, params)",
            "            global_state.set_data(data_id, data)",
            "        if params.get(\"sort\") is not None:",
            "            curr_settings = dict_merge(curr_settings, dict(sortInfo=params[\"sort\"]))",
            "        else:",
            "            curr_settings = {k: v for k, v in curr_settings.items() if k != \"sortInfo\"}",
            "        filtered_indexes = []",
            "        data = run_query(",
            "            handle_predefined(data_id),",
            "            final_query,",
            "            global_state.get_context_variables(data_id),",
            "            ignore_empty=True,",
            "            highlight_filter=highlight_filter,",
            "        )",
            "        if highlight_filter:",
            "            data, filtered_indexes = data",
            "        global_state.set_settings(data_id, curr_settings)",
            "",
            "        total = len(data)",
            "        results = {}",
            "        if total:",
            "            if export:",
            "                export_rows = get_int_arg(request, \"export_rows\")",
            "                if export_rows:",
            "                    data = data.head(export_rows)",
            "                results = f.format_dicts(data.itertuples())",
            "                results = [dict_merge({IDX_COL: i}, r) for i, r in enumerate(results)]",
            "            else:",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = data.iloc[sub_range[0] : sub_range[0] + 1]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                        if highlight_filter and sub_range[0] in filtered_indexes:",
            "                            results[sub_range[0]][\"__filtered\"] = True",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = (",
            "                            data.iloc[start:]",
            "                            if end >= total - 1",
            "                            else data.iloc[start : end + 1]",
            "                        )",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "                            if highlight_filter and i in filtered_indexes:",
            "                                results[i][\"__filtered\"] = True",
            "    columns = [",
            "        dict(name=IDX_COL, dtype=\"int64\", visible=True)",
            "    ] + global_state.get_dtypes(data_id)",
            "    return_data = dict(",
            "        results=results,",
            "        columns=columns,",
            "        total=total,",
            "        final_query=None if highlight_filter else final_query,",
            "    )",
            "",
            "    if export:",
            "        return export_html(data_id, return_data)",
            "",
            "    return jsonify(return_data)",
            "",
            "",
            "def export_html(data_id, return_data):",
            "    def load_file(fpath, encoding=\"utf-8\"):",
            "        return read_file(",
            "            os.path.join(os.path.dirname(__file__), \"static/{}\".format(fpath)),",
            "            encoding=encoding,",
            "        )",
            "",
            "    istok_woff = load_file(\"fonts/istok_woff64.txt\", encoding=None)",
            "    istok_bold_woff = load_file(\"fonts/istok-bold_woff64.txt\", encoding=None)",
            "",
            "    font_styles = (",
            "        \"\"\"",
            "        @font-face {",
            "          font-family: \"istok\";",
            "          font-weight: 400;",
            "          font-style: normal;",
            "          src: url(data:font/truetype;charset=utf-8;base64,\"\"\"",
            "        + istok_woff",
            "        + \"\"\") format(\"woff\");",
            "        }",
            "",
            "        @font-face {",
            "          font-family: \"istok\";",
            "          font-weight: 700;",
            "          font-style: normal;",
            "          src: url(data:font/truetype;charset=utf-8;base64,\"\"\"",
            "        + istok_bold_woff",
            "        + \"\"\") format(\"woff\");",
            "        }",
            "        \"\"\"",
            "    )",
            "",
            "    main_styles = load_file(\"css/main.css\", encoding=\"utf-8\" if PY3 else None).split(",
            "        \"\\n\"",
            "    )",
            "    main_styles = \"\\n\".join(main_styles[28:])",
            "    main_styles = \"{}\\n{}\\n\".format(font_styles, main_styles)",
            "",
            "    if not PY3:",
            "        main_styles = main_styles.decode(\"utf-8\")",
            "",
            "    return_data[\"results\"] = {r[IDX_COL]: r for r in return_data[\"results\"]}",
            "",
            "    polyfills_js = load_file(\"dist/polyfills_bundle.js\")",
            "    export_js = load_file(\"dist/export_bundle.js\")",
            "",
            "    return send_file(",
            "        base_render_template(",
            "            \"dtale/html_export.html\",",
            "            data_id,",
            "            main_styles=main_styles,",
            "            polyfills_js=polyfills_js,",
            "            export_js=export_js,",
            "            response=return_data,",
            "        ),",
            "        \"dtale_html_export_{}.html\".format(json_timestamp(pd.Timestamp(\"now\"))),",
            "        \"text/html\",",
            "    )",
            "",
            "",
            "@dtale.route(\"/load-filtered-ranges/<data_id>\")",
            "@exception_decorator",
            "def load_filtered_ranges(data_id):",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    final_query = build_query(data_id, global_state.get_query(data_id))",
            "    if not final_query:",
            "        return {}",
            "    curr_filtered_ranges = curr_settings.get(\"filteredRanges\", {})",
            "    if final_query == curr_filtered_ranges.get(\"query\"):",
            "        return jsonify(curr_filtered_ranges)",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        final_query,",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "",
            "    def _filter_numeric(col):",
            "        s = data[col]",
            "        dtype = find_dtype(s)",
            "        return classify_type(dtype) in [\"F\", \"I\"] and not s.isnull().all()",
            "",
            "    numeric_cols = [col for col in data.columns if _filter_numeric(col)]",
            "    filtered_ranges = calc_data_ranges(data[numeric_cols])",
            "    updated_dtypes = build_dtypes_state(",
            "        data, global_state.get_dtypes(data_id) or [], filtered_ranges",
            "    )",
            "    updated_dtypes = {col[\"name\"]: col for col in updated_dtypes}",
            "    overall_min, overall_max = None, None",
            "    if len(filtered_ranges):",
            "        overall_min = min([v[\"min\"] for v in filtered_ranges.values()])",
            "        overall_max = max([v[\"max\"] for v in filtered_ranges.values()])",
            "    curr_settings[\"filteredRanges\"] = dict(",
            "        query=final_query,",
            "        ranges=filtered_ranges,",
            "        dtypes=updated_dtypes,",
            "        overall=dict(min=overall_min, max=overall_max),",
            "    )",
            "    global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(curr_settings[\"filteredRanges\"])",
            "",
            "",
            "@dtale.route(\"/data-export/<data_id>\")",
            "@exception_decorator",
            "def data_export(data_id):",
            "    curr_dtypes = global_state.get_dtypes(data_id) or []",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    data = data[",
            "        [",
            "            c[\"name\"]",
            "            for c in sorted(curr_dtypes, key=lambda c: c[\"index\"])",
            "            if c[\"visible\"]",
            "        ]",
            "    ]",
            "    file_type = get_str_arg(request, \"type\", \"csv\")",
            "    if file_type in [\"csv\", \"tsv\"]:",
            "        tsv = file_type == \"tsv\"",
            "        csv_buffer = export_to_csv_buffer(data, tsv=tsv)",
            "        filename = build_chart_filename(\"data\", ext=file_type)",
            "        return send_file(csv_buffer.getvalue(), filename, \"text/{}\".format(file_type))",
            "    elif file_type == \"parquet\":",
            "        from dtale.utils import export_to_parquet_buffer",
            "",
            "        parquet_buffer = export_to_parquet_buffer(data)",
            "        filename = build_chart_filename(\"data\", ext=\"parquet.gzip\")",
            "        return send_file(",
            "            parquet_buffer.getvalue(), filename, \"application/octet-stream\"",
            "        )",
            "    return jsonify(success=False)",
            "",
            "",
            "@dtale.route(\"/column-analysis/<data_id>\")",
            "@exception_decorator",
            "def get_column_analysis(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns output from numpy.histogram/pd.value_counts to front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param col: string from flask.request.args['col'] containing name of a column in your dataframe",
            "    :param type: string from flask.request.args['type'] to signify either a histogram or value counts",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :param bins: the number of bins to display in your histogram, options on the front-end are 5, 10, 20, 50",
            "    :param top: the number of top values to display in your value counts, default is 100",
            "    :returns: JSON {results: DATA, desc: output from pd.DataFrame[col].describe(), success: True/False}",
            "    \"\"\"",
            "",
            "    analysis = ColumnAnalysis(data_id, request)",
            "    return jsonify(**analysis.build())",
            "",
            "",
            "@matplotlib_decorator",
            "def build_correlations_matrix_image(",
            "    data,",
            "    is_pps,",
            "    valid_corr_cols,",
            "    valid_str_corr_cols,",
            "    valid_date_cols,",
            "    dummy_col_mappings,",
            "    pps_data,",
            "    code,",
            "):",
            "    import matplotlib.pyplot as plt",
            "    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas",
            "",
            "    plt.figure(figsize=(20, 12))",
            "    ax0 = plt.gca()",
            "    cmap = \"Blues\" if is_pps else \"RdYlGn\"",
            "    vmin = 0.0 if is_pps else -1.0",
            "    sns.heatmap(",
            "        data.mask(data.apply(lambda x: x.name == x.index)),",
            "        ax=ax0,",
            "        vmin=vmin,",
            "        vmax=1.0,",
            "        xticklabels=True,",
            "        yticklabels=True,",
            "        cmap=cmap,",
            "    )",
            "    output = BytesIO()",
            "    FigureCanvas(ax0.get_figure()).print_png(output)",
            "    return (",
            "        valid_corr_cols,",
            "        valid_str_corr_cols,",
            "        valid_date_cols,",
            "        dummy_col_mappings,",
            "        pps_data,",
            "        code,",
            "        output.getvalue(),",
            "    )",
            "",
            "",
            "def build_correlations_matrix(data_id, is_pps=False, encode_strings=False, image=False):",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    valid_corr_cols, valid_str_corr_cols, valid_date_cols = correlations.get_col_groups(",
            "        data_id, data",
            "    )",
            "",
            "    str_encodings_code = \"\"",
            "    dummy_col_mappings = {}",
            "    if encode_strings and valid_str_corr_cols:",
            "        data = data[valid_corr_cols + valid_str_corr_cols]",
            "        dummy_kwargs = {}",
            "        if pandas_util.is_pandas2():",
            "            dummy_kwargs[\"dtype\"] = \"int\"",
            "        for str_col in valid_str_corr_cols:",
            "            dummies = pd.get_dummies(data[[str_col]], columns=[str_col], **dummy_kwargs)",
            "            dummy_cols = list(dummies.columns)",
            "            dummy_col_mappings[str_col] = dummy_cols",
            "            data[dummy_cols] = dummies",
            "            valid_corr_cols += dummy_cols",
            "        str_encodings_code = (",
            "            \"str_corr_cols = [\\n\\t'{valid_str_corr_cols}'\\n]\\n\"",
            "            \"dummies = pd.get_dummies(corr_data, str_corr_cols)\\n\"",
            "            \"corr_data.loc[:, dummies.columns] = dummies\\n\"",
            "        ).format(valid_str_corr_cols=\"', '\".join(valid_str_corr_cols))",
            "    else:",
            "        data = data[valid_corr_cols]",
            "",
            "    corr_cols_str = \"'\\n\\t'\".join(",
            "        [\"', '\".join(chunk) for chunk in divide_chunks(valid_corr_cols, 8)]",
            "    )",
            "",
            "    pps_data = None",
            "    if is_pps:",
            "        code = build_code_export(data_id, imports=\"import ppscore\\n\")",
            "        code.append(",
            "            (",
            "                \"corr_cols = [\\n\"",
            "                \"\\t'{corr_cols}'\\n\"",
            "                \"]\\n\"",
            "                \"corr_data = df[corr_cols]\\n\"",
            "                \"{str_encodings}\"",
            "                \"corr_data = ppscore.matrix(corr_data)\\n\"",
            "            ).format(corr_cols=corr_cols_str, str_encodings=str_encodings_code)",
            "        )",
            "",
            "        data, pps_data = get_ppscore_matrix(data[valid_corr_cols])",
            "    else:",
            "        data, matrix_code = correlations.build_matrix(",
            "            data_id,",
            "            data,",
            "            valid_corr_cols,",
            "            {\"corr_cols\": corr_cols_str, \"str_encodings\": str_encodings_code},",
            "        )",
            "        code = [matrix_code]",
            "",
            "    code.append(",
            "        \"corr_data.index.name = str('column')\\ncorr_data = corr_data.reset_index()\"",
            "    )",
            "    code = \"\\n\".join(code)",
            "    data.index.name = str(\"column\")",
            "    if image:",
            "        return build_correlations_matrix_image(",
            "            data,",
            "            is_pps,",
            "            valid_corr_cols,",
            "            valid_str_corr_cols,",
            "            valid_date_cols,",
            "            dummy_col_mappings,",
            "            pps_data,",
            "            code,",
            "        )",
            "    return (",
            "        valid_corr_cols,",
            "        valid_str_corr_cols,",
            "        valid_date_cols,",
            "        dummy_col_mappings,",
            "        pps_data,",
            "        code,",
            "        data,",
            "    )",
            "",
            "",
            "@dtale.route(\"/correlations/<data_id>\")",
            "@exception_decorator",
            "def get_correlations(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which gathers Pearson correlations against all combinations of columns with",
            "    numeric data using :meth:`pandas:pandas.DataFrame.corr`",
            "",
            "    On large datasets with no :attr:`numpy:numpy.nan` data this code will use :meth:`numpy:numpy.corrcoef`",
            "    for speed purposes",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :returns: JSON {",
            "        data: [{column: col1, col1: 1.0, col2: 0.99, colN: 0.45},...,{column: colN, col1: 0.34, col2: 0.88, colN: 1.0}],",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    is_pps = get_bool_arg(request, \"pps\")",
            "    image = get_bool_arg(request, \"image\")",
            "    matrix_data = build_correlations_matrix(",
            "        data_id,",
            "        is_pps=is_pps,",
            "        encode_strings=get_bool_arg(request, \"encodeStrings\"),",
            "        image=image,",
            "    )",
            "    (",
            "        valid_corr_cols,",
            "        valid_str_corr_cols,",
            "        valid_date_cols,",
            "        dummy_col_mappings,",
            "        pps_data,",
            "        code,",
            "        df_or_image,",
            "    ) = matrix_data",
            "    if image:",
            "        fname = \"{}.png\".format(\"predictive_power_score\" if is_pps else \"correlations\")",
            "        return send_file(df_or_image, fname, \"image/png\")",
            "",
            "    data = df_or_image.reset_index()",
            "    col_types = grid_columns(data)",
            "    f = grid_formatter(col_types, nan_display=None)",
            "    return jsonify(",
            "        data=f.format_dicts(data.itertuples()),",
            "        dates=valid_date_cols,",
            "        strings=valid_str_corr_cols,",
            "        dummyColMappings=dummy_col_mappings,",
            "        code=code,",
            "        pps=pps_data,",
            "    )",
            "",
            "",
            "@dtale.route(\"/corr-analysis/<data_id>\")",
            "@exception_decorator",
            "def get_corr_analysis(data_id):",
            "    column_name, max_score, corrs, ranks = correlations.get_analysis(data_id)",
            "    return jsonify(",
            "        column_name=column_name, max_score=max_score, corrs=corrs, ranks=ranks",
            "    )",
            "",
            "",
            "@dtale.route(\"/chart-data/<data_id>\")",
            "@exception_decorator",
            "def get_chart_data(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which builds data associated with a chart.js chart",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :param x: string from flask.request.args['x'] column to be used as x-axis of chart",
            "    :param y: string from flask.request.args['y'] column to be used as y-axis of chart",
            "    :param group: string from flask.request.args['group'] comma-separated string of columns to group chart data by",
            "    :param agg: string from flask.request.args['agg'] points to a specific function that can be applied to",
            "                :func: pandas.core.groupby.DataFrameGroupBy.  Possible values are: count, first, last mean,",
            "                median, min, max, std, var, mad, prod, sum",
            "    :returns: JSON {",
            "        data: {",
            "            series1: { x: [x1, x2, ..., xN], y: [y1, y2, ..., yN] },",
            "            series2: { x: [x1, x2, ..., xN], y: [y1, y2, ..., yN] },",
            "            ...,",
            "            seriesN: { x: [x1, x2, ..., xN], y: [y1, y2, ..., yN] },",
            "        },",
            "        min: minY,",
            "        max: maxY,",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, get_str_arg(request, \"query\")),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    x = get_str_arg(request, \"x\")",
            "    y = get_json_arg(request, \"y\")",
            "    group_col = get_json_arg(request, \"group\")",
            "    agg = get_str_arg(request, \"agg\")",
            "    allow_duplicates = get_bool_arg(request, \"allowDupes\")",
            "    window = get_int_arg(request, \"rollingWin\")",
            "    comp = get_str_arg(request, \"rollingComp\")",
            "    data, code = build_base_chart(",
            "        data,",
            "        x,",
            "        y,",
            "        group_col=group_col,",
            "        agg=agg,",
            "        allow_duplicates=allow_duplicates,",
            "        rolling_win=window,",
            "        rolling_comp=comp,",
            "    )",
            "    data[\"success\"] = True",
            "    return jsonify(data)",
            "",
            "",
            "def get_ppscore(df, col1, col2):",
            "    if not PY3:",
            "        return None",
            "    try:",
            "        import dtale.ppscore as ppscore",
            "",
            "        pps = ppscore.score(df, col1, col2)",
            "        pps[\"model\"] = pps[\"model\"].__str__()",
            "        pps[\"ppscore\"] = float(pps[\"ppscore\"])",
            "        pps[\"baseline_score\"] = float(pps[\"baseline_score\"])",
            "        pps[\"model_score\"] = float(pps[\"model_score\"])",
            "        return pps",
            "    except BaseException:",
            "        return None",
            "",
            "",
            "def get_ppscore_matrix(df):",
            "    if not PY3:",
            "        return [], None",
            "    try:",
            "        import dtale.ppscore as ppscore",
            "",
            "        pps_data = ppscore.matrix(df)",
            "        data = (",
            "            pps_data[[\"x\", \"y\", \"ppscore\"]].set_index([\"x\", \"y\"]).unstack()[\"ppscore\"]",
            "        )",
            "",
            "        # additional PPS display",
            "        pps_data.loc[:, \"model\"] = pps_data[\"model\"].astype(\"str\")",
            "        pps_data = format_grid(pps_data)",
            "        pps_data = pps_data[\"results\"]",
            "        return data, pps_data",
            "    except BaseException:",
            "        return [], None",
            "",
            "",
            "def update_df_for_encoded_strings(df, dummy_cols, cols, code):",
            "    if not dummy_cols:",
            "        return df",
            "    dummy_kwargs = {}",
            "    if pandas_util.is_pandas2():",
            "        dummy_kwargs[\"dtype\"] = \"int\"",
            "    dummies = pd.get_dummies(df[dummy_cols], columns=dummy_cols, **dummy_kwargs)",
            "    dummies = dummies[[c for c in dummies.columns if c in cols]]",
            "    df[dummies.columns] = dummies",
            "",
            "    code.append(",
            "        (",
            "            \"dummy_cols = ['{}']\\n\"",
            "            \"dummies = pd.get_dummies(df[dummy_cols], columns=dummy_cols)\\n\"",
            "            \"final_cols = ['{}']\\n\"",
            "            \"dummies = dummies[[c for c in dummies.columns if c in final_cols]]\\n\"",
            "            \"df.loc[:, dummies.columns] = dummies\"",
            "        ).format(\"', '\".join(dummy_cols), \"', '\".join(cols))",
            "    )",
            "    return df",
            "",
            "",
            "@dtale.route(\"/correlations-ts/<data_id>\")",
            "@exception_decorator",
            "def get_correlations_ts(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns timeseries of Pearson correlations of two columns with numeric data",
            "    using :meth:`pandas:pandas.DataFrame.corr`",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param cols: comma-separated string from flask.request.args['cols'] containing names of two columns in dataframe",
            "    :param dateCol: string from flask.request.args['dateCol'] with name of date-type column in dateframe for timeseries",
            "    :returns: JSON {",
            "        data: {:col1:col2: {data: [{corr: 0.99, date: 'YYYY-MM-DD'},...], max: 0.99, min: 0.99}",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    cols = get_json_arg(request, \"cols\")",
            "    [col1, col2] = cols",
            "    date_col = get_str_arg(request, \"dateCol\")",
            "    rolling = get_bool_arg(request, \"rolling\")",
            "    rolling_window = get_int_arg(request, \"rollingWindow\")",
            "    min_periods = get_int_arg(request, \"minPeriods\")",
            "    dummy_cols = get_json_arg(request, \"dummyCols\", [])",
            "",
            "    code = build_code_export(data_id)",
            "    pps = get_ppscore(data, col1, col2)",
            "",
            "    if rolling:",
            "        data = data[",
            "            [c for c in data.columns if c in [date_col, col1, col2] + dummy_cols]",
            "        ]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        data = data.set_index(date_col)",
            "        rolling_kwargs = {}",
            "        if min_periods is not None:",
            "            rolling_kwargs[\"min_periods\"] = min_periods",
            "        data = (",
            "            data[[col1, col2]]",
            "            .rolling(rolling_window, **rolling_kwargs)",
            "            .corr()",
            "            .reset_index()",
            "        )",
            "        data = data.dropna()",
            "        data = data[data[\"level_1\"] == col1][[date_col, col2]]",
            "        code.append(",
            "            (",
            "                \"corr_ts = df[['{date_col}', '{col1}', '{col2}']].set_index('{date_col}')\\n\"",
            "                \"corr_ts = corr_ts[['{col1}', '{col2}']].rolling({rolling_window}, min_periods=min_periods).corr()\\n\"",
            "                \"corr_ts = corr_ts.reset_index().dropna()\\n\"",
            "                \"corr_ts = corr_ts[corr_ts['level_1'] == '{col1}'][['{date_col}', '{col2}']]\"",
            "            ).format(",
            "                col1=col1, col2=col2, date_col=date_col, rolling_window=rolling_window",
            "            )",
            "        )",
            "    else:",
            "        data = data[[c for c in data.columns if c in [date_col] + cols + dummy_cols]]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        data = data.groupby(date_col)[cols].corr(method=\"pearson\")",
            "        data.index.names = [\"date\", \"column\"]",
            "        data = data.reset_index()",
            "        data = data[data.column == col1][[\"date\", col2]]",
            "        code.append(",
            "            (",
            "                \"corr_ts = df.groupby('{date_col}')['{cols}'].corr(method='pearson')\\n\"",
            "                \"corr_ts.index.names = ['date', 'column']\\n\"",
            "                \"corr_ts = corr_ts[corr_ts.column == '{col1}'][['date', '{col2}']]\\n\"",
            "            ).format(col1=col1, col2=col2, date_col=date_col, cols=\"', '\".join(cols))",
            "        )",
            "        if rolling_window:",
            "            data = data.set_index(\"date\")",
            "            rolling_kwargs = {}",
            "            if min_periods is not None:",
            "                rolling_kwargs[\"min_periods\"] = min_periods",
            "            data = (",
            "                data[[col2]]",
            "                .rolling(rolling_window, **rolling_kwargs)",
            "                .mean()",
            "                .reset_index()",
            "            )",
            "            data = data.dropna()",
            "            code.append(",
            "                (",
            "                    \"corr_ts = corr_ts.set_index('date')\\n\"",
            "                    \"corr_ts = corr_ts[['{col}']].rolling({rolling_window}, min_periods={min_periods}).mean()\\n\"",
            "                    \"corr_ts = corr_ts.reset_index().dropna()\"",
            "                ).format(",
            "                    col=col2, rolling_window=rolling_window, min_periods=min_periods",
            "                )",
            "            )",
            "",
            "    data.columns = [\"date\", \"corr\"]",
            "    code.append(\"corr_ts.columns = ['date', 'corr']\")",
            "    return_data, _code = build_base_chart(data.fillna(0), \"date\", \"corr\", agg=\"raw\")",
            "    return_data[\"success\"] = True",
            "    return_data[\"code\"] = \"\\n\".join(code)",
            "    return_data[\"pps\"] = pps",
            "    return jsonify(return_data)",
            "",
            "",
            "@dtale.route(\"/scatter/<data_id>\")",
            "@exception_decorator",
            "def get_scatter(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns data used in correlation of two columns for scatter chart",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param cols: comma-separated string from flask.request.args['cols'] containing names of two columns in dataframe",
            "    :param dateCol: string from flask.request.args['dateCol'] with name of date-type column in dateframe for timeseries",
            "    :param date: string from flask.request.args['date'] date value in dateCol to filter dataframe to",
            "    :returns: JSON {",
            "        data: [{col1: 0.123, col2: 0.123, index: 1},...,{col1: 0.123, col2: 0.123, index: N}],",
            "        stats: {",
            "        stats: {",
            "            correlated: 50,",
            "            only_in_s0: 1,",
            "            only_in_s1: 2,",
            "            pearson: 0.987,",
            "            spearman: 0.879,",
            "        }",
            "        x: col1,",
            "        y: col2",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    cols = get_json_arg(request, \"cols\")",
            "    dummy_cols = get_json_arg(request, \"dummyCols\", [])",
            "    date_index = get_int_arg(request, \"index\")",
            "    date_col = get_str_arg(request, \"dateCol\")",
            "    rolling = get_bool_arg(request, \"rolling\")",
            "",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    idx_col = str(\"_corr_index\")",
            "    y_cols = [cols[1], idx_col]",
            "    code = build_code_export(data_id)",
            "    selected_date = None",
            "    if rolling:",
            "        data = data[[c for c in data.columns if c in [date_col] + cols + dummy_cols]]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        window = get_int_arg(request, \"window\")",
            "        min_periods = get_int_arg(request, \"minPeriods\", default=0)",
            "        dates = data[date_col].sort_values().unique()",
            "        date_index = min(date_index + max(min_periods - 1, 1), len(dates) - 1)",
            "        selected_date = dates[date_index]",
            "        idx = min(data[data[date_col] == selected_date].index) + 1",
            "        selected_date = json_date(selected_date, nan_display=None)",
            "        selected_date = \"{} thru {}\".format(",
            "            json_date(dates[max(date_index - (window - 1), 0)]), selected_date",
            "        )",
            "        data = data.iloc[max(idx - window, 0) : idx]",
            "        data = data[cols + [date_col]].dropna(how=\"any\")",
            "        y_cols.append(date_col)",
            "        code.append(",
            "            (",
            "                \"idx = min(df[df['{date_col}'] == '{date}'].index) + 1\\n\"",
            "                \"scatter_data = scatter_data.iloc[max(idx - {window}, 0):idx]\\n\"",
            "                \"scatter_data = scatter_data['{cols}'].dropna(how='any')\"",
            "            ).format(",
            "                date_col=date_col,",
            "                date=selected_date,",
            "                window=window,",
            "                cols=\"', '\".join(sorted(list(set(cols)) + [date_col])),",
            "            )",
            "        )",
            "    else:",
            "        selected_cols = (",
            "            ([date_col] if date_index is not None else []) + cols + dummy_cols",
            "        )",
            "        data = data[[c for c in data.columns if c in selected_cols]]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        if date_index is not None:",
            "            selected_date = data[date_col].sort_values().unique()[date_index]",
            "            data = data[data[date_col] == selected_date]",
            "            selected_date = json_date(selected_date, nan_display=None)",
            "        data = data[cols].dropna(how=\"any\")",
            "        code.append(",
            "            (",
            "                \"scatter_data = df[df['{date_col}'] == '{date}']\"",
            "                if date_index is not None",
            "                else \"scatter_data = df\"",
            "            ).format(date_col=date_col, date=selected_date)",
            "        )",
            "        code.append(",
            "            \"scatter_data = scatter_data['{cols}'].dropna(how='any')\".format(",
            "                cols=\"', '\".join(cols)",
            "            )",
            "        )",
            "",
            "    data[idx_col] = data.index",
            "    [col1, col2] = cols",
            "    s0 = data[col1]",
            "    s1 = data[col2]",
            "    pearson = s0.corr(s1, method=\"pearson\")",
            "    spearman = s0.corr(s1, method=\"spearman\")",
            "    pps = get_ppscore(data, col1, col2)",
            "    stats = dict(",
            "        pearson=\"N/A\" if pd.isnull(pearson) else pearson,",
            "        spearman=\"N/A\" if pd.isnull(spearman) else spearman,",
            "        pps=pps,",
            "        correlated=len(data),",
            "        only_in_s0=len(data[data[col1].isnull()]),",
            "        only_in_s1=len(data[data[col2].isnull()]),",
            "    )",
            "    code.append(",
            "        (",
            "            \"scatter_data['{idx_col}'] = scatter_data.index\\n\"",
            "            \"s0 = scatter_data['{col1}']\\n\"",
            "            \"s1 = scatter_data['{col2}']\\n\"",
            "            \"pearson = s0.corr(s1, method='pearson')\\n\"",
            "            \"spearman = s0.corr(s1, method='spearman')\\n\"",
            "            \"\\nimport ppscore\\n\\n\"",
            "            \"pps = ppscore.score(data, '{col1}', '{col2}')\\n\"",
            "            \"only_in_s0 = len(scatter_data[scatter_data['{col1}'].isnull()])\\n\"",
            "            \"only_in_s1 = len(scatter_data[scatter_data['{col2}'].isnull()])\"",
            "        ).format(col1=col1, col2=col2, idx_col=idx_col)",
            "    )",
            "",
            "    max_points = global_state.get_chart_settings()[\"scatter_points\"]",
            "    if len(data) > max_points:",
            "        return jsonify(",
            "            stats=stats,",
            "            code=\"\\n\".join(code),",
            "            error=\"Dataset exceeds {:,} records, cannot render scatter. Please apply filter...\".format(",
            "                max_points",
            "            ),",
            "            traceback=CHART_POINTS_LIMIT,",
            "        )",
            "    data, _code = build_base_chart(data, cols[0], y_cols, allow_duplicates=True)",
            "    data[\"x\"] = cols[0]",
            "    data[\"y\"] = cols[1]",
            "    data[\"stats\"] = stats",
            "    data[\"code\"] = \"\\n\".join(code)",
            "    data[\"date\"] = \" for {}\".format(selected_date) if selected_date else \"\"",
            "    return jsonify(data)",
            "",
            "",
            "def build_context_variables(data_id, new_context_vars=None):",
            "    \"\"\"",
            "    Build and return the dictionary of context variables associated with a process.",
            "    If the names of any new variables are not formatted properly, an exception will be raised.",
            "    New variables will overwrite the values of existing variables if they share the same name.",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param new_context_vars: dictionary of name, value pairs for new context variables",
            "    :type new_context_vars: dict, optional",
            "    :returns: dict of the context variables for this process",
            "    :rtype: dict",
            "    \"\"\"",
            "    if new_context_vars:",
            "        for name, value in new_context_vars.items():",
            "            if not isinstance(name, string_types):",
            "                raise SyntaxError(",
            "                    \"{}, context variables must be a valid string\".format(name)",
            "                )",
            "            elif not name.replace(\"_\", \"\").isalnum():",
            "                raise SyntaxError(",
            "                    \"{}, context variables can only contain letters, digits, or underscores\".format(",
            "                        name",
            "                    )",
            "                )",
            "            elif name.startswith(\"_\"):",
            "                raise SyntaxError(",
            "                    \"{}, context variables can not start with an underscore\".format(",
            "                        name",
            "                    )",
            "                )",
            "",
            "    return dict_merge(global_state.get_context_variables(data_id), new_context_vars)",
            "",
            "",
            "@dtale.route(\"/filter-info/<data_id>\")",
            "@exception_decorator",
            "def get_filter_info(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns a view-only version of the query, column filters & context variables",
            "    to the front end.",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: JSON",
            "    \"\"\"",
            "",
            "    def value_as_str(value):",
            "        \"\"\"Convert values into a string representation that can be shown to the user in the front-end.\"\"\"",
            "        return str(value)[:1000]",
            "",
            "    ctxt_vars = global_state.get_context_variables(data_id) or {}",
            "    ctxt_vars = [dict(name=k, value=value_as_str(v)) for k, v in ctxt_vars.items()]",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    curr_settings = {",
            "        k: v",
            "        for k, v in curr_settings.items()",
            "        if k",
            "        in [",
            "            \"query\",",
            "            \"columnFilters\",",
            "            \"outlierFilters\",",
            "            \"predefinedFilters\",",
            "            \"invertFilter\",",
            "            \"highlightFilter\",",
            "        ]",
            "    }",
            "    return jsonify(contextVars=ctxt_vars, success=True, **curr_settings)",
            "",
            "",
            "@dtale.route(\"/xarray-coordinates/<data_id>\")",
            "@exception_decorator",
            "def get_xarray_coords(data_id):",
            "    ds = global_state.get_dataset(data_id)",
            "",
            "    def _format_dim(coord, count):",
            "        return dict(name=coord, count=count, dtype=ds.coords[coord].dtype.name)",
            "",
            "    coord_data = [_format_dim(coord, count) for coord, count in ds.coords.dims.items()]",
            "    return jsonify(data=coord_data)",
            "",
            "",
            "@dtale.route(\"/xarray-dimension-values/<data_id>/<dim>\")",
            "@exception_decorator",
            "def get_xarray_dimension_values(data_id, dim):",
            "    ds = global_state.get_dataset(data_id)",
            "    dim_entries = ds.coords[dim].data",
            "    dim = pd.DataFrame({\"value\": dim_entries})",
            "    dim_f, _ = build_formatters(dim)",
            "    return jsonify(data=dim_f.format_dicts(dim.itertuples()))",
            "",
            "",
            "@dtale.route(\"/update-xarray-selection/<data_id>\")",
            "@exception_decorator",
            "def update_xarray_selection(data_id):",
            "    ds = global_state.get_dataset(data_id)",
            "    selection = get_json_arg(request, \"selection\") or {}",
            "    df = convert_xarray_to_dataset(ds, **selection)",
            "    startup(data=df, data_id=data_id, ignore_duplicate=True)",
            "    global_state.set_dataset_dim(data_id, selection)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/to-xarray/<data_id>\")",
            "@exception_decorator",
            "def to_xarray(data_id):",
            "    df = global_state.get_data(data_id)",
            "    index_cols = get_json_arg(request, \"index\")",
            "    ds = df.set_index(index_cols).to_xarray()",
            "    startup(data=ds, data_id=data_id, ignore_duplicate=True)",
            "    curr_settings = global_state.get_settings(data_id)",
            "    startup_code = \"df = df.set_index(['{index}']).to_xarray()\".format(",
            "        index=\"', '\".join(index_cols)",
            "    )",
            "    global_state.set_settings(",
            "        data_id, dict_merge(curr_settings, dict(startup_code=startup_code))",
            "    )",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/code-export/<data_id>\")",
            "@exception_decorator",
            "def get_code_export(data_id):",
            "    code = build_code_export(data_id)",
            "    return jsonify(code=\"\\n\".join(code), success=True)",
            "",
            "",
            "def build_chart_filename(chart_type, ext=\"html\"):",
            "    return \"{}_export_{}.{}\".format(",
            "        chart_type, json_timestamp(pd.Timestamp(\"now\")), ext",
            "    )",
            "",
            "",
            "def send_file(output, filename, content_type):",
            "    resp = make_response(output)",
            "    resp.headers[\"Content-Disposition\"] = \"attachment; filename=%s\" % filename",
            "    resp.headers[\"Content-Type\"] = content_type",
            "    return resp",
            "",
            "",
            "@dtale.route(\"/chart-export/<data_id>\")",
            "@exception_decorator",
            "def chart_export(data_id):",
            "    export_type = get_str_arg(request, \"export_type\")",
            "    params = chart_url_params(request.args.to_dict())",
            "    if export_type == \"png\":",
            "        output = export_png(data_id, params)",
            "        filename = build_chart_filename(params[\"chart_type\"], ext=\"png\")",
            "        content_type = \"image/png\"",
            "    else:",
            "        output = export_chart(data_id, params)",
            "        filename = build_chart_filename(params[\"chart_type\"])",
            "        content_type = \"text/html\"",
            "    return send_file(output, filename, content_type)",
            "",
            "",
            "@dtale.route(\"/chart-export-all/<data_id>\")",
            "@exception_decorator",
            "def chart_export_all(data_id):",
            "    params = chart_url_params(request.args.to_dict())",
            "    params[\"export_all\"] = True",
            "    output = export_chart(data_id, params)",
            "    filename = build_chart_filename(params[\"chart_type\"])",
            "    content_type = \"text/html\"",
            "    return send_file(output, filename, content_type)",
            "",
            "",
            "@dtale.route(\"/chart-csv-export/<data_id>\")",
            "@exception_decorator",
            "def chart_csv_export(data_id):",
            "    params = chart_url_params(request.args.to_dict())",
            "    csv_buffer = export_chart_data(data_id, params)",
            "    filename = build_chart_filename(params[\"chart_type\"], ext=\"csv\")",
            "    return send_file(csv_buffer.getvalue(), filename, \"text/csv\")",
            "",
            "",
            "@dtale.route(\"/cleanup-datasets\")",
            "@exception_decorator",
            "def cleanup_datasets():",
            "    data_ids = get_str_arg(request, \"dataIds\")",
            "    data_ids = (data_ids or \"\").split(\",\")",
            "    for data_id in data_ids:",
            "        global_state.cleanup(data_id)",
            "    return jsonify(success=True)",
            "",
            "",
            "def load_new_data(df, startup_code, name=None, return_id=False, settings=None):",
            "    instance = startup(data=df, name=name, ignore_duplicate=True)",
            "    curr_settings = global_state.get_settings(instance._data_id)",
            "    global_state.set_settings(",
            "        instance._data_id,",
            "        dict_merge(curr_settings, dict(startup_code=startup_code, **(settings or {}))),",
            "    )",
            "    if return_id:",
            "        return instance._data_id",
            "    return jsonify(success=True, data_id=instance._data_id)",
            "",
            "",
            "def handle_excel_upload(dfs):",
            "    sheet_names = list(dfs.keys())",
            "    data_ids = []",
            "    for sheet_name in sheet_names:",
            "        df, code = dfs[sheet_name]",
            "        if len(sheet_names) == 1:",
            "            return load_new_data(df, code, name=sheet_name)",
            "        data_id = load_new_data(df, code, name=sheet_name, return_id=True)",
            "        data_ids.append(dict(name=sheet_name, dataId=data_id))",
            "    return jsonify(dict(sheets=data_ids, success=True))",
            "",
            "",
            "UPLOAD_SEPARATORS = {\"comma\": \",\", \"tab\": \"\\t\", \"colon\": \":\", \"pipe\": \"|\"}",
            "",
            "",
            "def build_csv_kwargs(request):",
            "    # Set engine to python to auto detect delimiter...",
            "    kwargs = {\"sep\": None}",
            "    sep_type = request.form.get(\"separatorType\")",
            "",
            "    if sep_type in UPLOAD_SEPARATORS:",
            "        kwargs[\"sep\"] = UPLOAD_SEPARATORS[sep_type]",
            "    elif sep_type == \"custom\" and request.form.get(\"separator\"):",
            "        kwargs[\"sep\"] = request.form[\"separator\"]",
            "        kwargs[\"sep\"] = str(kwargs[\"sep\"]) if PY3 else kwargs[\"sep\"].encode(\"utf8\")",
            "",
            "    if \"header\" in request.form:",
            "        kwargs[\"header\"] = 0 if request.form[\"header\"] == \"true\" else None",
            "",
            "    return kwargs",
            "",
            "",
            "@dtale.route(\"/upload\", methods=[\"POST\"])",
            "@exception_decorator",
            "def upload():",
            "    if not request.files:",
            "        raise Exception(\"No file data loaded!\")",
            "    for filename in request.files:",
            "        contents = request.files[filename]",
            "        _, ext = os.path.splitext(filename)",
            "        if ext in [\".csv\", \".tsv\"]:",
            "            kwargs = build_csv_kwargs(request)",
            "            df = pd.read_csv(",
            "                StringIO(contents.read().decode()), engine=\"python\", **kwargs",
            "            )",
            "            return load_new_data(",
            "                df, \"df = pd.read_csv('{}', engine='python', sep=None)\".format(filename)",
            "            )",
            "        if ext in [\".xls\", \".xlsx\"]:",
            "            engine = \"xlrd\" if ext == \".xls\" else \"openpyxl\"",
            "            dfs = pd.read_excel(contents, sheet_name=None, engine=engine)",
            "",
            "            def build_xls_code(sheet_name):",
            "                return \"df = pd.read_excel('{}', sheet_name='{}', engine='{}')\".format(",
            "                    filename, sheet_name, engine",
            "                )",
            "",
            "            dfs = {",
            "                sheet_name: (df, build_xls_code(sheet_name))",
            "                for sheet_name, df in dfs.items()",
            "            }",
            "            return handle_excel_upload(dfs)",
            "        if \"parquet\" in filename:",
            "            df = pd.read_parquet(contents)",
            "            return load_new_data(df, \"df = pd.read_parquet('{}')\".format(filename))",
            "        raise Exception(\"File type of {} is not supported!\".format(ext))",
            "",
            "",
            "@dtale.route(\"/web-upload\")",
            "@exception_decorator",
            "def web_upload():",
            "    from dtale.cli.loaders.csv_loader import loader_func as load_csv",
            "    from dtale.cli.loaders.json_loader import loader_func as load_json",
            "    from dtale.cli.loaders.excel_loader import load_file as load_excel",
            "    from dtale.cli.loaders.parquet_loader import loader_func as load_parquet",
            "",
            "    if not global_state.get_app_settings().get(\"enable_web_uploads\", False):",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Web uploads not enabled! Web uploads are vulnerable to blind server side request forgery, please \"",
            "                    \"only use in trusted environments.\"",
            "                ),",
            "            )",
            "        )",
            "",
            "    data_type = get_str_arg(request, \"type\")",
            "    url = get_str_arg(request, \"url\")",
            "    proxy = get_str_arg(request, \"proxy\")",
            "    if data_type == \"csv\":",
            "        df = load_csv(path=url, proxy=proxy)",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.csv_loader import loader_func as load_csv\\n\\n\"",
            "            \"df = load_csv(path='{url}'{proxy})\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    elif data_type == \"tsv\":",
            "        df = load_csv(path=url, proxy=proxy, delimiter=\"\\t\")",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.csv_loader import loader_func as load_csv\\n\\n\"",
            "            \"df = load_csv(path='{url}'{proxy}, delimiter='\\t')\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    elif data_type == \"json\":",
            "        df = load_json(path=url, proxy=proxy)",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.json_loader import loader_func as load_json\\n\\n\"",
            "            \"df = load_json(path='{url}'{proxy})\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    elif data_type == \"excel\":",
            "        dfs = load_excel(path=url, proxy=proxy)",
            "",
            "        def build_xls_code(sheet_name):",
            "            return (",
            "                \"from dtale.cli.loaders.excel_loader import load_file as load_excel\\n\\n\"",
            "                \"df = load_excel(sheet_name='{sheet_name}', path='{url}'{proxy})\"",
            "            ).format(",
            "                sheet_name=sheet_name,",
            "                url=url,",
            "                proxy=\", '{}'\".format(proxy) if proxy else \"\",",
            "            )",
            "",
            "        dfs = {",
            "            sheet_name: (df, build_xls_code(sheet_name))",
            "            for sheet_name, df in dfs.items()",
            "        }",
            "        return handle_excel_upload(dfs)",
            "    elif data_type == \"parquet\":",
            "        df = load_parquet(path=url)",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.parquet_loader import loader_func as load_parquet\\n\\n\"",
            "            \"df = load_parquet(path='{url}'{proxy})\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    return load_new_data(df, startup_code)",
            "",
            "",
            "@dtale.route(\"/datasets\")",
            "@exception_decorator",
            "def dataset_upload():",
            "    dataset = get_str_arg(request, \"dataset\")",
            "    startup_code = \"from dtale.datasets import {dataset}\\n\\n\" \"df = {dataset}()\".format(",
            "        dataset=dataset",
            "    )",
            "    df, settings = getattr(datasets, dataset)()",
            "    return load_new_data(df, startup_code, settings=settings)",
            "",
            "",
            "@dtale.route(\"/build-column-copy/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def build_column_text(data_id):",
            "    columns = request.json.get(\"columns\")",
            "    columns = json.loads(columns)",
            "",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    return data[columns].to_csv(index=False, sep=\"\\t\", header=False)",
            "",
            "",
            "@dtale.route(\"/build-row-copy/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def build_row_text(data_id):",
            "    start, end, rows, columns = (",
            "        request.json.get(p) for p in [\"start\", \"end\", \"rows\", \"columns\"]",
            "    )",
            "    columns = json.loads(columns)",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    if rows:",
            "        rows = json.loads(rows)",
            "        data = data.iloc[rows, :]",
            "    else:",
            "        start = int(start)",
            "        end = int(end)",
            "        data = data.iloc[(start - 1) : end, :]",
            "    return data[columns].to_csv(index=False, sep=\"\\t\", header=False)",
            "",
            "",
            "@dtale.route(\"/network-data/<data_id>\")",
            "@exception_decorator",
            "def network_data(data_id):",
            "    df = global_state.get_data(data_id)",
            "    to_col = get_str_arg(request, \"to\")",
            "    from_col = get_str_arg(request, \"from\")",
            "    group = get_str_arg(request, \"group\", \"\")",
            "    color = get_str_arg(request, \"color\", \"\")",
            "    weight = get_str_arg(request, \"weight\")",
            "",
            "    nodes = list(df[to_col].unique())",
            "    nodes += list(df[~df[from_col].isin(nodes)][from_col].unique())",
            "    nodes = sorted(nodes)",
            "    nodes = {node: node_id for node_id, node in enumerate(nodes, 1)}",
            "",
            "    edge_cols = [to_col, from_col]",
            "    if weight:",
            "        edge_cols.append(weight)",
            "",
            "    edges = df[[to_col, from_col]].applymap(nodes.get)",
            "    edges.columns = [\"to\", \"from\"]",
            "    if weight:",
            "        edges.loc[:, \"value\"] = df[weight]",
            "    edge_f = grid_formatter(grid_columns(edges), nan_display=\"nan\")",
            "    edges = edge_f.format_dicts(edges.itertuples())",
            "",
            "    def build_mapping(col):",
            "        if col:",
            "            return df[[from_col, col]].set_index(from_col)[col].astype(\"str\").to_dict()",
            "        return {}",
            "",
            "    group = build_mapping(group)",
            "    color = build_mapping(color)",
            "    groups = {}",
            "",
            "    def build_group(node, node_id):",
            "        group_val = group.get(node, \"N/A\")",
            "        groups[group_val] = node_id",
            "        return group_val",
            "",
            "    nodes = [",
            "        dict(",
            "            id=node_id,",
            "            label=node,",
            "            group=build_group(node, node_id),",
            "            color=color.get(node),",
            "        )",
            "        for node, node_id in nodes.items()",
            "    ]",
            "    return jsonify(dict(nodes=nodes, edges=edges, groups=groups, success=True))",
            "",
            "",
            "@dtale.route(\"/network-analysis/<data_id>\")",
            "@exception_decorator",
            "def network_analysis(data_id):",
            "    df = global_state.get_data(data_id)",
            "    to_col = get_str_arg(request, \"to\")",
            "    from_col = get_str_arg(request, \"from\")",
            "    weight = get_str_arg(request, \"weight\")",
            "",
            "    G = nx.Graph()",
            "    max_edge, min_edge, avg_weight = (None, None, None)",
            "    if weight:",
            "        G.add_weighted_edges_from(",
            "            [tuple(x) for x in df[[to_col, from_col, weight]].values]",
            "        )",
            "        sorted_edges = sorted(",
            "            G.edges(data=True), key=lambda x: x[2][\"weight\"], reverse=True",
            "        )",
            "        max_edge = sorted_edges[0]",
            "        min_edge = sorted_edges[-1]",
            "        avg_weight = df[weight].mean()",
            "    else:",
            "        G.add_edges_from([tuple(x) for x in df[[to_col, from_col]].values])",
            "",
            "    most_connected_node = max(dict(G.degree()).items(), key=lambda x: x[1])",
            "    return_data = {",
            "        \"node_ct\": len(G),",
            "        \"triangle_ct\": int(sum(nx.triangles(G).values()) / 3),",
            "        \"most_connected_node\": \"{} (Connections: {})\".format(*most_connected_node),",
            "        \"leaf_ct\": sum((1 for edge, degree in dict(G.degree()).items() if degree == 1)),",
            "        \"edge_ct\": sum(dict(G.degree()).values()),",
            "        \"max_edge\": (",
            "            None",
            "            if max_edge is None",
            "            else \"{} (source: {}, target: {})\".format(",
            "                max_edge[-1][\"weight\"], max_edge[0], max_edge[1]",
            "            )",
            "        ),",
            "        \"min_edge\": (",
            "            None",
            "            if min_edge is None",
            "            else \"{} (source: {}, target: {})\".format(",
            "                min_edge[-1][\"weight\"], min_edge[0], min_edge[1]",
            "            )",
            "        ),",
            "        \"avg_weight\": json_float(avg_weight),",
            "    }",
            "    return jsonify(dict(data=return_data, success=True))",
            "",
            "",
            "@dtale.route(\"/shortest-path/<data_id>\")",
            "@exception_decorator",
            "def shortest_path(data_id):",
            "    df = global_state.get_data(data_id)",
            "    to_col = get_str_arg(request, \"to\")",
            "    from_col = get_str_arg(request, \"from\")",
            "    start_val = get_str_arg(request, \"start\")",
            "    end_val = get_str_arg(request, \"end\")",
            "",
            "    G = nx.Graph()",
            "    G.add_edges_from([tuple(x) for x in df[[to_col, from_col]].values])",
            "    shortest_path = nx.shortest_path(G, source=start_val, target=end_val)",
            "    return jsonify(dict(data=shortest_path, success=True))",
            "",
            "",
            "@dtale.route(\"/sorted-sequential-diffs/<data_id>\")",
            "@exception_decorator",
            "def get_sorted_sequential_diffs(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    sort = get_str_arg(request, \"sort\")",
            "    df = global_state.get_data(data_id)",
            "    metrics, _ = build_sequential_diffs(df[column], column, sort=sort)",
            "    return jsonify(metrics)",
            "",
            "",
            "@dtale.route(\"/merge\", methods=[\"POST\"])",
            "@exception_decorator",
            "def build_merge():",
            "    cfg = request.json",
            "    name = cfg.get(\"name\")",
            "    builder = CombineData(cfg)",
            "    data = builder.build_data()",
            "    code = builder.build_code()",
            "    return load_new_data(data, code, name)",
            "",
            "",
            "@dtale.route(\"/missingno/<chart_type>/<data_id>\")",
            "@matplotlib_decorator",
            "@exception_decorator",
            "def build_missingno_chart(chart_type, data_id):",
            "    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas",
            "",
            "    df = global_state.get_data(data_id)",
            "    if chart_type == \"matrix\":",
            "        date_index = get_str_arg(request, \"date_index\")",
            "        freq = get_str_arg(request, \"freq\")",
            "        if date_index:",
            "            figure = msno.matrix(df.set_index(date_index), freq=freq)",
            "        else:",
            "            figure = msno.matrix(df)",
            "    elif chart_type == \"bar\":",
            "        figure = msno.bar(df)",
            "    elif chart_type == \"heatmap\":",
            "        figure = msno.heatmap(df)",
            "    elif chart_type == \"dendrogram\":",
            "        figure = msno.dendrogram(df)",
            "",
            "    output = BytesIO()",
            "    FigureCanvas(figure.get_figure()).print_png(output)",
            "    if get_bool_arg(request, \"file\"):",
            "        fname = \"missingno_{}.png\".format(chart_type)",
            "        return send_file(output.getvalue(), fname, \"image/png\")",
            "    return Response(output.getvalue(), mimetype=\"image/png\")",
            "",
            "",
            "@dtale.route(\"/drop-filtered-rows/<data_id>\")",
            "@exception_decorator",
            "def drop_filtered_rows(data_id):",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    final_query = build_query(data_id, global_state.get_query(data_id))",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [",
            "        (",
            "            \"# drop filtered rows\\n\"",
            "            'df = df.query(\"{}\")'.format(final_query.replace(\"`\", \"\"))",
            "        )",
            "    ]",
            "    global_state.set_history(data_id, curr_history)",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        final_query,",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, build_dtypes_state(data, []))",
            "    curr_predefined = curr_settings.get(\"predefinedFilters\", {})",
            "    global_state.update_settings(",
            "        data_id,",
            "        dict(",
            "            query=\"\",",
            "            columnFilters={},",
            "            outlierFilters={},",
            "            predefinedFilters={",
            "                k: dict_merge(v, {\"active\": False}) for k, v in curr_predefined.items()",
            "            },",
            "            invertFilter=False,",
            "        ),",
            "    )",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/move-filters-to-custom/<data_id>\")",
            "@exception_decorator",
            "def move_filters_to_custom(data_id):",
            "    if not global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Custom Filters not enabled! Custom filters are vulnerable to code injection attacks, please only \"",
            "                    \"use in trusted environments.\"",
            "                ),",
            "            )",
            "        )",
            "    query = build_query(data_id, global_state.get_query(data_id))",
            "    global_state.update_settings(",
            "        data_id,",
            "        {",
            "            \"columnFilters\": {},",
            "            \"outlierFilters\": {},",
            "            \"invertFilter\": False,",
            "            \"query\": query,",
            "        },",
            "    )",
            "    return jsonify(",
            "        dict(success=True, settings=global_state.get_settings(data_id) or {})",
            "    )",
            "",
            "",
            "@dtale.route(\"/gage-rnr/<data_id>\")",
            "@exception_decorator",
            "def build_gage_rnr(data_id):",
            "    data = load_filterable_data(data_id, request)",
            "    operator_cols = get_json_arg(request, \"operator\")",
            "    operators = data.groupby(operator_cols)",
            "    measurements = get_json_arg(request, \"measurements\") or [",
            "        col for col in data.columns if col not in operator_cols",
            "    ]",
            "    sizes = set((len(operator) for _, operator in operators))",
            "    if len(sizes) > 1:",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Operators do not have the same amount of parts! Please select a new operator with equal rows in \"",
            "                    \"each group.\"",
            "                ),",
            "            )",
            "        )",
            "",
            "    res = gage_rnr.GageRnR(",
            "        np.array([operator[measurements].values for _, operator in operators])",
            "    ).calculate()",
            "    df = pd.DataFrame({name: res[name] for name in gage_rnr.ResultNames})",
            "    df.index = df.index.map(lambda idx: gage_rnr.ComponentNames.get(idx, idx))",
            "    df.index.name = \"Sources of Variance\"",
            "    df.columns = [gage_rnr.ResultNames.get(col, col) for col in df.columns]",
            "    df = df[df.index.isin(df.index.dropna())]",
            "    df = df.reset_index()",
            "    overrides = {\"F\": lambda f, i, c: f.add_float(i, c, precision=3)}",
            "    return jsonify(dict_merge(dict(success=True), format_grid(df, overrides)))",
            "",
            "",
            "@dtale.route(\"/timeseries-analysis/<data_id>\")",
            "@exception_decorator",
            "def get_timeseries_analysis(data_id):",
            "    report_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    ts_rpt = TimeseriesAnalysis(data_id, report_type, cfg)",
            "    data = ts_rpt.run()",
            "    return jsonify(dict_merge(dict(success=True), data))",
            "",
            "",
            "@dtale.route(\"/arcticdb/libraries\")",
            "@exception_decorator",
            "def get_arcticdb_libraries():",
            "    if get_bool_arg(request, \"refresh\"):",
            "        global_state.store.load_libraries()",
            "",
            "    libraries = global_state.store.libraries",
            "    is_async = False",
            "    if len(libraries) > 500:",
            "        is_async = True",
            "        libraries = libraries[:5]",
            "    ret_data = {\"success\": True, \"libraries\": libraries, \"async\": is_async}",
            "    if global_state.store.lib is not None:",
            "        ret_data[\"library\"] = global_state.store.lib.name",
            "    return jsonify(ret_data)",
            "",
            "",
            "@dtale.route(\"/arcticdb/async-libraries\")",
            "@exception_decorator",
            "def get_async_arcticdb_libraries():",
            "    libraries = global_state.store.libraries",
            "    input = get_str_arg(request, \"input\")",
            "    vals = list(",
            "        itertools.islice((option(lib) for lib in libraries if lib.startswith(input)), 5)",
            "    )",
            "    return jsonify(vals)",
            "",
            "",
            "@dtale.route(\"/arcticdb/<library>/symbols\")",
            "@exception_decorator",
            "def get_arcticdb_symbols(library):",
            "    if get_bool_arg(request, \"refresh\") or library not in global_state.store._symbols:",
            "        global_state.store.load_symbols(library)",
            "",
            "    symbols = global_state.store._symbols[library]",
            "    is_async = False",
            "    if len(symbols) > 500:",
            "        is_async = True",
            "        symbols = symbols[:5]",
            "    return jsonify({\"success\": True, \"symbols\": symbols, \"async\": is_async})",
            "",
            "",
            "@dtale.route(\"/arcticdb/<library>/async-symbols\")",
            "@exception_decorator",
            "def get_async_arcticdb_symbols(library):",
            "    symbols = global_state.store._symbols[library]",
            "    input = get_str_arg(request, \"input\")",
            "    vals = list(",
            "        itertools.islice((option(sym) for sym in symbols if sym.startswith(input)), 5)",
            "    )",
            "    return jsonify(vals)",
            "",
            "",
            "@dtale.route(\"/arcticdb/load-description\")",
            "@exception_decorator",
            "def load_arcticdb_description():",
            "    from arcticc.pb2.descriptors_pb2 import _TYPEDESCRIPTOR_VALUETYPE",
            "",
            "    library = get_str_arg(request, \"library\")",
            "    symbol = get_str_arg(request, \"symbol\")",
            "",
            "    lib = global_state.store.conn[library]",
            "    description = lib.get_description(symbol)",
            "",
            "    columns = list(",
            "        map(",
            "            lambda c: \"{} ({})\".format(",
            "                c.name, _TYPEDESCRIPTOR_VALUETYPE.values[c.dtype.value_type].name",
            "            ),",
            "            sorted(description.columns, key=lambda c: c.name),",
            "        )",
            "    )",
            "    index = list(",
            "        map(",
            "            lambda i: \"{} ({})\".format(",
            "                i[0], _TYPEDESCRIPTOR_VALUETYPE.values[i[1].value_type].name",
            "            ),",
            "            zip(description.index.name, description.index.dtype),",
            "        )",
            "    )",
            "    rows = description.row_count",
            "",
            "    description_str = (",
            "        \"ROWS: {rows:,.0f}\\n\"",
            "        \"INDEX:\\n\"",
            "        \"\\t- {index}\\n\"",
            "        \"COLUMNS ({col_count}):\\n\"",
            "        \"\\t- {columns}\\n\"",
            "    ).format(",
            "        rows=rows,",
            "        index=\"\\n\\t- \".join(index),",
            "        col_count=len(columns),",
            "        columns=\"\\n\\t- \".join(columns),",
            "    )",
            "    return jsonify(",
            "        dict(success=True, library=library, symbol=symbol, description=description_str)",
            "    )",
            "",
            "",
            "@dtale.route(\"/arcticdb/load-symbol\")",
            "@exception_decorator",
            "def load_arcticdb_symbol():",
            "    library = get_str_arg(request, \"library\")",
            "    symbol = get_str_arg(request, \"symbol\")",
            "    data_id = \"{}|{}\".format(library, symbol)",
            "",
            "    if not global_state.store.lib or global_state.store.lib.name != library:",
            "        global_state.store.update_library(library)",
            "",
            "    startup(data=data_id)",
            "    startup_code = (",
            "        \"from arcticdb import Arctic\\n\"",
            "        \"from arcticdb.version_store._store import VersionedItem\\n\\n\"",
            "        \"conn = Arctic('{uri}')\\n\"",
            "        \"lib = conn.get_library('{library}')\\n\"",
            "        \"df = lib.read('{symbol}')\\n\"",
            "        \"if isinstance(data, VersionedItem):\\n\"",
            "        \"\\tdf = df.data\\n\"",
            "    ).format(uri=global_state.store.uri, library=library, symbol=symbol)",
            "    curr_settings = global_state.get_settings(data_id)",
            "    global_state.set_settings(",
            "        data_id, dict_merge(curr_settings, dict(startup_code=startup_code))",
            "    )",
            "    return jsonify(dict(success=True, data_id=data_id))",
            "",
            "",
            "@dtale.route(\"/aggregations/<data_id>/<col>\")",
            "@exception_decorator",
            "def load_aggregations(data_id, col):",
            "    data = load_filterable_data(data_id, request, columns=[col])",
            "    s = data[col]",
            "    sum = s.sum()",
            "    mean = s.mean()",
            "    median = s.median()",
            "    return jsonify(success=True, sum=float(sum), mean=float(mean), median=float(median))",
            "",
            "",
            "@dtale.route(\"/weighted-average/<data_id>/<col>/<weights>\")",
            "@exception_decorator",
            "def load_weighted_average(data_id, col, weights):",
            "    data = load_filterable_data(data_id, request, columns=[col, weights])",
            "    weighted_average = sum(data[col] * data[weights]) / sum(data[weights])",
            "    return jsonify(success=True, result=float(weighted_average))",
            "",
            "",
            "@dtale.route(\"/raw-pandas/<data_id>\")",
            "@exception_decorator",
            "def raw_pandas(data_id):",
            "    func_type = get_str_arg(request, \"func_type\", \"info\")",
            "    data = load_filterable_data(data_id, request)",
            "    if func_type == \"info\":",
            "        buffer = StringIO()",
            "        data.info(buf=buffer)",
            "        output = buffer.getvalue()",
            "        return jsonify(success=True, output=output)",
            "    elif func_type == \"nunique\":",
            "        output = data.nunique().to_string()",
            "        return jsonify(success=True, output=output)",
            "    elif func_type == \"describe\":",
            "        output = data.describe().T.to_string()",
            "        return jsonify(success=True, output=output)",
            "    return jsonify(",
            "        success=False, error=\"Invalid function type passed in: {}\".format(func_type)",
            "    )"
        ],
        "afterPatchFile": [
            "# coding=utf-8",
            "from __future__ import absolute_import, division",
            "",
            "import os",
            "import time",
            "from builtins import map, range, str, zip",
            "from collections import namedtuple",
            "from functools import wraps",
            "from logging import getLogger",
            "",
            "from flask import (",
            "    current_app,",
            "    json,",
            "    make_response,",
            "    redirect,",
            "    render_template,",
            "    request,",
            "    Response,",
            ")",
            "",
            "import itertools",
            "import missingno as msno",
            "import networkx as nx",
            "import numpy as np",
            "import pandas as pd",
            "import platform",
            "import requests",
            "import scipy.stats as sts",
            "import seaborn as sns",
            "import xarray as xr",
            "from six import BytesIO, PY3, string_types, StringIO",
            "",
            "import dtale.correlations as correlations",
            "import dtale.datasets as datasets",
            "import dtale.env_util as env_util",
            "import dtale.gage_rnr as gage_rnr",
            "import dtale.global_state as global_state",
            "import dtale.pandas_util as pandas_util",
            "import dtale.predefined_filters as predefined_filters",
            "from dtale import dtale",
            "from dtale.charts.utils import build_base_chart, CHART_POINTS_LIMIT",
            "from dtale.cli.clickutils import retrieve_meta_info_and_version",
            "from dtale.column_analysis import ColumnAnalysis",
            "from dtale.column_builders import ColumnBuilder, printable",
            "from dtale.column_filters import ColumnFilter",
            "from dtale.column_replacements import ColumnReplacement",
            "from dtale.combine_data import CombineData",
            "from dtale.describe import load_describe",
            "from dtale.duplicate_checks import DuplicateCheck",
            "from dtale.dash_application.charts import (",
            "    build_raw_chart,",
            "    chart_url_params,",
            "    chart_url_querystring,",
            "    export_chart,",
            "    export_png,",
            "    export_chart_data,",
            "    url_encode_func,",
            ")",
            "from dtale.data_reshapers import DataReshaper",
            "from dtale.code_export import build_code_export",
            "from dtale.query import (",
            "    build_col_key,",
            "    build_query,",
            "    build_query_builder,",
            "    handle_predefined,",
            "    load_filterable_data,",
            "    load_index_filter,",
            "    run_query,",
            ")",
            "from dtale.timeseries_analysis import TimeseriesAnalysis",
            "from dtale.utils import (",
            "    DuplicateDataError,",
            "    apply,",
            "    build_formatters,",
            "    build_shutdown_url,",
            "    build_url,",
            "    classify_type,",
            "    coord_type,",
            "    dict_merge,",
            "    divide_chunks,",
            "    export_to_csv_buffer,",
            "    find_dtype,",
            "    find_dtype_formatter,",
            "    format_data,",
            "    format_grid,",
            "    get_bool_arg,",
            "    get_dtypes,",
            "    get_int_arg,",
            "    get_json_arg,",
            "    get_str_arg,",
            "    get_url_quote,",
            "    grid_columns,",
            "    grid_formatter,",
            "    json_date,",
            "    json_float,",
            "    json_int,",
            "    json_timestamp,",
            "    jsonify,",
            "    jsonify_error,",
            "    read_file,",
            "    make_list,",
            "    optimize_df,",
            "    option,",
            "    retrieve_grid_params,",
            "    running_with_flask_debug,",
            "    running_with_pytest,",
            "    sort_df_for_grid,",
            "    unique_count,",
            ")",
            "from dtale.translations import text",
            "",
            "logger = getLogger(__name__)",
            "IDX_COL = str(\"dtale_index\")",
            "",
            "",
            "def exception_decorator(func):",
            "    @wraps(func)",
            "    def _handle_exceptions(*args, **kwargs):",
            "        try:",
            "            return func(*args, **kwargs)",
            "        except BaseException as e:",
            "            return jsonify_error(e)",
            "",
            "    return _handle_exceptions",
            "",
            "",
            "def matplotlib_decorator(func):",
            "    @wraps(func)",
            "    def _handle_matplotlib(*args, **kwargs):",
            "        try:",
            "            import matplotlib",
            "",
            "            current_backend = matplotlib.get_backend()",
            "",
            "            matplotlib.use(\"agg\")  # noqa: E261",
            "",
            "            import matplotlib.pyplot as plt",
            "",
            "            plt.rcParams[\"font.sans-serif\"] = [",
            "                \"SimHei\"",
            "            ]  # Or any other Chinese characters",
            "            matplotlib.rcParams[\"font.family\"] = [\"Heiti TC\"]",
            "",
            "            return func(*args, **kwargs)",
            "        except BaseException as e:",
            "            raise e",
            "        finally:",
            "            try:",
            "                matplotlib.pyplot.switch_backend(current_backend)",
            "            except BaseException:",
            "                pass",
            "",
            "    return _handle_matplotlib",
            "",
            "",
            "class NoDataLoadedException(Exception):",
            "    \"\"\"Container class for any scenario where no data has been loaded into D-Tale.",
            "",
            "    This will usually force the user to load data using the CSV/TSV loader UI.",
            "    \"\"\"",
            "",
            "",
            "def head_endpoint(popup_type=None):",
            "    data_keys = global_state.keys()",
            "    if not len(data_keys):",
            "        return \"popup/{}\".format(\"arcticdb\" if global_state.is_arcticdb else \"upload\")",
            "    head_id = sorted(data_keys)[0]",
            "    head_id = get_url_quote()(get_url_quote()(head_id, safe=\"\"))",
            "    if popup_type:",
            "        return \"popup/{}/{}\".format(popup_type, head_id)",
            "    return \"main/{}\".format(head_id)",
            "",
            "",
            "def in_ipython_frontend():",
            "    \"\"\"",
            "    Helper function which is variation of :meth:`pandas:pandas.io.formats.console.in_ipython_frontend` which",
            "    checks to see if we are inside an IPython zmq frontend",
            "",
            "    :return: `True` if D-Tale is being invoked within ipython notebook, `False` otherwise",
            "    \"\"\"",
            "    try:",
            "        from IPython import get_ipython",
            "",
            "        ip = get_ipython()",
            "        return \"zmq\" in str(type(ip)).lower()",
            "    except BaseException:",
            "        pass",
            "    return False",
            "",
            "",
            "def kill(base):",
            "    \"\"\"",
            "    This function fires a request to this instance's 'shutdown' route to kill it",
            "",
            "    \"\"\"",
            "    try:",
            "        requests.get(build_shutdown_url(base))",
            "    except BaseException:",
            "        logger.info(\"Shutdown complete\")",
            "",
            "",
            "def is_up(base):",
            "    \"\"\"",
            "    This function checks to see if instance's :mod:`flask:flask.Flask` process is up by hitting 'health' route.",
            "",
            "    Using `verify=False` will allow us to validate instances being served up over SSL",
            "",
            "    :return: `True` if :mod:`flask:flask.Flask` process is up and running, `False` otherwise",
            "    \"\"\"",
            "    try:",
            "        return requests.get(\"{}/health\".format(base), verify=False, timeout=10).ok",
            "    except BaseException:",
            "        return False",
            "",
            "",
            "class DtaleData(object):",
            "    \"\"\"",
            "    Wrapper class to abstract the global state of a D-Tale process while allowing",
            "    a user to programatically interact with a running D-Tale instance",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param url: endpoint for instances :class:`flask:flask.Flask` process",
            "    :type url: str",
            "",
            "    Attributes:",
            "        _data_id            data identifier",
            "        _url                :class:`flask:flask.Flask` endpoint",
            "        _notebook_handle    reference to the most recent :class:`ipython:IPython.display.DisplayHandle` created",
            "",
            "    :Example:",
            "",
            "        >>> import dtale",
            "        >>> import pandas as pd",
            "        >>> df = pd.DataFrame([dict(a=1,b=2,c=3)])",
            "        >>> d = dtale.show(df)",
            "        >>> tmp = d.data.copy()",
            "        >>> tmp['d'] = 4",
            "        >>> d.data = tmp",
            "        >>> d.kill()",
            "    \"\"\"",
            "",
            "    def __init__(self, data_id, url, is_proxy=False, app_root=None):",
            "        self._data_id = data_id",
            "        self._url = url",
            "        self._notebook_handle = None",
            "        self.started_with_open_browser = False",
            "        self.is_proxy = is_proxy",
            "        self.app_root = app_root",
            "",
            "    def build_main_url(self, name=None):",
            "        data_keys = global_state.keys()",
            "        if (name or self._data_id) and len(data_keys):",
            "            quoted_data_id = get_url_quote()(",
            "                get_url_quote()(name or self._data_id, safe=\"\")",
            "            )",
            "            return \"{}/dtale/main/{}\".format(",
            "                self.app_root if self.is_proxy else self._url, quoted_data_id",
            "            )",
            "        return (",
            "            self.app_root if self.is_proxy else self._url",
            "        )  # \"load data\" or \"library/symbol selection\" screens",
            "",
            "    @property",
            "    def _main_url(self):",
            "        data_keys = global_state.keys()",
            "        if not len(data_keys):",
            "            return self.build_main_url()",
            "        suffix = self._data_id",
            "        name = global_state.get_name(suffix)",
            "        if name:",
            "            suffix = global_state.convert_name_to_url_path(name)",
            "        return self.build_main_url(name=suffix)",
            "",
            "    @property",
            "    def data(self):",
            "        \"\"\"",
            "        Property which is a reference to the globally stored data associated with this instance",
            "",
            "        \"\"\"",
            "        return global_state.get_data(self._data_id)",
            "",
            "    @property",
            "    def view_data(self):",
            "        \"\"\"",
            "        Property which returns the data associated with this instance as well as any sorting or filtering applied",
            "        from the UI",
            "",
            "        \"\"\"",
            "        req = namedtuple(\"req\", \"args\")",
            "        return load_filterable_data(self._data_id, req(dict(filtered=\"true\")))",
            "",
            "    @data.setter",
            "    def data(self, data):",
            "        \"\"\"",
            "        Setter which will go through all standard formatting to make sure changes will be handled correctly by D-Tale",
            "",
            "        \"\"\"",
            "        startup(self._url, data=data, data_id=self._data_id)",
            "",
            "    def get_corr_matrix(self, encode_strings=False, as_df=False):",
            "        \"\"\"Helper function to build correlation matrix from data (can be an image or dataframe).\"\"\"",
            "        matrix_data = build_correlations_matrix(",
            "            self._data_id, is_pps=False, encode_strings=encode_strings, image=not as_df",
            "        )",
            "        _, _, _, _, _, _, df_or_image = matrix_data",
            "        return df_or_image",
            "",
            "    def get_pps_matrix(self, encode_strings=False, as_df=False):",
            "        \"\"\"Helper function to build correlation matrix from data (can be an image or dataframe).\"\"\"",
            "        matrix_data = build_correlations_matrix(",
            "            self._data_id, is_pps=True, encode_strings=encode_strings, image=not as_df",
            "        )",
            "        _, _, _, _, _, _, df_or_image = matrix_data",
            "        return df_or_image",
            "",
            "    def update_id(self, new_data_id):",
            "        \"\"\"",
            "        Update current data_id to new data_id",
            "",
            "        :param new_data_id: the data_id to update to",
            "        \"\"\"",
            "        self._data_id = global_state.update_id(self._data_id, new_data_id)",
            "",
            "    def main_url(self):",
            "        \"\"\"",
            "        Helper function creating main :class:`flask:flask.Flask` route using instance's url & data_id",
            "        :return: str",
            "        \"\"\"",
            "        if in_ipython_frontend():",
            "            print(self._main_url)",
            "            return None",
            "        return self._main_url",
            "",
            "    def kill(self):",
            "        \"\"\"Helper function to pass instance's endpoint to :meth:`dtale.views.kill`\"\"\"",
            "        kill_url = self._url",
            "        if in_ipython_frontend() and not kill_url.startswith(\"http\"):",
            "            from dtale.app import ACTIVE_PORT, ACTIVE_HOST",
            "",
            "            kill_url = build_url(ACTIVE_PORT, ACTIVE_HOST)",
            "        kill(kill_url)",
            "",
            "    def cleanup(self):",
            "        \"\"\"Helper function to clean up data associated with this instance from global state.\"\"\"",
            "        global_state.cleanup(self._data_id)",
            "",
            "    def update_settings(self, **updates):",
            "        \"\"\"",
            "        Helper function for updating instance-specific settings. For example:",
            "        * allow_cell_edits - whether cells can be edited",
            "        * locked - which columns are locked to the left of the grid",
            "        * sort - The sort to apply to the data on startup (EX: [(\"col1\", \"ASC\"), (\"col2\", \"DESC\"),...])",
            "        * custom_formats - display formatting for specific columns",
            "        * background_mode - different background displays in grid",
            "        * range_highlights - specify background colors for ranges of values in the grid",
            "        * vertical_headers - if True, then rotate column headers vertically",
            "        * column_edit_options - the options to allow on the front-end when editing a cell for the columns specified",
            "        * highlight_filter - if True, then highlight rows on the frontend which will be filtered when applying a filter",
            "                             rather than hiding them from the dataframe",
            "        * hide_shutdown - if true, this will hide the \"Shutdown\" button from users",
            "        * nan_display - if value in dataframe is :attr:`numpy:numpy.nan` then return this value on the frontend",
            "        * hide_header_editor - if true, this will hide header editor when editing cells on the frontend",
            "        * lock_header_menu - if true, this will always the display the header menu which usually only displays when you",
            "                             hover over the top",
            "        * hide_header_menu - if true, this will hide the header menu from the screen",
            "        * hide_main_menu - if true, this will hide the main menu from the screen",
            "        * hide_column_menus - if true, this will hide the column menus from the screen",
            "        * enable_custom_filters - if True, allow users to specify custom filters from the UI using pandas.query strings",
            "        * enable_web_uploads - if True, allow users to upload files using URLs from the UI",
            "",
            "        After applying please refresh any open browsers!",
            "        \"\"\"",
            "        name_updates = dict(",
            "            range_highlights=\"rangeHighlight\",",
            "            column_formats=\"columnFormats\",",
            "            background_mode=\"backgroundMode\",",
            "            vertical_headers=\"verticalHeaders\",",
            "            highlight_filter=\"highlightFilter\",",
            "        )",
            "        settings = {name_updates.get(k, k): v for k, v in updates.items()}",
            "        global_state.update_settings(self._data_id, settings)",
            "",
            "    def get_settings(self):",
            "        \"\"\"Helper function for retrieving any instance-specific settings.\"\"\"",
            "        return global_state.get_settings(self._data_id) or {}",
            "",
            "    def open_browser(self):",
            "        \"\"\"",
            "        This function uses the :mod:`python:webbrowser` library to try and automatically open server's default browser",
            "        to this D-Tale instance",
            "        \"\"\"",
            "        env_util.open_browser(self._main_url)",
            "",
            "    def is_up(self):",
            "        \"\"\"",
            "        Helper function to pass instance's endpoint to :meth:`dtale.views.is_up`",
            "        \"\"\"",
            "        return is_up(self._url)",
            "",
            "    def __str__(self):",
            "        \"\"\"",
            "        Will try to create an :class:`ipython:IPython.display.IFrame` if being invoked from within ipython notebook",
            "        otherwise simply returns the output of running :meth:`pandas:pandas.DataFrame.__str__` on the data associated",
            "        with this instance",
            "",
            "        \"\"\"",
            "        if in_ipython_frontend():",
            "            if self.started_with_open_browser:",
            "                self.started_with_open_browser = False",
            "                return \"\"",
            "            self.notebook()",
            "            return \"\"",
            "",
            "        if global_state.is_arcticdb and global_state.store.get(self._data_id).is_large:",
            "            return self.main_url()",
            "",
            "        return self.data.__str__()",
            "",
            "    def __repr__(self):",
            "        \"\"\"",
            "        Will try to create an :class:`ipython:IPython.display.IFrame` if being invoked from within ipython notebook",
            "        otherwise simply returns the output of running :meth:`pandas:pandas.DataFrame.__repr__` on the data for",
            "        this instance",
            "",
            "        \"\"\"",
            "        if in_ipython_frontend():",
            "            if self.started_with_open_browser:",
            "                self.started_with_open_browser = False",
            "                return \"\"",
            "            self.notebook()",
            "            if self._notebook_handle is not None:",
            "                return \"\"",
            "        return self.main_url()",
            "",
            "    def _build_iframe(",
            "        self, route=\"/dtale/iframe/\", params=None, width=\"100%\", height=475",
            "    ):",
            "        \"\"\"",
            "        Helper function to build an :class:`ipython:IPython.display.IFrame` if that module exists within",
            "        your environment",
            "",
            "        :param route: the :class:`flask:flask.Flask` route to hit on D-Tale",
            "        :type route: str, optional",
            "        :param params: properties & values passed as query parameters to the route",
            "        :type params: dict, optional",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        :return: :class:`ipython:IPython.display.IFrame`",
            "        \"\"\"",
            "        try:",
            "            from IPython.display import IFrame",
            "        except ImportError:",
            "            logger.info(\"in order to use this function, please install IPython\")",
            "            return None",
            "        iframe_url = \"{}{}{}\".format(",
            "            self.app_root if self.is_proxy else self._url, route, self._data_id",
            "        )",
            "        if params is not None:",
            "            if isinstance(params, string_types):  # has this already been encoded?",
            "                iframe_url = \"{}?{}\".format(iframe_url, params)",
            "            else:",
            "                iframe_url = \"{}?{}\".format(iframe_url, url_encode_func()(params))",
            "",
            "        return IFrame(iframe_url, width=width, height=height)",
            "",
            "    def notebook(self, route=\"/dtale/iframe/\", params=None, width=\"100%\", height=475):",
            "        \"\"\"",
            "        Helper function which checks to see if :mod:`flask:flask.Flask` process is up and running and then tries to",
            "        build an :class:`ipython:IPython.display.IFrame` and run :meth:`ipython:IPython.display.display` on it so",
            "        it will be displayed in the ipython notebook which invoked it.",
            "",
            "        A reference to the :class:`ipython:IPython.display.DisplayHandle` is stored in _notebook_handle for",
            "        updating if you are running ipython>=5.0",
            "",
            "        :param route: the :class:`flask:flask.Flask` route to hit on D-Tale",
            "        :type route: str, optional",
            "        :param params: properties & values passed as query parameters to the route",
            "        :type params: dict, optional",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        \"\"\"",
            "        try:",
            "            from IPython.display import display",
            "        except ImportError:",
            "            logger.info(\"in order to use this function, please install IPython\")",
            "            return self.data.__repr__()",
            "",
            "        retries = 0",
            "        while not self.is_up() and retries < 10:",
            "            time.sleep(0.01)",
            "            retries += 1",
            "",
            "        self._notebook_handle = display(",
            "            self._build_iframe(route=route, params=params, width=width, height=height),",
            "            display_id=True,",
            "        )",
            "        if self._notebook_handle is None:",
            "            self._notebook_handle = True",
            "",
            "    def notebook_correlations(self, col1, col2, width=\"100%\", height=475):",
            "        \"\"\"",
            "        Helper function to build an `ipython:IPython.display.IFrame` pointing at the correlations popup",
            "",
            "        :param col1: column on left side of correlation",
            "        :type col1: str",
            "        :param col2: column on right side of correlation",
            "        :type col2: str",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        :return: :class:`ipython:IPython.display.IFrame`",
            "        \"\"\"",
            "        self.notebook(",
            "            \"/dtale/popup/correlations/\",",
            "            params=dict(col1=col1, col2=col2),",
            "            width=width,",
            "            height=height,",
            "        )",
            "",
            "    def notebook_charts(",
            "        self,",
            "        chart_type=\"line\",",
            "        query=None,",
            "        x=None,",
            "        y=None,",
            "        z=None,",
            "        group=None,",
            "        agg=None,",
            "        window=None,",
            "        rolling_comp=None,",
            "        barmode=None,",
            "        barsort=None,",
            "        width=\"100%\",",
            "        height=800,",
            "    ):",
            "        \"\"\"",
            "        Helper function to build an `ipython:IPython.display.IFrame` pointing at the charts popup",
            "",
            "        :param chart_type: type of chart, possible options are line|bar|pie|scatter|3d_scatter|surface|heatmap",
            "        :type chart_type: str",
            "        :param query: pandas dataframe query string",
            "        :type query: str, optional",
            "        :param x: column to use for the X-Axis",
            "        :type x: str",
            "        :param y: columns to use for the Y-Axes",
            "        :type y: list of str",
            "        :param z: column to use for the Z-Axis",
            "        :type z: str, optional",
            "        :param group: column(s) to use for grouping",
            "        :type group: list of str or str, optional",
            "        :param agg: specific aggregation that can be applied to y or z axes.  Possible values are: count, first, last,",
            "                    mean, median, min, max, std, var, mad, prod, sum.  This is included in label of axis it is being",
            "                    applied to.",
            "        :type agg: str, optional",
            "        :param window: number of days to include in rolling aggregations",
            "        :type window: int, optional",
            "        :param rolling_comp: computation to use in rolling aggregations",
            "        :type rolling_comp: str, optional",
            "        :param barmode: mode to use for bar chart display. possible values are stack|group(default)|overlay|relative",
            "        :type barmode: str, optional",
            "        :param barsort: axis name to sort the bars in a bar chart by (default is the 'x', but other options are any of",
            "                        columns names used in the 'y' parameter",
            "        :type barsort: str, optional",
            "        :param width: width of the ipython cell",
            "        :type width: str or int, optional",
            "        :param height: height of the ipython cell",
            "        :type height: str or int, optional",
            "        :return: :class:`ipython:IPython.display.IFrame`",
            "        \"\"\"",
            "        params = dict(",
            "            chart_type=chart_type,",
            "            query=query,",
            "            x=x,",
            "            y=make_list(y),",
            "            z=z,",
            "            group=make_list(group),",
            "            agg=agg,",
            "            window=window,",
            "            rolling_comp=rolling_comp,",
            "            barmode=barmode,",
            "            barsort=barsort,",
            "        )",
            "        self.notebook(",
            "            route=\"/dtale/charts/\",",
            "            params=chart_url_querystring(params),",
            "            width=width,",
            "            height=height,",
            "        )",
            "",
            "    def offline_chart(",
            "        self,",
            "        return_object=False,",
            "        chart_type=None,",
            "        query=None,",
            "        x=None,",
            "        y=None,",
            "        z=None,",
            "        group=None,",
            "        agg=None,",
            "        window=None,",
            "        rolling_comp=None,",
            "        barmode=None,",
            "        barsort=None,",
            "        yaxis=None,",
            "        filepath=None,",
            "        title=None,",
            "        # fmt: off",
            "        **kwargs",
            "        # fmt: on",
            "    ):",
            "        \"\"\"",
            "        Builds the HTML for a plotly chart figure to saved to a file or output to a jupyter notebook",
            "",
            "        :param return_object: if True, return the plotly graph object for this chart",
            "        :type return_object: bool",
            "        :param chart_type: type of chart, possible options are line|bar|pie|scatter|3d_scatter|surface|heatmap",
            "        :type chart_type: str",
            "        :param query: pandas dataframe query string",
            "        :type query: str, optional",
            "        :param x: column to use for the X-Axis",
            "        :type x: str",
            "        :param y: columns to use for the Y-Axes",
            "        :type y: list of str",
            "        :param z: column to use for the Z-Axis",
            "        :type z: str, optional",
            "        :param group: column(s) to use for grouping",
            "        :type group: list of str or str, optional",
            "        :param agg: specific aggregation that can be applied to y or z axes.  Possible values are: count, first, last,",
            "                    mean, median, min, max, std, var, mad, prod, sum.  This is included in label of axis it is being",
            "                    applied to.",
            "        :type agg: str, optional",
            "        :param window: number of days to include in rolling aggregations",
            "        :type window: int, optional",
            "        :param rolling_comp: computation to use in rolling aggregations",
            "        :type rolling_comp: str, optional",
            "        :param barmode: mode to use for bar chart display. possible values are stack|group(default)|overlay|relative",
            "        :type barmode: str, optional",
            "        :param barsort: axis name to sort the bars in a bar chart by (default is the 'x', but other options are any of",
            "                        columns names used in the 'y' parameter",
            "        :type barsort: str, optional",
            "        :param yaxis: dictionary specifying the min/max for each y-axis in your chart",
            "        :type yaxis: dict, optional",
            "        :param filepath: location to save HTML output",
            "        :type filepath: str, optional",
            "        :param title: Title of your chart",
            "        :type title: str, optional",
            "        :param kwargs: optional keyword arguments, here in case invalid arguments are passed to this function",
            "        :type kwargs: dict",
            "        :return: possible outcomes are:",
            "                 - if run within a jupyter notebook and no 'filepath' is specified it will print the resulting HTML",
            "                   within a cell in your notebook",
            "                 - if 'filepath' is specified it will save the chart to the path specified",
            "                 - otherwise it will return the HTML output as a string",
            "        \"\"\"",
            "        params = dict(",
            "            return_object=return_object,",
            "            chart_type=chart_type,",
            "            query=query,",
            "            x=x,",
            "            y=make_list(y),",
            "            z=z,",
            "            group=make_list(group),",
            "            agg=agg,",
            "            window=window,",
            "            rolling_comp=rolling_comp,",
            "            barmode=barmode,",
            "            barsort=barsort,",
            "            yaxis=yaxis,",
            "            title=title,",
            "        )",
            "        params = dict_merge(params, kwargs)",
            "",
            "        if filepath is None and in_ipython_frontend():",
            "            from plotly.offline import iplot, init_notebook_mode",
            "",
            "            init_notebook_mode(connected=True)",
            "            chart = build_raw_chart(self._data_id, export=True, **params)",
            "            chart.pop(",
            "                \"id\", None",
            "            )  # for some reason iplot does not like when the 'id' property is populated",
            "            iplot(chart)",
            "            return",
            "",
            "        if return_object:",
            "            return build_raw_chart(self._data_id, export=True, **params)",
            "",
            "        html_str = export_chart(self._data_id, params)",
            "        if filepath is None:",
            "            return html_str",
            "",
            "        if not filepath.endswith(\".html\"):",
            "            filepath = \"{}.html\".format(filepath)",
            "",
            "        with open(filepath, \"w\") as f:",
            "            f.write(html_str)",
            "",
            "    def adjust_cell_dimensions(self, width=\"100%\", height=350):",
            "        \"\"\"",
            "        If you are running ipython>=5.0 then this will update the most recent notebook cell you displayed D-Tale in",
            "        for this instance with the height/width properties you have passed in as input",
            "",
            "        :param width: width of the ipython cell",
            "        :param height: height of the ipython cell",
            "        \"\"\"",
            "        if self._notebook_handle is not None and hasattr(",
            "            self._notebook_handle, \"update\"",
            "        ):",
            "            self._notebook_handle.update(self._build_iframe(width=width, height=height))",
            "        else:",
            "            logger.debug(\"You must ipython>=5.0 installed to use this functionality\")",
            "",
            "",
            "def dtype_formatter(data, dtypes, data_ranges, prev_dtypes=None):",
            "    \"\"\"",
            "    Helper function to build formatter for the descriptive information about each column in the dataframe you",
            "    are viewing in D-Tale.  This data is later returned to the browser to help with controlling inputs to functions",
            "    which are heavily tied to specific data types.",
            "",
            "    :param data: dataframe",
            "    :type data: :class:`pandas:pandas.DataFrame`",
            "    :param dtypes: column data type",
            "    :type dtypes: dict",
            "    :param data_ranges: dictionary containing minimum and maximum value for column (if applicable)",
            "    :type data_ranges: dict, optional",
            "    :param prev_dtypes: previous column information for syncing updates to pre-existing columns",
            "    :type prev_dtypes: dict, optional",
            "    :return: formatter function which takes column indexes and names",
            "    :rtype: func",
            "    \"\"\"",
            "",
            "    def _formatter(col_index, col):",
            "        visible = True",
            "        dtype = dtypes.get(col)",
            "        if prev_dtypes and col in prev_dtypes:",
            "            visible = prev_dtypes[col].get(\"visible\", True)",
            "        s = data[col]",
            "        dtype_data = dict(",
            "            name=col,",
            "            dtype=dtype,",
            "            index=col_index,",
            "            visible=visible,",
            "            hasOutliers=0,",
            "            hasMissing=1,",
            "        )",
            "        if global_state.is_arcticdb:",
            "            return dtype_data",
            "",
            "        dtype_data[\"unique_ct\"] = unique_count(s)",
            "        dtype_data[\"hasMissing\"] = int(s.isnull().sum())",
            "        classification = classify_type(dtype)",
            "        if (",
            "            classification in [\"F\", \"I\"] and not s.isnull().all() and col in data_ranges",
            "        ):  # floats/ints",
            "            col_ranges = data_ranges[col]",
            "            if not any((np.isnan(v) or np.isinf(v) for v in col_ranges.values())):",
            "                dtype_data = dict_merge(col_ranges, dtype_data)",
            "",
            "            # load outlier information",
            "            o_s, o_e = calc_outlier_range(s)",
            "            if not any((np.isnan(v) or np.isinf(v) for v in [o_s, o_e])):",
            "                dtype_data[\"hasOutliers\"] += int(((s < o_s) | (s > o_e)).sum())",
            "                dtype_data[\"outlierRange\"] = dict(lower=o_s, upper=o_e)",
            "            skew_val = pandas_util.run_function(s, \"skew\")",
            "            if skew_val is not None:",
            "                dtype_data[\"skew\"] = json_float(skew_val)",
            "            kurt_val = pandas_util.run_function(s, \"kurt\")",
            "            if kurt_val is not None:",
            "                dtype_data[\"kurt\"] = json_float(kurt_val)",
            "",
            "        if classification in [\"F\", \"I\"] and not s.isnull().all():",
            "            # build variance flag",
            "            unique_ct = dtype_data[\"unique_ct\"]",
            "            check1 = (unique_ct / len(data[col])) < 0.1",
            "            check2 = False",
            "            if check1 and unique_ct >= 2:",
            "                val_counts = s.value_counts()",
            "                check2 = (val_counts.values[0] / val_counts.values[1]) > 20",
            "            dtype_data[\"lowVariance\"] = bool(check1 and check2)",
            "            dtype_data[\"coord\"] = coord_type(s)",
            "",
            "        if classification in [\"D\"] and not s.isnull().all():",
            "            timestamps = apply(s, lambda x: json_timestamp(x, np.nan))",
            "            skew_val = pandas_util.run_function(timestamps, \"skew\")",
            "            if skew_val is not None:",
            "                dtype_data[\"skew\"] = json_float(skew_val)",
            "            kurt_val = pandas_util.run_function(timestamps, \"kurt\")",
            "            if kurt_val is not None:",
            "                dtype_data[\"kurt\"] = json_float(kurt_val)",
            "",
            "        if classification == \"S\" and not dtype_data[\"hasMissing\"]:",
            "            if (",
            "                dtype.startswith(\"category\")",
            "                and classify_type(s.dtype.categories.dtype.name) == \"S\"",
            "            ):",
            "                dtype_data[\"hasMissing\"] += int(",
            "                    (apply(s, lambda x: str(x).strip()) == \"\").sum()",
            "                )",
            "            else:",
            "                dtype_data[\"hasMissing\"] += int(",
            "                    (s.astype(\"str\").str.strip() == \"\").sum()",
            "                )",
            "",
            "        return dtype_data",
            "",
            "    return _formatter",
            "",
            "",
            "def calc_data_ranges(data, dtypes={}):",
            "    try:",
            "        return data.agg([\"min\", \"max\"]).to_dict()",
            "    except ValueError:",
            "        # I've seen when transposing data and data types get combined into one column this exception emerges",
            "        # when calling 'agg' on the new data",
            "        return {}",
            "    except TypeError:",
            "        non_str_cols = [",
            "            c for c in data.columns if classify_type(dtypes.get(c, \"\")) != \"S\"",
            "        ]",
            "        if not len(non_str_cols):",
            "            return {}",
            "        try:",
            "            return data[non_str_cols].agg([\"min\", \"max\"]).to_dict()",
            "        except BaseException:",
            "            return {}",
            "",
            "",
            "def build_dtypes_state(data, prev_state=None, ranges=None):",
            "    \"\"\"",
            "    Helper function to build globally managed state pertaining to a D-Tale instances columns & data types",
            "",
            "    :param data: dataframe to build data type information for",
            "    :type data: :class:`pandas:pandas.DataFrame`",
            "    :return: a list of dictionaries containing column names, indexes and data types",
            "    \"\"\"",
            "    prev_dtypes = {c[\"name\"]: c for c in prev_state or []}",
            "    dtypes = get_dtypes(data)",
            "    loaded_ranges = ranges or calc_data_ranges(data, dtypes)",
            "    dtype_f = dtype_formatter(data, dtypes, loaded_ranges, prev_dtypes)",
            "    return [dtype_f(i, c) for i, c in enumerate(data.columns)]",
            "",
            "",
            "def check_duplicate_data(data):",
            "    \"\"\"",
            "    This function will do a rough check to see if a user has already loaded this piece of data to D-Tale to avoid",
            "    duplicated state.  The checks that take place are:",
            "     - shape (# of rows & # of columns",
            "     - column names and ordering of columns (eventually might add dtype checking as well...)",
            "",
            "    :param data: dataframe to validate",
            "    :type data: :class:`pandas:pandas.DataFrame`",
            "    :raises :class:`dtale.utils.DuplicateDataError`: if duplicate data exists",
            "    \"\"\"",
            "    cols = [str(col) for col in data.columns]",
            "",
            "    for d_id, datainst in global_state.items():",
            "        d_cols = [str(col) for col in datainst.data.columns]",
            "        if datainst.data.shape == data.shape and cols == d_cols:",
            "            raise DuplicateDataError(d_id)",
            "",
            "",
            "def convert_xarray_to_dataset(dataset, **indexers):",
            "    def _convert_zero_dim_dataset(dataset):",
            "        ds_dict = dataset.to_dict()",
            "        data = {}",
            "        for coord, coord_data in ds_dict[\"coords\"].items():",
            "            data[coord] = coord_data[\"data\"]",
            "        for col, col_data in ds_dict[\"data_vars\"].items():",
            "            data[col] = col_data[\"data\"]",
            "        return pd.DataFrame([data]).set_index(list(ds_dict[\"coords\"].keys()))",
            "",
            "    ds_sel = dataset.sel(**indexers)",
            "    try:",
            "        df = ds_sel.to_dataframe()",
            "        df = df.reset_index().drop(\"index\", axis=1, errors=\"ignore\")",
            "        return df.set_index(list(dataset.dims.keys()))",
            "    except ValueError:",
            "        return _convert_zero_dim_dataset(ds_sel)",
            "",
            "",
            "def handle_koalas(data):",
            "    \"\"\"",
            "    Helper function to check if koalas is installed and also if incoming data is a koalas dataframe, if so convert it",
            "    to :class:`pandas:pandas.DataFrame`, otherwise simply return the original data structure.",
            "",
            "    :param data: data we want to check if its a koalas dataframe and if so convert to :class:`pandas:pandas.DataFrame`",
            "    :return: :class:`pandas:pandas.DataFrame`",
            "    \"\"\"",
            "    if is_koalas(data):",
            "        return data.to_pandas()",
            "    return data",
            "",
            "",
            "def is_koalas(data):",
            "    try:",
            "        from databricks.koalas import frame",
            "",
            "        return isinstance(data, frame.DataFrame)",
            "    except BaseException:",
            "        return False",
            "",
            "",
            "def startup(",
            "    url=\"\",",
            "    data=None,",
            "    data_loader=None,",
            "    name=None,",
            "    data_id=None,",
            "    context_vars=None,",
            "    ignore_duplicate=True,",
            "    allow_cell_edits=True,",
            "    inplace=False,",
            "    drop_index=False,",
            "    precision=2,",
            "    show_columns=None,",
            "    hide_columns=None,",
            "    optimize_dataframe=False,",
            "    column_formats=None,",
            "    nan_display=None,",
            "    sort=None,",
            "    locked=None,",
            "    background_mode=None,",
            "    range_highlights=None,",
            "    app_root=None,",
            "    is_proxy=None,",
            "    vertical_headers=False,",
            "    hide_shutdown=None,",
            "    column_edit_options=None,",
            "    auto_hide_empty_columns=False,",
            "    highlight_filter=False,",
            "    hide_header_editor=None,",
            "    lock_header_menu=None,",
            "    hide_header_menu=None,",
            "    hide_main_menu=None,",
            "    hide_column_menus=None,",
            "    enable_custom_filters=None,",
            "    enable_web_uploads=None,",
            "    force_save=True,",
            "    main_title=None,",
            "    main_title_font=None,",
            "):",
            "    \"\"\"",
            "    Loads and stores data globally",
            "     - If data has indexes then it will lock save those columns as locked on the front-end",
            "     - If data has column named index it will be dropped so that it won't collide with row numbering (dtale_index)",
            "     - Create location in memory for storing settings which can be manipulated from the front-end (sorts, filter, ...)",
            "",
            "    :param url: the base URL that D-Tale is running from to be referenced in redirects to shutdown",
            "    :param data: :class:`pandas:pandas.DataFrame` or :class:`pandas:pandas.Series`",
            "    :param data_loader: function which returns :class:`pandas:pandas.DataFrame`",
            "    :param name: string label to apply to your session",
            "    :param data_id: integer id assigned to a piece of data viewable in D-Tale, if this is populated then it will",
            "                    override the data at that id",
            "    :param context_vars: a dictionary of the variables that will be available for use in user-defined expressions,",
            "                         such as filters",
            "    :type context_vars: dict, optional",
            "    :param ignore_duplicate: if set to True this will not test whether this data matches any previously loaded to D-Tale",
            "    :param allow_cell_edits: If false, this will not allow users to edit cells directly in their D-Tale grid",
            "    :type allow_cell_edits: bool, optional",
            "    :param inplace: If true, this will call `reset_index(inplace=True)` on the dataframe used as a way to save memory.",
            "                    Otherwise this will create a brand new dataframe, thus doubling memory but leaving the dataframe",
            "                    input unchanged.",
            "    :type inplace: bool, optional",
            "    :param drop_index: If true, this will drop any pre-existing index on the dataframe input.",
            "    :type drop_index: bool, optional",
            "    :param precision: The default precision to display for float data in D-Tale grid",
            "    :type precision: int, optional",
            "    :param show_columns: Columns to show on load, hide all others",
            "    :type show_columns: list, optional",
            "    :param hide_columns: Columns to hide on load",
            "    :type hide_columns: list, optional",
            "    :param optimize_dataframe: this will convert string columns with less certain then a certain number of distinct",
            "                              values into categories",
            "    :type optimize_dataframe: boolean",
            "    :param column_formats: The formatting to apply to certain columns on the front-end",
            "    :type column_formats: dict, optional",
            "    :param sort: The sort to apply to the data on startup (EX: [(\"col1\", \"ASC\"), (\"col2\", \"DESC\"),...])",
            "    :type sort: list[tuple], optional",
            "    :param locked: Columns to lock to the left of your grid on load",
            "    :type locked: list, optional",
            "    :param background_mode: Different background highlighting modes available on the frontend. Possible values are:",
            "                            - heatmap-all: turn on heatmap for all numeric columns where the colors are determined by",
            "                                           the range of values over all numeric columns combined",
            "                            - heatmap-col: turn on heatmap for all numeric columns where the colors are determined by",
            "                                           the range of values in the column",
            "                            - heatmap-col-[column name]: turn on heatmap highlighting for a specific column",
            "                            - dtypes: highlight columns based on it's data type",
            "                            - missing: highlight any missing values (np.nan, empty strings, strings of all spaces)",
            "                            - outliers: highlight any outliers",
            "                            - range: highlight values for any matchers entered in the \"range_highlights\" option",
            "                            - lowVariance: highlight values with a low variance",
            "    :type background_mode: string, optional",
            "    :param range_highlights: Definitions for equals, less-than or greater-than ranges for individual (or all) columns",
            "                             which apply different background colors to cells which fall in those ranges.",
            "    :type range_highlights: dict, optional",
            "    :param vertical_headers: if True, then rotate column headers vertically",
            "    :type vertical_headers: boolean, optional",
            "    :param column_edit_options: The options to allow on the front-end when editing a cell for the columns specified",
            "    :type column_edit_options: dict, optional",
            "    :param auto_hide_empty_columns: if True, then auto-hide any columns on the front-end that are comprised entirely of",
            "                                    NaN values",
            "    :type auto_hide_empty_columns: boolean, optional",
            "    :param highlight_filter: if True, then highlight rows on the frontend which will be filtered when applying a filter",
            "                             rather than hiding them from the dataframe",
            "    :type highlight_filter: boolean, optional",
            "    \"\"\"",
            "",
            "    if (",
            "        data_loader is None and data is None",
            "    ):  # scenario where we'll force users to upload a CSV/TSV",
            "        return DtaleData(\"1\", url, is_proxy=is_proxy, app_root=app_root)",
            "",
            "    if data_loader is not None:",
            "        data = data_loader()",
            "        if isinstance(data, string_types) and global_state.contains(data):",
            "            return DtaleData(data, url, is_proxy=is_proxy, app_root=app_root)",
            "        elif (",
            "            data is None and global_state.is_arcticdb",
            "        ):  # send user to the library/symbol selection screen",
            "            return DtaleData(None, url, is_proxy=is_proxy, app_root=app_root)",
            "",
            "    if global_state.is_arcticdb and isinstance(data, string_types):",
            "        data_id = data",
            "        data_id_segs = data_id.split(\"|\")",
            "        if len(data_id_segs) < 2:",
            "            if not global_state.store.lib:",
            "                raise ValueError(",
            "                    (",
            "                        \"When specifying a data identifier for ArcticDB it must be comprised of a library and a symbol.\"",
            "                        \"Use the following format: [library]|[symbol]\"",
            "                    )",
            "                )",
            "            data_id = \"{}|{}\".format(global_state.store.lib.name, data_id)",
            "        global_state.new_data_inst(data_id)",
            "        instance = global_state.store.get(data_id)",
            "        data = instance.base_df",
            "        ret_data = startup(",
            "            url=url,",
            "            data=data,",
            "            data_id=data_id,",
            "            force_save=False,",
            "            name=name,",
            "            context_vars=context_vars,",
            "            ignore_duplicate=ignore_duplicate,",
            "            allow_cell_edits=allow_cell_edits,",
            "            precision=precision,",
            "            show_columns=show_columns,",
            "            hide_columns=hide_columns,",
            "            column_formats=column_formats,",
            "            nan_display=nan_display,",
            "            sort=sort,",
            "            locked=locked,",
            "            background_mode=background_mode,",
            "            range_highlights=range_highlights,",
            "            app_root=app_root,",
            "            is_proxy=is_proxy,",
            "            vertical_headers=vertical_headers,",
            "            hide_shutdown=hide_shutdown,",
            "            column_edit_options=column_edit_options,",
            "            auto_hide_empty_columns=auto_hide_empty_columns,",
            "            highlight_filter=highlight_filter,",
            "            hide_header_editor=hide_header_editor,",
            "            lock_header_menu=lock_header_menu,",
            "            hide_header_menu=hide_header_menu,",
            "            hide_main_menu=hide_main_menu,",
            "            hide_column_menus=hide_column_menus,",
            "            enable_custom_filters=enable_custom_filters,",
            "            enable_web_uploads=enable_web_uploads,",
            "            main_title=main_title,",
            "            main_title_font=main_title_font,",
            "        )",
            "        startup_code = (",
            "            \"from arcticdb import Arctic\\n\"",
            "            \"from arcticdb.version_store._store import VersionedItem\\n\\n\"",
            "            \"conn = Arctic('{uri}')\\n\"",
            "            \"lib = conn.get_library('{library}')\\n\"",
            "            \"df = lib.read('{symbol}')\\n\"",
            "            \"if isinstance(data, VersionedItem):\\n\"",
            "            \"\\tdf = df.data\\n\"",
            "        ).format(",
            "            uri=global_state.store.uri,",
            "            library=global_state.store.lib.name,",
            "            symbol=data_id,",
            "        )",
            "        curr_settings = global_state.get_settings(data_id)",
            "        global_state.set_settings(",
            "            data_id, dict_merge(curr_settings, dict(startup_code=startup_code))",
            "        )",
            "        return ret_data",
            "",
            "    if data is not None:",
            "        data = handle_koalas(data)",
            "        valid_types = (",
            "            pd.DataFrame,",
            "            pd.Series,",
            "            pd.DatetimeIndex,",
            "            pd.MultiIndex,",
            "            xr.Dataset,",
            "            np.ndarray,",
            "            list,",
            "            dict,",
            "        )",
            "        if not isinstance(data, valid_types):",
            "            raise Exception(",
            "                (",
            "                    \"data loaded must be one of the following types: pandas.DataFrame, pandas.Series, \"",
            "                    \"pandas.DatetimeIndex, pandas.MultiIndex, xarray.Dataset, numpy.array, numpy.ndarray, list, dict\"",
            "                )",
            "            )",
            "",
            "        if isinstance(data, xr.Dataset):",
            "            df = convert_xarray_to_dataset(data)",
            "            instance = startup(",
            "                url,",
            "                df,",
            "                name=name,",
            "                data_id=data_id,",
            "                context_vars=context_vars,",
            "                ignore_duplicate=ignore_duplicate,",
            "                allow_cell_edits=allow_cell_edits,",
            "                precision=precision,",
            "                show_columns=show_columns,",
            "                hide_columns=hide_columns,",
            "                column_formats=column_formats,",
            "                nan_display=nan_display,",
            "                sort=sort,",
            "                locked=locked,",
            "                background_mode=background_mode,",
            "                range_highlights=range_highlights,",
            "                app_root=app_root,",
            "                is_proxy=is_proxy,",
            "                vertical_headers=vertical_headers,",
            "                hide_shutdown=hide_shutdown,",
            "                column_edit_options=column_edit_options,",
            "                auto_hide_empty_columns=auto_hide_empty_columns,",
            "                highlight_filter=highlight_filter,",
            "                hide_header_editor=hide_header_editor,",
            "                lock_header_menu=lock_header_menu,",
            "                hide_header_menu=hide_header_menu,",
            "                hide_main_menu=hide_main_menu,",
            "                hide_column_menus=hide_column_menus,",
            "                enable_custom_filters=enable_custom_filters,",
            "                enable_web_uploads=enable_web_uploads,",
            "                main_title=main_title,",
            "                main_title_font=main_title_font,",
            "            )",
            "",
            "            global_state.set_dataset(instance._data_id, data)",
            "            global_state.set_dataset_dim(instance._data_id, {})",
            "            return instance",
            "",
            "        data, curr_index = format_data(data, inplace=inplace, drop_index=drop_index)",
            "        # check to see if this dataframe has already been loaded to D-Tale",
            "        if data_id is None and not ignore_duplicate and not global_state.is_arcticdb:",
            "            check_duplicate_data(data)",
            "",
            "        logger.debug(",
            "            \"pytest: {}, flask-debug: {}\".format(",
            "                running_with_pytest(), running_with_flask_debug()",
            "            )",
            "        )",
            "",
            "        if data_id is None:",
            "            data_id = global_state.new_data_inst()",
            "        if global_state.get_settings(data_id) is not None:",
            "            curr_settings = global_state.get_settings(data_id)",
            "            curr_locked = curr_settings.get(\"locked\", [])",
            "            # filter out previous locked columns that don't exist",
            "            curr_locked = [c for c in curr_locked if c in data.columns]",
            "            # add any new columns in index",
            "            curr_locked += [c for c in curr_index if c not in curr_locked]",
            "        else:",
            "            logger.debug(",
            "                \"pre-locking index columns ({}) to settings[{}]\".format(",
            "                    curr_index, data_id",
            "                )",
            "            )",
            "            curr_locked = locked or curr_index",
            "            global_state.set_metadata(data_id, dict(start=pd.Timestamp(\"now\")))",
            "        global_state.set_name(data_id, name)",
            "        # in the case that data has been updated we will drop any sorts or filter for ease of use",
            "        base_settings = dict(",
            "            indexes=curr_index,",
            "            locked=curr_locked,",
            "            allow_cell_edits=True if allow_cell_edits is None else allow_cell_edits,",
            "            precision=precision,",
            "            columnFormats=column_formats or {},",
            "            backgroundMode=background_mode,",
            "            rangeHighlight=range_highlights,",
            "            verticalHeaders=vertical_headers,",
            "            highlightFilter=highlight_filter,",
            "        )",
            "        base_predefined = predefined_filters.init_filters()",
            "        if base_predefined:",
            "            base_settings[\"predefinedFilters\"] = base_predefined",
            "        if sort:",
            "            base_settings[\"sortInfo\"] = sort",
            "            data = sort_df_for_grid(data, dict(sort=sort))",
            "        if nan_display is not None:",
            "            base_settings[\"nanDisplay\"] = nan_display",
            "        if hide_shutdown is not None:",
            "            base_settings[\"hide_shutdown\"] = hide_shutdown",
            "        if hide_header_editor is not None:",
            "            base_settings[\"hide_header_editor\"] = hide_header_editor",
            "        if lock_header_menu is not None:",
            "            base_settings[\"lock_header_menu\"] = lock_header_menu",
            "        if hide_header_menu is not None:",
            "            base_settings[\"hide_header_menu\"] = hide_header_menu",
            "        if hide_main_menu is not None:",
            "            base_settings[\"hide_main_menu\"] = hide_main_menu",
            "        if hide_column_menus is not None:",
            "            base_settings[\"hide_column_menus\"] = hide_column_menus",
            "        if enable_custom_filters is not None:",
            "            base_settings[\"enable_custom_filters\"] = enable_custom_filters",
            "        if enable_web_uploads is not None:",
            "            base_settings[\"enable_web_uploads\"] = enable_web_uploads",
            "        if column_edit_options is not None:",
            "            base_settings[\"column_edit_options\"] = column_edit_options",
            "        if main_title is not None:",
            "            base_settings[\"main_title\"] = main_title",
            "        if main_title_font is not None:",
            "            base_settings[\"main_title_font\"] = main_title_font",
            "        global_state.set_settings(data_id, base_settings)",
            "        if optimize_dataframe and not global_state.is_arcticdb:",
            "            data = optimize_df(data)",
            "        if force_save or (",
            "            global_state.is_arcticdb and not global_state.contains(data_id)",
            "        ):",
            "            data = data[curr_locked + [c for c in data.columns if c not in curr_locked]]",
            "            global_state.set_data(data_id, data)",
            "        dtypes_data = data",
            "        ranges = None",
            "        if global_state.is_arcticdb:",
            "            instance = global_state.store.get(data_id)",
            "            if not instance.is_large:",
            "                dtypes_data = instance.load_data()",
            "                dtypes_data, _ = format_data(",
            "                    dtypes_data, inplace=inplace, drop_index=drop_index",
            "                )",
            "                ranges = calc_data_ranges(dtypes_data)",
            "                dtypes_data = dtypes_data[",
            "                    curr_locked",
            "                    + [c for c in dtypes_data.columns if c not in curr_locked]",
            "                ]",
            "        dtypes_state = build_dtypes_state(",
            "            dtypes_data, global_state.get_dtypes(data_id) or [], ranges=ranges",
            "        )",
            "",
            "        for col in dtypes_state:",
            "            if show_columns and col[\"name\"] not in show_columns:",
            "                col[\"visible\"] = False",
            "                continue",
            "            if hide_columns and col[\"name\"] in hide_columns:",
            "                col[\"visible\"] = False",
            "                continue",
            "            if col[\"index\"] >= 100:",
            "                col[\"visible\"] = False",
            "        if auto_hide_empty_columns and not global_state.is_arcticdb:",
            "            is_empty = data.isnull().all()",
            "            is_empty = list(is_empty[is_empty].index.values)",
            "            for col in dtypes_state:",
            "                if col[\"name\"] in is_empty:",
            "                    col[\"visible\"] = False",
            "        global_state.set_dtypes(data_id, dtypes_state)",
            "        global_state.set_context_variables(",
            "            data_id, build_context_variables(data_id, context_vars)",
            "        )",
            "        if global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "            logger.warning(",
            "                (",
            "                    \"Custom filtering enabled. Custom filters are vulnerable to code injection attacks, please only \"",
            "                    \"use in trusted environments.\"",
            "                )",
            "            )",
            "        if global_state.load_flag(data_id, \"enable_web_uploads\", False):",
            "            logger.warning(",
            "                (",
            "                    \"Web uploads enabled. Web uploads are vulnerable to blind server side request forgery, please \"",
            "                    \"only use in trusted environments.\"",
            "                )",
            "            )",
            "        return DtaleData(data_id, url, is_proxy=is_proxy, app_root=app_root)",
            "    else:",
            "        raise NoDataLoadedException(\"No data has been loaded into this D-Tale session!\")",
            "",
            "",
            "def is_vscode():",
            "    if os.environ.get(\"VSCODE_PID\") is not None:",
            "        return True",
            "    if \"1\" == os.environ.get(\"VSCODE_INJECTION\"):",
            "        return True",
            "    return False",
            "",
            "",
            "def base_render_template(template, data_id, **kwargs):",
            "    \"\"\"",
            "    Overriden version of Flask.render_template which will also include vital instance information",
            "     - settings",
            "     - version",
            "     - processes",
            "    \"\"\"",
            "    if not len(os.listdir(\"{}/static/dist\".format(os.path.dirname(__file__)))):",
            "        return redirect(current_app.url_for(\"missing_js\"))",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    curr_app_settings = global_state.get_app_settings()",
            "    _, version = retrieve_meta_info_and_version(\"dtale\")",
            "    hide_shutdown = global_state.load_flag(data_id, \"hide_shutdown\", False)",
            "    allow_cell_edits = global_state.load_flag(data_id, \"allow_cell_edits\", True)",
            "    github_fork = global_state.load_flag(data_id, \"github_fork\", False)",
            "    hide_header_editor = global_state.load_flag(data_id, \"hide_header_editor\", False)",
            "    lock_header_menu = global_state.load_flag(data_id, \"lock_header_menu\", False)",
            "    hide_header_menu = global_state.load_flag(data_id, \"hide_header_menu\", False)",
            "    hide_main_menu = global_state.load_flag(data_id, \"hide_main_menu\", False)",
            "    hide_column_menus = global_state.load_flag(data_id, \"hide_column_menus\", False)",
            "    main_title = global_state.load_flag(data_id, \"main_title\", None)",
            "    main_title_font = global_state.load_flag(data_id, \"main_title_font\", None)",
            "    enable_custom_filters = global_state.load_flag(",
            "        data_id, \"enable_custom_filters\", False",
            "    )",
            "    enable_web_uploads = global_state.load_flag(data_id, \"enable_web_uploads\", False)",
            "    app_overrides = dict(",
            "        allow_cell_edits=json.dumps(allow_cell_edits),",
            "        hide_shutdown=hide_shutdown,",
            "        hide_header_editor=hide_header_editor,",
            "        lock_header_menu=lock_header_menu,",
            "        hide_header_menu=hide_header_menu,",
            "        hide_main_menu=hide_main_menu,",
            "        hide_column_menus=hide_column_menus,",
            "        enable_custom_filters=enable_custom_filters,",
            "        enable_web_uploads=enable_web_uploads,",
            "        github_fork=github_fork,",
            "        main_title=main_title,",
            "        main_title_font=main_title_font,",
            "    )",
            "    is_arcticdb = 0",
            "    arctic_conn = \"\"",
            "    if global_state.is_arcticdb:",
            "        instance = global_state.store.get(data_id)",
            "        is_arcticdb = instance.rows()",
            "        arctic_conn = global_state.store.uri",
            "    return render_template(",
            "        template,",
            "        data_id=(",
            "            get_url_quote()(get_url_quote()(data_id, safe=\"\"))",
            "            if data_id is not None",
            "            else \"\"",
            "        ),",
            "        xarray=global_state.get_data_inst(data_id).is_xarray_dataset,",
            "        xarray_dim=json.dumps(global_state.get_dataset_dim(data_id)),",
            "        settings=json.dumps(curr_settings),",
            "        version=str(version),",
            "        processes=global_state.size(),",
            "        python_version=platform.python_version(),",
            "        predefined_filters=json.dumps(",
            "            [f.asdict() for f in predefined_filters.get_filters()]",
            "        ),",
            "        is_vscode=is_vscode(),",
            "        is_arcticdb=is_arcticdb,",
            "        arctic_conn=arctic_conn,",
            "        column_count=len(global_state.get_dtypes(data_id) or []),",
            "        # fmt: off",
            "        **dict_merge(kwargs, curr_app_settings, app_overrides)",
            "        # fmt: on",
            "    )",
            "",
            "",
            "def _view_main(data_id, iframe=False):",
            "    \"\"\"",
            "    Helper function rendering main HTML which will also build title and store whether we are viewing from an <iframe>",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param iframe: boolean flag indicating whether this is being viewed from an <iframe> (usually means ipython)",
            "    :type iframe: bool, optional",
            "    :return: HTML",
            "    \"\"\"",
            "    title = global_state.load_flag(data_id, \"main_title\", None) or \"D-Tale\"",
            "    name = global_state.get_name(data_id)",
            "    if name:",
            "        title = \"{} ({})\".format(title, name)",
            "    return base_render_template(\"dtale/main.html\", data_id, title=title, iframe=iframe)",
            "",
            "",
            "@dtale.route(\"/main\")",
            "@dtale.route(\"/main/<data_id>\")",
            "def view_main(data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if not global_state.contains(data_id):",
            "        if global_state.is_arcticdb:",
            "            try:",
            "                startup(data=data_id)",
            "                return _view_main(data_id)",
            "            except BaseException as ex:",
            "                logger.exception(ex)",
            "        return redirect(\"/dtale/{}\".format(head_endpoint()))",
            "    return _view_main(data_id)",
            "",
            "",
            "@dtale.route(\"/main/name/<data_name>\")",
            "def view_main_by_name(data_name=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_name: integer string identifier for a D-Tale process's data",
            "    :type data_name: str",
            "    :return: HTML",
            "    \"\"\"",
            "    data_id = global_state.get_data_id_by_name(data_name)",
            "    return view_main(data_id)",
            "",
            "",
            "@dtale.route(\"/iframe\")",
            "@dtale.route(\"/iframe/<data_id>\")",
            "def view_iframe(data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if data_id is None:",
            "        return redirect(\"/dtale/iframe/{}\".format(head_endpoint()))",
            "    return _view_main(data_id, iframe=True)",
            "",
            "",
            "@dtale.route(\"/iframe/popup/<popup_type>\")",
            "@dtale.route(\"/iframe/popup/<popup_type>/<data_id>\")",
            "def iframe_popup(popup_type, data_id=None):",
            "    route = \"/dtale/popup/{}\".format(popup_type)",
            "    if data_id:",
            "        return redirect(\"{}/{}\".format(route, data_id))",
            "    return redirect(route)",
            "",
            "",
            "POPUP_TITLES = {",
            "    \"reshape\": \"Summarize Data\",",
            "    \"filter\": \"Custom Filter\",",
            "    \"upload\": \"Load Data\",",
            "    \"pps\": \"Predictive Power Score\",",
            "    \"merge\": \"Merge & Stack\",",
            "    \"arcticdb\": \"Load ArcticDB Data\",",
            "    \"raw-pandas\": \"Raw Pandas Output\",",
            "}",
            "",
            "",
            "@dtale.route(\"/popup/<popup_type>\")",
            "@dtale.route(\"/popup/<popup_type>/<data_id>\")",
            "def view_popup(popup_type, data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up a base jinja template for any popup, additionally forwards any",
            "    request parameters as input to template.",
            "",
            "    :param popup_type: type of popup to be opened. Possible values: charts, correlations, describe, histogram, instances",
            "    :type popup_type: str",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if data_id is None and popup_type not in [\"upload\", \"merge\", \"arcticdb\"]:",
            "        return redirect(\"/dtale/{}\".format(head_endpoint(popup_type)))",
            "    main_title = global_state.load_flag(data_id, \"main_title\", None)",
            "    title = main_title or \"D-Tale\"",
            "    name = global_state.get_name(data_id)",
            "    if name:",
            "        title = \"{} ({})\".format(title, name)",
            "    popup_title = text(",
            "        POPUP_TITLES.get(popup_type)",
            "        or \" \".join([pt.capitalize() for pt in popup_type.split(\"-\")])",
            "    )",
            "    title = \"{} - {}\".format(title, popup_title)",
            "    params = request.args.to_dict()",
            "    if len(params):",
            "",
            "        def pretty_print(obj):",
            "            return \", \".join([\"{}: {}\".format(k, str(v)) for k, v in obj.items()])",
            "",
            "        title = \"{} ({})\".format(title, pretty_print(params))",
            "",
            "    grid_links = []",
            "    for id in global_state.keys():",
            "        label = global_state.get_name(id)",
            "        if label:",
            "            label = \" ({})\".format(label)",
            "        else:",
            "            label = \"\"",
            "        grid_links.append((id, \"{}{}\".format(id, label)))",
            "    return base_render_template(",
            "        \"dtale/popup.html\",",
            "        data_id,",
            "        title=title,",
            "        popup_title=popup_title,",
            "        js_prefix=popup_type,",
            "        grid_links=grid_links,",
            "        back_to_data=text(\"Back To Data\"),",
            "    )",
            "",
            "",
            "@dtale.route(\"/calculation/<calc_type>\")",
            "def view_calculation(calc_type=\"skew\"):",
            "    return render_template(\"dtale/{}.html\".format(calc_type))",
            "",
            "",
            "@dtale.route(\"/network\")",
            "@dtale.route(\"/network/<data_id>\")",
            "def view_network(data_id=None):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up base jinja template housing JS files",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: HTML",
            "    \"\"\"",
            "    if not global_state.contains(data_id):",
            "        return redirect(\"/dtale/network/{}\".format(head_endpoint()))",
            "    return base_render_template(",
            "        \"dtale/network.html\", data_id, title=\"Network Viewer\", iframe=False",
            "    )",
            "",
            "",
            "@dtale.route(\"/code-popup\")",
            "def view_code_popup():",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which serves up a base jinja template for code snippets",
            "",
            "    :return: HTML",
            "    \"\"\"",
            "    return render_template(\"dtale/code_popup.html\", **global_state.get_app_settings())",
            "",
            "",
            "@dtale.route(\"/processes\")",
            "@exception_decorator",
            "def get_processes():",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns list of running D-Tale processes within current python process",
            "",
            "    :return: JSON {",
            "        data: [",
            "            {",
            "                port: 1, name: 'name1', rows: 5, columns: 5, names: 'col1,...,col5', start: '2018-04-30 12:36:44',",
            "                ts: 1525106204000",
            "            },",
            "            ...,",
            "            {",
            "                port: N, name: 'nameN', rows: 5, columns: 5, names: 'col1,...,col5', start: '2018-04-30 12:36:44',",
            "                ts: 1525106204000",
            "            }",
            "        ],",
            "        success: True/False",
            "    }",
            "    \"\"\"",
            "",
            "    load_dtypes = get_bool_arg(request, \"dtypes\")",
            "",
            "    def _load_process(data_id):",
            "        data = global_state.get_data(data_id)",
            "        dtypes = global_state.get_dtypes(data_id)",
            "        mdata = global_state.get_metadata(data_id)",
            "        return dict(",
            "            data_id=str(data_id),",
            "            rows=len(data),",
            "            columns=len(dtypes),",
            "            names=dtypes if load_dtypes else \",\".join([c[\"name\"] for c in dtypes]),",
            "            start=json_date(mdata[\"start\"], fmt=\"%-I:%M:%S %p\"),",
            "            ts=json_timestamp(mdata[\"start\"]),",
            "            name=global_state.get_name(data_id),",
            "            # mem usage in MB",
            "            mem_usage=int(",
            "                global_state.get_data(data_id)",
            "                .memory_usage(index=False, deep=True)",
            "                .sum()",
            "            ),",
            "        )",
            "",
            "    processes = sorted(",
            "        [_load_process(data_id) for data_id in global_state.keys()],",
            "        key=lambda p: p[\"ts\"],",
            "    )",
            "    return jsonify(dict(data=processes, success=True))",
            "",
            "",
            "@dtale.route(\"/process-keys\")",
            "@exception_decorator",
            "def process_keys():",
            "    return jsonify(",
            "        dict(",
            "            data=[",
            "                dict(id=str(data_id), name=global_state.get_name(data_id))",
            "                for data_id in global_state.keys()",
            "            ],",
            "            success=True,",
            "        )",
            "    )",
            "",
            "",
            "@dtale.route(\"/update-settings/<data_id>\")",
            "@exception_decorator",
            "def update_settings(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which updates global SETTINGS for current port",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param settings: JSON string from flask.request.args['settings'] which gets decoded and stored in SETTINGS variable",
            "    :return: JSON",
            "    \"\"\"",
            "",
            "    updated_settings = get_json_arg(request, \"settings\", {})",
            "    if not global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "        updated_settings.pop(\"query\", None)",
            "",
            "    global_state.update_settings(data_id, updated_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-theme\")",
            "@exception_decorator",
            "def update_theme():",
            "    theme = get_str_arg(request, \"theme\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"theme\"] = theme",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-pin-menu\")",
            "@exception_decorator",
            "def update_pin_menu():",
            "    pinned = get_bool_arg(request, \"pinned\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"pin_menu\"] = pinned",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-language\")",
            "@exception_decorator",
            "def update_language():",
            "    language = get_str_arg(request, \"language\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"language\"] = language",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-maximum-column-width\")",
            "@exception_decorator",
            "def update_maximum_column_width():",
            "    width = get_str_arg(request, \"width\")",
            "    if width:",
            "        width = int(width)",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"max_column_width\"] = width",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-maximum-row-height\")",
            "@exception_decorator",
            "def update_maximum_row_height():",
            "    height = get_str_arg(request, \"height\")",
            "    if height:",
            "        height = int(height)",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"max_row_height\"] = height",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-query-engine\")",
            "@exception_decorator",
            "def update_query_engine():",
            "    engine = get_str_arg(request, \"engine\")",
            "    curr_app_settings = global_state.get_app_settings()",
            "    curr_app_settings[\"query_engine\"] = engine",
            "    global_state.set_app_settings(curr_app_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/update-formats/<data_id>\")",
            "@exception_decorator",
            "def update_formats(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which updates the \"columnFormats\" property for global SETTINGS associated w/ the",
            "    current port",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param all: boolean flag which, if true, tells us we should apply this formatting to all columns with the same",
            "                data type as our selected column",
            "    :param col: selected column",
            "    :param format: JSON string for the formatting configuration we want applied to either the selected column of all",
            "                   columns with the selected column's data type",
            "    :return: JSON",
            "    \"\"\"",
            "    update_all_dtype = get_bool_arg(request, \"all\")",
            "    nan_display = get_str_arg(request, \"nanDisplay\")",
            "    if nan_display is None:",
            "        nan_display = \"nan\"",
            "    col = get_str_arg(request, \"col\")",
            "    col_format = get_json_arg(request, \"format\")",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    updated_formats = {col: col_format}",
            "    if update_all_dtype:",
            "        col_dtype = global_state.get_dtype_info(data_id, col)[\"dtype\"]",
            "        updated_formats = {",
            "            c[\"name\"]: col_format",
            "            for c in global_state.get_dtypes(data_id)",
            "            if c[\"dtype\"] == col_dtype",
            "        }",
            "    updated_formats = dict_merge(",
            "        curr_settings.get(\"columnFormats\") or {}, updated_formats",
            "    )",
            "    updated_settings = dict_merge(",
            "        curr_settings, dict(columnFormats=updated_formats, nanDisplay=nan_display)",
            "    )",
            "    global_state.set_settings(data_id, updated_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/save-range-highlights/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def save_range_highlights(data_id):",
            "    ranges = json.loads(request.json.get(\"ranges\", \"{}\"))",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    updated_settings = dict_merge(curr_settings, dict(rangeHighlight=ranges))",
            "    global_state.set_settings(data_id, updated_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "def refresh_col_indexes(data_id):",
            "    \"\"\"",
            "    Helper function to sync column indexes to current state of dataframe for data_id.",
            "    \"\"\"",
            "    curr_dtypes = {c[\"name\"]: c for c in global_state.get_dtypes(data_id)}",
            "    curr_data = global_state.get_data(data_id)",
            "    global_state.set_dtypes(",
            "        data_id,",
            "        [",
            "            dict_merge(curr_dtypes[c], dict(index=idx))",
            "            for idx, c in enumerate(curr_data.columns)",
            "        ],",
            "    )",
            "",
            "",
            "@dtale.route(\"/update-column-position/<data_id>\")",
            "@exception_decorator",
            "def update_column_position(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle moving of columns within a :class:`pandas:pandas.DataFrame`. Columns can",
            "    be moved in one of these 4 directions: front, back, left, right",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param action: string from flask.request.args['action'] of direction to move column",
            "    :param col: string from flask.request.args['col'] of column name to move",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    action = get_str_arg(request, \"action\")",
            "    col = get_str_arg(request, \"col\")",
            "",
            "    curr_cols = global_state.get_data(data_id).columns.tolist()",
            "    if action == \"front\":",
            "        curr_cols = [col] + [c for c in curr_cols if c != col]",
            "    elif action == \"back\":",
            "        curr_cols = [c for c in curr_cols if c != col] + [col]",
            "    elif action == \"left\":",
            "        if curr_cols[0] != col:",
            "            col_idx = next((idx for idx, c in enumerate(curr_cols) if c == col), None)",
            "            col_to_shift = curr_cols[col_idx - 1]",
            "            curr_cols[col_idx - 1] = col",
            "            curr_cols[col_idx] = col_to_shift",
            "    elif action == \"right\":",
            "        if curr_cols[-1] != col:",
            "            col_idx = next((idx for idx, c in enumerate(curr_cols) if c == col), None)",
            "            col_to_shift = curr_cols[col_idx + 1]",
            "            curr_cols[col_idx + 1] = col",
            "            curr_cols[col_idx] = col_to_shift",
            "",
            "    global_state.set_data(data_id, global_state.get_data(data_id)[curr_cols])",
            "    refresh_col_indexes(data_id)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/update-locked/<data_id>\")",
            "@exception_decorator",
            "def update_locked(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle saving state associated with locking and unlocking columns",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param action: string from flask.request.args['action'] of action to perform (lock or unlock)",
            "    :param col: string from flask.request.args['col'] of column name to lock/unlock",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    action = get_str_arg(request, \"action\")",
            "    col = get_str_arg(request, \"col\")",
            "    curr_settings = global_state.get_settings(data_id)",
            "    curr_data = global_state.get_data(data_id)",
            "    curr_settings[\"locked\"] = curr_settings.get(\"locked\") or []",
            "    if action == \"lock\" and col not in curr_settings[\"locked\"]:",
            "        curr_settings[\"locked\"] = curr_settings[\"locked\"] + [col]",
            "    elif action == \"unlock\":",
            "        curr_settings[\"locked\"] = [c for c in curr_settings[\"locked\"] if c != col]",
            "",
            "    final_cols = curr_settings[\"locked\"] + [",
            "        c for c in curr_data.columns if c not in curr_settings[\"locked\"]",
            "    ]",
            "    global_state.set_data(data_id, curr_data[final_cols])",
            "    global_state.set_settings(data_id, curr_settings)",
            "    refresh_col_indexes(data_id)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/update-visibility/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def update_visibility(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle saving state associated visiblity of columns on the front-end",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param visibility: string from flask.request.args['action'] of dictionary of visibility of all columns in a",
            "                       dataframe",
            "    :type visibility: dict, optional",
            "    :param toggle: string from flask.request.args['col'] of column name whose visibility should be toggled",
            "    :type toggle: str, optional",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    curr_dtypes = global_state.get_dtypes(data_id)",
            "    if request.json.get(\"visibility\"):",
            "        visibility = json.loads(request.json.get(\"visibility\", \"{}\"))",
            "        global_state.set_dtypes(",
            "            data_id,",
            "            [dict_merge(d, dict(visible=visibility[d[\"name\"]])) for d in curr_dtypes],",
            "        )",
            "    elif request.json.get(\"toggle\"):",
            "        toggle_col = request.json.get(\"toggle\")",
            "        toggle_idx = next(",
            "            (idx for idx, d in enumerate(curr_dtypes) if d[\"name\"] == toggle_col), None",
            "        )",
            "        toggle_cfg = curr_dtypes[toggle_idx]",
            "        curr_dtypes[toggle_idx] = dict_merge(",
            "            toggle_cfg, dict(visible=not toggle_cfg[\"visible\"])",
            "        )",
            "        global_state.set_dtypes(data_id, curr_dtypes)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/build-column/<data_id>\")",
            "@exception_decorator",
            "def build_column(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle the building of new columns in a dataframe. Some of the operations the",
            "    are available are:",
            "     - numeric: sum/difference/multiply/divide any combination of two columns or static values",
            "     - datetime: retrieving date properties (hour, minute, month, year...) or conversions of dates (month start, month",
            "                 end, quarter start...)",
            "     - bins: bucketing numeric data into bins using :meth:`pandas:pandas.cut` & :meth:`pandas:pandas.qcut`",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param name: string from flask.request.args['name'] of new column to create",
            "    :param type: string from flask.request.args['type'] of the type of column to build (numeric/datetime/bins)",
            "    :param cfg: dict from flask.request.args['cfg'] of how to calculate the new column",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    data = global_state.get_data(data_id)",
            "    col_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    save_as = get_str_arg(request, \"saveAs\", \"new\")",
            "    if save_as == \"inplace\":",
            "        name = cfg[\"col\"]",
            "    else:",
            "        name = get_str_arg(request, \"name\")",
            "        if not name and col_type != \"type_conversion\":",
            "            raise Exception(\"'name' is required for new column!\")",
            "        # non-type conversions cannot be done inplace and thus need a name and the name needs to be checked that it",
            "        # won't overwrite something else",
            "        name = str(name)",
            "        data = global_state.get_data(data_id)",
            "        if name in data.columns:",
            "            raise Exception(\"A column named '{}' already exists!\".format(name))",
            "",
            "    def _build_column():",
            "        builder = ColumnBuilder(data_id, col_type, name, cfg)",
            "        new_col_data = builder.build_column()",
            "        new_cols = []",
            "        if isinstance(new_col_data, pd.Series):",
            "            if pandas_util.is_pandas2():",
            "                data[name] = new_col_data",
            "            else:",
            "                data.loc[:, name] = new_col_data",
            "            new_cols.append(name)",
            "        else:",
            "            for i in range(len(new_col_data.columns)):",
            "                new_col = new_col_data.iloc[:, i]",
            "                if pandas_util.is_pandas2():",
            "                    data[str(new_col.name)] = new_col",
            "                else:",
            "                    data.loc[:, str(new_col.name)] = new_col",
            "",
            "        new_types = {}",
            "        data_ranges = {}",
            "        for new_col in new_cols:",
            "            dtype = find_dtype(data[new_col])",
            "            if classify_type(dtype) == \"F\" and not data[new_col].isnull().all():",
            "                new_ranges = calc_data_ranges(data[[new_col]])",
            "                data_ranges[new_col] = new_ranges.get(new_col, data_ranges.get(new_col))",
            "            new_types[new_col] = dtype",
            "        dtype_f = dtype_formatter(data, new_types, data_ranges)",
            "        global_state.set_data(data_id, data)",
            "        curr_dtypes = global_state.get_dtypes(data_id)",
            "        if next((cdt for cdt in curr_dtypes if cdt[\"name\"] in new_cols), None):",
            "            curr_dtypes = [",
            "                (",
            "                    dtype_f(len(curr_dtypes), cdt[\"name\"])",
            "                    if cdt[\"name\"] in new_cols",
            "                    else cdt",
            "                )",
            "                for cdt in curr_dtypes",
            "            ]",
            "        else:",
            "            curr_dtypes += [dtype_f(len(curr_dtypes), new_col) for new_col in new_cols]",
            "        global_state.set_dtypes(data_id, curr_dtypes)",
            "        curr_history = global_state.get_history(data_id) or []",
            "        curr_history += make_list(builder.build_code())",
            "        global_state.set_history(data_id, curr_history)",
            "",
            "    if cfg.get(\"applyAllType\", False):",
            "        cols = [",
            "            dtype[\"name\"]",
            "            for dtype in global_state.get_dtypes(data_id)",
            "            if dtype[\"dtype\"] == cfg[\"from\"]",
            "        ]",
            "        for col in cols:",
            "            cfg = dict_merge(cfg, dict(col=col))",
            "            name = col",
            "            _build_column()",
            "    else:",
            "        _build_column()",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/bins-tester/<data_id>\")",
            "@exception_decorator",
            "def build_column_bins_tester(data_id):",
            "    col_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    builder = ColumnBuilder(data_id, col_type, cfg[\"col\"], cfg)",
            "    data = global_state.get_data(data_id)",
            "    data, labels = builder.builder.build_test(data)",
            "    return jsonify(dict(data=data, labels=labels, timestamp=round(time.time() * 1000)))",
            "",
            "",
            "@dtale.route(\"/duplicates/<data_id>\")",
            "@exception_decorator",
            "def get_duplicates(data_id):",
            "    dupe_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    action = get_str_arg(request, \"action\")",
            "    duplicate_check = DuplicateCheck(data_id, dupe_type, cfg)",
            "    if action == \"test\":",
            "        return jsonify(results=duplicate_check.test())",
            "    updated_data_id = duplicate_check.execute()",
            "    return jsonify(success=True, data_id=updated_data_id)",
            "",
            "",
            "@dtale.route(\"/reshape/<data_id>\")",
            "@exception_decorator",
            "def reshape_data(data_id):",
            "    output = get_str_arg(request, \"output\")",
            "    shape_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    builder = DataReshaper(data_id, shape_type, cfg)",
            "    if output == \"new\":",
            "        instance = startup(data=builder.reshape(), ignore_duplicate=True)",
            "    else:",
            "        instance = startup(",
            "            data=builder.reshape(), data_id=data_id, ignore_duplicate=True",
            "        )",
            "    curr_settings = global_state.get_settings(instance._data_id)",
            "    global_state.set_settings(",
            "        instance._data_id,",
            "        dict_merge(curr_settings, dict(startup_code=builder.build_code())),",
            "    )",
            "    return jsonify(success=True, data_id=instance._data_id)",
            "",
            "",
            "@dtale.route(\"/build-replacement/<data_id>\")",
            "@exception_decorator",
            "def build_replacement(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route to handle the replacement of specific values within a column in a dataframe. Some",
            "    of the operations the are available are:",
            "     - spaces: replace values consisting of only spaces with a specific value",
            "     - value: replace specific values with a specific value or aggregation",
            "     - strings: replace values which contain a specific character or string (case-insensitive or not) with a",
            "                       specific value",
            "     - imputer: replace nan values using sklearn imputers iterative, knn or simple",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param col: string from flask.request.args['col'] of the column to perform replacements upon",
            "    :param type: string from flask.request.args['type'] of the type of replacement to perform",
            "                 (spaces/fillna/strings/imputer)",
            "    :param cfg: dict from flask.request.args['cfg'] of how to calculate the replacements",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "",
            "    def _build_data_ranges(data, col, dtype):",
            "        data_ranges = {}",
            "        if classify_type(dtype) == \"F\" and not data[col].isnull().all():",
            "            col_ranges = calc_data_ranges(data[[col]])",
            "            if col_ranges:",
            "                data_ranges[col] = col_ranges[col]",
            "        return data_ranges",
            "",
            "    data = global_state.get_data(data_id)",
            "    name = get_str_arg(request, \"name\")",
            "    if name is not None:",
            "        name = str(name)",
            "        if name in data.columns:",
            "            raise Exception(\"A column named '{}' already exists!\".format(name))",
            "    col = get_str_arg(request, \"col\")",
            "    replacement_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "",
            "    builder = ColumnReplacement(data_id, col, replacement_type, cfg, name)",
            "    output = builder.build_replacements()",
            "    dtype = find_dtype(output)",
            "    curr_dtypes = global_state.get_dtypes(data_id)",
            "",
            "    if name is not None:",
            "        data.loc[:, name] = output",
            "        dtype_f = dtype_formatter(",
            "            data, {name: dtype}, _build_data_ranges(data, name, dtype)",
            "        )",
            "        curr_dtypes.append(dtype_f(len(curr_dtypes), name))",
            "    else:",
            "        data.loc[:, col] = output",
            "        dtype_f = dtype_formatter(",
            "            data, {col: dtype}, _build_data_ranges(data, col, dtype)",
            "        )",
            "        col_index = next(",
            "            (i for i, d in enumerate(curr_dtypes) if d[\"name\"] == col), None",
            "        )",
            "        curr_col_dtype = dtype_f(col_index, col)",
            "        curr_dtypes = [curr_col_dtype if d[\"name\"] == col else d for d in curr_dtypes]",
            "",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, curr_dtypes)",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [builder.build_code()]",
            "    global_state.set_history(data_id, curr_history)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/test-filter/<data_id>\")",
            "@exception_decorator",
            "def test_filter(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which will test out pandas query before it gets applied to DATA and return",
            "    exception information to the screen if there is any",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :return: JSON {success: True/False}",
            "    \"\"\"",
            "    query = get_str_arg(request, \"query\")",
            "    if query and not global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Custom Filters not enabled! Custom filters are vulnerable to code injection attacks, please only \"",
            "                    \"use in trusted environments.\"",
            "                ),",
            "            )",
            "        )",
            "    run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, query),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    if get_str_arg(request, \"save\"):",
            "        curr_settings = global_state.get_settings(data_id) or {}",
            "        if query is not None:",
            "            curr_settings = dict_merge(curr_settings, dict(query=query))",
            "        else:",
            "            curr_settings = {k: v for k, v in curr_settings.items() if k != \"query\"}",
            "        global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/dtypes/<data_id>\")",
            "@exception_decorator",
            "def dtypes(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns a list of column names and dtypes to the front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "",
            "    :return: JSON {",
            "        dtypes: [",
            "            {index: 1, name: col1, dtype: int64},",
            "            ...,",
            "            {index: N, name: colN, dtype: float64}",
            "        ],",
            "        success: True/False",
            "    }",
            "    \"\"\"",
            "    return jsonify(dtypes=global_state.get_dtypes(data_id), success=True)",
            "",
            "",
            "def build_sequential_diffs(s, col, sort=None):",
            "    if sort is not None:",
            "        s = s.sort_values(ascending=sort == \"ASC\")",
            "    diff = s.diff()",
            "    diff = diff[diff == diff]  # remove nan or nat values",
            "    min_diff = diff.min()",
            "    max_diff = diff.max()",
            "    avg_diff = diff.mean()",
            "    diff_vals = diff.value_counts().sort_values(ascending=False)",
            "    diff_vals.index.name = \"value\"",
            "    diff_vals.name = \"count\"",
            "    diff_vals = diff_vals.reset_index()",
            "",
            "    diff_vals_f = grid_formatter(grid_columns(diff_vals), as_string=True)",
            "    diff_fmt = next((f[2] for f in diff_vals_f.fmts if f[1] == \"value\"), None)",
            "    diff_ct = len(diff_vals)",
            "",
            "    code = (",
            "        \"sequential_diffs = data['{}'].diff()\\n\"",
            "        \"diff = diff[diff == diff]\\n\"",
            "        \"min_diff = sequential_diffs.min()\\n\"",
            "        \"max_diff = sequential_diffs.max()\\n\"",
            "        \"avg_diff = sequential_diffs.mean()\\n\"",
            "        \"diff_vals = sequential_diffs.value_counts().sort_values(ascending=False)\"",
            "    ).format(col)",
            "",
            "    metrics = {",
            "        \"diffs\": {",
            "            \"data\": diff_vals_f.format_dicts(diff_vals.head(100).itertuples()),",
            "            \"top\": diff_ct > 100,",
            "            \"total\": diff_ct,",
            "        },",
            "        \"min\": diff_fmt(min_diff, \"N/A\"),",
            "        \"max\": diff_fmt(max_diff, \"N/A\"),",
            "        \"avg\": diff_fmt(avg_diff, \"N/A\"),",
            "    }",
            "    return metrics, code",
            "",
            "",
            "def build_string_metrics(s, col):",
            "    char_len = s.len()",
            "",
            "    def calc_len(x):",
            "        try:",
            "            return len(x)",
            "        except BaseException:",
            "            return 0",
            "",
            "    word_len = apply(s.replace(r\"[\\s]+\", \" \").str.split(\" \"), calc_len)",
            "",
            "    def txt_count(r):",
            "        return s.count(r).astype(bool).sum()",
            "",
            "    string_metrics = dict(",
            "        char_min=int(char_len.min()),",
            "        char_max=int(char_len.max()),",
            "        char_mean=json_float(char_len.mean()),",
            "        char_std=json_float(char_len.std()),",
            "        with_space=int(txt_count(r\"\\s\")),",
            "        with_accent=int(txt_count(r\"[\u00c0-\u00d6\u00d9-\u00f6\u00f9-\u00ff\u0100-\u017e\u1e00-\u1eff]\")),",
            "        with_num=int(txt_count(r\"[\\d]\")),",
            "        with_upper=int(txt_count(r\"[A-Z]\")),",
            "        with_lower=int(txt_count(r\"[a-z]\")),",
            "        with_punc=int(",
            "            txt_count(",
            "                r'(\\!|\"|\\#|\\$|%|&|\\'|\\(|\\)|\\*|\\+|,|\\-|\\.|/|\\:|\\;|\\<|\\=|\\>|\\?|@|\\[|\\\\|\\]|\\^|_|\\`|\\{|\\||\\}|\\~)'",
            "            )",
            "        ),",
            "        space_at_the_first=int(txt_count(r\"^ \")),",
            "        space_at_the_end=int(txt_count(r\" $\")),",
            "        multi_space_after_each_other=int(txt_count(r\"\\s{2,}\")),",
            "        with_hidden=int(txt_count(r\"[^{}]+\".format(printable))),",
            "        word_min=int(word_len.min()),",
            "        word_max=int(word_len.max()),",
            "        word_mean=json_float(word_len.mean()),",
            "        word_std=json_float(word_len.std()),",
            "    )",
            "",
            "    punc_reg = (",
            "        \"\"\"\\tr'(\\\\!|\"|\\\\#|\\\\$|%|&|\\\\'|\\\\(|\\\\)|\\\\*|\\\\+|,|\\\\-|\\\\.|/|\\\\:|\\\\;|\\\\<|\\\\=|\"\"\"",
            "        \"\"\"\\\\>|\\\\?|@|\\\\[|\\\\\\\\|\\\\]|\\\\^|_|\\\\`|\\\\{|\\\\||\\\\}|\\\\~)'\"\"\"",
            "    )",
            "    code = [",
            "        \"s = data['{}']\".format(col),",
            "        \"s = s[~s.isnull()].str\",",
            "        \"char_len = s.len()\\n\",",
            "        \"def calc_len(x):\",",
            "        \"\\ttry:\",",
            "        \"\\t\\treturn len(x)\",",
            "        \"\\texcept:\",",
            "        \"\\t\\treturn 0\\n\",",
            "        \"word_len = s.replace(r'[\\\\s]+', ' ').str.split(' ').apply(calc_len)\\n\",",
            "        \"def txt_count(r):\",",
            "        \"\\treturn s.count(r).astype(bool).sum()\\n\",",
            "        \"char_min=char_len.min()\",",
            "        \"char_max = char_len.max()\",",
            "        \"char_mean = char_len.mean()\",",
            "        \"char_std = char_len.std()\",",
            "        \"with_space = txt_count(r'\\\\s')\",",
            "        \"with_accent = txt_count(r'[\u00c0-\u00d6\u00d9-\u00f6\u00f9-\u00ff\u0100-\u017e\u1e00-\u1eff]')\",",
            "        \"with_num = txt_count(r'[\\\\d]')\",",
            "        \"with_upper = txt_count(r'[A-Z]')\",",
            "        \"with_lower = txt_count(r'[a-z]')\",",
            "        \"with_punc = txt_count(\",",
            "        \"\\t{}\".format(punc_reg),",
            "        \")\",",
            "        \"space_at_the_first = txt_count(r'^ ')\",",
            "        \"space_at_the_end = txt_count(r' $')\",",
            "        \"multi_space_after_each_other = txt_count(r'\\\\s{2,}')\",",
            "        \"printable = r'\\\\w \\\\!\\\"#\\\\$%&'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<\u00bb\u00ab\u061b\u060c\u0640\\\\=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}~'\",",
            "        \"with_hidden = txt_count(r'[^{}]+'.format(printable))\",",
            "        \"word_min = word_len.min()\",",
            "        \"word_max = word_len.max()\",",
            "        \"word_mean = word_len.mean()\",",
            "        \"word_std = word_len.std()\",",
            "    ]",
            "",
            "    return string_metrics, code",
            "",
            "",
            "@dtale.route(\"/describe/<data_id>\")",
            "@exception_decorator",
            "def describe(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns standard details about column data using",
            "    :meth:`pandas:pandas.DataFrame.describe` to the front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param column: required dash separated string \"START-END\" stating a range of row indexes to be returned",
            "                   to the screen",
            "    :return: JSON {",
            "        describe: object representing output from :meth:`pandas:pandas.Series.describe`,",
            "        unique_data: array of unique values when data has <= 100 unique values",
            "        success: True/False",
            "    }",
            "",
            "    \"\"\"",
            "    column = get_str_arg(request, \"col\")",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    columns_to_load = [column]",
            "    indexes = curr_settings.get(\"indexes\", [])",
            "    # TODO: update this to use arcticdb's index function once it becomes available",
            "    if global_state.is_arcticdb and column in indexes:",
            "        column_to_load = next(",
            "            (",
            "                c",
            "                for c in global_state.get_dtypes(data_id) or []",
            "                if c[\"name\"] not in indexes",
            "            ),",
            "            None,",
            "        )",
            "        columns_to_load = [column_to_load[\"name\"]] if column_to_load else None",
            "    data = load_filterable_data(data_id, request, columns=columns_to_load)",
            "    data = data[[column]]",
            "    additional_aggs = None",
            "    dtype = global_state.get_dtype_info(data_id, column)",
            "    classification = classify_type(dtype[\"dtype\"])",
            "    if classification == \"I\":",
            "        additional_aggs = [\"sum\", \"median\", \"mode\", \"var\", \"sem\"]",
            "    elif classification == \"F\":",
            "        additional_aggs = [\"sum\", \"median\", \"var\", \"sem\"]",
            "    code = build_code_export(data_id)",
            "    desc, desc_code = load_describe(data[column], additional_aggs=additional_aggs)",
            "    code += desc_code",
            "    return_data = dict(describe=desc, success=True)",
            "    if \"unique\" not in return_data[\"describe\"] and \"unique_ct\" in dtype:",
            "        return_data[\"describe\"][\"unique\"] = json_int(dtype[\"unique_ct\"], as_string=True)",
            "    for p in [\"skew\", \"kurt\"]:",
            "        if p in dtype:",
            "            return_data[\"describe\"][p] = dtype[p]",
            "",
            "    if classification != \"F\" and not global_state.store.get(data_id).is_large:",
            "        uniq_vals = data[column].value_counts().sort_values(ascending=False)",
            "        uniq_vals.index.name = \"value\"",
            "        uniq_vals.name = \"count\"",
            "        uniq_vals = uniq_vals.reset_index()",
            "",
            "        # build top",
            "        top_freq = uniq_vals[\"count\"].values[0]",
            "        top_freq_pct = (top_freq / uniq_vals[\"count\"].sum()) * 100",
            "        top_vals = (",
            "            uniq_vals[uniq_vals[\"count\"] == top_freq].sort_values(\"value\").head(5)",
            "        )",
            "        top_vals_f = grid_formatter(grid_columns(top_vals), as_string=True)",
            "        top_vals = top_vals_f.format_lists(top_vals)",
            "        return_data[\"describe\"][\"top\"] = \"{} ({}%)\".format(",
            "            \", \".join(top_vals[\"value\"]), json_float(top_freq_pct, as_string=True)",
            "        )",
            "        return_data[\"describe\"][\"freq\"] = int(top_freq)",
            "",
            "        code.append(",
            "            (",
            "                \"uniq_vals = data['{}'].value_counts().sort_values(ascending=False)\\n\"",
            "                \"uniq_vals.index.name = 'value'\\n\"",
            "                \"uniq_vals.name = 'count'\\n\"",
            "                \"uniq_vals = uniq_vals.reset_index()\"",
            "            ).format(column)",
            "        )",
            "",
            "        if dtype[\"dtype\"].startswith(\"mixed\"):",
            "            uniq_vals[\"type\"] = apply(uniq_vals[\"value\"], lambda i: type(i).__name__)",
            "            dtype_counts = uniq_vals.groupby(\"type\")[\"count\"].sum().reset_index()",
            "            dtype_counts.columns = [\"dtype\", \"count\"]",
            "            return_data[\"dtype_counts\"] = dtype_counts.to_dict(orient=\"records\")",
            "            code.append(",
            "                (",
            "                    \"uniq_vals['type'] = uniq_vals['value'].apply( lambda i: type(i).__name__)\\n\"",
            "                    \"dtype_counts = uniq_vals.groupby('type')['count'].sum().reset_index()\\n\"",
            "                    \"dtype_counts.columns = ['dtype', 'count']\"",
            "                )",
            "            )",
            "        else:",
            "            uniq_vals.loc[:, \"type\"] = find_dtype(uniq_vals[\"value\"])",
            "            code.append(",
            "                \"uniq_vals.loc[:, 'type'] = '{}'\".format(uniq_vals[\"type\"].values[0])",
            "            )",
            "",
            "        return_data[\"uniques\"] = {}",
            "        for uniq_type, uniq_grp in uniq_vals.groupby(\"type\"):",
            "            total = len(uniq_grp)",
            "            top = total > 100",
            "            uniq_grp = (",
            "                uniq_grp[[\"value\", \"count\"]]",
            "                .sort_values([\"count\", \"value\"], ascending=[False, True])",
            "                .head(100)",
            "            )",
            "            # pandas started supporting string dtypes in 1.1.0",
            "            conversion_type = (",
            "                uniq_type",
            "                if pandas_util.check_pandas_version(\"1.1.0\") and uniq_type == \"string\"",
            "                else \"object\"",
            "            )",
            "            uniq_grp[\"value\"] = uniq_grp[\"value\"].astype(conversion_type)",
            "            uniq_f, _ = build_formatters(uniq_grp)",
            "            return_data[\"uniques\"][uniq_type] = dict(",
            "                data=uniq_f.format_dicts(uniq_grp.itertuples()), total=total, top=top",
            "            )",
            "",
            "    if (",
            "        classification in [\"I\", \"F\", \"D\"]",
            "        and not global_state.store.get(data_id).is_large",
            "    ):",
            "        sd_metrics, sd_code = build_sequential_diffs(data[column], column)",
            "        return_data[\"sequential_diffs\"] = sd_metrics",
            "        code.append(sd_code)",
            "",
            "    if classification == \"S\":",
            "        str_col = data[column]",
            "        sm_metrics, sm_code = build_string_metrics(",
            "            str_col[~str_col.isnull()].astype(\"str\").str, column",
            "        )",
            "        return_data[\"string_metrics\"] = sm_metrics",
            "        code += sm_code",
            "",
            "    return_data[\"code\"] = \"\\n\".join(code)",
            "    return jsonify(return_data)",
            "",
            "",
            "@dtale.route(\"/variance/<data_id>\")",
            "@exception_decorator",
            "def variance(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns standard details about column data using",
            "    :meth:`pandas:pandas.DataFrame.describe` to the front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param column: required dash separated string \"START-END\" stating a range of row indexes to be returned",
            "                   to the screen",
            "    :return: JSON {",
            "        describe: object representing output from :meth:`pandas:pandas.Series.describe`,",
            "        unique_data: array of unique values when data has <= 100 unique values",
            "        success: True/False",
            "    }",
            "",
            "    \"\"\"",
            "    column = get_str_arg(request, \"col\")",
            "    data = load_filterable_data(data_id, request)",
            "    s = data[column]",
            "    code = [\"s = df['{}']\".format(column)]",
            "    unique_ct = unique_count(s)",
            "    code.append(\"unique_ct = s.unique().size\")",
            "    s_size = len(s)",
            "    code.append(\"s_size = len(s)\")",
            "    check1 = bool((unique_ct / s_size) < 0.1)",
            "    code.append(\"check1 = (unique_ct / s_size) < 0.1\")",
            "    return_data = dict(check1=dict(unique=unique_ct, size=s_size, result=check1))",
            "    dtype = global_state.get_dtype_info(data_id, column)",
            "    if unique_ct >= 2:",
            "        val_counts = s.value_counts()",
            "        check2 = bool((val_counts.values[0] / val_counts.values[1]) > 20)",
            "        fmt = find_dtype_formatter(dtype[\"dtype\"])",
            "        return_data[\"check2\"] = dict(",
            "            val1=dict(val=fmt(val_counts.index[0]), ct=int(val_counts.values[0])),",
            "            val2=dict(val=fmt(val_counts.index[1]), ct=int(val_counts.values[1])),",
            "            result=check2,",
            "        )",
            "    code += [",
            "        \"check2 = False\",",
            "        \"if unique_ct > 1:\",",
            "        \"\\tval_counts = s.value_counts()\",",
            "        \"\\tcheck2 = (val_counts.values[0] / val_counts.values[1]) > 20\",",
            "        \"low_variance = check1 and check2\",",
            "    ]",
            "",
            "    return_data[\"size\"] = len(s)",
            "    return_data[\"outlierCt\"] = dtype[\"hasOutliers\"]",
            "    return_data[\"missingCt\"] = int(s.isnull().sum())",
            "",
            "    jb_stat, jb_p = sts.jarque_bera(s)",
            "    return_data[\"jarqueBera\"] = dict(statistic=float(jb_stat), pvalue=float(jb_p))",
            "    sw_stat, sw_p = sts.shapiro(s)",
            "    return_data[\"shapiroWilk\"] = dict(statistic=float(sw_stat), pvalue=float(sw_p))",
            "    code += [",
            "        \"\\nimport scipy.stats as sts\\n\",",
            "        \"jb_stat, jb_p = sts.jarque_bera(s)\",",
            "        \"sw_stat, sw_p = sts.shapiro(s)\",",
            "    ]",
            "    return_data[\"code\"] = \"\\n\".join(code)",
            "    return jsonify(return_data)",
            "",
            "",
            "def calc_outlier_range(s):",
            "    try:",
            "        q1 = s.quantile(0.25)",
            "        q3 = s.quantile(0.75)",
            "    except BaseException:  # this covers the case when a series contains pd.NA",
            "        return np.nan, np.nan",
            "    iqr = q3 - q1",
            "    iqr_lower = q1 - 1.5 * iqr",
            "    iqr_upper = q3 + 1.5 * iqr",
            "    return iqr_lower, iqr_upper",
            "",
            "",
            "def build_outlier_query(iqr_lower, iqr_upper, min_val, max_val, column):",
            "    queries = []",
            "    if iqr_lower > min_val:",
            "        queries.append(",
            "            \"{column} < {lower}\".format(",
            "                column=build_col_key(column), lower=json_float(iqr_lower)",
            "            )",
            "        )",
            "    if iqr_upper < max_val:",
            "        queries.append(",
            "            \"{column} > {upper}\".format(",
            "                column=build_col_key(column), upper=json_float(iqr_upper)",
            "            )",
            "        )",
            "    return \"(({}))\".format(\") or (\".join(queries)) if len(queries) > 1 else queries[0]",
            "",
            "",
            "@dtale.route(\"/outliers/<data_id>\")",
            "@exception_decorator",
            "def outliers(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    df = global_state.get_data(data_id)",
            "    s = df[column]",
            "    iqr_lower, iqr_upper = calc_outlier_range(s)",
            "    formatter = find_dtype_formatter(find_dtype(s))",
            "",
            "    df = load_filterable_data(data_id, request)",
            "    s = df[column]",
            "    outliers = sorted(s[(s < iqr_lower) | (s > iqr_upper)].unique())",
            "    if not len(outliers):",
            "        return jsonify(outliers=[])",
            "",
            "    top = len(outliers) > 100",
            "    outliers = [formatter(v) for v in outliers[:100]]",
            "    query = build_outlier_query(iqr_lower, iqr_upper, s.min(), s.max(), column)",
            "    code = (",
            "        \"s = df['{column}']\\n\"",
            "        \"q1 = s.quantile(0.25)\\n\"",
            "        \"q3 = s.quantile(0.75)\\n\"",
            "        \"iqr = q3 - q1\\n\"",
            "        \"iqr_lower = q1 - 1.5 * iqr\\n\"",
            "        \"iqr_upper = q3 + 1.5 * iqr\\n\"",
            "        \"outliers = dict(s[(s < iqr_lower) | (s > iqr_upper)])\"",
            "    ).format(column=column)",
            "    queryApplied = column in (",
            "        (global_state.get_settings(data_id) or {}).get(\"outlierFilters\") or {}",
            "    )",
            "    return jsonify(",
            "        outliers=outliers, query=query, code=code, queryApplied=queryApplied, top=top",
            "    )",
            "",
            "",
            "@dtale.route(\"/toggle-outlier-filter/<data_id>\")",
            "@exception_decorator",
            "def toggle_outlier_filter(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    settings = global_state.get_settings(data_id) or {}",
            "    outlierFilters = settings.get(\"outlierFilters\") or {}",
            "    if column in outlierFilters:",
            "        settings[\"outlierFilters\"] = {",
            "            k: v for k, v in outlierFilters.items() if k != column",
            "        }",
            "    else:",
            "        dtype_info = global_state.get_dtype_info(data_id, column)",
            "        outlier_range, min_val, max_val = (",
            "            dtype_info.get(p) for p in [\"outlierRange\", \"min\", \"max\"]",
            "        )",
            "        iqr_lower, iqr_upper = (outlier_range.get(p) for p in [\"lower\", \"upper\"])",
            "        query = build_outlier_query(iqr_lower, iqr_upper, min_val, max_val, column)",
            "        settings[\"outlierFilters\"] = dict_merge(",
            "            outlierFilters, {column: {\"query\": query}}",
            "        )",
            "    global_state.set_settings(data_id, settings)",
            "    return jsonify(dict(success=True, outlierFilters=settings[\"outlierFilters\"]))",
            "",
            "",
            "@dtale.route(\"/delete-col/<data_id>\")",
            "@exception_decorator",
            "def delete_col(data_id):",
            "    columns = get_json_arg(request, \"cols\")",
            "    data = global_state.get_data(data_id)",
            "    data = data[[c for c in data.columns if c not in columns]]",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [\"df = df.drop(columns=['{}'])\".format(\"','\".join(columns))]",
            "    global_state.set_history(data_id, curr_history)",
            "    dtypes = global_state.get_dtypes(data_id)",
            "    dtypes = [dt for dt in dtypes if dt[\"name\"] not in columns]",
            "    curr_settings = global_state.get_settings(data_id)",
            "    curr_settings[\"locked\"] = [",
            "        c for c in curr_settings.get(\"locked\", []) if c not in columns",
            "    ]",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/rename-col/<data_id>\")",
            "@exception_decorator",
            "def rename_col(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    rename = get_str_arg(request, \"rename\")",
            "    data = global_state.get_data(data_id)",
            "    if column != rename and rename in data.columns:",
            "        return jsonify(error='Column name \"{}\" already exists!')",
            "",
            "    data = data.rename(columns={column: rename})",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [\"df = df.rename(columns={'%s': '%s'})\" % (column, rename)]",
            "    global_state.set_history(data_id, curr_history)",
            "    dtypes = global_state.get_dtypes(data_id)",
            "    dtypes = [",
            "        dict_merge(dt, {\"name\": rename}) if dt[\"name\"] == column else dt",
            "        for dt in dtypes",
            "    ]",
            "    curr_settings = global_state.get_settings(data_id)",
            "    curr_settings[\"locked\"] = [",
            "        rename if c == column else c for c in curr_settings.get(\"locked\", [])",
            "    ]",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/duplicate-col/<data_id>\")",
            "@exception_decorator",
            "def duplicate_col(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    data = global_state.get_data(data_id)",
            "    dupe_idx = 2",
            "    new_col = \"{}_{}\".format(column, dupe_idx)",
            "    while new_col in data.columns:",
            "        dupe_idx += 1",
            "        new_col = \"{}_{}\".format(column, dupe_idx)",
            "",
            "    data.loc[:, new_col] = data[column]",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [\"df.loc[:, '%s'] = df['%s']\" % (new_col, column)]",
            "    global_state.set_history(data_id, curr_history)",
            "    dtypes = []",
            "    cols = []",
            "    idx = 0",
            "    for dt in global_state.get_dtypes(data_id):",
            "        dt[\"index\"] = idx",
            "        dtypes.append(dt)",
            "        cols.append(dt[\"name\"])",
            "        idx += 1",
            "        if dt[\"name\"] == column:",
            "            dtypes.append(dict_merge(dt, dict(name=new_col, index=idx)))",
            "            cols.append(new_col)",
            "            idx += 1",
            "",
            "    global_state.set_data(data_id, data[cols])",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    return jsonify(success=True, col=new_col)",
            "",
            "",
            "@dtale.route(\"/edit-cell/<data_id>\")",
            "@exception_decorator",
            "def edit_cell(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    row_index = get_int_arg(request, \"rowIndex\")",
            "    updated = get_str_arg(request, \"updated\")",
            "    updated_str = updated",
            "",
            "    # make sure to load filtered data in order to get correct row index",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    row_index_val = data.iloc[[row_index]].index[0]",
            "    data = global_state.get_data(data_id)",
            "    dtype = find_dtype(data[column])",
            "",
            "    code = []",
            "    if updated in [\"nan\", \"inf\"]:",
            "        updated_str = \"np.{}\".format(updated)",
            "        updated = getattr(np, updated)",
            "        data.loc[row_index_val, column] = updated",
            "        code.append(",
            "            \"df.loc[{row_index}, '{column}'] = {updated}\".format(",
            "                row_index=row_index_val, column=column, updated=updated_str",
            "            )",
            "        )",
            "    else:",
            "        classification = classify_type(dtype)",
            "        if classification == \"B\":",
            "            updated = updated.lower() == \"true\"",
            "            updated_str = str(updated)",
            "        elif classification == \"I\":",
            "            updated = int(updated)",
            "        elif classification == \"F\":",
            "            updated = float(updated)",
            "        elif classification == \"D\":",
            "            updated_str = \"pd.Timestamp({})\".format(updated)",
            "            updated = pd.Timestamp(updated)",
            "        elif classification == \"TD\":",
            "            updated_str = \"pd.Timedelta({})\".format(updated)",
            "            updated = pd.Timedelta(updated)",
            "        else:",
            "            if dtype.startswith(\"category\") and updated not in data[column].unique():",
            "                if pandas_util.is_pandas2():",
            "                    data.loc[:, column] = pd.Categorical(",
            "                        data[column],",
            "                        categories=data[column].cat.add_categories(updated),",
            "                        ordered=True,",
            "                    )",
            "                    code.append(",
            "                        (",
            "                            \"data.loc[:, '{column}'] = pd.Categorical(\\n\"",
            "                            \"\\tdata['{column}'],\\n\"",
            "                            \"\\tcategories=data['{column}'].cat.add_categories('{updated}'),\\n\"",
            "                            \"\\tordered=True\\n\"",
            "                            \")\"",
            "                        ).format(column=column, updated=updated)",
            "                    )",
            "                else:",
            "                    data[column].cat.add_categories(updated, inplace=True)",
            "                    code.append(",
            "                        \"data['{column}'].cat.add_categories('{updated}', inplace=True)\".format(",
            "                            column=column, updated=updated",
            "                        )",
            "                    )",
            "            updated_str = \"'{}'\".format(updated)",
            "        data.at[row_index_val, column] = updated",
            "        code.append(",
            "            \"df.at[{row_index}, '{column}'] = {updated}\".format(",
            "                row_index=row_index_val, column=column, updated=updated_str",
            "            )",
            "        )",
            "    global_state.set_data(data_id, data)",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += code",
            "    global_state.set_history(data_id, curr_history)",
            "",
            "    data = global_state.get_data(data_id)",
            "    dtypes = global_state.get_dtypes(data_id)",
            "    ranges = calc_data_ranges(data[[column]])",
            "    dtype_f = dtype_formatter(data, {column: dtype}, ranges)",
            "    dtypes = [",
            "        dtype_f(dt[\"index\"], column) if dt[\"name\"] == column else dt for dt in dtypes",
            "    ]",
            "    global_state.set_dtypes(data_id, dtypes)",
            "    return jsonify(success=True)",
            "",
            "",
            "def build_filter_vals(series, data_id, column, fmt):",
            "    dtype_info = global_state.get_dtype_info(data_id, column)",
            "    vals = list(series.dropna().unique())",
            "    try:",
            "        vals = sorted(vals)",
            "    except BaseException:",
            "        pass  # if there are mixed values (EX: strings with ints) this fails",
            "    if dtype_info.get(\"unique_ct\", 0) > 500:",
            "        # columns with too many unique values will need to use asynchronous loading, so for now we'll give the",
            "        # first 5 values",
            "        vals = vals[:5]",
            "    vals = [fmt(v) for v in vals]",
            "    return vals",
            "",
            "",
            "@dtale.route(\"/column-filter-data/<data_id>\")",
            "@exception_decorator",
            "def get_column_filter_data(data_id):",
            "    if global_state.is_arcticdb and global_state.store.get(data_id).is_large:",
            "        return jsonify(dict(success=True, hasMissing=True))",
            "    column = get_str_arg(request, \"col\")",
            "    s = global_state.get_data(data_id)[column]",
            "    dtype = find_dtype(s)",
            "    fmt = find_dtype_formatter(dtype)",
            "    classification = classify_type(dtype)",
            "    ret = dict(success=True, hasMissing=bool(s.isnull().any()))",
            "    if classification not in [\"S\", \"B\"]:",
            "        data_range = s.agg([\"min\", \"max\"]).to_dict()",
            "        data_range = {k: fmt(v) for k, v in data_range.items()}",
            "        ret = dict_merge(ret, data_range)",
            "    if classification in [\"S\", \"I\", \"B\"]:",
            "        ret[\"uniques\"] = build_filter_vals(s, data_id, column, fmt)",
            "    return jsonify(ret)",
            "",
            "",
            "@dtale.route(\"/async-column-filter-data/<data_id>\")",
            "@exception_decorator",
            "def get_async_column_filter_data(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    input = get_str_arg(request, \"input\")",
            "    s = global_state.get_data(data_id)[column]",
            "    dtype = find_dtype(s)",
            "    fmt = find_dtype_formatter(dtype)",
            "    vals = s[s.astype(\"str\").str.startswith(input)]",
            "    vals = [option(fmt(v)) for v in sorted(vals.unique())[:5]]",
            "    return jsonify(vals)",
            "",
            "",
            "@dtale.route(\"/save-column-filter/<data_id>\")",
            "@exception_decorator",
            "def save_column_filter(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    curr_filters = ColumnFilter(",
            "        data_id, column, get_str_arg(request, \"cfg\")",
            "    ).save_filter()",
            "    return jsonify(success=True, currFilters=curr_filters)",
            "",
            "",
            "@dtale.route(\"/data/<data_id>\")",
            "@exception_decorator",
            "def get_data(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns current rows from DATA (based on scrollbar specs and saved settings)",
            "    to front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param ids: required dash separated string \"START-END\" stating a range of row indexes to be returned to the screen",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :param sort: JSON string from flask.request.args['sort'] which is applied to DATA using the sort_values() or",
            "                 sort_index() function.  Here is the JSON structure: [col1,dir1],[col2,dir2],....[coln,dirn]",
            "    :return: JSON {",
            "        results: [",
            "            {dtale_index: 1, col1: val1_1, ...,colN: valN_1},",
            "            ...,",
            "            {dtale_index: N2, col1: val1_N2, ...,colN: valN_N2}",
            "        ],",
            "        columns: [{name: col1, dtype: 'int64'},...,{name: colN, dtype: 'datetime'}],",
            "        total: N2,",
            "        success: True/False",
            "    }",
            "    \"\"\"",
            "",
            "    # handling for gunicorn-hosted instances w/ ArcticDB",
            "    if global_state.is_arcticdb and not len(global_state.get_dtypes(data_id) or []):",
            "        global_state.store.build_instance(data_id)",
            "        startup(data=data_id)",
            "",
            "    params = retrieve_grid_params(request)",
            "    export = get_bool_arg(request, \"export\")",
            "    ids = get_json_arg(request, \"ids\")",
            "    if not export and ids is None:",
            "        return jsonify({})",
            "",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    curr_locked = curr_settings.get(\"locked\", [])",
            "    final_query = build_query(data_id, global_state.get_query(data_id))",
            "    highlight_filter = curr_settings.get(\"highlightFilter\") or False",
            "",
            "    if global_state.is_arcticdb:",
            "        col_types = global_state.get_dtypes(data_id) or []",
            "        columns_to_load = [c[\"name\"] for c in col_types if c[\"visible\"]]",
            "        f = grid_formatter(",
            "            [c for c in col_types if c[\"visible\"]],",
            "            nan_display=curr_settings.get(\"nanDisplay\", \"nan\"),",
            "        )",
            "",
            "        query_builder = build_query_builder(data_id)",
            "        date_range = load_index_filter(data_id)",
            "        instance = global_state.store.get(data_id)",
            "        total = instance.rows()",
            "        results = {}",
            "        if total:",
            "            if export:",
            "                export_rows = get_int_arg(request, \"export_rows\")",
            "                if export_rows:",
            "                    if query_builder:",
            "                        data = instance.load_data(",
            "                            query_builder=query_builder, **date_range",
            "                        )",
            "                        data = data.head(export_rows)",
            "                    elif len(date_range):",
            "                        data = instance.load_data(**date_range)",
            "                        data = data.head(export_rows)",
            "                    else:",
            "                        data = instance.load_data(row_range=[0, export_rows])",
            "                data, _ = format_data(data)",
            "                data = data[",
            "                    curr_locked + [c for c in data.columns if c not in curr_locked]",
            "                ]",
            "                results = f.format_dicts(data.itertuples())",
            "                results = [dict_merge({IDX_COL: i}, r) for i, r in enumerate(results)]",
            "            elif query_builder:",
            "                df = instance.load_data(",
            "                    query_builder=query_builder,",
            "                    columns=columns_to_load,",
            "                    # fmt: off",
            "                    **date_range",
            "                    # fmt: on",
            "                )",
            "                total = len(df)",
            "                df, _ = format_data(df)",
            "                df = df[curr_locked + [c for c in df.columns if c not in curr_locked]]",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = df.iloc[sub_range[0] : sub_range[0] + 1]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = (",
            "                            df.iloc[start:]",
            "                            if end >= total - 1",
            "                            else df.iloc[start : end + 1]",
            "                        )",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "            elif len(date_range):",
            "                df = instance.load_data(columns=columns_to_load, **date_range)",
            "                total = len(df)",
            "                df, _ = format_data(df)",
            "                df = df[curr_locked + [c for c in df.columns if c not in curr_locked]]",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = df.iloc[sub_range[0] : sub_range[0] + 1]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = (",
            "                            df.iloc[start:]",
            "                            if end >= total - 1",
            "                            else df.iloc[start : end + 1]",
            "                        )",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "            else:",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = instance.load_data(",
            "                            row_range=[sub_range[0], sub_range[0] + 1],",
            "                            columns=columns_to_load,",
            "                        )",
            "                        sub_df, _ = format_data(sub_df)",
            "                        sub_df = sub_df[",
            "                            curr_locked",
            "                            + [c for c in sub_df.columns if c not in curr_locked]",
            "                        ]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = instance.load_data(",
            "                            row_range=[start, total if end >= total else end + 1],",
            "                            columns=columns_to_load,",
            "                        )",
            "                        sub_df, _ = format_data(sub_df)",
            "                        sub_df = sub_df[",
            "                            curr_locked",
            "                            + [c for c in sub_df.columns if c not in curr_locked]",
            "                        ]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "    else:",
            "        data = global_state.get_data(data_id)",
            "",
            "        # this will check for when someone instantiates D-Tale programmatically and directly alters the internal",
            "        # state of the dataframe (EX: d.data['new_col'] = 'foo')",
            "        curr_dtypes = [c[\"name\"] for c in global_state.get_dtypes(data_id)]",
            "        if any(c not in curr_dtypes for c in data.columns):",
            "            data, _ = format_data(data)",
            "            data = data[curr_locked + [c for c in data.columns if c not in curr_locked]]",
            "            global_state.set_data(data_id, data)",
            "            global_state.set_dtypes(",
            "                data_id,",
            "                build_dtypes_state(data, global_state.get_dtypes(data_id) or []),",
            "            )",
            "",
            "        col_types = global_state.get_dtypes(data_id)",
            "        f = grid_formatter(",
            "            col_types, nan_display=curr_settings.get(\"nanDisplay\", \"nan\")",
            "        )",
            "        if curr_settings.get(\"sortInfo\") != params.get(\"sort\"):",
            "            data = sort_df_for_grid(data, params)",
            "            global_state.set_data(data_id, data)",
            "        if params.get(\"sort\") is not None:",
            "            curr_settings = dict_merge(curr_settings, dict(sortInfo=params[\"sort\"]))",
            "        else:",
            "            curr_settings = {k: v for k, v in curr_settings.items() if k != \"sortInfo\"}",
            "        filtered_indexes = []",
            "        data = run_query(",
            "            handle_predefined(data_id),",
            "            final_query,",
            "            global_state.get_context_variables(data_id),",
            "            ignore_empty=True,",
            "            highlight_filter=highlight_filter,",
            "        )",
            "        if highlight_filter:",
            "            data, filtered_indexes = data",
            "        global_state.set_settings(data_id, curr_settings)",
            "",
            "        total = len(data)",
            "        results = {}",
            "        if total:",
            "            if export:",
            "                export_rows = get_int_arg(request, \"export_rows\")",
            "                if export_rows:",
            "                    data = data.head(export_rows)",
            "                results = f.format_dicts(data.itertuples())",
            "                results = [dict_merge({IDX_COL: i}, r) for i, r in enumerate(results)]",
            "            else:",
            "                for sub_range in ids:",
            "                    sub_range = list(map(int, sub_range.split(\"-\")))",
            "                    if len(sub_range) == 1:",
            "                        sub_df = data.iloc[sub_range[0] : sub_range[0] + 1]",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        results[sub_range[0]] = dict_merge(",
            "                            {IDX_COL: sub_range[0]}, sub_df[0]",
            "                        )",
            "                        if highlight_filter and sub_range[0] in filtered_indexes:",
            "                            results[sub_range[0]][\"__filtered\"] = True",
            "                    else:",
            "                        [start, end] = sub_range",
            "                        sub_df = (",
            "                            data.iloc[start:]",
            "                            if end >= total - 1",
            "                            else data.iloc[start : end + 1]",
            "                        )",
            "                        sub_df = f.format_dicts(sub_df.itertuples())",
            "                        for i, d in zip(range(start, end + 1), sub_df):",
            "                            results[i] = dict_merge({IDX_COL: i}, d)",
            "                            if highlight_filter and i in filtered_indexes:",
            "                                results[i][\"__filtered\"] = True",
            "    columns = [",
            "        dict(name=IDX_COL, dtype=\"int64\", visible=True)",
            "    ] + global_state.get_dtypes(data_id)",
            "    return_data = dict(",
            "        results=results,",
            "        columns=columns,",
            "        total=total,",
            "        final_query=None if highlight_filter else final_query,",
            "    )",
            "",
            "    if export:",
            "        return export_html(data_id, return_data)",
            "",
            "    return jsonify(return_data)",
            "",
            "",
            "def export_html(data_id, return_data):",
            "    def load_file(fpath, encoding=\"utf-8\"):",
            "        return read_file(",
            "            os.path.join(os.path.dirname(__file__), \"static/{}\".format(fpath)),",
            "            encoding=encoding,",
            "        )",
            "",
            "    istok_woff = load_file(\"fonts/istok_woff64.txt\", encoding=None)",
            "    istok_bold_woff = load_file(\"fonts/istok-bold_woff64.txt\", encoding=None)",
            "",
            "    font_styles = (",
            "        \"\"\"",
            "        @font-face {",
            "          font-family: \"istok\";",
            "          font-weight: 400;",
            "          font-style: normal;",
            "          src: url(data:font/truetype;charset=utf-8;base64,\"\"\"",
            "        + istok_woff",
            "        + \"\"\") format(\"woff\");",
            "        }",
            "",
            "        @font-face {",
            "          font-family: \"istok\";",
            "          font-weight: 700;",
            "          font-style: normal;",
            "          src: url(data:font/truetype;charset=utf-8;base64,\"\"\"",
            "        + istok_bold_woff",
            "        + \"\"\") format(\"woff\");",
            "        }",
            "        \"\"\"",
            "    )",
            "",
            "    main_styles = load_file(\"css/main.css\", encoding=\"utf-8\" if PY3 else None).split(",
            "        \"\\n\"",
            "    )",
            "    main_styles = \"\\n\".join(main_styles[28:])",
            "    main_styles = \"{}\\n{}\\n\".format(font_styles, main_styles)",
            "",
            "    if not PY3:",
            "        main_styles = main_styles.decode(\"utf-8\")",
            "",
            "    return_data[\"results\"] = {r[IDX_COL]: r for r in return_data[\"results\"]}",
            "",
            "    polyfills_js = load_file(\"dist/polyfills_bundle.js\")",
            "    export_js = load_file(\"dist/export_bundle.js\")",
            "",
            "    return send_file(",
            "        base_render_template(",
            "            \"dtale/html_export.html\",",
            "            data_id,",
            "            main_styles=main_styles,",
            "            polyfills_js=polyfills_js,",
            "            export_js=export_js,",
            "            response=return_data,",
            "        ),",
            "        \"dtale_html_export_{}.html\".format(json_timestamp(pd.Timestamp(\"now\"))),",
            "        \"text/html\",",
            "    )",
            "",
            "",
            "@dtale.route(\"/load-filtered-ranges/<data_id>\")",
            "@exception_decorator",
            "def load_filtered_ranges(data_id):",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    final_query = build_query(data_id, global_state.get_query(data_id))",
            "    if not final_query:",
            "        return {}",
            "    curr_filtered_ranges = curr_settings.get(\"filteredRanges\", {})",
            "    if final_query == curr_filtered_ranges.get(\"query\"):",
            "        return jsonify(curr_filtered_ranges)",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        final_query,",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "",
            "    def _filter_numeric(col):",
            "        s = data[col]",
            "        dtype = find_dtype(s)",
            "        return classify_type(dtype) in [\"F\", \"I\"] and not s.isnull().all()",
            "",
            "    numeric_cols = [col for col in data.columns if _filter_numeric(col)]",
            "    filtered_ranges = calc_data_ranges(data[numeric_cols])",
            "    updated_dtypes = build_dtypes_state(",
            "        data, global_state.get_dtypes(data_id) or [], filtered_ranges",
            "    )",
            "    updated_dtypes = {col[\"name\"]: col for col in updated_dtypes}",
            "    overall_min, overall_max = None, None",
            "    if len(filtered_ranges):",
            "        overall_min = min([v[\"min\"] for v in filtered_ranges.values()])",
            "        overall_max = max([v[\"max\"] for v in filtered_ranges.values()])",
            "    curr_settings[\"filteredRanges\"] = dict(",
            "        query=final_query,",
            "        ranges=filtered_ranges,",
            "        dtypes=updated_dtypes,",
            "        overall=dict(min=overall_min, max=overall_max),",
            "    )",
            "    global_state.set_settings(data_id, curr_settings)",
            "    return jsonify(curr_settings[\"filteredRanges\"])",
            "",
            "",
            "@dtale.route(\"/data-export/<data_id>\")",
            "@exception_decorator",
            "def data_export(data_id):",
            "    curr_dtypes = global_state.get_dtypes(data_id) or []",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    data = data[",
            "        [",
            "            c[\"name\"]",
            "            for c in sorted(curr_dtypes, key=lambda c: c[\"index\"])",
            "            if c[\"visible\"]",
            "        ]",
            "    ]",
            "    file_type = get_str_arg(request, \"type\", \"csv\")",
            "    if file_type in [\"csv\", \"tsv\"]:",
            "        tsv = file_type == \"tsv\"",
            "        csv_buffer = export_to_csv_buffer(data, tsv=tsv)",
            "        filename = build_chart_filename(\"data\", ext=file_type)",
            "        return send_file(csv_buffer.getvalue(), filename, \"text/{}\".format(file_type))",
            "    elif file_type == \"parquet\":",
            "        from dtale.utils import export_to_parquet_buffer",
            "",
            "        parquet_buffer = export_to_parquet_buffer(data)",
            "        filename = build_chart_filename(\"data\", ext=\"parquet.gzip\")",
            "        return send_file(",
            "            parquet_buffer.getvalue(), filename, \"application/octet-stream\"",
            "        )",
            "    return jsonify(success=False)",
            "",
            "",
            "@dtale.route(\"/column-analysis/<data_id>\")",
            "@exception_decorator",
            "def get_column_analysis(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns output from numpy.histogram/pd.value_counts to front-end as JSON",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param col: string from flask.request.args['col'] containing name of a column in your dataframe",
            "    :param type: string from flask.request.args['type'] to signify either a histogram or value counts",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :param bins: the number of bins to display in your histogram, options on the front-end are 5, 10, 20, 50",
            "    :param top: the number of top values to display in your value counts, default is 100",
            "    :returns: JSON {results: DATA, desc: output from pd.DataFrame[col].describe(), success: True/False}",
            "    \"\"\"",
            "",
            "    analysis = ColumnAnalysis(data_id, request)",
            "    return jsonify(**analysis.build())",
            "",
            "",
            "@matplotlib_decorator",
            "def build_correlations_matrix_image(",
            "    data,",
            "    is_pps,",
            "    valid_corr_cols,",
            "    valid_str_corr_cols,",
            "    valid_date_cols,",
            "    dummy_col_mappings,",
            "    pps_data,",
            "    code,",
            "):",
            "    import matplotlib.pyplot as plt",
            "    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas",
            "",
            "    plt.figure(figsize=(20, 12))",
            "    ax0 = plt.gca()",
            "    cmap = \"Blues\" if is_pps else \"RdYlGn\"",
            "    vmin = 0.0 if is_pps else -1.0",
            "    sns.heatmap(",
            "        data.mask(data.apply(lambda x: x.name == x.index)),",
            "        ax=ax0,",
            "        vmin=vmin,",
            "        vmax=1.0,",
            "        xticklabels=True,",
            "        yticklabels=True,",
            "        cmap=cmap,",
            "    )",
            "    output = BytesIO()",
            "    FigureCanvas(ax0.get_figure()).print_png(output)",
            "    return (",
            "        valid_corr_cols,",
            "        valid_str_corr_cols,",
            "        valid_date_cols,",
            "        dummy_col_mappings,",
            "        pps_data,",
            "        code,",
            "        output.getvalue(),",
            "    )",
            "",
            "",
            "def build_correlations_matrix(data_id, is_pps=False, encode_strings=False, image=False):",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    valid_corr_cols, valid_str_corr_cols, valid_date_cols = correlations.get_col_groups(",
            "        data_id, data",
            "    )",
            "",
            "    str_encodings_code = \"\"",
            "    dummy_col_mappings = {}",
            "    if encode_strings and valid_str_corr_cols:",
            "        data = data[valid_corr_cols + valid_str_corr_cols]",
            "        dummy_kwargs = {}",
            "        if pandas_util.is_pandas2():",
            "            dummy_kwargs[\"dtype\"] = \"int\"",
            "        for str_col in valid_str_corr_cols:",
            "            dummies = pd.get_dummies(data[[str_col]], columns=[str_col], **dummy_kwargs)",
            "            dummy_cols = list(dummies.columns)",
            "            dummy_col_mappings[str_col] = dummy_cols",
            "            data[dummy_cols] = dummies",
            "            valid_corr_cols += dummy_cols",
            "        str_encodings_code = (",
            "            \"str_corr_cols = [\\n\\t'{valid_str_corr_cols}'\\n]\\n\"",
            "            \"dummies = pd.get_dummies(corr_data, str_corr_cols)\\n\"",
            "            \"corr_data.loc[:, dummies.columns] = dummies\\n\"",
            "        ).format(valid_str_corr_cols=\"', '\".join(valid_str_corr_cols))",
            "    else:",
            "        data = data[valid_corr_cols]",
            "",
            "    corr_cols_str = \"'\\n\\t'\".join(",
            "        [\"', '\".join(chunk) for chunk in divide_chunks(valid_corr_cols, 8)]",
            "    )",
            "",
            "    pps_data = None",
            "    if is_pps:",
            "        code = build_code_export(data_id, imports=\"import ppscore\\n\")",
            "        code.append(",
            "            (",
            "                \"corr_cols = [\\n\"",
            "                \"\\t'{corr_cols}'\\n\"",
            "                \"]\\n\"",
            "                \"corr_data = df[corr_cols]\\n\"",
            "                \"{str_encodings}\"",
            "                \"corr_data = ppscore.matrix(corr_data)\\n\"",
            "            ).format(corr_cols=corr_cols_str, str_encodings=str_encodings_code)",
            "        )",
            "",
            "        data, pps_data = get_ppscore_matrix(data[valid_corr_cols])",
            "    else:",
            "        data, matrix_code = correlations.build_matrix(",
            "            data_id,",
            "            data,",
            "            valid_corr_cols,",
            "            {\"corr_cols\": corr_cols_str, \"str_encodings\": str_encodings_code},",
            "        )",
            "        code = [matrix_code]",
            "",
            "    code.append(",
            "        \"corr_data.index.name = str('column')\\ncorr_data = corr_data.reset_index()\"",
            "    )",
            "    code = \"\\n\".join(code)",
            "    data.index.name = str(\"column\")",
            "    if image:",
            "        return build_correlations_matrix_image(",
            "            data,",
            "            is_pps,",
            "            valid_corr_cols,",
            "            valid_str_corr_cols,",
            "            valid_date_cols,",
            "            dummy_col_mappings,",
            "            pps_data,",
            "            code,",
            "        )",
            "    return (",
            "        valid_corr_cols,",
            "        valid_str_corr_cols,",
            "        valid_date_cols,",
            "        dummy_col_mappings,",
            "        pps_data,",
            "        code,",
            "        data,",
            "    )",
            "",
            "",
            "@dtale.route(\"/correlations/<data_id>\")",
            "@exception_decorator",
            "def get_correlations(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which gathers Pearson correlations against all combinations of columns with",
            "    numeric data using :meth:`pandas:pandas.DataFrame.corr`",
            "",
            "    On large datasets with no :attr:`numpy:numpy.nan` data this code will use :meth:`numpy:numpy.corrcoef`",
            "    for speed purposes",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :returns: JSON {",
            "        data: [{column: col1, col1: 1.0, col2: 0.99, colN: 0.45},...,{column: colN, col1: 0.34, col2: 0.88, colN: 1.0}],",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    is_pps = get_bool_arg(request, \"pps\")",
            "    image = get_bool_arg(request, \"image\")",
            "    matrix_data = build_correlations_matrix(",
            "        data_id,",
            "        is_pps=is_pps,",
            "        encode_strings=get_bool_arg(request, \"encodeStrings\"),",
            "        image=image,",
            "    )",
            "    (",
            "        valid_corr_cols,",
            "        valid_str_corr_cols,",
            "        valid_date_cols,",
            "        dummy_col_mappings,",
            "        pps_data,",
            "        code,",
            "        df_or_image,",
            "    ) = matrix_data",
            "    if image:",
            "        fname = \"{}.png\".format(\"predictive_power_score\" if is_pps else \"correlations\")",
            "        return send_file(df_or_image, fname, \"image/png\")",
            "",
            "    data = df_or_image.reset_index()",
            "    col_types = grid_columns(data)",
            "    f = grid_formatter(col_types, nan_display=None)",
            "    return jsonify(",
            "        data=f.format_dicts(data.itertuples()),",
            "        dates=valid_date_cols,",
            "        strings=valid_str_corr_cols,",
            "        dummyColMappings=dummy_col_mappings,",
            "        code=code,",
            "        pps=pps_data,",
            "    )",
            "",
            "",
            "@dtale.route(\"/corr-analysis/<data_id>\")",
            "@exception_decorator",
            "def get_corr_analysis(data_id):",
            "    column_name, max_score, corrs, ranks = correlations.get_analysis(data_id)",
            "    return jsonify(",
            "        column_name=column_name, max_score=max_score, corrs=corrs, ranks=ranks",
            "    )",
            "",
            "",
            "@dtale.route(\"/chart-data/<data_id>\")",
            "@exception_decorator",
            "def get_chart_data(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which builds data associated with a chart.js chart",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param query: string from flask.request.args['query'] which is applied to DATA using the query() function",
            "    :param x: string from flask.request.args['x'] column to be used as x-axis of chart",
            "    :param y: string from flask.request.args['y'] column to be used as y-axis of chart",
            "    :param group: string from flask.request.args['group'] comma-separated string of columns to group chart data by",
            "    :param agg: string from flask.request.args['agg'] points to a specific function that can be applied to",
            "                :func: pandas.core.groupby.DataFrameGroupBy.  Possible values are: count, first, last mean,",
            "                median, min, max, std, var, mad, prod, sum",
            "    :returns: JSON {",
            "        data: {",
            "            series1: { x: [x1, x2, ..., xN], y: [y1, y2, ..., yN] },",
            "            series2: { x: [x1, x2, ..., xN], y: [y1, y2, ..., yN] },",
            "            ...,",
            "            seriesN: { x: [x1, x2, ..., xN], y: [y1, y2, ..., yN] },",
            "        },",
            "        min: minY,",
            "        max: maxY,",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    custom_query = None",
            "    if global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "        custom_query = get_str_arg(request, \"query\")",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, custom_query),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    x = get_str_arg(request, \"x\")",
            "    y = get_json_arg(request, \"y\")",
            "    group_col = get_json_arg(request, \"group\")",
            "    agg = get_str_arg(request, \"agg\")",
            "    allow_duplicates = get_bool_arg(request, \"allowDupes\")",
            "    window = get_int_arg(request, \"rollingWin\")",
            "    comp = get_str_arg(request, \"rollingComp\")",
            "    data, code = build_base_chart(",
            "        data,",
            "        x,",
            "        y,",
            "        group_col=group_col,",
            "        agg=agg,",
            "        allow_duplicates=allow_duplicates,",
            "        rolling_win=window,",
            "        rolling_comp=comp,",
            "    )",
            "    data[\"success\"] = True",
            "    return jsonify(data)",
            "",
            "",
            "def get_ppscore(df, col1, col2):",
            "    if not PY3:",
            "        return None",
            "    try:",
            "        import dtale.ppscore as ppscore",
            "",
            "        pps = ppscore.score(df, col1, col2)",
            "        pps[\"model\"] = pps[\"model\"].__str__()",
            "        pps[\"ppscore\"] = float(pps[\"ppscore\"])",
            "        pps[\"baseline_score\"] = float(pps[\"baseline_score\"])",
            "        pps[\"model_score\"] = float(pps[\"model_score\"])",
            "        return pps",
            "    except BaseException:",
            "        return None",
            "",
            "",
            "def get_ppscore_matrix(df):",
            "    if not PY3:",
            "        return [], None",
            "    try:",
            "        import dtale.ppscore as ppscore",
            "",
            "        pps_data = ppscore.matrix(df)",
            "        data = (",
            "            pps_data[[\"x\", \"y\", \"ppscore\"]].set_index([\"x\", \"y\"]).unstack()[\"ppscore\"]",
            "        )",
            "",
            "        # additional PPS display",
            "        pps_data.loc[:, \"model\"] = pps_data[\"model\"].astype(\"str\")",
            "        pps_data = format_grid(pps_data)",
            "        pps_data = pps_data[\"results\"]",
            "        return data, pps_data",
            "    except BaseException:",
            "        return [], None",
            "",
            "",
            "def update_df_for_encoded_strings(df, dummy_cols, cols, code):",
            "    if not dummy_cols:",
            "        return df",
            "    dummy_kwargs = {}",
            "    if pandas_util.is_pandas2():",
            "        dummy_kwargs[\"dtype\"] = \"int\"",
            "    dummies = pd.get_dummies(df[dummy_cols], columns=dummy_cols, **dummy_kwargs)",
            "    dummies = dummies[[c for c in dummies.columns if c in cols]]",
            "    df[dummies.columns] = dummies",
            "",
            "    code.append(",
            "        (",
            "            \"dummy_cols = ['{}']\\n\"",
            "            \"dummies = pd.get_dummies(df[dummy_cols], columns=dummy_cols)\\n\"",
            "            \"final_cols = ['{}']\\n\"",
            "            \"dummies = dummies[[c for c in dummies.columns if c in final_cols]]\\n\"",
            "            \"df.loc[:, dummies.columns] = dummies\"",
            "        ).format(\"', '\".join(dummy_cols), \"', '\".join(cols))",
            "    )",
            "    return df",
            "",
            "",
            "@dtale.route(\"/correlations-ts/<data_id>\")",
            "@exception_decorator",
            "def get_correlations_ts(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns timeseries of Pearson correlations of two columns with numeric data",
            "    using :meth:`pandas:pandas.DataFrame.corr`",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param cols: comma-separated string from flask.request.args['cols'] containing names of two columns in dataframe",
            "    :param dateCol: string from flask.request.args['dateCol'] with name of date-type column in dateframe for timeseries",
            "    :returns: JSON {",
            "        data: {:col1:col2: {data: [{corr: 0.99, date: 'YYYY-MM-DD'},...], max: 0.99, min: 0.99}",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    cols = get_json_arg(request, \"cols\")",
            "    [col1, col2] = cols",
            "    date_col = get_str_arg(request, \"dateCol\")",
            "    rolling = get_bool_arg(request, \"rolling\")",
            "    rolling_window = get_int_arg(request, \"rollingWindow\")",
            "    min_periods = get_int_arg(request, \"minPeriods\")",
            "    dummy_cols = get_json_arg(request, \"dummyCols\", [])",
            "",
            "    code = build_code_export(data_id)",
            "    pps = get_ppscore(data, col1, col2)",
            "",
            "    if rolling:",
            "        data = data[",
            "            [c for c in data.columns if c in [date_col, col1, col2] + dummy_cols]",
            "        ]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        data = data.set_index(date_col)",
            "        rolling_kwargs = {}",
            "        if min_periods is not None:",
            "            rolling_kwargs[\"min_periods\"] = min_periods",
            "        data = (",
            "            data[[col1, col2]]",
            "            .rolling(rolling_window, **rolling_kwargs)",
            "            .corr()",
            "            .reset_index()",
            "        )",
            "        data = data.dropna()",
            "        data = data[data[\"level_1\"] == col1][[date_col, col2]]",
            "        code.append(",
            "            (",
            "                \"corr_ts = df[['{date_col}', '{col1}', '{col2}']].set_index('{date_col}')\\n\"",
            "                \"corr_ts = corr_ts[['{col1}', '{col2}']].rolling({rolling_window}, min_periods=min_periods).corr()\\n\"",
            "                \"corr_ts = corr_ts.reset_index().dropna()\\n\"",
            "                \"corr_ts = corr_ts[corr_ts['level_1'] == '{col1}'][['{date_col}', '{col2}']]\"",
            "            ).format(",
            "                col1=col1, col2=col2, date_col=date_col, rolling_window=rolling_window",
            "            )",
            "        )",
            "    else:",
            "        data = data[[c for c in data.columns if c in [date_col] + cols + dummy_cols]]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        data = data.groupby(date_col)[cols].corr(method=\"pearson\")",
            "        data.index.names = [\"date\", \"column\"]",
            "        data = data.reset_index()",
            "        data = data[data.column == col1][[\"date\", col2]]",
            "        code.append(",
            "            (",
            "                \"corr_ts = df.groupby('{date_col}')['{cols}'].corr(method='pearson')\\n\"",
            "                \"corr_ts.index.names = ['date', 'column']\\n\"",
            "                \"corr_ts = corr_ts[corr_ts.column == '{col1}'][['date', '{col2}']]\\n\"",
            "            ).format(col1=col1, col2=col2, date_col=date_col, cols=\"', '\".join(cols))",
            "        )",
            "        if rolling_window:",
            "            data = data.set_index(\"date\")",
            "            rolling_kwargs = {}",
            "            if min_periods is not None:",
            "                rolling_kwargs[\"min_periods\"] = min_periods",
            "            data = (",
            "                data[[col2]]",
            "                .rolling(rolling_window, **rolling_kwargs)",
            "                .mean()",
            "                .reset_index()",
            "            )",
            "            data = data.dropna()",
            "            code.append(",
            "                (",
            "                    \"corr_ts = corr_ts.set_index('date')\\n\"",
            "                    \"corr_ts = corr_ts[['{col}']].rolling({rolling_window}, min_periods={min_periods}).mean()\\n\"",
            "                    \"corr_ts = corr_ts.reset_index().dropna()\"",
            "                ).format(",
            "                    col=col2, rolling_window=rolling_window, min_periods=min_periods",
            "                )",
            "            )",
            "",
            "    data.columns = [\"date\", \"corr\"]",
            "    code.append(\"corr_ts.columns = ['date', 'corr']\")",
            "    return_data, _code = build_base_chart(data.fillna(0), \"date\", \"corr\", agg=\"raw\")",
            "    return_data[\"success\"] = True",
            "    return_data[\"code\"] = \"\\n\".join(code)",
            "    return_data[\"pps\"] = pps",
            "    return jsonify(return_data)",
            "",
            "",
            "@dtale.route(\"/scatter/<data_id>\")",
            "@exception_decorator",
            "def get_scatter(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns data used in correlation of two columns for scatter chart",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param cols: comma-separated string from flask.request.args['cols'] containing names of two columns in dataframe",
            "    :param dateCol: string from flask.request.args['dateCol'] with name of date-type column in dateframe for timeseries",
            "    :param date: string from flask.request.args['date'] date value in dateCol to filter dataframe to",
            "    :returns: JSON {",
            "        data: [{col1: 0.123, col2: 0.123, index: 1},...,{col1: 0.123, col2: 0.123, index: N}],",
            "        stats: {",
            "        stats: {",
            "            correlated: 50,",
            "            only_in_s0: 1,",
            "            only_in_s1: 2,",
            "            pearson: 0.987,",
            "            spearman: 0.879,",
            "        }",
            "        x: col1,",
            "        y: col2",
            "    } or {error: 'Exception message', traceback: 'Exception stacktrace'}",
            "    \"\"\"",
            "    cols = get_json_arg(request, \"cols\")",
            "    dummy_cols = get_json_arg(request, \"dummyCols\", [])",
            "    date_index = get_int_arg(request, \"index\")",
            "    date_col = get_str_arg(request, \"dateCol\")",
            "    rolling = get_bool_arg(request, \"rolling\")",
            "",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "    )",
            "    idx_col = str(\"_corr_index\")",
            "    y_cols = [cols[1], idx_col]",
            "    code = build_code_export(data_id)",
            "    selected_date = None",
            "    if rolling:",
            "        data = data[[c for c in data.columns if c in [date_col] + cols + dummy_cols]]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        window = get_int_arg(request, \"window\")",
            "        min_periods = get_int_arg(request, \"minPeriods\", default=0)",
            "        dates = data[date_col].sort_values().unique()",
            "        date_index = min(date_index + max(min_periods - 1, 1), len(dates) - 1)",
            "        selected_date = dates[date_index]",
            "        idx = min(data[data[date_col] == selected_date].index) + 1",
            "        selected_date = json_date(selected_date, nan_display=None)",
            "        selected_date = \"{} thru {}\".format(",
            "            json_date(dates[max(date_index - (window - 1), 0)]), selected_date",
            "        )",
            "        data = data.iloc[max(idx - window, 0) : idx]",
            "        data = data[cols + [date_col]].dropna(how=\"any\")",
            "        y_cols.append(date_col)",
            "        code.append(",
            "            (",
            "                \"idx = min(df[df['{date_col}'] == '{date}'].index) + 1\\n\"",
            "                \"scatter_data = scatter_data.iloc[max(idx - {window}, 0):idx]\\n\"",
            "                \"scatter_data = scatter_data['{cols}'].dropna(how='any')\"",
            "            ).format(",
            "                date_col=date_col,",
            "                date=selected_date,",
            "                window=window,",
            "                cols=\"', '\".join(sorted(list(set(cols)) + [date_col])),",
            "            )",
            "        )",
            "    else:",
            "        selected_cols = (",
            "            ([date_col] if date_index is not None else []) + cols + dummy_cols",
            "        )",
            "        data = data[[c for c in data.columns if c in selected_cols]]",
            "        data = update_df_for_encoded_strings(data, dummy_cols, cols, code)",
            "        if date_index is not None:",
            "            selected_date = data[date_col].sort_values().unique()[date_index]",
            "            data = data[data[date_col] == selected_date]",
            "            selected_date = json_date(selected_date, nan_display=None)",
            "        data = data[cols].dropna(how=\"any\")",
            "        code.append(",
            "            (",
            "                \"scatter_data = df[df['{date_col}'] == '{date}']\"",
            "                if date_index is not None",
            "                else \"scatter_data = df\"",
            "            ).format(date_col=date_col, date=selected_date)",
            "        )",
            "        code.append(",
            "            \"scatter_data = scatter_data['{cols}'].dropna(how='any')\".format(",
            "                cols=\"', '\".join(cols)",
            "            )",
            "        )",
            "",
            "    data[idx_col] = data.index",
            "    [col1, col2] = cols",
            "    s0 = data[col1]",
            "    s1 = data[col2]",
            "    pearson = s0.corr(s1, method=\"pearson\")",
            "    spearman = s0.corr(s1, method=\"spearman\")",
            "    pps = get_ppscore(data, col1, col2)",
            "    stats = dict(",
            "        pearson=\"N/A\" if pd.isnull(pearson) else pearson,",
            "        spearman=\"N/A\" if pd.isnull(spearman) else spearman,",
            "        pps=pps,",
            "        correlated=len(data),",
            "        only_in_s0=len(data[data[col1].isnull()]),",
            "        only_in_s1=len(data[data[col2].isnull()]),",
            "    )",
            "    code.append(",
            "        (",
            "            \"scatter_data['{idx_col}'] = scatter_data.index\\n\"",
            "            \"s0 = scatter_data['{col1}']\\n\"",
            "            \"s1 = scatter_data['{col2}']\\n\"",
            "            \"pearson = s0.corr(s1, method='pearson')\\n\"",
            "            \"spearman = s0.corr(s1, method='spearman')\\n\"",
            "            \"\\nimport ppscore\\n\\n\"",
            "            \"pps = ppscore.score(data, '{col1}', '{col2}')\\n\"",
            "            \"only_in_s0 = len(scatter_data[scatter_data['{col1}'].isnull()])\\n\"",
            "            \"only_in_s1 = len(scatter_data[scatter_data['{col2}'].isnull()])\"",
            "        ).format(col1=col1, col2=col2, idx_col=idx_col)",
            "    )",
            "",
            "    max_points = global_state.get_chart_settings()[\"scatter_points\"]",
            "    if len(data) > max_points:",
            "        return jsonify(",
            "            stats=stats,",
            "            code=\"\\n\".join(code),",
            "            error=\"Dataset exceeds {:,} records, cannot render scatter. Please apply filter...\".format(",
            "                max_points",
            "            ),",
            "            traceback=CHART_POINTS_LIMIT,",
            "        )",
            "    data, _code = build_base_chart(data, cols[0], y_cols, allow_duplicates=True)",
            "    data[\"x\"] = cols[0]",
            "    data[\"y\"] = cols[1]",
            "    data[\"stats\"] = stats",
            "    data[\"code\"] = \"\\n\".join(code)",
            "    data[\"date\"] = \" for {}\".format(selected_date) if selected_date else \"\"",
            "    return jsonify(data)",
            "",
            "",
            "def build_context_variables(data_id, new_context_vars=None):",
            "    \"\"\"",
            "    Build and return the dictionary of context variables associated with a process.",
            "    If the names of any new variables are not formatted properly, an exception will be raised.",
            "    New variables will overwrite the values of existing variables if they share the same name.",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :param new_context_vars: dictionary of name, value pairs for new context variables",
            "    :type new_context_vars: dict, optional",
            "    :returns: dict of the context variables for this process",
            "    :rtype: dict",
            "    \"\"\"",
            "    if new_context_vars:",
            "        for name, value in new_context_vars.items():",
            "            if not isinstance(name, string_types):",
            "                raise SyntaxError(",
            "                    \"{}, context variables must be a valid string\".format(name)",
            "                )",
            "            elif not name.replace(\"_\", \"\").isalnum():",
            "                raise SyntaxError(",
            "                    \"{}, context variables can only contain letters, digits, or underscores\".format(",
            "                        name",
            "                    )",
            "                )",
            "            elif name.startswith(\"_\"):",
            "                raise SyntaxError(",
            "                    \"{}, context variables can not start with an underscore\".format(",
            "                        name",
            "                    )",
            "                )",
            "",
            "    return dict_merge(global_state.get_context_variables(data_id), new_context_vars)",
            "",
            "",
            "@dtale.route(\"/filter-info/<data_id>\")",
            "@exception_decorator",
            "def get_filter_info(data_id):",
            "    \"\"\"",
            "    :class:`flask:flask.Flask` route which returns a view-only version of the query, column filters & context variables",
            "    to the front end.",
            "",
            "    :param data_id: integer string identifier for a D-Tale process's data",
            "    :type data_id: str",
            "    :return: JSON",
            "    \"\"\"",
            "",
            "    def value_as_str(value):",
            "        \"\"\"Convert values into a string representation that can be shown to the user in the front-end.\"\"\"",
            "        return str(value)[:1000]",
            "",
            "    ctxt_vars = global_state.get_context_variables(data_id) or {}",
            "    ctxt_vars = [dict(name=k, value=value_as_str(v)) for k, v in ctxt_vars.items()]",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    curr_settings = {",
            "        k: v",
            "        for k, v in curr_settings.items()",
            "        if k",
            "        in [",
            "            \"query\",",
            "            \"columnFilters\",",
            "            \"outlierFilters\",",
            "            \"predefinedFilters\",",
            "            \"invertFilter\",",
            "            \"highlightFilter\",",
            "        ]",
            "    }",
            "    return jsonify(contextVars=ctxt_vars, success=True, **curr_settings)",
            "",
            "",
            "@dtale.route(\"/xarray-coordinates/<data_id>\")",
            "@exception_decorator",
            "def get_xarray_coords(data_id):",
            "    ds = global_state.get_dataset(data_id)",
            "",
            "    def _format_dim(coord, count):",
            "        return dict(name=coord, count=count, dtype=ds.coords[coord].dtype.name)",
            "",
            "    coord_data = [_format_dim(coord, count) for coord, count in ds.coords.dims.items()]",
            "    return jsonify(data=coord_data)",
            "",
            "",
            "@dtale.route(\"/xarray-dimension-values/<data_id>/<dim>\")",
            "@exception_decorator",
            "def get_xarray_dimension_values(data_id, dim):",
            "    ds = global_state.get_dataset(data_id)",
            "    dim_entries = ds.coords[dim].data",
            "    dim = pd.DataFrame({\"value\": dim_entries})",
            "    dim_f, _ = build_formatters(dim)",
            "    return jsonify(data=dim_f.format_dicts(dim.itertuples()))",
            "",
            "",
            "@dtale.route(\"/update-xarray-selection/<data_id>\")",
            "@exception_decorator",
            "def update_xarray_selection(data_id):",
            "    ds = global_state.get_dataset(data_id)",
            "    selection = get_json_arg(request, \"selection\") or {}",
            "    df = convert_xarray_to_dataset(ds, **selection)",
            "    startup(data=df, data_id=data_id, ignore_duplicate=True)",
            "    global_state.set_dataset_dim(data_id, selection)",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/to-xarray/<data_id>\")",
            "@exception_decorator",
            "def to_xarray(data_id):",
            "    df = global_state.get_data(data_id)",
            "    index_cols = get_json_arg(request, \"index\")",
            "    ds = df.set_index(index_cols).to_xarray()",
            "    startup(data=ds, data_id=data_id, ignore_duplicate=True)",
            "    curr_settings = global_state.get_settings(data_id)",
            "    startup_code = \"df = df.set_index(['{index}']).to_xarray()\".format(",
            "        index=\"', '\".join(index_cols)",
            "    )",
            "    global_state.set_settings(",
            "        data_id, dict_merge(curr_settings, dict(startup_code=startup_code))",
            "    )",
            "    return jsonify(success=True)",
            "",
            "",
            "@dtale.route(\"/code-export/<data_id>\")",
            "@exception_decorator",
            "def get_code_export(data_id):",
            "    code = build_code_export(data_id)",
            "    return jsonify(code=\"\\n\".join(code), success=True)",
            "",
            "",
            "def build_chart_filename(chart_type, ext=\"html\"):",
            "    return \"{}_export_{}.{}\".format(",
            "        chart_type, json_timestamp(pd.Timestamp(\"now\")), ext",
            "    )",
            "",
            "",
            "def send_file(output, filename, content_type):",
            "    resp = make_response(output)",
            "    resp.headers[\"Content-Disposition\"] = \"attachment; filename=%s\" % filename",
            "    resp.headers[\"Content-Type\"] = content_type",
            "    return resp",
            "",
            "",
            "@dtale.route(\"/chart-export/<data_id>\")",
            "@exception_decorator",
            "def chart_export(data_id):",
            "    export_type = get_str_arg(request, \"export_type\")",
            "    params = chart_url_params(request.args.to_dict())",
            "    if export_type == \"png\":",
            "        output = export_png(data_id, params)",
            "        filename = build_chart_filename(params[\"chart_type\"], ext=\"png\")",
            "        content_type = \"image/png\"",
            "    else:",
            "        output = export_chart(data_id, params)",
            "        filename = build_chart_filename(params[\"chart_type\"])",
            "        content_type = \"text/html\"",
            "    return send_file(output, filename, content_type)",
            "",
            "",
            "@dtale.route(\"/chart-export-all/<data_id>\")",
            "@exception_decorator",
            "def chart_export_all(data_id):",
            "    params = chart_url_params(request.args.to_dict())",
            "    params[\"export_all\"] = True",
            "    output = export_chart(data_id, params)",
            "    filename = build_chart_filename(params[\"chart_type\"])",
            "    content_type = \"text/html\"",
            "    return send_file(output, filename, content_type)",
            "",
            "",
            "@dtale.route(\"/chart-csv-export/<data_id>\")",
            "@exception_decorator",
            "def chart_csv_export(data_id):",
            "    params = chart_url_params(request.args.to_dict())",
            "    csv_buffer = export_chart_data(data_id, params)",
            "    filename = build_chart_filename(params[\"chart_type\"], ext=\"csv\")",
            "    return send_file(csv_buffer.getvalue(), filename, \"text/csv\")",
            "",
            "",
            "@dtale.route(\"/cleanup-datasets\")",
            "@exception_decorator",
            "def cleanup_datasets():",
            "    data_ids = get_str_arg(request, \"dataIds\")",
            "    data_ids = (data_ids or \"\").split(\",\")",
            "    for data_id in data_ids:",
            "        global_state.cleanup(data_id)",
            "    return jsonify(success=True)",
            "",
            "",
            "def load_new_data(df, startup_code, name=None, return_id=False, settings=None):",
            "    instance = startup(data=df, name=name, ignore_duplicate=True)",
            "    curr_settings = global_state.get_settings(instance._data_id)",
            "    global_state.set_settings(",
            "        instance._data_id,",
            "        dict_merge(curr_settings, dict(startup_code=startup_code, **(settings or {}))),",
            "    )",
            "    if return_id:",
            "        return instance._data_id",
            "    return jsonify(success=True, data_id=instance._data_id)",
            "",
            "",
            "def handle_excel_upload(dfs):",
            "    sheet_names = list(dfs.keys())",
            "    data_ids = []",
            "    for sheet_name in sheet_names:",
            "        df, code = dfs[sheet_name]",
            "        if len(sheet_names) == 1:",
            "            return load_new_data(df, code, name=sheet_name)",
            "        data_id = load_new_data(df, code, name=sheet_name, return_id=True)",
            "        data_ids.append(dict(name=sheet_name, dataId=data_id))",
            "    return jsonify(dict(sheets=data_ids, success=True))",
            "",
            "",
            "UPLOAD_SEPARATORS = {\"comma\": \",\", \"tab\": \"\\t\", \"colon\": \":\", \"pipe\": \"|\"}",
            "",
            "",
            "def build_csv_kwargs(request):",
            "    # Set engine to python to auto detect delimiter...",
            "    kwargs = {\"sep\": None}",
            "    sep_type = request.form.get(\"separatorType\")",
            "",
            "    if sep_type in UPLOAD_SEPARATORS:",
            "        kwargs[\"sep\"] = UPLOAD_SEPARATORS[sep_type]",
            "    elif sep_type == \"custom\" and request.form.get(\"separator\"):",
            "        kwargs[\"sep\"] = request.form[\"separator\"]",
            "        kwargs[\"sep\"] = str(kwargs[\"sep\"]) if PY3 else kwargs[\"sep\"].encode(\"utf8\")",
            "",
            "    if \"header\" in request.form:",
            "        kwargs[\"header\"] = 0 if request.form[\"header\"] == \"true\" else None",
            "",
            "    return kwargs",
            "",
            "",
            "@dtale.route(\"/upload\", methods=[\"POST\"])",
            "@exception_decorator",
            "def upload():",
            "    if not request.files:",
            "        raise Exception(\"No file data loaded!\")",
            "    for filename in request.files:",
            "        contents = request.files[filename]",
            "        _, ext = os.path.splitext(filename)",
            "        if ext in [\".csv\", \".tsv\"]:",
            "            kwargs = build_csv_kwargs(request)",
            "            df = pd.read_csv(",
            "                StringIO(contents.read().decode()), engine=\"python\", **kwargs",
            "            )",
            "            return load_new_data(",
            "                df, \"df = pd.read_csv('{}', engine='python', sep=None)\".format(filename)",
            "            )",
            "        if ext in [\".xls\", \".xlsx\"]:",
            "            engine = \"xlrd\" if ext == \".xls\" else \"openpyxl\"",
            "            dfs = pd.read_excel(contents, sheet_name=None, engine=engine)",
            "",
            "            def build_xls_code(sheet_name):",
            "                return \"df = pd.read_excel('{}', sheet_name='{}', engine='{}')\".format(",
            "                    filename, sheet_name, engine",
            "                )",
            "",
            "            dfs = {",
            "                sheet_name: (df, build_xls_code(sheet_name))",
            "                for sheet_name, df in dfs.items()",
            "            }",
            "            return handle_excel_upload(dfs)",
            "        if \"parquet\" in filename:",
            "            df = pd.read_parquet(contents)",
            "            return load_new_data(df, \"df = pd.read_parquet('{}')\".format(filename))",
            "        raise Exception(\"File type of {} is not supported!\".format(ext))",
            "",
            "",
            "@dtale.route(\"/web-upload\")",
            "@exception_decorator",
            "def web_upload():",
            "    from dtale.cli.loaders.csv_loader import loader_func as load_csv",
            "    from dtale.cli.loaders.json_loader import loader_func as load_json",
            "    from dtale.cli.loaders.excel_loader import load_file as load_excel",
            "    from dtale.cli.loaders.parquet_loader import loader_func as load_parquet",
            "",
            "    if not global_state.get_app_settings().get(\"enable_web_uploads\", False):",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Web uploads not enabled! Web uploads are vulnerable to blind server side request forgery, please \"",
            "                    \"only use in trusted environments.\"",
            "                ),",
            "            )",
            "        )",
            "",
            "    data_type = get_str_arg(request, \"type\")",
            "    url = get_str_arg(request, \"url\")",
            "    proxy = get_str_arg(request, \"proxy\")",
            "    if data_type == \"csv\":",
            "        df = load_csv(path=url, proxy=proxy)",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.csv_loader import loader_func as load_csv\\n\\n\"",
            "            \"df = load_csv(path='{url}'{proxy})\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    elif data_type == \"tsv\":",
            "        df = load_csv(path=url, proxy=proxy, delimiter=\"\\t\")",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.csv_loader import loader_func as load_csv\\n\\n\"",
            "            \"df = load_csv(path='{url}'{proxy}, delimiter='\\t')\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    elif data_type == \"json\":",
            "        df = load_json(path=url, proxy=proxy)",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.json_loader import loader_func as load_json\\n\\n\"",
            "            \"df = load_json(path='{url}'{proxy})\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    elif data_type == \"excel\":",
            "        dfs = load_excel(path=url, proxy=proxy)",
            "",
            "        def build_xls_code(sheet_name):",
            "            return (",
            "                \"from dtale.cli.loaders.excel_loader import load_file as load_excel\\n\\n\"",
            "                \"df = load_excel(sheet_name='{sheet_name}', path='{url}'{proxy})\"",
            "            ).format(",
            "                sheet_name=sheet_name,",
            "                url=url,",
            "                proxy=\", '{}'\".format(proxy) if proxy else \"\",",
            "            )",
            "",
            "        dfs = {",
            "            sheet_name: (df, build_xls_code(sheet_name))",
            "            for sheet_name, df in dfs.items()",
            "        }",
            "        return handle_excel_upload(dfs)",
            "    elif data_type == \"parquet\":",
            "        df = load_parquet(path=url)",
            "        startup_code = (",
            "            \"from dtale.cli.loaders.parquet_loader import loader_func as load_parquet\\n\\n\"",
            "            \"df = load_parquet(path='{url}'{proxy})\"",
            "        ).format(url=url, proxy=\", '{}'\".format(proxy) if proxy else \"\")",
            "    return load_new_data(df, startup_code)",
            "",
            "",
            "@dtale.route(\"/datasets\")",
            "@exception_decorator",
            "def dataset_upload():",
            "    dataset = get_str_arg(request, \"dataset\")",
            "    startup_code = \"from dtale.datasets import {dataset}\\n\\n\" \"df = {dataset}()\".format(",
            "        dataset=dataset",
            "    )",
            "    df, settings = getattr(datasets, dataset)()",
            "    return load_new_data(df, startup_code, settings=settings)",
            "",
            "",
            "@dtale.route(\"/build-column-copy/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def build_column_text(data_id):",
            "    columns = request.json.get(\"columns\")",
            "    columns = json.loads(columns)",
            "",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    return data[columns].to_csv(index=False, sep=\"\\t\", header=False)",
            "",
            "",
            "@dtale.route(\"/build-row-copy/<data_id>\", methods=[\"POST\"])",
            "@exception_decorator",
            "def build_row_text(data_id):",
            "    start, end, rows, columns = (",
            "        request.json.get(p) for p in [\"start\", \"end\", \"rows\", \"columns\"]",
            "    )",
            "    columns = json.loads(columns)",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        build_query(data_id, global_state.get_query(data_id)),",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    if rows:",
            "        rows = json.loads(rows)",
            "        data = data.iloc[rows, :]",
            "    else:",
            "        start = int(start)",
            "        end = int(end)",
            "        data = data.iloc[(start - 1) : end, :]",
            "    return data[columns].to_csv(index=False, sep=\"\\t\", header=False)",
            "",
            "",
            "@dtale.route(\"/network-data/<data_id>\")",
            "@exception_decorator",
            "def network_data(data_id):",
            "    df = global_state.get_data(data_id)",
            "    to_col = get_str_arg(request, \"to\")",
            "    from_col = get_str_arg(request, \"from\")",
            "    group = get_str_arg(request, \"group\", \"\")",
            "    color = get_str_arg(request, \"color\", \"\")",
            "    weight = get_str_arg(request, \"weight\")",
            "",
            "    nodes = list(df[to_col].unique())",
            "    nodes += list(df[~df[from_col].isin(nodes)][from_col].unique())",
            "    nodes = sorted(nodes)",
            "    nodes = {node: node_id for node_id, node in enumerate(nodes, 1)}",
            "",
            "    edge_cols = [to_col, from_col]",
            "    if weight:",
            "        edge_cols.append(weight)",
            "",
            "    edges = df[[to_col, from_col]].applymap(nodes.get)",
            "    edges.columns = [\"to\", \"from\"]",
            "    if weight:",
            "        edges.loc[:, \"value\"] = df[weight]",
            "    edge_f = grid_formatter(grid_columns(edges), nan_display=\"nan\")",
            "    edges = edge_f.format_dicts(edges.itertuples())",
            "",
            "    def build_mapping(col):",
            "        if col:",
            "            return df[[from_col, col]].set_index(from_col)[col].astype(\"str\").to_dict()",
            "        return {}",
            "",
            "    group = build_mapping(group)",
            "    color = build_mapping(color)",
            "    groups = {}",
            "",
            "    def build_group(node, node_id):",
            "        group_val = group.get(node, \"N/A\")",
            "        groups[group_val] = node_id",
            "        return group_val",
            "",
            "    nodes = [",
            "        dict(",
            "            id=node_id,",
            "            label=node,",
            "            group=build_group(node, node_id),",
            "            color=color.get(node),",
            "        )",
            "        for node, node_id in nodes.items()",
            "    ]",
            "    return jsonify(dict(nodes=nodes, edges=edges, groups=groups, success=True))",
            "",
            "",
            "@dtale.route(\"/network-analysis/<data_id>\")",
            "@exception_decorator",
            "def network_analysis(data_id):",
            "    df = global_state.get_data(data_id)",
            "    to_col = get_str_arg(request, \"to\")",
            "    from_col = get_str_arg(request, \"from\")",
            "    weight = get_str_arg(request, \"weight\")",
            "",
            "    G = nx.Graph()",
            "    max_edge, min_edge, avg_weight = (None, None, None)",
            "    if weight:",
            "        G.add_weighted_edges_from(",
            "            [tuple(x) for x in df[[to_col, from_col, weight]].values]",
            "        )",
            "        sorted_edges = sorted(",
            "            G.edges(data=True), key=lambda x: x[2][\"weight\"], reverse=True",
            "        )",
            "        max_edge = sorted_edges[0]",
            "        min_edge = sorted_edges[-1]",
            "        avg_weight = df[weight].mean()",
            "    else:",
            "        G.add_edges_from([tuple(x) for x in df[[to_col, from_col]].values])",
            "",
            "    most_connected_node = max(dict(G.degree()).items(), key=lambda x: x[1])",
            "    return_data = {",
            "        \"node_ct\": len(G),",
            "        \"triangle_ct\": int(sum(nx.triangles(G).values()) / 3),",
            "        \"most_connected_node\": \"{} (Connections: {})\".format(*most_connected_node),",
            "        \"leaf_ct\": sum((1 for edge, degree in dict(G.degree()).items() if degree == 1)),",
            "        \"edge_ct\": sum(dict(G.degree()).values()),",
            "        \"max_edge\": (",
            "            None",
            "            if max_edge is None",
            "            else \"{} (source: {}, target: {})\".format(",
            "                max_edge[-1][\"weight\"], max_edge[0], max_edge[1]",
            "            )",
            "        ),",
            "        \"min_edge\": (",
            "            None",
            "            if min_edge is None",
            "            else \"{} (source: {}, target: {})\".format(",
            "                min_edge[-1][\"weight\"], min_edge[0], min_edge[1]",
            "            )",
            "        ),",
            "        \"avg_weight\": json_float(avg_weight),",
            "    }",
            "    return jsonify(dict(data=return_data, success=True))",
            "",
            "",
            "@dtale.route(\"/shortest-path/<data_id>\")",
            "@exception_decorator",
            "def shortest_path(data_id):",
            "    df = global_state.get_data(data_id)",
            "    to_col = get_str_arg(request, \"to\")",
            "    from_col = get_str_arg(request, \"from\")",
            "    start_val = get_str_arg(request, \"start\")",
            "    end_val = get_str_arg(request, \"end\")",
            "",
            "    G = nx.Graph()",
            "    G.add_edges_from([tuple(x) for x in df[[to_col, from_col]].values])",
            "    shortest_path = nx.shortest_path(G, source=start_val, target=end_val)",
            "    return jsonify(dict(data=shortest_path, success=True))",
            "",
            "",
            "@dtale.route(\"/sorted-sequential-diffs/<data_id>\")",
            "@exception_decorator",
            "def get_sorted_sequential_diffs(data_id):",
            "    column = get_str_arg(request, \"col\")",
            "    sort = get_str_arg(request, \"sort\")",
            "    df = global_state.get_data(data_id)",
            "    metrics, _ = build_sequential_diffs(df[column], column, sort=sort)",
            "    return jsonify(metrics)",
            "",
            "",
            "@dtale.route(\"/merge\", methods=[\"POST\"])",
            "@exception_decorator",
            "def build_merge():",
            "    cfg = request.json",
            "    name = cfg.get(\"name\")",
            "    builder = CombineData(cfg)",
            "    data = builder.build_data()",
            "    code = builder.build_code()",
            "    return load_new_data(data, code, name)",
            "",
            "",
            "@dtale.route(\"/missingno/<chart_type>/<data_id>\")",
            "@matplotlib_decorator",
            "@exception_decorator",
            "def build_missingno_chart(chart_type, data_id):",
            "    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas",
            "",
            "    df = global_state.get_data(data_id)",
            "    if chart_type == \"matrix\":",
            "        date_index = get_str_arg(request, \"date_index\")",
            "        freq = get_str_arg(request, \"freq\")",
            "        if date_index:",
            "            figure = msno.matrix(df.set_index(date_index), freq=freq)",
            "        else:",
            "            figure = msno.matrix(df)",
            "    elif chart_type == \"bar\":",
            "        figure = msno.bar(df)",
            "    elif chart_type == \"heatmap\":",
            "        figure = msno.heatmap(df)",
            "    elif chart_type == \"dendrogram\":",
            "        figure = msno.dendrogram(df)",
            "",
            "    output = BytesIO()",
            "    FigureCanvas(figure.get_figure()).print_png(output)",
            "    if get_bool_arg(request, \"file\"):",
            "        fname = \"missingno_{}.png\".format(chart_type)",
            "        return send_file(output.getvalue(), fname, \"image/png\")",
            "    return Response(output.getvalue(), mimetype=\"image/png\")",
            "",
            "",
            "@dtale.route(\"/drop-filtered-rows/<data_id>\")",
            "@exception_decorator",
            "def drop_filtered_rows(data_id):",
            "    curr_settings = global_state.get_settings(data_id) or {}",
            "    final_query = build_query(data_id, global_state.get_query(data_id))",
            "    curr_history = global_state.get_history(data_id) or []",
            "    curr_history += [",
            "        (",
            "            \"# drop filtered rows\\n\"",
            "            'df = df.query(\"{}\")'.format(final_query.replace(\"`\", \"\"))",
            "        )",
            "    ]",
            "    global_state.set_history(data_id, curr_history)",
            "    data = run_query(",
            "        handle_predefined(data_id),",
            "        final_query,",
            "        global_state.get_context_variables(data_id),",
            "        ignore_empty=True,",
            "    )",
            "    global_state.set_data(data_id, data)",
            "    global_state.set_dtypes(data_id, build_dtypes_state(data, []))",
            "    curr_predefined = curr_settings.get(\"predefinedFilters\", {})",
            "    global_state.update_settings(",
            "        data_id,",
            "        dict(",
            "            query=\"\",",
            "            columnFilters={},",
            "            outlierFilters={},",
            "            predefinedFilters={",
            "                k: dict_merge(v, {\"active\": False}) for k, v in curr_predefined.items()",
            "            },",
            "            invertFilter=False,",
            "        ),",
            "    )",
            "    return jsonify(dict(success=True))",
            "",
            "",
            "@dtale.route(\"/move-filters-to-custom/<data_id>\")",
            "@exception_decorator",
            "def move_filters_to_custom(data_id):",
            "    if not global_state.load_flag(data_id, \"enable_custom_filters\", False):",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Custom Filters not enabled! Custom filters are vulnerable to code injection attacks, please only \"",
            "                    \"use in trusted environments.\"",
            "                ),",
            "            )",
            "        )",
            "    query = build_query(data_id, global_state.get_query(data_id))",
            "    global_state.update_settings(",
            "        data_id,",
            "        {",
            "            \"columnFilters\": {},",
            "            \"outlierFilters\": {},",
            "            \"invertFilter\": False,",
            "            \"query\": query,",
            "        },",
            "    )",
            "    return jsonify(",
            "        dict(success=True, settings=global_state.get_settings(data_id) or {})",
            "    )",
            "",
            "",
            "@dtale.route(\"/gage-rnr/<data_id>\")",
            "@exception_decorator",
            "def build_gage_rnr(data_id):",
            "    data = load_filterable_data(data_id, request)",
            "    operator_cols = get_json_arg(request, \"operator\")",
            "    operators = data.groupby(operator_cols)",
            "    measurements = get_json_arg(request, \"measurements\") or [",
            "        col for col in data.columns if col not in operator_cols",
            "    ]",
            "    sizes = set((len(operator) for _, operator in operators))",
            "    if len(sizes) > 1:",
            "        return jsonify(",
            "            dict(",
            "                success=False,",
            "                error=(",
            "                    \"Operators do not have the same amount of parts! Please select a new operator with equal rows in \"",
            "                    \"each group.\"",
            "                ),",
            "            )",
            "        )",
            "",
            "    res = gage_rnr.GageRnR(",
            "        np.array([operator[measurements].values for _, operator in operators])",
            "    ).calculate()",
            "    df = pd.DataFrame({name: res[name] for name in gage_rnr.ResultNames})",
            "    df.index = df.index.map(lambda idx: gage_rnr.ComponentNames.get(idx, idx))",
            "    df.index.name = \"Sources of Variance\"",
            "    df.columns = [gage_rnr.ResultNames.get(col, col) for col in df.columns]",
            "    df = df[df.index.isin(df.index.dropna())]",
            "    df = df.reset_index()",
            "    overrides = {\"F\": lambda f, i, c: f.add_float(i, c, precision=3)}",
            "    return jsonify(dict_merge(dict(success=True), format_grid(df, overrides)))",
            "",
            "",
            "@dtale.route(\"/timeseries-analysis/<data_id>\")",
            "@exception_decorator",
            "def get_timeseries_analysis(data_id):",
            "    report_type = get_str_arg(request, \"type\")",
            "    cfg = json.loads(get_str_arg(request, \"cfg\"))",
            "    ts_rpt = TimeseriesAnalysis(data_id, report_type, cfg)",
            "    data = ts_rpt.run()",
            "    return jsonify(dict_merge(dict(success=True), data))",
            "",
            "",
            "@dtale.route(\"/arcticdb/libraries\")",
            "@exception_decorator",
            "def get_arcticdb_libraries():",
            "    if get_bool_arg(request, \"refresh\"):",
            "        global_state.store.load_libraries()",
            "",
            "    libraries = global_state.store.libraries",
            "    is_async = False",
            "    if len(libraries) > 500:",
            "        is_async = True",
            "        libraries = libraries[:5]",
            "    ret_data = {\"success\": True, \"libraries\": libraries, \"async\": is_async}",
            "    if global_state.store.lib is not None:",
            "        ret_data[\"library\"] = global_state.store.lib.name",
            "    return jsonify(ret_data)",
            "",
            "",
            "@dtale.route(\"/arcticdb/async-libraries\")",
            "@exception_decorator",
            "def get_async_arcticdb_libraries():",
            "    libraries = global_state.store.libraries",
            "    input = get_str_arg(request, \"input\")",
            "    vals = list(",
            "        itertools.islice((option(lib) for lib in libraries if lib.startswith(input)), 5)",
            "    )",
            "    return jsonify(vals)",
            "",
            "",
            "@dtale.route(\"/arcticdb/<library>/symbols\")",
            "@exception_decorator",
            "def get_arcticdb_symbols(library):",
            "    if get_bool_arg(request, \"refresh\") or library not in global_state.store._symbols:",
            "        global_state.store.load_symbols(library)",
            "",
            "    symbols = global_state.store._symbols[library]",
            "    is_async = False",
            "    if len(symbols) > 500:",
            "        is_async = True",
            "        symbols = symbols[:5]",
            "    return jsonify({\"success\": True, \"symbols\": symbols, \"async\": is_async})",
            "",
            "",
            "@dtale.route(\"/arcticdb/<library>/async-symbols\")",
            "@exception_decorator",
            "def get_async_arcticdb_symbols(library):",
            "    symbols = global_state.store._symbols[library]",
            "    input = get_str_arg(request, \"input\")",
            "    vals = list(",
            "        itertools.islice((option(sym) for sym in symbols if sym.startswith(input)), 5)",
            "    )",
            "    return jsonify(vals)",
            "",
            "",
            "@dtale.route(\"/arcticdb/load-description\")",
            "@exception_decorator",
            "def load_arcticdb_description():",
            "    from arcticc.pb2.descriptors_pb2 import _TYPEDESCRIPTOR_VALUETYPE",
            "",
            "    library = get_str_arg(request, \"library\")",
            "    symbol = get_str_arg(request, \"symbol\")",
            "",
            "    lib = global_state.store.conn[library]",
            "    description = lib.get_description(symbol)",
            "",
            "    columns = list(",
            "        map(",
            "            lambda c: \"{} ({})\".format(",
            "                c.name, _TYPEDESCRIPTOR_VALUETYPE.values[c.dtype.value_type].name",
            "            ),",
            "            sorted(description.columns, key=lambda c: c.name),",
            "        )",
            "    )",
            "    index = list(",
            "        map(",
            "            lambda i: \"{} ({})\".format(",
            "                i[0], _TYPEDESCRIPTOR_VALUETYPE.values[i[1].value_type].name",
            "            ),",
            "            zip(description.index.name, description.index.dtype),",
            "        )",
            "    )",
            "    rows = description.row_count",
            "",
            "    description_str = (",
            "        \"ROWS: {rows:,.0f}\\n\"",
            "        \"INDEX:\\n\"",
            "        \"\\t- {index}\\n\"",
            "        \"COLUMNS ({col_count}):\\n\"",
            "        \"\\t- {columns}\\n\"",
            "    ).format(",
            "        rows=rows,",
            "        index=\"\\n\\t- \".join(index),",
            "        col_count=len(columns),",
            "        columns=\"\\n\\t- \".join(columns),",
            "    )",
            "    return jsonify(",
            "        dict(success=True, library=library, symbol=symbol, description=description_str)",
            "    )",
            "",
            "",
            "@dtale.route(\"/arcticdb/load-symbol\")",
            "@exception_decorator",
            "def load_arcticdb_symbol():",
            "    library = get_str_arg(request, \"library\")",
            "    symbol = get_str_arg(request, \"symbol\")",
            "    data_id = \"{}|{}\".format(library, symbol)",
            "",
            "    if not global_state.store.lib or global_state.store.lib.name != library:",
            "        global_state.store.update_library(library)",
            "",
            "    startup(data=data_id)",
            "    startup_code = (",
            "        \"from arcticdb import Arctic\\n\"",
            "        \"from arcticdb.version_store._store import VersionedItem\\n\\n\"",
            "        \"conn = Arctic('{uri}')\\n\"",
            "        \"lib = conn.get_library('{library}')\\n\"",
            "        \"df = lib.read('{symbol}')\\n\"",
            "        \"if isinstance(data, VersionedItem):\\n\"",
            "        \"\\tdf = df.data\\n\"",
            "    ).format(uri=global_state.store.uri, library=library, symbol=symbol)",
            "    curr_settings = global_state.get_settings(data_id)",
            "    global_state.set_settings(",
            "        data_id, dict_merge(curr_settings, dict(startup_code=startup_code))",
            "    )",
            "    return jsonify(dict(success=True, data_id=data_id))",
            "",
            "",
            "@dtale.route(\"/aggregations/<data_id>/<col>\")",
            "@exception_decorator",
            "def load_aggregations(data_id, col):",
            "    data = load_filterable_data(data_id, request, columns=[col])",
            "    s = data[col]",
            "    sum = s.sum()",
            "    mean = s.mean()",
            "    median = s.median()",
            "    return jsonify(success=True, sum=float(sum), mean=float(mean), median=float(median))",
            "",
            "",
            "@dtale.route(\"/weighted-average/<data_id>/<col>/<weights>\")",
            "@exception_decorator",
            "def load_weighted_average(data_id, col, weights):",
            "    data = load_filterable_data(data_id, request, columns=[col, weights])",
            "    weighted_average = sum(data[col] * data[weights]) / sum(data[weights])",
            "    return jsonify(success=True, result=float(weighted_average))",
            "",
            "",
            "@dtale.route(\"/raw-pandas/<data_id>\")",
            "@exception_decorator",
            "def raw_pandas(data_id):",
            "    func_type = get_str_arg(request, \"func_type\", \"info\")",
            "    data = load_filterable_data(data_id, request)",
            "    if func_type == \"info\":",
            "        buffer = StringIO()",
            "        data.info(buf=buffer)",
            "        output = buffer.getvalue()",
            "        return jsonify(success=True, output=output)",
            "    elif func_type == \"nunique\":",
            "        output = data.nunique().to_string()",
            "        return jsonify(success=True, output=output)",
            "    elif func_type == \"describe\":",
            "        output = data.describe().T.to_string()",
            "        return jsonify(success=True, output=output)",
            "    return jsonify(",
            "        success=False, error=\"Invalid function type passed in: {}\".format(func_type)",
            "    )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "3385": [
                "get_chart_data"
            ]
        },
        "addLocation": [
            "dtale.views.exception_decorator.func",
            "django.db.models.sql.query.Query"
        ]
    }
}