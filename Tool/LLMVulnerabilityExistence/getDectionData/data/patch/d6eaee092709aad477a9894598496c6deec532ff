{
    "django/middleware/common.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " )"
            },
            "1": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from django.utils.deprecation import MiddlewareMixin, RemovedInDjango21Warning"
            },
            "2": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " from django.utils.encoding import force_text"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 14,
                "PatchRowcode": "+from django.utils.http import escape_leading_slashes"
            },
            "4": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " from django.utils.six.moves.urllib.parse import urlparse"
            },
            "5": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 91,
                "PatchRowcode": "         POST, PUT, or PATCH."
            },
            "8": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 92,
                "PatchRowcode": "         \"\"\""
            },
            "9": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "         new_path = request.get_full_path(force_append_slash=True)"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+        # Prevent construction of scheme relative urls."
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+        new_path = escape_leading_slashes(new_path)"
            },
            "12": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 96,
                "PatchRowcode": "         if settings.DEBUG and request.method in ('POST', 'PUT', 'PATCH'):"
            },
            "13": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 97,
                "PatchRowcode": "             raise RuntimeError("
            },
            "14": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "                 \"You called this URL via %(method)s, but the URL doesn't end \""
            }
        },
        "frontPatchFile": [
            "import re",
            "import warnings",
            "",
            "from django import http",
            "from django.conf import settings",
            "from django.core.exceptions import PermissionDenied",
            "from django.core.mail import mail_managers",
            "from django.urls import is_valid_path",
            "from django.utils.cache import (",
            "    cc_delim_re, get_conditional_response, set_response_etag,",
            ")",
            "from django.utils.deprecation import MiddlewareMixin, RemovedInDjango21Warning",
            "from django.utils.encoding import force_text",
            "from django.utils.six.moves.urllib.parse import urlparse",
            "",
            "",
            "class CommonMiddleware(MiddlewareMixin):",
            "    \"\"\"",
            "    \"Common\" middleware for taking care of some basic operations:",
            "",
            "        - Forbids access to User-Agents in settings.DISALLOWED_USER_AGENTS",
            "",
            "        - URL rewriting: Based on the APPEND_SLASH and PREPEND_WWW settings,",
            "          this middleware appends missing slashes and/or prepends missing",
            "          \"www.\"s.",
            "",
            "            - If APPEND_SLASH is set and the initial URL doesn't end with a",
            "              slash, and it is not found in urlpatterns, a new URL is formed by",
            "              appending a slash at the end. If this new URL is found in",
            "              urlpatterns, then an HTTP-redirect is returned to this new URL;",
            "              otherwise the initial URL is processed as usual.",
            "",
            "          This behavior can be customized by subclassing CommonMiddleware and",
            "          overriding the response_redirect_class attribute.",
            "",
            "        - ETags: If the USE_ETAGS setting is set, ETags will be calculated from",
            "          the entire page content and Not Modified responses will be returned",
            "          appropriately. USE_ETAGS is deprecated in favor of",
            "          ConditionalGetMiddleware.",
            "    \"\"\"",
            "",
            "    response_redirect_class = http.HttpResponsePermanentRedirect",
            "",
            "    def process_request(self, request):",
            "        \"\"\"",
            "        Check for denied User-Agents and rewrite the URL based on",
            "        settings.APPEND_SLASH and settings.PREPEND_WWW",
            "        \"\"\"",
            "",
            "        # Check for denied User-Agents",
            "        if 'HTTP_USER_AGENT' in request.META:",
            "            for user_agent_regex in settings.DISALLOWED_USER_AGENTS:",
            "                if user_agent_regex.search(request.META['HTTP_USER_AGENT']):",
            "                    raise PermissionDenied('Forbidden user agent')",
            "",
            "        # Check for a redirect based on settings.PREPEND_WWW",
            "        host = request.get_host()",
            "        must_prepend = settings.PREPEND_WWW and host and not host.startswith('www.')",
            "        redirect_url = ('%s://www.%s' % (request.scheme, host)) if must_prepend else ''",
            "",
            "        # Check if a slash should be appended",
            "        if self.should_redirect_with_slash(request):",
            "            path = self.get_full_path_with_slash(request)",
            "        else:",
            "            path = request.get_full_path()",
            "",
            "        # Return a redirect if necessary",
            "        if redirect_url or path != request.get_full_path():",
            "            redirect_url += path",
            "            return self.response_redirect_class(redirect_url)",
            "",
            "    def should_redirect_with_slash(self, request):",
            "        \"\"\"",
            "        Return True if settings.APPEND_SLASH is True and appending a slash to",
            "        the request path turns an invalid path into a valid one.",
            "        \"\"\"",
            "        if settings.APPEND_SLASH and not request.path_info.endswith('/'):",
            "            urlconf = getattr(request, 'urlconf', None)",
            "            return (",
            "                not is_valid_path(request.path_info, urlconf) and",
            "                is_valid_path('%s/' % request.path_info, urlconf)",
            "            )",
            "        return False",
            "",
            "    def get_full_path_with_slash(self, request):",
            "        \"\"\"",
            "        Return the full path of the request with a trailing slash appended.",
            "",
            "        Raise a RuntimeError if settings.DEBUG is True and request.method is",
            "        POST, PUT, or PATCH.",
            "        \"\"\"",
            "        new_path = request.get_full_path(force_append_slash=True)",
            "        if settings.DEBUG and request.method in ('POST', 'PUT', 'PATCH'):",
            "            raise RuntimeError(",
            "                \"You called this URL via %(method)s, but the URL doesn't end \"",
            "                \"in a slash and you have APPEND_SLASH set. Django can't \"",
            "                \"redirect to the slash URL while maintaining %(method)s data. \"",
            "                \"Change your form to point to %(url)s (note the trailing \"",
            "                \"slash), or set APPEND_SLASH=False in your Django settings.\" % {",
            "                    'method': request.method,",
            "                    'url': request.get_host() + new_path,",
            "                }",
            "            )",
            "        return new_path",
            "",
            "    def process_response(self, request, response):",
            "        \"\"\"",
            "        Calculate the ETag, if needed.",
            "",
            "        When the status code of the response is 404, it may redirect to a path",
            "        with an appended slash if should_redirect_with_slash() returns True.",
            "        \"\"\"",
            "        # If the given URL is \"Not Found\", then check if we should redirect to",
            "        # a path with a slash appended.",
            "        if response.status_code == 404:",
            "            if self.should_redirect_with_slash(request):",
            "                return self.response_redirect_class(self.get_full_path_with_slash(request))",
            "",
            "        if settings.USE_ETAGS and self.needs_etag(response):",
            "            warnings.warn(",
            "                \"The USE_ETAGS setting is deprecated in favor of \"",
            "                \"ConditionalGetMiddleware which sets the ETag regardless of \"",
            "                \"the setting. CommonMiddleware won't do ETag processing in \"",
            "                \"Django 2.1.\",",
            "                RemovedInDjango21Warning",
            "            )",
            "            if not response.has_header('ETag'):",
            "                set_response_etag(response)",
            "",
            "            if response.has_header('ETag'):",
            "                return get_conditional_response(",
            "                    request,",
            "                    etag=response['ETag'],",
            "                    response=response,",
            "                )",
            "        # Add the Content-Length header to non-streaming responses if not",
            "        # already set.",
            "        if not response.streaming and not response.has_header('Content-Length'):",
            "            response['Content-Length'] = str(len(response.content))",
            "",
            "        return response",
            "",
            "    def needs_etag(self, response):",
            "        \"\"\"",
            "        Return True if an ETag header should be added to response.",
            "        \"\"\"",
            "        cache_control_headers = cc_delim_re.split(response.get('Cache-Control', ''))",
            "        return all(header.lower() != 'no-store' for header in cache_control_headers)",
            "",
            "",
            "class BrokenLinkEmailsMiddleware(MiddlewareMixin):",
            "",
            "    def process_response(self, request, response):",
            "        \"\"\"",
            "        Send broken link emails for relevant 404 NOT FOUND responses.",
            "        \"\"\"",
            "        if response.status_code == 404 and not settings.DEBUG:",
            "            domain = request.get_host()",
            "            path = request.get_full_path()",
            "            referer = force_text(request.META.get('HTTP_REFERER', ''), errors='replace')",
            "",
            "            if not self.is_ignorable_request(request, path, domain, referer):",
            "                ua = force_text(request.META.get('HTTP_USER_AGENT', '<none>'), errors='replace')",
            "                ip = request.META.get('REMOTE_ADDR', '<none>')",
            "                mail_managers(",
            "                    \"Broken %slink on %s\" % (",
            "                        ('INTERNAL ' if self.is_internal_request(domain, referer) else ''),",
            "                        domain",
            "                    ),",
            "                    \"Referrer: %s\\nRequested URL: %s\\nUser agent: %s\\n\"",
            "                    \"IP address: %s\\n\" % (referer, path, ua, ip),",
            "                    fail_silently=True)",
            "        return response",
            "",
            "    def is_internal_request(self, domain, referer):",
            "        \"\"\"",
            "        Returns True if the referring URL is the same domain as the current request.",
            "        \"\"\"",
            "        # Different subdomains are treated as different domains.",
            "        return bool(re.match(\"^https?://%s/\" % re.escape(domain), referer))",
            "",
            "    def is_ignorable_request(self, request, uri, domain, referer):",
            "        \"\"\"",
            "        Return True if the given request *shouldn't* notify the site managers",
            "        according to project settings or in situations outlined by the inline",
            "        comments.",
            "        \"\"\"",
            "        # The referer is empty.",
            "        if not referer:",
            "            return True",
            "",
            "        # APPEND_SLASH is enabled and the referer is equal to the current URL",
            "        # without a trailing slash indicating an internal redirect.",
            "        if settings.APPEND_SLASH and uri.endswith('/') and referer == uri[:-1]:",
            "            return True",
            "",
            "        # A '?' in referer is identified as a search engine source.",
            "        if not self.is_internal_request(domain, referer) and '?' in referer:",
            "            return True",
            "",
            "        # The referer is equal to the current URL, ignoring the scheme (assumed",
            "        # to be a poorly implemented bot).",
            "        parsed_referer = urlparse(referer)",
            "        if parsed_referer.netloc in ['', domain] and parsed_referer.path == uri:",
            "            return True",
            "",
            "        return any(pattern.search(uri) for pattern in settings.IGNORABLE_404_URLS)"
        ],
        "afterPatchFile": [
            "import re",
            "import warnings",
            "",
            "from django import http",
            "from django.conf import settings",
            "from django.core.exceptions import PermissionDenied",
            "from django.core.mail import mail_managers",
            "from django.urls import is_valid_path",
            "from django.utils.cache import (",
            "    cc_delim_re, get_conditional_response, set_response_etag,",
            ")",
            "from django.utils.deprecation import MiddlewareMixin, RemovedInDjango21Warning",
            "from django.utils.encoding import force_text",
            "from django.utils.http import escape_leading_slashes",
            "from django.utils.six.moves.urllib.parse import urlparse",
            "",
            "",
            "class CommonMiddleware(MiddlewareMixin):",
            "    \"\"\"",
            "    \"Common\" middleware for taking care of some basic operations:",
            "",
            "        - Forbids access to User-Agents in settings.DISALLOWED_USER_AGENTS",
            "",
            "        - URL rewriting: Based on the APPEND_SLASH and PREPEND_WWW settings,",
            "          this middleware appends missing slashes and/or prepends missing",
            "          \"www.\"s.",
            "",
            "            - If APPEND_SLASH is set and the initial URL doesn't end with a",
            "              slash, and it is not found in urlpatterns, a new URL is formed by",
            "              appending a slash at the end. If this new URL is found in",
            "              urlpatterns, then an HTTP-redirect is returned to this new URL;",
            "              otherwise the initial URL is processed as usual.",
            "",
            "          This behavior can be customized by subclassing CommonMiddleware and",
            "          overriding the response_redirect_class attribute.",
            "",
            "        - ETags: If the USE_ETAGS setting is set, ETags will be calculated from",
            "          the entire page content and Not Modified responses will be returned",
            "          appropriately. USE_ETAGS is deprecated in favor of",
            "          ConditionalGetMiddleware.",
            "    \"\"\"",
            "",
            "    response_redirect_class = http.HttpResponsePermanentRedirect",
            "",
            "    def process_request(self, request):",
            "        \"\"\"",
            "        Check for denied User-Agents and rewrite the URL based on",
            "        settings.APPEND_SLASH and settings.PREPEND_WWW",
            "        \"\"\"",
            "",
            "        # Check for denied User-Agents",
            "        if 'HTTP_USER_AGENT' in request.META:",
            "            for user_agent_regex in settings.DISALLOWED_USER_AGENTS:",
            "                if user_agent_regex.search(request.META['HTTP_USER_AGENT']):",
            "                    raise PermissionDenied('Forbidden user agent')",
            "",
            "        # Check for a redirect based on settings.PREPEND_WWW",
            "        host = request.get_host()",
            "        must_prepend = settings.PREPEND_WWW and host and not host.startswith('www.')",
            "        redirect_url = ('%s://www.%s' % (request.scheme, host)) if must_prepend else ''",
            "",
            "        # Check if a slash should be appended",
            "        if self.should_redirect_with_slash(request):",
            "            path = self.get_full_path_with_slash(request)",
            "        else:",
            "            path = request.get_full_path()",
            "",
            "        # Return a redirect if necessary",
            "        if redirect_url or path != request.get_full_path():",
            "            redirect_url += path",
            "            return self.response_redirect_class(redirect_url)",
            "",
            "    def should_redirect_with_slash(self, request):",
            "        \"\"\"",
            "        Return True if settings.APPEND_SLASH is True and appending a slash to",
            "        the request path turns an invalid path into a valid one.",
            "        \"\"\"",
            "        if settings.APPEND_SLASH and not request.path_info.endswith('/'):",
            "            urlconf = getattr(request, 'urlconf', None)",
            "            return (",
            "                not is_valid_path(request.path_info, urlconf) and",
            "                is_valid_path('%s/' % request.path_info, urlconf)",
            "            )",
            "        return False",
            "",
            "    def get_full_path_with_slash(self, request):",
            "        \"\"\"",
            "        Return the full path of the request with a trailing slash appended.",
            "",
            "        Raise a RuntimeError if settings.DEBUG is True and request.method is",
            "        POST, PUT, or PATCH.",
            "        \"\"\"",
            "        new_path = request.get_full_path(force_append_slash=True)",
            "        # Prevent construction of scheme relative urls.",
            "        new_path = escape_leading_slashes(new_path)",
            "        if settings.DEBUG and request.method in ('POST', 'PUT', 'PATCH'):",
            "            raise RuntimeError(",
            "                \"You called this URL via %(method)s, but the URL doesn't end \"",
            "                \"in a slash and you have APPEND_SLASH set. Django can't \"",
            "                \"redirect to the slash URL while maintaining %(method)s data. \"",
            "                \"Change your form to point to %(url)s (note the trailing \"",
            "                \"slash), or set APPEND_SLASH=False in your Django settings.\" % {",
            "                    'method': request.method,",
            "                    'url': request.get_host() + new_path,",
            "                }",
            "            )",
            "        return new_path",
            "",
            "    def process_response(self, request, response):",
            "        \"\"\"",
            "        Calculate the ETag, if needed.",
            "",
            "        When the status code of the response is 404, it may redirect to a path",
            "        with an appended slash if should_redirect_with_slash() returns True.",
            "        \"\"\"",
            "        # If the given URL is \"Not Found\", then check if we should redirect to",
            "        # a path with a slash appended.",
            "        if response.status_code == 404:",
            "            if self.should_redirect_with_slash(request):",
            "                return self.response_redirect_class(self.get_full_path_with_slash(request))",
            "",
            "        if settings.USE_ETAGS and self.needs_etag(response):",
            "            warnings.warn(",
            "                \"The USE_ETAGS setting is deprecated in favor of \"",
            "                \"ConditionalGetMiddleware which sets the ETag regardless of \"",
            "                \"the setting. CommonMiddleware won't do ETag processing in \"",
            "                \"Django 2.1.\",",
            "                RemovedInDjango21Warning",
            "            )",
            "            if not response.has_header('ETag'):",
            "                set_response_etag(response)",
            "",
            "            if response.has_header('ETag'):",
            "                return get_conditional_response(",
            "                    request,",
            "                    etag=response['ETag'],",
            "                    response=response,",
            "                )",
            "        # Add the Content-Length header to non-streaming responses if not",
            "        # already set.",
            "        if not response.streaming and not response.has_header('Content-Length'):",
            "            response['Content-Length'] = str(len(response.content))",
            "",
            "        return response",
            "",
            "    def needs_etag(self, response):",
            "        \"\"\"",
            "        Return True if an ETag header should be added to response.",
            "        \"\"\"",
            "        cache_control_headers = cc_delim_re.split(response.get('Cache-Control', ''))",
            "        return all(header.lower() != 'no-store' for header in cache_control_headers)",
            "",
            "",
            "class BrokenLinkEmailsMiddleware(MiddlewareMixin):",
            "",
            "    def process_response(self, request, response):",
            "        \"\"\"",
            "        Send broken link emails for relevant 404 NOT FOUND responses.",
            "        \"\"\"",
            "        if response.status_code == 404 and not settings.DEBUG:",
            "            domain = request.get_host()",
            "            path = request.get_full_path()",
            "            referer = force_text(request.META.get('HTTP_REFERER', ''), errors='replace')",
            "",
            "            if not self.is_ignorable_request(request, path, domain, referer):",
            "                ua = force_text(request.META.get('HTTP_USER_AGENT', '<none>'), errors='replace')",
            "                ip = request.META.get('REMOTE_ADDR', '<none>')",
            "                mail_managers(",
            "                    \"Broken %slink on %s\" % (",
            "                        ('INTERNAL ' if self.is_internal_request(domain, referer) else ''),",
            "                        domain",
            "                    ),",
            "                    \"Referrer: %s\\nRequested URL: %s\\nUser agent: %s\\n\"",
            "                    \"IP address: %s\\n\" % (referer, path, ua, ip),",
            "                    fail_silently=True)",
            "        return response",
            "",
            "    def is_internal_request(self, domain, referer):",
            "        \"\"\"",
            "        Returns True if the referring URL is the same domain as the current request.",
            "        \"\"\"",
            "        # Different subdomains are treated as different domains.",
            "        return bool(re.match(\"^https?://%s/\" % re.escape(domain), referer))",
            "",
            "    def is_ignorable_request(self, request, uri, domain, referer):",
            "        \"\"\"",
            "        Return True if the given request *shouldn't* notify the site managers",
            "        according to project settings or in situations outlined by the inline",
            "        comments.",
            "        \"\"\"",
            "        # The referer is empty.",
            "        if not referer:",
            "            return True",
            "",
            "        # APPEND_SLASH is enabled and the referer is equal to the current URL",
            "        # without a trailing slash indicating an internal redirect.",
            "        if settings.APPEND_SLASH and uri.endswith('/') and referer == uri[:-1]:",
            "            return True",
            "",
            "        # A '?' in referer is identified as a search engine source.",
            "        if not self.is_internal_request(domain, referer) and '?' in referer:",
            "            return True",
            "",
            "        # The referer is equal to the current URL, ignoring the scheme (assumed",
            "        # to be a poorly implemented bot).",
            "        parsed_referer = urlparse(referer)",
            "        if parsed_referer.netloc in ['', domain] and parsed_referer.path == uri:",
            "            return True",
            "",
            "        return any(pattern.search(uri) for pattern in settings.IGNORABLE_404_URLS)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "airflow.www.views.Airflow",
            "django.middleware.common.CommonMiddleware.process_request",
            "django.middleware.common.CommonMiddleware.process_response"
        ]
    },
    "django/urls/resolvers.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from django.utils.datastructures import MultiValueDict"
            },
            "1": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from django.utils.encoding import force_str, force_text"
            },
            "2": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from django.utils.functional import cached_property"
            },
            "3": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from django.utils.http import RFC3986_SUBDELIMS, urlquote"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+from django.utils.http import ("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+    RFC3986_SUBDELIMS, escape_leading_slashes, urlquote,"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+)"
            },
            "7": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from django.utils.regex_helper import normalize"
            },
            "8": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from django.utils.translation import get_language"
            },
            "9": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 465,
                "afterPatchRowNumber": 467,
                "PatchRowcode": "                     # safe characters from `pchar` definition of RFC 3986"
            },
            "11": {
                "beforePatchRowNumber": 466,
                "afterPatchRowNumber": 468,
                "PatchRowcode": "                     url = urlquote(candidate_pat % candidate_subs, safe=RFC3986_SUBDELIMS + str('/~:@'))"
            },
            "12": {
                "beforePatchRowNumber": 467,
                "afterPatchRowNumber": 469,
                "PatchRowcode": "                     # Don't allow construction of scheme relative urls."
            },
            "13": {
                "beforePatchRowNumber": 468,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    if url.startswith('//'):"
            },
            "14": {
                "beforePatchRowNumber": 469,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        url = '/%%2F%s' % url[2:]"
            },
            "15": {
                "beforePatchRowNumber": 470,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    return url"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 470,
                "PatchRowcode": "+                    return escape_leading_slashes(url)"
            },
            "17": {
                "beforePatchRowNumber": 471,
                "afterPatchRowNumber": 471,
                "PatchRowcode": "         # lookup_view can be URL name or callable, but callables are not"
            },
            "18": {
                "beforePatchRowNumber": 472,
                "afterPatchRowNumber": 472,
                "PatchRowcode": "         # friendly in error messages."
            },
            "19": {
                "beforePatchRowNumber": 473,
                "afterPatchRowNumber": 473,
                "PatchRowcode": "         m = getattr(lookup_view, '__module__', None)"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "This module converts requested URLs to callback view functions.",
            "",
            "RegexURLResolver is the main class here. Its resolve() method takes a URL (as",
            "a string) and returns a ResolverMatch object which provides access to all",
            "attributes of the resolved URL match.",
            "\"\"\"",
            "from __future__ import unicode_literals",
            "",
            "import functools",
            "import re",
            "import threading",
            "from importlib import import_module",
            "",
            "from django.conf import settings",
            "from django.core.checks import Warning",
            "from django.core.checks.urls import check_resolver",
            "from django.core.exceptions import ImproperlyConfigured",
            "from django.utils import lru_cache, six",
            "from django.utils.datastructures import MultiValueDict",
            "from django.utils.encoding import force_str, force_text",
            "from django.utils.functional import cached_property",
            "from django.utils.http import RFC3986_SUBDELIMS, urlquote",
            "from django.utils.regex_helper import normalize",
            "from django.utils.translation import get_language",
            "",
            "from .exceptions import NoReverseMatch, Resolver404",
            "from .utils import get_callable",
            "",
            "",
            "class ResolverMatch(object):",
            "    def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None):",
            "        self.func = func",
            "        self.args = args",
            "        self.kwargs = kwargs",
            "        self.url_name = url_name",
            "",
            "        # If a URLRegexResolver doesn't have a namespace or app_name, it passes",
            "        # in an empty value.",
            "        self.app_names = [x for x in app_names if x] if app_names else []",
            "        self.app_name = ':'.join(self.app_names)",
            "        self.namespaces = [x for x in namespaces if x] if namespaces else []",
            "        self.namespace = ':'.join(self.namespaces)",
            "",
            "        if not hasattr(func, '__name__'):",
            "            # A class-based view",
            "            self._func_path = '.'.join([func.__class__.__module__, func.__class__.__name__])",
            "        else:",
            "            # A function-based view",
            "            self._func_path = '.'.join([func.__module__, func.__name__])",
            "",
            "        view_path = url_name or self._func_path",
            "        self.view_name = ':'.join(self.namespaces + [view_path])",
            "",
            "    def __getitem__(self, index):",
            "        return (self.func, self.args, self.kwargs)[index]",
            "",
            "    def __repr__(self):",
            "        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s)\" % (",
            "            self._func_path, self.args, self.kwargs, self.url_name,",
            "            self.app_names, self.namespaces,",
            "        )",
            "",
            "",
            "@lru_cache.lru_cache(maxsize=None)",
            "def get_resolver(urlconf=None):",
            "    if urlconf is None:",
            "        from django.conf import settings",
            "        urlconf = settings.ROOT_URLCONF",
            "    return RegexURLResolver(r'^/', urlconf)",
            "",
            "",
            "@lru_cache.lru_cache(maxsize=None)",
            "def get_ns_resolver(ns_pattern, resolver):",
            "    # Build a namespaced resolver for the given parent URLconf pattern.",
            "    # This makes it possible to have captured parameters in the parent",
            "    # URLconf pattern.",
            "    ns_resolver = RegexURLResolver(ns_pattern, resolver.url_patterns)",
            "    return RegexURLResolver(r'^/', [ns_resolver])",
            "",
            "",
            "class LocaleRegexDescriptor(object):",
            "    def __get__(self, instance, cls=None):",
            "        \"\"\"",
            "        Return a compiled regular expression based on the active language.",
            "        \"\"\"",
            "        if instance is None:",
            "            return self",
            "        # As a performance optimization, if the given regex string is a regular",
            "        # string (not a lazily-translated string proxy), compile it once and",
            "        # avoid per-language compilation.",
            "        if isinstance(instance._regex, six.string_types):",
            "            instance.__dict__['regex'] = self._compile(instance._regex)",
            "            return instance.__dict__['regex']",
            "        language_code = get_language()",
            "        if language_code not in instance._regex_dict:",
            "            instance._regex_dict[language_code] = self._compile(force_text(instance._regex))",
            "        return instance._regex_dict[language_code]",
            "",
            "    def _compile(self, regex):",
            "        \"\"\"",
            "        Compile and return the given regular expression.",
            "        \"\"\"",
            "        try:",
            "            return re.compile(regex, re.UNICODE)",
            "        except re.error as e:",
            "            raise ImproperlyConfigured(",
            "                '\"%s\" is not a valid regular expression: %s' %",
            "                (regex, six.text_type(e))",
            "            )",
            "",
            "",
            "class LocaleRegexProvider(object):",
            "    \"\"\"",
            "    A mixin to provide a default regex property which can vary by active",
            "    language.",
            "    \"\"\"",
            "    def __init__(self, regex):",
            "        # regex is either a string representing a regular expression, or a",
            "        # translatable string (using ugettext_lazy) representing a regular",
            "        # expression.",
            "        self._regex = regex",
            "        self._regex_dict = {}",
            "",
            "    regex = LocaleRegexDescriptor()",
            "",
            "    def describe(self):",
            "        \"\"\"",
            "        Format the URL pattern for display in warning messages.",
            "        \"\"\"",
            "        description = \"'{}'\".format(self.regex.pattern)",
            "        if getattr(self, 'name', False):",
            "            description += \" [name='{}']\".format(self.name)",
            "        return description",
            "",
            "    def _check_pattern_startswith_slash(self):",
            "        \"\"\"",
            "        Check that the pattern does not begin with a forward slash.",
            "        \"\"\"",
            "        regex_pattern = self.regex.pattern",
            "        if not settings.APPEND_SLASH:",
            "            # Skip check as it can be useful to start a URL pattern with a slash",
            "            # when APPEND_SLASH=False.",
            "            return []",
            "        if (regex_pattern.startswith('/') or regex_pattern.startswith('^/')) and not regex_pattern.endswith('/'):",
            "            warning = Warning(",
            "                \"Your URL pattern {} has a regex beginning with a '/'. Remove this \"",
            "                \"slash as it is unnecessary. If this pattern is targeted in an \"",
            "                \"include(), ensure the include() pattern has a trailing '/'.\".format(",
            "                    self.describe()",
            "                ),",
            "                id=\"urls.W002\",",
            "            )",
            "            return [warning]",
            "        else:",
            "            return []",
            "",
            "",
            "class RegexURLPattern(LocaleRegexProvider):",
            "    def __init__(self, regex, callback, default_args=None, name=None):",
            "        LocaleRegexProvider.__init__(self, regex)",
            "        self.callback = callback  # the view",
            "        self.default_args = default_args or {}",
            "        self.name = name",
            "",
            "    def __repr__(self):",
            "        return force_str('<%s %s %s>' % (self.__class__.__name__, self.name, self.regex.pattern))",
            "",
            "    def check(self):",
            "        warnings = self._check_pattern_name()",
            "        if not warnings:",
            "            warnings = self._check_pattern_startswith_slash()",
            "        return warnings",
            "",
            "    def _check_pattern_name(self):",
            "        \"\"\"",
            "        Check that the pattern name does not contain a colon.",
            "        \"\"\"",
            "        if self.name is not None and \":\" in self.name:",
            "            warning = Warning(",
            "                \"Your URL pattern {} has a name including a ':'. Remove the colon, to \"",
            "                \"avoid ambiguous namespace references.\".format(self.describe()),",
            "                id=\"urls.W003\",",
            "            )",
            "            return [warning]",
            "        else:",
            "            return []",
            "",
            "    def resolve(self, path):",
            "        match = self.regex.search(path)",
            "        if match:",
            "            # If there are any named groups, use those as kwargs, ignoring",
            "            # non-named groups. Otherwise, pass all non-named arguments as",
            "            # positional arguments.",
            "            kwargs = match.groupdict()",
            "            args = () if kwargs else match.groups()",
            "            # In both cases, pass any extra_kwargs as **kwargs.",
            "            kwargs.update(self.default_args)",
            "            return ResolverMatch(self.callback, args, kwargs, self.name)",
            "",
            "    @cached_property",
            "    def lookup_str(self):",
            "        \"\"\"",
            "        A string that identifies the view (e.g. 'path.to.view_function' or",
            "        'path.to.ClassBasedView').",
            "        \"\"\"",
            "        callback = self.callback",
            "        # Python 3.5 collapses nested partials, so can change \"while\" to \"if\"",
            "        # when it's the minimum supported version.",
            "        while isinstance(callback, functools.partial):",
            "            callback = callback.func",
            "        if not hasattr(callback, '__name__'):",
            "            return callback.__module__ + \".\" + callback.__class__.__name__",
            "        elif six.PY3:",
            "            return callback.__module__ + \".\" + callback.__qualname__",
            "        else:",
            "            # PY2 does not support __qualname__",
            "            return callback.__module__ + \".\" + callback.__name__",
            "",
            "",
            "class RegexURLResolver(LocaleRegexProvider):",
            "    def __init__(self, regex, urlconf_name, default_kwargs=None, app_name=None, namespace=None):",
            "        LocaleRegexProvider.__init__(self, regex)",
            "        # urlconf_name is the dotted Python path to the module defining",
            "        # urlpatterns. It may also be an object with an urlpatterns attribute",
            "        # or urlpatterns itself.",
            "        self.urlconf_name = urlconf_name",
            "        self.callback = None",
            "        self.default_kwargs = default_kwargs or {}",
            "        self.namespace = namespace",
            "        self.app_name = app_name",
            "        self._reverse_dict = {}",
            "        self._namespace_dict = {}",
            "        self._app_dict = {}",
            "        # set of dotted paths to all functions and classes that are used in",
            "        # urlpatterns",
            "        self._callback_strs = set()",
            "        self._populated = False",
            "        self._local = threading.local()",
            "",
            "    def __repr__(self):",
            "        if isinstance(self.urlconf_name, list) and len(self.urlconf_name):",
            "            # Don't bother to output the whole list, it can be huge",
            "            urlconf_repr = '<%s list>' % self.urlconf_name[0].__class__.__name__",
            "        else:",
            "            urlconf_repr = repr(self.urlconf_name)",
            "        return str('<%s %s (%s:%s) %s>') % (",
            "            self.__class__.__name__, urlconf_repr, self.app_name,",
            "            self.namespace, self.regex.pattern,",
            "        )",
            "",
            "    def check(self):",
            "        warnings = self._check_include_trailing_dollar()",
            "        for pattern in self.url_patterns:",
            "            warnings.extend(check_resolver(pattern))",
            "        if not warnings:",
            "            warnings = self._check_pattern_startswith_slash()",
            "        return warnings",
            "",
            "    def _check_include_trailing_dollar(self):",
            "        \"\"\"",
            "        Check that include is not used with a regex ending with a dollar.",
            "        \"\"\"",
            "        regex_pattern = self.regex.pattern",
            "        if regex_pattern.endswith('$') and not regex_pattern.endswith(r'\\$'):",
            "            warning = Warning(",
            "                \"Your URL pattern {} uses include with a regex ending with a '$'. \"",
            "                \"Remove the dollar from the regex to avoid problems including \"",
            "                \"URLs.\".format(self.describe()),",
            "                id=\"urls.W001\",",
            "            )",
            "            return [warning]",
            "        else:",
            "            return []",
            "",
            "    def _populate(self):",
            "        # Short-circuit if called recursively in this thread to prevent",
            "        # infinite recursion. Concurrent threads may call this at the same",
            "        # time and will need to continue, so set 'populating' on a",
            "        # thread-local variable.",
            "        if getattr(self._local, 'populating', False):",
            "            return",
            "        self._local.populating = True",
            "        lookups = MultiValueDict()",
            "        namespaces = {}",
            "        apps = {}",
            "        language_code = get_language()",
            "        for pattern in reversed(self.url_patterns):",
            "            if isinstance(pattern, RegexURLPattern):",
            "                self._callback_strs.add(pattern.lookup_str)",
            "            p_pattern = pattern.regex.pattern",
            "            if p_pattern.startswith('^'):",
            "                p_pattern = p_pattern[1:]",
            "            if isinstance(pattern, RegexURLResolver):",
            "                if pattern.namespace:",
            "                    namespaces[pattern.namespace] = (p_pattern, pattern)",
            "                    if pattern.app_name:",
            "                        apps.setdefault(pattern.app_name, []).append(pattern.namespace)",
            "                else:",
            "                    parent_pat = pattern.regex.pattern",
            "                    for name in pattern.reverse_dict:",
            "                        for matches, pat, defaults in pattern.reverse_dict.getlist(name):",
            "                            new_matches = normalize(parent_pat + pat)",
            "                            lookups.appendlist(",
            "                                name,",
            "                                (",
            "                                    new_matches,",
            "                                    p_pattern + pat,",
            "                                    dict(defaults, **pattern.default_kwargs),",
            "                                )",
            "                            )",
            "                    for namespace, (prefix, sub_pattern) in pattern.namespace_dict.items():",
            "                        namespaces[namespace] = (p_pattern + prefix, sub_pattern)",
            "                    for app_name, namespace_list in pattern.app_dict.items():",
            "                        apps.setdefault(app_name, []).extend(namespace_list)",
            "                if not getattr(pattern._local, 'populating', False):",
            "                    pattern._populate()",
            "                self._callback_strs.update(pattern._callback_strs)",
            "            else:",
            "                bits = normalize(p_pattern)",
            "                lookups.appendlist(pattern.callback, (bits, p_pattern, pattern.default_args))",
            "                if pattern.name is not None:",
            "                    lookups.appendlist(pattern.name, (bits, p_pattern, pattern.default_args))",
            "        self._reverse_dict[language_code] = lookups",
            "        self._namespace_dict[language_code] = namespaces",
            "        self._app_dict[language_code] = apps",
            "        self._populated = True",
            "        self._local.populating = False",
            "",
            "    @property",
            "    def reverse_dict(self):",
            "        language_code = get_language()",
            "        if language_code not in self._reverse_dict:",
            "            self._populate()",
            "        return self._reverse_dict[language_code]",
            "",
            "    @property",
            "    def namespace_dict(self):",
            "        language_code = get_language()",
            "        if language_code not in self._namespace_dict:",
            "            self._populate()",
            "        return self._namespace_dict[language_code]",
            "",
            "    @property",
            "    def app_dict(self):",
            "        language_code = get_language()",
            "        if language_code not in self._app_dict:",
            "            self._populate()",
            "        return self._app_dict[language_code]",
            "",
            "    def _is_callback(self, name):",
            "        if not self._populated:",
            "            self._populate()",
            "        return name in self._callback_strs",
            "",
            "    def resolve(self, path):",
            "        path = force_text(path)  # path may be a reverse_lazy object",
            "        tried = []",
            "        match = self.regex.search(path)",
            "        if match:",
            "            new_path = path[match.end():]",
            "            for pattern in self.url_patterns:",
            "                try:",
            "                    sub_match = pattern.resolve(new_path)",
            "                except Resolver404 as e:",
            "                    sub_tried = e.args[0].get('tried')",
            "                    if sub_tried is not None:",
            "                        tried.extend([pattern] + t for t in sub_tried)",
            "                    else:",
            "                        tried.append([pattern])",
            "                else:",
            "                    if sub_match:",
            "                        # Merge captured arguments in match with submatch",
            "                        sub_match_dict = dict(match.groupdict(), **self.default_kwargs)",
            "                        sub_match_dict.update(sub_match.kwargs)",
            "",
            "                        # If there are *any* named groups, ignore all non-named groups.",
            "                        # Otherwise, pass all non-named arguments as positional arguments.",
            "                        sub_match_args = sub_match.args",
            "                        if not sub_match_dict:",
            "                            sub_match_args = match.groups() + sub_match.args",
            "",
            "                        return ResolverMatch(",
            "                            sub_match.func,",
            "                            sub_match_args,",
            "                            sub_match_dict,",
            "                            sub_match.url_name,",
            "                            [self.app_name] + sub_match.app_names,",
            "                            [self.namespace] + sub_match.namespaces,",
            "                        )",
            "                    tried.append([pattern])",
            "            raise Resolver404({'tried': tried, 'path': new_path})",
            "        raise Resolver404({'path': path})",
            "",
            "    @cached_property",
            "    def urlconf_module(self):",
            "        if isinstance(self.urlconf_name, six.string_types):",
            "            return import_module(self.urlconf_name)",
            "        else:",
            "            return self.urlconf_name",
            "",
            "    @cached_property",
            "    def url_patterns(self):",
            "        # urlconf_module might be a valid set of patterns, so we default to it",
            "        patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)",
            "        try:",
            "            iter(patterns)",
            "        except TypeError:",
            "            msg = (",
            "                \"The included URLconf '{name}' does not appear to have any \"",
            "                \"patterns in it. If you see valid patterns in the file then \"",
            "                \"the issue is probably caused by a circular import.\"",
            "            )",
            "            raise ImproperlyConfigured(msg.format(name=self.urlconf_name))",
            "        return patterns",
            "",
            "    def resolve_error_handler(self, view_type):",
            "        callback = getattr(self.urlconf_module, 'handler%s' % view_type, None)",
            "        if not callback:",
            "            # No handler specified in file; use lazy import, since",
            "            # django.conf.urls imports this file.",
            "            from django.conf import urls",
            "            callback = getattr(urls, 'handler%s' % view_type)",
            "        return get_callable(callback), {}",
            "",
            "    def reverse(self, lookup_view, *args, **kwargs):",
            "        return self._reverse_with_prefix(lookup_view, '', *args, **kwargs)",
            "",
            "    def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):",
            "        if args and kwargs:",
            "            raise ValueError(\"Don't mix *args and **kwargs in call to reverse()!\")",
            "        text_args = [force_text(v) for v in args]",
            "        text_kwargs = {k: force_text(v) for (k, v) in kwargs.items()}",
            "",
            "        if not self._populated:",
            "            self._populate()",
            "",
            "        possibilities = self.reverse_dict.getlist(lookup_view)",
            "",
            "        for possibility, pattern, defaults in possibilities:",
            "            for result, params in possibility:",
            "                if args:",
            "                    if len(args) != len(params):",
            "                        continue",
            "                    candidate_subs = dict(zip(params, text_args))",
            "                else:",
            "                    if (set(kwargs.keys()) | set(defaults.keys()) != set(params) |",
            "                            set(defaults.keys())):",
            "                        continue",
            "                    matches = True",
            "                    for k, v in defaults.items():",
            "                        if kwargs.get(k, v) != v:",
            "                            matches = False",
            "                            break",
            "                    if not matches:",
            "                        continue",
            "                    candidate_subs = text_kwargs",
            "                # WSGI provides decoded URLs, without %xx escapes, and the URL",
            "                # resolver operates on such URLs. First substitute arguments",
            "                # without quoting to build a decoded URL and look for a match.",
            "                # Then, if we have a match, redo the substitution with quoted",
            "                # arguments in order to return a properly encoded URL.",
            "                candidate_pat = _prefix.replace('%', '%%') + result",
            "                if re.search('^%s%s' % (re.escape(_prefix), pattern), candidate_pat % candidate_subs, re.UNICODE):",
            "                    # safe characters from `pchar` definition of RFC 3986",
            "                    url = urlquote(candidate_pat % candidate_subs, safe=RFC3986_SUBDELIMS + str('/~:@'))",
            "                    # Don't allow construction of scheme relative urls.",
            "                    if url.startswith('//'):",
            "                        url = '/%%2F%s' % url[2:]",
            "                    return url",
            "        # lookup_view can be URL name or callable, but callables are not",
            "        # friendly in error messages.",
            "        m = getattr(lookup_view, '__module__', None)",
            "        n = getattr(lookup_view, '__name__', None)",
            "        if m is not None and n is not None:",
            "            lookup_view_s = \"%s.%s\" % (m, n)",
            "        else:",
            "            lookup_view_s = lookup_view",
            "",
            "        patterns = [pattern for (possibility, pattern, defaults) in possibilities]",
            "        if patterns:",
            "            if args:",
            "                arg_msg = \"arguments '%s'\" % (args,)",
            "            elif kwargs:",
            "                arg_msg = \"keyword arguments '%s'\" % (kwargs,)",
            "            else:",
            "                arg_msg = \"no arguments\"",
            "            msg = (",
            "                \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" %",
            "                (lookup_view_s, arg_msg, len(patterns), patterns)",
            "            )",
            "        else:",
            "            msg = (",
            "                \"Reverse for '%(view)s' not found. '%(view)s' is not \"",
            "                \"a valid view function or pattern name.\" % {'view': lookup_view_s}",
            "            )",
            "        raise NoReverseMatch(msg)",
            "",
            "",
            "class LocaleRegexURLResolver(RegexURLResolver):",
            "    \"\"\"",
            "    A URL resolver that always matches the active language code as URL prefix.",
            "",
            "    Rather than taking a regex argument, we just override the ``regex``",
            "    function to always return the active language-code as regex.",
            "    \"\"\"",
            "    def __init__(",
            "        self, urlconf_name, default_kwargs=None, app_name=None, namespace=None,",
            "        prefix_default_language=True,",
            "    ):",
            "        super(LocaleRegexURLResolver, self).__init__(",
            "            None, urlconf_name, default_kwargs, app_name, namespace,",
            "        )",
            "        self.prefix_default_language = prefix_default_language",
            "",
            "    @property",
            "    def regex(self):",
            "        language_code = get_language() or settings.LANGUAGE_CODE",
            "        if language_code not in self._regex_dict:",
            "            if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:",
            "                regex_string = ''",
            "            else:",
            "                regex_string = '^%s/' % language_code",
            "            self._regex_dict[language_code] = re.compile(regex_string, re.UNICODE)",
            "        return self._regex_dict[language_code]"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "This module converts requested URLs to callback view functions.",
            "",
            "RegexURLResolver is the main class here. Its resolve() method takes a URL (as",
            "a string) and returns a ResolverMatch object which provides access to all",
            "attributes of the resolved URL match.",
            "\"\"\"",
            "from __future__ import unicode_literals",
            "",
            "import functools",
            "import re",
            "import threading",
            "from importlib import import_module",
            "",
            "from django.conf import settings",
            "from django.core.checks import Warning",
            "from django.core.checks.urls import check_resolver",
            "from django.core.exceptions import ImproperlyConfigured",
            "from django.utils import lru_cache, six",
            "from django.utils.datastructures import MultiValueDict",
            "from django.utils.encoding import force_str, force_text",
            "from django.utils.functional import cached_property",
            "from django.utils.http import (",
            "    RFC3986_SUBDELIMS, escape_leading_slashes, urlquote,",
            ")",
            "from django.utils.regex_helper import normalize",
            "from django.utils.translation import get_language",
            "",
            "from .exceptions import NoReverseMatch, Resolver404",
            "from .utils import get_callable",
            "",
            "",
            "class ResolverMatch(object):",
            "    def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None):",
            "        self.func = func",
            "        self.args = args",
            "        self.kwargs = kwargs",
            "        self.url_name = url_name",
            "",
            "        # If a URLRegexResolver doesn't have a namespace or app_name, it passes",
            "        # in an empty value.",
            "        self.app_names = [x for x in app_names if x] if app_names else []",
            "        self.app_name = ':'.join(self.app_names)",
            "        self.namespaces = [x for x in namespaces if x] if namespaces else []",
            "        self.namespace = ':'.join(self.namespaces)",
            "",
            "        if not hasattr(func, '__name__'):",
            "            # A class-based view",
            "            self._func_path = '.'.join([func.__class__.__module__, func.__class__.__name__])",
            "        else:",
            "            # A function-based view",
            "            self._func_path = '.'.join([func.__module__, func.__name__])",
            "",
            "        view_path = url_name or self._func_path",
            "        self.view_name = ':'.join(self.namespaces + [view_path])",
            "",
            "    def __getitem__(self, index):",
            "        return (self.func, self.args, self.kwargs)[index]",
            "",
            "    def __repr__(self):",
            "        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s)\" % (",
            "            self._func_path, self.args, self.kwargs, self.url_name,",
            "            self.app_names, self.namespaces,",
            "        )",
            "",
            "",
            "@lru_cache.lru_cache(maxsize=None)",
            "def get_resolver(urlconf=None):",
            "    if urlconf is None:",
            "        from django.conf import settings",
            "        urlconf = settings.ROOT_URLCONF",
            "    return RegexURLResolver(r'^/', urlconf)",
            "",
            "",
            "@lru_cache.lru_cache(maxsize=None)",
            "def get_ns_resolver(ns_pattern, resolver):",
            "    # Build a namespaced resolver for the given parent URLconf pattern.",
            "    # This makes it possible to have captured parameters in the parent",
            "    # URLconf pattern.",
            "    ns_resolver = RegexURLResolver(ns_pattern, resolver.url_patterns)",
            "    return RegexURLResolver(r'^/', [ns_resolver])",
            "",
            "",
            "class LocaleRegexDescriptor(object):",
            "    def __get__(self, instance, cls=None):",
            "        \"\"\"",
            "        Return a compiled regular expression based on the active language.",
            "        \"\"\"",
            "        if instance is None:",
            "            return self",
            "        # As a performance optimization, if the given regex string is a regular",
            "        # string (not a lazily-translated string proxy), compile it once and",
            "        # avoid per-language compilation.",
            "        if isinstance(instance._regex, six.string_types):",
            "            instance.__dict__['regex'] = self._compile(instance._regex)",
            "            return instance.__dict__['regex']",
            "        language_code = get_language()",
            "        if language_code not in instance._regex_dict:",
            "            instance._regex_dict[language_code] = self._compile(force_text(instance._regex))",
            "        return instance._regex_dict[language_code]",
            "",
            "    def _compile(self, regex):",
            "        \"\"\"",
            "        Compile and return the given regular expression.",
            "        \"\"\"",
            "        try:",
            "            return re.compile(regex, re.UNICODE)",
            "        except re.error as e:",
            "            raise ImproperlyConfigured(",
            "                '\"%s\" is not a valid regular expression: %s' %",
            "                (regex, six.text_type(e))",
            "            )",
            "",
            "",
            "class LocaleRegexProvider(object):",
            "    \"\"\"",
            "    A mixin to provide a default regex property which can vary by active",
            "    language.",
            "    \"\"\"",
            "    def __init__(self, regex):",
            "        # regex is either a string representing a regular expression, or a",
            "        # translatable string (using ugettext_lazy) representing a regular",
            "        # expression.",
            "        self._regex = regex",
            "        self._regex_dict = {}",
            "",
            "    regex = LocaleRegexDescriptor()",
            "",
            "    def describe(self):",
            "        \"\"\"",
            "        Format the URL pattern for display in warning messages.",
            "        \"\"\"",
            "        description = \"'{}'\".format(self.regex.pattern)",
            "        if getattr(self, 'name', False):",
            "            description += \" [name='{}']\".format(self.name)",
            "        return description",
            "",
            "    def _check_pattern_startswith_slash(self):",
            "        \"\"\"",
            "        Check that the pattern does not begin with a forward slash.",
            "        \"\"\"",
            "        regex_pattern = self.regex.pattern",
            "        if not settings.APPEND_SLASH:",
            "            # Skip check as it can be useful to start a URL pattern with a slash",
            "            # when APPEND_SLASH=False.",
            "            return []",
            "        if (regex_pattern.startswith('/') or regex_pattern.startswith('^/')) and not regex_pattern.endswith('/'):",
            "            warning = Warning(",
            "                \"Your URL pattern {} has a regex beginning with a '/'. Remove this \"",
            "                \"slash as it is unnecessary. If this pattern is targeted in an \"",
            "                \"include(), ensure the include() pattern has a trailing '/'.\".format(",
            "                    self.describe()",
            "                ),",
            "                id=\"urls.W002\",",
            "            )",
            "            return [warning]",
            "        else:",
            "            return []",
            "",
            "",
            "class RegexURLPattern(LocaleRegexProvider):",
            "    def __init__(self, regex, callback, default_args=None, name=None):",
            "        LocaleRegexProvider.__init__(self, regex)",
            "        self.callback = callback  # the view",
            "        self.default_args = default_args or {}",
            "        self.name = name",
            "",
            "    def __repr__(self):",
            "        return force_str('<%s %s %s>' % (self.__class__.__name__, self.name, self.regex.pattern))",
            "",
            "    def check(self):",
            "        warnings = self._check_pattern_name()",
            "        if not warnings:",
            "            warnings = self._check_pattern_startswith_slash()",
            "        return warnings",
            "",
            "    def _check_pattern_name(self):",
            "        \"\"\"",
            "        Check that the pattern name does not contain a colon.",
            "        \"\"\"",
            "        if self.name is not None and \":\" in self.name:",
            "            warning = Warning(",
            "                \"Your URL pattern {} has a name including a ':'. Remove the colon, to \"",
            "                \"avoid ambiguous namespace references.\".format(self.describe()),",
            "                id=\"urls.W003\",",
            "            )",
            "            return [warning]",
            "        else:",
            "            return []",
            "",
            "    def resolve(self, path):",
            "        match = self.regex.search(path)",
            "        if match:",
            "            # If there are any named groups, use those as kwargs, ignoring",
            "            # non-named groups. Otherwise, pass all non-named arguments as",
            "            # positional arguments.",
            "            kwargs = match.groupdict()",
            "            args = () if kwargs else match.groups()",
            "            # In both cases, pass any extra_kwargs as **kwargs.",
            "            kwargs.update(self.default_args)",
            "            return ResolverMatch(self.callback, args, kwargs, self.name)",
            "",
            "    @cached_property",
            "    def lookup_str(self):",
            "        \"\"\"",
            "        A string that identifies the view (e.g. 'path.to.view_function' or",
            "        'path.to.ClassBasedView').",
            "        \"\"\"",
            "        callback = self.callback",
            "        # Python 3.5 collapses nested partials, so can change \"while\" to \"if\"",
            "        # when it's the minimum supported version.",
            "        while isinstance(callback, functools.partial):",
            "            callback = callback.func",
            "        if not hasattr(callback, '__name__'):",
            "            return callback.__module__ + \".\" + callback.__class__.__name__",
            "        elif six.PY3:",
            "            return callback.__module__ + \".\" + callback.__qualname__",
            "        else:",
            "            # PY2 does not support __qualname__",
            "            return callback.__module__ + \".\" + callback.__name__",
            "",
            "",
            "class RegexURLResolver(LocaleRegexProvider):",
            "    def __init__(self, regex, urlconf_name, default_kwargs=None, app_name=None, namespace=None):",
            "        LocaleRegexProvider.__init__(self, regex)",
            "        # urlconf_name is the dotted Python path to the module defining",
            "        # urlpatterns. It may also be an object with an urlpatterns attribute",
            "        # or urlpatterns itself.",
            "        self.urlconf_name = urlconf_name",
            "        self.callback = None",
            "        self.default_kwargs = default_kwargs or {}",
            "        self.namespace = namespace",
            "        self.app_name = app_name",
            "        self._reverse_dict = {}",
            "        self._namespace_dict = {}",
            "        self._app_dict = {}",
            "        # set of dotted paths to all functions and classes that are used in",
            "        # urlpatterns",
            "        self._callback_strs = set()",
            "        self._populated = False",
            "        self._local = threading.local()",
            "",
            "    def __repr__(self):",
            "        if isinstance(self.urlconf_name, list) and len(self.urlconf_name):",
            "            # Don't bother to output the whole list, it can be huge",
            "            urlconf_repr = '<%s list>' % self.urlconf_name[0].__class__.__name__",
            "        else:",
            "            urlconf_repr = repr(self.urlconf_name)",
            "        return str('<%s %s (%s:%s) %s>') % (",
            "            self.__class__.__name__, urlconf_repr, self.app_name,",
            "            self.namespace, self.regex.pattern,",
            "        )",
            "",
            "    def check(self):",
            "        warnings = self._check_include_trailing_dollar()",
            "        for pattern in self.url_patterns:",
            "            warnings.extend(check_resolver(pattern))",
            "        if not warnings:",
            "            warnings = self._check_pattern_startswith_slash()",
            "        return warnings",
            "",
            "    def _check_include_trailing_dollar(self):",
            "        \"\"\"",
            "        Check that include is not used with a regex ending with a dollar.",
            "        \"\"\"",
            "        regex_pattern = self.regex.pattern",
            "        if regex_pattern.endswith('$') and not regex_pattern.endswith(r'\\$'):",
            "            warning = Warning(",
            "                \"Your URL pattern {} uses include with a regex ending with a '$'. \"",
            "                \"Remove the dollar from the regex to avoid problems including \"",
            "                \"URLs.\".format(self.describe()),",
            "                id=\"urls.W001\",",
            "            )",
            "            return [warning]",
            "        else:",
            "            return []",
            "",
            "    def _populate(self):",
            "        # Short-circuit if called recursively in this thread to prevent",
            "        # infinite recursion. Concurrent threads may call this at the same",
            "        # time and will need to continue, so set 'populating' on a",
            "        # thread-local variable.",
            "        if getattr(self._local, 'populating', False):",
            "            return",
            "        self._local.populating = True",
            "        lookups = MultiValueDict()",
            "        namespaces = {}",
            "        apps = {}",
            "        language_code = get_language()",
            "        for pattern in reversed(self.url_patterns):",
            "            if isinstance(pattern, RegexURLPattern):",
            "                self._callback_strs.add(pattern.lookup_str)",
            "            p_pattern = pattern.regex.pattern",
            "            if p_pattern.startswith('^'):",
            "                p_pattern = p_pattern[1:]",
            "            if isinstance(pattern, RegexURLResolver):",
            "                if pattern.namespace:",
            "                    namespaces[pattern.namespace] = (p_pattern, pattern)",
            "                    if pattern.app_name:",
            "                        apps.setdefault(pattern.app_name, []).append(pattern.namespace)",
            "                else:",
            "                    parent_pat = pattern.regex.pattern",
            "                    for name in pattern.reverse_dict:",
            "                        for matches, pat, defaults in pattern.reverse_dict.getlist(name):",
            "                            new_matches = normalize(parent_pat + pat)",
            "                            lookups.appendlist(",
            "                                name,",
            "                                (",
            "                                    new_matches,",
            "                                    p_pattern + pat,",
            "                                    dict(defaults, **pattern.default_kwargs),",
            "                                )",
            "                            )",
            "                    for namespace, (prefix, sub_pattern) in pattern.namespace_dict.items():",
            "                        namespaces[namespace] = (p_pattern + prefix, sub_pattern)",
            "                    for app_name, namespace_list in pattern.app_dict.items():",
            "                        apps.setdefault(app_name, []).extend(namespace_list)",
            "                if not getattr(pattern._local, 'populating', False):",
            "                    pattern._populate()",
            "                self._callback_strs.update(pattern._callback_strs)",
            "            else:",
            "                bits = normalize(p_pattern)",
            "                lookups.appendlist(pattern.callback, (bits, p_pattern, pattern.default_args))",
            "                if pattern.name is not None:",
            "                    lookups.appendlist(pattern.name, (bits, p_pattern, pattern.default_args))",
            "        self._reverse_dict[language_code] = lookups",
            "        self._namespace_dict[language_code] = namespaces",
            "        self._app_dict[language_code] = apps",
            "        self._populated = True",
            "        self._local.populating = False",
            "",
            "    @property",
            "    def reverse_dict(self):",
            "        language_code = get_language()",
            "        if language_code not in self._reverse_dict:",
            "            self._populate()",
            "        return self._reverse_dict[language_code]",
            "",
            "    @property",
            "    def namespace_dict(self):",
            "        language_code = get_language()",
            "        if language_code not in self._namespace_dict:",
            "            self._populate()",
            "        return self._namespace_dict[language_code]",
            "",
            "    @property",
            "    def app_dict(self):",
            "        language_code = get_language()",
            "        if language_code not in self._app_dict:",
            "            self._populate()",
            "        return self._app_dict[language_code]",
            "",
            "    def _is_callback(self, name):",
            "        if not self._populated:",
            "            self._populate()",
            "        return name in self._callback_strs",
            "",
            "    def resolve(self, path):",
            "        path = force_text(path)  # path may be a reverse_lazy object",
            "        tried = []",
            "        match = self.regex.search(path)",
            "        if match:",
            "            new_path = path[match.end():]",
            "            for pattern in self.url_patterns:",
            "                try:",
            "                    sub_match = pattern.resolve(new_path)",
            "                except Resolver404 as e:",
            "                    sub_tried = e.args[0].get('tried')",
            "                    if sub_tried is not None:",
            "                        tried.extend([pattern] + t for t in sub_tried)",
            "                    else:",
            "                        tried.append([pattern])",
            "                else:",
            "                    if sub_match:",
            "                        # Merge captured arguments in match with submatch",
            "                        sub_match_dict = dict(match.groupdict(), **self.default_kwargs)",
            "                        sub_match_dict.update(sub_match.kwargs)",
            "",
            "                        # If there are *any* named groups, ignore all non-named groups.",
            "                        # Otherwise, pass all non-named arguments as positional arguments.",
            "                        sub_match_args = sub_match.args",
            "                        if not sub_match_dict:",
            "                            sub_match_args = match.groups() + sub_match.args",
            "",
            "                        return ResolverMatch(",
            "                            sub_match.func,",
            "                            sub_match_args,",
            "                            sub_match_dict,",
            "                            sub_match.url_name,",
            "                            [self.app_name] + sub_match.app_names,",
            "                            [self.namespace] + sub_match.namespaces,",
            "                        )",
            "                    tried.append([pattern])",
            "            raise Resolver404({'tried': tried, 'path': new_path})",
            "        raise Resolver404({'path': path})",
            "",
            "    @cached_property",
            "    def urlconf_module(self):",
            "        if isinstance(self.urlconf_name, six.string_types):",
            "            return import_module(self.urlconf_name)",
            "        else:",
            "            return self.urlconf_name",
            "",
            "    @cached_property",
            "    def url_patterns(self):",
            "        # urlconf_module might be a valid set of patterns, so we default to it",
            "        patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)",
            "        try:",
            "            iter(patterns)",
            "        except TypeError:",
            "            msg = (",
            "                \"The included URLconf '{name}' does not appear to have any \"",
            "                \"patterns in it. If you see valid patterns in the file then \"",
            "                \"the issue is probably caused by a circular import.\"",
            "            )",
            "            raise ImproperlyConfigured(msg.format(name=self.urlconf_name))",
            "        return patterns",
            "",
            "    def resolve_error_handler(self, view_type):",
            "        callback = getattr(self.urlconf_module, 'handler%s' % view_type, None)",
            "        if not callback:",
            "            # No handler specified in file; use lazy import, since",
            "            # django.conf.urls imports this file.",
            "            from django.conf import urls",
            "            callback = getattr(urls, 'handler%s' % view_type)",
            "        return get_callable(callback), {}",
            "",
            "    def reverse(self, lookup_view, *args, **kwargs):",
            "        return self._reverse_with_prefix(lookup_view, '', *args, **kwargs)",
            "",
            "    def _reverse_with_prefix(self, lookup_view, _prefix, *args, **kwargs):",
            "        if args and kwargs:",
            "            raise ValueError(\"Don't mix *args and **kwargs in call to reverse()!\")",
            "        text_args = [force_text(v) for v in args]",
            "        text_kwargs = {k: force_text(v) for (k, v) in kwargs.items()}",
            "",
            "        if not self._populated:",
            "            self._populate()",
            "",
            "        possibilities = self.reverse_dict.getlist(lookup_view)",
            "",
            "        for possibility, pattern, defaults in possibilities:",
            "            for result, params in possibility:",
            "                if args:",
            "                    if len(args) != len(params):",
            "                        continue",
            "                    candidate_subs = dict(zip(params, text_args))",
            "                else:",
            "                    if (set(kwargs.keys()) | set(defaults.keys()) != set(params) |",
            "                            set(defaults.keys())):",
            "                        continue",
            "                    matches = True",
            "                    for k, v in defaults.items():",
            "                        if kwargs.get(k, v) != v:",
            "                            matches = False",
            "                            break",
            "                    if not matches:",
            "                        continue",
            "                    candidate_subs = text_kwargs",
            "                # WSGI provides decoded URLs, without %xx escapes, and the URL",
            "                # resolver operates on such URLs. First substitute arguments",
            "                # without quoting to build a decoded URL and look for a match.",
            "                # Then, if we have a match, redo the substitution with quoted",
            "                # arguments in order to return a properly encoded URL.",
            "                candidate_pat = _prefix.replace('%', '%%') + result",
            "                if re.search('^%s%s' % (re.escape(_prefix), pattern), candidate_pat % candidate_subs, re.UNICODE):",
            "                    # safe characters from `pchar` definition of RFC 3986",
            "                    url = urlquote(candidate_pat % candidate_subs, safe=RFC3986_SUBDELIMS + str('/~:@'))",
            "                    # Don't allow construction of scheme relative urls.",
            "                    return escape_leading_slashes(url)",
            "        # lookup_view can be URL name or callable, but callables are not",
            "        # friendly in error messages.",
            "        m = getattr(lookup_view, '__module__', None)",
            "        n = getattr(lookup_view, '__name__', None)",
            "        if m is not None and n is not None:",
            "            lookup_view_s = \"%s.%s\" % (m, n)",
            "        else:",
            "            lookup_view_s = lookup_view",
            "",
            "        patterns = [pattern for (possibility, pattern, defaults) in possibilities]",
            "        if patterns:",
            "            if args:",
            "                arg_msg = \"arguments '%s'\" % (args,)",
            "            elif kwargs:",
            "                arg_msg = \"keyword arguments '%s'\" % (kwargs,)",
            "            else:",
            "                arg_msg = \"no arguments\"",
            "            msg = (",
            "                \"Reverse for '%s' with %s not found. %d pattern(s) tried: %s\" %",
            "                (lookup_view_s, arg_msg, len(patterns), patterns)",
            "            )",
            "        else:",
            "            msg = (",
            "                \"Reverse for '%(view)s' not found. '%(view)s' is not \"",
            "                \"a valid view function or pattern name.\" % {'view': lookup_view_s}",
            "            )",
            "        raise NoReverseMatch(msg)",
            "",
            "",
            "class LocaleRegexURLResolver(RegexURLResolver):",
            "    \"\"\"",
            "    A URL resolver that always matches the active language code as URL prefix.",
            "",
            "    Rather than taking a regex argument, we just override the ``regex``",
            "    function to always return the active language-code as regex.",
            "    \"\"\"",
            "    def __init__(",
            "        self, urlconf_name, default_kwargs=None, app_name=None, namespace=None,",
            "        prefix_default_language=True,",
            "    ):",
            "        super(LocaleRegexURLResolver, self).__init__(",
            "            None, urlconf_name, default_kwargs, app_name, namespace,",
            "        )",
            "        self.prefix_default_language = prefix_default_language",
            "",
            "    @property",
            "    def regex(self):",
            "        language_code = get_language() or settings.LANGUAGE_CODE",
            "        if language_code not in self._regex_dict:",
            "            if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language:",
            "                regex_string = ''",
            "            else:",
            "                regex_string = '^%s/' % language_code",
            "            self._regex_dict[language_code] = re.compile(regex_string, re.UNICODE)",
            "        return self._regex_dict[language_code]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "23": [],
            "468": [
                "RegexURLResolver",
                "_reverse_with_prefix"
            ],
            "469": [
                "RegexURLResolver",
                "_reverse_with_prefix"
            ],
            "470": [
                "RegexURLResolver",
                "_reverse_with_prefix"
            ]
        },
        "addLocation": []
    },
    "django/utils/http.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 466,
                "afterPatchRowNumber": 466,
                "PatchRowcode": "                 value = unquote(nv[1].replace(b'+', b' '))"
            },
            "1": {
                "beforePatchRowNumber": 467,
                "afterPatchRowNumber": 467,
                "PatchRowcode": "             r.append((name, value))"
            },
            "2": {
                "beforePatchRowNumber": 468,
                "afterPatchRowNumber": 468,
                "PatchRowcode": "     return r"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 469,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 470,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 471,
                "PatchRowcode": "+def escape_leading_slashes(url):"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 472,
                "PatchRowcode": "+    \"\"\""
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 473,
                "PatchRowcode": "+    If redirecting to an absolute path (two leading slashes), a slash must be"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 474,
                "PatchRowcode": "+    escaped to prevent browsers from handling the path as schemaless and"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 475,
                "PatchRowcode": "+    redirecting to another host."
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 476,
                "PatchRowcode": "+    \"\"\""
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 477,
                "PatchRowcode": "+    if url.startswith('//'):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 478,
                "PatchRowcode": "+        url = '/%2F{}'.format(url[2:])"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 479,
                "PatchRowcode": "+    return url"
            }
        },
        "frontPatchFile": [
            "from __future__ import unicode_literals",
            "",
            "import base64",
            "import calendar",
            "import datetime",
            "import re",
            "import sys",
            "import unicodedata",
            "import warnings",
            "from binascii import Error as BinasciiError",
            "from email.utils import formatdate",
            "",
            "from django.core.exceptions import TooManyFieldsSent",
            "from django.utils import six",
            "from django.utils.datastructures import MultiValueDict",
            "from django.utils.deprecation import RemovedInDjango21Warning",
            "from django.utils.encoding import force_bytes, force_str, force_text",
            "from django.utils.functional import keep_lazy_text",
            "from django.utils.six.moves.urllib.parse import (",
            "    quote, quote_plus, unquote, unquote_plus, urlencode as original_urlencode,",
            ")",
            "",
            "if six.PY2:",
            "    from urlparse import (",
            "        ParseResult, SplitResult, _splitnetloc, _splitparams, scheme_chars,",
            "        uses_params,",
            "    )",
            "    _coerce_args = None",
            "else:",
            "    from urllib.parse import (",
            "        ParseResult, SplitResult, _coerce_args, _splitnetloc, _splitparams,",
            "        scheme_chars, uses_params,",
            "    )",
            "",
            "# based on RFC 7232, Appendix C",
            "ETAG_MATCH = re.compile(r'''",
            "    \\A(      # start of string and capture group",
            "    (?:W/)?  # optional weak indicator",
            "    \"        # opening quote",
            "    [^\"]*    # any sequence of non-quote characters",
            "    \"        # end quote",
            "    )\\Z      # end of string and capture group",
            "''', re.X)",
            "",
            "MONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()",
            "__D = r'(?P<day>\\d{2})'",
            "__D2 = r'(?P<day>[ \\d]\\d)'",
            "__M = r'(?P<mon>\\w{3})'",
            "__Y = r'(?P<year>\\d{4})'",
            "__Y2 = r'(?P<year>\\d{2})'",
            "__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'",
            "RFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))",
            "RFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))",
            "ASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))",
            "",
            "RFC3986_GENDELIMS = str(\":/?#[]@\")",
            "RFC3986_SUBDELIMS = str(\"!$&'()*+,;=\")",
            "",
            "FIELDS_MATCH = re.compile('[&;]')",
            "",
            "",
            "@keep_lazy_text",
            "def urlquote(url, safe='/'):",
            "    \"\"\"",
            "    A version of Python's urllib.quote() function that can operate on unicode",
            "    strings. The url is first UTF-8 encoded before quoting. The returned string",
            "    can safely be used as part of an argument to a subsequent iri_to_uri() call",
            "    without double-quoting occurring.",
            "    \"\"\"",
            "    return force_text(quote(force_str(url), force_str(safe)))",
            "",
            "",
            "@keep_lazy_text",
            "def urlquote_plus(url, safe=''):",
            "    \"\"\"",
            "    A version of Python's urllib.quote_plus() function that can operate on",
            "    unicode strings. The url is first UTF-8 encoded before quoting. The",
            "    returned string can safely be used as part of an argument to a subsequent",
            "    iri_to_uri() call without double-quoting occurring.",
            "    \"\"\"",
            "    return force_text(quote_plus(force_str(url), force_str(safe)))",
            "",
            "",
            "@keep_lazy_text",
            "def urlunquote(quoted_url):",
            "    \"\"\"",
            "    A wrapper for Python's urllib.unquote() function that can operate on",
            "    the result of django.utils.http.urlquote().",
            "    \"\"\"",
            "    return force_text(unquote(force_str(quoted_url)))",
            "",
            "",
            "@keep_lazy_text",
            "def urlunquote_plus(quoted_url):",
            "    \"\"\"",
            "    A wrapper for Python's urllib.unquote_plus() function that can operate on",
            "    the result of django.utils.http.urlquote_plus().",
            "    \"\"\"",
            "    return force_text(unquote_plus(force_str(quoted_url)))",
            "",
            "",
            "def urlencode(query, doseq=0):",
            "    \"\"\"",
            "    A version of Python's urllib.urlencode() function that can operate on",
            "    unicode strings. The parameters are first cast to UTF-8 encoded strings and",
            "    then encoded as per normal.",
            "    \"\"\"",
            "    if isinstance(query, MultiValueDict):",
            "        query = query.lists()",
            "    elif hasattr(query, 'items'):",
            "        query = query.items()",
            "    return original_urlencode(",
            "        [(force_str(k),",
            "         [force_str(i) for i in v] if isinstance(v, (list, tuple)) else force_str(v))",
            "            for k, v in query],",
            "        doseq)",
            "",
            "",
            "def cookie_date(epoch_seconds=None):",
            "    \"\"\"",
            "    Formats the time to ensure compatibility with Netscape's cookie standard.",
            "",
            "    Accepts a floating point number expressed in seconds since the epoch, in",
            "    UTC - such as that outputted by time.time(). If set to None, defaults to",
            "    the current time.",
            "",
            "    Outputs a string in the format 'Wdy, DD-Mon-YYYY HH:MM:SS GMT'.",
            "    \"\"\"",
            "    rfcdate = formatdate(epoch_seconds)",
            "    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])",
            "",
            "",
            "def http_date(epoch_seconds=None):",
            "    \"\"\"",
            "    Formats the time to match the RFC1123 date format as specified by HTTP",
            "    RFC7231 section 7.1.1.1.",
            "",
            "    Accepts a floating point number expressed in seconds since the epoch, in",
            "    UTC - such as that outputted by time.time(). If set to None, defaults to",
            "    the current time.",
            "",
            "    Outputs a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.",
            "    \"\"\"",
            "    return formatdate(epoch_seconds, usegmt=True)",
            "",
            "",
            "def parse_http_date(date):",
            "    \"\"\"",
            "    Parses a date format as specified by HTTP RFC7231 section 7.1.1.1.",
            "",
            "    The three formats allowed by the RFC are accepted, even if only the first",
            "    one is still in widespread use.",
            "",
            "    Returns an integer expressed in seconds since the epoch, in UTC.",
            "    \"\"\"",
            "    # emails.Util.parsedate does the job for RFC1123 dates; unfortunately",
            "    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll",
            "    # our own RFC-compliant parsing.",
            "    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:",
            "        m = regex.match(date)",
            "        if m is not None:",
            "            break",
            "    else:",
            "        raise ValueError(\"%r is not in a valid HTTP date format\" % date)",
            "    try:",
            "        year = int(m.group('year'))",
            "        if year < 100:",
            "            if year < 70:",
            "                year += 2000",
            "            else:",
            "                year += 1900",
            "        month = MONTHS.index(m.group('mon').lower()) + 1",
            "        day = int(m.group('day'))",
            "        hour = int(m.group('hour'))",
            "        min = int(m.group('min'))",
            "        sec = int(m.group('sec'))",
            "        result = datetime.datetime(year, month, day, hour, min, sec)",
            "        return calendar.timegm(result.utctimetuple())",
            "    except Exception:",
            "        six.reraise(ValueError, ValueError(\"%r is not a valid date\" % date), sys.exc_info()[2])",
            "",
            "",
            "def parse_http_date_safe(date):",
            "    \"\"\"",
            "    Same as parse_http_date, but returns None if the input is invalid.",
            "    \"\"\"",
            "    try:",
            "        return parse_http_date(date)",
            "    except Exception:",
            "        pass",
            "",
            "",
            "# Base 36 functions: useful for generating compact URLs",
            "",
            "def base36_to_int(s):",
            "    \"\"\"",
            "    Converts a base 36 string to an ``int``. Raises ``ValueError` if the",
            "    input won't fit into an int.",
            "    \"\"\"",
            "    # To prevent overconsumption of server resources, reject any",
            "    # base36 string that is longer than 13 base36 digits (13 digits",
            "    # is sufficient to base36-encode any 64-bit integer)",
            "    if len(s) > 13:",
            "        raise ValueError(\"Base36 input too large\")",
            "    value = int(s, 36)",
            "    # ... then do a final check that the value will fit into an int to avoid",
            "    # returning a long (#15067). The long type was removed in Python 3.",
            "    if six.PY2 and value > sys.maxint:",
            "        raise ValueError(\"Base36 input too large\")",
            "    return value",
            "",
            "",
            "def int_to_base36(i):",
            "    \"\"\"",
            "    Converts an integer to a base36 string",
            "    \"\"\"",
            "    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'",
            "    if i < 0:",
            "        raise ValueError(\"Negative base36 conversion input.\")",
            "    if six.PY2:",
            "        if not isinstance(i, six.integer_types):",
            "            raise TypeError(\"Non-integer base36 conversion input.\")",
            "        if i > sys.maxint:",
            "            raise ValueError(\"Base36 conversion input too large.\")",
            "    if i < 36:",
            "        return char_set[i]",
            "    b36 = ''",
            "    while i != 0:",
            "        i, n = divmod(i, 36)",
            "        b36 = char_set[n] + b36",
            "    return b36",
            "",
            "",
            "def urlsafe_base64_encode(s):",
            "    \"\"\"",
            "    Encodes a bytestring in base64 for use in URLs, stripping any trailing",
            "    equal signs.",
            "    \"\"\"",
            "    return base64.urlsafe_b64encode(s).rstrip(b'\\n=')",
            "",
            "",
            "def urlsafe_base64_decode(s):",
            "    \"\"\"",
            "    Decodes a base64 encoded string, adding back any trailing equal signs that",
            "    might have been stripped.",
            "    \"\"\"",
            "    s = force_bytes(s)",
            "    try:",
            "        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))",
            "    except (LookupError, BinasciiError) as e:",
            "        raise ValueError(e)",
            "",
            "",
            "def parse_etags(etag_str):",
            "    \"\"\"",
            "    Parse a string of ETags given in an If-None-Match or If-Match header as",
            "    defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags",
            "    should be matched.",
            "    \"\"\"",
            "    if etag_str.strip() == '*':",
            "        return ['*']",
            "    else:",
            "        # Parse each ETag individually, and return any that are valid.",
            "        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(','))",
            "        return [match.group(1) for match in etag_matches if match]",
            "",
            "",
            "def quote_etag(etag_str):",
            "    \"\"\"",
            "    If the provided string is already a quoted ETag, return it. Otherwise, wrap",
            "    the string in quotes, making it a strong ETag.",
            "    \"\"\"",
            "    if ETAG_MATCH.match(etag_str):",
            "        return etag_str",
            "    else:",
            "        return '\"%s\"' % etag_str",
            "",
            "",
            "def is_same_domain(host, pattern):",
            "    \"\"\"",
            "    Return ``True`` if the host is either an exact match or a match",
            "    to the wildcard pattern.",
            "",
            "    Any pattern beginning with a period matches a domain and all of its",
            "    subdomains. (e.g. ``.example.com`` matches ``example.com`` and",
            "    ``foo.example.com``). Anything else is an exact string match.",
            "    \"\"\"",
            "    if not pattern:",
            "        return False",
            "",
            "    pattern = pattern.lower()",
            "    return (",
            "        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or",
            "        pattern == host",
            "    )",
            "",
            "",
            "def is_safe_url(url, host=None, allowed_hosts=None, require_https=False):",
            "    \"\"\"",
            "    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to",
            "    a different host and uses a safe scheme).",
            "",
            "    Always returns ``False`` on an empty url.",
            "",
            "    If ``require_https`` is ``True``, only 'https' will be considered a valid",
            "    scheme, as opposed to 'http' and 'https' with the default, ``False``.",
            "    \"\"\"",
            "    if url is not None:",
            "        url = url.strip()",
            "    if not url:",
            "        return False",
            "    if six.PY2:",
            "        try:",
            "            url = force_text(url)",
            "        except UnicodeDecodeError:",
            "            return False",
            "    if allowed_hosts is None:",
            "        allowed_hosts = set()",
            "    if host:",
            "        warnings.warn(",
            "            \"The host argument is deprecated, use allowed_hosts instead.\",",
            "            RemovedInDjango21Warning,",
            "            stacklevel=2,",
            "        )",
            "        # Avoid mutating the passed in allowed_hosts.",
            "        allowed_hosts = allowed_hosts | {host}",
            "    # Chrome treats \\ completely as / in paths but it could be part of some",
            "    # basic auth credentials so we need to check both URLs.",
            "    return (_is_safe_url(url, allowed_hosts, require_https=require_https) and",
            "            _is_safe_url(url.replace('\\\\', '/'), allowed_hosts, require_https=require_https))",
            "",
            "",
            "# Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.",
            "def _urlparse(url, scheme='', allow_fragments=True):",
            "    \"\"\"Parse a URL into 6 components:",
            "    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>",
            "    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).",
            "    Note that we don't break the components up in smaller bits",
            "    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"",
            "    if _coerce_args:",
            "        url, scheme, _coerce_result = _coerce_args(url, scheme)",
            "    splitresult = _urlsplit(url, scheme, allow_fragments)",
            "    scheme, netloc, url, query, fragment = splitresult",
            "    if scheme in uses_params and ';' in url:",
            "        url, params = _splitparams(url)",
            "    else:",
            "        params = ''",
            "    result = ParseResult(scheme, netloc, url, params, query, fragment)",
            "    return _coerce_result(result) if _coerce_args else result",
            "",
            "",
            "# Copied from urllib.parse.urlsplit() with",
            "# https://github.com/python/cpython/pull/661 applied.",
            "def _urlsplit(url, scheme='', allow_fragments=True):",
            "    \"\"\"Parse a URL into 5 components:",
            "    <scheme>://<netloc>/<path>?<query>#<fragment>",
            "    Return a 5-tuple: (scheme, netloc, path, query, fragment).",
            "    Note that we don't break the components up in smaller bits",
            "    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"",
            "    if _coerce_args:",
            "        url, scheme, _coerce_result = _coerce_args(url, scheme)",
            "    allow_fragments = bool(allow_fragments)",
            "    netloc = query = fragment = ''",
            "    i = url.find(':')",
            "    if i > 0:",
            "        for c in url[:i]:",
            "            if c not in scheme_chars:",
            "                break",
            "        else:",
            "            scheme, url = url[:i].lower(), url[i + 1:]",
            "",
            "    if url[:2] == '//':",
            "        netloc, url = _splitnetloc(url, 2)",
            "        if (('[' in netloc and ']' not in netloc) or",
            "                (']' in netloc and '[' not in netloc)):",
            "            raise ValueError(\"Invalid IPv6 URL\")",
            "    if allow_fragments and '#' in url:",
            "        url, fragment = url.split('#', 1)",
            "    if '?' in url:",
            "        url, query = url.split('?', 1)",
            "    v = SplitResult(scheme, netloc, url, query, fragment)",
            "    return _coerce_result(v) if _coerce_args else v",
            "",
            "",
            "def _is_safe_url(url, allowed_hosts, require_https=False):",
            "    # Chrome considers any URL with more than two slashes to be absolute, but",
            "    # urlparse is not so flexible. Treat any url with three slashes as unsafe.",
            "    if url.startswith('///'):",
            "        return False",
            "    try:",
            "        url_info = _urlparse(url)",
            "    except ValueError:  # e.g. invalid IPv6 addresses",
            "        return False",
            "    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.",
            "    # In that URL, example.com is not the hostname but, a path component. However,",
            "    # Chrome will still consider example.com to be the hostname, so we must not",
            "    # allow this syntax.",
            "    if not url_info.netloc and url_info.scheme:",
            "        return False",
            "    # Forbid URLs that start with control characters. Some browsers (like",
            "    # Chrome) ignore quite a few control characters at the start of a",
            "    # URL and might consider the URL as scheme relative.",
            "    if unicodedata.category(url[0])[0] == 'C':",
            "        return False",
            "    scheme = url_info.scheme",
            "    # Consider URLs without a scheme (e.g. //example.com/p) to be http.",
            "    if not url_info.scheme and url_info.netloc:",
            "        scheme = 'http'",
            "    valid_schemes = ['https'] if require_https else ['http', 'https']",
            "    return ((not url_info.netloc or url_info.netloc in allowed_hosts) and",
            "            (not scheme or scheme in valid_schemes))",
            "",
            "",
            "def limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',",
            "                      errors='replace', fields_limit=None):",
            "    \"\"\"",
            "    Return a list of key/value tuples parsed from query string.",
            "",
            "    Copied from urlparse with an additional \"fields_limit\" argument.",
            "    Copyright (C) 2013 Python Software Foundation (see LICENSE.python).",
            "",
            "    Arguments:",
            "",
            "    qs: percent-encoded query string to be parsed",
            "",
            "    keep_blank_values: flag indicating whether blank values in",
            "        percent-encoded queries should be treated as blank strings. A",
            "        true value indicates that blanks should be retained as blank",
            "        strings. The default false value indicates that blank values",
            "        are to be ignored and treated as if they were  not included.",
            "",
            "    encoding and errors: specify how to decode percent-encoded sequences",
            "        into Unicode characters, as accepted by the bytes.decode() method.",
            "",
            "    fields_limit: maximum number of fields parsed or an exception",
            "        is raised. None means no limit and is the default.",
            "    \"\"\"",
            "    if fields_limit:",
            "        pairs = FIELDS_MATCH.split(qs, fields_limit)",
            "        if len(pairs) > fields_limit:",
            "            raise TooManyFieldsSent(",
            "                'The number of GET/POST parameters exceeded '",
            "                'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'",
            "            )",
            "    else:",
            "        pairs = FIELDS_MATCH.split(qs)",
            "    r = []",
            "    for name_value in pairs:",
            "        if not name_value:",
            "            continue",
            "        nv = name_value.split(str('='), 1)",
            "        if len(nv) != 2:",
            "            # Handle case of a control-name with no equal sign",
            "            if keep_blank_values:",
            "                nv.append('')",
            "            else:",
            "                continue",
            "        if len(nv[1]) or keep_blank_values:",
            "            if six.PY3:",
            "                name = nv[0].replace('+', ' ')",
            "                name = unquote(name, encoding=encoding, errors=errors)",
            "                value = nv[1].replace('+', ' ')",
            "                value = unquote(value, encoding=encoding, errors=errors)",
            "            else:",
            "                name = unquote(nv[0].replace(b'+', b' '))",
            "                value = unquote(nv[1].replace(b'+', b' '))",
            "            r.append((name, value))",
            "    return r"
        ],
        "afterPatchFile": [
            "from __future__ import unicode_literals",
            "",
            "import base64",
            "import calendar",
            "import datetime",
            "import re",
            "import sys",
            "import unicodedata",
            "import warnings",
            "from binascii import Error as BinasciiError",
            "from email.utils import formatdate",
            "",
            "from django.core.exceptions import TooManyFieldsSent",
            "from django.utils import six",
            "from django.utils.datastructures import MultiValueDict",
            "from django.utils.deprecation import RemovedInDjango21Warning",
            "from django.utils.encoding import force_bytes, force_str, force_text",
            "from django.utils.functional import keep_lazy_text",
            "from django.utils.six.moves.urllib.parse import (",
            "    quote, quote_plus, unquote, unquote_plus, urlencode as original_urlencode,",
            ")",
            "",
            "if six.PY2:",
            "    from urlparse import (",
            "        ParseResult, SplitResult, _splitnetloc, _splitparams, scheme_chars,",
            "        uses_params,",
            "    )",
            "    _coerce_args = None",
            "else:",
            "    from urllib.parse import (",
            "        ParseResult, SplitResult, _coerce_args, _splitnetloc, _splitparams,",
            "        scheme_chars, uses_params,",
            "    )",
            "",
            "# based on RFC 7232, Appendix C",
            "ETAG_MATCH = re.compile(r'''",
            "    \\A(      # start of string and capture group",
            "    (?:W/)?  # optional weak indicator",
            "    \"        # opening quote",
            "    [^\"]*    # any sequence of non-quote characters",
            "    \"        # end quote",
            "    )\\Z      # end of string and capture group",
            "''', re.X)",
            "",
            "MONTHS = 'jan feb mar apr may jun jul aug sep oct nov dec'.split()",
            "__D = r'(?P<day>\\d{2})'",
            "__D2 = r'(?P<day>[ \\d]\\d)'",
            "__M = r'(?P<mon>\\w{3})'",
            "__Y = r'(?P<year>\\d{4})'",
            "__Y2 = r'(?P<year>\\d{2})'",
            "__T = r'(?P<hour>\\d{2}):(?P<min>\\d{2}):(?P<sec>\\d{2})'",
            "RFC1123_DATE = re.compile(r'^\\w{3}, %s %s %s %s GMT$' % (__D, __M, __Y, __T))",
            "RFC850_DATE = re.compile(r'^\\w{6,9}, %s-%s-%s %s GMT$' % (__D, __M, __Y2, __T))",
            "ASCTIME_DATE = re.compile(r'^\\w{3} %s %s %s %s$' % (__M, __D2, __T, __Y))",
            "",
            "RFC3986_GENDELIMS = str(\":/?#[]@\")",
            "RFC3986_SUBDELIMS = str(\"!$&'()*+,;=\")",
            "",
            "FIELDS_MATCH = re.compile('[&;]')",
            "",
            "",
            "@keep_lazy_text",
            "def urlquote(url, safe='/'):",
            "    \"\"\"",
            "    A version of Python's urllib.quote() function that can operate on unicode",
            "    strings. The url is first UTF-8 encoded before quoting. The returned string",
            "    can safely be used as part of an argument to a subsequent iri_to_uri() call",
            "    without double-quoting occurring.",
            "    \"\"\"",
            "    return force_text(quote(force_str(url), force_str(safe)))",
            "",
            "",
            "@keep_lazy_text",
            "def urlquote_plus(url, safe=''):",
            "    \"\"\"",
            "    A version of Python's urllib.quote_plus() function that can operate on",
            "    unicode strings. The url is first UTF-8 encoded before quoting. The",
            "    returned string can safely be used as part of an argument to a subsequent",
            "    iri_to_uri() call without double-quoting occurring.",
            "    \"\"\"",
            "    return force_text(quote_plus(force_str(url), force_str(safe)))",
            "",
            "",
            "@keep_lazy_text",
            "def urlunquote(quoted_url):",
            "    \"\"\"",
            "    A wrapper for Python's urllib.unquote() function that can operate on",
            "    the result of django.utils.http.urlquote().",
            "    \"\"\"",
            "    return force_text(unquote(force_str(quoted_url)))",
            "",
            "",
            "@keep_lazy_text",
            "def urlunquote_plus(quoted_url):",
            "    \"\"\"",
            "    A wrapper for Python's urllib.unquote_plus() function that can operate on",
            "    the result of django.utils.http.urlquote_plus().",
            "    \"\"\"",
            "    return force_text(unquote_plus(force_str(quoted_url)))",
            "",
            "",
            "def urlencode(query, doseq=0):",
            "    \"\"\"",
            "    A version of Python's urllib.urlencode() function that can operate on",
            "    unicode strings. The parameters are first cast to UTF-8 encoded strings and",
            "    then encoded as per normal.",
            "    \"\"\"",
            "    if isinstance(query, MultiValueDict):",
            "        query = query.lists()",
            "    elif hasattr(query, 'items'):",
            "        query = query.items()",
            "    return original_urlencode(",
            "        [(force_str(k),",
            "         [force_str(i) for i in v] if isinstance(v, (list, tuple)) else force_str(v))",
            "            for k, v in query],",
            "        doseq)",
            "",
            "",
            "def cookie_date(epoch_seconds=None):",
            "    \"\"\"",
            "    Formats the time to ensure compatibility with Netscape's cookie standard.",
            "",
            "    Accepts a floating point number expressed in seconds since the epoch, in",
            "    UTC - such as that outputted by time.time(). If set to None, defaults to",
            "    the current time.",
            "",
            "    Outputs a string in the format 'Wdy, DD-Mon-YYYY HH:MM:SS GMT'.",
            "    \"\"\"",
            "    rfcdate = formatdate(epoch_seconds)",
            "    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])",
            "",
            "",
            "def http_date(epoch_seconds=None):",
            "    \"\"\"",
            "    Formats the time to match the RFC1123 date format as specified by HTTP",
            "    RFC7231 section 7.1.1.1.",
            "",
            "    Accepts a floating point number expressed in seconds since the epoch, in",
            "    UTC - such as that outputted by time.time(). If set to None, defaults to",
            "    the current time.",
            "",
            "    Outputs a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.",
            "    \"\"\"",
            "    return formatdate(epoch_seconds, usegmt=True)",
            "",
            "",
            "def parse_http_date(date):",
            "    \"\"\"",
            "    Parses a date format as specified by HTTP RFC7231 section 7.1.1.1.",
            "",
            "    The three formats allowed by the RFC are accepted, even if only the first",
            "    one is still in widespread use.",
            "",
            "    Returns an integer expressed in seconds since the epoch, in UTC.",
            "    \"\"\"",
            "    # emails.Util.parsedate does the job for RFC1123 dates; unfortunately",
            "    # RFC7231 makes it mandatory to support RFC850 dates too. So we roll",
            "    # our own RFC-compliant parsing.",
            "    for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE:",
            "        m = regex.match(date)",
            "        if m is not None:",
            "            break",
            "    else:",
            "        raise ValueError(\"%r is not in a valid HTTP date format\" % date)",
            "    try:",
            "        year = int(m.group('year'))",
            "        if year < 100:",
            "            if year < 70:",
            "                year += 2000",
            "            else:",
            "                year += 1900",
            "        month = MONTHS.index(m.group('mon').lower()) + 1",
            "        day = int(m.group('day'))",
            "        hour = int(m.group('hour'))",
            "        min = int(m.group('min'))",
            "        sec = int(m.group('sec'))",
            "        result = datetime.datetime(year, month, day, hour, min, sec)",
            "        return calendar.timegm(result.utctimetuple())",
            "    except Exception:",
            "        six.reraise(ValueError, ValueError(\"%r is not a valid date\" % date), sys.exc_info()[2])",
            "",
            "",
            "def parse_http_date_safe(date):",
            "    \"\"\"",
            "    Same as parse_http_date, but returns None if the input is invalid.",
            "    \"\"\"",
            "    try:",
            "        return parse_http_date(date)",
            "    except Exception:",
            "        pass",
            "",
            "",
            "# Base 36 functions: useful for generating compact URLs",
            "",
            "def base36_to_int(s):",
            "    \"\"\"",
            "    Converts a base 36 string to an ``int``. Raises ``ValueError` if the",
            "    input won't fit into an int.",
            "    \"\"\"",
            "    # To prevent overconsumption of server resources, reject any",
            "    # base36 string that is longer than 13 base36 digits (13 digits",
            "    # is sufficient to base36-encode any 64-bit integer)",
            "    if len(s) > 13:",
            "        raise ValueError(\"Base36 input too large\")",
            "    value = int(s, 36)",
            "    # ... then do a final check that the value will fit into an int to avoid",
            "    # returning a long (#15067). The long type was removed in Python 3.",
            "    if six.PY2 and value > sys.maxint:",
            "        raise ValueError(\"Base36 input too large\")",
            "    return value",
            "",
            "",
            "def int_to_base36(i):",
            "    \"\"\"",
            "    Converts an integer to a base36 string",
            "    \"\"\"",
            "    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'",
            "    if i < 0:",
            "        raise ValueError(\"Negative base36 conversion input.\")",
            "    if six.PY2:",
            "        if not isinstance(i, six.integer_types):",
            "            raise TypeError(\"Non-integer base36 conversion input.\")",
            "        if i > sys.maxint:",
            "            raise ValueError(\"Base36 conversion input too large.\")",
            "    if i < 36:",
            "        return char_set[i]",
            "    b36 = ''",
            "    while i != 0:",
            "        i, n = divmod(i, 36)",
            "        b36 = char_set[n] + b36",
            "    return b36",
            "",
            "",
            "def urlsafe_base64_encode(s):",
            "    \"\"\"",
            "    Encodes a bytestring in base64 for use in URLs, stripping any trailing",
            "    equal signs.",
            "    \"\"\"",
            "    return base64.urlsafe_b64encode(s).rstrip(b'\\n=')",
            "",
            "",
            "def urlsafe_base64_decode(s):",
            "    \"\"\"",
            "    Decodes a base64 encoded string, adding back any trailing equal signs that",
            "    might have been stripped.",
            "    \"\"\"",
            "    s = force_bytes(s)",
            "    try:",
            "        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))",
            "    except (LookupError, BinasciiError) as e:",
            "        raise ValueError(e)",
            "",
            "",
            "def parse_etags(etag_str):",
            "    \"\"\"",
            "    Parse a string of ETags given in an If-None-Match or If-Match header as",
            "    defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags",
            "    should be matched.",
            "    \"\"\"",
            "    if etag_str.strip() == '*':",
            "        return ['*']",
            "    else:",
            "        # Parse each ETag individually, and return any that are valid.",
            "        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(','))",
            "        return [match.group(1) for match in etag_matches if match]",
            "",
            "",
            "def quote_etag(etag_str):",
            "    \"\"\"",
            "    If the provided string is already a quoted ETag, return it. Otherwise, wrap",
            "    the string in quotes, making it a strong ETag.",
            "    \"\"\"",
            "    if ETAG_MATCH.match(etag_str):",
            "        return etag_str",
            "    else:",
            "        return '\"%s\"' % etag_str",
            "",
            "",
            "def is_same_domain(host, pattern):",
            "    \"\"\"",
            "    Return ``True`` if the host is either an exact match or a match",
            "    to the wildcard pattern.",
            "",
            "    Any pattern beginning with a period matches a domain and all of its",
            "    subdomains. (e.g. ``.example.com`` matches ``example.com`` and",
            "    ``foo.example.com``). Anything else is an exact string match.",
            "    \"\"\"",
            "    if not pattern:",
            "        return False",
            "",
            "    pattern = pattern.lower()",
            "    return (",
            "        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or",
            "        pattern == host",
            "    )",
            "",
            "",
            "def is_safe_url(url, host=None, allowed_hosts=None, require_https=False):",
            "    \"\"\"",
            "    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to",
            "    a different host and uses a safe scheme).",
            "",
            "    Always returns ``False`` on an empty url.",
            "",
            "    If ``require_https`` is ``True``, only 'https' will be considered a valid",
            "    scheme, as opposed to 'http' and 'https' with the default, ``False``.",
            "    \"\"\"",
            "    if url is not None:",
            "        url = url.strip()",
            "    if not url:",
            "        return False",
            "    if six.PY2:",
            "        try:",
            "            url = force_text(url)",
            "        except UnicodeDecodeError:",
            "            return False",
            "    if allowed_hosts is None:",
            "        allowed_hosts = set()",
            "    if host:",
            "        warnings.warn(",
            "            \"The host argument is deprecated, use allowed_hosts instead.\",",
            "            RemovedInDjango21Warning,",
            "            stacklevel=2,",
            "        )",
            "        # Avoid mutating the passed in allowed_hosts.",
            "        allowed_hosts = allowed_hosts | {host}",
            "    # Chrome treats \\ completely as / in paths but it could be part of some",
            "    # basic auth credentials so we need to check both URLs.",
            "    return (_is_safe_url(url, allowed_hosts, require_https=require_https) and",
            "            _is_safe_url(url.replace('\\\\', '/'), allowed_hosts, require_https=require_https))",
            "",
            "",
            "# Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.",
            "def _urlparse(url, scheme='', allow_fragments=True):",
            "    \"\"\"Parse a URL into 6 components:",
            "    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>",
            "    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).",
            "    Note that we don't break the components up in smaller bits",
            "    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"",
            "    if _coerce_args:",
            "        url, scheme, _coerce_result = _coerce_args(url, scheme)",
            "    splitresult = _urlsplit(url, scheme, allow_fragments)",
            "    scheme, netloc, url, query, fragment = splitresult",
            "    if scheme in uses_params and ';' in url:",
            "        url, params = _splitparams(url)",
            "    else:",
            "        params = ''",
            "    result = ParseResult(scheme, netloc, url, params, query, fragment)",
            "    return _coerce_result(result) if _coerce_args else result",
            "",
            "",
            "# Copied from urllib.parse.urlsplit() with",
            "# https://github.com/python/cpython/pull/661 applied.",
            "def _urlsplit(url, scheme='', allow_fragments=True):",
            "    \"\"\"Parse a URL into 5 components:",
            "    <scheme>://<netloc>/<path>?<query>#<fragment>",
            "    Return a 5-tuple: (scheme, netloc, path, query, fragment).",
            "    Note that we don't break the components up in smaller bits",
            "    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"",
            "    if _coerce_args:",
            "        url, scheme, _coerce_result = _coerce_args(url, scheme)",
            "    allow_fragments = bool(allow_fragments)",
            "    netloc = query = fragment = ''",
            "    i = url.find(':')",
            "    if i > 0:",
            "        for c in url[:i]:",
            "            if c not in scheme_chars:",
            "                break",
            "        else:",
            "            scheme, url = url[:i].lower(), url[i + 1:]",
            "",
            "    if url[:2] == '//':",
            "        netloc, url = _splitnetloc(url, 2)",
            "        if (('[' in netloc and ']' not in netloc) or",
            "                (']' in netloc and '[' not in netloc)):",
            "            raise ValueError(\"Invalid IPv6 URL\")",
            "    if allow_fragments and '#' in url:",
            "        url, fragment = url.split('#', 1)",
            "    if '?' in url:",
            "        url, query = url.split('?', 1)",
            "    v = SplitResult(scheme, netloc, url, query, fragment)",
            "    return _coerce_result(v) if _coerce_args else v",
            "",
            "",
            "def _is_safe_url(url, allowed_hosts, require_https=False):",
            "    # Chrome considers any URL with more than two slashes to be absolute, but",
            "    # urlparse is not so flexible. Treat any url with three slashes as unsafe.",
            "    if url.startswith('///'):",
            "        return False",
            "    try:",
            "        url_info = _urlparse(url)",
            "    except ValueError:  # e.g. invalid IPv6 addresses",
            "        return False",
            "    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.",
            "    # In that URL, example.com is not the hostname but, a path component. However,",
            "    # Chrome will still consider example.com to be the hostname, so we must not",
            "    # allow this syntax.",
            "    if not url_info.netloc and url_info.scheme:",
            "        return False",
            "    # Forbid URLs that start with control characters. Some browsers (like",
            "    # Chrome) ignore quite a few control characters at the start of a",
            "    # URL and might consider the URL as scheme relative.",
            "    if unicodedata.category(url[0])[0] == 'C':",
            "        return False",
            "    scheme = url_info.scheme",
            "    # Consider URLs without a scheme (e.g. //example.com/p) to be http.",
            "    if not url_info.scheme and url_info.netloc:",
            "        scheme = 'http'",
            "    valid_schemes = ['https'] if require_https else ['http', 'https']",
            "    return ((not url_info.netloc or url_info.netloc in allowed_hosts) and",
            "            (not scheme or scheme in valid_schemes))",
            "",
            "",
            "def limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',",
            "                      errors='replace', fields_limit=None):",
            "    \"\"\"",
            "    Return a list of key/value tuples parsed from query string.",
            "",
            "    Copied from urlparse with an additional \"fields_limit\" argument.",
            "    Copyright (C) 2013 Python Software Foundation (see LICENSE.python).",
            "",
            "    Arguments:",
            "",
            "    qs: percent-encoded query string to be parsed",
            "",
            "    keep_blank_values: flag indicating whether blank values in",
            "        percent-encoded queries should be treated as blank strings. A",
            "        true value indicates that blanks should be retained as blank",
            "        strings. The default false value indicates that blank values",
            "        are to be ignored and treated as if they were  not included.",
            "",
            "    encoding and errors: specify how to decode percent-encoded sequences",
            "        into Unicode characters, as accepted by the bytes.decode() method.",
            "",
            "    fields_limit: maximum number of fields parsed or an exception",
            "        is raised. None means no limit and is the default.",
            "    \"\"\"",
            "    if fields_limit:",
            "        pairs = FIELDS_MATCH.split(qs, fields_limit)",
            "        if len(pairs) > fields_limit:",
            "            raise TooManyFieldsSent(",
            "                'The number of GET/POST parameters exceeded '",
            "                'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'",
            "            )",
            "    else:",
            "        pairs = FIELDS_MATCH.split(qs)",
            "    r = []",
            "    for name_value in pairs:",
            "        if not name_value:",
            "            continue",
            "        nv = name_value.split(str('='), 1)",
            "        if len(nv) != 2:",
            "            # Handle case of a control-name with no equal sign",
            "            if keep_blank_values:",
            "                nv.append('')",
            "            else:",
            "                continue",
            "        if len(nv[1]) or keep_blank_values:",
            "            if six.PY3:",
            "                name = nv[0].replace('+', ' ')",
            "                name = unquote(name, encoding=encoding, errors=errors)",
            "                value = nv[1].replace('+', ' ')",
            "                value = unquote(value, encoding=encoding, errors=errors)",
            "            else:",
            "                name = unquote(nv[0].replace(b'+', b' '))",
            "                value = unquote(nv[1].replace(b'+', b' '))",
            "            r.append((name, value))",
            "    return r",
            "",
            "",
            "def escape_leading_slashes(url):",
            "    \"\"\"",
            "    If redirecting to an absolute path (two leading slashes), a slash must be",
            "    escaped to prevent browsers from handling the path as schemaless and",
            "    redirecting to another host.",
            "    \"\"\"",
            "    if url.startswith('//'):",
            "        url = '/%2F{}'.format(url[2:])",
            "    return url"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "airflow.www.views.Airflow"
        ]
    }
}