{
    "django/core/cache/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " from django.conf import settings"
            },
            "1": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " from django.core import signals"
            },
            "2": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from django.core.cache.backends.base import ("
            },
            "3": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    BaseCache, CacheKeyWarning, InvalidCacheBackendError,"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+    BaseCache, CacheKeyWarning, InvalidCacheBackendError, InvalidCacheKey,"
            },
            "5": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " )"
            },
            "6": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from django.utils.module_loading import import_string"
            },
            "7": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " __all__ = ["
            },
            "9": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": "     'cache', 'caches', 'DEFAULT_CACHE_ALIAS', 'InvalidCacheBackendError',"
            },
            "10": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    'CacheKeyWarning', 'BaseCache',"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+    'CacheKeyWarning', 'BaseCache', 'InvalidCacheKey',"
            },
            "12": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " ]"
            },
            "13": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " DEFAULT_CACHE_ALIAS = 'default'"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Caching framework.",
            "",
            "This package defines set of cache backends that all conform to a simple API.",
            "In a nutshell, a cache is a set of values -- which can be any object that",
            "may be pickled -- identified by string keys.  For the complete API, see",
            "the abstract BaseCache class in django.core.cache.backends.base.",
            "",
            "Client code should use the `cache` variable defined here to access the default",
            "cache backend and look up non-default cache backends in the `caches` dict-like",
            "object.",
            "",
            "See docs/topics/cache.txt for information on the public API.",
            "\"\"\"",
            "from threading import local",
            "",
            "from django.conf import settings",
            "from django.core import signals",
            "from django.core.cache.backends.base import (",
            "    BaseCache, CacheKeyWarning, InvalidCacheBackendError,",
            ")",
            "from django.utils.module_loading import import_string",
            "",
            "__all__ = [",
            "    'cache', 'caches', 'DEFAULT_CACHE_ALIAS', 'InvalidCacheBackendError',",
            "    'CacheKeyWarning', 'BaseCache',",
            "]",
            "",
            "DEFAULT_CACHE_ALIAS = 'default'",
            "",
            "",
            "def _create_cache(backend, **kwargs):",
            "    try:",
            "        # Try to get the CACHES entry for the given backend name first",
            "        try:",
            "            conf = settings.CACHES[backend]",
            "        except KeyError:",
            "            try:",
            "                # Trying to import the given backend, in case it's a dotted path",
            "                import_string(backend)",
            "            except ImportError as e:",
            "                raise InvalidCacheBackendError(\"Could not find backend '%s': %s\" % (",
            "                    backend, e))",
            "            location = kwargs.pop('LOCATION', '')",
            "            params = kwargs",
            "        else:",
            "            params = {**conf, **kwargs}",
            "            backend = params.pop('BACKEND')",
            "            location = params.pop('LOCATION', '')",
            "        backend_cls = import_string(backend)",
            "    except ImportError as e:",
            "        raise InvalidCacheBackendError(",
            "            \"Could not find backend '%s': %s\" % (backend, e))",
            "    return backend_cls(location, params)",
            "",
            "",
            "class CacheHandler:",
            "    \"\"\"",
            "    A Cache Handler to manage access to Cache instances.",
            "",
            "    Ensure only one instance of each alias exists per thread.",
            "    \"\"\"",
            "    def __init__(self):",
            "        self._caches = local()",
            "",
            "    def __getitem__(self, alias):",
            "        try:",
            "            return self._caches.caches[alias]",
            "        except AttributeError:",
            "            self._caches.caches = {}",
            "        except KeyError:",
            "            pass",
            "",
            "        if alias not in settings.CACHES:",
            "            raise InvalidCacheBackendError(",
            "                \"Could not find config for '%s' in settings.CACHES\" % alias",
            "            )",
            "",
            "        cache = _create_cache(alias)",
            "        self._caches.caches[alias] = cache",
            "        return cache",
            "",
            "    def all(self):",
            "        return getattr(self._caches, 'caches', {}).values()",
            "",
            "",
            "caches = CacheHandler()",
            "",
            "",
            "class DefaultCacheProxy:",
            "    \"\"\"",
            "    Proxy access to the default Cache object's attributes.",
            "",
            "    This allows the legacy `cache` object to be thread-safe using the new",
            "    ``caches`` API.",
            "    \"\"\"",
            "    def __getattr__(self, name):",
            "        return getattr(caches[DEFAULT_CACHE_ALIAS], name)",
            "",
            "    def __setattr__(self, name, value):",
            "        return setattr(caches[DEFAULT_CACHE_ALIAS], name, value)",
            "",
            "    def __delattr__(self, name):",
            "        return delattr(caches[DEFAULT_CACHE_ALIAS], name)",
            "",
            "    def __contains__(self, key):",
            "        return key in caches[DEFAULT_CACHE_ALIAS]",
            "",
            "    def __eq__(self, other):",
            "        return caches[DEFAULT_CACHE_ALIAS] == other",
            "",
            "",
            "cache = DefaultCacheProxy()",
            "",
            "",
            "def close_caches(**kwargs):",
            "    # Some caches -- python-memcached in particular -- need to do a cleanup at the",
            "    # end of a request cycle. If not implemented in a particular backend",
            "    # cache.close is a no-op",
            "    for cache in caches.all():",
            "        cache.close()",
            "",
            "",
            "signals.request_finished.connect(close_caches)"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Caching framework.",
            "",
            "This package defines set of cache backends that all conform to a simple API.",
            "In a nutshell, a cache is a set of values -- which can be any object that",
            "may be pickled -- identified by string keys.  For the complete API, see",
            "the abstract BaseCache class in django.core.cache.backends.base.",
            "",
            "Client code should use the `cache` variable defined here to access the default",
            "cache backend and look up non-default cache backends in the `caches` dict-like",
            "object.",
            "",
            "See docs/topics/cache.txt for information on the public API.",
            "\"\"\"",
            "from threading import local",
            "",
            "from django.conf import settings",
            "from django.core import signals",
            "from django.core.cache.backends.base import (",
            "    BaseCache, CacheKeyWarning, InvalidCacheBackendError, InvalidCacheKey,",
            ")",
            "from django.utils.module_loading import import_string",
            "",
            "__all__ = [",
            "    'cache', 'caches', 'DEFAULT_CACHE_ALIAS', 'InvalidCacheBackendError',",
            "    'CacheKeyWarning', 'BaseCache', 'InvalidCacheKey',",
            "]",
            "",
            "DEFAULT_CACHE_ALIAS = 'default'",
            "",
            "",
            "def _create_cache(backend, **kwargs):",
            "    try:",
            "        # Try to get the CACHES entry for the given backend name first",
            "        try:",
            "            conf = settings.CACHES[backend]",
            "        except KeyError:",
            "            try:",
            "                # Trying to import the given backend, in case it's a dotted path",
            "                import_string(backend)",
            "            except ImportError as e:",
            "                raise InvalidCacheBackendError(\"Could not find backend '%s': %s\" % (",
            "                    backend, e))",
            "            location = kwargs.pop('LOCATION', '')",
            "            params = kwargs",
            "        else:",
            "            params = {**conf, **kwargs}",
            "            backend = params.pop('BACKEND')",
            "            location = params.pop('LOCATION', '')",
            "        backend_cls = import_string(backend)",
            "    except ImportError as e:",
            "        raise InvalidCacheBackendError(",
            "            \"Could not find backend '%s': %s\" % (backend, e))",
            "    return backend_cls(location, params)",
            "",
            "",
            "class CacheHandler:",
            "    \"\"\"",
            "    A Cache Handler to manage access to Cache instances.",
            "",
            "    Ensure only one instance of each alias exists per thread.",
            "    \"\"\"",
            "    def __init__(self):",
            "        self._caches = local()",
            "",
            "    def __getitem__(self, alias):",
            "        try:",
            "            return self._caches.caches[alias]",
            "        except AttributeError:",
            "            self._caches.caches = {}",
            "        except KeyError:",
            "            pass",
            "",
            "        if alias not in settings.CACHES:",
            "            raise InvalidCacheBackendError(",
            "                \"Could not find config for '%s' in settings.CACHES\" % alias",
            "            )",
            "",
            "        cache = _create_cache(alias)",
            "        self._caches.caches[alias] = cache",
            "        return cache",
            "",
            "    def all(self):",
            "        return getattr(self._caches, 'caches', {}).values()",
            "",
            "",
            "caches = CacheHandler()",
            "",
            "",
            "class DefaultCacheProxy:",
            "    \"\"\"",
            "    Proxy access to the default Cache object's attributes.",
            "",
            "    This allows the legacy `cache` object to be thread-safe using the new",
            "    ``caches`` API.",
            "    \"\"\"",
            "    def __getattr__(self, name):",
            "        return getattr(caches[DEFAULT_CACHE_ALIAS], name)",
            "",
            "    def __setattr__(self, name, value):",
            "        return setattr(caches[DEFAULT_CACHE_ALIAS], name, value)",
            "",
            "    def __delattr__(self, name):",
            "        return delattr(caches[DEFAULT_CACHE_ALIAS], name)",
            "",
            "    def __contains__(self, key):",
            "        return key in caches[DEFAULT_CACHE_ALIAS]",
            "",
            "    def __eq__(self, other):",
            "        return caches[DEFAULT_CACHE_ALIAS] == other",
            "",
            "",
            "cache = DefaultCacheProxy()",
            "",
            "",
            "def close_caches(**kwargs):",
            "    # Some caches -- python-memcached in particular -- need to do a cleanup at the",
            "    # end of a request cycle. If not implemented in a particular backend",
            "    # cache.close is a no-op",
            "    for cache in caches.all():",
            "        cache.close()",
            "",
            "",
            "signals.request_finished.connect(close_caches)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "20": [],
            "26": []
        },
        "addLocation": []
    },
    "django/core/cache/backends/base.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": "     pass"
            },
            "1": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 17,
                "PatchRowcode": "+class InvalidCacheKey(ValueError):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+    pass"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+"
            },
            "7": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " # Stub class to ensure not passing in a `timeout` argument results in"
            },
            "8": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " # the default timeout"
            },
            "9": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " DEFAULT_TIMEOUT = object()"
            },
            "10": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 246,
                "PatchRowcode": "         backend. This encourages (but does not force) writing backend-portable"
            },
            "11": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 247,
                "PatchRowcode": "         cache code."
            },
            "12": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 248,
                "PatchRowcode": "         \"\"\""
            },
            "13": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if len(key) > MEMCACHE_MAX_KEY_LENGTH:"
            },
            "14": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            warnings.warn("
            },
            "15": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'Cache key will cause errors if used with memcached: %r '"
            },
            "16": {
                "beforePatchRowNumber": 248,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                '(longer than %s)' % (key, MEMCACHE_MAX_KEY_LENGTH), CacheKeyWarning"
            },
            "17": {
                "beforePatchRowNumber": 249,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            )"
            },
            "18": {
                "beforePatchRowNumber": 250,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for char in key:"
            },
            "19": {
                "beforePatchRowNumber": 251,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if ord(char) < 33 or ord(char) == 127:"
            },
            "20": {
                "beforePatchRowNumber": 252,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                warnings.warn("
            },
            "21": {
                "beforePatchRowNumber": 253,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    'Cache key contains characters that will cause errors if '"
            },
            "22": {
                "beforePatchRowNumber": 254,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    'used with memcached: %r' % key, CacheKeyWarning"
            },
            "23": {
                "beforePatchRowNumber": 255,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                )"
            },
            "24": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                break"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 249,
                "PatchRowcode": "+        for warning in memcache_key_warnings(key):"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 250,
                "PatchRowcode": "+            warnings.warn(warning, CacheKeyWarning)"
            },
            "27": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": 251,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 258,
                "afterPatchRowNumber": 252,
                "PatchRowcode": "     def incr_version(self, key, delta=1, version=None):"
            },
            "29": {
                "beforePatchRowNumber": 259,
                "afterPatchRowNumber": 253,
                "PatchRowcode": "         \"\"\""
            },
            "30": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": 275,
                "PatchRowcode": "     def close(self, **kwargs):"
            },
            "31": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": 276,
                "PatchRowcode": "         \"\"\"Close the cache connection\"\"\""
            },
            "32": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": 277,
                "PatchRowcode": "         pass"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 278,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 279,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 280,
                "PatchRowcode": "+def memcache_key_warnings(key):"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 281,
                "PatchRowcode": "+    if len(key) > MEMCACHE_MAX_KEY_LENGTH:"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 282,
                "PatchRowcode": "+        yield ("
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 283,
                "PatchRowcode": "+            'Cache key will cause errors if used with memcached: %r '"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 284,
                "PatchRowcode": "+            '(longer than %s)' % (key, MEMCACHE_MAX_KEY_LENGTH)"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 285,
                "PatchRowcode": "+        )"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 286,
                "PatchRowcode": "+    for char in key:"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 287,
                "PatchRowcode": "+        if ord(char) < 33 or ord(char) == 127:"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 288,
                "PatchRowcode": "+            yield ("
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 289,
                "PatchRowcode": "+                'Cache key contains characters that will cause errors if '"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 290,
                "PatchRowcode": "+                'used with memcached: %r' % key, CacheKeyWarning"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 291,
                "PatchRowcode": "+            )"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 292,
                "PatchRowcode": "+            break"
            }
        },
        "frontPatchFile": [
            "\"Base Cache class.\"",
            "import time",
            "import warnings",
            "",
            "from django.core.exceptions import ImproperlyConfigured",
            "from django.utils.module_loading import import_string",
            "",
            "",
            "class InvalidCacheBackendError(ImproperlyConfigured):",
            "    pass",
            "",
            "",
            "class CacheKeyWarning(RuntimeWarning):",
            "    pass",
            "",
            "",
            "# Stub class to ensure not passing in a `timeout` argument results in",
            "# the default timeout",
            "DEFAULT_TIMEOUT = object()",
            "",
            "# Memcached does not accept keys longer than this.",
            "MEMCACHE_MAX_KEY_LENGTH = 250",
            "",
            "",
            "def default_key_func(key, key_prefix, version):",
            "    \"\"\"",
            "    Default function to generate keys.",
            "",
            "    Construct the key used by all other methods. By default, prepend",
            "    the `key_prefix'. KEY_FUNCTION can be used to specify an alternate",
            "    function with custom key making behavior.",
            "    \"\"\"",
            "    return '%s:%s:%s' % (key_prefix, version, key)",
            "",
            "",
            "def get_key_func(key_func):",
            "    \"\"\"",
            "    Function to decide which key function to use.",
            "",
            "    Default to ``default_key_func``.",
            "    \"\"\"",
            "    if key_func is not None:",
            "        if callable(key_func):",
            "            return key_func",
            "        else:",
            "            return import_string(key_func)",
            "    return default_key_func",
            "",
            "",
            "class BaseCache:",
            "    def __init__(self, params):",
            "        timeout = params.get('timeout', params.get('TIMEOUT', 300))",
            "        if timeout is not None:",
            "            try:",
            "                timeout = int(timeout)",
            "            except (ValueError, TypeError):",
            "                timeout = 300",
            "        self.default_timeout = timeout",
            "",
            "        options = params.get('OPTIONS', {})",
            "        max_entries = params.get('max_entries', options.get('MAX_ENTRIES', 300))",
            "        try:",
            "            self._max_entries = int(max_entries)",
            "        except (ValueError, TypeError):",
            "            self._max_entries = 300",
            "",
            "        cull_frequency = params.get('cull_frequency', options.get('CULL_FREQUENCY', 3))",
            "        try:",
            "            self._cull_frequency = int(cull_frequency)",
            "        except (ValueError, TypeError):",
            "            self._cull_frequency = 3",
            "",
            "        self.key_prefix = params.get('KEY_PREFIX', '')",
            "        self.version = params.get('VERSION', 1)",
            "        self.key_func = get_key_func(params.get('KEY_FUNCTION'))",
            "",
            "    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):",
            "        \"\"\"",
            "        Return the timeout value usable by this backend based upon the provided",
            "        timeout.",
            "        \"\"\"",
            "        if timeout == DEFAULT_TIMEOUT:",
            "            timeout = self.default_timeout",
            "        elif timeout == 0:",
            "            # ticket 21147 - avoid time.time() related precision issues",
            "            timeout = -1",
            "        return None if timeout is None else time.time() + timeout",
            "",
            "    def make_key(self, key, version=None):",
            "        \"\"\"",
            "        Construct the key used by all other methods. By default, use the",
            "        key_func to generate a key (which, by default, prepends the",
            "        `key_prefix' and 'version'). A different key function can be provided",
            "        at the time of cache construction; alternatively, you can subclass the",
            "        cache backend to provide custom key making behavior.",
            "        \"\"\"",
            "        if version is None:",
            "            version = self.version",
            "",
            "        new_key = self.key_func(key, self.key_prefix, version)",
            "        return new_key",
            "",
            "    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Set a value in the cache if the key does not already exist. If",
            "        timeout is given, use that timeout for the key; otherwise use the",
            "        default cache timeout.",
            "",
            "        Return True if the value was stored, False otherwise.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide an add() method')",
            "",
            "    def get(self, key, default=None, version=None):",
            "        \"\"\"",
            "        Fetch a given key from the cache. If the key does not exist, return",
            "        default, which itself defaults to None.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a get() method')",
            "",
            "    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Set a value in the cache. If timeout is given, use that timeout for the",
            "        key; otherwise use the default cache timeout.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a set() method')",
            "",
            "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Update the key's expiry time using timeout. Return True if successful",
            "        or False if the key does not exist.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a touch() method')",
            "",
            "    def delete(self, key, version=None):",
            "        \"\"\"",
            "        Delete a key from the cache, failing silently.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a delete() method')",
            "",
            "    def get_many(self, keys, version=None):",
            "        \"\"\"",
            "        Fetch a bunch of keys from the cache. For certain backends (memcached,",
            "        pgsql) this can be *much* faster when fetching multiple values.",
            "",
            "        Return a dict mapping each key in keys to its value. If the given",
            "        key is missing, it will be missing from the response dict.",
            "        \"\"\"",
            "        d = {}",
            "        for k in keys:",
            "            val = self.get(k, version=version)",
            "            if val is not None:",
            "                d[k] = val",
            "        return d",
            "",
            "    def get_or_set(self, key, default, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Fetch a given key from the cache. If the key does not exist,",
            "        add the key and set it to the default value. The default value can",
            "        also be any callable. If timeout is given, use that timeout for the",
            "        key; otherwise use the default cache timeout.",
            "",
            "        Return the value of the key stored or retrieved.",
            "        \"\"\"",
            "        val = self.get(key, version=version)",
            "        if val is None:",
            "            if callable(default):",
            "                default = default()",
            "            if default is not None:",
            "                self.add(key, default, timeout=timeout, version=version)",
            "                # Fetch the value again to avoid a race condition if another",
            "                # caller added a value between the first get() and the add()",
            "                # above.",
            "                return self.get(key, default, version=version)",
            "        return val",
            "",
            "    def has_key(self, key, version=None):",
            "        \"\"\"",
            "        Return True if the key is in the cache and has not expired.",
            "        \"\"\"",
            "        return self.get(key, version=version) is not None",
            "",
            "    def incr(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Add delta to value in the cache. If the key does not exist, raise a",
            "        ValueError exception.",
            "        \"\"\"",
            "        value = self.get(key, version=version)",
            "        if value is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "        new_value = value + delta",
            "        self.set(key, new_value, version=version)",
            "        return new_value",
            "",
            "    def decr(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Subtract delta from value in the cache. If the key does not exist, raise",
            "        a ValueError exception.",
            "        \"\"\"",
            "        return self.incr(key, -delta, version=version)",
            "",
            "    def __contains__(self, key):",
            "        \"\"\"",
            "        Return True if the key is in the cache and has not expired.",
            "        \"\"\"",
            "        # This is a separate method, rather than just a copy of has_key(),",
            "        # so that it always has the same functionality as has_key(), even",
            "        # if a subclass overrides it.",
            "        return self.has_key(key)",
            "",
            "    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Set a bunch of values in the cache at once from a dict of key/value",
            "        pairs.  For certain backends (memcached), this is much more efficient",
            "        than calling set() multiple times.",
            "",
            "        If timeout is given, use that timeout for the key; otherwise use the",
            "        default cache timeout.",
            "",
            "        On backends that support it, return a list of keys that failed",
            "        insertion, or an empty list if all keys were inserted successfully.",
            "        \"\"\"",
            "        for key, value in data.items():",
            "            self.set(key, value, timeout=timeout, version=version)",
            "        return []",
            "",
            "    def delete_many(self, keys, version=None):",
            "        \"\"\"",
            "        Delete a bunch of values in the cache at once. For certain backends",
            "        (memcached), this is much more efficient than calling delete() multiple",
            "        times.",
            "        \"\"\"",
            "        for key in keys:",
            "            self.delete(key, version=version)",
            "",
            "    def clear(self):",
            "        \"\"\"Remove *all* values from the cache at once.\"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a clear() method')",
            "",
            "    def validate_key(self, key):",
            "        \"\"\"",
            "        Warn about keys that would not be portable to the memcached",
            "        backend. This encourages (but does not force) writing backend-portable",
            "        cache code.",
            "        \"\"\"",
            "        if len(key) > MEMCACHE_MAX_KEY_LENGTH:",
            "            warnings.warn(",
            "                'Cache key will cause errors if used with memcached: %r '",
            "                '(longer than %s)' % (key, MEMCACHE_MAX_KEY_LENGTH), CacheKeyWarning",
            "            )",
            "        for char in key:",
            "            if ord(char) < 33 or ord(char) == 127:",
            "                warnings.warn(",
            "                    'Cache key contains characters that will cause errors if '",
            "                    'used with memcached: %r' % key, CacheKeyWarning",
            "                )",
            "                break",
            "",
            "    def incr_version(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Add delta to the cache version for the supplied key. Return the new",
            "        version.",
            "        \"\"\"",
            "        if version is None:",
            "            version = self.version",
            "",
            "        value = self.get(key, version=version)",
            "        if value is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "",
            "        self.set(key, value, version=version + delta)",
            "        self.delete(key, version=version)",
            "        return version + delta",
            "",
            "    def decr_version(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Subtract delta from the cache version for the supplied key. Return the",
            "        new version.",
            "        \"\"\"",
            "        return self.incr_version(key, -delta, version)",
            "",
            "    def close(self, **kwargs):",
            "        \"\"\"Close the cache connection\"\"\"",
            "        pass"
        ],
        "afterPatchFile": [
            "\"Base Cache class.\"",
            "import time",
            "import warnings",
            "",
            "from django.core.exceptions import ImproperlyConfigured",
            "from django.utils.module_loading import import_string",
            "",
            "",
            "class InvalidCacheBackendError(ImproperlyConfigured):",
            "    pass",
            "",
            "",
            "class CacheKeyWarning(RuntimeWarning):",
            "    pass",
            "",
            "",
            "class InvalidCacheKey(ValueError):",
            "    pass",
            "",
            "",
            "# Stub class to ensure not passing in a `timeout` argument results in",
            "# the default timeout",
            "DEFAULT_TIMEOUT = object()",
            "",
            "# Memcached does not accept keys longer than this.",
            "MEMCACHE_MAX_KEY_LENGTH = 250",
            "",
            "",
            "def default_key_func(key, key_prefix, version):",
            "    \"\"\"",
            "    Default function to generate keys.",
            "",
            "    Construct the key used by all other methods. By default, prepend",
            "    the `key_prefix'. KEY_FUNCTION can be used to specify an alternate",
            "    function with custom key making behavior.",
            "    \"\"\"",
            "    return '%s:%s:%s' % (key_prefix, version, key)",
            "",
            "",
            "def get_key_func(key_func):",
            "    \"\"\"",
            "    Function to decide which key function to use.",
            "",
            "    Default to ``default_key_func``.",
            "    \"\"\"",
            "    if key_func is not None:",
            "        if callable(key_func):",
            "            return key_func",
            "        else:",
            "            return import_string(key_func)",
            "    return default_key_func",
            "",
            "",
            "class BaseCache:",
            "    def __init__(self, params):",
            "        timeout = params.get('timeout', params.get('TIMEOUT', 300))",
            "        if timeout is not None:",
            "            try:",
            "                timeout = int(timeout)",
            "            except (ValueError, TypeError):",
            "                timeout = 300",
            "        self.default_timeout = timeout",
            "",
            "        options = params.get('OPTIONS', {})",
            "        max_entries = params.get('max_entries', options.get('MAX_ENTRIES', 300))",
            "        try:",
            "            self._max_entries = int(max_entries)",
            "        except (ValueError, TypeError):",
            "            self._max_entries = 300",
            "",
            "        cull_frequency = params.get('cull_frequency', options.get('CULL_FREQUENCY', 3))",
            "        try:",
            "            self._cull_frequency = int(cull_frequency)",
            "        except (ValueError, TypeError):",
            "            self._cull_frequency = 3",
            "",
            "        self.key_prefix = params.get('KEY_PREFIX', '')",
            "        self.version = params.get('VERSION', 1)",
            "        self.key_func = get_key_func(params.get('KEY_FUNCTION'))",
            "",
            "    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):",
            "        \"\"\"",
            "        Return the timeout value usable by this backend based upon the provided",
            "        timeout.",
            "        \"\"\"",
            "        if timeout == DEFAULT_TIMEOUT:",
            "            timeout = self.default_timeout",
            "        elif timeout == 0:",
            "            # ticket 21147 - avoid time.time() related precision issues",
            "            timeout = -1",
            "        return None if timeout is None else time.time() + timeout",
            "",
            "    def make_key(self, key, version=None):",
            "        \"\"\"",
            "        Construct the key used by all other methods. By default, use the",
            "        key_func to generate a key (which, by default, prepends the",
            "        `key_prefix' and 'version'). A different key function can be provided",
            "        at the time of cache construction; alternatively, you can subclass the",
            "        cache backend to provide custom key making behavior.",
            "        \"\"\"",
            "        if version is None:",
            "            version = self.version",
            "",
            "        new_key = self.key_func(key, self.key_prefix, version)",
            "        return new_key",
            "",
            "    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Set a value in the cache if the key does not already exist. If",
            "        timeout is given, use that timeout for the key; otherwise use the",
            "        default cache timeout.",
            "",
            "        Return True if the value was stored, False otherwise.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide an add() method')",
            "",
            "    def get(self, key, default=None, version=None):",
            "        \"\"\"",
            "        Fetch a given key from the cache. If the key does not exist, return",
            "        default, which itself defaults to None.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a get() method')",
            "",
            "    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Set a value in the cache. If timeout is given, use that timeout for the",
            "        key; otherwise use the default cache timeout.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a set() method')",
            "",
            "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Update the key's expiry time using timeout. Return True if successful",
            "        or False if the key does not exist.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a touch() method')",
            "",
            "    def delete(self, key, version=None):",
            "        \"\"\"",
            "        Delete a key from the cache, failing silently.",
            "        \"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a delete() method')",
            "",
            "    def get_many(self, keys, version=None):",
            "        \"\"\"",
            "        Fetch a bunch of keys from the cache. For certain backends (memcached,",
            "        pgsql) this can be *much* faster when fetching multiple values.",
            "",
            "        Return a dict mapping each key in keys to its value. If the given",
            "        key is missing, it will be missing from the response dict.",
            "        \"\"\"",
            "        d = {}",
            "        for k in keys:",
            "            val = self.get(k, version=version)",
            "            if val is not None:",
            "                d[k] = val",
            "        return d",
            "",
            "    def get_or_set(self, key, default, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Fetch a given key from the cache. If the key does not exist,",
            "        add the key and set it to the default value. The default value can",
            "        also be any callable. If timeout is given, use that timeout for the",
            "        key; otherwise use the default cache timeout.",
            "",
            "        Return the value of the key stored or retrieved.",
            "        \"\"\"",
            "        val = self.get(key, version=version)",
            "        if val is None:",
            "            if callable(default):",
            "                default = default()",
            "            if default is not None:",
            "                self.add(key, default, timeout=timeout, version=version)",
            "                # Fetch the value again to avoid a race condition if another",
            "                # caller added a value between the first get() and the add()",
            "                # above.",
            "                return self.get(key, default, version=version)",
            "        return val",
            "",
            "    def has_key(self, key, version=None):",
            "        \"\"\"",
            "        Return True if the key is in the cache and has not expired.",
            "        \"\"\"",
            "        return self.get(key, version=version) is not None",
            "",
            "    def incr(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Add delta to value in the cache. If the key does not exist, raise a",
            "        ValueError exception.",
            "        \"\"\"",
            "        value = self.get(key, version=version)",
            "        if value is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "        new_value = value + delta",
            "        self.set(key, new_value, version=version)",
            "        return new_value",
            "",
            "    def decr(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Subtract delta from value in the cache. If the key does not exist, raise",
            "        a ValueError exception.",
            "        \"\"\"",
            "        return self.incr(key, -delta, version=version)",
            "",
            "    def __contains__(self, key):",
            "        \"\"\"",
            "        Return True if the key is in the cache and has not expired.",
            "        \"\"\"",
            "        # This is a separate method, rather than just a copy of has_key(),",
            "        # so that it always has the same functionality as has_key(), even",
            "        # if a subclass overrides it.",
            "        return self.has_key(key)",
            "",
            "    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):",
            "        \"\"\"",
            "        Set a bunch of values in the cache at once from a dict of key/value",
            "        pairs.  For certain backends (memcached), this is much more efficient",
            "        than calling set() multiple times.",
            "",
            "        If timeout is given, use that timeout for the key; otherwise use the",
            "        default cache timeout.",
            "",
            "        On backends that support it, return a list of keys that failed",
            "        insertion, or an empty list if all keys were inserted successfully.",
            "        \"\"\"",
            "        for key, value in data.items():",
            "            self.set(key, value, timeout=timeout, version=version)",
            "        return []",
            "",
            "    def delete_many(self, keys, version=None):",
            "        \"\"\"",
            "        Delete a bunch of values in the cache at once. For certain backends",
            "        (memcached), this is much more efficient than calling delete() multiple",
            "        times.",
            "        \"\"\"",
            "        for key in keys:",
            "            self.delete(key, version=version)",
            "",
            "    def clear(self):",
            "        \"\"\"Remove *all* values from the cache at once.\"\"\"",
            "        raise NotImplementedError('subclasses of BaseCache must provide a clear() method')",
            "",
            "    def validate_key(self, key):",
            "        \"\"\"",
            "        Warn about keys that would not be portable to the memcached",
            "        backend. This encourages (but does not force) writing backend-portable",
            "        cache code.",
            "        \"\"\"",
            "        for warning in memcache_key_warnings(key):",
            "            warnings.warn(warning, CacheKeyWarning)",
            "",
            "    def incr_version(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Add delta to the cache version for the supplied key. Return the new",
            "        version.",
            "        \"\"\"",
            "        if version is None:",
            "            version = self.version",
            "",
            "        value = self.get(key, version=version)",
            "        if value is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "",
            "        self.set(key, value, version=version + delta)",
            "        self.delete(key, version=version)",
            "        return version + delta",
            "",
            "    def decr_version(self, key, delta=1, version=None):",
            "        \"\"\"",
            "        Subtract delta from the cache version for the supplied key. Return the",
            "        new version.",
            "        \"\"\"",
            "        return self.incr_version(key, -delta, version)",
            "",
            "    def close(self, **kwargs):",
            "        \"\"\"Close the cache connection\"\"\"",
            "        pass",
            "",
            "",
            "def memcache_key_warnings(key):",
            "    if len(key) > MEMCACHE_MAX_KEY_LENGTH:",
            "        yield (",
            "            'Cache key will cause errors if used with memcached: %r '",
            "            '(longer than %s)' % (key, MEMCACHE_MAX_KEY_LENGTH)",
            "        )",
            "    for char in key:",
            "        if ord(char) < 33 or ord(char) == 127:",
            "            yield (",
            "                'Cache key contains characters that will cause errors if '",
            "                'used with memcached: %r' % key, CacheKeyWarning",
            "            )",
            "            break"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "245": [
                "BaseCache",
                "validate_key"
            ],
            "246": [
                "BaseCache",
                "validate_key"
            ],
            "247": [
                "BaseCache",
                "validate_key"
            ],
            "248": [
                "BaseCache",
                "validate_key"
            ],
            "249": [
                "BaseCache",
                "validate_key"
            ],
            "250": [
                "BaseCache",
                "validate_key"
            ],
            "251": [
                "BaseCache",
                "validate_key"
            ],
            "252": [
                "BaseCache",
                "validate_key"
            ],
            "253": [
                "BaseCache",
                "validate_key"
            ],
            "254": [
                "BaseCache",
                "validate_key"
            ],
            "255": [
                "BaseCache",
                "validate_key"
            ],
            "256": [
                "BaseCache",
                "validate_key"
            ]
        },
        "addLocation": []
    },
    "django/core/cache/backends/memcached.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import re"
            },
            "1": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import time"
            },
            "2": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 7,
                "PatchRowcode": "+from django.core.cache.backends.base import ("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+    DEFAULT_TIMEOUT, BaseCache, InvalidCacheKey, memcache_key_warnings,"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+)"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from django.utils.functional import cached_property"
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 64,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 65,
                "afterPatchRowNumber": 67,
                "PatchRowcode": "     def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):"
            },
            "12": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "         key = self.make_key(key, version=version)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+        self.validate_key(key)"
            },
            "14": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 70,
                "PatchRowcode": "         return self._cache.add(key, value, self.get_backend_timeout(timeout))"
            },
            "15": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 71,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 72,
                "PatchRowcode": "     def get(self, key, default=None, version=None):"
            },
            "17": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 73,
                "PatchRowcode": "         key = self.make_key(key, version=version)"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+        self.validate_key(key)"
            },
            "19": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 75,
                "PatchRowcode": "         val = self._cache.get(key)"
            },
            "20": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 76,
                "PatchRowcode": "         if val is None:"
            },
            "21": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 77,
                "PatchRowcode": "             return default"
            },
            "22": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": 78,
                "PatchRowcode": "         return val"
            },
            "23": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": 79,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": 80,
                "PatchRowcode": "     def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):"
            },
            "25": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "         key = self.make_key(key, version=version)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+        self.validate_key(key)"
            },
            "27": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "         if not self._cache.set(key, value, self.get_backend_timeout(timeout)):"
            },
            "28": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "             # make sure the key doesn't keep its old value in case of failure to set (memcached's 1MB limit)"
            },
            "29": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "             self._cache.delete(key)"
            },
            "30": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 86,
                "PatchRowcode": " "
            },
            "31": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "     def delete(self, key, version=None):"
            },
            "32": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "         key = self.make_key(key, version=version)"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+        self.validate_key(key)"
            },
            "34": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "         self._cache.delete(key)"
            },
            "35": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 91,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 92,
                "PatchRowcode": "     def get_many(self, keys, version=None):"
            },
            "37": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "         key_map = {self.make_key(key, version=version): key for key in keys}"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+        for key in key_map:"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+            self.validate_key(key)"
            },
            "40": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 96,
                "PatchRowcode": "         ret = self._cache.get_multi(key_map.keys())"
            },
            "41": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 97,
                "PatchRowcode": "         return {key_map[k]: v for k, v in ret.items()}"
            },
            "42": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 98,
                "PatchRowcode": " "
            },
            "43": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 102,
                "PatchRowcode": " "
            },
            "44": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "     def incr(self, key, delta=1, version=None):"
            },
            "45": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "         key = self.make_key(key, version=version)"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+        self.validate_key(key)"
            },
            "47": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 106,
                "PatchRowcode": "         # memcached doesn't support a negative delta"
            },
            "48": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 107,
                "PatchRowcode": "         if delta < 0:"
            },
            "49": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 108,
                "PatchRowcode": "             return self._cache.decr(key, -delta)"
            },
            "50": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": 121,
                "PatchRowcode": " "
            },
            "51": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "     def decr(self, key, delta=1, version=None):"
            },
            "52": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 123,
                "PatchRowcode": "         key = self.make_key(key, version=version)"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+        self.validate_key(key)"
            },
            "54": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "         # memcached doesn't support a negative delta"
            },
            "55": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "         if delta < 0:"
            },
            "56": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "             return self._cache.incr(key, -delta)"
            },
            "57": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 143,
                "PatchRowcode": "         original_keys = {}"
            },
            "58": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 144,
                "PatchRowcode": "         for key, value in data.items():"
            },
            "59": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 145,
                "PatchRowcode": "             safe_key = self.make_key(key, version=version)"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+            self.validate_key(safe_key)"
            },
            "61": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "             safe_data[safe_key] = value"
            },
            "62": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "             original_keys[safe_key] = key"
            },
            "63": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "         failed_keys = self._cache.set_multi(safe_data, self.get_backend_timeout(timeout))"
            },
            "64": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 155,
                "PatchRowcode": "     def clear(self):"
            },
            "65": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "         self._cache.flush_all()"
            },
            "66": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 157,
                "PatchRowcode": " "
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 158,
                "PatchRowcode": "+    def validate_key(self, key):"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+        for warning in memcache_key_warnings(key):"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+            raise InvalidCacheKey(warning)"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+"
            },
            "71": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 162,
                "PatchRowcode": " "
            },
            "72": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 163,
                "PatchRowcode": " class MemcachedCache(BaseMemcachedCache):"
            },
            "73": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "     \"An implementation of a cache binding using python-memcached\""
            }
        },
        "frontPatchFile": [
            "\"Memcached cache backend\"",
            "",
            "import pickle",
            "import re",
            "import time",
            "",
            "from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache",
            "from django.utils.functional import cached_property",
            "",
            "",
            "class BaseMemcachedCache(BaseCache):",
            "    def __init__(self, server, params, library, value_not_found_exception):",
            "        super().__init__(params)",
            "        if isinstance(server, str):",
            "            self._servers = re.split('[;,]', server)",
            "        else:",
            "            self._servers = server",
            "",
            "        # The exception type to catch from the underlying library for a key",
            "        # that was not found. This is a ValueError for python-memcache,",
            "        # pylibmc.NotFound for pylibmc, and cmemcache will return None without",
            "        # raising an exception.",
            "        self.LibraryValueNotFoundException = value_not_found_exception",
            "",
            "        self._lib = library",
            "        self._options = params.get('OPTIONS') or {}",
            "",
            "    @property",
            "    def _cache(self):",
            "        \"\"\"",
            "        Implement transparent thread-safe access to a memcached client.",
            "        \"\"\"",
            "        if getattr(self, '_client', None) is None:",
            "            self._client = self._lib.Client(self._servers, **self._options)",
            "",
            "        return self._client",
            "",
            "    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):",
            "        \"\"\"",
            "        Memcached deals with long (> 30 days) timeouts in a special",
            "        way. Call this function to obtain a safe value for your timeout.",
            "        \"\"\"",
            "        if timeout == DEFAULT_TIMEOUT:",
            "            timeout = self.default_timeout",
            "",
            "        if timeout is None:",
            "            # Using 0 in memcache sets a non-expiring timeout.",
            "            return 0",
            "        elif int(timeout) == 0:",
            "            # Other cache backends treat 0 as set-and-expire. To achieve this",
            "            # in memcache backends, a negative timeout must be passed.",
            "            timeout = -1",
            "",
            "        if timeout > 2592000:  # 60*60*24*30, 30 days",
            "            # See https://github.com/memcached/memcached/wiki/Programming#expiration",
            "            # \"Expiration times can be set from 0, meaning \"never expire\", to",
            "            # 30 days. Any time higher than 30 days is interpreted as a Unix",
            "            # timestamp date. If you want to expire an object on January 1st of",
            "            # next year, this is how you do that.\"",
            "            #",
            "            # This means that we have to switch to absolute timestamps.",
            "            timeout += int(time.time())",
            "        return int(timeout)",
            "",
            "    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        return self._cache.add(key, value, self.get_backend_timeout(timeout))",
            "",
            "    def get(self, key, default=None, version=None):",
            "        key = self.make_key(key, version=version)",
            "        val = self._cache.get(key)",
            "        if val is None:",
            "            return default",
            "        return val",
            "",
            "    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        if not self._cache.set(key, value, self.get_backend_timeout(timeout)):",
            "            # make sure the key doesn't keep its old value in case of failure to set (memcached's 1MB limit)",
            "            self._cache.delete(key)",
            "",
            "    def delete(self, key, version=None):",
            "        key = self.make_key(key, version=version)",
            "        self._cache.delete(key)",
            "",
            "    def get_many(self, keys, version=None):",
            "        key_map = {self.make_key(key, version=version): key for key in keys}",
            "        ret = self._cache.get_multi(key_map.keys())",
            "        return {key_map[k]: v for k, v in ret.items()}",
            "",
            "    def close(self, **kwargs):",
            "        # Many clients don't clean up connections properly.",
            "        self._cache.disconnect_all()",
            "",
            "    def incr(self, key, delta=1, version=None):",
            "        key = self.make_key(key, version=version)",
            "        # memcached doesn't support a negative delta",
            "        if delta < 0:",
            "            return self._cache.decr(key, -delta)",
            "        try:",
            "            val = self._cache.incr(key, delta)",
            "",
            "        # python-memcache responds to incr on nonexistent keys by",
            "        # raising a ValueError, pylibmc by raising a pylibmc.NotFound",
            "        # and Cmemcache returns None. In all cases,",
            "        # we should raise a ValueError though.",
            "        except self.LibraryValueNotFoundException:",
            "            val = None",
            "        if val is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "        return val",
            "",
            "    def decr(self, key, delta=1, version=None):",
            "        key = self.make_key(key, version=version)",
            "        # memcached doesn't support a negative delta",
            "        if delta < 0:",
            "            return self._cache.incr(key, -delta)",
            "        try:",
            "            val = self._cache.decr(key, delta)",
            "",
            "        # python-memcache responds to incr on nonexistent keys by",
            "        # raising a ValueError, pylibmc by raising a pylibmc.NotFound",
            "        # and Cmemcache returns None. In all cases,",
            "        # we should raise a ValueError though.",
            "        except self.LibraryValueNotFoundException:",
            "            val = None",
            "        if val is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "        return val",
            "",
            "    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):",
            "        safe_data = {}",
            "        original_keys = {}",
            "        for key, value in data.items():",
            "            safe_key = self.make_key(key, version=version)",
            "            safe_data[safe_key] = value",
            "            original_keys[safe_key] = key",
            "        failed_keys = self._cache.set_multi(safe_data, self.get_backend_timeout(timeout))",
            "        return [original_keys[k] for k in failed_keys]",
            "",
            "    def delete_many(self, keys, version=None):",
            "        self._cache.delete_multi(self.make_key(key, version=version) for key in keys)",
            "",
            "    def clear(self):",
            "        self._cache.flush_all()",
            "",
            "",
            "class MemcachedCache(BaseMemcachedCache):",
            "    \"An implementation of a cache binding using python-memcached\"",
            "    def __init__(self, server, params):",
            "        import memcache",
            "        super().__init__(server, params, library=memcache, value_not_found_exception=ValueError)",
            "",
            "    @property",
            "    def _cache(self):",
            "        if getattr(self, '_client', None) is None:",
            "            client_kwargs = {'pickleProtocol': pickle.HIGHEST_PROTOCOL}",
            "            client_kwargs.update(self._options)",
            "            self._client = self._lib.Client(self._servers, **client_kwargs)",
            "        return self._client",
            "",
            "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        return self._cache.touch(key, self.get_backend_timeout(timeout)) != 0",
            "",
            "",
            "class PyLibMCCache(BaseMemcachedCache):",
            "    \"An implementation of a cache binding using pylibmc\"",
            "    def __init__(self, server, params):",
            "        import pylibmc",
            "        super().__init__(server, params, library=pylibmc, value_not_found_exception=pylibmc.NotFound)",
            "",
            "    @cached_property",
            "    def _cache(self):",
            "        return self._lib.Client(self._servers, **self._options)",
            "",
            "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        if timeout == 0:",
            "            return self._cache.delete(key)",
            "        return self._cache.touch(key, self.get_backend_timeout(timeout))",
            "",
            "    def close(self, **kwargs):",
            "        # libmemcached manages its own connections. Don't call disconnect_all()",
            "        # as it resets the failover state and creates unnecessary reconnects.",
            "        pass"
        ],
        "afterPatchFile": [
            "\"Memcached cache backend\"",
            "",
            "import pickle",
            "import re",
            "import time",
            "",
            "from django.core.cache.backends.base import (",
            "    DEFAULT_TIMEOUT, BaseCache, InvalidCacheKey, memcache_key_warnings,",
            ")",
            "from django.utils.functional import cached_property",
            "",
            "",
            "class BaseMemcachedCache(BaseCache):",
            "    def __init__(self, server, params, library, value_not_found_exception):",
            "        super().__init__(params)",
            "        if isinstance(server, str):",
            "            self._servers = re.split('[;,]', server)",
            "        else:",
            "            self._servers = server",
            "",
            "        # The exception type to catch from the underlying library for a key",
            "        # that was not found. This is a ValueError for python-memcache,",
            "        # pylibmc.NotFound for pylibmc, and cmemcache will return None without",
            "        # raising an exception.",
            "        self.LibraryValueNotFoundException = value_not_found_exception",
            "",
            "        self._lib = library",
            "        self._options = params.get('OPTIONS') or {}",
            "",
            "    @property",
            "    def _cache(self):",
            "        \"\"\"",
            "        Implement transparent thread-safe access to a memcached client.",
            "        \"\"\"",
            "        if getattr(self, '_client', None) is None:",
            "            self._client = self._lib.Client(self._servers, **self._options)",
            "",
            "        return self._client",
            "",
            "    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):",
            "        \"\"\"",
            "        Memcached deals with long (> 30 days) timeouts in a special",
            "        way. Call this function to obtain a safe value for your timeout.",
            "        \"\"\"",
            "        if timeout == DEFAULT_TIMEOUT:",
            "            timeout = self.default_timeout",
            "",
            "        if timeout is None:",
            "            # Using 0 in memcache sets a non-expiring timeout.",
            "            return 0",
            "        elif int(timeout) == 0:",
            "            # Other cache backends treat 0 as set-and-expire. To achieve this",
            "            # in memcache backends, a negative timeout must be passed.",
            "            timeout = -1",
            "",
            "        if timeout > 2592000:  # 60*60*24*30, 30 days",
            "            # See https://github.com/memcached/memcached/wiki/Programming#expiration",
            "            # \"Expiration times can be set from 0, meaning \"never expire\", to",
            "            # 30 days. Any time higher than 30 days is interpreted as a Unix",
            "            # timestamp date. If you want to expire an object on January 1st of",
            "            # next year, this is how you do that.\"",
            "            #",
            "            # This means that we have to switch to absolute timestamps.",
            "            timeout += int(time.time())",
            "        return int(timeout)",
            "",
            "    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        self.validate_key(key)",
            "        return self._cache.add(key, value, self.get_backend_timeout(timeout))",
            "",
            "    def get(self, key, default=None, version=None):",
            "        key = self.make_key(key, version=version)",
            "        self.validate_key(key)",
            "        val = self._cache.get(key)",
            "        if val is None:",
            "            return default",
            "        return val",
            "",
            "    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        self.validate_key(key)",
            "        if not self._cache.set(key, value, self.get_backend_timeout(timeout)):",
            "            # make sure the key doesn't keep its old value in case of failure to set (memcached's 1MB limit)",
            "            self._cache.delete(key)",
            "",
            "    def delete(self, key, version=None):",
            "        key = self.make_key(key, version=version)",
            "        self.validate_key(key)",
            "        self._cache.delete(key)",
            "",
            "    def get_many(self, keys, version=None):",
            "        key_map = {self.make_key(key, version=version): key for key in keys}",
            "        for key in key_map:",
            "            self.validate_key(key)",
            "        ret = self._cache.get_multi(key_map.keys())",
            "        return {key_map[k]: v for k, v in ret.items()}",
            "",
            "    def close(self, **kwargs):",
            "        # Many clients don't clean up connections properly.",
            "        self._cache.disconnect_all()",
            "",
            "    def incr(self, key, delta=1, version=None):",
            "        key = self.make_key(key, version=version)",
            "        self.validate_key(key)",
            "        # memcached doesn't support a negative delta",
            "        if delta < 0:",
            "            return self._cache.decr(key, -delta)",
            "        try:",
            "            val = self._cache.incr(key, delta)",
            "",
            "        # python-memcache responds to incr on nonexistent keys by",
            "        # raising a ValueError, pylibmc by raising a pylibmc.NotFound",
            "        # and Cmemcache returns None. In all cases,",
            "        # we should raise a ValueError though.",
            "        except self.LibraryValueNotFoundException:",
            "            val = None",
            "        if val is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "        return val",
            "",
            "    def decr(self, key, delta=1, version=None):",
            "        key = self.make_key(key, version=version)",
            "        self.validate_key(key)",
            "        # memcached doesn't support a negative delta",
            "        if delta < 0:",
            "            return self._cache.incr(key, -delta)",
            "        try:",
            "            val = self._cache.decr(key, delta)",
            "",
            "        # python-memcache responds to incr on nonexistent keys by",
            "        # raising a ValueError, pylibmc by raising a pylibmc.NotFound",
            "        # and Cmemcache returns None. In all cases,",
            "        # we should raise a ValueError though.",
            "        except self.LibraryValueNotFoundException:",
            "            val = None",
            "        if val is None:",
            "            raise ValueError(\"Key '%s' not found\" % key)",
            "        return val",
            "",
            "    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):",
            "        safe_data = {}",
            "        original_keys = {}",
            "        for key, value in data.items():",
            "            safe_key = self.make_key(key, version=version)",
            "            self.validate_key(safe_key)",
            "            safe_data[safe_key] = value",
            "            original_keys[safe_key] = key",
            "        failed_keys = self._cache.set_multi(safe_data, self.get_backend_timeout(timeout))",
            "        return [original_keys[k] for k in failed_keys]",
            "",
            "    def delete_many(self, keys, version=None):",
            "        self._cache.delete_multi(self.make_key(key, version=version) for key in keys)",
            "",
            "    def clear(self):",
            "        self._cache.flush_all()",
            "",
            "    def validate_key(self, key):",
            "        for warning in memcache_key_warnings(key):",
            "            raise InvalidCacheKey(warning)",
            "",
            "",
            "class MemcachedCache(BaseMemcachedCache):",
            "    \"An implementation of a cache binding using python-memcached\"",
            "    def __init__(self, server, params):",
            "        import memcache",
            "        super().__init__(server, params, library=memcache, value_not_found_exception=ValueError)",
            "",
            "    @property",
            "    def _cache(self):",
            "        if getattr(self, '_client', None) is None:",
            "            client_kwargs = {'pickleProtocol': pickle.HIGHEST_PROTOCOL}",
            "            client_kwargs.update(self._options)",
            "            self._client = self._lib.Client(self._servers, **client_kwargs)",
            "        return self._client",
            "",
            "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        return self._cache.touch(key, self.get_backend_timeout(timeout)) != 0",
            "",
            "",
            "class PyLibMCCache(BaseMemcachedCache):",
            "    \"An implementation of a cache binding using pylibmc\"",
            "    def __init__(self, server, params):",
            "        import pylibmc",
            "        super().__init__(server, params, library=pylibmc, value_not_found_exception=pylibmc.NotFound)",
            "",
            "    @cached_property",
            "    def _cache(self):",
            "        return self._lib.Client(self._servers, **self._options)",
            "",
            "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):",
            "        key = self.make_key(key, version=version)",
            "        if timeout == 0:",
            "            return self._cache.delete(key)",
            "        return self._cache.touch(key, self.get_backend_timeout(timeout))",
            "",
            "    def close(self, **kwargs):",
            "        # libmemcached manages its own connections. Don't call disconnect_all()",
            "        # as it resets the failover state and creates unnecessary reconnects.",
            "        pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "7": []
        },
        "addLocation": []
    }
}