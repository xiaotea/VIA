{
    "neutron/plugins/bigswitch/config.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "     cfg.StrOpt('server_auth', default=None, secret=True,"
            },
            "1": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "                help=_(\"The username and password for authenticating against \""
            },
            "2": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "                       \" the BigSwitch or Floodlight controller.\")),"
            },
            "3": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    cfg.BoolOpt('server_ssl', default=False,"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+    cfg.BoolOpt('server_ssl', default=True,"
            },
            "5": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "                 help=_(\"If True, Use SSL when connecting to the BigSwitch or \""
            },
            "6": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 44,
                "PatchRowcode": "                        \"Floodlight controller.\")),"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+    cfg.BoolOpt('ssl_sticky', default=True,"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+                help=_(\"Trust and store the first certificate received for \""
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+                       \"each controller address and use it to validate future \""
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+                       \"connections to that address.\")),"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+    cfg.BoolOpt('no_ssl_validation', default=False,"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+                help=_(\"Disables SSL certificate validation for controllers\")),"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 51,
                "PatchRowcode": "+    cfg.BoolOpt('cache_connections', default=True,"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+                help=_(\"Re-use HTTP/HTTPS connections to the controller.\")),"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+    cfg.StrOpt('ssl_cert_directory',"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+               default='/etc/neutron/plugins/bigswitch/ssl',"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+               help=_(\"Directory containing ca_certs and host_certs \""
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+                      \"certificate directories.\")),"
            },
            "19": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "     cfg.BoolOpt('sync_data', default=False,"
            },
            "20": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "                 help=_(\"Sync data on connect\")),"
            },
            "21": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "     cfg.BoolOpt('auto_sync_on_failure', default=True,"
            }
        },
        "frontPatchFile": [
            "# vim: tabstop=4 shiftwidth=4 softtabstop=4",
            "# Copyright 2014 Big Switch Networks, Inc.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "#",
            "# @author: Mandeep Dhami, Big Switch Networks, Inc.",
            "# @author: Sumit Naiksatam, sumitnaiksatam@gmail.com, Big Switch Networks, Inc.",
            "# @author: Kevin Benton, Big Switch Networks, Inc.",
            "",
            "\"\"\"",
            "This module manages configuration options",
            "\"\"\"",
            "",
            "from oslo.config import cfg",
            "",
            "from neutron.agent.common import config as agconfig",
            "from neutron.common import utils",
            "from neutron.extensions import portbindings",
            "",
            "restproxy_opts = [",
            "    cfg.ListOpt('servers', default=['localhost:8800'],",
            "                help=_(\"A comma separated list of BigSwitch or Floodlight \"",
            "                       \"servers and port numbers. The plugin proxies the \"",
            "                       \"requests to the BigSwitch/Floodlight server, \"",
            "                       \"which performs the networking configuration. Only one\"",
            "                       \"server is needed per deployment, but you may wish to\"",
            "                       \"deploy multiple servers to support failover.\")),",
            "    cfg.StrOpt('server_auth', default=None, secret=True,",
            "               help=_(\"The username and password for authenticating against \"",
            "                      \" the BigSwitch or Floodlight controller.\")),",
            "    cfg.BoolOpt('server_ssl', default=False,",
            "                help=_(\"If True, Use SSL when connecting to the BigSwitch or \"",
            "                       \"Floodlight controller.\")),",
            "    cfg.BoolOpt('sync_data', default=False,",
            "                help=_(\"Sync data on connect\")),",
            "    cfg.BoolOpt('auto_sync_on_failure', default=True,",
            "                help=_(\"If neutron fails to create a resource because \"",
            "                       \"the backend controller doesn't know of a dependency, \"",
            "                       \"automatically trigger a full data synchronization \"",
            "                       \"to the controller.\")),",
            "    cfg.IntOpt('consistency_interval', default=60,",
            "               help=_(\"Time between verifications that the backend controller \"",
            "                      \"database is consistent with Neutron\")),",
            "    cfg.IntOpt('server_timeout', default=10,",
            "               help=_(\"Maximum number of seconds to wait for proxy request \"",
            "                      \"to connect and complete.\")),",
            "    cfg.IntOpt('thread_pool_size', default=4,",
            "               help=_(\"Maximum number of threads to spawn to handle large \"",
            "                      \"volumes of port creations.\")),",
            "    cfg.StrOpt('neutron_id', default='neutron-' + utils.get_hostname(),",
            "               deprecated_name='quantum_id',",
            "               help=_(\"User defined identifier for this Neutron deployment\")),",
            "    cfg.BoolOpt('add_meta_server_route', default=True,",
            "                help=_(\"Flag to decide if a route to the metadata server \"",
            "                       \"should be injected into the VM\")),",
            "]",
            "router_opts = [",
            "    cfg.MultiStrOpt('tenant_default_router_rule', default=['*:any:any:permit'],",
            "                    help=_(\"The default router rules installed in new tenant \"",
            "                           \"routers. Repeat the config option for each rule. \"",
            "                           \"Format is <tenant>:<source>:<destination>:<action>\"",
            "                           \" Use an * to specify default for all tenants.\")),",
            "    cfg.IntOpt('max_router_rules', default=200,",
            "               help=_(\"Maximum number of router rules\")),",
            "]",
            "nova_opts = [",
            "    cfg.StrOpt('vif_type', default='ovs',",
            "               help=_(\"Virtual interface type to configure on \"",
            "                      \"Nova compute nodes\")),",
            "]",
            "",
            "# Each VIF Type can have a list of nova host IDs that are fixed to that type",
            "for i in portbindings.VIF_TYPES:",
            "    opt = cfg.ListOpt('node_override_vif_' + i, default=[],",
            "                      help=_(\"Nova compute nodes to manually set VIF \"",
            "                             \"type to %s\") % i)",
            "    nova_opts.append(opt)",
            "",
            "# Add the vif types for reference later",
            "nova_opts.append(cfg.ListOpt('vif_types',",
            "                             default=portbindings.VIF_TYPES,",
            "                             help=_('List of allowed vif_type values.')))",
            "",
            "agent_opts = [",
            "    cfg.StrOpt('integration_bridge', default='br-int',",
            "               help=_('Name of integration bridge on compute '",
            "                      'nodes used for security group insertion.')),",
            "    cfg.IntOpt('polling_interval', default=5,",
            "               help=_('Seconds between agent checks for port changes')),",
            "    cfg.StrOpt('virtual_switch_type', default='ovs',",
            "               help=_('Virtual switch type.'))",
            "]",
            "",
            "",
            "def register_config():",
            "    cfg.CONF.register_opts(restproxy_opts, \"RESTPROXY\")",
            "    cfg.CONF.register_opts(router_opts, \"ROUTER\")",
            "    cfg.CONF.register_opts(nova_opts, \"NOVA\")",
            "    cfg.CONF.register_opts(agent_opts, \"RESTPROXYAGENT\")",
            "    agconfig.register_root_helper(cfg.CONF)"
        ],
        "afterPatchFile": [
            "# vim: tabstop=4 shiftwidth=4 softtabstop=4",
            "# Copyright 2014 Big Switch Networks, Inc.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "#",
            "# @author: Mandeep Dhami, Big Switch Networks, Inc.",
            "# @author: Sumit Naiksatam, sumitnaiksatam@gmail.com, Big Switch Networks, Inc.",
            "# @author: Kevin Benton, Big Switch Networks, Inc.",
            "",
            "\"\"\"",
            "This module manages configuration options",
            "\"\"\"",
            "",
            "from oslo.config import cfg",
            "",
            "from neutron.agent.common import config as agconfig",
            "from neutron.common import utils",
            "from neutron.extensions import portbindings",
            "",
            "restproxy_opts = [",
            "    cfg.ListOpt('servers', default=['localhost:8800'],",
            "                help=_(\"A comma separated list of BigSwitch or Floodlight \"",
            "                       \"servers and port numbers. The plugin proxies the \"",
            "                       \"requests to the BigSwitch/Floodlight server, \"",
            "                       \"which performs the networking configuration. Only one\"",
            "                       \"server is needed per deployment, but you may wish to\"",
            "                       \"deploy multiple servers to support failover.\")),",
            "    cfg.StrOpt('server_auth', default=None, secret=True,",
            "               help=_(\"The username and password for authenticating against \"",
            "                      \" the BigSwitch or Floodlight controller.\")),",
            "    cfg.BoolOpt('server_ssl', default=True,",
            "                help=_(\"If True, Use SSL when connecting to the BigSwitch or \"",
            "                       \"Floodlight controller.\")),",
            "    cfg.BoolOpt('ssl_sticky', default=True,",
            "                help=_(\"Trust and store the first certificate received for \"",
            "                       \"each controller address and use it to validate future \"",
            "                       \"connections to that address.\")),",
            "    cfg.BoolOpt('no_ssl_validation', default=False,",
            "                help=_(\"Disables SSL certificate validation for controllers\")),",
            "    cfg.BoolOpt('cache_connections', default=True,",
            "                help=_(\"Re-use HTTP/HTTPS connections to the controller.\")),",
            "    cfg.StrOpt('ssl_cert_directory',",
            "               default='/etc/neutron/plugins/bigswitch/ssl',",
            "               help=_(\"Directory containing ca_certs and host_certs \"",
            "                      \"certificate directories.\")),",
            "    cfg.BoolOpt('sync_data', default=False,",
            "                help=_(\"Sync data on connect\")),",
            "    cfg.BoolOpt('auto_sync_on_failure', default=True,",
            "                help=_(\"If neutron fails to create a resource because \"",
            "                       \"the backend controller doesn't know of a dependency, \"",
            "                       \"automatically trigger a full data synchronization \"",
            "                       \"to the controller.\")),",
            "    cfg.IntOpt('consistency_interval', default=60,",
            "               help=_(\"Time between verifications that the backend controller \"",
            "                      \"database is consistent with Neutron\")),",
            "    cfg.IntOpt('server_timeout', default=10,",
            "               help=_(\"Maximum number of seconds to wait for proxy request \"",
            "                      \"to connect and complete.\")),",
            "    cfg.IntOpt('thread_pool_size', default=4,",
            "               help=_(\"Maximum number of threads to spawn to handle large \"",
            "                      \"volumes of port creations.\")),",
            "    cfg.StrOpt('neutron_id', default='neutron-' + utils.get_hostname(),",
            "               deprecated_name='quantum_id',",
            "               help=_(\"User defined identifier for this Neutron deployment\")),",
            "    cfg.BoolOpt('add_meta_server_route', default=True,",
            "                help=_(\"Flag to decide if a route to the metadata server \"",
            "                       \"should be injected into the VM\")),",
            "]",
            "router_opts = [",
            "    cfg.MultiStrOpt('tenant_default_router_rule', default=['*:any:any:permit'],",
            "                    help=_(\"The default router rules installed in new tenant \"",
            "                           \"routers. Repeat the config option for each rule. \"",
            "                           \"Format is <tenant>:<source>:<destination>:<action>\"",
            "                           \" Use an * to specify default for all tenants.\")),",
            "    cfg.IntOpt('max_router_rules', default=200,",
            "               help=_(\"Maximum number of router rules\")),",
            "]",
            "nova_opts = [",
            "    cfg.StrOpt('vif_type', default='ovs',",
            "               help=_(\"Virtual interface type to configure on \"",
            "                      \"Nova compute nodes\")),",
            "]",
            "",
            "# Each VIF Type can have a list of nova host IDs that are fixed to that type",
            "for i in portbindings.VIF_TYPES:",
            "    opt = cfg.ListOpt('node_override_vif_' + i, default=[],",
            "                      help=_(\"Nova compute nodes to manually set VIF \"",
            "                             \"type to %s\") % i)",
            "    nova_opts.append(opt)",
            "",
            "# Add the vif types for reference later",
            "nova_opts.append(cfg.ListOpt('vif_types',",
            "                             default=portbindings.VIF_TYPES,",
            "                             help=_('List of allowed vif_type values.')))",
            "",
            "agent_opts = [",
            "    cfg.StrOpt('integration_bridge', default='br-int',",
            "               help=_('Name of integration bridge on compute '",
            "                      'nodes used for security group insertion.')),",
            "    cfg.IntOpt('polling_interval', default=5,",
            "               help=_('Seconds between agent checks for port changes')),",
            "    cfg.StrOpt('virtual_switch_type', default='ovs',",
            "               help=_('Virtual switch type.'))",
            "]",
            "",
            "",
            "def register_config():",
            "    cfg.CONF.register_opts(restproxy_opts, \"RESTPROXY\")",
            "    cfg.CONF.register_opts(router_opts, \"ROUTER\")",
            "    cfg.CONF.register_opts(nova_opts, \"NOVA\")",
            "    cfg.CONF.register_opts(agent_opts, \"RESTPROXYAGENT\")",
            "    agconfig.register_root_helper(cfg.CONF)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "42": []
        },
        "addLocation": []
    },
    "neutron/plugins/bigswitch/servermanager.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " The following functionality is handled by this module:"
            },
            "1": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " - Translation of rest_* function calls to HTTP/HTTPS calls to the controllers"
            },
            "2": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " - Automatic failover between controllers"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+- SSL Certificate enforcement"
            },
            "4": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " - HTTP Authentication"
            },
            "5": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " \"\"\""
            },
            "7": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " import base64"
            },
            "8": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " import httplib"
            },
            "9": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " import json"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+import os"
            },
            "11": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " import socket"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+import ssl"
            },
            "13": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 40,
                "PatchRowcode": " import time"
            },
            "14": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 41,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " import eventlet"
            },
            "16": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " from oslo.config import cfg"
            },
            "17": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 45,
                "PatchRowcode": " from neutron.common import exceptions"
            },
            "19": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 46,
                "PatchRowcode": " from neutron.common import utils"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+from neutron.openstack.common import excutils"
            },
            "21": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 48,
                "PatchRowcode": " from neutron.openstack.common import log as logging"
            },
            "22": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 49,
                "PatchRowcode": " from neutron.plugins.bigswitch.db import consistency_db as cdb"
            },
            "23": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 50,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "     \"\"\"REST server proxy to a network controller.\"\"\""
            },
            "25": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 90,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 91,
                "PatchRowcode": "     def __init__(self, server, port, ssl, auth, neutron_id, timeout,"
            },
            "27": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                 base_uri, name, mypool):"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+                 base_uri, name, mypool, combined_cert):"
            },
            "29": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "         self.server = server"
            },
            "30": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "         self.port = port"
            },
            "31": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "         self.ssl = ssl"
            },
            "32": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "         self.capabilities = []"
            },
            "33": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "         # enable server to reference parent pool"
            },
            "34": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "         self.mypool = mypool"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        # cache connection here to avoid a SSL handshake for every connection"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+        self.currentconn = None"
            },
            "37": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 108,
                "PatchRowcode": "         if auth:"
            },
            "38": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 109,
                "PatchRowcode": "             self.auth = 'Basic ' + base64.encodestring(auth).strip()"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+        self.combined_cert = combined_cert"
            },
            "40": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 111,
                "PatchRowcode": " "
            },
            "41": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 112,
                "PatchRowcode": "     def get_capabilities(self):"
            },
            "42": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 113,
                "PatchRowcode": "         try:"
            },
            "43": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 121,
                "PatchRowcode": "                                                 'cap': self.capabilities})"
            },
            "44": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 122,
                "PatchRowcode": "         return self.capabilities"
            },
            "45": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 123,
                "PatchRowcode": " "
            },
            "46": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def rest_call(self, action, resource, data='', headers={}, timeout=None):"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+    def rest_call(self, action, resource, data='', headers={}, timeout=False,"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+                  reconnect=False):"
            },
            "49": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "         uri = self.base_uri + resource"
            },
            "50": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "         body = json.dumps(data)"
            },
            "51": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "         if not headers:"
            },
            "52": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "         headers['Instance-ID'] = self.neutron_id"
            },
            "53": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "         headers['Orchestration-Service-ID'] = ORCHESTRATION_SERVICE_ID"
            },
            "54": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "         headers[HASH_MATCH_HEADER] = self.mypool.consistency_hash"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 136,
                "PatchRowcode": "+        if 'keep-alive' in self.capabilities:"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 137,
                "PatchRowcode": "+            headers['Connection'] = 'keep-alive'"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+        else:"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+            reconnect = True"
            },
            "59": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "         if self.auth:"
            },
            "60": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "             headers['Authorization'] = self.auth"
            },
            "61": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 142,
                "PatchRowcode": " "
            },
            "62": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "                   {'resource': resource, 'data': data, 'headers': headers,"
            },
            "63": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "                    'action': action})"
            },
            "64": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 150,
                "PatchRowcode": " "
            },
            "65": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        conn = None"
            },
            "66": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        timeout = timeout or self.timeout"
            },
            "67": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if self.ssl:"
            },
            "68": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            conn = httplib.HTTPSConnection("
            },
            "69": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                self.server, self.port, timeout=timeout)"
            },
            "70": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if conn is None:"
            },
            "71": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                LOG.error(_('ServerProxy: Could not establish HTTPS '"
            },
            "72": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            'connection'))"
            },
            "73": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                return 0, None, None, None"
            },
            "74": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        else:"
            },
            "75": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            conn = httplib.HTTPConnection("
            },
            "76": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                self.server, self.port, timeout=timeout)"
            },
            "77": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if conn is None:"
            },
            "78": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                LOG.error(_('ServerProxy: Could not establish HTTP '"
            },
            "79": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            'connection'))"
            },
            "80": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                return 0, None, None, None"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+        # unspecified timeout is False because a timeout can be specified as"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+        # None to indicate no timeout."
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+        if timeout is False:"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 154,
                "PatchRowcode": "+            timeout = self.timeout"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 156,
                "PatchRowcode": "+        if timeout != self.timeout:"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 157,
                "PatchRowcode": "+            # need a new connection if timeout has changed"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 158,
                "PatchRowcode": "+            reconnect = True"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 159,
                "PatchRowcode": "+"
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 160,
                "PatchRowcode": "+        if not self.currentconn or reconnect:"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 161,
                "PatchRowcode": "+            if self.currentconn:"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 162,
                "PatchRowcode": "+                self.currentconn.close()"
            },
            "93": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 163,
                "PatchRowcode": "+            if self.ssl:"
            },
            "94": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 164,
                "PatchRowcode": "+                self.currentconn = HTTPSConnectionWithValidation("
            },
            "95": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 165,
                "PatchRowcode": "+                    self.server, self.port, timeout=timeout)"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 166,
                "PatchRowcode": "+                self.currentconn.combined_cert = self.combined_cert"
            },
            "97": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+                if self.currentconn is None:"
            },
            "98": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 168,
                "PatchRowcode": "+                    LOG.error(_('ServerProxy: Could not establish HTTPS '"
            },
            "99": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+                                'connection'))"
            },
            "100": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+                    return 0, None, None, None"
            },
            "101": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+            else:"
            },
            "102": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+                self.currentconn = httplib.HTTPConnection("
            },
            "103": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 173,
                "PatchRowcode": "+                    self.server, self.port, timeout=timeout)"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+                if self.currentconn is None:"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 175,
                "PatchRowcode": "+                    LOG.error(_('ServerProxy: Could not establish HTTP '"
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 176,
                "PatchRowcode": "+                                'connection'))"
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 177,
                "PatchRowcode": "+                    return 0, None, None, None"
            },
            "108": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 178,
                "PatchRowcode": " "
            },
            "109": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "         try:"
            },
            "110": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            conn.request(action, uri, body, headers)"
            },
            "111": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            response = conn.getresponse()"
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 180,
                "PatchRowcode": "+            self.currentconn.request(action, uri, body, headers)"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 181,
                "PatchRowcode": "+            response = self.currentconn.getresponse()"
            },
            "114": {
                "beforePatchRowNumber": 159,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "             newhash = response.getheader(HASH_MATCH_HEADER)"
            },
            "115": {
                "beforePatchRowNumber": 160,
                "afterPatchRowNumber": 183,
                "PatchRowcode": "             if newhash:"
            },
            "116": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "                 self._put_consistency_hash(newhash)"
            },
            "117": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "                     # response was not JSON, ignore the exception"
            },
            "118": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "                     pass"
            },
            "119": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 193,
                "PatchRowcode": "             ret = (response.status, response.reason, respstr, respdata)"
            },
            "120": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+        except httplib.ImproperConnectionState:"
            },
            "121": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+            # If we were using a cached connection, try again with a new one."
            },
            "122": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 196,
                "PatchRowcode": "+            with excutils.save_and_reraise_exception() as ctxt:"
            },
            "123": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 197,
                "PatchRowcode": "+                if not reconnect:"
            },
            "124": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 198,
                "PatchRowcode": "+                    ctxt.reraise = False"
            },
            "125": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 199,
                "PatchRowcode": "+"
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 200,
                "PatchRowcode": "+            if self.currentconn:"
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 201,
                "PatchRowcode": "+                self.currentconn.close()"
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 202,
                "PatchRowcode": "+            return self.rest_call(action, resource, data, headers,"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 203,
                "PatchRowcode": "+                                  timeout=timeout, reconnect=True)"
            },
            "130": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 204,
                "PatchRowcode": "         except (socket.timeout, socket.error) as e:"
            },
            "131": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 205,
                "PatchRowcode": "             LOG.error(_('ServerProxy: %(action)s failure, %(e)r'),"
            },
            "132": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 206,
                "PatchRowcode": "                       {'action': action, 'e': e})"
            },
            "133": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 207,
                "PatchRowcode": "             ret = 0, None, None, None"
            },
            "134": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        conn.close()"
            },
            "135": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 208,
                "PatchRowcode": "         LOG.debug(_(\"ServerProxy: status=%(status)d, reason=%(reason)r, \""
            },
            "136": {
                "beforePatchRowNumber": 177,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "                     \"ret=%(ret)s, data=%(data)r\"), {'status': ret[0],"
            },
            "137": {
                "beforePatchRowNumber": 178,
                "afterPatchRowNumber": 210,
                "PatchRowcode": "                                                     'reason': ret[1],"
            },
            "138": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 219,
                "PatchRowcode": " "
            },
            "139": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 220,
                "PatchRowcode": " class ServerPool(object):"
            },
            "140": {
                "beforePatchRowNumber": 189,
                "afterPatchRowNumber": 221,
                "PatchRowcode": " "
            },
            "141": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def __init__(self, timeout=10,"
            },
            "142": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 222,
                "PatchRowcode": "+    def __init__(self, timeout=False,"
            },
            "143": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 223,
                "PatchRowcode": "                  base_uri=BASE_URI, name='NeutronRestProxy'):"
            },
            "144": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 224,
                "PatchRowcode": "         LOG.debug(_(\"ServerPool: initializing\"))"
            },
            "145": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 225,
                "PatchRowcode": "         # 'servers' is the list of network controller REST end-points"
            },
            "146": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 232,
                "PatchRowcode": "         self.base_uri = base_uri"
            },
            "147": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 233,
                "PatchRowcode": "         self.name = name"
            },
            "148": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": 234,
                "PatchRowcode": "         self.timeout = cfg.CONF.RESTPROXY.server_timeout"
            },
            "149": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+        self.always_reconnect = not cfg.CONF.RESTPROXY.cache_connections"
            },
            "150": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "         default_port = 8000"
            },
            "151": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if timeout is not None:"
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+        if timeout is not False:"
            },
            "153": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "             self.timeout = timeout"
            },
            "154": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 239,
                "PatchRowcode": " "
            },
            "155": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 240,
                "PatchRowcode": "         # Function to use to retrieve topology for consistency syncs."
            },
            "156": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 277,
                "PatchRowcode": "             return self.capabilities"
            },
            "157": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": 278,
                "PatchRowcode": " "
            },
            "158": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": 279,
                "PatchRowcode": "     def server_proxy_for(self, server, port):"
            },
            "159": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 280,
                "PatchRowcode": "+        combined_cert = self._get_combined_cert_for_server(server, port)"
            },
            "160": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": 281,
                "PatchRowcode": "         return ServerProxy(server, port, self.ssl, self.auth, self.neutron_id,"
            },
            "161": {
                "beforePatchRowNumber": 248,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                           self.timeout, self.base_uri, self.name, mypool=self)"
            },
            "162": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 282,
                "PatchRowcode": "+                           self.timeout, self.base_uri, self.name, mypool=self,"
            },
            "163": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 283,
                "PatchRowcode": "+                           combined_cert=combined_cert)"
            },
            "164": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 284,
                "PatchRowcode": "+"
            },
            "165": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 285,
                "PatchRowcode": "+    def _get_combined_cert_for_server(self, server, port):"
            },
            "166": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 286,
                "PatchRowcode": "+        # The ssl library requires a combined file with all trusted certs"
            },
            "167": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 287,
                "PatchRowcode": "+        # so we make one containing the trusted CAs and the corresponding"
            },
            "168": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 288,
                "PatchRowcode": "+        # host cert for this server"
            },
            "169": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 289,
                "PatchRowcode": "+        combined_cert = None"
            },
            "170": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 290,
                "PatchRowcode": "+        if self.ssl and not cfg.CONF.RESTPROXY.no_ssl_validation:"
            },
            "171": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 291,
                "PatchRowcode": "+            base_ssl = cfg.CONF.RESTPROXY.ssl_cert_directory"
            },
            "172": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 292,
                "PatchRowcode": "+            host_dir = os.path.join(base_ssl, 'host_certs')"
            },
            "173": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 293,
                "PatchRowcode": "+            ca_dir = os.path.join(base_ssl, 'ca_certs')"
            },
            "174": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 294,
                "PatchRowcode": "+            combined_dir = os.path.join(base_ssl, 'combined')"
            },
            "175": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 295,
                "PatchRowcode": "+            combined_cert = os.path.join(combined_dir, '%s.pem' % server)"
            },
            "176": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 296,
                "PatchRowcode": "+            if not os.path.exists(base_ssl):"
            },
            "177": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 297,
                "PatchRowcode": "+                raise cfg.Error(_('ssl_cert_directory [%s] does not exist. '"
            },
            "178": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 298,
                "PatchRowcode": "+                                  'Create it or disable ssl.') % base_ssl)"
            },
            "179": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 299,
                "PatchRowcode": "+            for automake in [combined_dir, ca_dir, host_dir]:"
            },
            "180": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 300,
                "PatchRowcode": "+                if not os.path.exists(automake):"
            },
            "181": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 301,
                "PatchRowcode": "+                    os.makedirs(automake)"
            },
            "182": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 302,
                "PatchRowcode": "+"
            },
            "183": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 303,
                "PatchRowcode": "+            # get all CA certs"
            },
            "184": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 304,
                "PatchRowcode": "+            certs = self._get_ca_cert_paths(ca_dir)"
            },
            "185": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 305,
                "PatchRowcode": "+"
            },
            "186": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 306,
                "PatchRowcode": "+            # check for a host specific cert"
            },
            "187": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 307,
                "PatchRowcode": "+            hcert, exists = self._get_host_cert_path(host_dir, server)"
            },
            "188": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 308,
                "PatchRowcode": "+            if exists:"
            },
            "189": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 309,
                "PatchRowcode": "+                certs.append(hcert)"
            },
            "190": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 310,
                "PatchRowcode": "+            elif cfg.CONF.RESTPROXY.ssl_sticky:"
            },
            "191": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 311,
                "PatchRowcode": "+                self._fetch_and_store_cert(server, port, hcert)"
            },
            "192": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 312,
                "PatchRowcode": "+                certs.append(hcert)"
            },
            "193": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 313,
                "PatchRowcode": "+            if not certs:"
            },
            "194": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 314,
                "PatchRowcode": "+                raise cfg.Error(_('No certificates were found to verify '"
            },
            "195": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 315,
                "PatchRowcode": "+                                  'controller %s') % (server))"
            },
            "196": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 316,
                "PatchRowcode": "+            self._combine_certs_to_file(certs, combined_cert)"
            },
            "197": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 317,
                "PatchRowcode": "+        return combined_cert"
            },
            "198": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 318,
                "PatchRowcode": "+"
            },
            "199": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 319,
                "PatchRowcode": "+    def _combine_certs_to_file(certs, cfile):"
            },
            "200": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 320,
                "PatchRowcode": "+        '''"
            },
            "201": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 321,
                "PatchRowcode": "+        Concatenates the contents of each certificate in a list of"
            },
            "202": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 322,
                "PatchRowcode": "+        certificate paths to one combined location for use with ssl"
            },
            "203": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 323,
                "PatchRowcode": "+        sockets."
            },
            "204": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 324,
                "PatchRowcode": "+        '''"
            },
            "205": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 325,
                "PatchRowcode": "+        with open(cfile, 'w') as combined:"
            },
            "206": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 326,
                "PatchRowcode": "+            for c in certs:"
            },
            "207": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 327,
                "PatchRowcode": "+                with open(c, 'r') as cert_handle:"
            },
            "208": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 328,
                "PatchRowcode": "+                    combined.write(cert_handle.read())"
            },
            "209": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 329,
                "PatchRowcode": "+"
            },
            "210": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 330,
                "PatchRowcode": "+    def _get_host_cert_path(self, host_dir, server):"
            },
            "211": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 331,
                "PatchRowcode": "+        '''"
            },
            "212": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 332,
                "PatchRowcode": "+        returns full path and boolean indicating existence"
            },
            "213": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 333,
                "PatchRowcode": "+        '''"
            },
            "214": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 334,
                "PatchRowcode": "+        hcert = os.path.join(host_dir, '%s.pem' % server)"
            },
            "215": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 335,
                "PatchRowcode": "+        if os.path.exists(hcert):"
            },
            "216": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 336,
                "PatchRowcode": "+            return hcert, True"
            },
            "217": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 337,
                "PatchRowcode": "+        return hcert, False"
            },
            "218": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 338,
                "PatchRowcode": "+"
            },
            "219": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 339,
                "PatchRowcode": "+    def _get_ca_cert_paths(self, ca_dir):"
            },
            "220": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 340,
                "PatchRowcode": "+        certs = [os.path.join(root, name)"
            },
            "221": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+                 for name in ["
            },
            "222": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 342,
                "PatchRowcode": "+                     name for (root, dirs, files) in os.walk(ca_dir)"
            },
            "223": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 343,
                "PatchRowcode": "+                     for name in files"
            },
            "224": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 344,
                "PatchRowcode": "+                 ]"
            },
            "225": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 345,
                "PatchRowcode": "+                 if name.endswith('.pem')]"
            },
            "226": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 346,
                "PatchRowcode": "+        return certs"
            },
            "227": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 347,
                "PatchRowcode": "+"
            },
            "228": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+    def _fetch_and_store_cert(self, server, port, path):"
            },
            "229": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 349,
                "PatchRowcode": "+        '''"
            },
            "230": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 350,
                "PatchRowcode": "+        Grabs a certificate from a server and writes it to"
            },
            "231": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 351,
                "PatchRowcode": "+        a given path."
            },
            "232": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 352,
                "PatchRowcode": "+        '''"
            },
            "233": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 353,
                "PatchRowcode": "+        try:"
            },
            "234": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 354,
                "PatchRowcode": "+            cert = ssl.get_server_certificate((server, port))"
            },
            "235": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 355,
                "PatchRowcode": "+        except Exception as e:"
            },
            "236": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 356,
                "PatchRowcode": "+            raise cfg.Error(_('Could not retrieve initial '"
            },
            "237": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 357,
                "PatchRowcode": "+                              'certificate from controller %(server)s. '"
            },
            "238": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 358,
                "PatchRowcode": "+                              'Error details: %(error)s'),"
            },
            "239": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 359,
                "PatchRowcode": "+                            {'server': server, 'error': e.strerror})"
            },
            "240": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+"
            },
            "241": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 361,
                "PatchRowcode": "+        LOG.warning(_(\"Storing to certificate for host %(server)s \""
            },
            "242": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 362,
                "PatchRowcode": "+                      \"at %(path)s\") % {'server': server,"
            },
            "243": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+                                        'path': path})"
            },
            "244": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+        self._file_put_contents(path, cert)"
            },
            "245": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+"
            },
            "246": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+        return cert"
            },
            "247": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+"
            },
            "248": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 368,
                "PatchRowcode": "+    def _file_put_contents(path, contents):"
            },
            "249": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+        # Simple method to write to file."
            },
            "250": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+        # Created for easy Mocking"
            },
            "251": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+        with open(path, 'w') as handle:"
            },
            "252": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 372,
                "PatchRowcode": "+            handle.write(contents)"
            },
            "253": {
                "beforePatchRowNumber": 249,
                "afterPatchRowNumber": 373,
                "PatchRowcode": " "
            },
            "254": {
                "beforePatchRowNumber": 250,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "     def server_failure(self, resp, ignore_codes=[]):"
            },
            "255": {
                "beforePatchRowNumber": 251,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "         \"\"\"Define failure codes as required."
            },
            "256": {
                "beforePatchRowNumber": 264,
                "afterPatchRowNumber": 388,
                "PatchRowcode": " "
            },
            "257": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": 389,
                "PatchRowcode": "     @utils.synchronized('bsn-rest-call')"
            },
            "258": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": 390,
                "PatchRowcode": "     def rest_call(self, action, resource, data, headers, ignore_codes,"
            },
            "259": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                  timeout=None):"
            },
            "260": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 391,
                "PatchRowcode": "+                  timeout=False):"
            },
            "261": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": 392,
                "PatchRowcode": "         good_first = sorted(self.servers, key=lambda x: x.failed)"
            },
            "262": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": 393,
                "PatchRowcode": "         first_response = None"
            },
            "263": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": 394,
                "PatchRowcode": "         for active_server in good_first:"
            },
            "264": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": 395,
                "PatchRowcode": "             ret = active_server.rest_call(action, resource, data, headers,"
            },
            "265": {
                "beforePatchRowNumber": 272,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                          timeout)"
            },
            "266": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+                                          timeout,"
            },
            "267": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+                                          reconnect=self.always_reconnect)"
            },
            "268": {
                "beforePatchRowNumber": 273,
                "afterPatchRowNumber": 398,
                "PatchRowcode": "             # If inconsistent, do a full synchronization"
            },
            "269": {
                "beforePatchRowNumber": 274,
                "afterPatchRowNumber": 399,
                "PatchRowcode": "             if ret[0] == httplib.CONFLICT:"
            },
            "270": {
                "beforePatchRowNumber": 275,
                "afterPatchRowNumber": 400,
                "PatchRowcode": "                 if not self.get_topo_function:"
            },
            "271": {
                "beforePatchRowNumber": 309,
                "afterPatchRowNumber": 434,
                "PatchRowcode": "         return first_response"
            },
            "272": {
                "beforePatchRowNumber": 310,
                "afterPatchRowNumber": 435,
                "PatchRowcode": " "
            },
            "273": {
                "beforePatchRowNumber": 311,
                "afterPatchRowNumber": 436,
                "PatchRowcode": "     def rest_action(self, action, resource, data='', errstr='%s',"
            },
            "274": {
                "beforePatchRowNumber": 312,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    ignore_codes=[], headers={}, timeout=None):"
            },
            "275": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 437,
                "PatchRowcode": "+                    ignore_codes=[], headers={}, timeout=False):"
            },
            "276": {
                "beforePatchRowNumber": 313,
                "afterPatchRowNumber": 438,
                "PatchRowcode": "         \"\"\""
            },
            "277": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": 439,
                "PatchRowcode": "         Wrapper for rest_call that verifies success and raises a"
            },
            "278": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": 440,
                "PatchRowcode": "         RemoteRestError on failure with a provided error string"
            },
            "279": {
                "beforePatchRowNumber": 427,
                "afterPatchRowNumber": 552,
                "PatchRowcode": "             # that will be handled by the rest_call."
            },
            "280": {
                "beforePatchRowNumber": 428,
                "afterPatchRowNumber": 553,
                "PatchRowcode": "             time.sleep(polling_interval)"
            },
            "281": {
                "beforePatchRowNumber": 429,
                "afterPatchRowNumber": 554,
                "PatchRowcode": "             self.servers.rest_call('GET', HEALTH_PATH)"
            },
            "282": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 555,
                "PatchRowcode": "+"
            },
            "283": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 556,
                "PatchRowcode": "+"
            },
            "284": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 557,
                "PatchRowcode": "+class HTTPSConnectionWithValidation(httplib.HTTPSConnection):"
            },
            "285": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 558,
                "PatchRowcode": "+"
            },
            "286": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 559,
                "PatchRowcode": "+    # If combined_cert is None, the connection will continue without"
            },
            "287": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 560,
                "PatchRowcode": "+    # any certificate validation."
            },
            "288": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 561,
                "PatchRowcode": "+    combined_cert = None"
            },
            "289": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 562,
                "PatchRowcode": "+"
            },
            "290": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 563,
                "PatchRowcode": "+    def connect(self):"
            },
            "291": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 564,
                "PatchRowcode": "+        sock = socket.create_connection((self.host, self.port),"
            },
            "292": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 565,
                "PatchRowcode": "+                                        self.timeout, self.source_address)"
            },
            "293": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 566,
                "PatchRowcode": "+        if self._tunnel_host:"
            },
            "294": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 567,
                "PatchRowcode": "+            self.sock = sock"
            },
            "295": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 568,
                "PatchRowcode": "+            self._tunnel()"
            },
            "296": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 569,
                "PatchRowcode": "+"
            },
            "297": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 570,
                "PatchRowcode": "+        if self.combined_cert:"
            },
            "298": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 571,
                "PatchRowcode": "+            self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,"
            },
            "299": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 572,
                "PatchRowcode": "+                                        cert_reqs=ssl.CERT_REQUIRED,"
            },
            "300": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 573,
                "PatchRowcode": "+                                        ca_certs=self.combined_cert)"
            },
            "301": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 574,
                "PatchRowcode": "+        else:"
            },
            "302": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 575,
                "PatchRowcode": "+            self.sock = ssl.wrap_socket(sock, self.key_file,"
            },
            "303": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 576,
                "PatchRowcode": "+                                        self.cert_file,"
            },
            "304": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 577,
                "PatchRowcode": "+                                        cert_reqs=ssl.CERT_NONE)"
            }
        },
        "frontPatchFile": [
            "# vim: tabstop=4 shiftwidth=4 softtabstop=4",
            "# Copyright 2014 Big Switch Networks, Inc.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "#",
            "# @author: Mandeep Dhami, Big Switch Networks, Inc.",
            "# @author: Sumit Naiksatam, sumitnaiksatam@gmail.com, Big Switch Networks, Inc.",
            "# @author: Kevin Benton, Big Switch Networks, Inc.",
            "",
            "\"\"\"",
            "This module manages the HTTP and HTTPS connections to the backend controllers.",
            "",
            "The main class it provides for external use is ServerPool which manages a set",
            "of ServerProxy objects that correspond to individual backend controllers.",
            "",
            "The following functionality is handled by this module:",
            "- Translation of rest_* function calls to HTTP/HTTPS calls to the controllers",
            "- Automatic failover between controllers",
            "- HTTP Authentication",
            "",
            "\"\"\"",
            "import base64",
            "import httplib",
            "import json",
            "import socket",
            "import time",
            "",
            "import eventlet",
            "from oslo.config import cfg",
            "",
            "from neutron.common import exceptions",
            "from neutron.common import utils",
            "from neutron.openstack.common import log as logging",
            "from neutron.plugins.bigswitch.db import consistency_db as cdb",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "# The following are used to invoke the API on the external controller",
            "CAPABILITIES_PATH = \"/capabilities\"",
            "NET_RESOURCE_PATH = \"/tenants/%s/networks\"",
            "PORT_RESOURCE_PATH = \"/tenants/%s/networks/%s/ports\"",
            "ROUTER_RESOURCE_PATH = \"/tenants/%s/routers\"",
            "ROUTER_INTF_OP_PATH = \"/tenants/%s/routers/%s/interfaces\"",
            "NETWORKS_PATH = \"/tenants/%s/networks/%s\"",
            "FLOATINGIPS_PATH = \"/tenants/%s/floatingips/%s\"",
            "PORTS_PATH = \"/tenants/%s/networks/%s/ports/%s\"",
            "ATTACHMENT_PATH = \"/tenants/%s/networks/%s/ports/%s/attachment\"",
            "ROUTERS_PATH = \"/tenants/%s/routers/%s\"",
            "ROUTER_INTF_PATH = \"/tenants/%s/routers/%s/interfaces/%s\"",
            "TOPOLOGY_PATH = \"/topology\"",
            "HEALTH_PATH = \"/health\"",
            "SUCCESS_CODES = range(200, 207)",
            "FAILURE_CODES = [0, 301, 302, 303, 400, 401, 403, 404, 500, 501, 502, 503,",
            "                 504, 505]",
            "BASE_URI = '/networkService/v1.1'",
            "ORCHESTRATION_SERVICE_ID = 'Neutron v2.0'",
            "HASH_MATCH_HEADER = 'X-BSN-BVS-HASH-MATCH'",
            "# error messages",
            "NXNETWORK = 'NXVNS'",
            "",
            "",
            "class RemoteRestError(exceptions.NeutronException):",
            "    message = _(\"Error in REST call to remote network \"",
            "                \"controller: %(reason)s\")",
            "    status = None",
            "",
            "    def __init__(self, **kwargs):",
            "        self.status = kwargs.pop('status', None)",
            "        self.reason = kwargs.get('reason')",
            "        super(RemoteRestError, self).__init__(**kwargs)",
            "",
            "",
            "class ServerProxy(object):",
            "    \"\"\"REST server proxy to a network controller.\"\"\"",
            "",
            "    def __init__(self, server, port, ssl, auth, neutron_id, timeout,",
            "                 base_uri, name, mypool):",
            "        self.server = server",
            "        self.port = port",
            "        self.ssl = ssl",
            "        self.base_uri = base_uri",
            "        self.timeout = timeout",
            "        self.name = name",
            "        self.success_codes = SUCCESS_CODES",
            "        self.auth = None",
            "        self.neutron_id = neutron_id",
            "        self.failed = False",
            "        self.capabilities = []",
            "        # enable server to reference parent pool",
            "        self.mypool = mypool",
            "        if auth:",
            "            self.auth = 'Basic ' + base64.encodestring(auth).strip()",
            "",
            "    def get_capabilities(self):",
            "        try:",
            "            body = self.rest_call('GET', CAPABILITIES_PATH)[3]",
            "            self.capabilities = json.loads(body)",
            "        except Exception:",
            "            LOG.error(_(\"Couldn't retrieve capabilities. \"",
            "                        \"Newer API calls won't be supported.\"))",
            "        LOG.info(_(\"The following capabilities were received \"",
            "                   \"for %(server)s: %(cap)s\"), {'server': self.server,",
            "                                                'cap': self.capabilities})",
            "        return self.capabilities",
            "",
            "    def rest_call(self, action, resource, data='', headers={}, timeout=None):",
            "        uri = self.base_uri + resource",
            "        body = json.dumps(data)",
            "        if not headers:",
            "            headers = {}",
            "        headers['Content-type'] = 'application/json'",
            "        headers['Accept'] = 'application/json'",
            "        headers['NeutronProxy-Agent'] = self.name",
            "        headers['Instance-ID'] = self.neutron_id",
            "        headers['Orchestration-Service-ID'] = ORCHESTRATION_SERVICE_ID",
            "        headers[HASH_MATCH_HEADER] = self.mypool.consistency_hash",
            "        if self.auth:",
            "            headers['Authorization'] = self.auth",
            "",
            "        LOG.debug(_(\"ServerProxy: server=%(server)s, port=%(port)d, \"",
            "                    \"ssl=%(ssl)r\"),",
            "                  {'server': self.server, 'port': self.port, 'ssl': self.ssl})",
            "        LOG.debug(_(\"ServerProxy: resource=%(resource)s, data=%(data)r, \"",
            "                    \"headers=%(headers)r, action=%(action)s\"),",
            "                  {'resource': resource, 'data': data, 'headers': headers,",
            "                   'action': action})",
            "",
            "        conn = None",
            "        timeout = timeout or self.timeout",
            "        if self.ssl:",
            "            conn = httplib.HTTPSConnection(",
            "                self.server, self.port, timeout=timeout)",
            "            if conn is None:",
            "                LOG.error(_('ServerProxy: Could not establish HTTPS '",
            "                            'connection'))",
            "                return 0, None, None, None",
            "        else:",
            "            conn = httplib.HTTPConnection(",
            "                self.server, self.port, timeout=timeout)",
            "            if conn is None:",
            "                LOG.error(_('ServerProxy: Could not establish HTTP '",
            "                            'connection'))",
            "                return 0, None, None, None",
            "",
            "        try:",
            "            conn.request(action, uri, body, headers)",
            "            response = conn.getresponse()",
            "            newhash = response.getheader(HASH_MATCH_HEADER)",
            "            if newhash:",
            "                self._put_consistency_hash(newhash)",
            "            respstr = response.read()",
            "            respdata = respstr",
            "            if response.status in self.success_codes:",
            "                try:",
            "                    respdata = json.loads(respstr)",
            "                except ValueError:",
            "                    # response was not JSON, ignore the exception",
            "                    pass",
            "            ret = (response.status, response.reason, respstr, respdata)",
            "        except (socket.timeout, socket.error) as e:",
            "            LOG.error(_('ServerProxy: %(action)s failure, %(e)r'),",
            "                      {'action': action, 'e': e})",
            "            ret = 0, None, None, None",
            "        conn.close()",
            "        LOG.debug(_(\"ServerProxy: status=%(status)d, reason=%(reason)r, \"",
            "                    \"ret=%(ret)s, data=%(data)r\"), {'status': ret[0],",
            "                                                    'reason': ret[1],",
            "                                                    'ret': ret[2],",
            "                                                    'data': ret[3]})",
            "        return ret",
            "",
            "    def _put_consistency_hash(self, newhash):",
            "        self.mypool.consistency_hash = newhash",
            "        cdb.put_consistency_hash(newhash)",
            "",
            "",
            "class ServerPool(object):",
            "",
            "    def __init__(self, timeout=10,",
            "                 base_uri=BASE_URI, name='NeutronRestProxy'):",
            "        LOG.debug(_(\"ServerPool: initializing\"))",
            "        # 'servers' is the list of network controller REST end-points",
            "        # (used in order specified till one succeeds, and it is sticky",
            "        # till next failure). Use 'server_auth' to encode api-key",
            "        servers = cfg.CONF.RESTPROXY.servers",
            "        self.auth = cfg.CONF.RESTPROXY.server_auth",
            "        self.ssl = cfg.CONF.RESTPROXY.server_ssl",
            "        self.neutron_id = cfg.CONF.RESTPROXY.neutron_id",
            "        self.base_uri = base_uri",
            "        self.name = name",
            "        self.timeout = cfg.CONF.RESTPROXY.server_timeout",
            "        default_port = 8000",
            "        if timeout is not None:",
            "            self.timeout = timeout",
            "",
            "        # Function to use to retrieve topology for consistency syncs.",
            "        # Needs to be set by module that uses the servermanager.",
            "        self.get_topo_function = None",
            "        self.get_topo_function_args = {}",
            "",
            "        # Hash to send to backend with request as expected previous",
            "        # state to verify consistency.",
            "        self.consistency_hash = cdb.get_consistency_hash()",
            "        eventlet.spawn(self._consistency_watchdog,",
            "                       cfg.CONF.RESTPROXY.consistency_interval)",
            "",
            "        if not servers:",
            "            raise cfg.Error(_('Servers not defined. Aborting server manager.'))",
            "        servers = [s if len(s.rsplit(':', 1)) == 2",
            "                   else \"%s:%d\" % (s, default_port)",
            "                   for s in servers]",
            "        if any((len(spl) != 2)for spl in [sp.rsplit(':', 1)",
            "                                          for sp in servers]):",
            "            raise cfg.Error(_('Servers must be defined as <ip>:<port>. '",
            "                              'Configuration was %s') % servers)",
            "        self.servers = [",
            "            self.server_proxy_for(server, int(port))",
            "            for server, port in (s.rsplit(':', 1) for s in servers)",
            "        ]",
            "        LOG.debug(_(\"ServerPool: initialization done\"))",
            "",
            "    def get_capabilities(self):",
            "        # lookup on first try",
            "        try:",
            "            return self.capabilities",
            "        except AttributeError:",
            "            # each server should return a list of capabilities it supports",
            "            # e.g. ['floatingip']",
            "            capabilities = [set(server.get_capabilities())",
            "                            for server in self.servers]",
            "            # Pool only supports what all of the servers support",
            "            self.capabilities = set.intersection(*capabilities)",
            "            return self.capabilities",
            "",
            "    def server_proxy_for(self, server, port):",
            "        return ServerProxy(server, port, self.ssl, self.auth, self.neutron_id,",
            "                           self.timeout, self.base_uri, self.name, mypool=self)",
            "",
            "    def server_failure(self, resp, ignore_codes=[]):",
            "        \"\"\"Define failure codes as required.",
            "",
            "        Note: We assume 301-303 is a failure, and try the next server in",
            "        the server pool.",
            "        \"\"\"",
            "        return (resp[0] in FAILURE_CODES and resp[0] not in ignore_codes)",
            "",
            "    def action_success(self, resp):",
            "        \"\"\"Defining success codes as required.",
            "",
            "        Note: We assume any valid 2xx as being successful response.",
            "        \"\"\"",
            "        return resp[0] in SUCCESS_CODES",
            "",
            "    @utils.synchronized('bsn-rest-call')",
            "    def rest_call(self, action, resource, data, headers, ignore_codes,",
            "                  timeout=None):",
            "        good_first = sorted(self.servers, key=lambda x: x.failed)",
            "        first_response = None",
            "        for active_server in good_first:",
            "            ret = active_server.rest_call(action, resource, data, headers,",
            "                                          timeout)",
            "            # If inconsistent, do a full synchronization",
            "            if ret[0] == httplib.CONFLICT:",
            "                if not self.get_topo_function:",
            "                    raise cfg.Error(_('Server requires synchronization, '",
            "                                      'but no topology function was defined.'))",
            "                data = self.get_topo_function(**self.get_topo_function_args)",
            "                active_server.rest_call('PUT', TOPOLOGY_PATH, data,",
            "                                        timeout=None)",
            "            # Store the first response as the error to be bubbled up to the",
            "            # user since it was a good server. Subsequent servers will most",
            "            # likely be cluster slaves and won't have a useful error for the",
            "            # user (e.g. 302 redirect to master)",
            "            if not first_response:",
            "                first_response = ret",
            "            if not self.server_failure(ret, ignore_codes):",
            "                active_server.failed = False",
            "                return ret",
            "            else:",
            "                LOG.error(_('ServerProxy: %(action)s failure for servers: '",
            "                            '%(server)r Response: %(response)s'),",
            "                          {'action': action,",
            "                           'server': (active_server.server,",
            "                                      active_server.port),",
            "                           'response': ret[3]})",
            "                LOG.error(_(\"ServerProxy: Error details: status=%(status)d, \"",
            "                            \"reason=%(reason)r, ret=%(ret)s, data=%(data)r\"),",
            "                          {'status': ret[0], 'reason': ret[1], 'ret': ret[2],",
            "                           'data': ret[3]})",
            "                active_server.failed = True",
            "",
            "        # All servers failed, reset server list and try again next time",
            "        LOG.error(_('ServerProxy: %(action)s failure for all servers: '",
            "                    '%(server)r'),",
            "                  {'action': action,",
            "                   'server': tuple((s.server,",
            "                                    s.port) for s in self.servers)})",
            "        return first_response",
            "",
            "    def rest_action(self, action, resource, data='', errstr='%s',",
            "                    ignore_codes=[], headers={}, timeout=None):",
            "        \"\"\"",
            "        Wrapper for rest_call that verifies success and raises a",
            "        RemoteRestError on failure with a provided error string",
            "        By default, 404 errors on DELETE calls are ignored because",
            "        they already do not exist on the backend.",
            "        \"\"\"",
            "        if not ignore_codes and action == 'DELETE':",
            "            ignore_codes = [404]",
            "        resp = self.rest_call(action, resource, data, headers, ignore_codes,",
            "                              timeout)",
            "        if self.server_failure(resp, ignore_codes):",
            "            LOG.error(errstr, resp[2])",
            "            raise RemoteRestError(reason=resp[2], status=resp[0])",
            "        if resp[0] in ignore_codes:",
            "            LOG.warning(_(\"NeutronRestProxyV2: Received and ignored error \"",
            "                          \"code %(code)s on %(action)s action to resource \"",
            "                          \"%(resource)s\"),",
            "                        {'code': resp[2], 'action': action,",
            "                         'resource': resource})",
            "        return resp",
            "",
            "    def rest_create_router(self, tenant_id, router):",
            "        resource = ROUTER_RESOURCE_PATH % tenant_id",
            "        data = {\"router\": router}",
            "        errstr = _(\"Unable to create remote router: %s\")",
            "        self.rest_action('POST', resource, data, errstr)",
            "",
            "    def rest_update_router(self, tenant_id, router, router_id):",
            "        resource = ROUTERS_PATH % (tenant_id, router_id)",
            "        data = {\"router\": router}",
            "        errstr = _(\"Unable to update remote router: %s\")",
            "        self.rest_action('PUT', resource, data, errstr)",
            "",
            "    def rest_delete_router(self, tenant_id, router_id):",
            "        resource = ROUTERS_PATH % (tenant_id, router_id)",
            "        errstr = _(\"Unable to delete remote router: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_add_router_interface(self, tenant_id, router_id, intf_details):",
            "        resource = ROUTER_INTF_OP_PATH % (tenant_id, router_id)",
            "        data = {\"interface\": intf_details}",
            "        errstr = _(\"Unable to add router interface: %s\")",
            "        self.rest_action('POST', resource, data, errstr)",
            "",
            "    def rest_remove_router_interface(self, tenant_id, router_id, interface_id):",
            "        resource = ROUTER_INTF_PATH % (tenant_id, router_id, interface_id)",
            "        errstr = _(\"Unable to delete remote intf: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_create_network(self, tenant_id, network):",
            "        resource = NET_RESOURCE_PATH % tenant_id",
            "        data = {\"network\": network}",
            "        errstr = _(\"Unable to create remote network: %s\")",
            "        self.rest_action('POST', resource, data, errstr)",
            "",
            "    def rest_update_network(self, tenant_id, net_id, network):",
            "        resource = NETWORKS_PATH % (tenant_id, net_id)",
            "        data = {\"network\": network}",
            "        errstr = _(\"Unable to update remote network: %s\")",
            "        self.rest_action('PUT', resource, data, errstr)",
            "",
            "    def rest_delete_network(self, tenant_id, net_id):",
            "        resource = NETWORKS_PATH % (tenant_id, net_id)",
            "        errstr = _(\"Unable to update remote network: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_create_port(self, tenant_id, net_id, port):",
            "        resource = ATTACHMENT_PATH % (tenant_id, net_id, port[\"id\"])",
            "        data = {\"port\": port}",
            "        device_id = port.get(\"device_id\")",
            "        if not port[\"mac_address\"] or not device_id:",
            "            # controller only cares about ports attached to devices",
            "            LOG.warning(_(\"No device MAC attached to port %s. \"",
            "                          \"Skipping notification to controller.\"), port[\"id\"])",
            "            return",
            "        data[\"attachment\"] = {\"id\": device_id,",
            "                              \"mac\": port[\"mac_address\"]}",
            "        errstr = _(\"Unable to create remote port: %s\")",
            "        self.rest_action('PUT', resource, data, errstr)",
            "",
            "    def rest_delete_port(self, tenant_id, network_id, port_id):",
            "        resource = ATTACHMENT_PATH % (tenant_id, network_id, port_id)",
            "        errstr = _(\"Unable to delete remote port: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_update_port(self, tenant_id, net_id, port):",
            "        # Controller has no update operation for the port endpoint",
            "        # the create PUT method will replace",
            "        self.rest_create_port(tenant_id, net_id, port)",
            "",
            "    def rest_create_floatingip(self, tenant_id, floatingip):",
            "        resource = FLOATINGIPS_PATH % (tenant_id, floatingip['id'])",
            "        errstr = _(\"Unable to create floating IP: %s\")",
            "        self.rest_action('PUT', resource, errstr=errstr)",
            "",
            "    def rest_update_floatingip(self, tenant_id, floatingip, oldid):",
            "        resource = FLOATINGIPS_PATH % (tenant_id, oldid)",
            "        errstr = _(\"Unable to update floating IP: %s\")",
            "        self.rest_action('PUT', resource, errstr=errstr)",
            "",
            "    def rest_delete_floatingip(self, tenant_id, oldid):",
            "        resource = FLOATINGIPS_PATH % (tenant_id, oldid)",
            "        errstr = _(\"Unable to delete floating IP: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def _consistency_watchdog(self, polling_interval=60):",
            "        if 'consistency' not in self.get_capabilities():",
            "            LOG.warning(_(\"Backend server(s) do not support automated \"",
            "                          \"consitency checks.\"))",
            "            return",
            "        while True:",
            "            # If consistency is supported, all we have to do is make any",
            "            # rest call and the consistency header will be added. If it",
            "            # doesn't match, the backend will return a synchronization error",
            "            # that will be handled by the rest_call.",
            "            time.sleep(polling_interval)",
            "            self.servers.rest_call('GET', HEALTH_PATH)"
        ],
        "afterPatchFile": [
            "# vim: tabstop=4 shiftwidth=4 softtabstop=4",
            "# Copyright 2014 Big Switch Networks, Inc.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "#",
            "# @author: Mandeep Dhami, Big Switch Networks, Inc.",
            "# @author: Sumit Naiksatam, sumitnaiksatam@gmail.com, Big Switch Networks, Inc.",
            "# @author: Kevin Benton, Big Switch Networks, Inc.",
            "",
            "\"\"\"",
            "This module manages the HTTP and HTTPS connections to the backend controllers.",
            "",
            "The main class it provides for external use is ServerPool which manages a set",
            "of ServerProxy objects that correspond to individual backend controllers.",
            "",
            "The following functionality is handled by this module:",
            "- Translation of rest_* function calls to HTTP/HTTPS calls to the controllers",
            "- Automatic failover between controllers",
            "- SSL Certificate enforcement",
            "- HTTP Authentication",
            "",
            "\"\"\"",
            "import base64",
            "import httplib",
            "import json",
            "import os",
            "import socket",
            "import ssl",
            "import time",
            "",
            "import eventlet",
            "from oslo.config import cfg",
            "",
            "from neutron.common import exceptions",
            "from neutron.common import utils",
            "from neutron.openstack.common import excutils",
            "from neutron.openstack.common import log as logging",
            "from neutron.plugins.bigswitch.db import consistency_db as cdb",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "# The following are used to invoke the API on the external controller",
            "CAPABILITIES_PATH = \"/capabilities\"",
            "NET_RESOURCE_PATH = \"/tenants/%s/networks\"",
            "PORT_RESOURCE_PATH = \"/tenants/%s/networks/%s/ports\"",
            "ROUTER_RESOURCE_PATH = \"/tenants/%s/routers\"",
            "ROUTER_INTF_OP_PATH = \"/tenants/%s/routers/%s/interfaces\"",
            "NETWORKS_PATH = \"/tenants/%s/networks/%s\"",
            "FLOATINGIPS_PATH = \"/tenants/%s/floatingips/%s\"",
            "PORTS_PATH = \"/tenants/%s/networks/%s/ports/%s\"",
            "ATTACHMENT_PATH = \"/tenants/%s/networks/%s/ports/%s/attachment\"",
            "ROUTERS_PATH = \"/tenants/%s/routers/%s\"",
            "ROUTER_INTF_PATH = \"/tenants/%s/routers/%s/interfaces/%s\"",
            "TOPOLOGY_PATH = \"/topology\"",
            "HEALTH_PATH = \"/health\"",
            "SUCCESS_CODES = range(200, 207)",
            "FAILURE_CODES = [0, 301, 302, 303, 400, 401, 403, 404, 500, 501, 502, 503,",
            "                 504, 505]",
            "BASE_URI = '/networkService/v1.1'",
            "ORCHESTRATION_SERVICE_ID = 'Neutron v2.0'",
            "HASH_MATCH_HEADER = 'X-BSN-BVS-HASH-MATCH'",
            "# error messages",
            "NXNETWORK = 'NXVNS'",
            "",
            "",
            "class RemoteRestError(exceptions.NeutronException):",
            "    message = _(\"Error in REST call to remote network \"",
            "                \"controller: %(reason)s\")",
            "    status = None",
            "",
            "    def __init__(self, **kwargs):",
            "        self.status = kwargs.pop('status', None)",
            "        self.reason = kwargs.get('reason')",
            "        super(RemoteRestError, self).__init__(**kwargs)",
            "",
            "",
            "class ServerProxy(object):",
            "    \"\"\"REST server proxy to a network controller.\"\"\"",
            "",
            "    def __init__(self, server, port, ssl, auth, neutron_id, timeout,",
            "                 base_uri, name, mypool, combined_cert):",
            "        self.server = server",
            "        self.port = port",
            "        self.ssl = ssl",
            "        self.base_uri = base_uri",
            "        self.timeout = timeout",
            "        self.name = name",
            "        self.success_codes = SUCCESS_CODES",
            "        self.auth = None",
            "        self.neutron_id = neutron_id",
            "        self.failed = False",
            "        self.capabilities = []",
            "        # enable server to reference parent pool",
            "        self.mypool = mypool",
            "        # cache connection here to avoid a SSL handshake for every connection",
            "        self.currentconn = None",
            "        if auth:",
            "            self.auth = 'Basic ' + base64.encodestring(auth).strip()",
            "        self.combined_cert = combined_cert",
            "",
            "    def get_capabilities(self):",
            "        try:",
            "            body = self.rest_call('GET', CAPABILITIES_PATH)[3]",
            "            self.capabilities = json.loads(body)",
            "        except Exception:",
            "            LOG.error(_(\"Couldn't retrieve capabilities. \"",
            "                        \"Newer API calls won't be supported.\"))",
            "        LOG.info(_(\"The following capabilities were received \"",
            "                   \"for %(server)s: %(cap)s\"), {'server': self.server,",
            "                                                'cap': self.capabilities})",
            "        return self.capabilities",
            "",
            "    def rest_call(self, action, resource, data='', headers={}, timeout=False,",
            "                  reconnect=False):",
            "        uri = self.base_uri + resource",
            "        body = json.dumps(data)",
            "        if not headers:",
            "            headers = {}",
            "        headers['Content-type'] = 'application/json'",
            "        headers['Accept'] = 'application/json'",
            "        headers['NeutronProxy-Agent'] = self.name",
            "        headers['Instance-ID'] = self.neutron_id",
            "        headers['Orchestration-Service-ID'] = ORCHESTRATION_SERVICE_ID",
            "        headers[HASH_MATCH_HEADER] = self.mypool.consistency_hash",
            "        if 'keep-alive' in self.capabilities:",
            "            headers['Connection'] = 'keep-alive'",
            "        else:",
            "            reconnect = True",
            "        if self.auth:",
            "            headers['Authorization'] = self.auth",
            "",
            "        LOG.debug(_(\"ServerProxy: server=%(server)s, port=%(port)d, \"",
            "                    \"ssl=%(ssl)r\"),",
            "                  {'server': self.server, 'port': self.port, 'ssl': self.ssl})",
            "        LOG.debug(_(\"ServerProxy: resource=%(resource)s, data=%(data)r, \"",
            "                    \"headers=%(headers)r, action=%(action)s\"),",
            "                  {'resource': resource, 'data': data, 'headers': headers,",
            "                   'action': action})",
            "",
            "        # unspecified timeout is False because a timeout can be specified as",
            "        # None to indicate no timeout.",
            "        if timeout is False:",
            "            timeout = self.timeout",
            "",
            "        if timeout != self.timeout:",
            "            # need a new connection if timeout has changed",
            "            reconnect = True",
            "",
            "        if not self.currentconn or reconnect:",
            "            if self.currentconn:",
            "                self.currentconn.close()",
            "            if self.ssl:",
            "                self.currentconn = HTTPSConnectionWithValidation(",
            "                    self.server, self.port, timeout=timeout)",
            "                self.currentconn.combined_cert = self.combined_cert",
            "                if self.currentconn is None:",
            "                    LOG.error(_('ServerProxy: Could not establish HTTPS '",
            "                                'connection'))",
            "                    return 0, None, None, None",
            "            else:",
            "                self.currentconn = httplib.HTTPConnection(",
            "                    self.server, self.port, timeout=timeout)",
            "                if self.currentconn is None:",
            "                    LOG.error(_('ServerProxy: Could not establish HTTP '",
            "                                'connection'))",
            "                    return 0, None, None, None",
            "",
            "        try:",
            "            self.currentconn.request(action, uri, body, headers)",
            "            response = self.currentconn.getresponse()",
            "            newhash = response.getheader(HASH_MATCH_HEADER)",
            "            if newhash:",
            "                self._put_consistency_hash(newhash)",
            "            respstr = response.read()",
            "            respdata = respstr",
            "            if response.status in self.success_codes:",
            "                try:",
            "                    respdata = json.loads(respstr)",
            "                except ValueError:",
            "                    # response was not JSON, ignore the exception",
            "                    pass",
            "            ret = (response.status, response.reason, respstr, respdata)",
            "        except httplib.ImproperConnectionState:",
            "            # If we were using a cached connection, try again with a new one.",
            "            with excutils.save_and_reraise_exception() as ctxt:",
            "                if not reconnect:",
            "                    ctxt.reraise = False",
            "",
            "            if self.currentconn:",
            "                self.currentconn.close()",
            "            return self.rest_call(action, resource, data, headers,",
            "                                  timeout=timeout, reconnect=True)",
            "        except (socket.timeout, socket.error) as e:",
            "            LOG.error(_('ServerProxy: %(action)s failure, %(e)r'),",
            "                      {'action': action, 'e': e})",
            "            ret = 0, None, None, None",
            "        LOG.debug(_(\"ServerProxy: status=%(status)d, reason=%(reason)r, \"",
            "                    \"ret=%(ret)s, data=%(data)r\"), {'status': ret[0],",
            "                                                    'reason': ret[1],",
            "                                                    'ret': ret[2],",
            "                                                    'data': ret[3]})",
            "        return ret",
            "",
            "    def _put_consistency_hash(self, newhash):",
            "        self.mypool.consistency_hash = newhash",
            "        cdb.put_consistency_hash(newhash)",
            "",
            "",
            "class ServerPool(object):",
            "",
            "    def __init__(self, timeout=False,",
            "                 base_uri=BASE_URI, name='NeutronRestProxy'):",
            "        LOG.debug(_(\"ServerPool: initializing\"))",
            "        # 'servers' is the list of network controller REST end-points",
            "        # (used in order specified till one succeeds, and it is sticky",
            "        # till next failure). Use 'server_auth' to encode api-key",
            "        servers = cfg.CONF.RESTPROXY.servers",
            "        self.auth = cfg.CONF.RESTPROXY.server_auth",
            "        self.ssl = cfg.CONF.RESTPROXY.server_ssl",
            "        self.neutron_id = cfg.CONF.RESTPROXY.neutron_id",
            "        self.base_uri = base_uri",
            "        self.name = name",
            "        self.timeout = cfg.CONF.RESTPROXY.server_timeout",
            "        self.always_reconnect = not cfg.CONF.RESTPROXY.cache_connections",
            "        default_port = 8000",
            "        if timeout is not False:",
            "            self.timeout = timeout",
            "",
            "        # Function to use to retrieve topology for consistency syncs.",
            "        # Needs to be set by module that uses the servermanager.",
            "        self.get_topo_function = None",
            "        self.get_topo_function_args = {}",
            "",
            "        # Hash to send to backend with request as expected previous",
            "        # state to verify consistency.",
            "        self.consistency_hash = cdb.get_consistency_hash()",
            "        eventlet.spawn(self._consistency_watchdog,",
            "                       cfg.CONF.RESTPROXY.consistency_interval)",
            "",
            "        if not servers:",
            "            raise cfg.Error(_('Servers not defined. Aborting server manager.'))",
            "        servers = [s if len(s.rsplit(':', 1)) == 2",
            "                   else \"%s:%d\" % (s, default_port)",
            "                   for s in servers]",
            "        if any((len(spl) != 2)for spl in [sp.rsplit(':', 1)",
            "                                          for sp in servers]):",
            "            raise cfg.Error(_('Servers must be defined as <ip>:<port>. '",
            "                              'Configuration was %s') % servers)",
            "        self.servers = [",
            "            self.server_proxy_for(server, int(port))",
            "            for server, port in (s.rsplit(':', 1) for s in servers)",
            "        ]",
            "        LOG.debug(_(\"ServerPool: initialization done\"))",
            "",
            "    def get_capabilities(self):",
            "        # lookup on first try",
            "        try:",
            "            return self.capabilities",
            "        except AttributeError:",
            "            # each server should return a list of capabilities it supports",
            "            # e.g. ['floatingip']",
            "            capabilities = [set(server.get_capabilities())",
            "                            for server in self.servers]",
            "            # Pool only supports what all of the servers support",
            "            self.capabilities = set.intersection(*capabilities)",
            "            return self.capabilities",
            "",
            "    def server_proxy_for(self, server, port):",
            "        combined_cert = self._get_combined_cert_for_server(server, port)",
            "        return ServerProxy(server, port, self.ssl, self.auth, self.neutron_id,",
            "                           self.timeout, self.base_uri, self.name, mypool=self,",
            "                           combined_cert=combined_cert)",
            "",
            "    def _get_combined_cert_for_server(self, server, port):",
            "        # The ssl library requires a combined file with all trusted certs",
            "        # so we make one containing the trusted CAs and the corresponding",
            "        # host cert for this server",
            "        combined_cert = None",
            "        if self.ssl and not cfg.CONF.RESTPROXY.no_ssl_validation:",
            "            base_ssl = cfg.CONF.RESTPROXY.ssl_cert_directory",
            "            host_dir = os.path.join(base_ssl, 'host_certs')",
            "            ca_dir = os.path.join(base_ssl, 'ca_certs')",
            "            combined_dir = os.path.join(base_ssl, 'combined')",
            "            combined_cert = os.path.join(combined_dir, '%s.pem' % server)",
            "            if not os.path.exists(base_ssl):",
            "                raise cfg.Error(_('ssl_cert_directory [%s] does not exist. '",
            "                                  'Create it or disable ssl.') % base_ssl)",
            "            for automake in [combined_dir, ca_dir, host_dir]:",
            "                if not os.path.exists(automake):",
            "                    os.makedirs(automake)",
            "",
            "            # get all CA certs",
            "            certs = self._get_ca_cert_paths(ca_dir)",
            "",
            "            # check for a host specific cert",
            "            hcert, exists = self._get_host_cert_path(host_dir, server)",
            "            if exists:",
            "                certs.append(hcert)",
            "            elif cfg.CONF.RESTPROXY.ssl_sticky:",
            "                self._fetch_and_store_cert(server, port, hcert)",
            "                certs.append(hcert)",
            "            if not certs:",
            "                raise cfg.Error(_('No certificates were found to verify '",
            "                                  'controller %s') % (server))",
            "            self._combine_certs_to_file(certs, combined_cert)",
            "        return combined_cert",
            "",
            "    def _combine_certs_to_file(certs, cfile):",
            "        '''",
            "        Concatenates the contents of each certificate in a list of",
            "        certificate paths to one combined location for use with ssl",
            "        sockets.",
            "        '''",
            "        with open(cfile, 'w') as combined:",
            "            for c in certs:",
            "                with open(c, 'r') as cert_handle:",
            "                    combined.write(cert_handle.read())",
            "",
            "    def _get_host_cert_path(self, host_dir, server):",
            "        '''",
            "        returns full path and boolean indicating existence",
            "        '''",
            "        hcert = os.path.join(host_dir, '%s.pem' % server)",
            "        if os.path.exists(hcert):",
            "            return hcert, True",
            "        return hcert, False",
            "",
            "    def _get_ca_cert_paths(self, ca_dir):",
            "        certs = [os.path.join(root, name)",
            "                 for name in [",
            "                     name for (root, dirs, files) in os.walk(ca_dir)",
            "                     for name in files",
            "                 ]",
            "                 if name.endswith('.pem')]",
            "        return certs",
            "",
            "    def _fetch_and_store_cert(self, server, port, path):",
            "        '''",
            "        Grabs a certificate from a server and writes it to",
            "        a given path.",
            "        '''",
            "        try:",
            "            cert = ssl.get_server_certificate((server, port))",
            "        except Exception as e:",
            "            raise cfg.Error(_('Could not retrieve initial '",
            "                              'certificate from controller %(server)s. '",
            "                              'Error details: %(error)s'),",
            "                            {'server': server, 'error': e.strerror})",
            "",
            "        LOG.warning(_(\"Storing to certificate for host %(server)s \"",
            "                      \"at %(path)s\") % {'server': server,",
            "                                        'path': path})",
            "        self._file_put_contents(path, cert)",
            "",
            "        return cert",
            "",
            "    def _file_put_contents(path, contents):",
            "        # Simple method to write to file.",
            "        # Created for easy Mocking",
            "        with open(path, 'w') as handle:",
            "            handle.write(contents)",
            "",
            "    def server_failure(self, resp, ignore_codes=[]):",
            "        \"\"\"Define failure codes as required.",
            "",
            "        Note: We assume 301-303 is a failure, and try the next server in",
            "        the server pool.",
            "        \"\"\"",
            "        return (resp[0] in FAILURE_CODES and resp[0] not in ignore_codes)",
            "",
            "    def action_success(self, resp):",
            "        \"\"\"Defining success codes as required.",
            "",
            "        Note: We assume any valid 2xx as being successful response.",
            "        \"\"\"",
            "        return resp[0] in SUCCESS_CODES",
            "",
            "    @utils.synchronized('bsn-rest-call')",
            "    def rest_call(self, action, resource, data, headers, ignore_codes,",
            "                  timeout=False):",
            "        good_first = sorted(self.servers, key=lambda x: x.failed)",
            "        first_response = None",
            "        for active_server in good_first:",
            "            ret = active_server.rest_call(action, resource, data, headers,",
            "                                          timeout,",
            "                                          reconnect=self.always_reconnect)",
            "            # If inconsistent, do a full synchronization",
            "            if ret[0] == httplib.CONFLICT:",
            "                if not self.get_topo_function:",
            "                    raise cfg.Error(_('Server requires synchronization, '",
            "                                      'but no topology function was defined.'))",
            "                data = self.get_topo_function(**self.get_topo_function_args)",
            "                active_server.rest_call('PUT', TOPOLOGY_PATH, data,",
            "                                        timeout=None)",
            "            # Store the first response as the error to be bubbled up to the",
            "            # user since it was a good server. Subsequent servers will most",
            "            # likely be cluster slaves and won't have a useful error for the",
            "            # user (e.g. 302 redirect to master)",
            "            if not first_response:",
            "                first_response = ret",
            "            if not self.server_failure(ret, ignore_codes):",
            "                active_server.failed = False",
            "                return ret",
            "            else:",
            "                LOG.error(_('ServerProxy: %(action)s failure for servers: '",
            "                            '%(server)r Response: %(response)s'),",
            "                          {'action': action,",
            "                           'server': (active_server.server,",
            "                                      active_server.port),",
            "                           'response': ret[3]})",
            "                LOG.error(_(\"ServerProxy: Error details: status=%(status)d, \"",
            "                            \"reason=%(reason)r, ret=%(ret)s, data=%(data)r\"),",
            "                          {'status': ret[0], 'reason': ret[1], 'ret': ret[2],",
            "                           'data': ret[3]})",
            "                active_server.failed = True",
            "",
            "        # All servers failed, reset server list and try again next time",
            "        LOG.error(_('ServerProxy: %(action)s failure for all servers: '",
            "                    '%(server)r'),",
            "                  {'action': action,",
            "                   'server': tuple((s.server,",
            "                                    s.port) for s in self.servers)})",
            "        return first_response",
            "",
            "    def rest_action(self, action, resource, data='', errstr='%s',",
            "                    ignore_codes=[], headers={}, timeout=False):",
            "        \"\"\"",
            "        Wrapper for rest_call that verifies success and raises a",
            "        RemoteRestError on failure with a provided error string",
            "        By default, 404 errors on DELETE calls are ignored because",
            "        they already do not exist on the backend.",
            "        \"\"\"",
            "        if not ignore_codes and action == 'DELETE':",
            "            ignore_codes = [404]",
            "        resp = self.rest_call(action, resource, data, headers, ignore_codes,",
            "                              timeout)",
            "        if self.server_failure(resp, ignore_codes):",
            "            LOG.error(errstr, resp[2])",
            "            raise RemoteRestError(reason=resp[2], status=resp[0])",
            "        if resp[0] in ignore_codes:",
            "            LOG.warning(_(\"NeutronRestProxyV2: Received and ignored error \"",
            "                          \"code %(code)s on %(action)s action to resource \"",
            "                          \"%(resource)s\"),",
            "                        {'code': resp[2], 'action': action,",
            "                         'resource': resource})",
            "        return resp",
            "",
            "    def rest_create_router(self, tenant_id, router):",
            "        resource = ROUTER_RESOURCE_PATH % tenant_id",
            "        data = {\"router\": router}",
            "        errstr = _(\"Unable to create remote router: %s\")",
            "        self.rest_action('POST', resource, data, errstr)",
            "",
            "    def rest_update_router(self, tenant_id, router, router_id):",
            "        resource = ROUTERS_PATH % (tenant_id, router_id)",
            "        data = {\"router\": router}",
            "        errstr = _(\"Unable to update remote router: %s\")",
            "        self.rest_action('PUT', resource, data, errstr)",
            "",
            "    def rest_delete_router(self, tenant_id, router_id):",
            "        resource = ROUTERS_PATH % (tenant_id, router_id)",
            "        errstr = _(\"Unable to delete remote router: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_add_router_interface(self, tenant_id, router_id, intf_details):",
            "        resource = ROUTER_INTF_OP_PATH % (tenant_id, router_id)",
            "        data = {\"interface\": intf_details}",
            "        errstr = _(\"Unable to add router interface: %s\")",
            "        self.rest_action('POST', resource, data, errstr)",
            "",
            "    def rest_remove_router_interface(self, tenant_id, router_id, interface_id):",
            "        resource = ROUTER_INTF_PATH % (tenant_id, router_id, interface_id)",
            "        errstr = _(\"Unable to delete remote intf: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_create_network(self, tenant_id, network):",
            "        resource = NET_RESOURCE_PATH % tenant_id",
            "        data = {\"network\": network}",
            "        errstr = _(\"Unable to create remote network: %s\")",
            "        self.rest_action('POST', resource, data, errstr)",
            "",
            "    def rest_update_network(self, tenant_id, net_id, network):",
            "        resource = NETWORKS_PATH % (tenant_id, net_id)",
            "        data = {\"network\": network}",
            "        errstr = _(\"Unable to update remote network: %s\")",
            "        self.rest_action('PUT', resource, data, errstr)",
            "",
            "    def rest_delete_network(self, tenant_id, net_id):",
            "        resource = NETWORKS_PATH % (tenant_id, net_id)",
            "        errstr = _(\"Unable to update remote network: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_create_port(self, tenant_id, net_id, port):",
            "        resource = ATTACHMENT_PATH % (tenant_id, net_id, port[\"id\"])",
            "        data = {\"port\": port}",
            "        device_id = port.get(\"device_id\")",
            "        if not port[\"mac_address\"] or not device_id:",
            "            # controller only cares about ports attached to devices",
            "            LOG.warning(_(\"No device MAC attached to port %s. \"",
            "                          \"Skipping notification to controller.\"), port[\"id\"])",
            "            return",
            "        data[\"attachment\"] = {\"id\": device_id,",
            "                              \"mac\": port[\"mac_address\"]}",
            "        errstr = _(\"Unable to create remote port: %s\")",
            "        self.rest_action('PUT', resource, data, errstr)",
            "",
            "    def rest_delete_port(self, tenant_id, network_id, port_id):",
            "        resource = ATTACHMENT_PATH % (tenant_id, network_id, port_id)",
            "        errstr = _(\"Unable to delete remote port: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def rest_update_port(self, tenant_id, net_id, port):",
            "        # Controller has no update operation for the port endpoint",
            "        # the create PUT method will replace",
            "        self.rest_create_port(tenant_id, net_id, port)",
            "",
            "    def rest_create_floatingip(self, tenant_id, floatingip):",
            "        resource = FLOATINGIPS_PATH % (tenant_id, floatingip['id'])",
            "        errstr = _(\"Unable to create floating IP: %s\")",
            "        self.rest_action('PUT', resource, errstr=errstr)",
            "",
            "    def rest_update_floatingip(self, tenant_id, floatingip, oldid):",
            "        resource = FLOATINGIPS_PATH % (tenant_id, oldid)",
            "        errstr = _(\"Unable to update floating IP: %s\")",
            "        self.rest_action('PUT', resource, errstr=errstr)",
            "",
            "    def rest_delete_floatingip(self, tenant_id, oldid):",
            "        resource = FLOATINGIPS_PATH % (tenant_id, oldid)",
            "        errstr = _(\"Unable to delete floating IP: %s\")",
            "        self.rest_action('DELETE', resource, errstr=errstr)",
            "",
            "    def _consistency_watchdog(self, polling_interval=60):",
            "        if 'consistency' not in self.get_capabilities():",
            "            LOG.warning(_(\"Backend server(s) do not support automated \"",
            "                          \"consitency checks.\"))",
            "            return",
            "        while True:",
            "            # If consistency is supported, all we have to do is make any",
            "            # rest call and the consistency header will be added. If it",
            "            # doesn't match, the backend will return a synchronization error",
            "            # that will be handled by the rest_call.",
            "            time.sleep(polling_interval)",
            "            self.servers.rest_call('GET', HEALTH_PATH)",
            "",
            "",
            "class HTTPSConnectionWithValidation(httplib.HTTPSConnection):",
            "",
            "    # If combined_cert is None, the connection will continue without",
            "    # any certificate validation.",
            "    combined_cert = None",
            "",
            "    def connect(self):",
            "        sock = socket.create_connection((self.host, self.port),",
            "                                        self.timeout, self.source_address)",
            "        if self._tunnel_host:",
            "            self.sock = sock",
            "            self._tunnel()",
            "",
            "        if self.combined_cert:",
            "            self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,",
            "                                        cert_reqs=ssl.CERT_REQUIRED,",
            "                                        ca_certs=self.combined_cert)",
            "        else:",
            "            self.sock = ssl.wrap_socket(sock, self.key_file,",
            "                                        self.cert_file,",
            "                                        cert_reqs=ssl.CERT_NONE)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "88": [
                "ServerProxy",
                "__init__"
            ],
            "117": [
                "ServerProxy",
                "rest_call"
            ],
            "139": [
                "ServerProxy",
                "rest_call"
            ],
            "140": [
                "ServerProxy",
                "rest_call"
            ],
            "141": [
                "ServerProxy",
                "rest_call"
            ],
            "142": [
                "ServerProxy",
                "rest_call"
            ],
            "143": [
                "ServerProxy",
                "rest_call"
            ],
            "144": [
                "ServerProxy",
                "rest_call"
            ],
            "145": [
                "ServerProxy",
                "rest_call"
            ],
            "146": [
                "ServerProxy",
                "rest_call"
            ],
            "147": [
                "ServerProxy",
                "rest_call"
            ],
            "148": [
                "ServerProxy",
                "rest_call"
            ],
            "149": [
                "ServerProxy",
                "rest_call"
            ],
            "150": [
                "ServerProxy",
                "rest_call"
            ],
            "151": [
                "ServerProxy",
                "rest_call"
            ],
            "152": [
                "ServerProxy",
                "rest_call"
            ],
            "153": [
                "ServerProxy",
                "rest_call"
            ],
            "154": [
                "ServerProxy",
                "rest_call"
            ],
            "157": [
                "ServerProxy",
                "rest_call"
            ],
            "158": [
                "ServerProxy",
                "rest_call"
            ],
            "175": [
                "ServerProxy",
                "rest_call"
            ],
            "190": [
                "ServerPool",
                "__init__"
            ],
            "204": [
                "ServerPool",
                "__init__"
            ],
            "248": [
                "ServerPool",
                "server_proxy_for"
            ],
            "267": [
                "ServerPool",
                "rest_call"
            ],
            "272": [
                "ServerPool",
                "rest_call"
            ],
            "312": [
                "ServerPool",
                "rest_action"
            ]
        },
        "addLocation": []
    }
}