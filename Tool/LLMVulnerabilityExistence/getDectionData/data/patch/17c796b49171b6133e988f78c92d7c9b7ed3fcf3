{
    "ironic_inspector/node_cache.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " import copy"
            },
            "1": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import datetime"
            },
            "2": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " import json"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+import operator"
            },
            "4": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from automaton import exceptions as automaton_errors"
            },
            "6": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from ironicclient import exceptions"
            },
            "7": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from oslo_utils import uuidutils"
            },
            "8": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " import six"
            },
            "9": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " from sqlalchemy.orm import exc as orm_errors"
            },
            "10": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from sqlalchemy import text"
            },
            "11": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " from ironic_inspector.common.i18n import _"
            },
            "13": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " from ironic_inspector.common import ironic as ir_utils"
            },
            "14": {
                "beforePatchRowNumber": 807,
                "afterPatchRowNumber": 807,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 808,
                "afterPatchRowNumber": 808,
                "PatchRowcode": "         LOG.debug('Trying to use %s of value %s for node look up',"
            },
            "16": {
                "beforePatchRowNumber": 809,
                "afterPatchRowNumber": 809,
                "PatchRowcode": "                   name, value)"
            },
            "17": {
                "beforePatchRowNumber": 810,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        value_list = []"
            },
            "18": {
                "beforePatchRowNumber": 811,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for v in value:"
            },
            "19": {
                "beforePatchRowNumber": 812,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            value_list.append(\"name='%s' AND value='%s'\" % (name, v))"
            },
            "20": {
                "beforePatchRowNumber": 813,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        stmt = ('select distinct node_uuid from attributes where ' +"
            },
            "21": {
                "beforePatchRowNumber": 814,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                ' OR '.join(value_list))"
            },
            "22": {
                "beforePatchRowNumber": 815,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        rows = (db.model_query(db.Attribute.node_uuid).from_statement("
            },
            "23": {
                "beforePatchRowNumber": 816,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            text(stmt)).all())"
            },
            "24": {
                "beforePatchRowNumber": 817,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        found.update(row.node_uuid for row in rows)"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 810,
                "PatchRowcode": "+        query = db.model_query(db.Attribute.node_uuid)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 811,
                "PatchRowcode": "+        pairs = [(db.Attribute.name == name) &"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 812,
                "PatchRowcode": "+                 (db.Attribute.value == v) for v in value]"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 813,
                "PatchRowcode": "+        query = query.filter(six.moves.reduce(operator.or_, pairs))"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 814,
                "PatchRowcode": "+        found.update(row.node_uuid for row in query.distinct().all())"
            },
            "30": {
                "beforePatchRowNumber": 818,
                "afterPatchRowNumber": 815,
                "PatchRowcode": " "
            },
            "31": {
                "beforePatchRowNumber": 819,
                "afterPatchRowNumber": 816,
                "PatchRowcode": "     if not found:"
            },
            "32": {
                "beforePatchRowNumber": 820,
                "afterPatchRowNumber": 817,
                "PatchRowcode": "         raise utils.NotFoundInCacheError(_("
            }
        },
        "frontPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Cache for nodes currently under introspection.\"\"\"",
            "",
            "import collections",
            "import contextlib",
            "import copy",
            "import datetime",
            "import json",
            "",
            "from automaton import exceptions as automaton_errors",
            "from ironicclient import exceptions",
            "from oslo_concurrency import lockutils",
            "from oslo_config import cfg",
            "from oslo_db.sqlalchemy import utils as db_utils",
            "from oslo_utils import excutils",
            "from oslo_utils import reflection",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import six",
            "from sqlalchemy.orm import exc as orm_errors",
            "from sqlalchemy import text",
            "",
            "from ironic_inspector.common.i18n import _",
            "from ironic_inspector.common import ironic as ir_utils",
            "from ironic_inspector import db",
            "from ironic_inspector import introspection_state as istate",
            "from ironic_inspector import utils",
            "",
            "",
            "CONF = cfg.CONF",
            "",
            "",
            "LOG = utils.getProcessingLogger(__name__)",
            "",
            "",
            "MACS_ATTRIBUTE = 'mac'",
            "_LOCK_TEMPLATE = 'node-%s'",
            "_SEMAPHORES = lockutils.Semaphores()",
            "",
            "",
            "def _get_lock(uuid):",
            "    \"\"\"Get lock object for a given node UUID.\"\"\"",
            "    return lockutils.internal_lock(_LOCK_TEMPLATE % uuid,",
            "                                   semaphores=_SEMAPHORES)",
            "",
            "",
            "def _get_lock_ctx(uuid):",
            "    \"\"\"Get context manager yielding a lock object for a given node UUID.\"\"\"",
            "    return lockutils.lock(_LOCK_TEMPLATE % uuid, semaphores=_SEMAPHORES)",
            "",
            "",
            "class NodeInfo(object):",
            "    \"\"\"Record about a node in the cache.",
            "",
            "    This class optionally allows to acquire a lock on a node. Note that the",
            "    class instance itself is NOT thread-safe, you need to create a new instance",
            "    for every thread.",
            "    \"\"\"",
            "",
            "    def __init__(self, uuid, version_id=None, state=None, started_at=None,",
            "                 finished_at=None, error=None, node=None, ports=None,",
            "                 ironic=None, lock=None):",
            "        self.uuid = uuid",
            "        self.started_at = started_at",
            "        self.finished_at = finished_at",
            "        self.error = error",
            "        self.invalidate_cache()",
            "        self._version_id = version_id",
            "        self._state = state",
            "        self._node = node",
            "        if ports is not None and not isinstance(ports, dict):",
            "            ports = {p.address: p for p in ports}",
            "        self._ports = ports",
            "        self._attributes = None",
            "        self._ironic = ironic",
            "        # This is a lock on a node UUID, not on a NodeInfo object",
            "        self._lock = lock if lock is not None else _get_lock(uuid)",
            "        # Whether lock was acquired using this NodeInfo object",
            "        self._locked = lock is not None",
            "        self._fsm = None",
            "",
            "    def __del__(self):",
            "        if self._locked:",
            "            LOG.warning('BUG: node lock was not released by the moment '",
            "                        'node info object is deleted')",
            "            self._lock.release()",
            "",
            "    def __str__(self):",
            "        \"\"\"Self represented as an UUID and a state.\"\"\"",
            "        parts = [self.uuid]",
            "        if self._state:",
            "            parts += [_('state'), self._state]",
            "        return ' '.join(parts)",
            "",
            "    def acquire_lock(self, blocking=True):",
            "        \"\"\"Acquire a lock on the associated node.",
            "",
            "        Exits with success if a lock is already acquired using this NodeInfo",
            "        object.",
            "",
            "        :param blocking: if True, wait for lock to be acquired, otherwise",
            "                         return immediately.",
            "        :returns: boolean value, whether lock was acquired successfully",
            "        \"\"\"",
            "        if self._locked:",
            "            return True",
            "",
            "        LOG.debug('Attempting to acquire lock', node_info=self)",
            "        if self._lock.acquire(blocking):",
            "            self._locked = True",
            "            LOG.debug('Successfully acquired lock', node_info=self)",
            "            return True",
            "        else:",
            "            LOG.debug('Unable to acquire lock', node_info=self)",
            "            return False",
            "",
            "    def release_lock(self):",
            "        \"\"\"Release a lock on a node.",
            "",
            "        Does nothing if lock was not acquired using this NodeInfo object.",
            "        \"\"\"",
            "        if self._locked:",
            "            LOG.debug('Successfully released lock', node_info=self)",
            "            self._lock.release()",
            "        self._locked = False",
            "",
            "    @property",
            "    def version_id(self):",
            "        \"\"\"Get the version id\"\"\"",
            "        if self._version_id is None:",
            "            row = db.model_query(db.Node).get(self.uuid)",
            "            if row is None:",
            "                raise utils.NotFoundInCacheError(_('Node not found in the '",
            "                                                   'cache'), node_info=self)",
            "            self._version_id = row.version_id",
            "        return self._version_id",
            "",
            "    def _set_version_id(self, value, session):",
            "        row = self._row(session)",
            "        row.version_id = value",
            "        row.save(session)",
            "        self._version_id = value",
            "",
            "    def _row(self, session=None):",
            "        \"\"\"Get a row from the database with self.uuid and self.version_id\"\"\"",
            "        try:",
            "            # race condition if version_id changed outside of this node_info",
            "            return db.model_query(db.Node, session=session).filter_by(",
            "                uuid=self.uuid, version_id=self.version_id).one()",
            "        except (orm_errors.NoResultFound, orm_errors.StaleDataError):",
            "            raise utils.NodeStateRaceCondition(node_info=self)",
            "",
            "    def _commit(self, **fields):",
            "        \"\"\"Commit the fields into the DB.\"\"\"",
            "        LOG.debug('Committing fields: %s', fields, node_info=self)",
            "        with db.ensure_transaction() as session:",
            "            self._set_version_id(uuidutils.generate_uuid(), session)",
            "            row = self._row(session)",
            "            row.update(fields)",
            "",
            "    def commit(self):",
            "        \"\"\"Commit current node status into the database.\"\"\"",
            "        # state and version_id are updated separately",
            "        self._commit(started_at=self.started_at, finished_at=self.finished_at,",
            "                     error=self.error)",
            "",
            "    @property",
            "    def state(self):",
            "        \"\"\"State of the node_info object.\"\"\"",
            "        if self._state is None:",
            "            row = self._row()",
            "            self._state = row.state",
            "        return self._state",
            "",
            "    def _set_state(self, value):",
            "        self._commit(state=value)",
            "        self._state = value",
            "",
            "    def _get_fsm(self):",
            "        \"\"\"Get an fsm instance initialized with self.state.\"\"\"",
            "        if self._fsm is None:",
            "            self._fsm = istate.FSM.copy(shallow=True)",
            "        self._fsm.initialize(start_state=self.state)",
            "        return self._fsm",
            "",
            "    @contextlib.contextmanager",
            "    def _fsm_ctx(self):",
            "        fsm = self._get_fsm()",
            "        try:",
            "            yield fsm",
            "        finally:",
            "            if fsm.current_state != self.state:",
            "                LOG.info('Updating node state: %(current)s --> %(new)s',",
            "                         {'current': self.state, 'new': fsm.current_state},",
            "                         node_info=self)",
            "                self._set_state(fsm.current_state)",
            "",
            "    def fsm_event(self, event, strict=False):",
            "        \"\"\"Update node_info.state based on a fsm.process_event(event) call.",
            "",
            "        An AutomatonException triggers an error event.",
            "        If strict, node_info.finished(istate.Events.error, error=str(exc))",
            "        is called with the AutomatonException instance and a EventError raised.",
            "",
            "        :param event: an event to process by the fsm",
            "        :strict: whether to fail the introspection upon an invalid event",
            "        :raises: NodeStateInvalidEvent",
            "        \"\"\"",
            "        with self._fsm_ctx() as fsm:",
            "            LOG.debug('Executing fsm(%(state)s).process_event(%(event)s)',",
            "                      {'state': fsm.current_state, 'event': event},",
            "                      node_info=self)",
            "            try:",
            "                fsm.process_event(event)",
            "            except automaton_errors.NotFound as exc:",
            "                msg = _('Invalid event: %s') % exc",
            "                if strict:",
            "                    LOG.error(msg, node_info=self)",
            "                    # assuming an error event is always possible",
            "                    self.finished(istate.Events.error, error=str(exc))",
            "                else:",
            "                    LOG.warning(msg, node_info=self)",
            "                raise utils.NodeStateInvalidEvent(str(exc), node_info=self)",
            "",
            "    @property",
            "    def options(self):",
            "        \"\"\"Node introspection options as a dict.\"\"\"",
            "        if self._options is None:",
            "            rows = db.model_query(db.Option).filter_by(",
            "                uuid=self.uuid)",
            "            self._options = {row.name: json.loads(row.value)",
            "                             for row in rows}",
            "        return self._options",
            "",
            "    @property",
            "    def attributes(self):",
            "        \"\"\"Node look up attributes as a dict.\"\"\"",
            "        if self._attributes is None:",
            "            self._attributes = {}",
            "            rows = db.model_query(db.Attribute).filter_by(",
            "                node_uuid=self.uuid)",
            "            for row in rows:",
            "                self._attributes.setdefault(row.name, []).append(row.value)",
            "        return self._attributes",
            "",
            "    @property",
            "    def ironic(self):",
            "        \"\"\"Ironic client instance.\"\"\"",
            "        if self._ironic is None:",
            "            self._ironic = ir_utils.get_client()",
            "        return self._ironic",
            "",
            "    def set_option(self, name, value):",
            "        \"\"\"Set an option for a node.\"\"\"",
            "        encoded = json.dumps(value)",
            "        self.options[name] = value",
            "        with db.ensure_transaction() as session:",
            "            db.model_query(db.Option, session=session).filter_by(",
            "                uuid=self.uuid, name=name).delete()",
            "            db.Option(uuid=self.uuid, name=name, value=encoded).save(",
            "                session)",
            "",
            "    def finished(self, event, error=None):",
            "        \"\"\"Record status for this node and process a terminal transition.",
            "",
            "        Also deletes look up attributes from the cache.",
            "",
            "        :param event: the event to process",
            "        :param error: error message",
            "        \"\"\"",
            "",
            "        self.release_lock()",
            "        self.finished_at = timeutils.utcnow()",
            "        self.error = error",
            "",
            "        with db.ensure_transaction() as session:",
            "            self.fsm_event(event)",
            "            self._commit(finished_at=self.finished_at, error=self.error)",
            "            db.model_query(db.Attribute, session=session).filter_by(",
            "                node_uuid=self.uuid).delete()",
            "            db.model_query(db.Option, session=session).filter_by(",
            "                uuid=self.uuid).delete()",
            "",
            "    def add_attribute(self, name, value, session=None):",
            "        \"\"\"Store look up attribute for a node in the database.",
            "",
            "        :param name: attribute name",
            "        :param value: attribute value or list of possible values",
            "        :param session: optional existing database session",
            "        \"\"\"",
            "        if not isinstance(value, list):",
            "            value = [value]",
            "",
            "        with db.ensure_transaction(session) as session:",
            "            for v in value:",
            "                db.Attribute(uuid=uuidutils.generate_uuid(), name=name,",
            "                             value=v, node_uuid=self.uuid).save(session)",
            "            # Invalidate attributes so they're loaded on next usage",
            "            self._attributes = None",
            "",
            "    @classmethod",
            "    def from_row(cls, row, ironic=None, lock=None, node=None):",
            "        \"\"\"Construct NodeInfo from a database row.\"\"\"",
            "        fields = {key: row[key]",
            "                  for key in ('uuid', 'version_id', 'state', 'started_at',",
            "                              'finished_at', 'error')}",
            "        return cls(ironic=ironic, lock=lock, node=node, **fields)",
            "",
            "    def invalidate_cache(self):",
            "        \"\"\"Clear all cached info, so that it's reloaded next time.\"\"\"",
            "        self._options = None",
            "        self._node = None",
            "        self._ports = None",
            "        self._attributes = None",
            "        self._ironic = None",
            "        self._fsm = None",
            "        self._state = None",
            "        self._version_id = None",
            "",
            "    def node(self, ironic=None):",
            "        \"\"\"Get Ironic node object associated with the cached node record.\"\"\"",
            "        if self._node is None:",
            "            ironic = ironic or self.ironic",
            "            self._node = ir_utils.get_node(self.uuid, ironic=ironic)",
            "        return self._node",
            "",
            "    def create_ports(self, ports, ironic=None):",
            "        \"\"\"Create one or several ports for this node.",
            "",
            "        :param ports: List of ports with all their attributes",
            "                      e.g  [{'mac': xx, 'ip': xx, 'client_id': None},",
            "                      {'mac': xx, 'ip': None, 'client_id': None}]",
            "                      It also support the old style of list of macs.",
            "                      A warning is issued if port already exists on a node.",
            "",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        existing_macs = []",
            "        for port in ports:",
            "            mac = port",
            "            extra = {}",
            "            pxe_enabled = True",
            "            if isinstance(port, dict):",
            "                mac = port['mac']",
            "                client_id = port.get('client_id')",
            "                if client_id:",
            "                    extra = {'client-id': client_id}",
            "                pxe_enabled = port.get('pxe', True)",
            "",
            "            if mac not in self.ports():",
            "                self._create_port(mac, ironic=ironic, extra=extra,",
            "                                  pxe_enabled=pxe_enabled)",
            "            else:",
            "                existing_macs.append(mac)",
            "",
            "        if existing_macs:",
            "            LOG.warning('Did not create ports %s as they already exist',",
            "                        existing_macs, node_info=self)",
            "",
            "    def ports(self, ironic=None):",
            "        \"\"\"Get Ironic port objects associated with the cached node record.",
            "",
            "        This value is cached as well, use invalidate_cache() to clean.",
            "",
            "        :return: dict MAC -> port object",
            "        \"\"\"",
            "        if self._ports is None:",
            "            ironic = ironic or self.ironic",
            "            port_list = ironic.node.list_ports(self.uuid, limit=0, detail=True)",
            "            self._ports = {p.address: p for p in port_list}",
            "        return self._ports",
            "",
            "    def _create_port(self, mac, ironic=None, **kwargs):",
            "        ironic = ironic or self.ironic",
            "        try:",
            "            port = ironic.port.create(",
            "                node_uuid=self.uuid, address=mac, **kwargs)",
            "            LOG.info('Port %(uuid)s was created successfully, MAC: %(mac)s,'",
            "                     'attributes: %(attrs)s',",
            "                     {'uuid': port.uuid, 'mac': port.address,",
            "                      'attrs': kwargs},",
            "                     node_info=self)",
            "        except exceptions.Conflict:",
            "            LOG.warning('Port %s already exists, skipping',",
            "                        mac, node_info=self)",
            "            # NOTE(dtantsur): we didn't get port object back, so we have to",
            "            # reload ports on next access",
            "            self._ports = None",
            "        else:",
            "            self._ports[mac] = port",
            "",
            "    def patch(self, patches, ironic=None):",
            "        \"\"\"Apply JSON patches to a node.",
            "",
            "        Refreshes cached node instance.",
            "",
            "        :param patches: JSON patches to apply",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        :raises: ironicclient exceptions",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        # NOTE(aarefiev): support path w/o ahead forward slash",
            "        # as Ironic cli does",
            "        for patch in patches:",
            "            if patch.get('path') and not patch['path'].startswith('/'):",
            "                patch['path'] = '/' + patch['path']",
            "",
            "        LOG.debug('Updating node with patches %s', patches, node_info=self)",
            "        self._node = ironic.node.update(self.uuid, patches)",
            "",
            "    def patch_port(self, port, patches, ironic=None):",
            "        \"\"\"Apply JSON patches to a port.",
            "",
            "        :param port: port object or its MAC",
            "        :param patches: JSON patches to apply",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        ports = self.ports()",
            "        if isinstance(port, six.string_types):",
            "            port = ports[port]",
            "",
            "        LOG.debug('Updating port %(mac)s with patches %(patches)s',",
            "                  {'mac': port.address, 'patches': patches},",
            "                  node_info=self)",
            "        new_port = ironic.port.update(port.uuid, patches)",
            "        ports[port.address] = new_port",
            "",
            "    def update_properties(self, ironic=None, **props):",
            "        \"\"\"Update properties on a node.",
            "",
            "        :param props: properties to update",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        patches = [{'op': 'add', 'path': '/properties/%s' % k, 'value': v}",
            "                   for k, v in props.items()]",
            "        self.patch(patches, ironic)",
            "",
            "    def update_capabilities(self, ironic=None, **caps):",
            "        \"\"\"Update capabilities on a node.",
            "",
            "        :param caps: capabilities to update",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        existing = ir_utils.capabilities_to_dict(",
            "            self.node().properties.get('capabilities'))",
            "        existing.update(caps)",
            "        self.update_properties(",
            "            ironic=ironic,",
            "            capabilities=ir_utils.dict_to_capabilities(existing))",
            "",
            "    def delete_port(self, port, ironic=None):",
            "        \"\"\"Delete port.",
            "",
            "        :param port: port object or its MAC",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        ports = self.ports()",
            "        if isinstance(port, six.string_types):",
            "            port = ports[port]",
            "",
            "        ironic.port.delete(port.uuid)",
            "        del ports[port.address]",
            "",
            "    def get_by_path(self, path):",
            "        \"\"\"Get field value by ironic-style path (e.g. /extra/foo).",
            "",
            "        :param path: path to a field",
            "        :returns: field value",
            "        :raises: KeyError if field was not found",
            "        \"\"\"",
            "        path = path.strip('/')",
            "        try:",
            "            if '/' in path:",
            "                prop, key = path.split('/', 1)",
            "                return getattr(self.node(), prop)[key]",
            "            else:",
            "                return getattr(self.node(), path)",
            "        except AttributeError:",
            "            raise KeyError(path)",
            "",
            "    def replace_field(self, path, func, **kwargs):",
            "        \"\"\"Replace a field on ironic node.",
            "",
            "        :param path: path to a field as used by the ironic client",
            "        :param func: function accepting an old value and returning a new one",
            "        :param kwargs: if 'default' value is passed here, it will be used when",
            "                       no existing value is found.",
            "        :raises: KeyError if value is not found and default is not set",
            "        :raises: everything that patch() may raise",
            "        \"\"\"",
            "        ironic = kwargs.pop(\"ironic\", None) or self.ironic",
            "        try:",
            "            value = self.get_by_path(path)",
            "            op = 'replace'",
            "        except KeyError:",
            "            if 'default' in kwargs:",
            "                value = kwargs['default']",
            "                op = 'add'",
            "            else:",
            "                raise",
            "",
            "        ref_value = copy.deepcopy(value)",
            "        value = func(value)",
            "        if value != ref_value:",
            "            self.patch([{'op': op, 'path': path, 'value': value}], ironic)",
            "",
            "",
            "def triggers_fsm_error_transition(errors=(Exception,),",
            "                                  no_errors=(utils.NodeStateInvalidEvent,",
            "                                             utils.NodeStateRaceCondition)):",
            "    \"\"\"Trigger an fsm error transition upon certain errors.",
            "",
            "    It is assumed the first function arg of the decorated function is always a",
            "    NodeInfo instance.",
            "",
            "    :param errors: a tuple of exceptions upon which an error",
            "                   event is triggered. Re-raised.",
            "    :param no_errors: a tuple of exceptions that won't trigger the",
            "                      error event.",
            "    \"\"\"",
            "    def outer(func):",
            "        @six.wraps(func)",
            "        def inner(node_info, *args, **kwargs):",
            "            ret = None",
            "            try:",
            "                ret = func(node_info, *args, **kwargs)",
            "            except no_errors as exc:",
            "                LOG.debug('Not processing error event for the '",
            "                          'exception: %(exc)s raised by %(func)s',",
            "                          {'exc': exc,",
            "                           'func': reflection.get_callable_name(func)},",
            "                          node_info=node_info)",
            "            except errors as exc:",
            "                with excutils.save_and_reraise_exception():",
            "                    LOG.error('Processing the error event because of an '",
            "                              'exception %(exc_type)s: %(exc)s raised by '",
            "                              '%(func)s',",
            "                              {'exc_type': type(exc), 'exc': exc,",
            "                               'func': reflection.get_callable_name(func)},",
            "                              node_info=node_info)",
            "                    # an error event should be possible from all states",
            "                    node_info.finished(istate.Events.error, error=str(exc))",
            "            return ret",
            "        return inner",
            "    return outer",
            "",
            "",
            "def fsm_event_before(event, strict=False):",
            "    \"\"\"Trigger an fsm event before the function execution.",
            "",
            "    It is assumed the first function arg of the decorated function is always a",
            "    NodeInfo instance.",
            "",
            "    :param event: the event to process before the function call",
            "    :param strict: make an invalid fsm event trigger an error event",
            "    \"\"\"",
            "    def outer(func):",
            "        @six.wraps(func)",
            "        def inner(node_info, *args, **kwargs):",
            "            LOG.debug('Processing event %(event)s before calling '",
            "                      '%(func)s', {'event': event, 'func': func},",
            "                      node_info=node_info)",
            "            node_info.fsm_event(event, strict=strict)",
            "            return func(node_info, *args, **kwargs)",
            "        return inner",
            "    return outer",
            "",
            "",
            "def fsm_event_after(event, strict=False):",
            "    \"\"\"Trigger an fsm event after the function execution.",
            "",
            "    It is assumed the first function arg of the decorated function is always a",
            "    NodeInfo instance.",
            "",
            "    :param event: the event to process after the function call",
            "    :param strict: make an invalid fsm event trigger an error event",
            "    \"\"\"",
            "    def outer(func):",
            "        @six.wraps(func)",
            "        def inner(node_info, *args, **kwargs):",
            "            ret = func(node_info, *args, **kwargs)",
            "            LOG.debug('Processing event %(event)s after calling '",
            "                      '%(func)s', {'event': event, 'func': func},",
            "                      node_info=node_info)",
            "            node_info.fsm_event(event, strict=strict)",
            "            return ret",
            "        return inner",
            "    return outer",
            "",
            "",
            "def fsm_transition(event, reentrant=True, **exc_kwargs):",
            "    \"\"\"Decorate a function to perform a (non-)reentrant transition.",
            "",
            "    If True, reentrant transition will be performed at the end of a function",
            "    call. If False, the transition will be performed before the function call.",
            "    The function is decorated with the triggers_fsm_error_transition decorator",
            "    as well.",
            "",
            "    :param event: the event to bind the transition to.",
            "    :param reentrant: whether the transition is reentrant.",
            "    :param exc_kwargs: passed on to the triggers_fsm_error_transition decorator",
            "    \"\"\"",
            "    def outer(func):",
            "        inner = triggers_fsm_error_transition(**exc_kwargs)(func)",
            "        if not reentrant:",
            "            return fsm_event_before(event, strict=True)(inner)",
            "        return fsm_event_after(event)(inner)",
            "    return outer",
            "",
            "",
            "def release_lock(func):",
            "    \"\"\"Decorate a node_info-function to release the node_info lock.",
            "",
            "    Assumes the first parameter of the function func is always a NodeInfo",
            "    instance.",
            "",
            "    \"\"\"",
            "    @six.wraps(func)",
            "    def inner(node_info, *args, **kwargs):",
            "        try:",
            "            return func(node_info, *args, **kwargs)",
            "        finally:",
            "            # FIXME(milan) hacking the test cases to work",
            "            # with release_lock.assert_called_once...",
            "            if node_info._locked:",
            "                node_info.release_lock()",
            "    return inner",
            "",
            "",
            "def start_introspection(uuid, **kwargs):",
            "    \"\"\"Start the introspection of a node.",
            "",
            "    If a node_info record exists in the DB, a start transition is used rather",
            "    than dropping the record in order to check for the start transition",
            "    validity in particular node state.",
            "",
            "    :param uuid: Ironic node UUID",
            "    :param kwargs: passed on to add_node()",
            "    :raises: NodeStateInvalidEvent in case the start transition is invalid in",
            "             the current node state",
            "    :raises: NodeStateRaceCondition if a mismatch was detected between the",
            "             node_info cache and the DB",
            "    :returns: NodeInfo",
            "    \"\"\"",
            "    with db.ensure_transaction():",
            "        node_info = NodeInfo(uuid)",
            "        # check that the start transition is possible",
            "        try:",
            "            node_info.fsm_event(istate.Events.start)",
            "        except utils.NotFoundInCacheError:",
            "            # node not found while in the fsm_event handler",
            "            LOG.debug('Node missing in the cache; adding it now',",
            "                      node_info=node_info)",
            "            state = istate.States.starting",
            "        else:",
            "            state = node_info.state",
            "        return add_node(uuid, state, **kwargs)",
            "",
            "",
            "def add_node(uuid, state, **attributes):",
            "    \"\"\"Store information about a node under introspection.",
            "",
            "    All existing information about this node is dropped.",
            "    Empty values are skipped.",
            "",
            "    :param uuid: Ironic node UUID",
            "    :param state: The initial state of the node",
            "    :param attributes: attributes known about this node (like macs, BMC etc);",
            "                       also ironic client instance may be passed under 'ironic'",
            "    :returns: NodeInfo",
            "    \"\"\"",
            "    started_at = timeutils.utcnow()",
            "    with db.ensure_transaction() as session:",
            "        _delete_node(uuid)",
            "        version_id = uuidutils.generate_uuid()",
            "        db.Node(uuid=uuid, state=state, version_id=version_id,",
            "                started_at=started_at).save(session)",
            "",
            "        node_info = NodeInfo(uuid=uuid, state=state, started_at=started_at,",
            "                             version_id=version_id,",
            "                             ironic=attributes.pop('ironic', None))",
            "        for (name, value) in attributes.items():",
            "            if not value:",
            "                continue",
            "            node_info.add_attribute(name, value, session=session)",
            "",
            "    return node_info",
            "",
            "",
            "def delete_nodes_not_in_list(uuids):",
            "    \"\"\"Delete nodes which don't exist in Ironic node UUIDs.",
            "",
            "    :param uuids: Ironic node UUIDs",
            "    \"\"\"",
            "    inspector_uuids = _list_node_uuids()",
            "    for uuid in inspector_uuids - uuids:",
            "        LOG.warning('Node %s was deleted from Ironic, dropping from Ironic '",
            "                    'Inspector database', uuid)",
            "        with _get_lock_ctx(uuid):",
            "            _delete_node(uuid)",
            "",
            "",
            "def _delete_node(uuid, session=None):",
            "    \"\"\"Delete information about a node.",
            "",
            "    :param uuid: Ironic node UUID",
            "    :param session: optional existing database session",
            "    \"\"\"",
            "    with db.ensure_transaction(session) as session:",
            "        db.model_query(db.Attribute, session=session).filter_by(",
            "            node_uuid=uuid).delete()",
            "        for model in (db.Option, db.Node):",
            "            db.model_query(model,",
            "                           session=session).filter_by(uuid=uuid).delete()",
            "",
            "",
            "def introspection_active():",
            "    \"\"\"Check if introspection is active for at least one node.\"\"\"",
            "    # FIXME(dtantsur): is there a better way to express it?",
            "    return (db.model_query(db.Node.uuid).filter_by(finished_at=None).first()",
            "            is not None)",
            "",
            "",
            "def active_macs():",
            "    \"\"\"List all MAC's that are on introspection right now.\"\"\"",
            "    return ({x.value for x in db.model_query(db.Attribute.value).",
            "            filter_by(name=MACS_ATTRIBUTE)})",
            "",
            "",
            "def _list_node_uuids():",
            "    \"\"\"Get all nodes' uuid from cache.",
            "",
            "    :returns: Set of nodes' uuid.",
            "    \"\"\"",
            "    return {x.uuid for x in db.model_query(db.Node.uuid)}",
            "",
            "",
            "def get_node(node_id, ironic=None, locked=False):",
            "    \"\"\"Get node from cache.",
            "",
            "    :param node_id: node UUID or name.",
            "    :param ironic: optional ironic client instance",
            "    :param locked: if True, get a lock on node before fetching its data",
            "    :returns: structure NodeInfo.",
            "    \"\"\"",
            "    if uuidutils.is_uuid_like(node_id):",
            "        node = None",
            "        uuid = node_id",
            "    else:",
            "        node = ir_utils.get_node(node_id, ironic=ironic)",
            "        uuid = node.uuid",
            "",
            "    if locked:",
            "        lock = _get_lock(uuid)",
            "        lock.acquire()",
            "    else:",
            "        lock = None",
            "",
            "    try:",
            "        row = db.model_query(db.Node).filter_by(uuid=uuid).first()",
            "        if row is None:",
            "            raise utils.Error(_('Could not find node %s in cache') % uuid,",
            "                              code=404)",
            "        return NodeInfo.from_row(row, ironic=ironic, lock=lock, node=node)",
            "    except Exception:",
            "        with excutils.save_and_reraise_exception():",
            "            if lock is not None:",
            "                lock.release()",
            "",
            "",
            "def find_node(**attributes):",
            "    \"\"\"Find node in cache.",
            "",
            "    Looks up a node based on attributes in a best-match fashion.",
            "    This function acquires a lock on a node.",
            "",
            "    :param attributes: attributes known about this node (like macs, BMC etc)",
            "                       also ironic client instance may be passed under 'ironic'",
            "    :returns: structure NodeInfo with attributes ``uuid`` and ``created_at``",
            "    :raises: Error if node is not found or multiple nodes match the attributes",
            "    \"\"\"",
            "    ironic = attributes.pop('ironic', None)",
            "    # NOTE(dtantsur): sorting is not required, but gives us predictability",
            "    found = collections.Counter()",
            "",
            "    for (name, value) in sorted(attributes.items()):",
            "        if not value:",
            "            LOG.debug('Empty value for attribute %s', name)",
            "            continue",
            "        if not isinstance(value, list):",
            "            value = [value]",
            "",
            "        LOG.debug('Trying to use %s of value %s for node look up',",
            "                  name, value)",
            "        value_list = []",
            "        for v in value:",
            "            value_list.append(\"name='%s' AND value='%s'\" % (name, v))",
            "        stmt = ('select distinct node_uuid from attributes where ' +",
            "                ' OR '.join(value_list))",
            "        rows = (db.model_query(db.Attribute.node_uuid).from_statement(",
            "            text(stmt)).all())",
            "        found.update(row.node_uuid for row in rows)",
            "",
            "    if not found:",
            "        raise utils.NotFoundInCacheError(_(",
            "            'Could not find a node for attributes %s') % attributes)",
            "",
            "    most_common = found.most_common()",
            "    LOG.debug('The following nodes match the attributes: %(attributes)s, '",
            "              'scoring: %(most_common)s',",
            "              {'most_common': ', '.join('%s: %d' % tpl for tpl in most_common),",
            "               'attributes': ', '.join('%s=%s' % tpl for tpl in",
            "                                       attributes.items())})",
            "",
            "    # NOTE(milan) most_common is sorted, higher scores first",
            "    highest_score = most_common[0][1]",
            "    found = [item[0] for item in most_common if highest_score == item[1]]",
            "    if len(found) > 1:",
            "        raise utils.Error(_(",
            "            'Multiple nodes match the same number of attributes '",
            "            '%(attr)s: %(found)s')",
            "            % {'attr': attributes, 'found': found}, code=404)",
            "",
            "    uuid = found.pop()",
            "    node_info = NodeInfo(uuid=uuid, ironic=ironic)",
            "    node_info.acquire_lock()",
            "",
            "    try:",
            "        row = (db.model_query(db.Node.started_at, db.Node.finished_at).",
            "               filter_by(uuid=uuid).first())",
            "",
            "        if not row:",
            "            raise utils.Error(_(",
            "                'Could not find node %s in introspection cache, '",
            "                'probably it\\'s not on introspection now') % uuid, code=404)",
            "",
            "        if row.finished_at:",
            "            raise utils.Error(_(",
            "                'Introspection for node %(node)s already finished on '",
            "                '%(finish)s') % {'node': uuid, 'finish': row.finished_at})",
            "",
            "        node_info.started_at = row.started_at",
            "        return node_info",
            "    except Exception:",
            "        with excutils.save_and_reraise_exception():",
            "            node_info.release_lock()",
            "",
            "",
            "def clean_up():",
            "    \"\"\"Clean up the cache.",
            "",
            "    * Finish introspection for timed out nodes.",
            "    * Drop outdated node status information.",
            "",
            "    :return: list of timed out node UUID's",
            "    \"\"\"",
            "    if CONF.node_status_keep_time > 0:",
            "        status_keep_threshold = (timeutils.utcnow() - datetime.timedelta(",
            "                                 seconds=CONF.node_status_keep_time))",
            "        with db.ensure_transaction() as session:",
            "            db.model_query(db.Node, session=session).filter(",
            "                db.Node.finished_at.isnot(None),",
            "                db.Node.finished_at < status_keep_threshold).delete()",
            "",
            "    timeout = CONF.timeout",
            "    if timeout <= 0:",
            "        return []",
            "    threshold = timeutils.utcnow() - datetime.timedelta(seconds=timeout)",
            "    uuids = [row.uuid for row in",
            "             db.model_query(db.Node.uuid).filter(",
            "                 db.Node.started_at < threshold,",
            "                 db.Node.finished_at.is_(None)).all()]",
            "",
            "    if not uuids:",
            "        return []",
            "",
            "    LOG.error('Introspection for nodes %s has timed out', uuids)",
            "    for u in uuids:",
            "        node_info = get_node(u, locked=True)",
            "        try:",
            "            if node_info.finished_at or node_info.started_at > threshold:",
            "                continue",
            "            if node_info.state != istate.States.waiting:",
            "                LOG.error('Something went wrong, timeout occurred '",
            "                          'while introspection in \"%s\" state',",
            "                          node_info.state,",
            "                          node_info=node_info)",
            "            node_info.finished(",
            "                istate.Events.timeout, error='Introspection timeout')",
            "        finally:",
            "            node_info.release_lock()",
            "",
            "    return uuids",
            "",
            "",
            "def create_node(driver, ironic=None, **attributes):",
            "    \"\"\"Create ironic node and cache it.",
            "",
            "    * Create new node in ironic.",
            "    * Cache it in inspector.",
            "    * Sets node_info state to enrolling.",
            "",
            "    :param driver: driver for Ironic node.",
            "    :param ironic: ronic client instance.",
            "    :param attributes: dict, additional keyword arguments to pass",
            "                             to the ironic client on node creation.",
            "    :return: NodeInfo, or None in case error happened.",
            "    \"\"\"",
            "    if ironic is None:",
            "        ironic = ir_utils.get_client()",
            "    try:",
            "        node = ironic.node.create(driver=driver, **attributes)",
            "    except exceptions.InvalidAttribute as e:",
            "        LOG.error('Failed to create new node: %s', e)",
            "    else:",
            "        LOG.info('Node %s was created successfully', node.uuid)",
            "        return add_node(node.uuid, istate.States.enrolling, ironic=ironic)",
            "",
            "",
            "def get_node_list(ironic=None, marker=None, limit=None):",
            "    \"\"\"Get node list from the cache.",
            "",
            "    The list of the nodes is ordered based on the (started_at, uuid)",
            "    attribute pair, newer items first.",
            "",
            "    :param ironic: optional ironic client instance",
            "    :param marker: pagination marker (an UUID or None)",
            "    :param limit: pagination limit; None for default CONF.api_max_limit",
            "    :returns: a list of NodeInfo instances.",
            "    \"\"\"",
            "    if marker is not None:",
            "        # uuid marker -> row marker for pagination",
            "        marker = db.model_query(db.Node).get(marker)",
            "        if marker is None:",
            "            raise utils.Error(_('Node not found for marker: %s') % marker,",
            "                              code=404)",
            "",
            "    rows = db.model_query(db.Node)",
            "    # ordered based on (started_at, uuid); newer first",
            "    rows = db_utils.paginate_query(rows, db.Node, limit,",
            "                                   ('started_at', 'uuid'),",
            "                                   marker=marker, sort_dir='desc')",
            "    return [NodeInfo.from_row(row, ironic=ironic) for row in rows]"
        ],
        "afterPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Cache for nodes currently under introspection.\"\"\"",
            "",
            "import collections",
            "import contextlib",
            "import copy",
            "import datetime",
            "import json",
            "import operator",
            "",
            "from automaton import exceptions as automaton_errors",
            "from ironicclient import exceptions",
            "from oslo_concurrency import lockutils",
            "from oslo_config import cfg",
            "from oslo_db.sqlalchemy import utils as db_utils",
            "from oslo_utils import excutils",
            "from oslo_utils import reflection",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import six",
            "from sqlalchemy.orm import exc as orm_errors",
            "",
            "from ironic_inspector.common.i18n import _",
            "from ironic_inspector.common import ironic as ir_utils",
            "from ironic_inspector import db",
            "from ironic_inspector import introspection_state as istate",
            "from ironic_inspector import utils",
            "",
            "",
            "CONF = cfg.CONF",
            "",
            "",
            "LOG = utils.getProcessingLogger(__name__)",
            "",
            "",
            "MACS_ATTRIBUTE = 'mac'",
            "_LOCK_TEMPLATE = 'node-%s'",
            "_SEMAPHORES = lockutils.Semaphores()",
            "",
            "",
            "def _get_lock(uuid):",
            "    \"\"\"Get lock object for a given node UUID.\"\"\"",
            "    return lockutils.internal_lock(_LOCK_TEMPLATE % uuid,",
            "                                   semaphores=_SEMAPHORES)",
            "",
            "",
            "def _get_lock_ctx(uuid):",
            "    \"\"\"Get context manager yielding a lock object for a given node UUID.\"\"\"",
            "    return lockutils.lock(_LOCK_TEMPLATE % uuid, semaphores=_SEMAPHORES)",
            "",
            "",
            "class NodeInfo(object):",
            "    \"\"\"Record about a node in the cache.",
            "",
            "    This class optionally allows to acquire a lock on a node. Note that the",
            "    class instance itself is NOT thread-safe, you need to create a new instance",
            "    for every thread.",
            "    \"\"\"",
            "",
            "    def __init__(self, uuid, version_id=None, state=None, started_at=None,",
            "                 finished_at=None, error=None, node=None, ports=None,",
            "                 ironic=None, lock=None):",
            "        self.uuid = uuid",
            "        self.started_at = started_at",
            "        self.finished_at = finished_at",
            "        self.error = error",
            "        self.invalidate_cache()",
            "        self._version_id = version_id",
            "        self._state = state",
            "        self._node = node",
            "        if ports is not None and not isinstance(ports, dict):",
            "            ports = {p.address: p for p in ports}",
            "        self._ports = ports",
            "        self._attributes = None",
            "        self._ironic = ironic",
            "        # This is a lock on a node UUID, not on a NodeInfo object",
            "        self._lock = lock if lock is not None else _get_lock(uuid)",
            "        # Whether lock was acquired using this NodeInfo object",
            "        self._locked = lock is not None",
            "        self._fsm = None",
            "",
            "    def __del__(self):",
            "        if self._locked:",
            "            LOG.warning('BUG: node lock was not released by the moment '",
            "                        'node info object is deleted')",
            "            self._lock.release()",
            "",
            "    def __str__(self):",
            "        \"\"\"Self represented as an UUID and a state.\"\"\"",
            "        parts = [self.uuid]",
            "        if self._state:",
            "            parts += [_('state'), self._state]",
            "        return ' '.join(parts)",
            "",
            "    def acquire_lock(self, blocking=True):",
            "        \"\"\"Acquire a lock on the associated node.",
            "",
            "        Exits with success if a lock is already acquired using this NodeInfo",
            "        object.",
            "",
            "        :param blocking: if True, wait for lock to be acquired, otherwise",
            "                         return immediately.",
            "        :returns: boolean value, whether lock was acquired successfully",
            "        \"\"\"",
            "        if self._locked:",
            "            return True",
            "",
            "        LOG.debug('Attempting to acquire lock', node_info=self)",
            "        if self._lock.acquire(blocking):",
            "            self._locked = True",
            "            LOG.debug('Successfully acquired lock', node_info=self)",
            "            return True",
            "        else:",
            "            LOG.debug('Unable to acquire lock', node_info=self)",
            "            return False",
            "",
            "    def release_lock(self):",
            "        \"\"\"Release a lock on a node.",
            "",
            "        Does nothing if lock was not acquired using this NodeInfo object.",
            "        \"\"\"",
            "        if self._locked:",
            "            LOG.debug('Successfully released lock', node_info=self)",
            "            self._lock.release()",
            "        self._locked = False",
            "",
            "    @property",
            "    def version_id(self):",
            "        \"\"\"Get the version id\"\"\"",
            "        if self._version_id is None:",
            "            row = db.model_query(db.Node).get(self.uuid)",
            "            if row is None:",
            "                raise utils.NotFoundInCacheError(_('Node not found in the '",
            "                                                   'cache'), node_info=self)",
            "            self._version_id = row.version_id",
            "        return self._version_id",
            "",
            "    def _set_version_id(self, value, session):",
            "        row = self._row(session)",
            "        row.version_id = value",
            "        row.save(session)",
            "        self._version_id = value",
            "",
            "    def _row(self, session=None):",
            "        \"\"\"Get a row from the database with self.uuid and self.version_id\"\"\"",
            "        try:",
            "            # race condition if version_id changed outside of this node_info",
            "            return db.model_query(db.Node, session=session).filter_by(",
            "                uuid=self.uuid, version_id=self.version_id).one()",
            "        except (orm_errors.NoResultFound, orm_errors.StaleDataError):",
            "            raise utils.NodeStateRaceCondition(node_info=self)",
            "",
            "    def _commit(self, **fields):",
            "        \"\"\"Commit the fields into the DB.\"\"\"",
            "        LOG.debug('Committing fields: %s', fields, node_info=self)",
            "        with db.ensure_transaction() as session:",
            "            self._set_version_id(uuidutils.generate_uuid(), session)",
            "            row = self._row(session)",
            "            row.update(fields)",
            "",
            "    def commit(self):",
            "        \"\"\"Commit current node status into the database.\"\"\"",
            "        # state and version_id are updated separately",
            "        self._commit(started_at=self.started_at, finished_at=self.finished_at,",
            "                     error=self.error)",
            "",
            "    @property",
            "    def state(self):",
            "        \"\"\"State of the node_info object.\"\"\"",
            "        if self._state is None:",
            "            row = self._row()",
            "            self._state = row.state",
            "        return self._state",
            "",
            "    def _set_state(self, value):",
            "        self._commit(state=value)",
            "        self._state = value",
            "",
            "    def _get_fsm(self):",
            "        \"\"\"Get an fsm instance initialized with self.state.\"\"\"",
            "        if self._fsm is None:",
            "            self._fsm = istate.FSM.copy(shallow=True)",
            "        self._fsm.initialize(start_state=self.state)",
            "        return self._fsm",
            "",
            "    @contextlib.contextmanager",
            "    def _fsm_ctx(self):",
            "        fsm = self._get_fsm()",
            "        try:",
            "            yield fsm",
            "        finally:",
            "            if fsm.current_state != self.state:",
            "                LOG.info('Updating node state: %(current)s --> %(new)s',",
            "                         {'current': self.state, 'new': fsm.current_state},",
            "                         node_info=self)",
            "                self._set_state(fsm.current_state)",
            "",
            "    def fsm_event(self, event, strict=False):",
            "        \"\"\"Update node_info.state based on a fsm.process_event(event) call.",
            "",
            "        An AutomatonException triggers an error event.",
            "        If strict, node_info.finished(istate.Events.error, error=str(exc))",
            "        is called with the AutomatonException instance and a EventError raised.",
            "",
            "        :param event: an event to process by the fsm",
            "        :strict: whether to fail the introspection upon an invalid event",
            "        :raises: NodeStateInvalidEvent",
            "        \"\"\"",
            "        with self._fsm_ctx() as fsm:",
            "            LOG.debug('Executing fsm(%(state)s).process_event(%(event)s)',",
            "                      {'state': fsm.current_state, 'event': event},",
            "                      node_info=self)",
            "            try:",
            "                fsm.process_event(event)",
            "            except automaton_errors.NotFound as exc:",
            "                msg = _('Invalid event: %s') % exc",
            "                if strict:",
            "                    LOG.error(msg, node_info=self)",
            "                    # assuming an error event is always possible",
            "                    self.finished(istate.Events.error, error=str(exc))",
            "                else:",
            "                    LOG.warning(msg, node_info=self)",
            "                raise utils.NodeStateInvalidEvent(str(exc), node_info=self)",
            "",
            "    @property",
            "    def options(self):",
            "        \"\"\"Node introspection options as a dict.\"\"\"",
            "        if self._options is None:",
            "            rows = db.model_query(db.Option).filter_by(",
            "                uuid=self.uuid)",
            "            self._options = {row.name: json.loads(row.value)",
            "                             for row in rows}",
            "        return self._options",
            "",
            "    @property",
            "    def attributes(self):",
            "        \"\"\"Node look up attributes as a dict.\"\"\"",
            "        if self._attributes is None:",
            "            self._attributes = {}",
            "            rows = db.model_query(db.Attribute).filter_by(",
            "                node_uuid=self.uuid)",
            "            for row in rows:",
            "                self._attributes.setdefault(row.name, []).append(row.value)",
            "        return self._attributes",
            "",
            "    @property",
            "    def ironic(self):",
            "        \"\"\"Ironic client instance.\"\"\"",
            "        if self._ironic is None:",
            "            self._ironic = ir_utils.get_client()",
            "        return self._ironic",
            "",
            "    def set_option(self, name, value):",
            "        \"\"\"Set an option for a node.\"\"\"",
            "        encoded = json.dumps(value)",
            "        self.options[name] = value",
            "        with db.ensure_transaction() as session:",
            "            db.model_query(db.Option, session=session).filter_by(",
            "                uuid=self.uuid, name=name).delete()",
            "            db.Option(uuid=self.uuid, name=name, value=encoded).save(",
            "                session)",
            "",
            "    def finished(self, event, error=None):",
            "        \"\"\"Record status for this node and process a terminal transition.",
            "",
            "        Also deletes look up attributes from the cache.",
            "",
            "        :param event: the event to process",
            "        :param error: error message",
            "        \"\"\"",
            "",
            "        self.release_lock()",
            "        self.finished_at = timeutils.utcnow()",
            "        self.error = error",
            "",
            "        with db.ensure_transaction() as session:",
            "            self.fsm_event(event)",
            "            self._commit(finished_at=self.finished_at, error=self.error)",
            "            db.model_query(db.Attribute, session=session).filter_by(",
            "                node_uuid=self.uuid).delete()",
            "            db.model_query(db.Option, session=session).filter_by(",
            "                uuid=self.uuid).delete()",
            "",
            "    def add_attribute(self, name, value, session=None):",
            "        \"\"\"Store look up attribute for a node in the database.",
            "",
            "        :param name: attribute name",
            "        :param value: attribute value or list of possible values",
            "        :param session: optional existing database session",
            "        \"\"\"",
            "        if not isinstance(value, list):",
            "            value = [value]",
            "",
            "        with db.ensure_transaction(session) as session:",
            "            for v in value:",
            "                db.Attribute(uuid=uuidutils.generate_uuid(), name=name,",
            "                             value=v, node_uuid=self.uuid).save(session)",
            "            # Invalidate attributes so they're loaded on next usage",
            "            self._attributes = None",
            "",
            "    @classmethod",
            "    def from_row(cls, row, ironic=None, lock=None, node=None):",
            "        \"\"\"Construct NodeInfo from a database row.\"\"\"",
            "        fields = {key: row[key]",
            "                  for key in ('uuid', 'version_id', 'state', 'started_at',",
            "                              'finished_at', 'error')}",
            "        return cls(ironic=ironic, lock=lock, node=node, **fields)",
            "",
            "    def invalidate_cache(self):",
            "        \"\"\"Clear all cached info, so that it's reloaded next time.\"\"\"",
            "        self._options = None",
            "        self._node = None",
            "        self._ports = None",
            "        self._attributes = None",
            "        self._ironic = None",
            "        self._fsm = None",
            "        self._state = None",
            "        self._version_id = None",
            "",
            "    def node(self, ironic=None):",
            "        \"\"\"Get Ironic node object associated with the cached node record.\"\"\"",
            "        if self._node is None:",
            "            ironic = ironic or self.ironic",
            "            self._node = ir_utils.get_node(self.uuid, ironic=ironic)",
            "        return self._node",
            "",
            "    def create_ports(self, ports, ironic=None):",
            "        \"\"\"Create one or several ports for this node.",
            "",
            "        :param ports: List of ports with all their attributes",
            "                      e.g  [{'mac': xx, 'ip': xx, 'client_id': None},",
            "                      {'mac': xx, 'ip': None, 'client_id': None}]",
            "                      It also support the old style of list of macs.",
            "                      A warning is issued if port already exists on a node.",
            "",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        existing_macs = []",
            "        for port in ports:",
            "            mac = port",
            "            extra = {}",
            "            pxe_enabled = True",
            "            if isinstance(port, dict):",
            "                mac = port['mac']",
            "                client_id = port.get('client_id')",
            "                if client_id:",
            "                    extra = {'client-id': client_id}",
            "                pxe_enabled = port.get('pxe', True)",
            "",
            "            if mac not in self.ports():",
            "                self._create_port(mac, ironic=ironic, extra=extra,",
            "                                  pxe_enabled=pxe_enabled)",
            "            else:",
            "                existing_macs.append(mac)",
            "",
            "        if existing_macs:",
            "            LOG.warning('Did not create ports %s as they already exist',",
            "                        existing_macs, node_info=self)",
            "",
            "    def ports(self, ironic=None):",
            "        \"\"\"Get Ironic port objects associated with the cached node record.",
            "",
            "        This value is cached as well, use invalidate_cache() to clean.",
            "",
            "        :return: dict MAC -> port object",
            "        \"\"\"",
            "        if self._ports is None:",
            "            ironic = ironic or self.ironic",
            "            port_list = ironic.node.list_ports(self.uuid, limit=0, detail=True)",
            "            self._ports = {p.address: p for p in port_list}",
            "        return self._ports",
            "",
            "    def _create_port(self, mac, ironic=None, **kwargs):",
            "        ironic = ironic or self.ironic",
            "        try:",
            "            port = ironic.port.create(",
            "                node_uuid=self.uuid, address=mac, **kwargs)",
            "            LOG.info('Port %(uuid)s was created successfully, MAC: %(mac)s,'",
            "                     'attributes: %(attrs)s',",
            "                     {'uuid': port.uuid, 'mac': port.address,",
            "                      'attrs': kwargs},",
            "                     node_info=self)",
            "        except exceptions.Conflict:",
            "            LOG.warning('Port %s already exists, skipping',",
            "                        mac, node_info=self)",
            "            # NOTE(dtantsur): we didn't get port object back, so we have to",
            "            # reload ports on next access",
            "            self._ports = None",
            "        else:",
            "            self._ports[mac] = port",
            "",
            "    def patch(self, patches, ironic=None):",
            "        \"\"\"Apply JSON patches to a node.",
            "",
            "        Refreshes cached node instance.",
            "",
            "        :param patches: JSON patches to apply",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        :raises: ironicclient exceptions",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        # NOTE(aarefiev): support path w/o ahead forward slash",
            "        # as Ironic cli does",
            "        for patch in patches:",
            "            if patch.get('path') and not patch['path'].startswith('/'):",
            "                patch['path'] = '/' + patch['path']",
            "",
            "        LOG.debug('Updating node with patches %s', patches, node_info=self)",
            "        self._node = ironic.node.update(self.uuid, patches)",
            "",
            "    def patch_port(self, port, patches, ironic=None):",
            "        \"\"\"Apply JSON patches to a port.",
            "",
            "        :param port: port object or its MAC",
            "        :param patches: JSON patches to apply",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        ports = self.ports()",
            "        if isinstance(port, six.string_types):",
            "            port = ports[port]",
            "",
            "        LOG.debug('Updating port %(mac)s with patches %(patches)s',",
            "                  {'mac': port.address, 'patches': patches},",
            "                  node_info=self)",
            "        new_port = ironic.port.update(port.uuid, patches)",
            "        ports[port.address] = new_port",
            "",
            "    def update_properties(self, ironic=None, **props):",
            "        \"\"\"Update properties on a node.",
            "",
            "        :param props: properties to update",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        patches = [{'op': 'add', 'path': '/properties/%s' % k, 'value': v}",
            "                   for k, v in props.items()]",
            "        self.patch(patches, ironic)",
            "",
            "    def update_capabilities(self, ironic=None, **caps):",
            "        \"\"\"Update capabilities on a node.",
            "",
            "        :param caps: capabilities to update",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        existing = ir_utils.capabilities_to_dict(",
            "            self.node().properties.get('capabilities'))",
            "        existing.update(caps)",
            "        self.update_properties(",
            "            ironic=ironic,",
            "            capabilities=ir_utils.dict_to_capabilities(existing))",
            "",
            "    def delete_port(self, port, ironic=None):",
            "        \"\"\"Delete port.",
            "",
            "        :param port: port object or its MAC",
            "        :param ironic: Ironic client to use instead of self.ironic",
            "        \"\"\"",
            "        ironic = ironic or self.ironic",
            "        ports = self.ports()",
            "        if isinstance(port, six.string_types):",
            "            port = ports[port]",
            "",
            "        ironic.port.delete(port.uuid)",
            "        del ports[port.address]",
            "",
            "    def get_by_path(self, path):",
            "        \"\"\"Get field value by ironic-style path (e.g. /extra/foo).",
            "",
            "        :param path: path to a field",
            "        :returns: field value",
            "        :raises: KeyError if field was not found",
            "        \"\"\"",
            "        path = path.strip('/')",
            "        try:",
            "            if '/' in path:",
            "                prop, key = path.split('/', 1)",
            "                return getattr(self.node(), prop)[key]",
            "            else:",
            "                return getattr(self.node(), path)",
            "        except AttributeError:",
            "            raise KeyError(path)",
            "",
            "    def replace_field(self, path, func, **kwargs):",
            "        \"\"\"Replace a field on ironic node.",
            "",
            "        :param path: path to a field as used by the ironic client",
            "        :param func: function accepting an old value and returning a new one",
            "        :param kwargs: if 'default' value is passed here, it will be used when",
            "                       no existing value is found.",
            "        :raises: KeyError if value is not found and default is not set",
            "        :raises: everything that patch() may raise",
            "        \"\"\"",
            "        ironic = kwargs.pop(\"ironic\", None) or self.ironic",
            "        try:",
            "            value = self.get_by_path(path)",
            "            op = 'replace'",
            "        except KeyError:",
            "            if 'default' in kwargs:",
            "                value = kwargs['default']",
            "                op = 'add'",
            "            else:",
            "                raise",
            "",
            "        ref_value = copy.deepcopy(value)",
            "        value = func(value)",
            "        if value != ref_value:",
            "            self.patch([{'op': op, 'path': path, 'value': value}], ironic)",
            "",
            "",
            "def triggers_fsm_error_transition(errors=(Exception,),",
            "                                  no_errors=(utils.NodeStateInvalidEvent,",
            "                                             utils.NodeStateRaceCondition)):",
            "    \"\"\"Trigger an fsm error transition upon certain errors.",
            "",
            "    It is assumed the first function arg of the decorated function is always a",
            "    NodeInfo instance.",
            "",
            "    :param errors: a tuple of exceptions upon which an error",
            "                   event is triggered. Re-raised.",
            "    :param no_errors: a tuple of exceptions that won't trigger the",
            "                      error event.",
            "    \"\"\"",
            "    def outer(func):",
            "        @six.wraps(func)",
            "        def inner(node_info, *args, **kwargs):",
            "            ret = None",
            "            try:",
            "                ret = func(node_info, *args, **kwargs)",
            "            except no_errors as exc:",
            "                LOG.debug('Not processing error event for the '",
            "                          'exception: %(exc)s raised by %(func)s',",
            "                          {'exc': exc,",
            "                           'func': reflection.get_callable_name(func)},",
            "                          node_info=node_info)",
            "            except errors as exc:",
            "                with excutils.save_and_reraise_exception():",
            "                    LOG.error('Processing the error event because of an '",
            "                              'exception %(exc_type)s: %(exc)s raised by '",
            "                              '%(func)s',",
            "                              {'exc_type': type(exc), 'exc': exc,",
            "                               'func': reflection.get_callable_name(func)},",
            "                              node_info=node_info)",
            "                    # an error event should be possible from all states",
            "                    node_info.finished(istate.Events.error, error=str(exc))",
            "            return ret",
            "        return inner",
            "    return outer",
            "",
            "",
            "def fsm_event_before(event, strict=False):",
            "    \"\"\"Trigger an fsm event before the function execution.",
            "",
            "    It is assumed the first function arg of the decorated function is always a",
            "    NodeInfo instance.",
            "",
            "    :param event: the event to process before the function call",
            "    :param strict: make an invalid fsm event trigger an error event",
            "    \"\"\"",
            "    def outer(func):",
            "        @six.wraps(func)",
            "        def inner(node_info, *args, **kwargs):",
            "            LOG.debug('Processing event %(event)s before calling '",
            "                      '%(func)s', {'event': event, 'func': func},",
            "                      node_info=node_info)",
            "            node_info.fsm_event(event, strict=strict)",
            "            return func(node_info, *args, **kwargs)",
            "        return inner",
            "    return outer",
            "",
            "",
            "def fsm_event_after(event, strict=False):",
            "    \"\"\"Trigger an fsm event after the function execution.",
            "",
            "    It is assumed the first function arg of the decorated function is always a",
            "    NodeInfo instance.",
            "",
            "    :param event: the event to process after the function call",
            "    :param strict: make an invalid fsm event trigger an error event",
            "    \"\"\"",
            "    def outer(func):",
            "        @six.wraps(func)",
            "        def inner(node_info, *args, **kwargs):",
            "            ret = func(node_info, *args, **kwargs)",
            "            LOG.debug('Processing event %(event)s after calling '",
            "                      '%(func)s', {'event': event, 'func': func},",
            "                      node_info=node_info)",
            "            node_info.fsm_event(event, strict=strict)",
            "            return ret",
            "        return inner",
            "    return outer",
            "",
            "",
            "def fsm_transition(event, reentrant=True, **exc_kwargs):",
            "    \"\"\"Decorate a function to perform a (non-)reentrant transition.",
            "",
            "    If True, reentrant transition will be performed at the end of a function",
            "    call. If False, the transition will be performed before the function call.",
            "    The function is decorated with the triggers_fsm_error_transition decorator",
            "    as well.",
            "",
            "    :param event: the event to bind the transition to.",
            "    :param reentrant: whether the transition is reentrant.",
            "    :param exc_kwargs: passed on to the triggers_fsm_error_transition decorator",
            "    \"\"\"",
            "    def outer(func):",
            "        inner = triggers_fsm_error_transition(**exc_kwargs)(func)",
            "        if not reentrant:",
            "            return fsm_event_before(event, strict=True)(inner)",
            "        return fsm_event_after(event)(inner)",
            "    return outer",
            "",
            "",
            "def release_lock(func):",
            "    \"\"\"Decorate a node_info-function to release the node_info lock.",
            "",
            "    Assumes the first parameter of the function func is always a NodeInfo",
            "    instance.",
            "",
            "    \"\"\"",
            "    @six.wraps(func)",
            "    def inner(node_info, *args, **kwargs):",
            "        try:",
            "            return func(node_info, *args, **kwargs)",
            "        finally:",
            "            # FIXME(milan) hacking the test cases to work",
            "            # with release_lock.assert_called_once...",
            "            if node_info._locked:",
            "                node_info.release_lock()",
            "    return inner",
            "",
            "",
            "def start_introspection(uuid, **kwargs):",
            "    \"\"\"Start the introspection of a node.",
            "",
            "    If a node_info record exists in the DB, a start transition is used rather",
            "    than dropping the record in order to check for the start transition",
            "    validity in particular node state.",
            "",
            "    :param uuid: Ironic node UUID",
            "    :param kwargs: passed on to add_node()",
            "    :raises: NodeStateInvalidEvent in case the start transition is invalid in",
            "             the current node state",
            "    :raises: NodeStateRaceCondition if a mismatch was detected between the",
            "             node_info cache and the DB",
            "    :returns: NodeInfo",
            "    \"\"\"",
            "    with db.ensure_transaction():",
            "        node_info = NodeInfo(uuid)",
            "        # check that the start transition is possible",
            "        try:",
            "            node_info.fsm_event(istate.Events.start)",
            "        except utils.NotFoundInCacheError:",
            "            # node not found while in the fsm_event handler",
            "            LOG.debug('Node missing in the cache; adding it now',",
            "                      node_info=node_info)",
            "            state = istate.States.starting",
            "        else:",
            "            state = node_info.state",
            "        return add_node(uuid, state, **kwargs)",
            "",
            "",
            "def add_node(uuid, state, **attributes):",
            "    \"\"\"Store information about a node under introspection.",
            "",
            "    All existing information about this node is dropped.",
            "    Empty values are skipped.",
            "",
            "    :param uuid: Ironic node UUID",
            "    :param state: The initial state of the node",
            "    :param attributes: attributes known about this node (like macs, BMC etc);",
            "                       also ironic client instance may be passed under 'ironic'",
            "    :returns: NodeInfo",
            "    \"\"\"",
            "    started_at = timeutils.utcnow()",
            "    with db.ensure_transaction() as session:",
            "        _delete_node(uuid)",
            "        version_id = uuidutils.generate_uuid()",
            "        db.Node(uuid=uuid, state=state, version_id=version_id,",
            "                started_at=started_at).save(session)",
            "",
            "        node_info = NodeInfo(uuid=uuid, state=state, started_at=started_at,",
            "                             version_id=version_id,",
            "                             ironic=attributes.pop('ironic', None))",
            "        for (name, value) in attributes.items():",
            "            if not value:",
            "                continue",
            "            node_info.add_attribute(name, value, session=session)",
            "",
            "    return node_info",
            "",
            "",
            "def delete_nodes_not_in_list(uuids):",
            "    \"\"\"Delete nodes which don't exist in Ironic node UUIDs.",
            "",
            "    :param uuids: Ironic node UUIDs",
            "    \"\"\"",
            "    inspector_uuids = _list_node_uuids()",
            "    for uuid in inspector_uuids - uuids:",
            "        LOG.warning('Node %s was deleted from Ironic, dropping from Ironic '",
            "                    'Inspector database', uuid)",
            "        with _get_lock_ctx(uuid):",
            "            _delete_node(uuid)",
            "",
            "",
            "def _delete_node(uuid, session=None):",
            "    \"\"\"Delete information about a node.",
            "",
            "    :param uuid: Ironic node UUID",
            "    :param session: optional existing database session",
            "    \"\"\"",
            "    with db.ensure_transaction(session) as session:",
            "        db.model_query(db.Attribute, session=session).filter_by(",
            "            node_uuid=uuid).delete()",
            "        for model in (db.Option, db.Node):",
            "            db.model_query(model,",
            "                           session=session).filter_by(uuid=uuid).delete()",
            "",
            "",
            "def introspection_active():",
            "    \"\"\"Check if introspection is active for at least one node.\"\"\"",
            "    # FIXME(dtantsur): is there a better way to express it?",
            "    return (db.model_query(db.Node.uuid).filter_by(finished_at=None).first()",
            "            is not None)",
            "",
            "",
            "def active_macs():",
            "    \"\"\"List all MAC's that are on introspection right now.\"\"\"",
            "    return ({x.value for x in db.model_query(db.Attribute.value).",
            "            filter_by(name=MACS_ATTRIBUTE)})",
            "",
            "",
            "def _list_node_uuids():",
            "    \"\"\"Get all nodes' uuid from cache.",
            "",
            "    :returns: Set of nodes' uuid.",
            "    \"\"\"",
            "    return {x.uuid for x in db.model_query(db.Node.uuid)}",
            "",
            "",
            "def get_node(node_id, ironic=None, locked=False):",
            "    \"\"\"Get node from cache.",
            "",
            "    :param node_id: node UUID or name.",
            "    :param ironic: optional ironic client instance",
            "    :param locked: if True, get a lock on node before fetching its data",
            "    :returns: structure NodeInfo.",
            "    \"\"\"",
            "    if uuidutils.is_uuid_like(node_id):",
            "        node = None",
            "        uuid = node_id",
            "    else:",
            "        node = ir_utils.get_node(node_id, ironic=ironic)",
            "        uuid = node.uuid",
            "",
            "    if locked:",
            "        lock = _get_lock(uuid)",
            "        lock.acquire()",
            "    else:",
            "        lock = None",
            "",
            "    try:",
            "        row = db.model_query(db.Node).filter_by(uuid=uuid).first()",
            "        if row is None:",
            "            raise utils.Error(_('Could not find node %s in cache') % uuid,",
            "                              code=404)",
            "        return NodeInfo.from_row(row, ironic=ironic, lock=lock, node=node)",
            "    except Exception:",
            "        with excutils.save_and_reraise_exception():",
            "            if lock is not None:",
            "                lock.release()",
            "",
            "",
            "def find_node(**attributes):",
            "    \"\"\"Find node in cache.",
            "",
            "    Looks up a node based on attributes in a best-match fashion.",
            "    This function acquires a lock on a node.",
            "",
            "    :param attributes: attributes known about this node (like macs, BMC etc)",
            "                       also ironic client instance may be passed under 'ironic'",
            "    :returns: structure NodeInfo with attributes ``uuid`` and ``created_at``",
            "    :raises: Error if node is not found or multiple nodes match the attributes",
            "    \"\"\"",
            "    ironic = attributes.pop('ironic', None)",
            "    # NOTE(dtantsur): sorting is not required, but gives us predictability",
            "    found = collections.Counter()",
            "",
            "    for (name, value) in sorted(attributes.items()):",
            "        if not value:",
            "            LOG.debug('Empty value for attribute %s', name)",
            "            continue",
            "        if not isinstance(value, list):",
            "            value = [value]",
            "",
            "        LOG.debug('Trying to use %s of value %s for node look up',",
            "                  name, value)",
            "        query = db.model_query(db.Attribute.node_uuid)",
            "        pairs = [(db.Attribute.name == name) &",
            "                 (db.Attribute.value == v) for v in value]",
            "        query = query.filter(six.moves.reduce(operator.or_, pairs))",
            "        found.update(row.node_uuid for row in query.distinct().all())",
            "",
            "    if not found:",
            "        raise utils.NotFoundInCacheError(_(",
            "            'Could not find a node for attributes %s') % attributes)",
            "",
            "    most_common = found.most_common()",
            "    LOG.debug('The following nodes match the attributes: %(attributes)s, '",
            "              'scoring: %(most_common)s',",
            "              {'most_common': ', '.join('%s: %d' % tpl for tpl in most_common),",
            "               'attributes': ', '.join('%s=%s' % tpl for tpl in",
            "                                       attributes.items())})",
            "",
            "    # NOTE(milan) most_common is sorted, higher scores first",
            "    highest_score = most_common[0][1]",
            "    found = [item[0] for item in most_common if highest_score == item[1]]",
            "    if len(found) > 1:",
            "        raise utils.Error(_(",
            "            'Multiple nodes match the same number of attributes '",
            "            '%(attr)s: %(found)s')",
            "            % {'attr': attributes, 'found': found}, code=404)",
            "",
            "    uuid = found.pop()",
            "    node_info = NodeInfo(uuid=uuid, ironic=ironic)",
            "    node_info.acquire_lock()",
            "",
            "    try:",
            "        row = (db.model_query(db.Node.started_at, db.Node.finished_at).",
            "               filter_by(uuid=uuid).first())",
            "",
            "        if not row:",
            "            raise utils.Error(_(",
            "                'Could not find node %s in introspection cache, '",
            "                'probably it\\'s not on introspection now') % uuid, code=404)",
            "",
            "        if row.finished_at:",
            "            raise utils.Error(_(",
            "                'Introspection for node %(node)s already finished on '",
            "                '%(finish)s') % {'node': uuid, 'finish': row.finished_at})",
            "",
            "        node_info.started_at = row.started_at",
            "        return node_info",
            "    except Exception:",
            "        with excutils.save_and_reraise_exception():",
            "            node_info.release_lock()",
            "",
            "",
            "def clean_up():",
            "    \"\"\"Clean up the cache.",
            "",
            "    * Finish introspection for timed out nodes.",
            "    * Drop outdated node status information.",
            "",
            "    :return: list of timed out node UUID's",
            "    \"\"\"",
            "    if CONF.node_status_keep_time > 0:",
            "        status_keep_threshold = (timeutils.utcnow() - datetime.timedelta(",
            "                                 seconds=CONF.node_status_keep_time))",
            "        with db.ensure_transaction() as session:",
            "            db.model_query(db.Node, session=session).filter(",
            "                db.Node.finished_at.isnot(None),",
            "                db.Node.finished_at < status_keep_threshold).delete()",
            "",
            "    timeout = CONF.timeout",
            "    if timeout <= 0:",
            "        return []",
            "    threshold = timeutils.utcnow() - datetime.timedelta(seconds=timeout)",
            "    uuids = [row.uuid for row in",
            "             db.model_query(db.Node.uuid).filter(",
            "                 db.Node.started_at < threshold,",
            "                 db.Node.finished_at.is_(None)).all()]",
            "",
            "    if not uuids:",
            "        return []",
            "",
            "    LOG.error('Introspection for nodes %s has timed out', uuids)",
            "    for u in uuids:",
            "        node_info = get_node(u, locked=True)",
            "        try:",
            "            if node_info.finished_at or node_info.started_at > threshold:",
            "                continue",
            "            if node_info.state != istate.States.waiting:",
            "                LOG.error('Something went wrong, timeout occurred '",
            "                          'while introspection in \"%s\" state',",
            "                          node_info.state,",
            "                          node_info=node_info)",
            "            node_info.finished(",
            "                istate.Events.timeout, error='Introspection timeout')",
            "        finally:",
            "            node_info.release_lock()",
            "",
            "    return uuids",
            "",
            "",
            "def create_node(driver, ironic=None, **attributes):",
            "    \"\"\"Create ironic node and cache it.",
            "",
            "    * Create new node in ironic.",
            "    * Cache it in inspector.",
            "    * Sets node_info state to enrolling.",
            "",
            "    :param driver: driver for Ironic node.",
            "    :param ironic: ronic client instance.",
            "    :param attributes: dict, additional keyword arguments to pass",
            "                             to the ironic client on node creation.",
            "    :return: NodeInfo, or None in case error happened.",
            "    \"\"\"",
            "    if ironic is None:",
            "        ironic = ir_utils.get_client()",
            "    try:",
            "        node = ironic.node.create(driver=driver, **attributes)",
            "    except exceptions.InvalidAttribute as e:",
            "        LOG.error('Failed to create new node: %s', e)",
            "    else:",
            "        LOG.info('Node %s was created successfully', node.uuid)",
            "        return add_node(node.uuid, istate.States.enrolling, ironic=ironic)",
            "",
            "",
            "def get_node_list(ironic=None, marker=None, limit=None):",
            "    \"\"\"Get node list from the cache.",
            "",
            "    The list of the nodes is ordered based on the (started_at, uuid)",
            "    attribute pair, newer items first.",
            "",
            "    :param ironic: optional ironic client instance",
            "    :param marker: pagination marker (an UUID or None)",
            "    :param limit: pagination limit; None for default CONF.api_max_limit",
            "    :returns: a list of NodeInfo instances.",
            "    \"\"\"",
            "    if marker is not None:",
            "        # uuid marker -> row marker for pagination",
            "        marker = db.model_query(db.Node).get(marker)",
            "        if marker is None:",
            "            raise utils.Error(_('Node not found for marker: %s') % marker,",
            "                              code=404)",
            "",
            "    rows = db.model_query(db.Node)",
            "    # ordered based on (started_at, uuid); newer first",
            "    rows = db_utils.paginate_query(rows, db.Node, limit,",
            "                                   ('started_at', 'uuid'),",
            "                                   marker=marker, sort_dir='desc')",
            "    return [NodeInfo.from_row(row, ironic=ironic) for row in rows]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "33": [],
            "810": [
                "find_node"
            ],
            "811": [
                "find_node"
            ],
            "812": [
                "find_node"
            ],
            "813": [
                "find_node"
            ],
            "814": [
                "find_node"
            ],
            "815": [
                "find_node"
            ],
            "816": [
                "find_node"
            ],
            "817": [
                "find_node"
            ]
        },
        "addLocation": []
    },
    "ironic_inspector/test/unit/test_node_cache.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 303,
                "PatchRowcode": "         self.assertRaises(utils.Error, node_cache.find_node,"
            },
            "1": {
                "beforePatchRowNumber": 304,
                "afterPatchRowNumber": 304,
                "PatchRowcode": "                           bmc_address='1.2.3.4')"
            },
            "2": {
                "beforePatchRowNumber": 305,
                "afterPatchRowNumber": 305,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 306,
                "PatchRowcode": "+    def test_input_filtering(self):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 307,
                "PatchRowcode": "+        self.assertRaises(utils.NotFoundInCacheError,"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 308,
                "PatchRowcode": "+                          node_cache.find_node,"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 309,
                "PatchRowcode": "+                          bmc_address=\"' OR ''='\")"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 310,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": 306,
                "afterPatchRowNumber": 311,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 307,
                "afterPatchRowNumber": 312,
                "PatchRowcode": " class TestNodeCacheCleanUp(test_base.NodeTest):"
            },
            "10": {
                "beforePatchRowNumber": 308,
                "afterPatchRowNumber": 313,
                "PatchRowcode": "     def setUp(self):"
            }
        },
        "frontPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import copy",
            "import datetime",
            "import json",
            "import unittest",
            "",
            "import automaton",
            "import mock",
            "from oslo_config import cfg",
            "import oslo_db",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import six",
            "",
            "from ironic_inspector.common import ironic as ir_utils",
            "from ironic_inspector import db",
            "from ironic_inspector import introspection_state as istate",
            "from ironic_inspector import node_cache",
            "from ironic_inspector.test import base as test_base",
            "from ironic_inspector import utils",
            "",
            "CONF = cfg.CONF",
            "",
            "",
            "class TestNodeCache(test_base.NodeTest):",
            "    def test_add_node(self):",
            "        # Ensure previous node information is cleared",
            "        uuid2 = uuidutils.generate_uuid()",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "            db.Node(uuid=uuid2,",
            "                    state=istate.States.starting).save(session)",
            "            db.Attribute(uuid=uuidutils.generate_uuid(), name='mac',",
            "                         value='11:22:11:22:11:22',",
            "                         node_uuid=self.uuid).save(session)",
            "",
            "        node = node_cache.add_node(self.node.uuid,",
            "                                   istate.States.starting,",
            "                                   mac=self.macs, bmc_address='1.2.3.4',",
            "                                   foo=None)",
            "        self.assertEqual(self.uuid, node.uuid)",
            "        self.assertTrue(",
            "            (datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "                < node.started_at <",
            "             datetime.datetime.utcnow() + datetime.timedelta(seconds=60)))",
            "        self.assertFalse(node._locked)",
            "",
            "        res = set(db.model_query(db.Node.uuid,",
            "                                 db.Node.started_at).all())",
            "",
            "        expected = {(node.uuid, node.started_at), (uuid2, None)}",
            "        self.assertEqual(expected, res)",
            "",
            "        res = db.model_query(db.Node).get(self.uuid)",
            "        self.assertIsNotNone(res.version_id)",
            "",
            "        res = (db.model_query(db.Attribute.name,",
            "                              db.Attribute.value, db.Attribute.node_uuid).",
            "               order_by(db.Attribute.name, db.Attribute.value).all())",
            "        self.assertEqual([('bmc_address', '1.2.3.4', self.uuid),",
            "                          ('mac', self.macs[0], self.uuid),",
            "                          ('mac', self.macs[1], self.uuid),",
            "                          ('mac', self.macs[2], self.uuid)],",
            "                         [(row.name, row.value, row.node_uuid) for row in res])",
            "",
            "    def test__delete_node(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.finished).save(session)",
            "            db.Attribute(uuid=uuidutils.generate_uuid(), name='mac',",
            "                         value='11:22:11:22:11:22', node_uuid=self.uuid).save(",
            "                             session)",
            "            data = {'s': 'value', 'b': True, 'i': 42}",
            "            encoded = json.dumps(data)",
            "            db.Option(uuid=self.uuid, name='name', value=encoded).save(",
            "                session)",
            "",
            "        node_cache._delete_node(self.uuid)",
            "        session = db.get_writer_session()",
            "        row_node = db.model_query(db.Node).filter_by(",
            "            uuid=self.uuid).first()",
            "        self.assertIsNone(row_node)",
            "        row_attribute = db.model_query(db.Attribute).filter_by(",
            "            node_uuid=self.uuid).first()",
            "        self.assertIsNone(row_attribute)",
            "        row_option = db.model_query(db.Option).filter_by(",
            "            uuid=self.uuid).first()",
            "        self.assertIsNone(row_option)",
            "",
            "    @mock.patch.object(node_cache, '_get_lock_ctx', autospec=True)",
            "    @mock.patch.object(node_cache, '_list_node_uuids')",
            "    @mock.patch.object(node_cache, '_delete_node')",
            "    def test_delete_nodes_not_in_list(self, mock__delete_node,",
            "                                      mock__list_node_uuids,",
            "                                      mock__get_lock_ctx):",
            "        uuid2 = uuidutils.generate_uuid()",
            "        uuids = {self.uuid}",
            "        mock__list_node_uuids.return_value = {self.uuid, uuid2}",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            node_cache.delete_nodes_not_in_list(uuids)",
            "        mock__delete_node.assert_called_once_with(uuid2)",
            "        mock__get_lock_ctx.assert_called_once_with(uuid2)",
            "        mock__get_lock_ctx.return_value.__enter__.assert_called_once_with()",
            "",
            "    def test_active_macs(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "            values = [('mac', '11:22:11:22:11:22', self.uuid),",
            "                      ('mac', '22:11:22:11:22:11', self.uuid)]",
            "            for value in values:",
            "                db.Attribute(uuid=uuidutils.generate_uuid(), name=value[0],",
            "                             value=value[1], node_uuid=value[2]).save(session)",
            "        self.assertEqual({'11:22:11:22:11:22', '22:11:22:11:22:11'},",
            "                         node_cache.active_macs())",
            "",
            "    def test__list_node_uuids(self):",
            "        session = db.get_writer_session()",
            "        uuid2 = uuidutils.generate_uuid()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "            db.Node(uuid=uuid2,",
            "                    state=istate.States.starting).save(session)",
            "",
            "        node_uuid_list = node_cache._list_node_uuids()",
            "        self.assertEqual({self.uuid, uuid2}, node_uuid_list)",
            "",
            "    def test_add_attribute(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=42)",
            "        node_info.add_attribute('key', 'value')",
            "        res = db.model_query(db.Attribute.name,",
            "                             db.Attribute.value,",
            "                             db.Attribute.node_uuid,",
            "                             session=session)",
            "        res = res.order_by(db.Attribute.name, db.Attribute.value).all()",
            "        self.assertEqual([('key', 'value', self.uuid)],",
            "                         [tuple(row) for row in res])",
            "        # check that .attributes got invalidated and reloaded",
            "        self.assertEqual({'key': ['value']}, node_info.attributes)",
            "",
            "    def test_add_attribute_same_name(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=42)",
            "",
            "        node_info.add_attribute('key', ['foo', 'bar'])",
            "        node_info.add_attribute('key', 'baz')",
            "        res = db.model_query(db.Attribute.name, db.Attribute.value,",
            "                             db.Attribute.node_uuid, session=session)",
            "        res = res.order_by(db.Attribute.name, db.Attribute.value).all()",
            "        self.assertEqual([('key', 'bar', self.uuid),",
            "                          ('key', 'baz', self.uuid),",
            "                          ('key', 'foo', self.uuid)],",
            "                         [tuple(row) for row in res])",
            "",
            "    def test_add_attribute_same_value(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=42)",
            "",
            "        node_info.add_attribute('key', 'value')",
            "        node_info.add_attribute('key', 'value')",
            "        res = db.model_query(db.Attribute.name, db.Attribute.value,",
            "                             db.Attribute.node_uuid, session=session)",
            "        self.assertEqual([('key', 'value', self.uuid),",
            "                          ('key', 'value', self.uuid)],",
            "                         [tuple(row) for row in res])",
            "",
            "    def test_attributes(self):",
            "        node_info = node_cache.add_node(self.uuid,",
            "                                        istate.States.starting,",
            "                                        bmc_address='1.2.3.4',",
            "                                        mac=self.macs)",
            "        self.assertEqual({'bmc_address': ['1.2.3.4'],",
            "                          'mac': self.macs},",
            "                         node_info.attributes)",
            "        # check invalidation",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Attribute(uuid=uuidutils.generate_uuid(), name='foo',",
            "                         value='bar', node_uuid=self.uuid).save(session)",
            "        # still cached",
            "        self.assertEqual({'bmc_address': ['1.2.3.4'],",
            "                          'mac': self.macs},",
            "                         node_info.attributes)",
            "        node_info.invalidate_cache()",
            "        self.assertEqual({'bmc_address': ['1.2.3.4'],",
            "                          'mac': self.macs, 'foo': ['bar']},",
            "                         node_info.attributes)",
            "",
            "",
            "class TestNodeCacheFind(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheFind, self).setUp()",
            "        self.macs2 = ['00:00:00:00:00:00']",
            "        node_cache.add_node(self.uuid,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs)",
            "",
            "    def test_no_data(self):",
            "        self.assertRaises(utils.Error, node_cache.find_node)",
            "        self.assertRaises(utils.Error, node_cache.find_node, mac=[])",
            "",
            "    def test_bmc(self):",
            "        res = node_cache.find_node(bmc_address='1.2.3.4')",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        self.assertTrue(",
            "            datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "            < res.started_at <",
            "            datetime.datetime.utcnow() + datetime.timedelta(seconds=1))",
            "        self.assertTrue(res._locked)",
            "",
            "    def test_same_bmc_different_macs(self):",
            "        uuid2 = uuidutils.generate_uuid()",
            "        node_cache.add_node(uuid2,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs2)",
            "        res = node_cache.find_node(bmc_address='1.2.3.4', mac=self.macs)",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        res = node_cache.find_node(bmc_address='1.2.3.4', mac=self.macs2)",
            "        self.assertEqual(uuid2, res.uuid)",
            "",
            "    def test_same_bmc_raises(self):",
            "        uuid2 = uuidutils.generate_uuid()",
            "        node_cache.add_node(uuid2,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4')",
            "        six.assertRaisesRegex(self, utils.Error, 'Multiple nodes',",
            "                              node_cache.find_node, bmc_address='1.2.3.4')",
            "",
            "    def test_macs(self):",
            "        res = node_cache.find_node(mac=['11:22:33:33:33:33', self.macs[1]])",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        self.assertTrue(",
            "            datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "            < res.started_at <",
            "            datetime.datetime.utcnow() + datetime.timedelta(seconds=1))",
            "        self.assertTrue(res._locked)",
            "",
            "    def test_macs_not_found(self):",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          mac=['11:22:33:33:33:33',",
            "                               '66:66:44:33:22:11'])",
            "",
            "    def test_macs_multiple_found(self):",
            "        node_cache.add_node('uuid2',",
            "                            istate.States.starting,",
            "                            mac=self.macs2)",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          mac=[self.macs[0], self.macs2[0]])",
            "",
            "    def test_both(self):",
            "        res = node_cache.find_node(bmc_address='1.2.3.4',",
            "                                   mac=self.macs)",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        self.assertTrue(",
            "            datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "            < res.started_at <",
            "            datetime.datetime.utcnow() + datetime.timedelta(seconds=1))",
            "        self.assertTrue(res._locked)",
            "",
            "    def test_inconsistency(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            (db.model_query(db.Node).filter_by(uuid=self.uuid).",
            "                delete())",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          bmc_address='1.2.3.4')",
            "",
            "    def test_already_finished(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            (db.model_query(db.Node).filter_by(uuid=self.uuid).",
            "                update({'finished_at': datetime.datetime.utcnow()}))",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          bmc_address='1.2.3.4')",
            "",
            "",
            "class TestNodeCacheCleanUp(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheCleanUp, self).setUp()",
            "        self.started_at = datetime.datetime.utcnow()",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.waiting,",
            "                    started_at=self.started_at).save(",
            "                session)",
            "            for v in self.macs:",
            "                db.Attribute(uuid=uuidutils.generate_uuid(), name='mac',",
            "                             value=v, node_uuid=self.uuid).save(session)",
            "            db.Option(uuid=self.uuid, name='foo', value='bar').save(",
            "                session)",
            "",
            "    def test_no_timeout(self):",
            "        CONF.set_override('timeout', 0)",
            "",
            "        self.assertFalse(node_cache.clean_up())",
            "",
            "        res = [tuple(row) for row in",
            "               db.model_query(db.Node.finished_at,",
            "                              db.Node.error).all()]",
            "        self.assertEqual([(None, None)], res)",
            "        self.assertEqual(len(self.macs),",
            "                         db.model_query(db.Attribute).count())",
            "        self.assertEqual(1, db.model_query(db.Option).count())",
            "",
            "    @mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "    @mock.patch.object(timeutils, 'utcnow')",
            "    def test_ok(self, time_mock, get_lock_mock):",
            "        time_mock.return_value = datetime.datetime.utcnow()",
            "",
            "        self.assertFalse(node_cache.clean_up())",
            "",
            "        res = [tuple(row) for row in db.model_query(",
            "            db.Node.finished_at, db.Node.error).all()]",
            "        self.assertEqual([(None, None)], res)",
            "        self.assertEqual(len(self.macs),",
            "                         db.model_query(db.Attribute).count())",
            "        self.assertEqual(1, db.model_query(db.Option).count())",
            "        self.assertFalse(get_lock_mock.called)",
            "",
            "    @mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "    @mock.patch.object(timeutils, 'utcnow')",
            "    def test_timeout(self, time_mock, get_lock_mock):",
            "        # Add a finished node to confirm we don't try to timeout it",
            "        time_mock.return_value = self.started_at",
            "        session = db.get_writer_session()",
            "        finished_at = self.started_at + datetime.timedelta(seconds=60)",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid + '1', started_at=self.started_at,",
            "                    state=istate.States.waiting,",
            "                    finished_at=finished_at).save(session)",
            "        CONF.set_override('timeout', 99)",
            "        time_mock.return_value = (self.started_at +",
            "                                  datetime.timedelta(seconds=100))",
            "",
            "        self.assertEqual([self.uuid], node_cache.clean_up())",
            "",
            "        res = [(row.state, row.finished_at, row.error) for row in",
            "               db.model_query(db.Node).all()]",
            "        self.assertEqual(",
            "            [(istate.States.error,",
            "              self.started_at + datetime.timedelta(seconds=100),",
            "              'Introspection timeout'),",
            "             (istate.States.waiting,",
            "              self.started_at + datetime.timedelta(seconds=60), None)],",
            "            res)",
            "        self.assertEqual([], db.model_query(db.Attribute).all())",
            "        self.assertEqual([], db.model_query(db.Option).all())",
            "        get_lock_mock.assert_called_once_with(self.uuid)",
            "        get_lock_mock.return_value.acquire.assert_called_once_with()",
            "",
            "    @mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "    @mock.patch.object(timeutils, 'utcnow')",
            "    def test_timeout_active_state(self, time_mock, get_lock_mock):",
            "        time_mock.return_value = self.started_at",
            "        session = db.get_writer_session()",
            "        CONF.set_override('timeout', 1)",
            "        for state in [istate.States.starting, istate.States.enrolling,",
            "                      istate.States.processing, istate.States.reapplying]:",
            "            db.model_query(db.Node, session=session).filter_by(",
            "                uuid=self.uuid).update({'state': state, 'finished_at': None})",
            "",
            "            current_time = self.started_at + datetime.timedelta(seconds=2)",
            "            time_mock.return_value = current_time",
            "",
            "            self.assertEqual([self.uuid], node_cache.clean_up())",
            "",
            "            res = [(row.state, row.finished_at, row.error) for row in",
            "                   db.model_query(db.Node).all()]",
            "            self.assertEqual(",
            "                [(istate.States.error, current_time, 'Introspection timeout')],",
            "                res)",
            "",
            "    def test_old_status(self):",
            "        CONF.set_override('node_status_keep_time', 42)",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.model_query(db.Node).update(",
            "                {'finished_at': (datetime.datetime.utcnow() -",
            "                                 datetime.timedelta(seconds=100))})",
            "",
            "        self.assertEqual([], node_cache.clean_up())",
            "",
            "        self.assertEqual([], db.model_query(db.Node).all())",
            "",
            "    def test_old_status_disabled(self):",
            "        # Status clean up is disabled by default",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.model_query(db.Node).update(",
            "                {'finished_at': (datetime.datetime.utcnow() -",
            "                                 datetime.timedelta(days=10000))})",
            "",
            "        self.assertEqual([], node_cache.clean_up())",
            "",
            "        self.assertNotEqual([], db.model_query(db.Node).all())",
            "",
            "",
            "class TestNodeCacheGetNode(test_base.NodeTest):",
            "    def test_ok(self):",
            "        started_at = (datetime.datetime.utcnow() -",
            "                      datetime.timedelta(seconds=42))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.starting,",
            "                    started_at=started_at).save(session)",
            "        info = node_cache.get_node(self.uuid)",
            "",
            "        self.assertEqual(self.uuid, info.uuid)",
            "        self.assertEqual(started_at, info.started_at)",
            "        self.assertIsNone(info.finished_at)",
            "        self.assertIsNone(info.error)",
            "        self.assertFalse(info._locked)",
            "",
            "    def test_locked(self):",
            "        started_at = (datetime.datetime.utcnow() -",
            "                      datetime.timedelta(seconds=42))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.starting,",
            "                    started_at=started_at).save(session)",
            "        info = node_cache.get_node(self.uuid, locked=True)",
            "",
            "        self.assertEqual(self.uuid, info.uuid)",
            "        self.assertEqual(started_at, info.started_at)",
            "        self.assertIsNone(info.finished_at)",
            "        self.assertIsNone(info.error)",
            "        self.assertTrue(info._locked)",
            "",
            "    def test_not_found(self):",
            "        self.assertRaises(utils.Error, node_cache.get_node,",
            "                          uuidutils.generate_uuid())",
            "",
            "    def test_with_name(self):",
            "        started_at = (datetime.datetime.utcnow() -",
            "                      datetime.timedelta(seconds=42))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.starting,",
            "                    started_at=started_at).save(session)",
            "        ironic = mock.Mock()",
            "        ironic.node.get.return_value = self.node",
            "",
            "        info = node_cache.get_node('name', ironic=ironic)",
            "",
            "        self.assertEqual(self.uuid, info.uuid)",
            "        self.assertEqual(started_at, info.started_at)",
            "        self.assertIsNone(info.finished_at)",
            "        self.assertIsNone(info.error)",
            "        self.assertFalse(info._locked)",
            "        ironic.node.get.assert_called_once_with('name')",
            "",
            "",
            "@mock.patch.object(timeutils, 'utcnow', lambda: datetime.datetime(1, 1, 1))",
            "class TestNodeInfoFinished(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeInfoFinished, self).setUp()",
            "        node_cache.add_node(self.uuid,",
            "                            istate.States.processing,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs)",
            "        self.node_info = node_cache.NodeInfo(",
            "            uuid=self.uuid, started_at=datetime.datetime(3, 1, 4))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Option(uuid=self.uuid, name='foo', value='bar').save(",
            "                session)",
            "",
            "    def test_success(self):",
            "        self.node_info.finished(istate.Events.finish)",
            "",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            self.assertEqual((datetime.datetime(1, 1, 1), None),",
            "                             tuple(db.model_query(",
            "                                   db.Node.finished_at,",
            "                                   db.Node.error).first()))",
            "            self.assertEqual([], db.model_query(db.Attribute,",
            "                             session=session).all())",
            "            self.assertEqual([], db.model_query(db.Option,",
            "                             session=session).all())",
            "",
            "    def test_error(self):",
            "        self.node_info.finished(istate.Events.error, error='boom')",
            "",
            "        self.assertEqual((datetime.datetime(1, 1, 1), 'boom'),",
            "                         tuple(db.model_query(db.Node.finished_at,",
            "                               db.Node.error).first()))",
            "        self.assertEqual([], db.model_query(db.Attribute).all())",
            "        self.assertEqual([], db.model_query(db.Option).all())",
            "",
            "    def test_release_lock(self):",
            "        self.node_info.acquire_lock()",
            "        self.node_info.finished(istate.Events.finish)",
            "        self.assertFalse(self.node_info._locked)",
            "",
            "",
            "class TestNodeInfoOptions(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeInfoOptions, self).setUp()",
            "        node_cache.add_node(self.uuid,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs)",
            "        self.node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=3.14)",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Option(uuid=self.uuid, name='foo', value='\"bar\"').save(",
            "                session)",
            "",
            "    def test_get(self):",
            "        self.assertEqual({'foo': 'bar'}, self.node_info.options)",
            "        # should be cached",
            "        self.assertEqual(self.node_info.options, self.node_info.options)",
            "        # invalidate cache",
            "        old_options = self.node_info.options",
            "        self.node_info.invalidate_cache()",
            "        self.assertIsNot(old_options, self.node_info.options)",
            "        self.assertEqual(old_options, self.node_info.options)",
            "",
            "    def test_set(self):",
            "        data = {'s': 'value', 'b': True, 'i': 42}",
            "        self.node_info.set_option('name', data)",
            "        self.assertEqual(data, self.node_info.options['name'])",
            "",
            "        new = node_cache.NodeInfo(uuid=self.uuid, started_at=3.14)",
            "        self.assertEqual(data, new.options['name'])",
            "",
            "",
            "@mock.patch.object(ir_utils, 'get_client', autospec=True)",
            "class TestNodeCacheIronicObjects(unittest.TestCase):",
            "    def setUp(self):",
            "        super(TestNodeCacheIronicObjects, self).setUp()",
            "        self.ports = {'mac1': mock.Mock(address='mac1', spec=['address']),",
            "                      'mac2': mock.Mock(address='mac2', spec=['address'])}",
            "        self.uuid = uuidutils.generate_uuid()",
            "",
            "    def test_node_provided(self, mock_ironic):",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        node=mock.sentinel.node)",
            "        self.assertIs(mock.sentinel.node, node_info.node())",
            "        self.assertFalse(mock_ironic.called)",
            "",
            "    def test_node_not_provided(self, mock_ironic):",
            "        mock_ironic.return_value.node.get.return_value = mock.sentinel.node",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0)",
            "",
            "        self.assertIs(mock.sentinel.node, node_info.node())",
            "        self.assertIs(node_info.node(), node_info.node())",
            "",
            "        mock_ironic.assert_called_once_with()",
            "        mock_ironic.return_value.node.get.assert_called_once_with(self.uuid)",
            "",
            "    def test_node_ironic_preset(self, mock_ironic):",
            "        mock_ironic2 = mock.Mock()",
            "        mock_ironic2.node.get.return_value = mock.sentinel.node",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ironic=mock_ironic2)",
            "        self.assertIs(mock.sentinel.node, node_info.node())",
            "",
            "        self.assertFalse(mock_ironic.called)",
            "        mock_ironic2.node.get.assert_called_once_with(self.uuid)",
            "",
            "    def test_ports_provided(self, mock_ironic):",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ports=self.ports)",
            "        self.assertIs(self.ports, node_info.ports())",
            "        self.assertFalse(mock_ironic.called)",
            "",
            "    def test_ports_provided_list(self, mock_ironic):",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ports=list(self.ports.values()))",
            "        self.assertEqual(self.ports, node_info.ports())",
            "        self.assertFalse(mock_ironic.called)",
            "",
            "    def test_ports_not_provided(self, mock_ironic):",
            "        mock_ironic.return_value.node.list_ports.return_value = list(",
            "            self.ports.values())",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0)",
            "",
            "        self.assertEqual(self.ports, node_info.ports())",
            "        self.assertIs(node_info.ports(), node_info.ports())",
            "",
            "        mock_ironic.assert_called_once_with()",
            "        mock_ironic.return_value.node.list_ports.assert_called_once_with(",
            "            self.uuid, limit=0, detail=True)",
            "",
            "    def test_ports_ironic_preset(self, mock_ironic):",
            "        mock_ironic2 = mock.Mock()",
            "        mock_ironic2.node.list_ports.return_value = list(",
            "            self.ports.values())",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ironic=mock_ironic2)",
            "        self.assertEqual(self.ports, node_info.ports())",
            "",
            "        self.assertFalse(mock_ironic.called)",
            "        mock_ironic2.node.list_ports.assert_called_once_with(",
            "            self.uuid, limit=0, detail=True)",
            "",
            "",
            "class TestUpdate(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestUpdate, self).setUp()",
            "        self.ironic = mock.Mock()",
            "        self.ports = {'mac%d' % i: mock.Mock(address='mac%d' % i, uuid=str(i))",
            "                      for i in range(2)}",
            "        self.node_info = node_cache.NodeInfo(uuid=self.uuid,",
            "                                             started_at=0,",
            "                                             node=self.node,",
            "                                             ports=self.ports,",
            "                                             ironic=self.ironic)",
            "",
            "    def test_patch(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.node_info.patch([{'patch': 'patch'}])",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid,",
            "                                                        [{'patch': 'patch'}])",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_patch_path_wo_leading_slash(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        patch = [{'op': 'add', 'path': 'driver_info/test', 'value': 42}]",
            "        expected_patch = copy.deepcopy(patch)",
            "        expected_patch[0]['path'] = '/' + 'driver_info/test'",
            "",
            "        self.node_info.patch(patch)",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid,",
            "                                                        expected_patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_patch_path_with_leading_slash(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        patch = [{'op': 'add', 'path': '/driver_info/test', 'value': 42}]",
            "",
            "        self.node_info.patch(patch)",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_update_properties(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.node_info.update_properties(prop=42)",
            "",
            "        patch = [{'op': 'add', 'path': '/properties/prop', 'value': 42}]",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_update_capabilities(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "        self.node.properties['capabilities'] = 'foo:bar,x:y'",
            "",
            "        self.node_info.update_capabilities(x=1, y=2)",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, mock.ANY)",
            "        patch = self.ironic.node.update.call_args[0][1]",
            "        new_caps = ir_utils.capabilities_to_dict(patch[0]['value'])",
            "        self.assertEqual({'foo': 'bar', 'x': '1', 'y': '2'}, new_caps)",
            "",
            "    def test_replace_field(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "        self.node.extra['foo'] = 'bar'",
            "",
            "        self.node_info.replace_field('/extra/foo', lambda v: v + '1')",
            "",
            "        patch = [{'op': 'replace', 'path': '/extra/foo', 'value': 'bar1'}]",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_replace_field_not_found(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.assertRaises(KeyError, self.node_info.replace_field,",
            "                          '/extra/foo', lambda v: v + '1')",
            "",
            "    def test_replace_field_with_default(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.node_info.replace_field('/extra/foo', lambda v: v + [42],",
            "                                     default=[])",
            "",
            "        patch = [{'op': 'add', 'path': '/extra/foo', 'value': [42]}]",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_replace_field_same_value(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "        self.node.extra['foo'] = 'bar'",
            "",
            "        self.node_info.replace_field('/extra/foo', lambda v: v)",
            "        self.assertFalse(self.ironic.node.update.called)",
            "",
            "    def test_patch_port(self):",
            "        self.ironic.port.update.return_value = mock.sentinel.port",
            "",
            "        self.node_info.patch_port(self.ports['mac0'], ['patch'])",
            "",
            "        self.ironic.port.update.assert_called_once_with('0', ['patch'])",
            "        self.assertIs(mock.sentinel.port,",
            "                      self.node_info.ports()['mac0'])",
            "",
            "    def test_patch_port_by_mac(self):",
            "        self.ironic.port.update.return_value = mock.sentinel.port",
            "",
            "        self.node_info.patch_port('mac0', ['patch'])",
            "",
            "        self.ironic.port.update.assert_called_once_with('0', ['patch'])",
            "        self.assertIs(mock.sentinel.port,",
            "                      self.node_info.ports()['mac0'])",
            "",
            "    def test_delete_port(self):",
            "        self.node_info.delete_port(self.ports['mac0'])",
            "",
            "        self.ironic.port.delete.assert_called_once_with('0')",
            "        self.assertEqual(['mac1'], list(self.node_info.ports()))",
            "",
            "    def test_delete_port_by_mac(self):",
            "        self.node_info.delete_port('mac0')",
            "",
            "        self.ironic.port.delete.assert_called_once_with('0')",
            "        self.assertEqual(['mac1'], list(self.node_info.ports()))",
            "",
            "    @mock.patch.object(node_cache.LOG, 'warning', autospec=True)",
            "    def test_create_ports(self, mock_warn):",
            "        ports = [",
            "            'mac2',",
            "            {'mac': 'mac3', 'client_id': '42', 'pxe': False},",
            "            {'mac': 'mac4', 'pxe': True}",
            "        ]",
            "",
            "        self.node_info.create_ports(ports)",
            "        self.assertEqual({'mac0', 'mac1', 'mac2', 'mac3', 'mac4'},",
            "                         set(self.node_info.ports()))",
            "",
            "        create_calls = [",
            "            mock.call(node_uuid=self.uuid, address='mac2', extra={},",
            "                      pxe_enabled=True),",
            "            mock.call(node_uuid=self.uuid, address='mac3',",
            "                      extra={'client-id': '42'}, pxe_enabled=False),",
            "            mock.call(node_uuid=self.uuid, address='mac4', extra={},",
            "                      pxe_enabled=True),",
            "        ]",
            "        self.assertEqual(create_calls, self.ironic.port.create.call_args_list)",
            "        # No conflicts - cache was not cleared - no calls to port.list",
            "        self.assertFalse(mock_warn.called)",
            "        self.assertFalse(self.ironic.port.list.called)",
            "",
            "    @mock.patch.object(node_cache.LOG, 'info', autospec=True)",
            "    def test__create_port(self, mock_info):",
            "        uuid = uuidutils.generate_uuid()",
            "        address = 'mac1'",
            "        self.ironic.port.create.return_value = mock.Mock(uuid=uuid,",
            "                                                         address=address)",
            "",
            "        self.node_info._create_port(address, client_id='42')",
            "",
            "        self.ironic.port.create.assert_called_once_with(",
            "            node_uuid=self.uuid, address='mac1', client_id='42')",
            "        mock_info.assert_called_once_with(",
            "            mock.ANY, {'uuid': uuid, 'mac': address,",
            "                       'attrs': {'client_id': '42'}},",
            "            node_info=self.node_info)",
            "",
            "    @mock.patch.object(node_cache.LOG, 'warning', autospec=True)",
            "    def test_create_ports_with_conflicts(self, mock_warn):",
            "        self.ironic.port.create.return_value = mock.Mock(",
            "            uuid='fake', address='mac')",
            "",
            "        ports = [",
            "            'mac',",
            "            {'mac': 'mac0'},",
            "            'mac1',",
            "            {'mac': 'mac2', 'client_id': '42', 'pxe': False},",
            "        ]",
            "",
            "        self.node_info.create_ports(ports)",
            "",
            "        create_calls = [",
            "            mock.call(node_uuid=self.uuid, address='mac', extra={},",
            "                      pxe_enabled=True),",
            "            mock.call(node_uuid=self.uuid, address='mac2',",
            "                      extra={'client-id': '42'}, pxe_enabled=False),",
            "        ]",
            "        self.assertEqual(create_calls, self.ironic.port.create.call_args_list)",
            "        mock_warn.assert_called_once_with(mock.ANY, ['mac0', 'mac1'],",
            "                                          node_info=self.node_info)",
            "",
            "",
            "class TestNodeCacheGetByPath(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheGetByPath, self).setUp()",
            "        self.node = mock.Mock(spec=['uuid', 'properties'],",
            "                              properties={'answer': 42},",
            "                              uuid=self.uuid)",
            "        self.node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                             node=self.node)",
            "",
            "    def test_get_by_path(self):",
            "        self.assertEqual(self.uuid, self.node_info.get_by_path('/uuid'))",
            "        self.assertEqual(self.uuid, self.node_info.get_by_path('uuid'))",
            "        self.assertEqual(42, self.node_info.get_by_path('/properties/answer'))",
            "        self.assertRaises(KeyError, self.node_info.get_by_path, '/foo')",
            "        self.assertRaises(KeyError, self.node_info.get_by_path, '/extra/foo')",
            "",
            "",
            "@mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "class TestLock(test_base.NodeTest):",
            "    def test_acquire(self, get_lock_mock):",
            "        node_info = node_cache.NodeInfo(self.uuid)",
            "        self.assertFalse(node_info._locked)",
            "        get_lock_mock.assert_called_once_with(self.uuid)",
            "        self.assertFalse(get_lock_mock.return_value.acquire.called)",
            "",
            "        self.assertTrue(node_info.acquire_lock())",
            "        self.assertTrue(node_info._locked)",
            "        self.assertTrue(node_info.acquire_lock())",
            "        self.assertTrue(node_info._locked)",
            "        get_lock_mock.return_value.acquire.assert_called_once_with(True)",
            "",
            "    def test_release(self, get_lock_mock):",
            "        node_info = node_cache.NodeInfo(self.uuid)",
            "        node_info.acquire_lock()",
            "        self.assertTrue(node_info._locked)",
            "        node_info.release_lock()",
            "        self.assertFalse(node_info._locked)",
            "        node_info.release_lock()",
            "        self.assertFalse(node_info._locked)",
            "        get_lock_mock.return_value.acquire.assert_called_once_with(True)",
            "        get_lock_mock.return_value.release.assert_called_once_with()",
            "",
            "    def test_acquire_non_blocking(self, get_lock_mock):",
            "        node_info = node_cache.NodeInfo(self.uuid)",
            "        self.assertFalse(node_info._locked)",
            "        get_lock_mock.return_value.acquire.side_effect = iter([False, True])",
            "",
            "        self.assertFalse(node_info.acquire_lock(blocking=False))",
            "        self.assertFalse(node_info._locked)",
            "        self.assertTrue(node_info.acquire_lock(blocking=False))",
            "        self.assertTrue(node_info._locked)",
            "        self.assertTrue(node_info.acquire_lock(blocking=False))",
            "        self.assertTrue(node_info._locked)",
            "        get_lock_mock.return_value.acquire.assert_called_with(False)",
            "        self.assertEqual(2, get_lock_mock.return_value.acquire.call_count)",
            "",
            "",
            "@mock.patch.object(node_cache, 'add_node', autospec=True)",
            "@mock.patch.object(ir_utils, 'get_client', autospec=True)",
            "class TestNodeCreate(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCreate, self).setUp()",
            "        self.mock_client = mock.Mock()",
            "",
            "    def test_default_create(self, mock_get_client, mock_add_node):",
            "        mock_get_client.return_value = self.mock_client",
            "        self.mock_client.node.create.return_value = self.node",
            "",
            "        node_cache.create_node('fake')",
            "",
            "        self.mock_client.node.create.assert_called_once_with(driver='fake')",
            "        mock_add_node.assert_called_once_with(",
            "            self.node.uuid,",
            "            istate.States.enrolling,",
            "            ironic=self.mock_client)",
            "",
            "    def test_create_with_args(self, mock_get_client, mock_add_node):",
            "        mock_get_client.return_value = self.mock_client",
            "        self.mock_client.node.create.return_value = self.node",
            "",
            "        node_cache.create_node('agent_ipmitool', ironic=self.mock_client)",
            "",
            "        self.assertFalse(mock_get_client.called)",
            "        self.mock_client.node.create.assert_called_once_with(",
            "            driver='agent_ipmitool')",
            "        mock_add_node.assert_called_once_with(",
            "            self.node.uuid,",
            "            istate.States.enrolling,",
            "            ironic=self.mock_client)",
            "",
            "    def test_create_client_error(self, mock_get_client, mock_add_node):",
            "        mock_get_client.return_value = self.mock_client",
            "        self.mock_client.node.create.side_effect = (",
            "            node_cache.exceptions.InvalidAttribute)",
            "",
            "        node_cache.create_node('fake')",
            "",
            "        mock_get_client.assert_called_once_with()",
            "        self.mock_client.node.create.assert_called_once_with(driver='fake')",
            "        self.assertFalse(mock_add_node.called)",
            "",
            "",
            "class TestNodeCacheListNode(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheListNode, self).setUp()",
            "        self.uuid2 = uuidutils.generate_uuid()",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    started_at=datetime.datetime(1, 1, 2)).save(session)",
            "            db.Node(uuid=self.uuid2, started_at=datetime.datetime(1, 1, 1),",
            "                    finished_at=datetime.datetime(1, 1, 3)).save(session)",
            "",
            "    # mind please node(self.uuid).started_at > node(self.uuid2).started_at",
            "    # and the result ordering is strict in node_cache.get_node_list newer first",
            "",
            "    def test_list_node(self):",
            "        nodes = node_cache.get_node_list()",
            "",
            "        self.assertEqual([self.uuid, self.uuid2],",
            "                         [node.uuid for node in nodes])",
            "",
            "    def test_list_node_limit(self):",
            "        nodes = node_cache.get_node_list(limit=1)",
            "        self.assertEqual([self.uuid], [node.uuid for node in nodes])",
            "",
            "    def test_list_node_marker(self):",
            "        # get nodes started_at after node(self.uuid)",
            "        nodes = node_cache.get_node_list(marker=self.uuid)",
            "        self.assertEqual([self.uuid2], [node.uuid for node in nodes])",
            "",
            "    def test_list_node_wrong_marker(self):",
            "        self.assertRaises(utils.Error, node_cache.get_node_list,",
            "                          marker='foo-bar')",
            "",
            "",
            "class TestNodeInfoVersionId(test_base.NodeStateTest):",
            "    def test_get(self):",
            "        self.node_info._version_id = None",
            "        self.assertEqual(self.db_node.version_id, self.node_info.version_id)",
            "",
            "    def test_get_missing_uuid(self):",
            "        self.node_info.uuid = 'foo'",
            "        self.node_info._version_id = None",
            "",
            "        def func():",
            "            return self.node_info.version_id",
            "",
            "        six.assertRaisesRegex(self, utils.NotFoundInCacheError, '.*', func)",
            "",
            "    def test_set(self):",
            "        with db.ensure_transaction() as session:",
            "            self.node_info._set_version_id(uuidutils.generate_uuid(),",
            "                                           session)",
            "        row = db.model_query(db.Node).get(self.node_info.uuid)",
            "        self.assertEqual(self.node_info.version_id, row.version_id)",
            "",
            "    def test_set_race(self):",
            "        with db.ensure_transaction() as session:",
            "            row = db.model_query(db.Node, session=session).get(",
            "                self.node_info.uuid)",
            "            row.update({'version_id': uuidutils.generate_uuid()})",
            "            row.save(session)",
            "",
            "        six.assertRaisesRegex(self, utils.NodeStateRaceCondition,",
            "                              'Node state mismatch', self.node_info._set_state,",
            "                              istate.States.finished)",
            "",
            "",
            "class TestNodeInfoState(test_base.NodeStateTest):",
            "    def test_get(self):",
            "        self.node_info._state = None",
            "        self.assertEqual(self.db_node.state, self.node_info.state)",
            "",
            "    def test_set(self):",
            "        self.node_info._set_state(istate.States.finished)",
            "        row = db.model_query(db.Node).get(self.node_info.uuid)",
            "        self.assertEqual(self.node_info.state, row.state)",
            "",
            "    def test_set_invalid_state(self):",
            "        six.assertRaisesRegex(self, oslo_db.exception.DBError,",
            "                              'constraint failed',",
            "                              self.node_info._set_state, 'foo')",
            "",
            "    def test_commit(self):",
            "        current_time = timeutils.utcnow()",
            "        self.node_info.started_at = self.node_info.finished_at = current_time",
            "        self.node_info.error = \"Boo!\"",
            "        self.node_info.commit()",
            "",
            "        row = db.model_query(db.Node).get(self.node_info.uuid)",
            "        self.assertEqual(self.node_info.started_at, row.started_at)",
            "        self.assertEqual(self.node_info.finished_at, row.finished_at)",
            "        self.assertEqual(self.node_info.error, row.error)",
            "",
            "",
            "class TestNodeInfoStateFsm(test_base.NodeStateTest):",
            "    def test__get_fsm(self):",
            "        self.node_info._fsm = None",
            "        fsm = self.node_info._get_fsm()",
            "        self.assertEqual(self.node_info.state, fsm.current_state)",
            "",
            "    def test__get_fsm_invalid_state(self):",
            "        self.node_info._fsm = None",
            "        self.node_info._state = 'foo'",
            "        six.assertRaisesRegex(self, automaton.exceptions.NotFound,",
            "                              '.*undefined state.*',",
            "                              self.node_info._get_fsm)",
            "",
            "    def test__fsm_ctx_set_state(self):",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            fsm.process_event(istate.Events.wait)",
            "            self.assertEqual(self.node_info.state, istate.States.starting)",
            "        self.assertEqual(self.node_info.state, istate.States.waiting)",
            "",
            "    def test__fsm_ctx_set_same_state(self):",
            "        version_id = self.node_info.version_id",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            fsm.initialize(self.node_info.state)",
            "        self.assertEqual(version_id, self.node_info.version_id)",
            "",
            "    def test__fsm_ctx_illegal_event(self):",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            six.assertRaisesRegex(self, automaton.exceptions.NotFound,",
            "                                  'no defined transition', fsm.process_event,",
            "                                  istate.Events.finish)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test__fsm_ctx_generic_exception(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        def func(fsm):",
            "            fsm.process_event(istate.Events.wait)",
            "            raise CustomException('Oops')",
            "",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            self.assertRaises(CustomException, func, fsm)",
            "        self.assertEqual(self.node_info.state, istate.States.waiting)",
            "",
            "    def test_fsm_event(self):",
            "        self.node_info.fsm_event(istate.Events.wait)",
            "        self.assertEqual(self.node_info.state, istate.States.waiting)",
            "",
            "    def test_fsm_illegal_event(self):",
            "        six.assertRaisesRegex(self, utils.NodeStateInvalidEvent,",
            "                              'no defined transition',",
            "                              self.node_info.fsm_event, istate.Events.finish)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test_fsm_illegal_strict_event(self):",
            "        six.assertRaisesRegex(self, utils.NodeStateInvalidEvent,",
            "                              'no defined transition',",
            "                              self.node_info.fsm_event,",
            "                              istate.Events.finish, strict=True)",
            "        self.assertIn('no defined transition', self.node_info.error)",
            "        self.assertEqual(self.node_info.state, istate.States.error)",
            "",
            "",
            "class TestFsmEvent(test_base.NodeStateTest):",
            "    def test_event_before(self):",
            "        @node_cache.fsm_event_before(istate.Events.wait)",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.waiting)",
            "            node_info.fsm_event(istate.Events.process)",
            "",
            "        function(self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.processing)",
            "",
            "    def test_event_after(self):",
            "        @node_cache.fsm_event_after(istate.Events.process)",
            "        def function(node_info):",
            "            node_info.fsm_event(istate.Events.wait)",
            "            self.assertEqual(node_info.state, istate.States.waiting)",
            "",
            "        function(self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.processing)",
            "",
            "    @mock.patch.object(node_cache, 'LOG', autospec=True)",
            "    def test_triggers_fsm_error_transition_no_errors(self, log_mock):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(no_errors=(CustomException,))",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops')",
            "",
            "        function(self.node_info)",
            "        log_msg = ('Not processing error event for the exception: '",
            "                   '%(exc)s raised by %(func)s')",
            "        log_mock.debug.assert_called_with(log_msg, mock.ANY,",
            "                                          node_info=mock.ANY)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test_triggers_fsm_error_transition_no_errors_empty(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(no_errors=())",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops!')",
            "",
            "        # assert an error event was performed",
            "        self.assertRaises(CustomException, function, self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.error)",
            "",
            "    def test_triggers_fsm_error_transition_no_errors_with_error(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(errors=(CustomException,))",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops')",
            "",
            "        # assert a generic error triggers an error event",
            "        self.assertRaises(CustomException, function, self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.error)",
            "",
            "    def test_triggers_fsm_error_transition_erros_masked(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(errors=())",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops')",
            "",
            "        # assert no error event was triggered",
            "        self.assertRaises(CustomException, function, self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test_unlock(self):",
            "        @node_cache.release_lock",
            "        def func(node_info):",
            "            self.assertTrue(node_info._locked)",
            "",
            "        self.node_info.acquire_lock(blocking=True)",
            "        with mock.patch.object(self.node_info, 'release_lock',",
            "                               autospec=True) as release_lock_mock:",
            "            func(self.node_info)",
            "        release_lock_mock.assert_called_once_with()",
            "",
            "    def test_unlock_unlocked(self):",
            "        @node_cache.release_lock",
            "        def func(node_info):",
            "            self.assertFalse(node_info._locked)",
            "",
            "        self.node_info.release_lock()",
            "        with mock.patch.object(self.node_info, 'release_lock',",
            "                               autospec=True) as release_lock_mock:",
            "            func(self.node_info)",
            "        self.assertEqual(0, release_lock_mock.call_count)",
            "",
            "    @mock.patch.object(node_cache, 'triggers_fsm_error_transition',",
            "                       autospec=True)",
            "    @mock.patch.object(node_cache, 'fsm_event_after', autospec=True)",
            "    def test_fsm_transition(self, fsm_event_after_mock, trigger_mock):",
            "        @node_cache.fsm_transition(istate.Events.finish)",
            "        def func():",
            "            pass",
            "        fsm_event_after_mock.assert_called_once_with(istate.Events.finish)",
            "        trigger_mock.assert_called_once_with()",
            "",
            "    @mock.patch.object(node_cache, 'triggers_fsm_error_transition',",
            "                       autospec=True)",
            "    @mock.patch.object(node_cache, 'fsm_event_before', autospec=True)",
            "    def test_nonreentrant_fsm_transition(self, fsm_event_before_mock,",
            "                                         trigger_mock):",
            "        @node_cache.fsm_transition(istate.Events.abort, reentrant=False)",
            "        def func():",
            "            pass",
            "        fsm_event_before_mock.assert_called_once_with(istate.Events.abort,",
            "                                                      strict=True)",
            "        trigger_mock.assert_called_once_with()",
            "",
            "",
            "@mock.patch.object(node_cache, 'add_node', autospec=True)",
            "@mock.patch.object(node_cache, 'NodeInfo', autospec=True)",
            "class TestStartIntrospection(test_base.NodeTest):",
            "    def prepare_mocks(fn):",
            "        @six.wraps(fn)",
            "        def inner(self, NodeMock, *args):",
            "            method_mock = mock.Mock()",
            "            NodeMock.return_value = self.node_info",
            "            self.node_info.fsm_event = method_mock",
            "            fn(self, method_mock, *args)",
            "            method_mock.assert_called_once_with(istate.Events.start)",
            "        return inner",
            "",
            "    @prepare_mocks",
            "    def test_node_in_db_ok_state(self, fsm_event_mock, add_node_mock):",
            "        def side_effect(*args):",
            "            self.node_info._state = 'foo'",
            "",
            "        fsm_event_mock.side_effect = side_effect",
            "        node_cache.start_introspection(self.node.uuid)",
            "        add_node_mock.assert_called_once_with(self.node_info.uuid, 'foo')",
            "",
            "    @prepare_mocks",
            "    def test_node_in_db_invalid_state(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.NodeStateInvalidEvent('Oops!')",
            "        six.assertRaisesRegex(self, utils.NodeStateInvalidEvent, 'Oops!',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)",
            "",
            "    @prepare_mocks",
            "    def test_node_in_db_race_condition(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.NodeStateRaceCondition()",
            "        six.assertRaisesRegex(self, utils.NodeStateRaceCondition, '.*',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)",
            "",
            "    @prepare_mocks",
            "    def test_error_fsm_event(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.Error('Oops!')",
            "        six.assertRaisesRegex(self, utils.Error, 'Oops!',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)",
            "",
            "    @prepare_mocks",
            "    def test_node_not_in_db(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.NotFoundInCacheError('Oops!')",
            "        node_cache.start_introspection(self.node_info.uuid)",
            "        add_node_mock.assert_called_once_with(self.node_info.uuid,",
            "                                              istate.States.starting)",
            "",
            "    @prepare_mocks",
            "    def test_custom_exc_fsm_event(self, fsm_event_mock, add_node_mock):",
            "        class CustomError(Exception):",
            "            pass",
            "",
            "        fsm_event_mock.side_effect = CustomError('Oops!')",
            "        six.assertRaisesRegex(self, CustomError, 'Oops!',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)"
        ],
        "afterPatchFile": [
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "import copy",
            "import datetime",
            "import json",
            "import unittest",
            "",
            "import automaton",
            "import mock",
            "from oslo_config import cfg",
            "import oslo_db",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import six",
            "",
            "from ironic_inspector.common import ironic as ir_utils",
            "from ironic_inspector import db",
            "from ironic_inspector import introspection_state as istate",
            "from ironic_inspector import node_cache",
            "from ironic_inspector.test import base as test_base",
            "from ironic_inspector import utils",
            "",
            "CONF = cfg.CONF",
            "",
            "",
            "class TestNodeCache(test_base.NodeTest):",
            "    def test_add_node(self):",
            "        # Ensure previous node information is cleared",
            "        uuid2 = uuidutils.generate_uuid()",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "            db.Node(uuid=uuid2,",
            "                    state=istate.States.starting).save(session)",
            "            db.Attribute(uuid=uuidutils.generate_uuid(), name='mac',",
            "                         value='11:22:11:22:11:22',",
            "                         node_uuid=self.uuid).save(session)",
            "",
            "        node = node_cache.add_node(self.node.uuid,",
            "                                   istate.States.starting,",
            "                                   mac=self.macs, bmc_address='1.2.3.4',",
            "                                   foo=None)",
            "        self.assertEqual(self.uuid, node.uuid)",
            "        self.assertTrue(",
            "            (datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "                < node.started_at <",
            "             datetime.datetime.utcnow() + datetime.timedelta(seconds=60)))",
            "        self.assertFalse(node._locked)",
            "",
            "        res = set(db.model_query(db.Node.uuid,",
            "                                 db.Node.started_at).all())",
            "",
            "        expected = {(node.uuid, node.started_at), (uuid2, None)}",
            "        self.assertEqual(expected, res)",
            "",
            "        res = db.model_query(db.Node).get(self.uuid)",
            "        self.assertIsNotNone(res.version_id)",
            "",
            "        res = (db.model_query(db.Attribute.name,",
            "                              db.Attribute.value, db.Attribute.node_uuid).",
            "               order_by(db.Attribute.name, db.Attribute.value).all())",
            "        self.assertEqual([('bmc_address', '1.2.3.4', self.uuid),",
            "                          ('mac', self.macs[0], self.uuid),",
            "                          ('mac', self.macs[1], self.uuid),",
            "                          ('mac', self.macs[2], self.uuid)],",
            "                         [(row.name, row.value, row.node_uuid) for row in res])",
            "",
            "    def test__delete_node(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.finished).save(session)",
            "            db.Attribute(uuid=uuidutils.generate_uuid(), name='mac',",
            "                         value='11:22:11:22:11:22', node_uuid=self.uuid).save(",
            "                             session)",
            "            data = {'s': 'value', 'b': True, 'i': 42}",
            "            encoded = json.dumps(data)",
            "            db.Option(uuid=self.uuid, name='name', value=encoded).save(",
            "                session)",
            "",
            "        node_cache._delete_node(self.uuid)",
            "        session = db.get_writer_session()",
            "        row_node = db.model_query(db.Node).filter_by(",
            "            uuid=self.uuid).first()",
            "        self.assertIsNone(row_node)",
            "        row_attribute = db.model_query(db.Attribute).filter_by(",
            "            node_uuid=self.uuid).first()",
            "        self.assertIsNone(row_attribute)",
            "        row_option = db.model_query(db.Option).filter_by(",
            "            uuid=self.uuid).first()",
            "        self.assertIsNone(row_option)",
            "",
            "    @mock.patch.object(node_cache, '_get_lock_ctx', autospec=True)",
            "    @mock.patch.object(node_cache, '_list_node_uuids')",
            "    @mock.patch.object(node_cache, '_delete_node')",
            "    def test_delete_nodes_not_in_list(self, mock__delete_node,",
            "                                      mock__list_node_uuids,",
            "                                      mock__get_lock_ctx):",
            "        uuid2 = uuidutils.generate_uuid()",
            "        uuids = {self.uuid}",
            "        mock__list_node_uuids.return_value = {self.uuid, uuid2}",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            node_cache.delete_nodes_not_in_list(uuids)",
            "        mock__delete_node.assert_called_once_with(uuid2)",
            "        mock__get_lock_ctx.assert_called_once_with(uuid2)",
            "        mock__get_lock_ctx.return_value.__enter__.assert_called_once_with()",
            "",
            "    def test_active_macs(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "            values = [('mac', '11:22:11:22:11:22', self.uuid),",
            "                      ('mac', '22:11:22:11:22:11', self.uuid)]",
            "            for value in values:",
            "                db.Attribute(uuid=uuidutils.generate_uuid(), name=value[0],",
            "                             value=value[1], node_uuid=value[2]).save(session)",
            "        self.assertEqual({'11:22:11:22:11:22', '22:11:22:11:22:11'},",
            "                         node_cache.active_macs())",
            "",
            "    def test__list_node_uuids(self):",
            "        session = db.get_writer_session()",
            "        uuid2 = uuidutils.generate_uuid()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "            db.Node(uuid=uuid2,",
            "                    state=istate.States.starting).save(session)",
            "",
            "        node_uuid_list = node_cache._list_node_uuids()",
            "        self.assertEqual({self.uuid, uuid2}, node_uuid_list)",
            "",
            "    def test_add_attribute(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=42)",
            "        node_info.add_attribute('key', 'value')",
            "        res = db.model_query(db.Attribute.name,",
            "                             db.Attribute.value,",
            "                             db.Attribute.node_uuid,",
            "                             session=session)",
            "        res = res.order_by(db.Attribute.name, db.Attribute.value).all()",
            "        self.assertEqual([('key', 'value', self.uuid)],",
            "                         [tuple(row) for row in res])",
            "        # check that .attributes got invalidated and reloaded",
            "        self.assertEqual({'key': ['value']}, node_info.attributes)",
            "",
            "    def test_add_attribute_same_name(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=42)",
            "",
            "        node_info.add_attribute('key', ['foo', 'bar'])",
            "        node_info.add_attribute('key', 'baz')",
            "        res = db.model_query(db.Attribute.name, db.Attribute.value,",
            "                             db.Attribute.node_uuid, session=session)",
            "        res = res.order_by(db.Attribute.name, db.Attribute.value).all()",
            "        self.assertEqual([('key', 'bar', self.uuid),",
            "                          ('key', 'baz', self.uuid),",
            "                          ('key', 'foo', self.uuid)],",
            "                         [tuple(row) for row in res])",
            "",
            "    def test_add_attribute_same_value(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.node.uuid,",
            "                    state=istate.States.starting).save(session)",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=42)",
            "",
            "        node_info.add_attribute('key', 'value')",
            "        node_info.add_attribute('key', 'value')",
            "        res = db.model_query(db.Attribute.name, db.Attribute.value,",
            "                             db.Attribute.node_uuid, session=session)",
            "        self.assertEqual([('key', 'value', self.uuid),",
            "                          ('key', 'value', self.uuid)],",
            "                         [tuple(row) for row in res])",
            "",
            "    def test_attributes(self):",
            "        node_info = node_cache.add_node(self.uuid,",
            "                                        istate.States.starting,",
            "                                        bmc_address='1.2.3.4',",
            "                                        mac=self.macs)",
            "        self.assertEqual({'bmc_address': ['1.2.3.4'],",
            "                          'mac': self.macs},",
            "                         node_info.attributes)",
            "        # check invalidation",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Attribute(uuid=uuidutils.generate_uuid(), name='foo',",
            "                         value='bar', node_uuid=self.uuid).save(session)",
            "        # still cached",
            "        self.assertEqual({'bmc_address': ['1.2.3.4'],",
            "                          'mac': self.macs},",
            "                         node_info.attributes)",
            "        node_info.invalidate_cache()",
            "        self.assertEqual({'bmc_address': ['1.2.3.4'],",
            "                          'mac': self.macs, 'foo': ['bar']},",
            "                         node_info.attributes)",
            "",
            "",
            "class TestNodeCacheFind(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheFind, self).setUp()",
            "        self.macs2 = ['00:00:00:00:00:00']",
            "        node_cache.add_node(self.uuid,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs)",
            "",
            "    def test_no_data(self):",
            "        self.assertRaises(utils.Error, node_cache.find_node)",
            "        self.assertRaises(utils.Error, node_cache.find_node, mac=[])",
            "",
            "    def test_bmc(self):",
            "        res = node_cache.find_node(bmc_address='1.2.3.4')",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        self.assertTrue(",
            "            datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "            < res.started_at <",
            "            datetime.datetime.utcnow() + datetime.timedelta(seconds=1))",
            "        self.assertTrue(res._locked)",
            "",
            "    def test_same_bmc_different_macs(self):",
            "        uuid2 = uuidutils.generate_uuid()",
            "        node_cache.add_node(uuid2,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs2)",
            "        res = node_cache.find_node(bmc_address='1.2.3.4', mac=self.macs)",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        res = node_cache.find_node(bmc_address='1.2.3.4', mac=self.macs2)",
            "        self.assertEqual(uuid2, res.uuid)",
            "",
            "    def test_same_bmc_raises(self):",
            "        uuid2 = uuidutils.generate_uuid()",
            "        node_cache.add_node(uuid2,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4')",
            "        six.assertRaisesRegex(self, utils.Error, 'Multiple nodes',",
            "                              node_cache.find_node, bmc_address='1.2.3.4')",
            "",
            "    def test_macs(self):",
            "        res = node_cache.find_node(mac=['11:22:33:33:33:33', self.macs[1]])",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        self.assertTrue(",
            "            datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "            < res.started_at <",
            "            datetime.datetime.utcnow() + datetime.timedelta(seconds=1))",
            "        self.assertTrue(res._locked)",
            "",
            "    def test_macs_not_found(self):",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          mac=['11:22:33:33:33:33',",
            "                               '66:66:44:33:22:11'])",
            "",
            "    def test_macs_multiple_found(self):",
            "        node_cache.add_node('uuid2',",
            "                            istate.States.starting,",
            "                            mac=self.macs2)",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          mac=[self.macs[0], self.macs2[0]])",
            "",
            "    def test_both(self):",
            "        res = node_cache.find_node(bmc_address='1.2.3.4',",
            "                                   mac=self.macs)",
            "        self.assertEqual(self.uuid, res.uuid)",
            "        self.assertTrue(",
            "            datetime.datetime.utcnow() - datetime.timedelta(seconds=60)",
            "            < res.started_at <",
            "            datetime.datetime.utcnow() + datetime.timedelta(seconds=1))",
            "        self.assertTrue(res._locked)",
            "",
            "    def test_inconsistency(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            (db.model_query(db.Node).filter_by(uuid=self.uuid).",
            "                delete())",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          bmc_address='1.2.3.4')",
            "",
            "    def test_already_finished(self):",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            (db.model_query(db.Node).filter_by(uuid=self.uuid).",
            "                update({'finished_at': datetime.datetime.utcnow()}))",
            "        self.assertRaises(utils.Error, node_cache.find_node,",
            "                          bmc_address='1.2.3.4')",
            "",
            "    def test_input_filtering(self):",
            "        self.assertRaises(utils.NotFoundInCacheError,",
            "                          node_cache.find_node,",
            "                          bmc_address=\"' OR ''='\")",
            "",
            "",
            "class TestNodeCacheCleanUp(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheCleanUp, self).setUp()",
            "        self.started_at = datetime.datetime.utcnow()",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.waiting,",
            "                    started_at=self.started_at).save(",
            "                session)",
            "            for v in self.macs:",
            "                db.Attribute(uuid=uuidutils.generate_uuid(), name='mac',",
            "                             value=v, node_uuid=self.uuid).save(session)",
            "            db.Option(uuid=self.uuid, name='foo', value='bar').save(",
            "                session)",
            "",
            "    def test_no_timeout(self):",
            "        CONF.set_override('timeout', 0)",
            "",
            "        self.assertFalse(node_cache.clean_up())",
            "",
            "        res = [tuple(row) for row in",
            "               db.model_query(db.Node.finished_at,",
            "                              db.Node.error).all()]",
            "        self.assertEqual([(None, None)], res)",
            "        self.assertEqual(len(self.macs),",
            "                         db.model_query(db.Attribute).count())",
            "        self.assertEqual(1, db.model_query(db.Option).count())",
            "",
            "    @mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "    @mock.patch.object(timeutils, 'utcnow')",
            "    def test_ok(self, time_mock, get_lock_mock):",
            "        time_mock.return_value = datetime.datetime.utcnow()",
            "",
            "        self.assertFalse(node_cache.clean_up())",
            "",
            "        res = [tuple(row) for row in db.model_query(",
            "            db.Node.finished_at, db.Node.error).all()]",
            "        self.assertEqual([(None, None)], res)",
            "        self.assertEqual(len(self.macs),",
            "                         db.model_query(db.Attribute).count())",
            "        self.assertEqual(1, db.model_query(db.Option).count())",
            "        self.assertFalse(get_lock_mock.called)",
            "",
            "    @mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "    @mock.patch.object(timeutils, 'utcnow')",
            "    def test_timeout(self, time_mock, get_lock_mock):",
            "        # Add a finished node to confirm we don't try to timeout it",
            "        time_mock.return_value = self.started_at",
            "        session = db.get_writer_session()",
            "        finished_at = self.started_at + datetime.timedelta(seconds=60)",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid + '1', started_at=self.started_at,",
            "                    state=istate.States.waiting,",
            "                    finished_at=finished_at).save(session)",
            "        CONF.set_override('timeout', 99)",
            "        time_mock.return_value = (self.started_at +",
            "                                  datetime.timedelta(seconds=100))",
            "",
            "        self.assertEqual([self.uuid], node_cache.clean_up())",
            "",
            "        res = [(row.state, row.finished_at, row.error) for row in",
            "               db.model_query(db.Node).all()]",
            "        self.assertEqual(",
            "            [(istate.States.error,",
            "              self.started_at + datetime.timedelta(seconds=100),",
            "              'Introspection timeout'),",
            "             (istate.States.waiting,",
            "              self.started_at + datetime.timedelta(seconds=60), None)],",
            "            res)",
            "        self.assertEqual([], db.model_query(db.Attribute).all())",
            "        self.assertEqual([], db.model_query(db.Option).all())",
            "        get_lock_mock.assert_called_once_with(self.uuid)",
            "        get_lock_mock.return_value.acquire.assert_called_once_with()",
            "",
            "    @mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "    @mock.patch.object(timeutils, 'utcnow')",
            "    def test_timeout_active_state(self, time_mock, get_lock_mock):",
            "        time_mock.return_value = self.started_at",
            "        session = db.get_writer_session()",
            "        CONF.set_override('timeout', 1)",
            "        for state in [istate.States.starting, istate.States.enrolling,",
            "                      istate.States.processing, istate.States.reapplying]:",
            "            db.model_query(db.Node, session=session).filter_by(",
            "                uuid=self.uuid).update({'state': state, 'finished_at': None})",
            "",
            "            current_time = self.started_at + datetime.timedelta(seconds=2)",
            "            time_mock.return_value = current_time",
            "",
            "            self.assertEqual([self.uuid], node_cache.clean_up())",
            "",
            "            res = [(row.state, row.finished_at, row.error) for row in",
            "                   db.model_query(db.Node).all()]",
            "            self.assertEqual(",
            "                [(istate.States.error, current_time, 'Introspection timeout')],",
            "                res)",
            "",
            "    def test_old_status(self):",
            "        CONF.set_override('node_status_keep_time', 42)",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.model_query(db.Node).update(",
            "                {'finished_at': (datetime.datetime.utcnow() -",
            "                                 datetime.timedelta(seconds=100))})",
            "",
            "        self.assertEqual([], node_cache.clean_up())",
            "",
            "        self.assertEqual([], db.model_query(db.Node).all())",
            "",
            "    def test_old_status_disabled(self):",
            "        # Status clean up is disabled by default",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.model_query(db.Node).update(",
            "                {'finished_at': (datetime.datetime.utcnow() -",
            "                                 datetime.timedelta(days=10000))})",
            "",
            "        self.assertEqual([], node_cache.clean_up())",
            "",
            "        self.assertNotEqual([], db.model_query(db.Node).all())",
            "",
            "",
            "class TestNodeCacheGetNode(test_base.NodeTest):",
            "    def test_ok(self):",
            "        started_at = (datetime.datetime.utcnow() -",
            "                      datetime.timedelta(seconds=42))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.starting,",
            "                    started_at=started_at).save(session)",
            "        info = node_cache.get_node(self.uuid)",
            "",
            "        self.assertEqual(self.uuid, info.uuid)",
            "        self.assertEqual(started_at, info.started_at)",
            "        self.assertIsNone(info.finished_at)",
            "        self.assertIsNone(info.error)",
            "        self.assertFalse(info._locked)",
            "",
            "    def test_locked(self):",
            "        started_at = (datetime.datetime.utcnow() -",
            "                      datetime.timedelta(seconds=42))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.starting,",
            "                    started_at=started_at).save(session)",
            "        info = node_cache.get_node(self.uuid, locked=True)",
            "",
            "        self.assertEqual(self.uuid, info.uuid)",
            "        self.assertEqual(started_at, info.started_at)",
            "        self.assertIsNone(info.finished_at)",
            "        self.assertIsNone(info.error)",
            "        self.assertTrue(info._locked)",
            "",
            "    def test_not_found(self):",
            "        self.assertRaises(utils.Error, node_cache.get_node,",
            "                          uuidutils.generate_uuid())",
            "",
            "    def test_with_name(self):",
            "        started_at = (datetime.datetime.utcnow() -",
            "                      datetime.timedelta(seconds=42))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    state=istate.States.starting,",
            "                    started_at=started_at).save(session)",
            "        ironic = mock.Mock()",
            "        ironic.node.get.return_value = self.node",
            "",
            "        info = node_cache.get_node('name', ironic=ironic)",
            "",
            "        self.assertEqual(self.uuid, info.uuid)",
            "        self.assertEqual(started_at, info.started_at)",
            "        self.assertIsNone(info.finished_at)",
            "        self.assertIsNone(info.error)",
            "        self.assertFalse(info._locked)",
            "        ironic.node.get.assert_called_once_with('name')",
            "",
            "",
            "@mock.patch.object(timeutils, 'utcnow', lambda: datetime.datetime(1, 1, 1))",
            "class TestNodeInfoFinished(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeInfoFinished, self).setUp()",
            "        node_cache.add_node(self.uuid,",
            "                            istate.States.processing,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs)",
            "        self.node_info = node_cache.NodeInfo(",
            "            uuid=self.uuid, started_at=datetime.datetime(3, 1, 4))",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Option(uuid=self.uuid, name='foo', value='bar').save(",
            "                session)",
            "",
            "    def test_success(self):",
            "        self.node_info.finished(istate.Events.finish)",
            "",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            self.assertEqual((datetime.datetime(1, 1, 1), None),",
            "                             tuple(db.model_query(",
            "                                   db.Node.finished_at,",
            "                                   db.Node.error).first()))",
            "            self.assertEqual([], db.model_query(db.Attribute,",
            "                             session=session).all())",
            "            self.assertEqual([], db.model_query(db.Option,",
            "                             session=session).all())",
            "",
            "    def test_error(self):",
            "        self.node_info.finished(istate.Events.error, error='boom')",
            "",
            "        self.assertEqual((datetime.datetime(1, 1, 1), 'boom'),",
            "                         tuple(db.model_query(db.Node.finished_at,",
            "                               db.Node.error).first()))",
            "        self.assertEqual([], db.model_query(db.Attribute).all())",
            "        self.assertEqual([], db.model_query(db.Option).all())",
            "",
            "    def test_release_lock(self):",
            "        self.node_info.acquire_lock()",
            "        self.node_info.finished(istate.Events.finish)",
            "        self.assertFalse(self.node_info._locked)",
            "",
            "",
            "class TestNodeInfoOptions(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeInfoOptions, self).setUp()",
            "        node_cache.add_node(self.uuid,",
            "                            istate.States.starting,",
            "                            bmc_address='1.2.3.4',",
            "                            mac=self.macs)",
            "        self.node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=3.14)",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Option(uuid=self.uuid, name='foo', value='\"bar\"').save(",
            "                session)",
            "",
            "    def test_get(self):",
            "        self.assertEqual({'foo': 'bar'}, self.node_info.options)",
            "        # should be cached",
            "        self.assertEqual(self.node_info.options, self.node_info.options)",
            "        # invalidate cache",
            "        old_options = self.node_info.options",
            "        self.node_info.invalidate_cache()",
            "        self.assertIsNot(old_options, self.node_info.options)",
            "        self.assertEqual(old_options, self.node_info.options)",
            "",
            "    def test_set(self):",
            "        data = {'s': 'value', 'b': True, 'i': 42}",
            "        self.node_info.set_option('name', data)",
            "        self.assertEqual(data, self.node_info.options['name'])",
            "",
            "        new = node_cache.NodeInfo(uuid=self.uuid, started_at=3.14)",
            "        self.assertEqual(data, new.options['name'])",
            "",
            "",
            "@mock.patch.object(ir_utils, 'get_client', autospec=True)",
            "class TestNodeCacheIronicObjects(unittest.TestCase):",
            "    def setUp(self):",
            "        super(TestNodeCacheIronicObjects, self).setUp()",
            "        self.ports = {'mac1': mock.Mock(address='mac1', spec=['address']),",
            "                      'mac2': mock.Mock(address='mac2', spec=['address'])}",
            "        self.uuid = uuidutils.generate_uuid()",
            "",
            "    def test_node_provided(self, mock_ironic):",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        node=mock.sentinel.node)",
            "        self.assertIs(mock.sentinel.node, node_info.node())",
            "        self.assertFalse(mock_ironic.called)",
            "",
            "    def test_node_not_provided(self, mock_ironic):",
            "        mock_ironic.return_value.node.get.return_value = mock.sentinel.node",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0)",
            "",
            "        self.assertIs(mock.sentinel.node, node_info.node())",
            "        self.assertIs(node_info.node(), node_info.node())",
            "",
            "        mock_ironic.assert_called_once_with()",
            "        mock_ironic.return_value.node.get.assert_called_once_with(self.uuid)",
            "",
            "    def test_node_ironic_preset(self, mock_ironic):",
            "        mock_ironic2 = mock.Mock()",
            "        mock_ironic2.node.get.return_value = mock.sentinel.node",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ironic=mock_ironic2)",
            "        self.assertIs(mock.sentinel.node, node_info.node())",
            "",
            "        self.assertFalse(mock_ironic.called)",
            "        mock_ironic2.node.get.assert_called_once_with(self.uuid)",
            "",
            "    def test_ports_provided(self, mock_ironic):",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ports=self.ports)",
            "        self.assertIs(self.ports, node_info.ports())",
            "        self.assertFalse(mock_ironic.called)",
            "",
            "    def test_ports_provided_list(self, mock_ironic):",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ports=list(self.ports.values()))",
            "        self.assertEqual(self.ports, node_info.ports())",
            "        self.assertFalse(mock_ironic.called)",
            "",
            "    def test_ports_not_provided(self, mock_ironic):",
            "        mock_ironic.return_value.node.list_ports.return_value = list(",
            "            self.ports.values())",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0)",
            "",
            "        self.assertEqual(self.ports, node_info.ports())",
            "        self.assertIs(node_info.ports(), node_info.ports())",
            "",
            "        mock_ironic.assert_called_once_with()",
            "        mock_ironic.return_value.node.list_ports.assert_called_once_with(",
            "            self.uuid, limit=0, detail=True)",
            "",
            "    def test_ports_ironic_preset(self, mock_ironic):",
            "        mock_ironic2 = mock.Mock()",
            "        mock_ironic2.node.list_ports.return_value = list(",
            "            self.ports.values())",
            "        node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                        ironic=mock_ironic2)",
            "        self.assertEqual(self.ports, node_info.ports())",
            "",
            "        self.assertFalse(mock_ironic.called)",
            "        mock_ironic2.node.list_ports.assert_called_once_with(",
            "            self.uuid, limit=0, detail=True)",
            "",
            "",
            "class TestUpdate(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestUpdate, self).setUp()",
            "        self.ironic = mock.Mock()",
            "        self.ports = {'mac%d' % i: mock.Mock(address='mac%d' % i, uuid=str(i))",
            "                      for i in range(2)}",
            "        self.node_info = node_cache.NodeInfo(uuid=self.uuid,",
            "                                             started_at=0,",
            "                                             node=self.node,",
            "                                             ports=self.ports,",
            "                                             ironic=self.ironic)",
            "",
            "    def test_patch(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.node_info.patch([{'patch': 'patch'}])",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid,",
            "                                                        [{'patch': 'patch'}])",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_patch_path_wo_leading_slash(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        patch = [{'op': 'add', 'path': 'driver_info/test', 'value': 42}]",
            "        expected_patch = copy.deepcopy(patch)",
            "        expected_patch[0]['path'] = '/' + 'driver_info/test'",
            "",
            "        self.node_info.patch(patch)",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid,",
            "                                                        expected_patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_patch_path_with_leading_slash(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        patch = [{'op': 'add', 'path': '/driver_info/test', 'value': 42}]",
            "",
            "        self.node_info.patch(patch)",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_update_properties(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.node_info.update_properties(prop=42)",
            "",
            "        patch = [{'op': 'add', 'path': '/properties/prop', 'value': 42}]",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_update_capabilities(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "        self.node.properties['capabilities'] = 'foo:bar,x:y'",
            "",
            "        self.node_info.update_capabilities(x=1, y=2)",
            "",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, mock.ANY)",
            "        patch = self.ironic.node.update.call_args[0][1]",
            "        new_caps = ir_utils.capabilities_to_dict(patch[0]['value'])",
            "        self.assertEqual({'foo': 'bar', 'x': '1', 'y': '2'}, new_caps)",
            "",
            "    def test_replace_field(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "        self.node.extra['foo'] = 'bar'",
            "",
            "        self.node_info.replace_field('/extra/foo', lambda v: v + '1')",
            "",
            "        patch = [{'op': 'replace', 'path': '/extra/foo', 'value': 'bar1'}]",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_replace_field_not_found(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.assertRaises(KeyError, self.node_info.replace_field,",
            "                          '/extra/foo', lambda v: v + '1')",
            "",
            "    def test_replace_field_with_default(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "",
            "        self.node_info.replace_field('/extra/foo', lambda v: v + [42],",
            "                                     default=[])",
            "",
            "        patch = [{'op': 'add', 'path': '/extra/foo', 'value': [42]}]",
            "        self.ironic.node.update.assert_called_once_with(self.uuid, patch)",
            "        self.assertIs(mock.sentinel.node, self.node_info.node())",
            "",
            "    def test_replace_field_same_value(self):",
            "        self.ironic.node.update.return_value = mock.sentinel.node",
            "        self.node.extra['foo'] = 'bar'",
            "",
            "        self.node_info.replace_field('/extra/foo', lambda v: v)",
            "        self.assertFalse(self.ironic.node.update.called)",
            "",
            "    def test_patch_port(self):",
            "        self.ironic.port.update.return_value = mock.sentinel.port",
            "",
            "        self.node_info.patch_port(self.ports['mac0'], ['patch'])",
            "",
            "        self.ironic.port.update.assert_called_once_with('0', ['patch'])",
            "        self.assertIs(mock.sentinel.port,",
            "                      self.node_info.ports()['mac0'])",
            "",
            "    def test_patch_port_by_mac(self):",
            "        self.ironic.port.update.return_value = mock.sentinel.port",
            "",
            "        self.node_info.patch_port('mac0', ['patch'])",
            "",
            "        self.ironic.port.update.assert_called_once_with('0', ['patch'])",
            "        self.assertIs(mock.sentinel.port,",
            "                      self.node_info.ports()['mac0'])",
            "",
            "    def test_delete_port(self):",
            "        self.node_info.delete_port(self.ports['mac0'])",
            "",
            "        self.ironic.port.delete.assert_called_once_with('0')",
            "        self.assertEqual(['mac1'], list(self.node_info.ports()))",
            "",
            "    def test_delete_port_by_mac(self):",
            "        self.node_info.delete_port('mac0')",
            "",
            "        self.ironic.port.delete.assert_called_once_with('0')",
            "        self.assertEqual(['mac1'], list(self.node_info.ports()))",
            "",
            "    @mock.patch.object(node_cache.LOG, 'warning', autospec=True)",
            "    def test_create_ports(self, mock_warn):",
            "        ports = [",
            "            'mac2',",
            "            {'mac': 'mac3', 'client_id': '42', 'pxe': False},",
            "            {'mac': 'mac4', 'pxe': True}",
            "        ]",
            "",
            "        self.node_info.create_ports(ports)",
            "        self.assertEqual({'mac0', 'mac1', 'mac2', 'mac3', 'mac4'},",
            "                         set(self.node_info.ports()))",
            "",
            "        create_calls = [",
            "            mock.call(node_uuid=self.uuid, address='mac2', extra={},",
            "                      pxe_enabled=True),",
            "            mock.call(node_uuid=self.uuid, address='mac3',",
            "                      extra={'client-id': '42'}, pxe_enabled=False),",
            "            mock.call(node_uuid=self.uuid, address='mac4', extra={},",
            "                      pxe_enabled=True),",
            "        ]",
            "        self.assertEqual(create_calls, self.ironic.port.create.call_args_list)",
            "        # No conflicts - cache was not cleared - no calls to port.list",
            "        self.assertFalse(mock_warn.called)",
            "        self.assertFalse(self.ironic.port.list.called)",
            "",
            "    @mock.patch.object(node_cache.LOG, 'info', autospec=True)",
            "    def test__create_port(self, mock_info):",
            "        uuid = uuidutils.generate_uuid()",
            "        address = 'mac1'",
            "        self.ironic.port.create.return_value = mock.Mock(uuid=uuid,",
            "                                                         address=address)",
            "",
            "        self.node_info._create_port(address, client_id='42')",
            "",
            "        self.ironic.port.create.assert_called_once_with(",
            "            node_uuid=self.uuid, address='mac1', client_id='42')",
            "        mock_info.assert_called_once_with(",
            "            mock.ANY, {'uuid': uuid, 'mac': address,",
            "                       'attrs': {'client_id': '42'}},",
            "            node_info=self.node_info)",
            "",
            "    @mock.patch.object(node_cache.LOG, 'warning', autospec=True)",
            "    def test_create_ports_with_conflicts(self, mock_warn):",
            "        self.ironic.port.create.return_value = mock.Mock(",
            "            uuid='fake', address='mac')",
            "",
            "        ports = [",
            "            'mac',",
            "            {'mac': 'mac0'},",
            "            'mac1',",
            "            {'mac': 'mac2', 'client_id': '42', 'pxe': False},",
            "        ]",
            "",
            "        self.node_info.create_ports(ports)",
            "",
            "        create_calls = [",
            "            mock.call(node_uuid=self.uuid, address='mac', extra={},",
            "                      pxe_enabled=True),",
            "            mock.call(node_uuid=self.uuid, address='mac2',",
            "                      extra={'client-id': '42'}, pxe_enabled=False),",
            "        ]",
            "        self.assertEqual(create_calls, self.ironic.port.create.call_args_list)",
            "        mock_warn.assert_called_once_with(mock.ANY, ['mac0', 'mac1'],",
            "                                          node_info=self.node_info)",
            "",
            "",
            "class TestNodeCacheGetByPath(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheGetByPath, self).setUp()",
            "        self.node = mock.Mock(spec=['uuid', 'properties'],",
            "                              properties={'answer': 42},",
            "                              uuid=self.uuid)",
            "        self.node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=0,",
            "                                             node=self.node)",
            "",
            "    def test_get_by_path(self):",
            "        self.assertEqual(self.uuid, self.node_info.get_by_path('/uuid'))",
            "        self.assertEqual(self.uuid, self.node_info.get_by_path('uuid'))",
            "        self.assertEqual(42, self.node_info.get_by_path('/properties/answer'))",
            "        self.assertRaises(KeyError, self.node_info.get_by_path, '/foo')",
            "        self.assertRaises(KeyError, self.node_info.get_by_path, '/extra/foo')",
            "",
            "",
            "@mock.patch.object(node_cache, '_get_lock', autospec=True)",
            "class TestLock(test_base.NodeTest):",
            "    def test_acquire(self, get_lock_mock):",
            "        node_info = node_cache.NodeInfo(self.uuid)",
            "        self.assertFalse(node_info._locked)",
            "        get_lock_mock.assert_called_once_with(self.uuid)",
            "        self.assertFalse(get_lock_mock.return_value.acquire.called)",
            "",
            "        self.assertTrue(node_info.acquire_lock())",
            "        self.assertTrue(node_info._locked)",
            "        self.assertTrue(node_info.acquire_lock())",
            "        self.assertTrue(node_info._locked)",
            "        get_lock_mock.return_value.acquire.assert_called_once_with(True)",
            "",
            "    def test_release(self, get_lock_mock):",
            "        node_info = node_cache.NodeInfo(self.uuid)",
            "        node_info.acquire_lock()",
            "        self.assertTrue(node_info._locked)",
            "        node_info.release_lock()",
            "        self.assertFalse(node_info._locked)",
            "        node_info.release_lock()",
            "        self.assertFalse(node_info._locked)",
            "        get_lock_mock.return_value.acquire.assert_called_once_with(True)",
            "        get_lock_mock.return_value.release.assert_called_once_with()",
            "",
            "    def test_acquire_non_blocking(self, get_lock_mock):",
            "        node_info = node_cache.NodeInfo(self.uuid)",
            "        self.assertFalse(node_info._locked)",
            "        get_lock_mock.return_value.acquire.side_effect = iter([False, True])",
            "",
            "        self.assertFalse(node_info.acquire_lock(blocking=False))",
            "        self.assertFalse(node_info._locked)",
            "        self.assertTrue(node_info.acquire_lock(blocking=False))",
            "        self.assertTrue(node_info._locked)",
            "        self.assertTrue(node_info.acquire_lock(blocking=False))",
            "        self.assertTrue(node_info._locked)",
            "        get_lock_mock.return_value.acquire.assert_called_with(False)",
            "        self.assertEqual(2, get_lock_mock.return_value.acquire.call_count)",
            "",
            "",
            "@mock.patch.object(node_cache, 'add_node', autospec=True)",
            "@mock.patch.object(ir_utils, 'get_client', autospec=True)",
            "class TestNodeCreate(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCreate, self).setUp()",
            "        self.mock_client = mock.Mock()",
            "",
            "    def test_default_create(self, mock_get_client, mock_add_node):",
            "        mock_get_client.return_value = self.mock_client",
            "        self.mock_client.node.create.return_value = self.node",
            "",
            "        node_cache.create_node('fake')",
            "",
            "        self.mock_client.node.create.assert_called_once_with(driver='fake')",
            "        mock_add_node.assert_called_once_with(",
            "            self.node.uuid,",
            "            istate.States.enrolling,",
            "            ironic=self.mock_client)",
            "",
            "    def test_create_with_args(self, mock_get_client, mock_add_node):",
            "        mock_get_client.return_value = self.mock_client",
            "        self.mock_client.node.create.return_value = self.node",
            "",
            "        node_cache.create_node('agent_ipmitool', ironic=self.mock_client)",
            "",
            "        self.assertFalse(mock_get_client.called)",
            "        self.mock_client.node.create.assert_called_once_with(",
            "            driver='agent_ipmitool')",
            "        mock_add_node.assert_called_once_with(",
            "            self.node.uuid,",
            "            istate.States.enrolling,",
            "            ironic=self.mock_client)",
            "",
            "    def test_create_client_error(self, mock_get_client, mock_add_node):",
            "        mock_get_client.return_value = self.mock_client",
            "        self.mock_client.node.create.side_effect = (",
            "            node_cache.exceptions.InvalidAttribute)",
            "",
            "        node_cache.create_node('fake')",
            "",
            "        mock_get_client.assert_called_once_with()",
            "        self.mock_client.node.create.assert_called_once_with(driver='fake')",
            "        self.assertFalse(mock_add_node.called)",
            "",
            "",
            "class TestNodeCacheListNode(test_base.NodeTest):",
            "    def setUp(self):",
            "        super(TestNodeCacheListNode, self).setUp()",
            "        self.uuid2 = uuidutils.generate_uuid()",
            "        session = db.get_writer_session()",
            "        with session.begin():",
            "            db.Node(uuid=self.uuid,",
            "                    started_at=datetime.datetime(1, 1, 2)).save(session)",
            "            db.Node(uuid=self.uuid2, started_at=datetime.datetime(1, 1, 1),",
            "                    finished_at=datetime.datetime(1, 1, 3)).save(session)",
            "",
            "    # mind please node(self.uuid).started_at > node(self.uuid2).started_at",
            "    # and the result ordering is strict in node_cache.get_node_list newer first",
            "",
            "    def test_list_node(self):",
            "        nodes = node_cache.get_node_list()",
            "",
            "        self.assertEqual([self.uuid, self.uuid2],",
            "                         [node.uuid for node in nodes])",
            "",
            "    def test_list_node_limit(self):",
            "        nodes = node_cache.get_node_list(limit=1)",
            "        self.assertEqual([self.uuid], [node.uuid for node in nodes])",
            "",
            "    def test_list_node_marker(self):",
            "        # get nodes started_at after node(self.uuid)",
            "        nodes = node_cache.get_node_list(marker=self.uuid)",
            "        self.assertEqual([self.uuid2], [node.uuid for node in nodes])",
            "",
            "    def test_list_node_wrong_marker(self):",
            "        self.assertRaises(utils.Error, node_cache.get_node_list,",
            "                          marker='foo-bar')",
            "",
            "",
            "class TestNodeInfoVersionId(test_base.NodeStateTest):",
            "    def test_get(self):",
            "        self.node_info._version_id = None",
            "        self.assertEqual(self.db_node.version_id, self.node_info.version_id)",
            "",
            "    def test_get_missing_uuid(self):",
            "        self.node_info.uuid = 'foo'",
            "        self.node_info._version_id = None",
            "",
            "        def func():",
            "            return self.node_info.version_id",
            "",
            "        six.assertRaisesRegex(self, utils.NotFoundInCacheError, '.*', func)",
            "",
            "    def test_set(self):",
            "        with db.ensure_transaction() as session:",
            "            self.node_info._set_version_id(uuidutils.generate_uuid(),",
            "                                           session)",
            "        row = db.model_query(db.Node).get(self.node_info.uuid)",
            "        self.assertEqual(self.node_info.version_id, row.version_id)",
            "",
            "    def test_set_race(self):",
            "        with db.ensure_transaction() as session:",
            "            row = db.model_query(db.Node, session=session).get(",
            "                self.node_info.uuid)",
            "            row.update({'version_id': uuidutils.generate_uuid()})",
            "            row.save(session)",
            "",
            "        six.assertRaisesRegex(self, utils.NodeStateRaceCondition,",
            "                              'Node state mismatch', self.node_info._set_state,",
            "                              istate.States.finished)",
            "",
            "",
            "class TestNodeInfoState(test_base.NodeStateTest):",
            "    def test_get(self):",
            "        self.node_info._state = None",
            "        self.assertEqual(self.db_node.state, self.node_info.state)",
            "",
            "    def test_set(self):",
            "        self.node_info._set_state(istate.States.finished)",
            "        row = db.model_query(db.Node).get(self.node_info.uuid)",
            "        self.assertEqual(self.node_info.state, row.state)",
            "",
            "    def test_set_invalid_state(self):",
            "        six.assertRaisesRegex(self, oslo_db.exception.DBError,",
            "                              'constraint failed',",
            "                              self.node_info._set_state, 'foo')",
            "",
            "    def test_commit(self):",
            "        current_time = timeutils.utcnow()",
            "        self.node_info.started_at = self.node_info.finished_at = current_time",
            "        self.node_info.error = \"Boo!\"",
            "        self.node_info.commit()",
            "",
            "        row = db.model_query(db.Node).get(self.node_info.uuid)",
            "        self.assertEqual(self.node_info.started_at, row.started_at)",
            "        self.assertEqual(self.node_info.finished_at, row.finished_at)",
            "        self.assertEqual(self.node_info.error, row.error)",
            "",
            "",
            "class TestNodeInfoStateFsm(test_base.NodeStateTest):",
            "    def test__get_fsm(self):",
            "        self.node_info._fsm = None",
            "        fsm = self.node_info._get_fsm()",
            "        self.assertEqual(self.node_info.state, fsm.current_state)",
            "",
            "    def test__get_fsm_invalid_state(self):",
            "        self.node_info._fsm = None",
            "        self.node_info._state = 'foo'",
            "        six.assertRaisesRegex(self, automaton.exceptions.NotFound,",
            "                              '.*undefined state.*',",
            "                              self.node_info._get_fsm)",
            "",
            "    def test__fsm_ctx_set_state(self):",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            fsm.process_event(istate.Events.wait)",
            "            self.assertEqual(self.node_info.state, istate.States.starting)",
            "        self.assertEqual(self.node_info.state, istate.States.waiting)",
            "",
            "    def test__fsm_ctx_set_same_state(self):",
            "        version_id = self.node_info.version_id",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            fsm.initialize(self.node_info.state)",
            "        self.assertEqual(version_id, self.node_info.version_id)",
            "",
            "    def test__fsm_ctx_illegal_event(self):",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            six.assertRaisesRegex(self, automaton.exceptions.NotFound,",
            "                                  'no defined transition', fsm.process_event,",
            "                                  istate.Events.finish)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test__fsm_ctx_generic_exception(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        def func(fsm):",
            "            fsm.process_event(istate.Events.wait)",
            "            raise CustomException('Oops')",
            "",
            "        with self.node_info._fsm_ctx() as fsm:",
            "            self.assertRaises(CustomException, func, fsm)",
            "        self.assertEqual(self.node_info.state, istate.States.waiting)",
            "",
            "    def test_fsm_event(self):",
            "        self.node_info.fsm_event(istate.Events.wait)",
            "        self.assertEqual(self.node_info.state, istate.States.waiting)",
            "",
            "    def test_fsm_illegal_event(self):",
            "        six.assertRaisesRegex(self, utils.NodeStateInvalidEvent,",
            "                              'no defined transition',",
            "                              self.node_info.fsm_event, istate.Events.finish)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test_fsm_illegal_strict_event(self):",
            "        six.assertRaisesRegex(self, utils.NodeStateInvalidEvent,",
            "                              'no defined transition',",
            "                              self.node_info.fsm_event,",
            "                              istate.Events.finish, strict=True)",
            "        self.assertIn('no defined transition', self.node_info.error)",
            "        self.assertEqual(self.node_info.state, istate.States.error)",
            "",
            "",
            "class TestFsmEvent(test_base.NodeStateTest):",
            "    def test_event_before(self):",
            "        @node_cache.fsm_event_before(istate.Events.wait)",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.waiting)",
            "            node_info.fsm_event(istate.Events.process)",
            "",
            "        function(self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.processing)",
            "",
            "    def test_event_after(self):",
            "        @node_cache.fsm_event_after(istate.Events.process)",
            "        def function(node_info):",
            "            node_info.fsm_event(istate.Events.wait)",
            "            self.assertEqual(node_info.state, istate.States.waiting)",
            "",
            "        function(self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.processing)",
            "",
            "    @mock.patch.object(node_cache, 'LOG', autospec=True)",
            "    def test_triggers_fsm_error_transition_no_errors(self, log_mock):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(no_errors=(CustomException,))",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops')",
            "",
            "        function(self.node_info)",
            "        log_msg = ('Not processing error event for the exception: '",
            "                   '%(exc)s raised by %(func)s')",
            "        log_mock.debug.assert_called_with(log_msg, mock.ANY,",
            "                                          node_info=mock.ANY)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test_triggers_fsm_error_transition_no_errors_empty(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(no_errors=())",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops!')",
            "",
            "        # assert an error event was performed",
            "        self.assertRaises(CustomException, function, self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.error)",
            "",
            "    def test_triggers_fsm_error_transition_no_errors_with_error(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(errors=(CustomException,))",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops')",
            "",
            "        # assert a generic error triggers an error event",
            "        self.assertRaises(CustomException, function, self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.error)",
            "",
            "    def test_triggers_fsm_error_transition_erros_masked(self):",
            "        class CustomException(Exception):",
            "            pass",
            "",
            "        @node_cache.triggers_fsm_error_transition(errors=())",
            "        def function(node_info):",
            "            self.assertEqual(node_info.state, istate.States.starting)",
            "            raise CustomException('Oops')",
            "",
            "        # assert no error event was triggered",
            "        self.assertRaises(CustomException, function, self.node_info)",
            "        self.assertEqual(self.node_info.state, istate.States.starting)",
            "",
            "    def test_unlock(self):",
            "        @node_cache.release_lock",
            "        def func(node_info):",
            "            self.assertTrue(node_info._locked)",
            "",
            "        self.node_info.acquire_lock(blocking=True)",
            "        with mock.patch.object(self.node_info, 'release_lock',",
            "                               autospec=True) as release_lock_mock:",
            "            func(self.node_info)",
            "        release_lock_mock.assert_called_once_with()",
            "",
            "    def test_unlock_unlocked(self):",
            "        @node_cache.release_lock",
            "        def func(node_info):",
            "            self.assertFalse(node_info._locked)",
            "",
            "        self.node_info.release_lock()",
            "        with mock.patch.object(self.node_info, 'release_lock',",
            "                               autospec=True) as release_lock_mock:",
            "            func(self.node_info)",
            "        self.assertEqual(0, release_lock_mock.call_count)",
            "",
            "    @mock.patch.object(node_cache, 'triggers_fsm_error_transition',",
            "                       autospec=True)",
            "    @mock.patch.object(node_cache, 'fsm_event_after', autospec=True)",
            "    def test_fsm_transition(self, fsm_event_after_mock, trigger_mock):",
            "        @node_cache.fsm_transition(istate.Events.finish)",
            "        def func():",
            "            pass",
            "        fsm_event_after_mock.assert_called_once_with(istate.Events.finish)",
            "        trigger_mock.assert_called_once_with()",
            "",
            "    @mock.patch.object(node_cache, 'triggers_fsm_error_transition',",
            "                       autospec=True)",
            "    @mock.patch.object(node_cache, 'fsm_event_before', autospec=True)",
            "    def test_nonreentrant_fsm_transition(self, fsm_event_before_mock,",
            "                                         trigger_mock):",
            "        @node_cache.fsm_transition(istate.Events.abort, reentrant=False)",
            "        def func():",
            "            pass",
            "        fsm_event_before_mock.assert_called_once_with(istate.Events.abort,",
            "                                                      strict=True)",
            "        trigger_mock.assert_called_once_with()",
            "",
            "",
            "@mock.patch.object(node_cache, 'add_node', autospec=True)",
            "@mock.patch.object(node_cache, 'NodeInfo', autospec=True)",
            "class TestStartIntrospection(test_base.NodeTest):",
            "    def prepare_mocks(fn):",
            "        @six.wraps(fn)",
            "        def inner(self, NodeMock, *args):",
            "            method_mock = mock.Mock()",
            "            NodeMock.return_value = self.node_info",
            "            self.node_info.fsm_event = method_mock",
            "            fn(self, method_mock, *args)",
            "            method_mock.assert_called_once_with(istate.Events.start)",
            "        return inner",
            "",
            "    @prepare_mocks",
            "    def test_node_in_db_ok_state(self, fsm_event_mock, add_node_mock):",
            "        def side_effect(*args):",
            "            self.node_info._state = 'foo'",
            "",
            "        fsm_event_mock.side_effect = side_effect",
            "        node_cache.start_introspection(self.node.uuid)",
            "        add_node_mock.assert_called_once_with(self.node_info.uuid, 'foo')",
            "",
            "    @prepare_mocks",
            "    def test_node_in_db_invalid_state(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.NodeStateInvalidEvent('Oops!')",
            "        six.assertRaisesRegex(self, utils.NodeStateInvalidEvent, 'Oops!',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)",
            "",
            "    @prepare_mocks",
            "    def test_node_in_db_race_condition(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.NodeStateRaceCondition()",
            "        six.assertRaisesRegex(self, utils.NodeStateRaceCondition, '.*',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)",
            "",
            "    @prepare_mocks",
            "    def test_error_fsm_event(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.Error('Oops!')",
            "        six.assertRaisesRegex(self, utils.Error, 'Oops!',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)",
            "",
            "    @prepare_mocks",
            "    def test_node_not_in_db(self, fsm_event_mock, add_node_mock):",
            "        fsm_event_mock.side_effect = utils.NotFoundInCacheError('Oops!')",
            "        node_cache.start_introspection(self.node_info.uuid)",
            "        add_node_mock.assert_called_once_with(self.node_info.uuid,",
            "                                              istate.States.starting)",
            "",
            "    @prepare_mocks",
            "    def test_custom_exc_fsm_event(self, fsm_event_mock, add_node_mock):",
            "        class CustomError(Exception):",
            "            pass",
            "",
            "        fsm_event_mock.side_effect = CustomError('Oops!')",
            "        six.assertRaisesRegex(self, CustomError, 'Oops!',",
            "                              node_cache.start_introspection,",
            "                              self.node_info.uuid)",
            "        self.assertFalse(add_node_mock.called)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "rdiffweb.controller.page_pref_sshkeys.ApiSshKeys.post"
        ]
    }
}