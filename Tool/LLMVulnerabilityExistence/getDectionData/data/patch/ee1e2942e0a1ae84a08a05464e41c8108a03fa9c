{
    "gradio/components/base.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from gradio import utils"
            },
            "1": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from gradio.blocks import Block, BlockContext"
            },
            "2": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from gradio.component_meta import ComponentMeta"
            },
            "3": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from gradio.data_classes import GradioDataModel"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+from gradio.data_classes import GradioDataModel, JsonData"
            },
            "5": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from gradio.events import EventListener"
            },
            "6": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from gradio.layouts import Form"
            },
            "7": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from gradio.processing_utils import move_files_to_cache"
            },
            "8": {
                "beforePatchRowNumber": 298,
                "afterPatchRowNumber": 298,
                "PatchRowcode": "             payload = self.data_model.from_json(payload)"
            },
            "9": {
                "beforePatchRowNumber": 299,
                "afterPatchRowNumber": 299,
                "PatchRowcode": "             Path(flag_dir).mkdir(exist_ok=True)"
            },
            "10": {
                "beforePatchRowNumber": 300,
                "afterPatchRowNumber": 300,
                "PatchRowcode": "             payload = payload.copy_to_dir(flag_dir).model_dump()"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 301,
                "PatchRowcode": "+        if isinstance(payload, JsonData):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 302,
                "PatchRowcode": "+            payload = payload.model_dump()"
            },
            "13": {
                "beforePatchRowNumber": 301,
                "afterPatchRowNumber": 303,
                "PatchRowcode": "         if not isinstance(payload, str):"
            },
            "14": {
                "beforePatchRowNumber": 302,
                "afterPatchRowNumber": 304,
                "PatchRowcode": "             payload = json.dumps(payload)"
            },
            "15": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 305,
                "PatchRowcode": "         return payload"
            }
        },
        "frontPatchFile": [
            "\"\"\"Contains all of the components that can be used with Gradio Interface / Blocks.",
            "Along with the docs for each component, you can find the names of example demos that use",
            "each component. These demos are located in the `demo` directory.\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import abc",
            "import hashlib",
            "import json",
            "import sys",
            "import warnings",
            "from abc import ABC, abstractmethod",
            "from enum import Enum",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any, Callable",
            "",
            "import gradio_client.utils as client_utils",
            "",
            "from gradio import utils",
            "from gradio.blocks import Block, BlockContext",
            "from gradio.component_meta import ComponentMeta",
            "from gradio.data_classes import GradioDataModel",
            "from gradio.events import EventListener",
            "from gradio.layouts import Form",
            "from gradio.processing_utils import move_files_to_cache",
            "",
            "if TYPE_CHECKING:",
            "    from typing import TypedDict",
            "",
            "    class DataframeData(TypedDict):",
            "        headers: list[str]",
            "        data: list[list[str | int | bool]]",
            "",
            "",
            "class _Keywords(Enum):",
            "    NO_VALUE = \"NO_VALUE\"  # Used as a sentinel to determine if nothing is provided as a argument for `value` in `Component.update()`",
            "    FINISHED_ITERATING = \"FINISHED_ITERATING\"  # Used to skip processing of a component's value (needed for generators + state)",
            "",
            "",
            "class ComponentBase(ABC, metaclass=ComponentMeta):",
            "    EVENTS: list[EventListener | str] = []",
            "",
            "    @abstractmethod",
            "    def preprocess(self, payload: Any) -> Any:",
            "        \"\"\"",
            "        Any preprocessing needed to be performed on function input.",
            "        Parameters:",
            "            payload: The input data received by the component from the frontend.",
            "        Returns:",
            "            The preprocessed input data sent to the user's function in the backend.",
            "        \"\"\"",
            "        return payload",
            "",
            "    @abstractmethod",
            "    def postprocess(self, value):",
            "        \"\"\"",
            "        Any postprocessing needed to be performed on function output.",
            "        Parameters:",
            "            value: The output data received by the component from the user's function in the backend.",
            "        Returns:",
            "            The postprocessed output data sent to the frontend.",
            "        \"\"\"",
            "        return value",
            "",
            "    @abstractmethod",
            "    def process_example(self, value):",
            "        \"\"\"",
            "        Process the input data in a way that can be displayed by the examples dataset component in the front-end.",
            "",
            "        For example, only return the name of a file as opposed to a full path. Or get the head of a dataframe.",
            "        The return value must be able to be json-serializable to put in the config.",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def api_info(self) -> dict[str, list[str]]:",
            "        \"\"\"",
            "        The typing information for this component as a dictionary whose values are a list of 2 strings: [Python type, language-agnostic description].",
            "        Keys of the dictionary are: raw_input, raw_output, serialized_input, serialized_output",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def example_inputs(self) -> Any:",
            "        \"\"\"",
            "        Deprecated and replaced by `example_payload()` and `example_value()`.",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def flag(self, payload: Any | GradioDataModel, flag_dir: str | Path = \"\") -> str:",
            "        \"\"\"",
            "        Write the component's value to a format that can be stored in a csv or jsonl format for flagging.",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def read_from_flag(self, payload: Any) -> GradioDataModel | Any:",
            "        \"\"\"",
            "        Convert the data from the csv or jsonl file into the component state.",
            "        \"\"\"",
            "        return payload",
            "",
            "    @property",
            "    @abstractmethod",
            "    def skip_api(self):",
            "        \"\"\"Whether this component should be skipped from the api return value\"\"\"",
            "",
            "    @classmethod",
            "    def has_event(cls, event: str | EventListener) -> bool:",
            "        return event in cls.EVENTS",
            "",
            "    @classmethod",
            "    def get_component_class_id(cls) -> str:",
            "        module_name = cls.__module__",
            "        module_path = sys.modules[module_name].__file__",
            "        module_hash = hashlib.md5(f\"{cls.__name__}_{module_path}\".encode()).hexdigest()",
            "        return module_hash",
            "",
            "",
            "def server(fn):",
            "    fn._is_server_fn = True",
            "    return fn",
            "",
            "",
            "class Component(ComponentBase, Block):",
            "    \"\"\"",
            "    A base class for defining methods that all input/output components should have.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        value: Any = None,",
            "        *,",
            "        label: str | None = None,",
            "        info: str | None = None,",
            "        show_label: bool | None = None,",
            "        container: bool = True,",
            "        scale: int | None = None,",
            "        min_width: int | None = None,",
            "        interactive: bool | None = None,",
            "        visible: bool = True,",
            "        elem_id: str | None = None,",
            "        elem_classes: list[str] | str | None = None,",
            "        render: bool = True,",
            "        key: int | str | None = None,",
            "        load_fn: Callable | None = None,",
            "        every: float | None = None,",
            "    ):",
            "        self.server_fns = [",
            "            getattr(self, value)",
            "            for value in dir(self.__class__)",
            "            if callable(getattr(self, value))",
            "            and getattr(getattr(self, value), \"_is_server_fn\", False)",
            "        ]",
            "",
            "        # Svelte components expect elem_classes to be a list",
            "        # If we don't do this, returning a new component for an",
            "        # update will break the frontend",
            "        if not elem_classes:",
            "            elem_classes = []",
            "",
            "        # This gets overridden when `select` is called",
            "        self._selectable = False",
            "        if not hasattr(self, \"data_model\"):",
            "            self.data_model: type[GradioDataModel] | None = None",
            "",
            "        Block.__init__(",
            "            self,",
            "            elem_id=elem_id,",
            "            elem_classes=elem_classes,",
            "            visible=visible,",
            "            render=render,",
            "            key=key,",
            "        )",
            "        if isinstance(self, StreamingInput):",
            "            self.check_streamable()",
            "",
            "        self.label = label",
            "        self.info = info",
            "        if not container:",
            "            if show_label:",
            "                warnings.warn(\"show_label has no effect when container is False.\")",
            "            show_label = False",
            "        if show_label is None:",
            "            show_label = True",
            "        self.show_label = show_label",
            "        self.container = container",
            "        if scale is not None and scale != round(scale):",
            "            warnings.warn(",
            "                f\"'scale' value should be an integer. Using {scale} will cause issues.\"",
            "            )",
            "        self.scale = scale",
            "        self.min_width = min_width",
            "        self.interactive = interactive",
            "",
            "        # load_event is set in the Blocks.attach_load_events method",
            "        self.load_event: None | dict[str, Any] = None",
            "        self.load_event_to_attach: None | tuple[Callable, float | None] = None",
            "        load_fn, initial_value = self.get_load_fn_and_initial_value(value)",
            "        initial_value = self.postprocess(initial_value)",
            "        self.value = move_files_to_cache(",
            "            initial_value,",
            "            self,  # type: ignore",
            "            postprocess=True,",
            "            keep_in_cache=True,",
            "        )",
            "        if client_utils.is_file_obj(self.value):",
            "            self.keep_in_cache.add(self.value[\"path\"])",
            "",
            "        if callable(load_fn):",
            "            self.attach_load_event(load_fn, every)",
            "",
            "        self.component_class_id = self.__class__.get_component_class_id()",
            "",
            "    TEMPLATE_DIR = \"./templates/\"",
            "    FRONTEND_DIR = \"../../frontend/\"",
            "",
            "    def get_config(self):",
            "        config = super().get_config()",
            "        if self.info:",
            "            config[\"info\"] = self.info",
            "        if len(self.server_fns):",
            "            config[\"server_fns\"] = [fn.__name__ for fn in self.server_fns]",
            "        config.pop(\"render\", None)",
            "        return config",
            "",
            "    @property",
            "    def skip_api(self):",
            "        return False",
            "",
            "    @staticmethod",
            "    def get_load_fn_and_initial_value(value):",
            "        if callable(value):",
            "            initial_value = value()",
            "            load_fn = value",
            "        else:",
            "            initial_value = value",
            "            load_fn = None",
            "        return load_fn, initial_value",
            "",
            "    def attach_load_event(self, callable: Callable, every: float | None):",
            "        \"\"\"Add a load event that runs `callable`, optionally every `every` seconds.\"\"\"",
            "        self.load_event_to_attach = (callable, every)",
            "",
            "    def process_example(self, value):",
            "        \"\"\"",
            "        Process the input data in a way that can be displayed by the examples dataset component in the front-end.",
            "        By default, this calls the `.postprocess()` method of the component. However, if the `.postprocess()` method is",
            "        computationally intensive, or returns a large payload, a custom implementation may be appropriate.",
            "",
            "        For example,  the `process_example()` method of the `gr.Audio()` component only returns the name of the file, not",
            "        the processed audio file. The `.process_example()` method of the `gr.Dataframe()` returns the head of a dataframe",
            "        instead of the full dataframe.",
            "",
            "        The return value of this method must be json-serializable to put in the config.",
            "        \"\"\"",
            "        return self.postprocess(value)",
            "",
            "    def as_example(self, value):",
            "        \"\"\"Deprecated and replaced by `process_example()`.\"\"\"",
            "        return self.process_example(value)",
            "",
            "    def example_inputs(self) -> Any:",
            "        \"\"\"Deprecated and replaced by `example_payload()` and `example_value()`.\"\"\"",
            "        return self.example_payload()",
            "",
            "    def example_payload(self) -> Any:",
            "        \"\"\"",
            "        An example input data for this component, e.g. what is passed to this component's preprocess() method.",
            "        This is used to generate the docs for the View API page for Gradio apps using this component.",
            "        \"\"\"",
            "        raise NotImplementedError()",
            "",
            "    def example_value(self) -> Any:",
            "        \"\"\"",
            "        An example output data for this component, e.g. what is passed to this component's postprocess() method.",
            "        This is used to generate an example value if this component is used as a template for a custom component.",
            "        \"\"\"",
            "        raise NotImplementedError()",
            "",
            "    def api_info(self) -> dict[str, Any]:",
            "        \"\"\"",
            "        The typing information for this component as a dictionary whose values are a list of 2 strings: [Python type, language-agnostic description].",
            "        Keys of the dictionary are: raw_input, raw_output, serialized_input, serialized_output",
            "        \"\"\"",
            "        if self.data_model is not None:",
            "            return self.data_model.model_json_schema()",
            "        raise NotImplementedError(",
            "            f\"The api_info method has not been implemented for {self.get_block_name()}\"",
            "        )",
            "",
            "    def flag(self, payload: Any, flag_dir: str | Path = \"\") -> str:",
            "        \"\"\"",
            "        Write the component's value to a format that can be stored in a csv or jsonl format for flagging.",
            "        \"\"\"",
            "        if self.data_model:",
            "            payload = self.data_model.from_json(payload)",
            "            Path(flag_dir).mkdir(exist_ok=True)",
            "            payload = payload.copy_to_dir(flag_dir).model_dump()",
            "        if not isinstance(payload, str):",
            "            payload = json.dumps(payload)",
            "        return payload",
            "",
            "    def read_from_flag(self, payload: Any):",
            "        \"\"\"",
            "        Convert the data from the csv or jsonl file into the component state.",
            "        \"\"\"",
            "        if self.data_model:",
            "            return self.data_model.from_json(json.loads(payload))",
            "        return payload",
            "",
            "",
            "class FormComponent(Component):",
            "    def get_expected_parent(self) -> type[Form] | None:",
            "        if getattr(self, \"container\", None) is False:",
            "            return None",
            "        return Form",
            "",
            "    def preprocess(self, payload: Any) -> Any:",
            "        return payload",
            "",
            "    def postprocess(self, value):",
            "        return value",
            "",
            "",
            "class StreamingOutput(metaclass=abc.ABCMeta):",
            "    def __init__(self, *args, **kwargs) -> None:",
            "        super().__init__(*args, **kwargs)",
            "        self.streaming: bool",
            "",
            "    @abc.abstractmethod",
            "    def stream_output(",
            "        self, value, output_id: str, first_chunk: bool",
            "    ) -> tuple[bytes, Any]:",
            "        pass",
            "",
            "",
            "class StreamingInput(metaclass=abc.ABCMeta):",
            "    def __init__(self, *args, **kwargs) -> None:",
            "        super().__init__(*args, **kwargs)",
            "",
            "    @abc.abstractmethod",
            "    def check_streamable(self):",
            "        \"\"\"Used to check if streaming is supported given the input.\"\"\"",
            "        pass",
            "",
            "",
            "def component(cls_name: str, render: bool) -> Component:",
            "    obj = utils.component_or_layout_class(cls_name)(render=render)",
            "    if isinstance(obj, BlockContext):",
            "        raise ValueError(f\"Invalid component: {obj.__class__}\")",
            "    if not isinstance(obj, Component):",
            "        raise TypeError(f\"Expected a Component instance, but got {obj.__class__}\")",
            "    return obj",
            "",
            "",
            "def get_component_instance(",
            "    comp: str | dict | Component, render: bool = False, unrender: bool = False",
            ") -> Component:",
            "    \"\"\"",
            "    Returns a component instance from a string, dict, or Component object.",
            "    Parameters:",
            "        comp: the component to instantiate. If a string, must be the name of a component, e.g. \"dropdown\". If a dict, must have a \"name\" key, e.g. {\"name\": \"dropdown\", \"choices\": [\"a\", \"b\"]}. If a Component object, will be returned as is.",
            "        render: whether to render the component. If True, renders the component (if not already rendered). If False, does not do anything.",
            "        unrender: whether to unrender the component. If True, unrenders the the component (if already rendered) -- this is useful when constructing an Interface or ChatInterface inside of a Blocks. If False, does not do anything.",
            "    \"\"\"",
            "    if isinstance(comp, str):",
            "        component_obj = component(comp, render=render)",
            "    elif isinstance(comp, dict):",
            "        name = comp.pop(\"name\")",
            "        component_cls = utils.component_or_layout_class(name)",
            "        component_obj = component_cls(**comp, render=render)",
            "        if isinstance(component_obj, BlockContext):",
            "            raise ValueError(f\"Invalid component: {name}\")",
            "    elif isinstance(comp, Component):",
            "        component_obj = comp",
            "    else:",
            "        raise ValueError(",
            "            f\"Component must provided as a `str` or `dict` or `Component` but is {comp}\"",
            "        )",
            "",
            "    if render and not component_obj.is_rendered:",
            "        component_obj.render()",
            "    elif unrender and component_obj.is_rendered:",
            "        component_obj.unrender()",
            "    if not isinstance(component_obj, Component):",
            "        raise TypeError(",
            "            f\"Expected a Component instance, but got {component_obj.__class__}\"",
            "        )",
            "    return component_obj"
        ],
        "afterPatchFile": [
            "\"\"\"Contains all of the components that can be used with Gradio Interface / Blocks.",
            "Along with the docs for each component, you can find the names of example demos that use",
            "each component. These demos are located in the `demo` directory.\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import abc",
            "import hashlib",
            "import json",
            "import sys",
            "import warnings",
            "from abc import ABC, abstractmethod",
            "from enum import Enum",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any, Callable",
            "",
            "import gradio_client.utils as client_utils",
            "",
            "from gradio import utils",
            "from gradio.blocks import Block, BlockContext",
            "from gradio.component_meta import ComponentMeta",
            "from gradio.data_classes import GradioDataModel, JsonData",
            "from gradio.events import EventListener",
            "from gradio.layouts import Form",
            "from gradio.processing_utils import move_files_to_cache",
            "",
            "if TYPE_CHECKING:",
            "    from typing import TypedDict",
            "",
            "    class DataframeData(TypedDict):",
            "        headers: list[str]",
            "        data: list[list[str | int | bool]]",
            "",
            "",
            "class _Keywords(Enum):",
            "    NO_VALUE = \"NO_VALUE\"  # Used as a sentinel to determine if nothing is provided as a argument for `value` in `Component.update()`",
            "    FINISHED_ITERATING = \"FINISHED_ITERATING\"  # Used to skip processing of a component's value (needed for generators + state)",
            "",
            "",
            "class ComponentBase(ABC, metaclass=ComponentMeta):",
            "    EVENTS: list[EventListener | str] = []",
            "",
            "    @abstractmethod",
            "    def preprocess(self, payload: Any) -> Any:",
            "        \"\"\"",
            "        Any preprocessing needed to be performed on function input.",
            "        Parameters:",
            "            payload: The input data received by the component from the frontend.",
            "        Returns:",
            "            The preprocessed input data sent to the user's function in the backend.",
            "        \"\"\"",
            "        return payload",
            "",
            "    @abstractmethod",
            "    def postprocess(self, value):",
            "        \"\"\"",
            "        Any postprocessing needed to be performed on function output.",
            "        Parameters:",
            "            value: The output data received by the component from the user's function in the backend.",
            "        Returns:",
            "            The postprocessed output data sent to the frontend.",
            "        \"\"\"",
            "        return value",
            "",
            "    @abstractmethod",
            "    def process_example(self, value):",
            "        \"\"\"",
            "        Process the input data in a way that can be displayed by the examples dataset component in the front-end.",
            "",
            "        For example, only return the name of a file as opposed to a full path. Or get the head of a dataframe.",
            "        The return value must be able to be json-serializable to put in the config.",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def api_info(self) -> dict[str, list[str]]:",
            "        \"\"\"",
            "        The typing information for this component as a dictionary whose values are a list of 2 strings: [Python type, language-agnostic description].",
            "        Keys of the dictionary are: raw_input, raw_output, serialized_input, serialized_output",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def example_inputs(self) -> Any:",
            "        \"\"\"",
            "        Deprecated and replaced by `example_payload()` and `example_value()`.",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def flag(self, payload: Any | GradioDataModel, flag_dir: str | Path = \"\") -> str:",
            "        \"\"\"",
            "        Write the component's value to a format that can be stored in a csv or jsonl format for flagging.",
            "        \"\"\"",
            "        pass",
            "",
            "    @abstractmethod",
            "    def read_from_flag(self, payload: Any) -> GradioDataModel | Any:",
            "        \"\"\"",
            "        Convert the data from the csv or jsonl file into the component state.",
            "        \"\"\"",
            "        return payload",
            "",
            "    @property",
            "    @abstractmethod",
            "    def skip_api(self):",
            "        \"\"\"Whether this component should be skipped from the api return value\"\"\"",
            "",
            "    @classmethod",
            "    def has_event(cls, event: str | EventListener) -> bool:",
            "        return event in cls.EVENTS",
            "",
            "    @classmethod",
            "    def get_component_class_id(cls) -> str:",
            "        module_name = cls.__module__",
            "        module_path = sys.modules[module_name].__file__",
            "        module_hash = hashlib.md5(f\"{cls.__name__}_{module_path}\".encode()).hexdigest()",
            "        return module_hash",
            "",
            "",
            "def server(fn):",
            "    fn._is_server_fn = True",
            "    return fn",
            "",
            "",
            "class Component(ComponentBase, Block):",
            "    \"\"\"",
            "    A base class for defining methods that all input/output components should have.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        value: Any = None,",
            "        *,",
            "        label: str | None = None,",
            "        info: str | None = None,",
            "        show_label: bool | None = None,",
            "        container: bool = True,",
            "        scale: int | None = None,",
            "        min_width: int | None = None,",
            "        interactive: bool | None = None,",
            "        visible: bool = True,",
            "        elem_id: str | None = None,",
            "        elem_classes: list[str] | str | None = None,",
            "        render: bool = True,",
            "        key: int | str | None = None,",
            "        load_fn: Callable | None = None,",
            "        every: float | None = None,",
            "    ):",
            "        self.server_fns = [",
            "            getattr(self, value)",
            "            for value in dir(self.__class__)",
            "            if callable(getattr(self, value))",
            "            and getattr(getattr(self, value), \"_is_server_fn\", False)",
            "        ]",
            "",
            "        # Svelte components expect elem_classes to be a list",
            "        # If we don't do this, returning a new component for an",
            "        # update will break the frontend",
            "        if not elem_classes:",
            "            elem_classes = []",
            "",
            "        # This gets overridden when `select` is called",
            "        self._selectable = False",
            "        if not hasattr(self, \"data_model\"):",
            "            self.data_model: type[GradioDataModel] | None = None",
            "",
            "        Block.__init__(",
            "            self,",
            "            elem_id=elem_id,",
            "            elem_classes=elem_classes,",
            "            visible=visible,",
            "            render=render,",
            "            key=key,",
            "        )",
            "        if isinstance(self, StreamingInput):",
            "            self.check_streamable()",
            "",
            "        self.label = label",
            "        self.info = info",
            "        if not container:",
            "            if show_label:",
            "                warnings.warn(\"show_label has no effect when container is False.\")",
            "            show_label = False",
            "        if show_label is None:",
            "            show_label = True",
            "        self.show_label = show_label",
            "        self.container = container",
            "        if scale is not None and scale != round(scale):",
            "            warnings.warn(",
            "                f\"'scale' value should be an integer. Using {scale} will cause issues.\"",
            "            )",
            "        self.scale = scale",
            "        self.min_width = min_width",
            "        self.interactive = interactive",
            "",
            "        # load_event is set in the Blocks.attach_load_events method",
            "        self.load_event: None | dict[str, Any] = None",
            "        self.load_event_to_attach: None | tuple[Callable, float | None] = None",
            "        load_fn, initial_value = self.get_load_fn_and_initial_value(value)",
            "        initial_value = self.postprocess(initial_value)",
            "        self.value = move_files_to_cache(",
            "            initial_value,",
            "            self,  # type: ignore",
            "            postprocess=True,",
            "            keep_in_cache=True,",
            "        )",
            "        if client_utils.is_file_obj(self.value):",
            "            self.keep_in_cache.add(self.value[\"path\"])",
            "",
            "        if callable(load_fn):",
            "            self.attach_load_event(load_fn, every)",
            "",
            "        self.component_class_id = self.__class__.get_component_class_id()",
            "",
            "    TEMPLATE_DIR = \"./templates/\"",
            "    FRONTEND_DIR = \"../../frontend/\"",
            "",
            "    def get_config(self):",
            "        config = super().get_config()",
            "        if self.info:",
            "            config[\"info\"] = self.info",
            "        if len(self.server_fns):",
            "            config[\"server_fns\"] = [fn.__name__ for fn in self.server_fns]",
            "        config.pop(\"render\", None)",
            "        return config",
            "",
            "    @property",
            "    def skip_api(self):",
            "        return False",
            "",
            "    @staticmethod",
            "    def get_load_fn_and_initial_value(value):",
            "        if callable(value):",
            "            initial_value = value()",
            "            load_fn = value",
            "        else:",
            "            initial_value = value",
            "            load_fn = None",
            "        return load_fn, initial_value",
            "",
            "    def attach_load_event(self, callable: Callable, every: float | None):",
            "        \"\"\"Add a load event that runs `callable`, optionally every `every` seconds.\"\"\"",
            "        self.load_event_to_attach = (callable, every)",
            "",
            "    def process_example(self, value):",
            "        \"\"\"",
            "        Process the input data in a way that can be displayed by the examples dataset component in the front-end.",
            "        By default, this calls the `.postprocess()` method of the component. However, if the `.postprocess()` method is",
            "        computationally intensive, or returns a large payload, a custom implementation may be appropriate.",
            "",
            "        For example,  the `process_example()` method of the `gr.Audio()` component only returns the name of the file, not",
            "        the processed audio file. The `.process_example()` method of the `gr.Dataframe()` returns the head of a dataframe",
            "        instead of the full dataframe.",
            "",
            "        The return value of this method must be json-serializable to put in the config.",
            "        \"\"\"",
            "        return self.postprocess(value)",
            "",
            "    def as_example(self, value):",
            "        \"\"\"Deprecated and replaced by `process_example()`.\"\"\"",
            "        return self.process_example(value)",
            "",
            "    def example_inputs(self) -> Any:",
            "        \"\"\"Deprecated and replaced by `example_payload()` and `example_value()`.\"\"\"",
            "        return self.example_payload()",
            "",
            "    def example_payload(self) -> Any:",
            "        \"\"\"",
            "        An example input data for this component, e.g. what is passed to this component's preprocess() method.",
            "        This is used to generate the docs for the View API page for Gradio apps using this component.",
            "        \"\"\"",
            "        raise NotImplementedError()",
            "",
            "    def example_value(self) -> Any:",
            "        \"\"\"",
            "        An example output data for this component, e.g. what is passed to this component's postprocess() method.",
            "        This is used to generate an example value if this component is used as a template for a custom component.",
            "        \"\"\"",
            "        raise NotImplementedError()",
            "",
            "    def api_info(self) -> dict[str, Any]:",
            "        \"\"\"",
            "        The typing information for this component as a dictionary whose values are a list of 2 strings: [Python type, language-agnostic description].",
            "        Keys of the dictionary are: raw_input, raw_output, serialized_input, serialized_output",
            "        \"\"\"",
            "        if self.data_model is not None:",
            "            return self.data_model.model_json_schema()",
            "        raise NotImplementedError(",
            "            f\"The api_info method has not been implemented for {self.get_block_name()}\"",
            "        )",
            "",
            "    def flag(self, payload: Any, flag_dir: str | Path = \"\") -> str:",
            "        \"\"\"",
            "        Write the component's value to a format that can be stored in a csv or jsonl format for flagging.",
            "        \"\"\"",
            "        if self.data_model:",
            "            payload = self.data_model.from_json(payload)",
            "            Path(flag_dir).mkdir(exist_ok=True)",
            "            payload = payload.copy_to_dir(flag_dir).model_dump()",
            "        if isinstance(payload, JsonData):",
            "            payload = payload.model_dump()",
            "        if not isinstance(payload, str):",
            "            payload = json.dumps(payload)",
            "        return payload",
            "",
            "    def read_from_flag(self, payload: Any):",
            "        \"\"\"",
            "        Convert the data from the csv or jsonl file into the component state.",
            "        \"\"\"",
            "        if self.data_model:",
            "            return self.data_model.from_json(json.loads(payload))",
            "        return payload",
            "",
            "",
            "class FormComponent(Component):",
            "    def get_expected_parent(self) -> type[Form] | None:",
            "        if getattr(self, \"container\", None) is False:",
            "            return None",
            "        return Form",
            "",
            "    def preprocess(self, payload: Any) -> Any:",
            "        return payload",
            "",
            "    def postprocess(self, value):",
            "        return value",
            "",
            "",
            "class StreamingOutput(metaclass=abc.ABCMeta):",
            "    def __init__(self, *args, **kwargs) -> None:",
            "        super().__init__(*args, **kwargs)",
            "        self.streaming: bool",
            "",
            "    @abc.abstractmethod",
            "    def stream_output(",
            "        self, value, output_id: str, first_chunk: bool",
            "    ) -> tuple[bytes, Any]:",
            "        pass",
            "",
            "",
            "class StreamingInput(metaclass=abc.ABCMeta):",
            "    def __init__(self, *args, **kwargs) -> None:",
            "        super().__init__(*args, **kwargs)",
            "",
            "    @abc.abstractmethod",
            "    def check_streamable(self):",
            "        \"\"\"Used to check if streaming is supported given the input.\"\"\"",
            "        pass",
            "",
            "",
            "def component(cls_name: str, render: bool) -> Component:",
            "    obj = utils.component_or_layout_class(cls_name)(render=render)",
            "    if isinstance(obj, BlockContext):",
            "        raise ValueError(f\"Invalid component: {obj.__class__}\")",
            "    if not isinstance(obj, Component):",
            "        raise TypeError(f\"Expected a Component instance, but got {obj.__class__}\")",
            "    return obj",
            "",
            "",
            "def get_component_instance(",
            "    comp: str | dict | Component, render: bool = False, unrender: bool = False",
            ") -> Component:",
            "    \"\"\"",
            "    Returns a component instance from a string, dict, or Component object.",
            "    Parameters:",
            "        comp: the component to instantiate. If a string, must be the name of a component, e.g. \"dropdown\". If a dict, must have a \"name\" key, e.g. {\"name\": \"dropdown\", \"choices\": [\"a\", \"b\"]}. If a Component object, will be returned as is.",
            "        render: whether to render the component. If True, renders the component (if not already rendered). If False, does not do anything.",
            "        unrender: whether to unrender the component. If True, unrenders the the component (if already rendered) -- this is useful when constructing an Interface or ChatInterface inside of a Blocks. If False, does not do anything.",
            "    \"\"\"",
            "    if isinstance(comp, str):",
            "        component_obj = component(comp, render=render)",
            "    elif isinstance(comp, dict):",
            "        name = comp.pop(\"name\")",
            "        component_cls = utils.component_or_layout_class(name)",
            "        component_obj = component_cls(**comp, render=render)",
            "        if isinstance(component_obj, BlockContext):",
            "            raise ValueError(f\"Invalid component: {name}\")",
            "    elif isinstance(comp, Component):",
            "        component_obj = comp",
            "    else:",
            "        raise ValueError(",
            "            f\"Component must provided as a `str` or `dict` or `Component` but is {comp}\"",
            "        )",
            "",
            "    if render and not component_obj.is_rendered:",
            "        component_obj.render()",
            "    elif unrender and component_obj.is_rendered:",
            "        component_obj.unrender()",
            "    if not isinstance(component_obj, Component):",
            "        raise TypeError(",
            "            f\"Expected a Component instance, but got {component_obj.__class__}\"",
            "        )",
            "    return component_obj"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "22": []
        },
        "addLocation": []
    },
    "gradio/components/json_component.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from gradio_client.documentation import document"
            },
            "1": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from gradio.components.base import Component"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+from gradio.data_classes import JsonData"
            },
            "4": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " from gradio.events import Events"
            },
            "5": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": 78,
                "PatchRowcode": "         \"\"\""
            },
            "8": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": 79,
                "PatchRowcode": "         return payload"
            },
            "9": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 80,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 80,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def postprocess(self, value: dict | list | str | None) -> dict | list | None:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+    def postprocess(self, value: dict | list | str | None) -> JsonData | None:"
            },
            "12": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "         \"\"\""
            },
            "13": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "         Parameters:"
            },
            "14": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "             value: Expects a valid JSON `str` -- or a `list` or `dict` that can be serialized to a JSON string. The `list` or `dict` value can contain numpy arrays."
            },
            "15": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "         if value is None:"
            },
            "16": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "             return None"
            },
            "17": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": 90,
                "PatchRowcode": "         if isinstance(value, str):"
            },
            "18": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return orjson.loads(value)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+            return JsonData(orjson.loads(value))"
            },
            "20": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 92,
                "PatchRowcode": "         else:"
            },
            "21": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 93,
                "PatchRowcode": "             # Use orjson to convert NumPy arrays and datetime objects to JSON."
            },
            "22": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 94,
                "PatchRowcode": "             # This ensures a backward compatibility with the previous behavior."
            },
            "23": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "             # See https://github.com/gradio-app/gradio/pull/8041"
            },
            "24": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return orjson.loads("
            },
            "25": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                orjson.dumps("
            },
            "26": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    value,"
            },
            "27": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    option=orjson.OPT_SERIALIZE_NUMPY | orjson.OPT_PASSTHROUGH_DATETIME,"
            },
            "28": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    default=str,"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 96,
                "PatchRowcode": "+            return JsonData("
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 97,
                "PatchRowcode": "+                orjson.loads("
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+                    orjson.dumps("
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+                        value,"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+                        option=orjson.OPT_SERIALIZE_NUMPY"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+                        | orjson.OPT_PASSTHROUGH_DATETIME,"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+                        default=str,"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+                    )"
            },
            "37": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "                 )"
            },
            "38": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "             )"
            },
            "39": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 106,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "\"\"\"gr.JSON() component.\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import json",
            "from typing import Any, Callable",
            "",
            "import orjson",
            "from gradio_client.documentation import document",
            "",
            "from gradio.components.base import Component",
            "from gradio.events import Events",
            "",
            "",
            "@document()",
            "class JSON(Component):",
            "    \"\"\"",
            "    Used to display arbitrary JSON output prettily. As this component does not accept user input, it is rarely used as an input component.",
            "",
            "    Demos: zip_to_json, blocks_xray",
            "    \"\"\"",
            "",
            "    EVENTS = [Events.change]",
            "",
            "    def __init__(",
            "        self,",
            "        value: str | dict | list | Callable | None = None,",
            "        *,",
            "        label: str | None = None,",
            "        every: float | None = None,",
            "        show_label: bool | None = None,",
            "        container: bool = True,",
            "        scale: int | None = None,",
            "        min_width: int = 160,",
            "        visible: bool = True,",
            "        elem_id: str | None = None,",
            "        elem_classes: list[str] | str | None = None,",
            "        render: bool = True,",
            "        key: int | str | None = None,",
            "    ):",
            "        \"\"\"",
            "        Parameters:",
            "            value: Default value as a valid JSON `str` -- or a `list` or `dict` that can be serialized to a JSON string. If callable, the function will be called whenever the app loads to set the initial value of the component.",
            "            label: The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",
            "            every: If `value` is a callable, run the function 'every' number of seconds while the client connection is open. Has no effect otherwise. The event can be accessed (e.g. to cancel it) via this component's .load_event attribute.",
            "            show_label: if True, will display label.",
            "            container: If True, will place the component in a container - providing some extra padding around the border.",
            "            scale: relative size compared to adjacent Components. For example if Components A and B are in a Row, and A has scale=2, and B has scale=1, A will be twice as wide as B. Should be an integer. scale applies in Rows, and to top-level Components in Blocks where fill_height=True.",
            "            min_width: minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",
            "            visible: If False, component will be hidden.",
            "            elem_id: An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",
            "            elem_classes: An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",
            "            render: If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",
            "            key: if assigned, will be used to assume identity across a re-render. Components that have the same key across a re-render will have their value preserved.",
            "        \"\"\"",
            "        super().__init__(",
            "            label=label,",
            "            every=every,",
            "            show_label=show_label,",
            "            container=container,",
            "            scale=scale,",
            "            min_width=min_width,",
            "            visible=visible,",
            "            elem_id=elem_id,",
            "            elem_classes=elem_classes,",
            "            render=render,",
            "            key=key,",
            "            value=value,",
            "        )",
            "",
            "    def preprocess(self, payload: dict | list | None) -> dict | list | None:",
            "        \"\"\"",
            "        Parameters:",
            "            payload: JSON value as a `dict` or `list`",
            "        Returns:",
            "            Passes the JSON value as a `dict` or `list` depending on the value.",
            "        \"\"\"",
            "        return payload",
            "",
            "    def postprocess(self, value: dict | list | str | None) -> dict | list | None:",
            "        \"\"\"",
            "        Parameters:",
            "            value: Expects a valid JSON `str` -- or a `list` or `dict` that can be serialized to a JSON string. The `list` or `dict` value can contain numpy arrays.",
            "        Returns:",
            "            Returns the JSON as a `list` or `dict`.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        if isinstance(value, str):",
            "            return orjson.loads(value)",
            "        else:",
            "            # Use orjson to convert NumPy arrays and datetime objects to JSON.",
            "            # This ensures a backward compatibility with the previous behavior.",
            "            # See https://github.com/gradio-app/gradio/pull/8041",
            "            return orjson.loads(",
            "                orjson.dumps(",
            "                    value,",
            "                    option=orjson.OPT_SERIALIZE_NUMPY | orjson.OPT_PASSTHROUGH_DATETIME,",
            "                    default=str,",
            "                )",
            "            )",
            "",
            "    def example_payload(self) -> Any:",
            "        return {\"foo\": \"bar\"}",
            "",
            "    def example_value(self) -> Any:",
            "        return {\"foo\": \"bar\"}",
            "",
            "    def read_from_flag(self, payload: Any):",
            "        return json.loads(payload)",
            "",
            "    def api_info(self) -> dict[str, Any]:",
            "        return {\"type\": {}, \"description\": \"any valid json\"}"
        ],
        "afterPatchFile": [
            "\"\"\"gr.JSON() component.\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import json",
            "from typing import Any, Callable",
            "",
            "import orjson",
            "from gradio_client.documentation import document",
            "",
            "from gradio.components.base import Component",
            "from gradio.data_classes import JsonData",
            "from gradio.events import Events",
            "",
            "",
            "@document()",
            "class JSON(Component):",
            "    \"\"\"",
            "    Used to display arbitrary JSON output prettily. As this component does not accept user input, it is rarely used as an input component.",
            "",
            "    Demos: zip_to_json, blocks_xray",
            "    \"\"\"",
            "",
            "    EVENTS = [Events.change]",
            "",
            "    def __init__(",
            "        self,",
            "        value: str | dict | list | Callable | None = None,",
            "        *,",
            "        label: str | None = None,",
            "        every: float | None = None,",
            "        show_label: bool | None = None,",
            "        container: bool = True,",
            "        scale: int | None = None,",
            "        min_width: int = 160,",
            "        visible: bool = True,",
            "        elem_id: str | None = None,",
            "        elem_classes: list[str] | str | None = None,",
            "        render: bool = True,",
            "        key: int | str | None = None,",
            "    ):",
            "        \"\"\"",
            "        Parameters:",
            "            value: Default value as a valid JSON `str` -- or a `list` or `dict` that can be serialized to a JSON string. If callable, the function will be called whenever the app loads to set the initial value of the component.",
            "            label: The label for this component. Appears above the component and is also used as the header if there are a table of examples for this component. If None and used in a `gr.Interface`, the label will be the name of the parameter this component is assigned to.",
            "            every: If `value` is a callable, run the function 'every' number of seconds while the client connection is open. Has no effect otherwise. The event can be accessed (e.g. to cancel it) via this component's .load_event attribute.",
            "            show_label: if True, will display label.",
            "            container: If True, will place the component in a container - providing some extra padding around the border.",
            "            scale: relative size compared to adjacent Components. For example if Components A and B are in a Row, and A has scale=2, and B has scale=1, A will be twice as wide as B. Should be an integer. scale applies in Rows, and to top-level Components in Blocks where fill_height=True.",
            "            min_width: minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.",
            "            visible: If False, component will be hidden.",
            "            elem_id: An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.",
            "            elem_classes: An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.",
            "            render: If False, component will not render be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.",
            "            key: if assigned, will be used to assume identity across a re-render. Components that have the same key across a re-render will have their value preserved.",
            "        \"\"\"",
            "        super().__init__(",
            "            label=label,",
            "            every=every,",
            "            show_label=show_label,",
            "            container=container,",
            "            scale=scale,",
            "            min_width=min_width,",
            "            visible=visible,",
            "            elem_id=elem_id,",
            "            elem_classes=elem_classes,",
            "            render=render,",
            "            key=key,",
            "            value=value,",
            "        )",
            "",
            "    def preprocess(self, payload: dict | list | None) -> dict | list | None:",
            "        \"\"\"",
            "        Parameters:",
            "            payload: JSON value as a `dict` or `list`",
            "        Returns:",
            "            Passes the JSON value as a `dict` or `list` depending on the value.",
            "        \"\"\"",
            "        return payload",
            "",
            "    def postprocess(self, value: dict | list | str | None) -> JsonData | None:",
            "        \"\"\"",
            "        Parameters:",
            "            value: Expects a valid JSON `str` -- or a `list` or `dict` that can be serialized to a JSON string. The `list` or `dict` value can contain numpy arrays.",
            "        Returns:",
            "            Returns the JSON as a `list` or `dict`.",
            "        \"\"\"",
            "        if value is None:",
            "            return None",
            "        if isinstance(value, str):",
            "            return JsonData(orjson.loads(value))",
            "        else:",
            "            # Use orjson to convert NumPy arrays and datetime objects to JSON.",
            "            # This ensures a backward compatibility with the previous behavior.",
            "            # See https://github.com/gradio-app/gradio/pull/8041",
            "            return JsonData(",
            "                orjson.loads(",
            "                    orjson.dumps(",
            "                        value,",
            "                        option=orjson.OPT_SERIALIZE_NUMPY",
            "                        | orjson.OPT_PASSTHROUGH_DATETIME,",
            "                        default=str,",
            "                    )",
            "                )",
            "            )",
            "",
            "    def example_payload(self) -> Any:",
            "        return {\"foo\": \"bar\"}",
            "",
            "    def example_value(self) -> Any:",
            "        return {\"foo\": \"bar\"}",
            "",
            "    def read_from_flag(self, payload: Any):",
            "        return json.loads(payload)",
            "",
            "    def api_info(self) -> dict[str, Any]:",
            "        return {\"type\": {}, \"description\": \"any valid json\"}"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "80": [
                "JSON",
                "postprocess"
            ],
            "90": [
                "JSON",
                "postprocess"
            ],
            "95": [
                "JSON",
                "postprocess"
            ],
            "96": [
                "JSON",
                "postprocess"
            ],
            "97": [
                "JSON",
                "postprocess"
            ],
            "98": [
                "JSON",
                "postprocess"
            ],
            "99": [
                "JSON",
                "postprocess"
            ]
        },
        "addLocation": []
    },
    "gradio/data_classes.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " from . import wasm_utils"
            },
            "1": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " if not wasm_utils.IS_WASM or TYPE_CHECKING:"
            },
            "3": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    from pydantic import BaseModel, RootModel, ValidationError"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+    from pydantic import BaseModel, JsonValue, RootModel, ValidationError"
            },
            "5": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " else:"
            },
            "6": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     # XXX: Currently Pyodide V2 is not available on Pyodide,"
            },
            "7": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": "     # so we install V1 for the Wasm version."
            },
            "8": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 25,
                "PatchRowcode": "     from pydantic import BaseModel as BaseModelV1"
            },
            "9": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 26,
                "PatchRowcode": "     from pydantic import ValidationError, schema_of"
            },
            "10": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+    JsonValue = Any"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+"
            },
            "13": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 30,
                "PatchRowcode": "     # Map V2 method calls to V1 implementations."
            },
            "14": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 31,
                "PatchRowcode": "     # Ref: https://docs.pydantic.dev/latest/migration/#changes-to-pydanticbasemodel"
            },
            "15": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 32,
                "PatchRowcode": "     class BaseModelMeta(type(BaseModelV1)):"
            },
            "16": {
                "beforePatchRowNumber": 161,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "         pass"
            },
            "17": {
                "beforePatchRowNumber": 162,
                "afterPatchRowNumber": 164,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 165,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 166,
                "PatchRowcode": "+class JsonData(RootModel):"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 167,
                "PatchRowcode": "+    \"\"\"JSON data returned from a component that should not be modified further.\"\"\""
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 168,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 169,
                "PatchRowcode": "+    root: JsonValue"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 170,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 171,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": 172,
                "PatchRowcode": " class GradioModel(GradioBaseModel, BaseModel):"
            },
            "26": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "     @classmethod"
            },
            "27": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "     def from_json(cls, x) -> GradioModel:"
            }
        },
        "frontPatchFile": [
            "\"\"\"Pydantic data models and other dataclasses. This is the only file that uses Optional[]",
            "typing syntax instead of | None syntax to work with pydantic\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import pathlib",
            "import secrets",
            "import shutil",
            "from abc import ABC, abstractmethod",
            "from enum import Enum, auto",
            "from typing import TYPE_CHECKING, Any, List, Optional, Tuple, Union",
            "",
            "from fastapi import Request",
            "from gradio_client.utils import traverse",
            "",
            "from . import wasm_utils",
            "",
            "if not wasm_utils.IS_WASM or TYPE_CHECKING:",
            "    from pydantic import BaseModel, RootModel, ValidationError",
            "else:",
            "    # XXX: Currently Pyodide V2 is not available on Pyodide,",
            "    # so we install V1 for the Wasm version.",
            "    from typing import Generic, TypeVar",
            "",
            "    from pydantic import BaseModel as BaseModelV1",
            "    from pydantic import ValidationError, schema_of",
            "",
            "    # Map V2 method calls to V1 implementations.",
            "    # Ref: https://docs.pydantic.dev/latest/migration/#changes-to-pydanticbasemodel",
            "    class BaseModelMeta(type(BaseModelV1)):",
            "        def __new__(cls, name, bases, dct):",
            "            # Override `dct` to dynamically create a `Config` class based on `model_config`.",
            "            if \"model_config\" in dct:",
            "                config_class = type(\"Config\", (), {})",
            "                for key, value in dct[\"model_config\"].items():",
            "                    setattr(config_class, key, value)",
            "                dct[\"Config\"] = config_class",
            "                del dct[\"model_config\"]",
            "",
            "            model_class = super().__new__(cls, name, bases, dct)",
            "            return model_class",
            "",
            "    class BaseModel(BaseModelV1, metaclass=BaseModelMeta):",
            "        pass",
            "",
            "    BaseModel.model_dump = BaseModel.dict  # type: ignore",
            "    BaseModel.model_json_schema = BaseModel.schema  # type: ignore",
            "",
            "    # RootModel is not available in V1, so we create a dummy class.",
            "    PydanticUndefined = object()",
            "    RootModelRootType = TypeVar(\"RootModelRootType\")",
            "",
            "    class RootModel(BaseModel, Generic[RootModelRootType]):",
            "        root: RootModelRootType",
            "",
            "        def __init__(self, root: RootModelRootType = PydanticUndefined, **data):",
            "            if data:",
            "                if root is not PydanticUndefined:",
            "                    raise ValueError(",
            "                        '\"RootModel.__init__\" accepts either a single positional argument or arbitrary keyword arguments'",
            "                    )",
            "                root = data  # type: ignore",
            "            # XXX: No runtime validation is executed.",
            "            super().__init__(root=root)  # type: ignore",
            "",
            "        def dict(self, **kwargs):",
            "            return super().dict(**kwargs)[\"root\"]",
            "",
            "        @classmethod",
            "        def schema(cls, **_kwargs):",
            "            # XXX: kwargs are ignored.",
            "            return schema_of(cls.__fields__[\"root\"].type_)  # type: ignore",
            "",
            "    RootModel.model_dump = RootModel.dict  # type: ignore",
            "    RootModel.model_json_schema = RootModel.schema  # type: ignore",
            "",
            "",
            "class CancelBody(BaseModel):",
            "    session_hash: str",
            "    fn_index: int",
            "    event_id: str",
            "",
            "",
            "class SimplePredictBody(BaseModel):",
            "    data: List[Any]",
            "    session_hash: Optional[str] = None",
            "",
            "",
            "class PredictBody(BaseModel):",
            "    model_config = {\"arbitrary_types_allowed\": True}",
            "",
            "    session_hash: Optional[str] = None",
            "    event_id: Optional[str] = None",
            "    data: List[Any]",
            "    event_data: Optional[Any] = None",
            "    fn_index: Optional[int] = None",
            "    trigger_id: Optional[int] = None",
            "    simple_format: bool = False",
            "    batched: Optional[bool] = (",
            "        False  # Whether the data is a batch of samples (i.e. called from the queue if batch=True) or a single sample (i.e. called from the UI)",
            "    )",
            "    request: Optional[Request] = (",
            "        None  # dictionary of request headers, query parameters, url, etc. (used to to pass in request for queuing)",
            "    )",
            "",
            "",
            "class ResetBody(BaseModel):",
            "    event_id: str",
            "",
            "",
            "class ComponentServerJSONBody(BaseModel):",
            "    session_hash: str",
            "    component_id: int",
            "    fn_name: str",
            "    data: Any",
            "",
            "",
            "class DataWithFiles(BaseModel):",
            "    data: Any",
            "    files: List[Tuple[str, bytes]]",
            "",
            "",
            "class ComponentServerBlobBody(BaseModel):",
            "    session_hash: str",
            "    component_id: int",
            "    fn_name: str",
            "    data: DataWithFiles",
            "",
            "",
            "class InterfaceTypes(Enum):",
            "    STANDARD = auto()",
            "    INPUT_ONLY = auto()",
            "    OUTPUT_ONLY = auto()",
            "    UNIFIED = auto()",
            "",
            "",
            "class GradioBaseModel(ABC):",
            "    def copy_to_dir(self, dir: str | pathlib.Path) -> GradioDataModel:",
            "        if not isinstance(self, (BaseModel, RootModel)):",
            "            raise TypeError(\"must be used in a Pydantic model\")",
            "        dir = pathlib.Path(dir)",
            "",
            "        # TODO: Making sure path is unique should be done in caller",
            "        def unique_copy(obj: dict):",
            "            data = FileData(**obj)",
            "            return data._copy_to_dir(",
            "                str(pathlib.Path(dir / secrets.token_hex(10)))",
            "            ).model_dump()",
            "",
            "        return self.__class__.from_json(",
            "            x=traverse(",
            "                self.model_dump(),",
            "                unique_copy,",
            "                FileData.is_file_data,",
            "            )",
            "        )",
            "",
            "    @classmethod",
            "    @abstractmethod",
            "    def from_json(cls, x) -> GradioDataModel:",
            "        pass",
            "",
            "",
            "class GradioModel(GradioBaseModel, BaseModel):",
            "    @classmethod",
            "    def from_json(cls, x) -> GradioModel:",
            "        return cls(**x)",
            "",
            "",
            "class GradioRootModel(GradioBaseModel, RootModel):",
            "    @classmethod",
            "    def from_json(cls, x) -> GradioRootModel:",
            "        return cls(root=x)",
            "",
            "",
            "GradioDataModel = Union[GradioModel, GradioRootModel]",
            "",
            "",
            "class FileData(GradioModel):",
            "    path: str  # server filepath",
            "    url: Optional[str] = None  # normalised server url",
            "    size: Optional[int] = None  # size in bytes",
            "    orig_name: Optional[str] = None  # original filename",
            "    mime_type: Optional[str] = None",
            "    is_stream: bool = False",
            "    meta: dict = {\"_type\": \"gradio.FileData\"}",
            "",
            "    @property",
            "    def is_none(self):",
            "        return all(",
            "            f is None",
            "            for f in [",
            "                self.path,",
            "                self.url,",
            "                self.size,",
            "                self.orig_name,",
            "                self.mime_type,",
            "            ]",
            "        )",
            "",
            "    @classmethod",
            "    def from_path(cls, path: str) -> FileData:",
            "        return cls(path=path)",
            "",
            "    def _copy_to_dir(self, dir: str) -> FileData:",
            "        pathlib.Path(dir).mkdir(exist_ok=True)",
            "        new_obj = dict(self)",
            "",
            "        if not self.path:",
            "            raise ValueError(\"Source file path is not set\")",
            "        new_name = shutil.copy(self.path, dir)",
            "        new_obj[\"path\"] = new_name",
            "        return self.__class__(**new_obj)",
            "",
            "    @classmethod",
            "    def is_file_data(cls, obj: Any):",
            "        if isinstance(obj, dict):",
            "            try:",
            "                return not FileData(**obj).is_none",
            "            except (TypeError, ValidationError):",
            "                return False",
            "        return False",
            "",
            "",
            "class ListFiles(GradioRootModel):",
            "    root: List[FileData]",
            "",
            "    def __getitem__(self, index):",
            "        return self.root[index]",
            "",
            "    def __iter__(self):",
            "        return iter(self.root)",
            "",
            "",
            "class _StaticFiles:",
            "    \"\"\"",
            "    Class to hold all static files for an app",
            "    \"\"\"",
            "",
            "    all_paths = []",
            "",
            "    def __init__(self, paths: list[str | pathlib.Path]) -> None:",
            "        self.paths = paths",
            "        self.all_paths = [pathlib.Path(p).resolve() for p in paths]",
            "",
            "    @classmethod",
            "    def clear(cls):",
            "        cls.all_paths = []"
        ],
        "afterPatchFile": [
            "\"\"\"Pydantic data models and other dataclasses. This is the only file that uses Optional[]",
            "typing syntax instead of | None syntax to work with pydantic\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import pathlib",
            "import secrets",
            "import shutil",
            "from abc import ABC, abstractmethod",
            "from enum import Enum, auto",
            "from typing import TYPE_CHECKING, Any, List, Optional, Tuple, Union",
            "",
            "from fastapi import Request",
            "from gradio_client.utils import traverse",
            "",
            "from . import wasm_utils",
            "",
            "if not wasm_utils.IS_WASM or TYPE_CHECKING:",
            "    from pydantic import BaseModel, JsonValue, RootModel, ValidationError",
            "else:",
            "    # XXX: Currently Pyodide V2 is not available on Pyodide,",
            "    # so we install V1 for the Wasm version.",
            "    from typing import Generic, TypeVar",
            "",
            "    from pydantic import BaseModel as BaseModelV1",
            "    from pydantic import ValidationError, schema_of",
            "",
            "    JsonValue = Any",
            "",
            "    # Map V2 method calls to V1 implementations.",
            "    # Ref: https://docs.pydantic.dev/latest/migration/#changes-to-pydanticbasemodel",
            "    class BaseModelMeta(type(BaseModelV1)):",
            "        def __new__(cls, name, bases, dct):",
            "            # Override `dct` to dynamically create a `Config` class based on `model_config`.",
            "            if \"model_config\" in dct:",
            "                config_class = type(\"Config\", (), {})",
            "                for key, value in dct[\"model_config\"].items():",
            "                    setattr(config_class, key, value)",
            "                dct[\"Config\"] = config_class",
            "                del dct[\"model_config\"]",
            "",
            "            model_class = super().__new__(cls, name, bases, dct)",
            "            return model_class",
            "",
            "    class BaseModel(BaseModelV1, metaclass=BaseModelMeta):",
            "        pass",
            "",
            "    BaseModel.model_dump = BaseModel.dict  # type: ignore",
            "    BaseModel.model_json_schema = BaseModel.schema  # type: ignore",
            "",
            "    # RootModel is not available in V1, so we create a dummy class.",
            "    PydanticUndefined = object()",
            "    RootModelRootType = TypeVar(\"RootModelRootType\")",
            "",
            "    class RootModel(BaseModel, Generic[RootModelRootType]):",
            "        root: RootModelRootType",
            "",
            "        def __init__(self, root: RootModelRootType = PydanticUndefined, **data):",
            "            if data:",
            "                if root is not PydanticUndefined:",
            "                    raise ValueError(",
            "                        '\"RootModel.__init__\" accepts either a single positional argument or arbitrary keyword arguments'",
            "                    )",
            "                root = data  # type: ignore",
            "            # XXX: No runtime validation is executed.",
            "            super().__init__(root=root)  # type: ignore",
            "",
            "        def dict(self, **kwargs):",
            "            return super().dict(**kwargs)[\"root\"]",
            "",
            "        @classmethod",
            "        def schema(cls, **_kwargs):",
            "            # XXX: kwargs are ignored.",
            "            return schema_of(cls.__fields__[\"root\"].type_)  # type: ignore",
            "",
            "    RootModel.model_dump = RootModel.dict  # type: ignore",
            "    RootModel.model_json_schema = RootModel.schema  # type: ignore",
            "",
            "",
            "class CancelBody(BaseModel):",
            "    session_hash: str",
            "    fn_index: int",
            "    event_id: str",
            "",
            "",
            "class SimplePredictBody(BaseModel):",
            "    data: List[Any]",
            "    session_hash: Optional[str] = None",
            "",
            "",
            "class PredictBody(BaseModel):",
            "    model_config = {\"arbitrary_types_allowed\": True}",
            "",
            "    session_hash: Optional[str] = None",
            "    event_id: Optional[str] = None",
            "    data: List[Any]",
            "    event_data: Optional[Any] = None",
            "    fn_index: Optional[int] = None",
            "    trigger_id: Optional[int] = None",
            "    simple_format: bool = False",
            "    batched: Optional[bool] = (",
            "        False  # Whether the data is a batch of samples (i.e. called from the queue if batch=True) or a single sample (i.e. called from the UI)",
            "    )",
            "    request: Optional[Request] = (",
            "        None  # dictionary of request headers, query parameters, url, etc. (used to to pass in request for queuing)",
            "    )",
            "",
            "",
            "class ResetBody(BaseModel):",
            "    event_id: str",
            "",
            "",
            "class ComponentServerJSONBody(BaseModel):",
            "    session_hash: str",
            "    component_id: int",
            "    fn_name: str",
            "    data: Any",
            "",
            "",
            "class DataWithFiles(BaseModel):",
            "    data: Any",
            "    files: List[Tuple[str, bytes]]",
            "",
            "",
            "class ComponentServerBlobBody(BaseModel):",
            "    session_hash: str",
            "    component_id: int",
            "    fn_name: str",
            "    data: DataWithFiles",
            "",
            "",
            "class InterfaceTypes(Enum):",
            "    STANDARD = auto()",
            "    INPUT_ONLY = auto()",
            "    OUTPUT_ONLY = auto()",
            "    UNIFIED = auto()",
            "",
            "",
            "class GradioBaseModel(ABC):",
            "    def copy_to_dir(self, dir: str | pathlib.Path) -> GradioDataModel:",
            "        if not isinstance(self, (BaseModel, RootModel)):",
            "            raise TypeError(\"must be used in a Pydantic model\")",
            "        dir = pathlib.Path(dir)",
            "",
            "        # TODO: Making sure path is unique should be done in caller",
            "        def unique_copy(obj: dict):",
            "            data = FileData(**obj)",
            "            return data._copy_to_dir(",
            "                str(pathlib.Path(dir / secrets.token_hex(10)))",
            "            ).model_dump()",
            "",
            "        return self.__class__.from_json(",
            "            x=traverse(",
            "                self.model_dump(),",
            "                unique_copy,",
            "                FileData.is_file_data,",
            "            )",
            "        )",
            "",
            "    @classmethod",
            "    @abstractmethod",
            "    def from_json(cls, x) -> GradioDataModel:",
            "        pass",
            "",
            "",
            "class JsonData(RootModel):",
            "    \"\"\"JSON data returned from a component that should not be modified further.\"\"\"",
            "",
            "    root: JsonValue",
            "",
            "",
            "class GradioModel(GradioBaseModel, BaseModel):",
            "    @classmethod",
            "    def from_json(cls, x) -> GradioModel:",
            "        return cls(**x)",
            "",
            "",
            "class GradioRootModel(GradioBaseModel, RootModel):",
            "    @classmethod",
            "    def from_json(cls, x) -> GradioRootModel:",
            "        return cls(root=x)",
            "",
            "",
            "GradioDataModel = Union[GradioModel, GradioRootModel]",
            "",
            "",
            "class FileData(GradioModel):",
            "    path: str  # server filepath",
            "    url: Optional[str] = None  # normalised server url",
            "    size: Optional[int] = None  # size in bytes",
            "    orig_name: Optional[str] = None  # original filename",
            "    mime_type: Optional[str] = None",
            "    is_stream: bool = False",
            "    meta: dict = {\"_type\": \"gradio.FileData\"}",
            "",
            "    @property",
            "    def is_none(self):",
            "        return all(",
            "            f is None",
            "            for f in [",
            "                self.path,",
            "                self.url,",
            "                self.size,",
            "                self.orig_name,",
            "                self.mime_type,",
            "            ]",
            "        )",
            "",
            "    @classmethod",
            "    def from_path(cls, path: str) -> FileData:",
            "        return cls(path=path)",
            "",
            "    def _copy_to_dir(self, dir: str) -> FileData:",
            "        pathlib.Path(dir).mkdir(exist_ok=True)",
            "        new_obj = dict(self)",
            "",
            "        if not self.path:",
            "            raise ValueError(\"Source file path is not set\")",
            "        new_name = shutil.copy(self.path, dir)",
            "        new_obj[\"path\"] = new_name",
            "        return self.__class__(**new_obj)",
            "",
            "    @classmethod",
            "    def is_file_data(cls, obj: Any):",
            "        if isinstance(obj, dict):",
            "            try:",
            "                return not FileData(**obj).is_none",
            "            except (TypeError, ValidationError):",
            "                return False",
            "        return False",
            "",
            "",
            "class ListFiles(GradioRootModel):",
            "    root: List[FileData]",
            "",
            "    def __getitem__(self, index):",
            "        return self.root[index]",
            "",
            "    def __iter__(self):",
            "        return iter(self.root)",
            "",
            "",
            "class _StaticFiles:",
            "    \"\"\"",
            "    Class to hold all static files for an app",
            "    \"\"\"",
            "",
            "    all_paths = []",
            "",
            "    def __init__(self, paths: list[str | pathlib.Path]) -> None:",
            "        self.paths = paths",
            "        self.all_paths = [pathlib.Path(p).resolve() for p in paths]",
            "",
            "    @classmethod",
            "    def clear(cls):",
            "        cls.all_paths = []"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "19": []
        },
        "addLocation": []
    },
    "gradio/helpers.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 933,
                "afterPatchRowNumber": 933,
                "PatchRowcode": "         ):"
            },
            "1": {
                "beforePatchRowNumber": 934,
                "afterPatchRowNumber": 934,
                "PatchRowcode": "             event_data_index = i"
            },
            "2": {
                "beforePatchRowNumber": 935,
                "afterPatchRowNumber": 935,
                "PatchRowcode": "             if inputs is not None and event_data is not None:"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 936,
                "PatchRowcode": "+                processing_utils.check_all_files_in_cache(event_data._data)"
            },
            "4": {
                "beforePatchRowNumber": 936,
                "afterPatchRowNumber": 937,
                "PatchRowcode": "                 inputs.insert(i, type_hint(event_data.target, event_data._data))"
            },
            "5": {
                "beforePatchRowNumber": 937,
                "afterPatchRowNumber": 938,
                "PatchRowcode": "         elif ("
            },
            "6": {
                "beforePatchRowNumber": 938,
                "afterPatchRowNumber": 939,
                "PatchRowcode": "             param.default is not param.empty and inputs is not None and len(inputs) <= i"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Defines helper methods useful for loading and caching Interface examples.",
            "\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import ast",
            "import csv",
            "import inspect",
            "import os",
            "import shutil",
            "import subprocess",
            "import tempfile",
            "import warnings",
            "from functools import partial",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any, Callable, Iterable, Literal, Optional",
            "",
            "import numpy as np",
            "import PIL",
            "import PIL.Image",
            "from gradio_client import utils as client_utils",
            "from gradio_client.documentation import document",
            "",
            "from gradio import components, oauth, processing_utils, routes, utils, wasm_utils",
            "from gradio.context import Context, LocalContext",
            "from gradio.data_classes import GradioModel, GradioRootModel",
            "from gradio.events import EventData",
            "from gradio.exceptions import Error",
            "from gradio.flagging import CSVLogger",
            "",
            "if TYPE_CHECKING:  # Only import for type checking (to avoid circular imports).",
            "    from gradio.components import Component",
            "",
            "LOG_FILE = \"log.csv\"",
            "",
            "",
            "def create_examples(",
            "    examples: list[Any] | list[list[Any]] | str,",
            "    inputs: Component | list[Component],",
            "    outputs: Component | list[Component] | None = None,",
            "    fn: Callable | None = None,",
            "    cache_examples: bool | Literal[\"lazy\"] | None = None,",
            "    examples_per_page: int = 10,",
            "    _api_mode: bool = False,",
            "    label: str | None = None,",
            "    elem_id: str | None = None,",
            "    run_on_click: bool = False,",
            "    preprocess: bool = True,",
            "    postprocess: bool = True,",
            "    api_name: str | Literal[False] = \"load_example\",",
            "    batch: bool = False,",
            "    _defer_caching: bool = False,",
            "):",
            "    \"\"\"Top-level synchronous function that creates Examples. Provided for backwards compatibility, i.e. so that gr.Examples(...) can be used to create the Examples component.\"\"\"",
            "    examples_obj = Examples(",
            "        examples=examples,",
            "        inputs=inputs,",
            "        outputs=outputs,",
            "        fn=fn,",
            "        cache_examples=cache_examples,",
            "        examples_per_page=examples_per_page,",
            "        _api_mode=_api_mode,",
            "        label=label,",
            "        elem_id=elem_id,",
            "        run_on_click=run_on_click,",
            "        preprocess=preprocess,",
            "        postprocess=postprocess,",
            "        api_name=api_name,",
            "        batch=batch,",
            "        _defer_caching=_defer_caching,",
            "        _initiated_directly=False,",
            "    )",
            "    examples_obj.create()",
            "    return examples_obj",
            "",
            "",
            "@document()",
            "class Examples:",
            "    \"\"\"",
            "    This class is a wrapper over the Dataset component and can be used to create Examples",
            "    for Blocks / Interfaces. Populates the Dataset component with examples and",
            "    assigns event listener so that clicking on an example populates the input/output",
            "    components. Optionally handles example caching for fast inference.",
            "",
            "    Demos: fake_gan",
            "    Guides: more-on-examples-and-flagging, using-hugging-face-integrations, image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers, create-your-own-friends-with-a-gan",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        examples: list[Any] | list[list[Any]] | str,",
            "        inputs: Component | list[Component],",
            "        outputs: Component | list[Component] | None = None,",
            "        fn: Callable | None = None,",
            "        cache_examples: bool | Literal[\"lazy\"] | None = None,",
            "        examples_per_page: int = 10,",
            "        _api_mode: bool = False,",
            "        label: str | None = \"Examples\",",
            "        elem_id: str | None = None,",
            "        run_on_click: bool = False,",
            "        preprocess: bool = True,",
            "        postprocess: bool = True,",
            "        api_name: str | Literal[False] = \"load_example\",",
            "        batch: bool = False,",
            "        _defer_caching: bool = False,",
            "        _initiated_directly: bool = True,",
            "    ):",
            "        \"\"\"",
            "        Parameters:",
            "            examples: example inputs that can be clicked to populate specific components. Should be nested list, in which the outer list consists of samples and each inner list consists of an input corresponding to each input component. A string path to a directory of examples can also be provided but it should be within the directory with the python file running the gradio app. If there are multiple input components and a directory is provided, a log.csv file must be present in the directory to link corresponding inputs.",
            "            inputs: the component or list of components corresponding to the examples",
            "            outputs: optionally, provide the component or list of components corresponding to the output of the examples. Required if `cache_examples` is not False.",
            "            fn: optionally, provide the function to run to generate the outputs corresponding to the examples. Required if `cache_examples` is not False. Also required if `run_on_click` is True.",
            "            cache_examples: If True, caches examples in the server for fast runtime in examples. If \"lazy\", then examples are cached after their first use. Can also be set by the GRADIO_CACHE_EXAMPLES environment variable, which takes a case-insensitive value, one of: {\"true\", \"lazy\", or \"false\"} (for the first two to take effect, `fn` and `outputs` should also be provided). In HuggingFace Spaces, this is True (as long as `fn` and `outputs` are also provided). The default option otherwise is False.",
            "            examples_per_page: how many examples to show per page.",
            "            label: the label to use for the examples component (by default, \"Examples\")",
            "            elem_id: an optional string that is assigned as the id of this component in the HTML DOM.",
            "            run_on_click: if cache_examples is False, clicking on an example does not run the function when an example is clicked. Set this to True to run the function when an example is clicked. Has no effect if cache_examples is True.",
            "            preprocess: if True, preprocesses the example input before running the prediction function and caching the output. Only applies if `cache_examples` is not False.",
            "            postprocess: if True, postprocesses the example output after running the prediction function and before caching. Only applies if `cache_examples` is not False.",
            "            api_name: Defines how the event associated with clicking on the examples appears in the API docs. Can be a string or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use the example function.",
            "            batch: If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. Used only if cache_examples is not False.",
            "        \"\"\"",
            "        if _initiated_directly:",
            "            warnings.warn(",
            "                \"Please use gr.Examples(...) instead of gr.examples.Examples(...) to create the Examples.\",",
            "            )",
            "",
            "        if cache_examples is None:",
            "            if cache_examples_env := os.getenv(\"GRADIO_CACHE_EXAMPLES\"):",
            "                if cache_examples_env.lower() == \"true\":",
            "                    if fn is not None and outputs is not None:",
            "                        self.cache_examples = True",
            "                    else:",
            "                        self.cache_examples = False",
            "                elif cache_examples_env.lower() == \"lazy\":",
            "                    if fn is not None and outputs is not None:",
            "                        self.cache_examples = \"lazy\"",
            "                    else:",
            "                        self.cache_examples = False",
            "                elif cache_examples_env.lower() == \"false\":",
            "                    self.cache_examples = False",
            "                else:",
            "                    raise ValueError(",
            "                        \"The `GRADIO_CACHE_EXAMPLES` env variable must be one of: 'true', 'false', 'lazy' (case-insensitive).\"",
            "                    )",
            "            elif utils.get_space() and fn is not None and outputs is not None:",
            "                self.cache_examples = True",
            "            else:",
            "                self.cache_examples = cache_examples or False",
            "        else:",
            "            if cache_examples not in [True, False, \"lazy\"]:",
            "                raise ValueError(",
            "                    \"The `cache_examples` parameter must be one of: True, False, 'lazy'.\"",
            "                )",
            "            self.cache_examples = cache_examples",
            "",
            "        if self.cache_examples and (fn is None or outputs is None):",
            "            raise ValueError(\"If caching examples, `fn` and `outputs` must be provided\")",
            "        self._defer_caching = _defer_caching",
            "",
            "        if not isinstance(inputs, list):",
            "            inputs = [inputs]",
            "        if outputs and not isinstance(outputs, list):",
            "            outputs = [outputs]",
            "",
            "        working_directory = Path().absolute()",
            "",
            "        if examples is None:",
            "            raise ValueError(\"The parameter `examples` cannot be None\")",
            "        elif isinstance(examples, list) and (",
            "            len(examples) == 0 or isinstance(examples[0], list)",
            "        ):",
            "            pass",
            "        elif (",
            "            isinstance(examples, list) and len(inputs) == 1",
            "        ):  # If there is only one input component, examples can be provided as a regular list instead of a list of lists",
            "            examples = [[e] for e in examples]",
            "        elif isinstance(examples, str):",
            "            if not Path(examples).exists():",
            "                raise FileNotFoundError(",
            "                    f\"Could not find examples directory: {examples}\"",
            "                )",
            "            working_directory = examples",
            "            if not (Path(examples) / LOG_FILE).exists():",
            "                if len(inputs) == 1:",
            "                    examples = [[e] for e in os.listdir(examples)]",
            "                else:",
            "                    raise FileNotFoundError(",
            "                        \"Could not find log file (required for multiple inputs): \"",
            "                        + LOG_FILE",
            "                    )",
            "            else:",
            "                with open(Path(examples) / LOG_FILE) as logs:",
            "                    examples = list(csv.reader(logs))",
            "                    examples = [",
            "                        examples[i][: len(inputs)] for i in range(1, len(examples))",
            "                    ]  # remove header and unnecessary columns",
            "",
            "        else:",
            "            raise ValueError(",
            "                \"The parameter `examples` must either be a string directory or a list\"",
            "                \"(if there is only 1 input component) or (more generally), a nested \"",
            "                \"list, where each sublist represents a set of inputs.\"",
            "            )",
            "",
            "        input_has_examples = [False] * len(inputs)",
            "        for example in examples:",
            "            for idx, example_for_input in enumerate(example):",
            "                if example_for_input is not None:",
            "                    try:",
            "                        input_has_examples[idx] = True",
            "                    except IndexError:",
            "                        pass  # If there are more example components than inputs, ignore. This can sometimes be intentional (e.g. loading from a log file where outputs and timestamps are also logged)",
            "",
            "        inputs_with_examples = [",
            "            inp for (inp, keep) in zip(inputs, input_has_examples) if keep",
            "        ]",
            "        non_none_examples = [",
            "            [ex for (ex, keep) in zip(example, input_has_examples) if keep]",
            "            for example in examples",
            "        ]",
            "",
            "        self.examples = examples",
            "        self.non_none_examples = non_none_examples",
            "        self.inputs = inputs",
            "        self.inputs_with_examples = inputs_with_examples",
            "        self.outputs = outputs or []",
            "        self.fn = fn",
            "        self._api_mode = _api_mode",
            "        self.preprocess = preprocess",
            "        self.postprocess = postprocess",
            "        self.api_name: str | Literal[False] = api_name",
            "        self.batch = batch",
            "",
            "        with utils.set_directory(working_directory):",
            "            self.processed_examples = []",
            "            for example in examples:",
            "                sub = []",
            "                for component, sample in zip(inputs, example):",
            "                    prediction_value = component.postprocess(sample)",
            "                    if isinstance(prediction_value, (GradioRootModel, GradioModel)):",
            "                        prediction_value = prediction_value.model_dump()",
            "                    prediction_value = processing_utils.move_files_to_cache(",
            "                        prediction_value,",
            "                        component,",
            "                        postprocess=True,",
            "                    )",
            "                    sub.append(prediction_value)",
            "                self.processed_examples.append(sub)",
            "",
            "        self.non_none_processed_examples = [",
            "            [ex for (ex, keep) in zip(example, input_has_examples) if keep]",
            "            for example in self.processed_examples",
            "        ]",
            "",
            "        from gradio import components",
            "",
            "        with utils.set_directory(working_directory):",
            "            self.dataset = components.Dataset(",
            "                components=inputs_with_examples,",
            "                samples=non_none_examples,",
            "                type=\"index\",",
            "                label=label,",
            "                samples_per_page=examples_per_page,",
            "                elem_id=elem_id,",
            "            )",
            "",
            "        self.cache_logger = CSVLogger(simplify_file_data=False)",
            "        self.cached_folder = utils.get_cache_folder() / str(self.dataset._id)",
            "        self.cached_file = Path(self.cached_folder) / \"log.csv\"",
            "        self.cached_indices_file = Path(self.cached_folder) / \"indices.csv\"",
            "        self.run_on_click = run_on_click",
            "",
            "    def create(self) -> None:",
            "        \"\"\"Caches the examples if self.cache_examples is True and creates the Dataset",
            "        component to hold the examples\"\"\"",
            "",
            "        async def load_example(example_id):",
            "            processed_example = self.non_none_processed_examples[example_id]",
            "            if len(self.inputs_with_examples) == 1:",
            "                return update(",
            "                    value=processed_example[0],",
            "                    **self.dataset.component_props[0],  # type: ignore",
            "                )",
            "            return [",
            "                update(value=processed_example[i], **self.dataset.component_props[i])  # type: ignore",
            "                for i in range(len(self.inputs_with_examples))",
            "            ]",
            "",
            "        if Context.root_block:",
            "            self.load_input_event = self.dataset.click(",
            "                load_example,",
            "                inputs=[self.dataset],",
            "                outputs=self.inputs_with_examples,  # type: ignore",
            "                show_progress=\"hidden\",",
            "                postprocess=False,",
            "                queue=False,",
            "                api_name=self.api_name,",
            "                show_api=False,",
            "            )",
            "            self.load_input_event_id = len(Context.root_block.fns) - 1",
            "            if self.run_on_click and not self.cache_examples:",
            "                if self.fn is None:",
            "                    raise ValueError(\"Cannot run_on_click if no function is provided\")",
            "                self.load_input_event.then(",
            "                    self.fn,",
            "                    inputs=self.inputs,  # type: ignore",
            "                    outputs=self.outputs,  # type: ignore",
            "                    show_api=False,",
            "                )",
            "        if not self._defer_caching:",
            "            self._start_caching()",
            "",
            "    async def _postprocess_output(self, output) -> list:",
            "        \"\"\"",
            "        This is a way that we can postprocess the data manually, since we set postprocess=False in the lazy_cache",
            "        event handler. The reason we did that is because we don't want to postprocess data if we are loading from",
            "        the cache, since that has already been postprocessed. We postprocess this data manually if we are calling",
            "        the function using the _handle_callable_as_generator() method.",
            "        \"\"\"",
            "        import gradio as gr",
            "",
            "        with gr.Blocks() as demo:",
            "            [output.render() for output in self.outputs]",
            "            demo.load(self.fn, self.inputs, self.outputs)",
            "        demo.unrender()",
            "        return await demo.postprocess_data(0, output, None)",
            "",
            "    def _get_cached_index_if_cached(self, example_index) -> int | None:",
            "        if Path(self.cached_indices_file).exists():",
            "            with open(self.cached_indices_file) as f:",
            "                cached_indices = [int(line.strip()) for line in f]",
            "            if example_index in cached_indices:",
            "                cached_index = cached_indices.index(example_index)",
            "                return cached_index",
            "        return None",
            "",
            "    def _start_caching(self):",
            "        if self.cache_examples:",
            "            for example in self.examples:",
            "                if len([ex for ex in example if ex is not None]) != len(self.inputs):",
            "                    warnings.warn(",
            "                        \"Examples will be cached but not all input components have \"",
            "                        \"example values. This may result in an exception being thrown by \"",
            "                        \"your function. If you do get an error while caching examples, make \"",
            "                        \"sure all of your inputs have example values for all of your examples \"",
            "                        \"or you provide default values for those particular parameters in your function.\"",
            "                    )",
            "                    break",
            "        if self.cache_examples == \"lazy\":",
            "            client_utils.synchronize_async(self.lazy_cache)",
            "        if self.cache_examples is True:",
            "            if wasm_utils.IS_WASM:",
            "                # In the Wasm mode, the `threading` module is not supported,",
            "                # so `client_utils.synchronize_async` is also not available.",
            "                # And `self.cache()` should be waited for to complete before this method returns,",
            "                # (otherwise, an error \"Cannot cache examples if not in a Blocks context\" will be raised anyway)",
            "                # so `eventloop.create_task(self.cache())` is also not an option.",
            "                warnings.warn(",
            "                    \"Setting `cache_examples=True` is not supported in the Wasm mode. You can set `cache_examples='lazy'` to cache examples after first use.\"",
            "                )",
            "            else:",
            "                client_utils.synchronize_async(self.cache)",
            "",
            "    async def lazy_cache(self) -> None:",
            "        print(",
            "            f\"Will cache examples in '{utils.abspath(self.cached_folder)}' directory at first use. \",",
            "            end=\"\",",
            "        )",
            "        if Path(self.cached_file).exists():",
            "            print(",
            "                \"If method or examples have changed since last caching, delete this folder to reset cache.\",",
            "                end=\"\",",
            "            )",
            "        print(\"\\n\\n\")",
            "        self.cache_logger.setup(self.outputs, self.cached_folder)",
            "        if inspect.iscoroutinefunction(self.fn) or inspect.isasyncgenfunction(self.fn):",
            "            lazy_cache_fn = self.async_lazy_cache",
            "        else:",
            "            lazy_cache_fn = self.sync_lazy_cache",
            "        self.load_input_event.then(",
            "            lazy_cache_fn,",
            "            inputs=[self.dataset] + self.inputs,",
            "            outputs=self.outputs,",
            "            postprocess=False,",
            "            api_name=self.api_name,",
            "            show_api=False,",
            "        )",
            "",
            "    async def async_lazy_cache(self, example_index, *input_values):",
            "        cached_index = self._get_cached_index_if_cached(example_index)",
            "        if cached_index is not None:",
            "            output = self.load_from_cache(cached_index)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "            return",
            "        output = [None] * len(self.outputs)",
            "        if inspect.isasyncgenfunction(self.fn):",
            "            fn = self.fn",
            "        else:",
            "            fn = utils.async_fn_to_generator(self.fn)",
            "        async for output in fn(*input_values):",
            "            output = await self._postprocess_output(output)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "        self.cache_logger.flag(output)",
            "        with open(self.cached_indices_file, \"a\") as f:",
            "            f.write(f\"{example_index}\\n\")",
            "",
            "    def sync_lazy_cache(self, example_index, *input_values):",
            "        cached_index = self._get_cached_index_if_cached(example_index)",
            "        if cached_index is not None:",
            "            output = self.load_from_cache(cached_index)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "            return",
            "        output = [None] * len(self.outputs)",
            "        if inspect.isgeneratorfunction(self.fn):",
            "            fn = self.fn",
            "        else:",
            "            fn = utils.sync_fn_to_generator(self.fn)",
            "        for output in fn(*input_values):",
            "            output = client_utils.synchronize_async(self._postprocess_output, output)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "        self.cache_logger.flag(output)",
            "        with open(self.cached_indices_file, \"a\") as f:",
            "            f.write(f\"{example_index}\\n\")",
            "",
            "    async def cache(self) -> None:",
            "        \"\"\"",
            "        Caches examples so that their predictions can be shown immediately.",
            "        \"\"\"",
            "        if Context.root_block is None:",
            "            raise ValueError(\"Cannot cache examples if not in a Blocks context\")",
            "        if Path(self.cached_file).exists():",
            "            print(",
            "                f\"Using cache from '{utils.abspath(self.cached_folder)}' directory. If method or examples have changed since last caching, delete this folder to clear cache.\\n\"",
            "            )",
            "        else:",
            "            print(f\"Caching examples at: '{utils.abspath(self.cached_folder)}'\")",
            "            self.cache_logger.setup(self.outputs, self.cached_folder)",
            "            generated_values = []",
            "            if inspect.isgeneratorfunction(self.fn):",
            "",
            "                def get_final_item(*args):  # type: ignore",
            "                    x = None",
            "                    generated_values.clear()",
            "                    for x in self.fn(*args):  # noqa: B007  # type: ignore",
            "                        generated_values.append(x)",
            "                    return x",
            "",
            "                fn = get_final_item",
            "            elif inspect.isasyncgenfunction(self.fn):",
            "",
            "                async def get_final_item(*args):",
            "                    x = None",
            "                    generated_values.clear()",
            "                    async for x in self.fn(*args):  # noqa: B007  # type: ignore",
            "                        generated_values.append(x)",
            "                    return x",
            "",
            "                fn = get_final_item",
            "            else:",
            "                fn = self.fn",
            "",
            "            # create a fake dependency to process the examples and get the predictions",
            "            from gradio.events import EventListenerMethod",
            "",
            "            dependency, fn_index = Context.root_block.set_event_trigger(",
            "                [EventListenerMethod(Context.root_block, \"load\")],",
            "                fn=fn,",
            "                inputs=self.inputs_with_examples,  # type: ignore",
            "                outputs=self.outputs,  # type: ignore",
            "                preprocess=self.preprocess and not self._api_mode,",
            "                postprocess=self.postprocess and not self._api_mode,",
            "                batch=self.batch,",
            "            )",
            "",
            "            if self.outputs is None:",
            "                raise ValueError(\"self.outputs is missing\")",
            "            for example_id in range(len(self.examples)):",
            "                print(f\"Caching example {example_id + 1}/{len(self.examples)}\")",
            "                processed_input = self.processed_examples[example_id]",
            "                if self.batch:",
            "                    processed_input = [[value] for value in processed_input]",
            "                with utils.MatplotlibBackendMananger():",
            "                    prediction = await Context.root_block.process_api(",
            "                        fn_index=fn_index,",
            "                        inputs=processed_input,",
            "                        request=None,",
            "                    )",
            "                output = prediction[\"data\"]",
            "                if len(generated_values):",
            "                    output = merge_generated_values_into_output(",
            "                        self.outputs, generated_values, output",
            "                    )",
            "                if self.batch:",
            "                    output = [value[0] for value in output]",
            "                self.cache_logger.flag(output)",
            "            # Remove the \"fake_event\" to prevent bugs in loading interfaces from spaces",
            "            Context.root_block.fns.pop(fn_index)",
            "",
            "        # Remove the original load_input_event and replace it with one that",
            "        # also populates the input. We do it this way to to allow the cache()",
            "        # method to be called independently of the create() method",
            "        Context.root_block.fns.pop(self.load_input_event_id)",
            "",
            "        def load_example(example_id):",
            "            processed_example = self.non_none_processed_examples[",
            "                example_id",
            "            ] + self.load_from_cache(example_id)",
            "            return utils.resolve_singleton(processed_example)",
            "",
            "        self.load_input_event = self.dataset.click(",
            "            load_example,",
            "            inputs=[self.dataset],",
            "            outputs=self.inputs_with_examples + self.outputs,  # type: ignore",
            "            show_progress=\"hidden\",",
            "            postprocess=False,",
            "            queue=False,",
            "            api_name=self.api_name,",
            "            show_api=False,",
            "        )",
            "        self.load_input_event_id = len(Context.root_block.fns) - 1",
            "",
            "    def load_from_cache(self, example_id: int) -> list[Any]:",
            "        \"\"\"Loads a particular cached example for the interface.",
            "        Parameters:",
            "            example_id: The id of the example to process (zero-indexed).",
            "        \"\"\"",
            "        with open(self.cached_file, encoding=\"utf-8\") as cache:",
            "            examples = list(csv.reader(cache))",
            "        example = examples[example_id + 1]  # +1 to adjust for header",
            "        output = []",
            "        if self.outputs is None:",
            "            raise ValueError(\"self.outputs is missing\")",
            "        for component, value in zip(self.outputs, example):",
            "            value_to_use = value",
            "            try:",
            "                value_as_dict = ast.literal_eval(value)",
            "                # File components that output multiple files get saved as a python list",
            "                # need to pass the parsed list to serialize",
            "                # TODO: Better file serialization in 4.0",
            "                if isinstance(value_as_dict, list) and isinstance(",
            "                    component, components.File",
            "                ):",
            "                    value_to_use = value_as_dict",
            "                if not utils.is_update(value_as_dict):",
            "                    raise TypeError(\"value wasn't an update\")  # caught below",
            "                output.append(value_as_dict)",
            "            except (ValueError, TypeError, SyntaxError):",
            "                output.append(component.read_from_flag(value_to_use))",
            "        return output",
            "",
            "",
            "def merge_generated_values_into_output(",
            "    components: list[Component], generated_values: list, output: list",
            "):",
            "    from gradio.components.base import StreamingOutput",
            "",
            "    for output_index, output_component in enumerate(components):",
            "        if isinstance(output_component, StreamingOutput) and output_component.streaming:",
            "            binary_chunks = []",
            "            for i, chunk in enumerate(generated_values):",
            "                if len(components) > 1:",
            "                    chunk = chunk[output_index]",
            "                processed_chunk = output_component.postprocess(chunk)",
            "                if isinstance(processed_chunk, (GradioModel, GradioRootModel)):",
            "                    processed_chunk = processed_chunk.model_dump()",
            "                binary_chunks.append(",
            "                    output_component.stream_output(processed_chunk, \"\", i == 0)[0]",
            "                )",
            "            binary_data = b\"\".join(binary_chunks)",
            "            tempdir = os.environ.get(\"GRADIO_TEMP_DIR\") or str(",
            "                Path(tempfile.gettempdir()) / \"gradio\"",
            "            )",
            "            os.makedirs(tempdir, exist_ok=True)",
            "            temp_file = tempfile.NamedTemporaryFile(dir=tempdir, delete=False)",
            "            with open(temp_file.name, \"wb\") as f:",
            "                f.write(binary_data)",
            "",
            "            output[output_index] = {",
            "                \"path\": temp_file.name,",
            "            }",
            "",
            "    return output",
            "",
            "",
            "class TrackedIterable:",
            "    def __init__(",
            "        self,",
            "        iterable: Iterable | None,",
            "        index: int | None,",
            "        length: int | None,",
            "        desc: str | None,",
            "        unit: str | None,",
            "        _tqdm=None,",
            "        progress: float | None = None,",
            "    ) -> None:",
            "        self.iterable = iterable",
            "        self.index = index",
            "        self.length = length",
            "        self.desc = desc",
            "        self.unit = unit",
            "        self._tqdm = _tqdm",
            "        self.progress = progress",
            "",
            "",
            "@document(\"__call__\", \"tqdm\")",
            "class Progress(Iterable):",
            "    \"\"\"",
            "    The Progress class provides a custom progress tracker that is used in a function signature.",
            "    To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a `gradio.Progress()` instance.",
            "    The Progress tracker can then be updated in the function by calling the Progress object or using the `tqdm` method on an Iterable.",
            "    The Progress tracker is currently only available with `queue()`.",
            "    Example:",
            "        import gradio as gr",
            "        import time",
            "        def my_function(x, progress=gr.Progress()):",
            "            progress(0, desc=\"Starting...\")",
            "            time.sleep(1)",
            "            for i in progress.tqdm(range(100)):",
            "                time.sleep(0.1)",
            "            return x",
            "        gr.Interface(my_function, gr.Textbox(), gr.Textbox()).queue().launch()",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        track_tqdm: bool = False,",
            "    ):",
            "        \"\"\"",
            "        Parameters:",
            "            track_tqdm: If True, the Progress object will track any tqdm.tqdm iterations with the tqdm library in the function.",
            "        \"\"\"",
            "        if track_tqdm:",
            "            patch_tqdm()",
            "        self.track_tqdm = track_tqdm",
            "        self.iterables: list[TrackedIterable] = []",
            "",
            "    def __len__(self):",
            "        return self.iterables[-1].length",
            "",
            "    def __iter__(self):",
            "        return self",
            "",
            "    def __next__(self):",
            "        \"\"\"",
            "        Updates progress tracker with next item in iterable.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            current_iterable = self.iterables[-1]",
            "            while (",
            "                not hasattr(current_iterable.iterable, \"__next__\")",
            "                and len(self.iterables) > 0",
            "            ):",
            "                current_iterable = self.iterables.pop()",
            "            callback(self.iterables)",
            "            if current_iterable.index is None:",
            "                raise IndexError(\"Index not set.\")",
            "            current_iterable.index += 1",
            "            try:",
            "                return next(current_iterable.iterable)  # type: ignore",
            "            except StopIteration:",
            "                self.iterables.pop()",
            "                raise",
            "        else:",
            "            return self",
            "",
            "    def __call__(",
            "        self,",
            "        progress: float | tuple[int, int | None] | None,",
            "        desc: str | None = None,",
            "        total: int | None = None,",
            "        unit: str = \"steps\",",
            "        _tqdm=None,",
            "    ):",
            "        \"\"\"",
            "        Updates progress tracker with progress and message text.",
            "        Parameters:",
            "            progress: If float, should be between 0 and 1 representing completion. If Tuple, first number represents steps completed, and second value represents total steps or None if unknown. If None, hides progress bar.",
            "            desc: description to display.",
            "            total: estimated total number of steps.",
            "            unit: unit of iterations.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            if isinstance(progress, tuple):",
            "                index, total = progress",
            "                progress = None",
            "            else:",
            "                index = None",
            "            callback(",
            "                self.iterables",
            "                + [TrackedIterable(None, index, total, desc, unit, _tqdm, progress)]",
            "            )",
            "        else:",
            "            return progress",
            "",
            "    def tqdm(",
            "        self,",
            "        iterable: Iterable | None,",
            "        desc: str | None = None,",
            "        total: int | None = None,",
            "        unit: str = \"steps\",",
            "        _tqdm=None,",
            "    ):",
            "        \"\"\"",
            "        Attaches progress tracker to iterable, like tqdm.",
            "        Parameters:",
            "            iterable: iterable to attach progress tracker to.",
            "            desc: description to display.",
            "            total: estimated total number of steps.",
            "            unit: unit of iterations.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            if iterable is None:",
            "                new_iterable = TrackedIterable(None, 0, total, desc, unit, _tqdm)",
            "                self.iterables.append(new_iterable)",
            "                callback(self.iterables)",
            "                return self",
            "            length = len(iterable) if hasattr(iterable, \"__len__\") else None  # type: ignore",
            "            self.iterables.append(",
            "                TrackedIterable(iter(iterable), 0, length, desc, unit, _tqdm)",
            "            )",
            "        return self",
            "",
            "    def update(self, n=1):",
            "        \"\"\"",
            "        Increases latest iterable with specified number of steps.",
            "        Parameters:",
            "            n: number of steps completed.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback and len(self.iterables) > 0:",
            "            current_iterable = self.iterables[-1]",
            "            if current_iterable.index is None:",
            "                raise IndexError(\"Index not set.\")",
            "            current_iterable.index += n",
            "            callback(self.iterables)",
            "        else:",
            "            return",
            "",
            "    def close(self, _tqdm):",
            "        \"\"\"",
            "        Removes iterable with given _tqdm.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            for i in range(len(self.iterables)):",
            "                if id(self.iterables[i]._tqdm) == id(_tqdm):",
            "                    self.iterables.pop(i)",
            "                    break",
            "            callback(self.iterables)",
            "        else:",
            "            return",
            "",
            "    @staticmethod",
            "    def _progress_callback():",
            "        blocks = LocalContext.blocks.get()",
            "        event_id = LocalContext.event_id.get()",
            "        if not (blocks and event_id):",
            "            return None",
            "        return partial(blocks._queue.set_progress, event_id)",
            "",
            "",
            "def patch_tqdm() -> None:",
            "    try:",
            "        _tqdm = __import__(\"tqdm\")",
            "    except ModuleNotFoundError:",
            "        return",
            "",
            "    def init_tqdm(",
            "        self, iterable=None, desc=None, total=None, unit=\"steps\", *args, **kwargs",
            "    ):",
            "        self._progress = LocalContext.progress.get()",
            "        if self._progress is not None:",
            "            self._progress.tqdm(iterable, desc, total, unit, _tqdm=self)",
            "            kwargs[\"file\"] = open(os.devnull, \"w\")  # noqa: SIM115",
            "        self.__init__orig__(iterable, desc, total, *args, unit=unit, **kwargs)",
            "",
            "    def iter_tqdm(self):",
            "        if self._progress is not None:",
            "            return self._progress",
            "        return self.__iter__orig__()",
            "",
            "    def update_tqdm(self, n=1):",
            "        if self._progress is not None:",
            "            self._progress.update(n)",
            "        return self.__update__orig__(n)",
            "",
            "    def close_tqdm(self):",
            "        if self._progress is not None:",
            "            self._progress.close(self)",
            "        return self.__close__orig__()",
            "",
            "    def exit_tqdm(self, exc_type, exc_value, traceback):",
            "        if self._progress is not None:",
            "            self._progress.close(self)",
            "        return self.__exit__orig__(exc_type, exc_value, traceback)",
            "",
            "    # Backup",
            "    if not hasattr(_tqdm.tqdm, \"__init__orig__\"):",
            "        _tqdm.tqdm.__init__orig__ = _tqdm.tqdm.__init__",
            "    if not hasattr(_tqdm.tqdm, \"__update__orig__\"):",
            "        _tqdm.tqdm.__update__orig__ = _tqdm.tqdm.update",
            "    if not hasattr(_tqdm.tqdm, \"__close__orig__\"):",
            "        _tqdm.tqdm.__close__orig__ = _tqdm.tqdm.close",
            "    if not hasattr(_tqdm.tqdm, \"__exit__orig__\"):",
            "        _tqdm.tqdm.__exit__orig__ = _tqdm.tqdm.__exit__",
            "    if not hasattr(_tqdm.tqdm, \"__iter__orig__\"):",
            "        _tqdm.tqdm.__iter__orig__ = _tqdm.tqdm.__iter__",
            "",
            "    # Patch",
            "    _tqdm.tqdm.__init__ = init_tqdm",
            "    _tqdm.tqdm.update = update_tqdm",
            "    _tqdm.tqdm.close = close_tqdm",
            "    _tqdm.tqdm.__exit__ = exit_tqdm",
            "    _tqdm.tqdm.__iter__ = iter_tqdm",
            "",
            "    if hasattr(_tqdm, \"auto\") and hasattr(_tqdm.auto, \"tqdm\"):",
            "        _tqdm.auto.tqdm = _tqdm.tqdm",
            "",
            "",
            "def create_tracker(fn, track_tqdm):",
            "    progress = Progress(track_tqdm=track_tqdm)",
            "    if not track_tqdm:",
            "        return progress, fn",
            "    return progress, utils.function_wrapper(",
            "        f=fn,",
            "        before_fn=LocalContext.progress.set,",
            "        before_args=(progress,),",
            "        after_fn=LocalContext.progress.set,",
            "        after_args=(None,),",
            "    )",
            "",
            "",
            "def special_args(",
            "    fn: Callable,",
            "    inputs: list[Any] | None = None,",
            "    request: routes.Request | None = None,",
            "    event_data: EventData | None = None,",
            ") -> tuple[list, int | None, int | None]:",
            "    \"\"\"",
            "    Checks if function has special arguments Request or EventData (via annotation) or Progress (via default value).",
            "    If inputs is provided, these values will be loaded into the inputs array.",
            "    Parameters:",
            "        fn: function to check.",
            "        inputs: array to load special arguments into.",
            "        request: request to load into inputs.",
            "        event_data: event-related data to load into inputs.",
            "    Returns:",
            "        updated inputs, progress index, event data index.",
            "    \"\"\"",
            "    try:",
            "        signature = inspect.signature(fn)",
            "    except ValueError:",
            "        return inputs or [], None, None",
            "    type_hints = utils.get_type_hints(fn)",
            "    positional_args = []",
            "    for param in signature.parameters.values():",
            "        if param.kind not in (param.POSITIONAL_ONLY, param.POSITIONAL_OR_KEYWORD):",
            "            break",
            "        positional_args.append(param)",
            "    progress_index = None",
            "    event_data_index = None",
            "    for i, param in enumerate(positional_args):",
            "        type_hint = type_hints.get(param.name)",
            "        if isinstance(param.default, Progress):",
            "            progress_index = i",
            "            if inputs is not None:",
            "                inputs.insert(i, param.default)",
            "        elif type_hint == routes.Request:",
            "            if inputs is not None:",
            "                inputs.insert(i, request)",
            "        elif type_hint in (",
            "            # Note: \"OAuthProfile | None\" is equals to Optional[OAuthProfile] in Python",
            "            #       => it is automatically handled as well by the above condition",
            "            #       (adding explicit \"OAuthProfile | None\" would break in Python3.9)",
            "            #       (same for \"OAuthToken\")",
            "            Optional[oauth.OAuthProfile],",
            "            Optional[oauth.OAuthToken],",
            "            oauth.OAuthProfile,",
            "            oauth.OAuthToken,",
            "        ):",
            "            if inputs is not None:",
            "                # Retrieve session from gr.Request, if it exists (i.e. if user is logged in)",
            "                session = (",
            "                    # request.session (if fastapi.Request obj i.e. direct call)",
            "                    getattr(request, \"session\", {})",
            "                    or",
            "                    # or request.request.session (if gr.Request obj i.e. websocket call)",
            "                    getattr(getattr(request, \"request\", None), \"session\", {})",
            "                )",
            "",
            "                # Inject user profile",
            "                if type_hint in (Optional[oauth.OAuthProfile], oauth.OAuthProfile):",
            "                    oauth_profile = (",
            "                        session[\"oauth_info\"][\"userinfo\"]",
            "                        if \"oauth_info\" in session",
            "                        else None",
            "                    )",
            "                    if oauth_profile is not None:",
            "                        oauth_profile = oauth.OAuthProfile(oauth_profile)",
            "                    elif type_hint == oauth.OAuthProfile:",
            "                        raise Error(",
            "                            \"This action requires a logged in user. Please sign in and retry.\"",
            "                        )",
            "                    inputs.insert(i, oauth_profile)",
            "",
            "                # Inject user token",
            "                elif type_hint in (Optional[oauth.OAuthToken], oauth.OAuthToken):",
            "                    oauth_info = session.get(\"oauth_info\", None)",
            "                    oauth_token = (",
            "                        oauth.OAuthToken(",
            "                            token=oauth_info[\"access_token\"],",
            "                            scope=oauth_info[\"scope\"],",
            "                            expires_at=oauth_info[\"expires_at\"],",
            "                        )",
            "                        if oauth_info is not None",
            "                        else None",
            "                    )",
            "                    if oauth_token is None and type_hint == oauth.OAuthToken:",
            "                        raise Error(",
            "                            \"This action requires a logged in user. Please sign in and retry.\"",
            "                        )",
            "                    inputs.insert(i, oauth_token)",
            "        elif (",
            "            type_hint",
            "            and inspect.isclass(type_hint)",
            "            and issubclass(type_hint, EventData)",
            "        ):",
            "            event_data_index = i",
            "            if inputs is not None and event_data is not None:",
            "                inputs.insert(i, type_hint(event_data.target, event_data._data))",
            "        elif (",
            "            param.default is not param.empty and inputs is not None and len(inputs) <= i",
            "        ):",
            "            inputs.insert(i, param.default)",
            "    if inputs is not None:",
            "        while len(inputs) < len(positional_args):",
            "            i = len(inputs)",
            "            param = positional_args[i]",
            "            if param.default == param.empty:",
            "                warnings.warn(\"Unexpected argument. Filling with None.\")",
            "                inputs.append(None)",
            "            else:",
            "                inputs.append(param.default)",
            "    return inputs or [], progress_index, event_data_index",
            "",
            "",
            "def update(",
            "    elem_id: str | None = None,",
            "    elem_classes: list[str] | str | None = None,",
            "    visible: bool | None = None,",
            "    **kwargs,",
            ") -> dict:",
            "    \"\"\"",
            "    Updates a component's properties. When a function passed into a Gradio Interface or a Blocks events returns a value, it typically updates the value of the output component. But it is also possible to update the *properties* of an output component (such as the number of lines of a `Textbox` or the visibility of an `Row`) by returning a component and passing in the parameters to update in the constructor of the component. Alternatively, you can return `gr.update(...)` with any arbitrary parameters to update. (This is useful as a shorthand or if the same function can be called with different components to update.)",
            "",
            "    Parameters:",
            "        elem_id: Use this to update the id of the component in the HTML DOM",
            "        elem_classes: Use this to update the classes of the component in the HTML DOM",
            "        visible: Use this to update the visibility of the component",
            "        kwargs: Any other keyword arguments to update the component's properties.",
            "    Example:",
            "        import gradio as gr",
            "        with gr.Blocks() as demo:",
            "            radio = gr.Radio([1, 2, 4], label=\"Set the value of the number\")",
            "            number = gr.Number(value=2, interactive=True)",
            "            radio.change(fn=lambda value: gr.update(value=value), inputs=radio, outputs=number)",
            "        demo.launch()",
            "    \"\"\"",
            "    kwargs[\"__type__\"] = \"update\"",
            "    if elem_id is not None:",
            "        kwargs[\"elem_id\"] = elem_id",
            "    if elem_classes is not None:",
            "        kwargs[\"elem_classes\"] = elem_classes",
            "    if visible is not None:",
            "        kwargs[\"visible\"] = visible",
            "    return kwargs",
            "",
            "",
            "def skip() -> dict:",
            "    return {\"__type__\": \"update\"}",
            "",
            "",
            "@document()",
            "def make_waveform(",
            "    audio: str | tuple[int, np.ndarray],",
            "    *,",
            "    bg_color: str = \"#f3f4f6\",",
            "    bg_image: str | None = None,",
            "    fg_alpha: float = 0.75,",
            "    bars_color: str | tuple[str, str] = (\"#fbbf24\", \"#ea580c\"),",
            "    bar_count: int = 50,",
            "    bar_width: float = 0.6,",
            "    animate: bool = False,",
            ") -> str:",
            "    \"\"\"",
            "    Generates a waveform video from an audio file. Useful for creating an easy to share audio visualization. The output should be passed into a `gr.Video` component.",
            "    Parameters:",
            "        audio: Audio file path or tuple of (sample_rate, audio_data)",
            "        bg_color: Background color of waveform (ignored if bg_image is provided)",
            "        bg_image: Background image of waveform",
            "        fg_alpha: Opacity of foreground waveform",
            "        bars_color: Color of waveform bars. Can be a single color or a tuple of (start_color, end_color) of gradient",
            "        bar_count: Number of bars in waveform",
            "        bar_width: Width of bars in waveform. 1 represents full width, 0.5 represents half width, etc.",
            "        animate: If true, the audio waveform overlay will be animated, if false, it will be static.",
            "    Returns:",
            "        A filepath to the output video in mp4 format.",
            "    \"\"\"",
            "    import matplotlib.pyplot as plt",
            "    from matplotlib.animation import FuncAnimation",
            "",
            "    if isinstance(audio, str):",
            "        audio_file = audio",
            "        audio = processing_utils.audio_from_file(audio)",
            "    else:",
            "        tmp_wav = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)",
            "        processing_utils.audio_to_file(audio[0], audio[1], tmp_wav.name, format=\"wav\")",
            "        audio_file = tmp_wav.name",
            "",
            "    if not os.path.isfile(audio_file):",
            "        raise ValueError(\"Audio file not found.\")",
            "",
            "    ffmpeg = shutil.which(\"ffmpeg\")",
            "    if not ffmpeg:",
            "        raise RuntimeError(\"ffmpeg not found.\")",
            "",
            "    duration = round(len(audio[1]) / audio[0], 4)",
            "",
            "    # Helper methods to create waveform",
            "    def hex_to_rgb(hex_str):",
            "        return [int(hex_str[i : i + 2], 16) for i in range(1, 6, 2)]",
            "",
            "    def get_color_gradient(c1, c2, n):",
            "        if n < 1:",
            "            raise ValueError(\"Must have at least one stop in gradient\")",
            "        c1_rgb = np.array(hex_to_rgb(c1)) / 255",
            "        c2_rgb = np.array(hex_to_rgb(c2)) / 255",
            "        mix_pcts = [x / (n - 1) for x in range(n)]",
            "        rgb_colors = [((1 - mix) * c1_rgb + (mix * c2_rgb)) for mix in mix_pcts]",
            "        return [",
            "            \"#\" + \"\".join(f\"{int(round(val * 255)):02x}\" for val in item)",
            "            for item in rgb_colors",
            "        ]",
            "",
            "    # Reshape audio to have a fixed number of bars",
            "    samples = audio[1]",
            "    if len(samples.shape) > 1:",
            "        samples = np.mean(samples, 1)",
            "    bins_to_pad = bar_count - (len(samples) % bar_count)",
            "    samples = np.pad(samples, [(0, bins_to_pad)])",
            "    samples = np.reshape(samples, (bar_count, -1))",
            "    samples = np.abs(samples)",
            "    samples = np.max(samples, 1)",
            "",
            "    with utils.MatplotlibBackendMananger():",
            "        plt.clf()",
            "        # Plot waveform",
            "        color = (",
            "            bars_color",
            "            if isinstance(bars_color, str)",
            "            else get_color_gradient(bars_color[0], bars_color[1], bar_count)",
            "        )",
            "",
            "        if animate:",
            "            fig = plt.figure(figsize=(5, 1), dpi=200, frameon=False)",
            "            fig.subplots_adjust(left=0, bottom=0, right=1, top=1)",
            "        plt.axis(\"off\")",
            "        plt.margins(x=0)",
            "",
            "        bar_alpha = fg_alpha if animate else 1.0",
            "        barcollection = plt.bar(",
            "            np.arange(0, bar_count),",
            "            samples * 2,",
            "            bottom=(-1 * samples),",
            "            width=bar_width,",
            "            color=color,",
            "            alpha=bar_alpha,",
            "        )",
            "",
            "        tmp_img = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)",
            "",
            "        savefig_kwargs: dict[str, Any] = {\"bbox_inches\": \"tight\"}",
            "        if bg_image is not None:",
            "            savefig_kwargs[\"transparent\"] = True",
            "            if animate:",
            "                savefig_kwargs[\"facecolor\"] = \"none\"",
            "        else:",
            "            savefig_kwargs[\"facecolor\"] = bg_color",
            "        plt.savefig(tmp_img.name, **savefig_kwargs)",
            "",
            "        if not animate:",
            "            waveform_img = PIL.Image.open(tmp_img.name)",
            "            waveform_img = waveform_img.resize((1000, 400))",
            "",
            "            # Composite waveform with background image",
            "            if bg_image is not None:",
            "                waveform_array = np.array(waveform_img)",
            "                waveform_array[:, :, 3] = waveform_array[:, :, 3] * fg_alpha",
            "                waveform_img = PIL.Image.fromarray(waveform_array)",
            "",
            "                bg_img = PIL.Image.open(bg_image)",
            "                waveform_width, waveform_height = waveform_img.size",
            "                bg_width, bg_height = bg_img.size",
            "                if waveform_width != bg_width:",
            "                    bg_img = bg_img.resize(",
            "                        (",
            "                            waveform_width,",
            "                            2 * int(bg_height * waveform_width / bg_width / 2),",
            "                        )",
            "                    )",
            "                    bg_width, bg_height = bg_img.size",
            "                composite_height = max(bg_height, waveform_height)",
            "                composite = PIL.Image.new(",
            "                    \"RGBA\", (waveform_width, composite_height), \"#FFFFFF\"",
            "                )",
            "                composite.paste(bg_img, (0, composite_height - bg_height))",
            "                composite.paste(",
            "                    waveform_img, (0, composite_height - waveform_height), waveform_img",
            "                )",
            "                composite.save(tmp_img.name)",
            "                img_width, img_height = composite.size",
            "            else:",
            "                img_width, img_height = waveform_img.size",
            "                waveform_img.save(tmp_img.name)",
            "        else:",
            "",
            "            def _animate(_):",
            "                for idx, b in enumerate(barcollection):",
            "                    rand_height = np.random.uniform(0.8, 1.2)",
            "                    b.set_height(samples[idx] * rand_height * 2)",
            "                    b.set_y((-rand_height * samples)[idx])",
            "",
            "            frames = int(duration * 10)",
            "            anim = FuncAnimation(",
            "                fig,  # type: ignore",
            "                _animate,  # type: ignore",
            "                repeat=False,",
            "                blit=False,",
            "                frames=frames,",
            "                interval=100,",
            "            )",
            "            anim.save(",
            "                tmp_img.name,",
            "                writer=\"pillow\",",
            "                fps=10,",
            "                codec=\"png\",",
            "                savefig_kwargs=savefig_kwargs,",
            "            )",
            "",
            "    # Convert waveform to video with ffmpeg",
            "    output_mp4 = tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False)",
            "",
            "    if animate and bg_image is not None:",
            "        ffmpeg_cmd = [",
            "            ffmpeg,",
            "            \"-loop\",",
            "            \"1\",",
            "            \"-i\",",
            "            bg_image,",
            "            \"-i\",",
            "            tmp_img.name,",
            "            \"-i\",",
            "            audio_file,",
            "            \"-filter_complex\",",
            "            \"[0:v]scale=w=trunc(iw/2)*2:h=trunc(ih/2)*2[bg];[1:v]format=rgba,colorchannelmixer=aa=1.0[ov];[bg][ov]overlay=(main_w-overlay_w*0.9)/2:main_h-overlay_h*0.9/2[output]\",",
            "            \"-t\",",
            "            str(duration),",
            "            \"-map\",",
            "            \"[output]\",",
            "            \"-map\",",
            "            \"2:a\",",
            "            \"-c:v\",",
            "            \"libx264\",",
            "            \"-c:a\",",
            "            \"aac\",",
            "            \"-shortest\",",
            "            \"-y\",",
            "            output_mp4.name,",
            "        ]",
            "    elif animate and bg_image is None:",
            "        ffmpeg_cmd = [",
            "            ffmpeg,",
            "            \"-i\",",
            "            tmp_img.name,",
            "            \"-i\",",
            "            audio_file,",
            "            \"-filter_complex\",",
            "            \"[0:v][1:a]concat=n=1:v=1:a=1[v];[v]scale=1000:400,format=yuv420p[v_scaled]\",",
            "            \"-map\",",
            "            \"[v_scaled]\",",
            "            \"-map\",",
            "            \"1:a\",",
            "            \"-c:v\",",
            "            \"libx264\",",
            "            \"-c:a\",",
            "            \"aac\",",
            "            \"-shortest\",",
            "            \"-y\",",
            "            output_mp4.name,",
            "        ]",
            "    else:",
            "        ffmpeg_cmd = [",
            "            ffmpeg,",
            "            \"-loop\",",
            "            \"1\",",
            "            \"-i\",",
            "            tmp_img.name,",
            "            \"-i\",",
            "            audio_file,",
            "            \"-vf\",",
            "            f\"color=c=#FFFFFF77:s={img_width}x{img_height}[bar];[0][bar]overlay=-w+(w/{duration})*t:H-h:shortest=1\",  # type: ignore",
            "            \"-t\",",
            "            str(duration),",
            "            \"-y\",",
            "            output_mp4.name,",
            "        ]",
            "",
            "    subprocess.check_call(ffmpeg_cmd)",
            "    return output_mp4.name",
            "",
            "",
            "def log_message(message: str, level: Literal[\"info\", \"warning\"] = \"info\"):",
            "    from gradio.context import LocalContext",
            "",
            "    blocks = LocalContext.blocks.get()",
            "    event_id = LocalContext.event_id.get()",
            "    if blocks is None or event_id is None:",
            "        # Function called outside of Gradio if blocks is None",
            "        # Or from /api/predict if event_id is None",
            "        if level == \"info\":",
            "            print(message)",
            "        elif level == \"warning\":",
            "            warnings.warn(message)",
            "        return",
            "    blocks._queue.log_message(event_id=event_id, log=message, level=level)",
            "",
            "",
            "@document(documentation_group=\"modals\")",
            "def Warning(message: str = \"Warning issued.\"):  # noqa: N802",
            "    \"\"\"",
            "    This function allows you to pass custom warning messages to the user. You can do so simply by writing `gr.Warning('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is yellow by default and has the heading: \"Warning.\" Queue must be enabled for this behavior; otherwise, the warning will be printed to the console using the `warnings` library.",
            "    Demos: blocks_chained_events",
            "    Parameters:",
            "        message: The warning message to be displayed to the user.",
            "    Example:",
            "        import gradio as gr",
            "        def hello_world():",
            "            gr.Warning('This is a warning message.')",
            "            return \"hello world\"",
            "        with gr.Blocks() as demo:",
            "            md = gr.Markdown()",
            "            demo.load(hello_world, inputs=None, outputs=[md])",
            "        demo.queue().launch()",
            "    \"\"\"",
            "    log_message(message, level=\"warning\")",
            "",
            "",
            "@document(documentation_group=\"modals\")",
            "def Info(message: str = \"Info issued.\"):  # noqa: N802",
            "    \"\"\"",
            "    This function allows you to pass custom info messages to the user. You can do so simply by writing `gr.Info('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is gray by default and has the heading: \"Info.\" Queue must be enabled for this behavior; otherwise, the message will be printed to the console.",
            "    Demos: blocks_chained_events",
            "    Parameters:",
            "        message: The info message to be displayed to the user.",
            "    Example:",
            "        import gradio as gr",
            "        def hello_world():",
            "            gr.Info('This is some info.')",
            "            return \"hello world\"",
            "        with gr.Blocks() as demo:",
            "            md = gr.Markdown()",
            "            demo.load(hello_world, inputs=None, outputs=[md])",
            "        demo.queue().launch()",
            "    \"\"\"",
            "    log_message(message, level=\"info\")"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Defines helper methods useful for loading and caching Interface examples.",
            "\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import ast",
            "import csv",
            "import inspect",
            "import os",
            "import shutil",
            "import subprocess",
            "import tempfile",
            "import warnings",
            "from functools import partial",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any, Callable, Iterable, Literal, Optional",
            "",
            "import numpy as np",
            "import PIL",
            "import PIL.Image",
            "from gradio_client import utils as client_utils",
            "from gradio_client.documentation import document",
            "",
            "from gradio import components, oauth, processing_utils, routes, utils, wasm_utils",
            "from gradio.context import Context, LocalContext",
            "from gradio.data_classes import GradioModel, GradioRootModel",
            "from gradio.events import EventData",
            "from gradio.exceptions import Error",
            "from gradio.flagging import CSVLogger",
            "",
            "if TYPE_CHECKING:  # Only import for type checking (to avoid circular imports).",
            "    from gradio.components import Component",
            "",
            "LOG_FILE = \"log.csv\"",
            "",
            "",
            "def create_examples(",
            "    examples: list[Any] | list[list[Any]] | str,",
            "    inputs: Component | list[Component],",
            "    outputs: Component | list[Component] | None = None,",
            "    fn: Callable | None = None,",
            "    cache_examples: bool | Literal[\"lazy\"] | None = None,",
            "    examples_per_page: int = 10,",
            "    _api_mode: bool = False,",
            "    label: str | None = None,",
            "    elem_id: str | None = None,",
            "    run_on_click: bool = False,",
            "    preprocess: bool = True,",
            "    postprocess: bool = True,",
            "    api_name: str | Literal[False] = \"load_example\",",
            "    batch: bool = False,",
            "    _defer_caching: bool = False,",
            "):",
            "    \"\"\"Top-level synchronous function that creates Examples. Provided for backwards compatibility, i.e. so that gr.Examples(...) can be used to create the Examples component.\"\"\"",
            "    examples_obj = Examples(",
            "        examples=examples,",
            "        inputs=inputs,",
            "        outputs=outputs,",
            "        fn=fn,",
            "        cache_examples=cache_examples,",
            "        examples_per_page=examples_per_page,",
            "        _api_mode=_api_mode,",
            "        label=label,",
            "        elem_id=elem_id,",
            "        run_on_click=run_on_click,",
            "        preprocess=preprocess,",
            "        postprocess=postprocess,",
            "        api_name=api_name,",
            "        batch=batch,",
            "        _defer_caching=_defer_caching,",
            "        _initiated_directly=False,",
            "    )",
            "    examples_obj.create()",
            "    return examples_obj",
            "",
            "",
            "@document()",
            "class Examples:",
            "    \"\"\"",
            "    This class is a wrapper over the Dataset component and can be used to create Examples",
            "    for Blocks / Interfaces. Populates the Dataset component with examples and",
            "    assigns event listener so that clicking on an example populates the input/output",
            "    components. Optionally handles example caching for fast inference.",
            "",
            "    Demos: fake_gan",
            "    Guides: more-on-examples-and-flagging, using-hugging-face-integrations, image-classification-in-pytorch, image-classification-in-tensorflow, image-classification-with-vision-transformers, create-your-own-friends-with-a-gan",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        examples: list[Any] | list[list[Any]] | str,",
            "        inputs: Component | list[Component],",
            "        outputs: Component | list[Component] | None = None,",
            "        fn: Callable | None = None,",
            "        cache_examples: bool | Literal[\"lazy\"] | None = None,",
            "        examples_per_page: int = 10,",
            "        _api_mode: bool = False,",
            "        label: str | None = \"Examples\",",
            "        elem_id: str | None = None,",
            "        run_on_click: bool = False,",
            "        preprocess: bool = True,",
            "        postprocess: bool = True,",
            "        api_name: str | Literal[False] = \"load_example\",",
            "        batch: bool = False,",
            "        _defer_caching: bool = False,",
            "        _initiated_directly: bool = True,",
            "    ):",
            "        \"\"\"",
            "        Parameters:",
            "            examples: example inputs that can be clicked to populate specific components. Should be nested list, in which the outer list consists of samples and each inner list consists of an input corresponding to each input component. A string path to a directory of examples can also be provided but it should be within the directory with the python file running the gradio app. If there are multiple input components and a directory is provided, a log.csv file must be present in the directory to link corresponding inputs.",
            "            inputs: the component or list of components corresponding to the examples",
            "            outputs: optionally, provide the component or list of components corresponding to the output of the examples. Required if `cache_examples` is not False.",
            "            fn: optionally, provide the function to run to generate the outputs corresponding to the examples. Required if `cache_examples` is not False. Also required if `run_on_click` is True.",
            "            cache_examples: If True, caches examples in the server for fast runtime in examples. If \"lazy\", then examples are cached after their first use. Can also be set by the GRADIO_CACHE_EXAMPLES environment variable, which takes a case-insensitive value, one of: {\"true\", \"lazy\", or \"false\"} (for the first two to take effect, `fn` and `outputs` should also be provided). In HuggingFace Spaces, this is True (as long as `fn` and `outputs` are also provided). The default option otherwise is False.",
            "            examples_per_page: how many examples to show per page.",
            "            label: the label to use for the examples component (by default, \"Examples\")",
            "            elem_id: an optional string that is assigned as the id of this component in the HTML DOM.",
            "            run_on_click: if cache_examples is False, clicking on an example does not run the function when an example is clicked. Set this to True to run the function when an example is clicked. Has no effect if cache_examples is True.",
            "            preprocess: if True, preprocesses the example input before running the prediction function and caching the output. Only applies if `cache_examples` is not False.",
            "            postprocess: if True, postprocesses the example output after running the prediction function and before caching. Only applies if `cache_examples` is not False.",
            "            api_name: Defines how the event associated with clicking on the examples appears in the API docs. Can be a string or False. If set to a string, the endpoint will be exposed in the API docs with the given name. If False, the endpoint will not be exposed in the API docs and downstream apps (including those that `gr.load` this app) will not be able to use the example function.",
            "            batch: If True, then the function should process a batch of inputs, meaning that it should accept a list of input values for each parameter. Used only if cache_examples is not False.",
            "        \"\"\"",
            "        if _initiated_directly:",
            "            warnings.warn(",
            "                \"Please use gr.Examples(...) instead of gr.examples.Examples(...) to create the Examples.\",",
            "            )",
            "",
            "        if cache_examples is None:",
            "            if cache_examples_env := os.getenv(\"GRADIO_CACHE_EXAMPLES\"):",
            "                if cache_examples_env.lower() == \"true\":",
            "                    if fn is not None and outputs is not None:",
            "                        self.cache_examples = True",
            "                    else:",
            "                        self.cache_examples = False",
            "                elif cache_examples_env.lower() == \"lazy\":",
            "                    if fn is not None and outputs is not None:",
            "                        self.cache_examples = \"lazy\"",
            "                    else:",
            "                        self.cache_examples = False",
            "                elif cache_examples_env.lower() == \"false\":",
            "                    self.cache_examples = False",
            "                else:",
            "                    raise ValueError(",
            "                        \"The `GRADIO_CACHE_EXAMPLES` env variable must be one of: 'true', 'false', 'lazy' (case-insensitive).\"",
            "                    )",
            "            elif utils.get_space() and fn is not None and outputs is not None:",
            "                self.cache_examples = True",
            "            else:",
            "                self.cache_examples = cache_examples or False",
            "        else:",
            "            if cache_examples not in [True, False, \"lazy\"]:",
            "                raise ValueError(",
            "                    \"The `cache_examples` parameter must be one of: True, False, 'lazy'.\"",
            "                )",
            "            self.cache_examples = cache_examples",
            "",
            "        if self.cache_examples and (fn is None or outputs is None):",
            "            raise ValueError(\"If caching examples, `fn` and `outputs` must be provided\")",
            "        self._defer_caching = _defer_caching",
            "",
            "        if not isinstance(inputs, list):",
            "            inputs = [inputs]",
            "        if outputs and not isinstance(outputs, list):",
            "            outputs = [outputs]",
            "",
            "        working_directory = Path().absolute()",
            "",
            "        if examples is None:",
            "            raise ValueError(\"The parameter `examples` cannot be None\")",
            "        elif isinstance(examples, list) and (",
            "            len(examples) == 0 or isinstance(examples[0], list)",
            "        ):",
            "            pass",
            "        elif (",
            "            isinstance(examples, list) and len(inputs) == 1",
            "        ):  # If there is only one input component, examples can be provided as a regular list instead of a list of lists",
            "            examples = [[e] for e in examples]",
            "        elif isinstance(examples, str):",
            "            if not Path(examples).exists():",
            "                raise FileNotFoundError(",
            "                    f\"Could not find examples directory: {examples}\"",
            "                )",
            "            working_directory = examples",
            "            if not (Path(examples) / LOG_FILE).exists():",
            "                if len(inputs) == 1:",
            "                    examples = [[e] for e in os.listdir(examples)]",
            "                else:",
            "                    raise FileNotFoundError(",
            "                        \"Could not find log file (required for multiple inputs): \"",
            "                        + LOG_FILE",
            "                    )",
            "            else:",
            "                with open(Path(examples) / LOG_FILE) as logs:",
            "                    examples = list(csv.reader(logs))",
            "                    examples = [",
            "                        examples[i][: len(inputs)] for i in range(1, len(examples))",
            "                    ]  # remove header and unnecessary columns",
            "",
            "        else:",
            "            raise ValueError(",
            "                \"The parameter `examples` must either be a string directory or a list\"",
            "                \"(if there is only 1 input component) or (more generally), a nested \"",
            "                \"list, where each sublist represents a set of inputs.\"",
            "            )",
            "",
            "        input_has_examples = [False] * len(inputs)",
            "        for example in examples:",
            "            for idx, example_for_input in enumerate(example):",
            "                if example_for_input is not None:",
            "                    try:",
            "                        input_has_examples[idx] = True",
            "                    except IndexError:",
            "                        pass  # If there are more example components than inputs, ignore. This can sometimes be intentional (e.g. loading from a log file where outputs and timestamps are also logged)",
            "",
            "        inputs_with_examples = [",
            "            inp for (inp, keep) in zip(inputs, input_has_examples) if keep",
            "        ]",
            "        non_none_examples = [",
            "            [ex for (ex, keep) in zip(example, input_has_examples) if keep]",
            "            for example in examples",
            "        ]",
            "",
            "        self.examples = examples",
            "        self.non_none_examples = non_none_examples",
            "        self.inputs = inputs",
            "        self.inputs_with_examples = inputs_with_examples",
            "        self.outputs = outputs or []",
            "        self.fn = fn",
            "        self._api_mode = _api_mode",
            "        self.preprocess = preprocess",
            "        self.postprocess = postprocess",
            "        self.api_name: str | Literal[False] = api_name",
            "        self.batch = batch",
            "",
            "        with utils.set_directory(working_directory):",
            "            self.processed_examples = []",
            "            for example in examples:",
            "                sub = []",
            "                for component, sample in zip(inputs, example):",
            "                    prediction_value = component.postprocess(sample)",
            "                    if isinstance(prediction_value, (GradioRootModel, GradioModel)):",
            "                        prediction_value = prediction_value.model_dump()",
            "                    prediction_value = processing_utils.move_files_to_cache(",
            "                        prediction_value,",
            "                        component,",
            "                        postprocess=True,",
            "                    )",
            "                    sub.append(prediction_value)",
            "                self.processed_examples.append(sub)",
            "",
            "        self.non_none_processed_examples = [",
            "            [ex for (ex, keep) in zip(example, input_has_examples) if keep]",
            "            for example in self.processed_examples",
            "        ]",
            "",
            "        from gradio import components",
            "",
            "        with utils.set_directory(working_directory):",
            "            self.dataset = components.Dataset(",
            "                components=inputs_with_examples,",
            "                samples=non_none_examples,",
            "                type=\"index\",",
            "                label=label,",
            "                samples_per_page=examples_per_page,",
            "                elem_id=elem_id,",
            "            )",
            "",
            "        self.cache_logger = CSVLogger(simplify_file_data=False)",
            "        self.cached_folder = utils.get_cache_folder() / str(self.dataset._id)",
            "        self.cached_file = Path(self.cached_folder) / \"log.csv\"",
            "        self.cached_indices_file = Path(self.cached_folder) / \"indices.csv\"",
            "        self.run_on_click = run_on_click",
            "",
            "    def create(self) -> None:",
            "        \"\"\"Caches the examples if self.cache_examples is True and creates the Dataset",
            "        component to hold the examples\"\"\"",
            "",
            "        async def load_example(example_id):",
            "            processed_example = self.non_none_processed_examples[example_id]",
            "            if len(self.inputs_with_examples) == 1:",
            "                return update(",
            "                    value=processed_example[0],",
            "                    **self.dataset.component_props[0],  # type: ignore",
            "                )",
            "            return [",
            "                update(value=processed_example[i], **self.dataset.component_props[i])  # type: ignore",
            "                for i in range(len(self.inputs_with_examples))",
            "            ]",
            "",
            "        if Context.root_block:",
            "            self.load_input_event = self.dataset.click(",
            "                load_example,",
            "                inputs=[self.dataset],",
            "                outputs=self.inputs_with_examples,  # type: ignore",
            "                show_progress=\"hidden\",",
            "                postprocess=False,",
            "                queue=False,",
            "                api_name=self.api_name,",
            "                show_api=False,",
            "            )",
            "            self.load_input_event_id = len(Context.root_block.fns) - 1",
            "            if self.run_on_click and not self.cache_examples:",
            "                if self.fn is None:",
            "                    raise ValueError(\"Cannot run_on_click if no function is provided\")",
            "                self.load_input_event.then(",
            "                    self.fn,",
            "                    inputs=self.inputs,  # type: ignore",
            "                    outputs=self.outputs,  # type: ignore",
            "                    show_api=False,",
            "                )",
            "        if not self._defer_caching:",
            "            self._start_caching()",
            "",
            "    async def _postprocess_output(self, output) -> list:",
            "        \"\"\"",
            "        This is a way that we can postprocess the data manually, since we set postprocess=False in the lazy_cache",
            "        event handler. The reason we did that is because we don't want to postprocess data if we are loading from",
            "        the cache, since that has already been postprocessed. We postprocess this data manually if we are calling",
            "        the function using the _handle_callable_as_generator() method.",
            "        \"\"\"",
            "        import gradio as gr",
            "",
            "        with gr.Blocks() as demo:",
            "            [output.render() for output in self.outputs]",
            "            demo.load(self.fn, self.inputs, self.outputs)",
            "        demo.unrender()",
            "        return await demo.postprocess_data(0, output, None)",
            "",
            "    def _get_cached_index_if_cached(self, example_index) -> int | None:",
            "        if Path(self.cached_indices_file).exists():",
            "            with open(self.cached_indices_file) as f:",
            "                cached_indices = [int(line.strip()) for line in f]",
            "            if example_index in cached_indices:",
            "                cached_index = cached_indices.index(example_index)",
            "                return cached_index",
            "        return None",
            "",
            "    def _start_caching(self):",
            "        if self.cache_examples:",
            "            for example in self.examples:",
            "                if len([ex for ex in example if ex is not None]) != len(self.inputs):",
            "                    warnings.warn(",
            "                        \"Examples will be cached but not all input components have \"",
            "                        \"example values. This may result in an exception being thrown by \"",
            "                        \"your function. If you do get an error while caching examples, make \"",
            "                        \"sure all of your inputs have example values for all of your examples \"",
            "                        \"or you provide default values for those particular parameters in your function.\"",
            "                    )",
            "                    break",
            "        if self.cache_examples == \"lazy\":",
            "            client_utils.synchronize_async(self.lazy_cache)",
            "        if self.cache_examples is True:",
            "            if wasm_utils.IS_WASM:",
            "                # In the Wasm mode, the `threading` module is not supported,",
            "                # so `client_utils.synchronize_async` is also not available.",
            "                # And `self.cache()` should be waited for to complete before this method returns,",
            "                # (otherwise, an error \"Cannot cache examples if not in a Blocks context\" will be raised anyway)",
            "                # so `eventloop.create_task(self.cache())` is also not an option.",
            "                warnings.warn(",
            "                    \"Setting `cache_examples=True` is not supported in the Wasm mode. You can set `cache_examples='lazy'` to cache examples after first use.\"",
            "                )",
            "            else:",
            "                client_utils.synchronize_async(self.cache)",
            "",
            "    async def lazy_cache(self) -> None:",
            "        print(",
            "            f\"Will cache examples in '{utils.abspath(self.cached_folder)}' directory at first use. \",",
            "            end=\"\",",
            "        )",
            "        if Path(self.cached_file).exists():",
            "            print(",
            "                \"If method or examples have changed since last caching, delete this folder to reset cache.\",",
            "                end=\"\",",
            "            )",
            "        print(\"\\n\\n\")",
            "        self.cache_logger.setup(self.outputs, self.cached_folder)",
            "        if inspect.iscoroutinefunction(self.fn) or inspect.isasyncgenfunction(self.fn):",
            "            lazy_cache_fn = self.async_lazy_cache",
            "        else:",
            "            lazy_cache_fn = self.sync_lazy_cache",
            "        self.load_input_event.then(",
            "            lazy_cache_fn,",
            "            inputs=[self.dataset] + self.inputs,",
            "            outputs=self.outputs,",
            "            postprocess=False,",
            "            api_name=self.api_name,",
            "            show_api=False,",
            "        )",
            "",
            "    async def async_lazy_cache(self, example_index, *input_values):",
            "        cached_index = self._get_cached_index_if_cached(example_index)",
            "        if cached_index is not None:",
            "            output = self.load_from_cache(cached_index)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "            return",
            "        output = [None] * len(self.outputs)",
            "        if inspect.isasyncgenfunction(self.fn):",
            "            fn = self.fn",
            "        else:",
            "            fn = utils.async_fn_to_generator(self.fn)",
            "        async for output in fn(*input_values):",
            "            output = await self._postprocess_output(output)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "        self.cache_logger.flag(output)",
            "        with open(self.cached_indices_file, \"a\") as f:",
            "            f.write(f\"{example_index}\\n\")",
            "",
            "    def sync_lazy_cache(self, example_index, *input_values):",
            "        cached_index = self._get_cached_index_if_cached(example_index)",
            "        if cached_index is not None:",
            "            output = self.load_from_cache(cached_index)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "            return",
            "        output = [None] * len(self.outputs)",
            "        if inspect.isgeneratorfunction(self.fn):",
            "            fn = self.fn",
            "        else:",
            "            fn = utils.sync_fn_to_generator(self.fn)",
            "        for output in fn(*input_values):",
            "            output = client_utils.synchronize_async(self._postprocess_output, output)",
            "            yield output[0] if len(self.outputs) == 1 else output",
            "        self.cache_logger.flag(output)",
            "        with open(self.cached_indices_file, \"a\") as f:",
            "            f.write(f\"{example_index}\\n\")",
            "",
            "    async def cache(self) -> None:",
            "        \"\"\"",
            "        Caches examples so that their predictions can be shown immediately.",
            "        \"\"\"",
            "        if Context.root_block is None:",
            "            raise ValueError(\"Cannot cache examples if not in a Blocks context\")",
            "        if Path(self.cached_file).exists():",
            "            print(",
            "                f\"Using cache from '{utils.abspath(self.cached_folder)}' directory. If method or examples have changed since last caching, delete this folder to clear cache.\\n\"",
            "            )",
            "        else:",
            "            print(f\"Caching examples at: '{utils.abspath(self.cached_folder)}'\")",
            "            self.cache_logger.setup(self.outputs, self.cached_folder)",
            "            generated_values = []",
            "            if inspect.isgeneratorfunction(self.fn):",
            "",
            "                def get_final_item(*args):  # type: ignore",
            "                    x = None",
            "                    generated_values.clear()",
            "                    for x in self.fn(*args):  # noqa: B007  # type: ignore",
            "                        generated_values.append(x)",
            "                    return x",
            "",
            "                fn = get_final_item",
            "            elif inspect.isasyncgenfunction(self.fn):",
            "",
            "                async def get_final_item(*args):",
            "                    x = None",
            "                    generated_values.clear()",
            "                    async for x in self.fn(*args):  # noqa: B007  # type: ignore",
            "                        generated_values.append(x)",
            "                    return x",
            "",
            "                fn = get_final_item",
            "            else:",
            "                fn = self.fn",
            "",
            "            # create a fake dependency to process the examples and get the predictions",
            "            from gradio.events import EventListenerMethod",
            "",
            "            dependency, fn_index = Context.root_block.set_event_trigger(",
            "                [EventListenerMethod(Context.root_block, \"load\")],",
            "                fn=fn,",
            "                inputs=self.inputs_with_examples,  # type: ignore",
            "                outputs=self.outputs,  # type: ignore",
            "                preprocess=self.preprocess and not self._api_mode,",
            "                postprocess=self.postprocess and not self._api_mode,",
            "                batch=self.batch,",
            "            )",
            "",
            "            if self.outputs is None:",
            "                raise ValueError(\"self.outputs is missing\")",
            "            for example_id in range(len(self.examples)):",
            "                print(f\"Caching example {example_id + 1}/{len(self.examples)}\")",
            "                processed_input = self.processed_examples[example_id]",
            "                if self.batch:",
            "                    processed_input = [[value] for value in processed_input]",
            "                with utils.MatplotlibBackendMananger():",
            "                    prediction = await Context.root_block.process_api(",
            "                        fn_index=fn_index,",
            "                        inputs=processed_input,",
            "                        request=None,",
            "                    )",
            "                output = prediction[\"data\"]",
            "                if len(generated_values):",
            "                    output = merge_generated_values_into_output(",
            "                        self.outputs, generated_values, output",
            "                    )",
            "                if self.batch:",
            "                    output = [value[0] for value in output]",
            "                self.cache_logger.flag(output)",
            "            # Remove the \"fake_event\" to prevent bugs in loading interfaces from spaces",
            "            Context.root_block.fns.pop(fn_index)",
            "",
            "        # Remove the original load_input_event and replace it with one that",
            "        # also populates the input. We do it this way to to allow the cache()",
            "        # method to be called independently of the create() method",
            "        Context.root_block.fns.pop(self.load_input_event_id)",
            "",
            "        def load_example(example_id):",
            "            processed_example = self.non_none_processed_examples[",
            "                example_id",
            "            ] + self.load_from_cache(example_id)",
            "            return utils.resolve_singleton(processed_example)",
            "",
            "        self.load_input_event = self.dataset.click(",
            "            load_example,",
            "            inputs=[self.dataset],",
            "            outputs=self.inputs_with_examples + self.outputs,  # type: ignore",
            "            show_progress=\"hidden\",",
            "            postprocess=False,",
            "            queue=False,",
            "            api_name=self.api_name,",
            "            show_api=False,",
            "        )",
            "        self.load_input_event_id = len(Context.root_block.fns) - 1",
            "",
            "    def load_from_cache(self, example_id: int) -> list[Any]:",
            "        \"\"\"Loads a particular cached example for the interface.",
            "        Parameters:",
            "            example_id: The id of the example to process (zero-indexed).",
            "        \"\"\"",
            "        with open(self.cached_file, encoding=\"utf-8\") as cache:",
            "            examples = list(csv.reader(cache))",
            "        example = examples[example_id + 1]  # +1 to adjust for header",
            "        output = []",
            "        if self.outputs is None:",
            "            raise ValueError(\"self.outputs is missing\")",
            "        for component, value in zip(self.outputs, example):",
            "            value_to_use = value",
            "            try:",
            "                value_as_dict = ast.literal_eval(value)",
            "                # File components that output multiple files get saved as a python list",
            "                # need to pass the parsed list to serialize",
            "                # TODO: Better file serialization in 4.0",
            "                if isinstance(value_as_dict, list) and isinstance(",
            "                    component, components.File",
            "                ):",
            "                    value_to_use = value_as_dict",
            "                if not utils.is_update(value_as_dict):",
            "                    raise TypeError(\"value wasn't an update\")  # caught below",
            "                output.append(value_as_dict)",
            "            except (ValueError, TypeError, SyntaxError):",
            "                output.append(component.read_from_flag(value_to_use))",
            "        return output",
            "",
            "",
            "def merge_generated_values_into_output(",
            "    components: list[Component], generated_values: list, output: list",
            "):",
            "    from gradio.components.base import StreamingOutput",
            "",
            "    for output_index, output_component in enumerate(components):",
            "        if isinstance(output_component, StreamingOutput) and output_component.streaming:",
            "            binary_chunks = []",
            "            for i, chunk in enumerate(generated_values):",
            "                if len(components) > 1:",
            "                    chunk = chunk[output_index]",
            "                processed_chunk = output_component.postprocess(chunk)",
            "                if isinstance(processed_chunk, (GradioModel, GradioRootModel)):",
            "                    processed_chunk = processed_chunk.model_dump()",
            "                binary_chunks.append(",
            "                    output_component.stream_output(processed_chunk, \"\", i == 0)[0]",
            "                )",
            "            binary_data = b\"\".join(binary_chunks)",
            "            tempdir = os.environ.get(\"GRADIO_TEMP_DIR\") or str(",
            "                Path(tempfile.gettempdir()) / \"gradio\"",
            "            )",
            "            os.makedirs(tempdir, exist_ok=True)",
            "            temp_file = tempfile.NamedTemporaryFile(dir=tempdir, delete=False)",
            "            with open(temp_file.name, \"wb\") as f:",
            "                f.write(binary_data)",
            "",
            "            output[output_index] = {",
            "                \"path\": temp_file.name,",
            "            }",
            "",
            "    return output",
            "",
            "",
            "class TrackedIterable:",
            "    def __init__(",
            "        self,",
            "        iterable: Iterable | None,",
            "        index: int | None,",
            "        length: int | None,",
            "        desc: str | None,",
            "        unit: str | None,",
            "        _tqdm=None,",
            "        progress: float | None = None,",
            "    ) -> None:",
            "        self.iterable = iterable",
            "        self.index = index",
            "        self.length = length",
            "        self.desc = desc",
            "        self.unit = unit",
            "        self._tqdm = _tqdm",
            "        self.progress = progress",
            "",
            "",
            "@document(\"__call__\", \"tqdm\")",
            "class Progress(Iterable):",
            "    \"\"\"",
            "    The Progress class provides a custom progress tracker that is used in a function signature.",
            "    To attach a Progress tracker to a function, simply add a parameter right after the input parameters that has a default value set to a `gradio.Progress()` instance.",
            "    The Progress tracker can then be updated in the function by calling the Progress object or using the `tqdm` method on an Iterable.",
            "    The Progress tracker is currently only available with `queue()`.",
            "    Example:",
            "        import gradio as gr",
            "        import time",
            "        def my_function(x, progress=gr.Progress()):",
            "            progress(0, desc=\"Starting...\")",
            "            time.sleep(1)",
            "            for i in progress.tqdm(range(100)):",
            "                time.sleep(0.1)",
            "            return x",
            "        gr.Interface(my_function, gr.Textbox(), gr.Textbox()).queue().launch()",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        track_tqdm: bool = False,",
            "    ):",
            "        \"\"\"",
            "        Parameters:",
            "            track_tqdm: If True, the Progress object will track any tqdm.tqdm iterations with the tqdm library in the function.",
            "        \"\"\"",
            "        if track_tqdm:",
            "            patch_tqdm()",
            "        self.track_tqdm = track_tqdm",
            "        self.iterables: list[TrackedIterable] = []",
            "",
            "    def __len__(self):",
            "        return self.iterables[-1].length",
            "",
            "    def __iter__(self):",
            "        return self",
            "",
            "    def __next__(self):",
            "        \"\"\"",
            "        Updates progress tracker with next item in iterable.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            current_iterable = self.iterables[-1]",
            "            while (",
            "                not hasattr(current_iterable.iterable, \"__next__\")",
            "                and len(self.iterables) > 0",
            "            ):",
            "                current_iterable = self.iterables.pop()",
            "            callback(self.iterables)",
            "            if current_iterable.index is None:",
            "                raise IndexError(\"Index not set.\")",
            "            current_iterable.index += 1",
            "            try:",
            "                return next(current_iterable.iterable)  # type: ignore",
            "            except StopIteration:",
            "                self.iterables.pop()",
            "                raise",
            "        else:",
            "            return self",
            "",
            "    def __call__(",
            "        self,",
            "        progress: float | tuple[int, int | None] | None,",
            "        desc: str | None = None,",
            "        total: int | None = None,",
            "        unit: str = \"steps\",",
            "        _tqdm=None,",
            "    ):",
            "        \"\"\"",
            "        Updates progress tracker with progress and message text.",
            "        Parameters:",
            "            progress: If float, should be between 0 and 1 representing completion. If Tuple, first number represents steps completed, and second value represents total steps or None if unknown. If None, hides progress bar.",
            "            desc: description to display.",
            "            total: estimated total number of steps.",
            "            unit: unit of iterations.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            if isinstance(progress, tuple):",
            "                index, total = progress",
            "                progress = None",
            "            else:",
            "                index = None",
            "            callback(",
            "                self.iterables",
            "                + [TrackedIterable(None, index, total, desc, unit, _tqdm, progress)]",
            "            )",
            "        else:",
            "            return progress",
            "",
            "    def tqdm(",
            "        self,",
            "        iterable: Iterable | None,",
            "        desc: str | None = None,",
            "        total: int | None = None,",
            "        unit: str = \"steps\",",
            "        _tqdm=None,",
            "    ):",
            "        \"\"\"",
            "        Attaches progress tracker to iterable, like tqdm.",
            "        Parameters:",
            "            iterable: iterable to attach progress tracker to.",
            "            desc: description to display.",
            "            total: estimated total number of steps.",
            "            unit: unit of iterations.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            if iterable is None:",
            "                new_iterable = TrackedIterable(None, 0, total, desc, unit, _tqdm)",
            "                self.iterables.append(new_iterable)",
            "                callback(self.iterables)",
            "                return self",
            "            length = len(iterable) if hasattr(iterable, \"__len__\") else None  # type: ignore",
            "            self.iterables.append(",
            "                TrackedIterable(iter(iterable), 0, length, desc, unit, _tqdm)",
            "            )",
            "        return self",
            "",
            "    def update(self, n=1):",
            "        \"\"\"",
            "        Increases latest iterable with specified number of steps.",
            "        Parameters:",
            "            n: number of steps completed.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback and len(self.iterables) > 0:",
            "            current_iterable = self.iterables[-1]",
            "            if current_iterable.index is None:",
            "                raise IndexError(\"Index not set.\")",
            "            current_iterable.index += n",
            "            callback(self.iterables)",
            "        else:",
            "            return",
            "",
            "    def close(self, _tqdm):",
            "        \"\"\"",
            "        Removes iterable with given _tqdm.",
            "        \"\"\"",
            "        callback = self._progress_callback()",
            "        if callback:",
            "            for i in range(len(self.iterables)):",
            "                if id(self.iterables[i]._tqdm) == id(_tqdm):",
            "                    self.iterables.pop(i)",
            "                    break",
            "            callback(self.iterables)",
            "        else:",
            "            return",
            "",
            "    @staticmethod",
            "    def _progress_callback():",
            "        blocks = LocalContext.blocks.get()",
            "        event_id = LocalContext.event_id.get()",
            "        if not (blocks and event_id):",
            "            return None",
            "        return partial(blocks._queue.set_progress, event_id)",
            "",
            "",
            "def patch_tqdm() -> None:",
            "    try:",
            "        _tqdm = __import__(\"tqdm\")",
            "    except ModuleNotFoundError:",
            "        return",
            "",
            "    def init_tqdm(",
            "        self, iterable=None, desc=None, total=None, unit=\"steps\", *args, **kwargs",
            "    ):",
            "        self._progress = LocalContext.progress.get()",
            "        if self._progress is not None:",
            "            self._progress.tqdm(iterable, desc, total, unit, _tqdm=self)",
            "            kwargs[\"file\"] = open(os.devnull, \"w\")  # noqa: SIM115",
            "        self.__init__orig__(iterable, desc, total, *args, unit=unit, **kwargs)",
            "",
            "    def iter_tqdm(self):",
            "        if self._progress is not None:",
            "            return self._progress",
            "        return self.__iter__orig__()",
            "",
            "    def update_tqdm(self, n=1):",
            "        if self._progress is not None:",
            "            self._progress.update(n)",
            "        return self.__update__orig__(n)",
            "",
            "    def close_tqdm(self):",
            "        if self._progress is not None:",
            "            self._progress.close(self)",
            "        return self.__close__orig__()",
            "",
            "    def exit_tqdm(self, exc_type, exc_value, traceback):",
            "        if self._progress is not None:",
            "            self._progress.close(self)",
            "        return self.__exit__orig__(exc_type, exc_value, traceback)",
            "",
            "    # Backup",
            "    if not hasattr(_tqdm.tqdm, \"__init__orig__\"):",
            "        _tqdm.tqdm.__init__orig__ = _tqdm.tqdm.__init__",
            "    if not hasattr(_tqdm.tqdm, \"__update__orig__\"):",
            "        _tqdm.tqdm.__update__orig__ = _tqdm.tqdm.update",
            "    if not hasattr(_tqdm.tqdm, \"__close__orig__\"):",
            "        _tqdm.tqdm.__close__orig__ = _tqdm.tqdm.close",
            "    if not hasattr(_tqdm.tqdm, \"__exit__orig__\"):",
            "        _tqdm.tqdm.__exit__orig__ = _tqdm.tqdm.__exit__",
            "    if not hasattr(_tqdm.tqdm, \"__iter__orig__\"):",
            "        _tqdm.tqdm.__iter__orig__ = _tqdm.tqdm.__iter__",
            "",
            "    # Patch",
            "    _tqdm.tqdm.__init__ = init_tqdm",
            "    _tqdm.tqdm.update = update_tqdm",
            "    _tqdm.tqdm.close = close_tqdm",
            "    _tqdm.tqdm.__exit__ = exit_tqdm",
            "    _tqdm.tqdm.__iter__ = iter_tqdm",
            "",
            "    if hasattr(_tqdm, \"auto\") and hasattr(_tqdm.auto, \"tqdm\"):",
            "        _tqdm.auto.tqdm = _tqdm.tqdm",
            "",
            "",
            "def create_tracker(fn, track_tqdm):",
            "    progress = Progress(track_tqdm=track_tqdm)",
            "    if not track_tqdm:",
            "        return progress, fn",
            "    return progress, utils.function_wrapper(",
            "        f=fn,",
            "        before_fn=LocalContext.progress.set,",
            "        before_args=(progress,),",
            "        after_fn=LocalContext.progress.set,",
            "        after_args=(None,),",
            "    )",
            "",
            "",
            "def special_args(",
            "    fn: Callable,",
            "    inputs: list[Any] | None = None,",
            "    request: routes.Request | None = None,",
            "    event_data: EventData | None = None,",
            ") -> tuple[list, int | None, int | None]:",
            "    \"\"\"",
            "    Checks if function has special arguments Request or EventData (via annotation) or Progress (via default value).",
            "    If inputs is provided, these values will be loaded into the inputs array.",
            "    Parameters:",
            "        fn: function to check.",
            "        inputs: array to load special arguments into.",
            "        request: request to load into inputs.",
            "        event_data: event-related data to load into inputs.",
            "    Returns:",
            "        updated inputs, progress index, event data index.",
            "    \"\"\"",
            "    try:",
            "        signature = inspect.signature(fn)",
            "    except ValueError:",
            "        return inputs or [], None, None",
            "    type_hints = utils.get_type_hints(fn)",
            "    positional_args = []",
            "    for param in signature.parameters.values():",
            "        if param.kind not in (param.POSITIONAL_ONLY, param.POSITIONAL_OR_KEYWORD):",
            "            break",
            "        positional_args.append(param)",
            "    progress_index = None",
            "    event_data_index = None",
            "    for i, param in enumerate(positional_args):",
            "        type_hint = type_hints.get(param.name)",
            "        if isinstance(param.default, Progress):",
            "            progress_index = i",
            "            if inputs is not None:",
            "                inputs.insert(i, param.default)",
            "        elif type_hint == routes.Request:",
            "            if inputs is not None:",
            "                inputs.insert(i, request)",
            "        elif type_hint in (",
            "            # Note: \"OAuthProfile | None\" is equals to Optional[OAuthProfile] in Python",
            "            #       => it is automatically handled as well by the above condition",
            "            #       (adding explicit \"OAuthProfile | None\" would break in Python3.9)",
            "            #       (same for \"OAuthToken\")",
            "            Optional[oauth.OAuthProfile],",
            "            Optional[oauth.OAuthToken],",
            "            oauth.OAuthProfile,",
            "            oauth.OAuthToken,",
            "        ):",
            "            if inputs is not None:",
            "                # Retrieve session from gr.Request, if it exists (i.e. if user is logged in)",
            "                session = (",
            "                    # request.session (if fastapi.Request obj i.e. direct call)",
            "                    getattr(request, \"session\", {})",
            "                    or",
            "                    # or request.request.session (if gr.Request obj i.e. websocket call)",
            "                    getattr(getattr(request, \"request\", None), \"session\", {})",
            "                )",
            "",
            "                # Inject user profile",
            "                if type_hint in (Optional[oauth.OAuthProfile], oauth.OAuthProfile):",
            "                    oauth_profile = (",
            "                        session[\"oauth_info\"][\"userinfo\"]",
            "                        if \"oauth_info\" in session",
            "                        else None",
            "                    )",
            "                    if oauth_profile is not None:",
            "                        oauth_profile = oauth.OAuthProfile(oauth_profile)",
            "                    elif type_hint == oauth.OAuthProfile:",
            "                        raise Error(",
            "                            \"This action requires a logged in user. Please sign in and retry.\"",
            "                        )",
            "                    inputs.insert(i, oauth_profile)",
            "",
            "                # Inject user token",
            "                elif type_hint in (Optional[oauth.OAuthToken], oauth.OAuthToken):",
            "                    oauth_info = session.get(\"oauth_info\", None)",
            "                    oauth_token = (",
            "                        oauth.OAuthToken(",
            "                            token=oauth_info[\"access_token\"],",
            "                            scope=oauth_info[\"scope\"],",
            "                            expires_at=oauth_info[\"expires_at\"],",
            "                        )",
            "                        if oauth_info is not None",
            "                        else None",
            "                    )",
            "                    if oauth_token is None and type_hint == oauth.OAuthToken:",
            "                        raise Error(",
            "                            \"This action requires a logged in user. Please sign in and retry.\"",
            "                        )",
            "                    inputs.insert(i, oauth_token)",
            "        elif (",
            "            type_hint",
            "            and inspect.isclass(type_hint)",
            "            and issubclass(type_hint, EventData)",
            "        ):",
            "            event_data_index = i",
            "            if inputs is not None and event_data is not None:",
            "                processing_utils.check_all_files_in_cache(event_data._data)",
            "                inputs.insert(i, type_hint(event_data.target, event_data._data))",
            "        elif (",
            "            param.default is not param.empty and inputs is not None and len(inputs) <= i",
            "        ):",
            "            inputs.insert(i, param.default)",
            "    if inputs is not None:",
            "        while len(inputs) < len(positional_args):",
            "            i = len(inputs)",
            "            param = positional_args[i]",
            "            if param.default == param.empty:",
            "                warnings.warn(\"Unexpected argument. Filling with None.\")",
            "                inputs.append(None)",
            "            else:",
            "                inputs.append(param.default)",
            "    return inputs or [], progress_index, event_data_index",
            "",
            "",
            "def update(",
            "    elem_id: str | None = None,",
            "    elem_classes: list[str] | str | None = None,",
            "    visible: bool | None = None,",
            "    **kwargs,",
            ") -> dict:",
            "    \"\"\"",
            "    Updates a component's properties. When a function passed into a Gradio Interface or a Blocks events returns a value, it typically updates the value of the output component. But it is also possible to update the *properties* of an output component (such as the number of lines of a `Textbox` or the visibility of an `Row`) by returning a component and passing in the parameters to update in the constructor of the component. Alternatively, you can return `gr.update(...)` with any arbitrary parameters to update. (This is useful as a shorthand or if the same function can be called with different components to update.)",
            "",
            "    Parameters:",
            "        elem_id: Use this to update the id of the component in the HTML DOM",
            "        elem_classes: Use this to update the classes of the component in the HTML DOM",
            "        visible: Use this to update the visibility of the component",
            "        kwargs: Any other keyword arguments to update the component's properties.",
            "    Example:",
            "        import gradio as gr",
            "        with gr.Blocks() as demo:",
            "            radio = gr.Radio([1, 2, 4], label=\"Set the value of the number\")",
            "            number = gr.Number(value=2, interactive=True)",
            "            radio.change(fn=lambda value: gr.update(value=value), inputs=radio, outputs=number)",
            "        demo.launch()",
            "    \"\"\"",
            "    kwargs[\"__type__\"] = \"update\"",
            "    if elem_id is not None:",
            "        kwargs[\"elem_id\"] = elem_id",
            "    if elem_classes is not None:",
            "        kwargs[\"elem_classes\"] = elem_classes",
            "    if visible is not None:",
            "        kwargs[\"visible\"] = visible",
            "    return kwargs",
            "",
            "",
            "def skip() -> dict:",
            "    return {\"__type__\": \"update\"}",
            "",
            "",
            "@document()",
            "def make_waveform(",
            "    audio: str | tuple[int, np.ndarray],",
            "    *,",
            "    bg_color: str = \"#f3f4f6\",",
            "    bg_image: str | None = None,",
            "    fg_alpha: float = 0.75,",
            "    bars_color: str | tuple[str, str] = (\"#fbbf24\", \"#ea580c\"),",
            "    bar_count: int = 50,",
            "    bar_width: float = 0.6,",
            "    animate: bool = False,",
            ") -> str:",
            "    \"\"\"",
            "    Generates a waveform video from an audio file. Useful for creating an easy to share audio visualization. The output should be passed into a `gr.Video` component.",
            "    Parameters:",
            "        audio: Audio file path or tuple of (sample_rate, audio_data)",
            "        bg_color: Background color of waveform (ignored if bg_image is provided)",
            "        bg_image: Background image of waveform",
            "        fg_alpha: Opacity of foreground waveform",
            "        bars_color: Color of waveform bars. Can be a single color or a tuple of (start_color, end_color) of gradient",
            "        bar_count: Number of bars in waveform",
            "        bar_width: Width of bars in waveform. 1 represents full width, 0.5 represents half width, etc.",
            "        animate: If true, the audio waveform overlay will be animated, if false, it will be static.",
            "    Returns:",
            "        A filepath to the output video in mp4 format.",
            "    \"\"\"",
            "    import matplotlib.pyplot as plt",
            "    from matplotlib.animation import FuncAnimation",
            "",
            "    if isinstance(audio, str):",
            "        audio_file = audio",
            "        audio = processing_utils.audio_from_file(audio)",
            "    else:",
            "        tmp_wav = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)",
            "        processing_utils.audio_to_file(audio[0], audio[1], tmp_wav.name, format=\"wav\")",
            "        audio_file = tmp_wav.name",
            "",
            "    if not os.path.isfile(audio_file):",
            "        raise ValueError(\"Audio file not found.\")",
            "",
            "    ffmpeg = shutil.which(\"ffmpeg\")",
            "    if not ffmpeg:",
            "        raise RuntimeError(\"ffmpeg not found.\")",
            "",
            "    duration = round(len(audio[1]) / audio[0], 4)",
            "",
            "    # Helper methods to create waveform",
            "    def hex_to_rgb(hex_str):",
            "        return [int(hex_str[i : i + 2], 16) for i in range(1, 6, 2)]",
            "",
            "    def get_color_gradient(c1, c2, n):",
            "        if n < 1:",
            "            raise ValueError(\"Must have at least one stop in gradient\")",
            "        c1_rgb = np.array(hex_to_rgb(c1)) / 255",
            "        c2_rgb = np.array(hex_to_rgb(c2)) / 255",
            "        mix_pcts = [x / (n - 1) for x in range(n)]",
            "        rgb_colors = [((1 - mix) * c1_rgb + (mix * c2_rgb)) for mix in mix_pcts]",
            "        return [",
            "            \"#\" + \"\".join(f\"{int(round(val * 255)):02x}\" for val in item)",
            "            for item in rgb_colors",
            "        ]",
            "",
            "    # Reshape audio to have a fixed number of bars",
            "    samples = audio[1]",
            "    if len(samples.shape) > 1:",
            "        samples = np.mean(samples, 1)",
            "    bins_to_pad = bar_count - (len(samples) % bar_count)",
            "    samples = np.pad(samples, [(0, bins_to_pad)])",
            "    samples = np.reshape(samples, (bar_count, -1))",
            "    samples = np.abs(samples)",
            "    samples = np.max(samples, 1)",
            "",
            "    with utils.MatplotlibBackendMananger():",
            "        plt.clf()",
            "        # Plot waveform",
            "        color = (",
            "            bars_color",
            "            if isinstance(bars_color, str)",
            "            else get_color_gradient(bars_color[0], bars_color[1], bar_count)",
            "        )",
            "",
            "        if animate:",
            "            fig = plt.figure(figsize=(5, 1), dpi=200, frameon=False)",
            "            fig.subplots_adjust(left=0, bottom=0, right=1, top=1)",
            "        plt.axis(\"off\")",
            "        plt.margins(x=0)",
            "",
            "        bar_alpha = fg_alpha if animate else 1.0",
            "        barcollection = plt.bar(",
            "            np.arange(0, bar_count),",
            "            samples * 2,",
            "            bottom=(-1 * samples),",
            "            width=bar_width,",
            "            color=color,",
            "            alpha=bar_alpha,",
            "        )",
            "",
            "        tmp_img = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)",
            "",
            "        savefig_kwargs: dict[str, Any] = {\"bbox_inches\": \"tight\"}",
            "        if bg_image is not None:",
            "            savefig_kwargs[\"transparent\"] = True",
            "            if animate:",
            "                savefig_kwargs[\"facecolor\"] = \"none\"",
            "        else:",
            "            savefig_kwargs[\"facecolor\"] = bg_color",
            "        plt.savefig(tmp_img.name, **savefig_kwargs)",
            "",
            "        if not animate:",
            "            waveform_img = PIL.Image.open(tmp_img.name)",
            "            waveform_img = waveform_img.resize((1000, 400))",
            "",
            "            # Composite waveform with background image",
            "            if bg_image is not None:",
            "                waveform_array = np.array(waveform_img)",
            "                waveform_array[:, :, 3] = waveform_array[:, :, 3] * fg_alpha",
            "                waveform_img = PIL.Image.fromarray(waveform_array)",
            "",
            "                bg_img = PIL.Image.open(bg_image)",
            "                waveform_width, waveform_height = waveform_img.size",
            "                bg_width, bg_height = bg_img.size",
            "                if waveform_width != bg_width:",
            "                    bg_img = bg_img.resize(",
            "                        (",
            "                            waveform_width,",
            "                            2 * int(bg_height * waveform_width / bg_width / 2),",
            "                        )",
            "                    )",
            "                    bg_width, bg_height = bg_img.size",
            "                composite_height = max(bg_height, waveform_height)",
            "                composite = PIL.Image.new(",
            "                    \"RGBA\", (waveform_width, composite_height), \"#FFFFFF\"",
            "                )",
            "                composite.paste(bg_img, (0, composite_height - bg_height))",
            "                composite.paste(",
            "                    waveform_img, (0, composite_height - waveform_height), waveform_img",
            "                )",
            "                composite.save(tmp_img.name)",
            "                img_width, img_height = composite.size",
            "            else:",
            "                img_width, img_height = waveform_img.size",
            "                waveform_img.save(tmp_img.name)",
            "        else:",
            "",
            "            def _animate(_):",
            "                for idx, b in enumerate(barcollection):",
            "                    rand_height = np.random.uniform(0.8, 1.2)",
            "                    b.set_height(samples[idx] * rand_height * 2)",
            "                    b.set_y((-rand_height * samples)[idx])",
            "",
            "            frames = int(duration * 10)",
            "            anim = FuncAnimation(",
            "                fig,  # type: ignore",
            "                _animate,  # type: ignore",
            "                repeat=False,",
            "                blit=False,",
            "                frames=frames,",
            "                interval=100,",
            "            )",
            "            anim.save(",
            "                tmp_img.name,",
            "                writer=\"pillow\",",
            "                fps=10,",
            "                codec=\"png\",",
            "                savefig_kwargs=savefig_kwargs,",
            "            )",
            "",
            "    # Convert waveform to video with ffmpeg",
            "    output_mp4 = tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False)",
            "",
            "    if animate and bg_image is not None:",
            "        ffmpeg_cmd = [",
            "            ffmpeg,",
            "            \"-loop\",",
            "            \"1\",",
            "            \"-i\",",
            "            bg_image,",
            "            \"-i\",",
            "            tmp_img.name,",
            "            \"-i\",",
            "            audio_file,",
            "            \"-filter_complex\",",
            "            \"[0:v]scale=w=trunc(iw/2)*2:h=trunc(ih/2)*2[bg];[1:v]format=rgba,colorchannelmixer=aa=1.0[ov];[bg][ov]overlay=(main_w-overlay_w*0.9)/2:main_h-overlay_h*0.9/2[output]\",",
            "            \"-t\",",
            "            str(duration),",
            "            \"-map\",",
            "            \"[output]\",",
            "            \"-map\",",
            "            \"2:a\",",
            "            \"-c:v\",",
            "            \"libx264\",",
            "            \"-c:a\",",
            "            \"aac\",",
            "            \"-shortest\",",
            "            \"-y\",",
            "            output_mp4.name,",
            "        ]",
            "    elif animate and bg_image is None:",
            "        ffmpeg_cmd = [",
            "            ffmpeg,",
            "            \"-i\",",
            "            tmp_img.name,",
            "            \"-i\",",
            "            audio_file,",
            "            \"-filter_complex\",",
            "            \"[0:v][1:a]concat=n=1:v=1:a=1[v];[v]scale=1000:400,format=yuv420p[v_scaled]\",",
            "            \"-map\",",
            "            \"[v_scaled]\",",
            "            \"-map\",",
            "            \"1:a\",",
            "            \"-c:v\",",
            "            \"libx264\",",
            "            \"-c:a\",",
            "            \"aac\",",
            "            \"-shortest\",",
            "            \"-y\",",
            "            output_mp4.name,",
            "        ]",
            "    else:",
            "        ffmpeg_cmd = [",
            "            ffmpeg,",
            "            \"-loop\",",
            "            \"1\",",
            "            \"-i\",",
            "            tmp_img.name,",
            "            \"-i\",",
            "            audio_file,",
            "            \"-vf\",",
            "            f\"color=c=#FFFFFF77:s={img_width}x{img_height}[bar];[0][bar]overlay=-w+(w/{duration})*t:H-h:shortest=1\",  # type: ignore",
            "            \"-t\",",
            "            str(duration),",
            "            \"-y\",",
            "            output_mp4.name,",
            "        ]",
            "",
            "    subprocess.check_call(ffmpeg_cmd)",
            "    return output_mp4.name",
            "",
            "",
            "def log_message(message: str, level: Literal[\"info\", \"warning\"] = \"info\"):",
            "    from gradio.context import LocalContext",
            "",
            "    blocks = LocalContext.blocks.get()",
            "    event_id = LocalContext.event_id.get()",
            "    if blocks is None or event_id is None:",
            "        # Function called outside of Gradio if blocks is None",
            "        # Or from /api/predict if event_id is None",
            "        if level == \"info\":",
            "            print(message)",
            "        elif level == \"warning\":",
            "            warnings.warn(message)",
            "        return",
            "    blocks._queue.log_message(event_id=event_id, log=message, level=level)",
            "",
            "",
            "@document(documentation_group=\"modals\")",
            "def Warning(message: str = \"Warning issued.\"):  # noqa: N802",
            "    \"\"\"",
            "    This function allows you to pass custom warning messages to the user. You can do so simply by writing `gr.Warning('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is yellow by default and has the heading: \"Warning.\" Queue must be enabled for this behavior; otherwise, the warning will be printed to the console using the `warnings` library.",
            "    Demos: blocks_chained_events",
            "    Parameters:",
            "        message: The warning message to be displayed to the user.",
            "    Example:",
            "        import gradio as gr",
            "        def hello_world():",
            "            gr.Warning('This is a warning message.')",
            "            return \"hello world\"",
            "        with gr.Blocks() as demo:",
            "            md = gr.Markdown()",
            "            demo.load(hello_world, inputs=None, outputs=[md])",
            "        demo.queue().launch()",
            "    \"\"\"",
            "    log_message(message, level=\"warning\")",
            "",
            "",
            "@document(documentation_group=\"modals\")",
            "def Info(message: str = \"Info issued.\"):  # noqa: N802",
            "    \"\"\"",
            "    This function allows you to pass custom info messages to the user. You can do so simply by writing `gr.Info('message here')` in your function, and when that line is executed the custom message will appear in a modal on the demo. The modal is gray by default and has the heading: \"Info.\" Queue must be enabled for this behavior; otherwise, the message will be printed to the console.",
            "    Demos: blocks_chained_events",
            "    Parameters:",
            "        message: The info message to be displayed to the user.",
            "    Example:",
            "        import gradio as gr",
            "        def hello_world():",
            "            gr.Info('This is some info.')",
            "            return \"hello world\"",
            "        with gr.Blocks() as demo:",
            "            md = gr.Markdown()",
            "            demo.load(hello_world, inputs=None, outputs=[md])",
            "        demo.queue().launch()",
            "    \"\"\"",
            "    log_message(message, level=\"info\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "airflow.auth.managers.fab.security_manager.override.FabAirflowSecurityManagerOverride.register_views",
            "gradio.helpers.special_args.positional_args"
        ]
    },
    "gradio/processing_utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from PIL import Image, ImageOps, PngImagePlugin"
            },
            "1": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from gradio import utils, wasm_utils"
            },
            "3": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from gradio.data_classes import FileData, GradioModel, GradioRootModel"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+from gradio.data_classes import FileData, GradioModel, GradioRootModel, JsonData"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+from gradio.exceptions import Error"
            },
            "6": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from gradio.utils import abspath, get_upload_folder, is_in_or_equal"
            },
            "7": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " with warnings.catch_warnings():"
            },
            "9": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": 342,
                "PatchRowcode": "     return block.move_resource_to_block_cache(url_or_file_path)"
            },
            "10": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": 343,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": 344,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 345,
                "PatchRowcode": "+def check_all_files_in_cache(data: JsonData):"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 346,
                "PatchRowcode": "+    def _in_cache(d: dict):"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 347,
                "PatchRowcode": "+        if ("
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+            (path := d.get(\"path\", \"\"))"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 349,
                "PatchRowcode": "+            and not client_utils.is_http_url_like(path)"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 350,
                "PatchRowcode": "+            and not is_in_or_equal(path, get_upload_folder())"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 351,
                "PatchRowcode": "+        ):"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 352,
                "PatchRowcode": "+            raise Error("
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 353,
                "PatchRowcode": "+                f\"File {path} is not in the cache folder and cannot be accessed.\""
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 354,
                "PatchRowcode": "+            )"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 355,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 356,
                "PatchRowcode": "+    client_utils.traverse(data, _in_cache, client_utils.is_file_obj)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 357,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 358,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": 359,
                "PatchRowcode": " def move_files_to_cache("
            },
            "27": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": 360,
                "PatchRowcode": "     data: Any,"
            },
            "28": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 361,
                "PatchRowcode": "     block: Block,"
            },
            "29": {
                "beforePatchRowNumber": 475,
                "afterPatchRowNumber": 490,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 476,
                "afterPatchRowNumber": 491,
                "PatchRowcode": "     if isinstance(data, (GradioRootModel, GradioModel)):"
            },
            "31": {
                "beforePatchRowNumber": 477,
                "afterPatchRowNumber": 492,
                "PatchRowcode": "         data = data.model_dump()"
            },
            "32": {
                "beforePatchRowNumber": 478,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "33": {
                "beforePatchRowNumber": 479,
                "afterPatchRowNumber": 493,
                "PatchRowcode": "     return await client_utils.async_traverse("
            },
            "34": {
                "beforePatchRowNumber": 480,
                "afterPatchRowNumber": 494,
                "PatchRowcode": "         data, _move_to_cache, client_utils.is_file_obj"
            },
            "35": {
                "beforePatchRowNumber": 481,
                "afterPatchRowNumber": 495,
                "PatchRowcode": "     )"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "import base64",
            "import hashlib",
            "import json",
            "import logging",
            "import os",
            "import shutil",
            "import subprocess",
            "import tempfile",
            "import warnings",
            "from io import BytesIO",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any",
            "",
            "import aiofiles",
            "import httpx",
            "import numpy as np",
            "from gradio_client import utils as client_utils",
            "from PIL import Image, ImageOps, PngImagePlugin",
            "",
            "from gradio import utils, wasm_utils",
            "from gradio.data_classes import FileData, GradioModel, GradioRootModel",
            "from gradio.utils import abspath, get_upload_folder, is_in_or_equal",
            "",
            "with warnings.catch_warnings():",
            "    warnings.simplefilter(\"ignore\")  # Ignore pydub warning if ffmpeg is not installed",
            "    from pydub import AudioSegment",
            "",
            "if wasm_utils.IS_WASM:",
            "    import pyodide.http  # type: ignore",
            "    import urllib3",
            "",
            "    # NOTE: In the Wasm env, we use urllib3 to make HTTP requests. See https://github.com/gradio-app/gradio/issues/6837.",
            "    class Urllib3ResponseSyncByteStream(httpx.SyncByteStream):",
            "        def __init__(self, response) -> None:",
            "            self.response = response",
            "",
            "        def __iter__(self):",
            "            yield from self.response.stream()",
            "",
            "    class Urllib3Transport(httpx.BaseTransport):",
            "        def __init__(self):",
            "            self.pool = urllib3.PoolManager()",
            "",
            "        def handle_request(self, request: httpx.Request) -> httpx.Response:",
            "            url = str(request.url)",
            "            method = request.method",
            "            headers = dict(request.headers)",
            "            body = None if method in [\"GET\", \"HEAD\"] else request.read()",
            "",
            "            response = self.pool.request(",
            "                headers=headers,",
            "                method=method,",
            "                url=url,",
            "                body=body,",
            "                preload_content=False,  # Stream the content",
            "            )",
            "",
            "            return httpx.Response(",
            "                status_code=response.status,",
            "                headers=response.headers,",
            "                stream=Urllib3ResponseSyncByteStream(response),",
            "            )",
            "",
            "    sync_transport = Urllib3Transport()",
            "",
            "    class PyodideHttpResponseAsyncByteStream(httpx.AsyncByteStream):",
            "        def __init__(self, response) -> None:",
            "            self.response = response",
            "",
            "        async def __aiter__(self):",
            "            yield await self.response.bytes()",
            "",
            "    class PyodideHttpTransport(httpx.AsyncBaseTransport):",
            "        async def handle_async_request(",
            "            self,",
            "            request: httpx.Request,",
            "        ) -> httpx.Response:",
            "            url = str(request.url)",
            "            method = request.method",
            "            headers = dict(request.headers)",
            "            body = None if method in [\"GET\", \"HEAD\"] else await request.aread()",
            "            response = await pyodide.http.pyfetch(",
            "                url, method=method, headers=headers, body=body",
            "            )",
            "            return httpx.Response(",
            "                status_code=response.status,",
            "                headers=response.headers,",
            "                stream=PyodideHttpResponseAsyncByteStream(response),",
            "            )",
            "",
            "    async_transport = PyodideHttpTransport()",
            "else:",
            "    sync_transport = None",
            "    async_transport = None",
            "",
            "sync_client = httpx.Client(transport=sync_transport)",
            "async_client = httpx.AsyncClient(transport=async_transport)",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "if TYPE_CHECKING:",
            "    from gradio.blocks import Block",
            "",
            "#########################",
            "# GENERAL",
            "#########################",
            "",
            "",
            "def to_binary(x: str | dict) -> bytes:",
            "    \"\"\"Converts a base64 string or dictionary to a binary string that can be sent in a POST.\"\"\"",
            "    if isinstance(x, dict):",
            "        if x.get(\"data\"):",
            "            base64str = x[\"data\"]",
            "        else:",
            "            base64str = client_utils.encode_url_or_file_to_base64(x[\"path\"])",
            "    else:",
            "        base64str = x",
            "    return base64.b64decode(extract_base64_data(base64str))",
            "",
            "",
            "def extract_base64_data(x: str) -> str:",
            "    \"\"\"Just extracts the base64 data from a general base64 string.\"\"\"",
            "    return x.rsplit(\",\", 1)[-1]",
            "",
            "",
            "#########################",
            "# IMAGE PRE-PROCESSING",
            "#########################",
            "",
            "",
            "def encode_plot_to_base64(plt, format: str = \"png\"):",
            "    fmt = format or \"png\"",
            "    with BytesIO() as output_bytes:",
            "        plt.savefig(output_bytes, format=fmt)",
            "        bytes_data = output_bytes.getvalue()",
            "    base64_str = str(base64.b64encode(bytes_data), \"utf-8\")",
            "    return output_base64(base64_str, fmt)",
            "",
            "",
            "def get_pil_exif_bytes(pil_image):",
            "    if \"exif\" in pil_image.info:",
            "        return pil_image.info[\"exif\"]",
            "",
            "",
            "def get_pil_metadata(pil_image):",
            "    # Copy any text-only metadata",
            "    metadata = PngImagePlugin.PngInfo()",
            "    for key, value in pil_image.info.items():",
            "        if isinstance(key, str) and isinstance(value, str):",
            "            metadata.add_text(key, value)",
            "",
            "    return metadata",
            "",
            "",
            "def encode_pil_to_bytes(pil_image, format=\"png\"):",
            "    with BytesIO() as output_bytes:",
            "        if format == \"png\":",
            "            params = {\"pnginfo\": get_pil_metadata(pil_image)}",
            "        else:",
            "            exif = get_pil_exif_bytes(pil_image)",
            "            params = {\"exif\": exif} if exif else {}",
            "        pil_image.save(output_bytes, format, **params)",
            "        return output_bytes.getvalue()",
            "",
            "",
            "def encode_pil_to_base64(pil_image, format=\"png\"):",
            "    bytes_data = encode_pil_to_bytes(pil_image, format)",
            "    base64_str = str(base64.b64encode(bytes_data), \"utf-8\")",
            "    return output_base64(base64_str, format)",
            "",
            "",
            "def encode_array_to_base64(image_array, format=\"png\"):",
            "    with BytesIO() as output_bytes:",
            "        pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))",
            "        pil_image.save(output_bytes, format)",
            "        bytes_data = output_bytes.getvalue()",
            "    base64_str = str(base64.b64encode(bytes_data), \"utf-8\")",
            "    return output_base64(base64_str, format)",
            "",
            "",
            "def output_base64(data, format=None) -> str:",
            "    return f\"data:image/{format or 'png'};base64,{data}\"",
            "",
            "",
            "def hash_file(file_path: str | Path, chunk_num_blocks: int = 128) -> str:",
            "    sha1 = hashlib.sha1()",
            "    with open(file_path, \"rb\") as f:",
            "        for chunk in iter(lambda: f.read(chunk_num_blocks * sha1.block_size), b\"\"):",
            "            sha1.update(chunk)",
            "    return sha1.hexdigest()",
            "",
            "",
            "def hash_url(url: str) -> str:",
            "    sha1 = hashlib.sha1()",
            "    sha1.update(url.encode(\"utf-8\"))",
            "    return sha1.hexdigest()",
            "",
            "",
            "def hash_bytes(bytes: bytes):",
            "    sha1 = hashlib.sha1()",
            "    sha1.update(bytes)",
            "    return sha1.hexdigest()",
            "",
            "",
            "def hash_base64(base64_encoding: str, chunk_num_blocks: int = 128) -> str:",
            "    sha1 = hashlib.sha1()",
            "    for i in range(0, len(base64_encoding), chunk_num_blocks * sha1.block_size):",
            "        data = base64_encoding[i : i + chunk_num_blocks * sha1.block_size]",
            "        sha1.update(data.encode(\"utf-8\"))",
            "    return sha1.hexdigest()",
            "",
            "",
            "def save_pil_to_cache(",
            "    img: Image.Image,",
            "    cache_dir: str,",
            "    name: str = \"image\",",
            "    format: str = \"webp\",",
            ") -> str:",
            "    bytes_data = encode_pil_to_bytes(img, format)",
            "    temp_dir = Path(cache_dir) / hash_bytes(bytes_data)",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    filename = str((temp_dir / f\"{name}.{format}\").resolve())",
            "    (temp_dir / f\"{name}.{format}\").resolve().write_bytes(bytes_data)",
            "    return filename",
            "",
            "",
            "def save_img_array_to_cache(",
            "    arr: np.ndarray, cache_dir: str, format: str = \"webp\"",
            ") -> str:",
            "    pil_image = Image.fromarray(_convert(arr, np.uint8, force_copy=False))",
            "    return save_pil_to_cache(pil_image, cache_dir, format=format)",
            "",
            "",
            "def save_audio_to_cache(",
            "    data: np.ndarray, sample_rate: int, format: str, cache_dir: str",
            ") -> str:",
            "    temp_dir = Path(cache_dir) / hash_bytes(data.tobytes())",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    filename = str((temp_dir / f\"audio.{format}\").resolve())",
            "    audio_to_file(sample_rate, data, filename, format=format)",
            "    return filename",
            "",
            "",
            "def save_bytes_to_cache(data: bytes, file_name: str, cache_dir: str) -> str:",
            "    path = Path(cache_dir) / hash_bytes(data)",
            "    path.mkdir(exist_ok=True, parents=True)",
            "    path = path / Path(file_name).name",
            "    path.write_bytes(data)",
            "    return str(path.resolve())",
            "",
            "",
            "def save_file_to_cache(file_path: str | Path, cache_dir: str) -> str:",
            "    \"\"\"Returns a temporary file path for a copy of the given file path if it does",
            "    not already exist. Otherwise returns the path to the existing temp file.\"\"\"",
            "    temp_dir = hash_file(file_path)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "",
            "    name = client_utils.strip_invalid_filename_characters(Path(file_path).name)",
            "    full_temp_file_path = str(abspath(temp_dir / name))",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        shutil.copy2(file_path, full_temp_file_path)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "def save_url_to_cache(url: str, cache_dir: str) -> str:",
            "    \"\"\"Downloads a file and makes a temporary file path for a copy if does not already",
            "    exist. Otherwise returns the path to the existing temp file.\"\"\"",
            "    temp_dir = hash_url(url)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    name = client_utils.strip_invalid_filename_characters(Path(url).name)",
            "    full_temp_file_path = str(abspath(temp_dir / name))",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        with sync_client.stream(\"GET\", url, follow_redirects=True) as r, open(",
            "            full_temp_file_path, \"wb\"",
            "        ) as f:",
            "            for chunk in r.iter_raw():",
            "                f.write(chunk)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "async def async_save_url_to_cache(url: str, cache_dir: str) -> str:",
            "    \"\"\"Downloads a file and makes a temporary file path for a copy if does not already",
            "    exist. Otherwise returns the path to the existing temp file. Uses async httpx.\"\"\"",
            "    temp_dir = hash_url(url)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    name = client_utils.strip_invalid_filename_characters(Path(url).name)",
            "    full_temp_file_path = str(abspath(temp_dir / name))",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        async with async_client.stream(\"GET\", url, follow_redirects=True) as response:",
            "            async with aiofiles.open(full_temp_file_path, \"wb\") as f:",
            "                async for chunk in response.aiter_raw():",
            "                    await f.write(chunk)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "def save_base64_to_cache(",
            "    base64_encoding: str, cache_dir: str, file_name: str | None = None",
            ") -> str:",
            "    \"\"\"Converts a base64 encoding to a file and returns the path to the file if",
            "    the file doesn't already exist. Otherwise returns the path to the existing file.",
            "    \"\"\"",
            "    temp_dir = hash_base64(base64_encoding)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "",
            "    guess_extension = client_utils.get_extension(base64_encoding)",
            "    if file_name:",
            "        file_name = client_utils.strip_invalid_filename_characters(file_name)",
            "    elif guess_extension:",
            "        file_name = f\"file.{guess_extension}\"",
            "    else:",
            "        file_name = \"file\"",
            "",
            "    full_temp_file_path = str(abspath(temp_dir / file_name))  # type: ignore",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        data, _ = client_utils.decode_base64_to_binary(base64_encoding)",
            "        with open(full_temp_file_path, \"wb\") as fb:",
            "            fb.write(data)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "def move_resource_to_block_cache(",
            "    url_or_file_path: str | Path | None, block: Block",
            ") -> str | None:",
            "    \"\"\"This method has been replaced by Block.move_resource_to_block_cache(), but is",
            "    left here for backwards compatibility for any custom components created in Gradio 4.2.0 or earlier.",
            "    \"\"\"",
            "    return block.move_resource_to_block_cache(url_or_file_path)",
            "",
            "",
            "def move_files_to_cache(",
            "    data: Any,",
            "    block: Block,",
            "    postprocess: bool = False,",
            "    check_in_upload_folder=False,",
            "    keep_in_cache=False,",
            "):",
            "    \"\"\"Move any files in `data` to cache and (optionally), adds URL prefixes (/file=...) needed to access the cached file.",
            "    Also handles the case where the file is on an external Gradio app (/proxy=...).",
            "",
            "    Runs after .postprocess() and before .preprocess().",
            "",
            "    Args:",
            "        data: The input or output data for a component. Can be a dictionary or a dataclass",
            "        block: The component whose data is being processed",
            "        postprocess: Whether its running from postprocessing",
            "        check_in_upload_folder: If True, instead of moving the file to cache, checks if the file is in already in cache (exception if not).",
            "        keep_in_cache: If True, the file will not be deleted from cache when the server is shut down.",
            "    \"\"\"",
            "",
            "    def _move_to_cache(d: dict):",
            "        payload = FileData(**d)",
            "        # If the gradio app developer is returning a URL from",
            "        # postprocess, it means the component can display a URL",
            "        # without it being served from the gradio server",
            "        # This makes it so that the URL is not downloaded and speeds up event processing",
            "        if payload.url and postprocess and client_utils.is_http_url_like(payload.url):",
            "            payload.path = payload.url",
            "        elif utils.is_static_file(payload):",
            "            pass",
            "        elif not block.proxy_url:",
            "            # If the file is on a remote server, do not move it to cache.",
            "            if check_in_upload_folder and not client_utils.is_http_url_like(",
            "                payload.path",
            "            ):",
            "                path = os.path.abspath(payload.path)",
            "                if not is_in_or_equal(path, get_upload_folder()):",
            "                    raise ValueError(",
            "                        f\"File {path} is not in the upload folder and cannot be accessed.\"",
            "                    )",
            "            if not payload.is_stream:",
            "                temp_file_path = block.move_resource_to_block_cache(payload.path)",
            "                if temp_file_path is None:",
            "                    raise ValueError(\"Did not determine a file path for the resource.\")",
            "                payload.path = temp_file_path",
            "                if keep_in_cache:",
            "                    block.keep_in_cache.add(payload.path)",
            "",
            "        url_prefix = \"/stream/\" if payload.is_stream else \"/file=\"",
            "        if block.proxy_url:",
            "            proxy_url = block.proxy_url.rstrip(\"/\")",
            "            url = f\"/proxy={proxy_url}{url_prefix}{payload.path}\"",
            "        elif client_utils.is_http_url_like(payload.path) or payload.path.startswith(",
            "            f\"{url_prefix}\"",
            "        ):",
            "            url = payload.path",
            "        else:",
            "            url = f\"{url_prefix}{payload.path}\"",
            "        payload.url = url",
            "",
            "        return payload.model_dump()",
            "",
            "    if isinstance(data, (GradioRootModel, GradioModel)):",
            "        data = data.model_dump()",
            "",
            "    return client_utils.traverse(data, _move_to_cache, client_utils.is_file_obj)",
            "",
            "",
            "async def async_move_files_to_cache(",
            "    data: Any,",
            "    block: Block,",
            "    postprocess: bool = False,",
            "    check_in_upload_folder=False,",
            "    keep_in_cache=False,",
            ") -> dict:",
            "    \"\"\"Move any files in `data` to cache and (optionally), adds URL prefixes (/file=...) needed to access the cached file.",
            "    Also handles the case where the file is on an external Gradio app (/proxy=...).",
            "",
            "    Runs after .postprocess() and before .preprocess().",
            "",
            "    Args:",
            "        data: The input or output data for a component. Can be a dictionary or a dataclass",
            "        block: The component whose data is being processed",
            "        postprocess: Whether its running from postprocessing",
            "        check_in_upload_folder: If True, instead of moving the file to cache, checks if the file is in already in cache (exception if not).",
            "        keep_in_cache: If True, the file will not be deleted from cache when the server is shut down.",
            "    \"\"\"",
            "",
            "    async def _move_to_cache(d: dict):",
            "        payload = FileData(**d)",
            "        # If the gradio app developer is returning a URL from",
            "        # postprocess, it means the component can display a URL",
            "        # without it being served from the gradio server",
            "        # This makes it so that the URL is not downloaded and speeds up event processing",
            "        if payload.url and postprocess and client_utils.is_http_url_like(payload.url):",
            "            payload.path = payload.url",
            "        elif utils.is_static_file(payload):",
            "            pass",
            "        elif not block.proxy_url:",
            "            # If the file is on a remote server, do not move it to cache.",
            "            if check_in_upload_folder and not client_utils.is_http_url_like(",
            "                payload.path",
            "            ):",
            "                path = os.path.abspath(payload.path)",
            "                if not is_in_or_equal(path, get_upload_folder()):",
            "                    raise ValueError(",
            "                        f\"File {path} is not in the upload folder and cannot be accessed.\"",
            "                    )",
            "            if not payload.is_stream:",
            "                temp_file_path = await block.async_move_resource_to_block_cache(",
            "                    payload.path",
            "                )",
            "                if temp_file_path is None:",
            "                    raise ValueError(\"Did not determine a file path for the resource.\")",
            "                payload.path = temp_file_path",
            "                if keep_in_cache:",
            "                    block.keep_in_cache.add(payload.path)",
            "",
            "        url_prefix = \"/stream/\" if payload.is_stream else \"/file=\"",
            "        if block.proxy_url:",
            "            proxy_url = block.proxy_url.rstrip(\"/\")",
            "            url = f\"/proxy={proxy_url}{url_prefix}{payload.path}\"",
            "        elif client_utils.is_http_url_like(payload.path) or payload.path.startswith(",
            "            f\"{url_prefix}\"",
            "        ):",
            "            url = payload.path",
            "        else:",
            "            url = f\"{url_prefix}{payload.path}\"",
            "        payload.url = url",
            "",
            "        return payload.model_dump()",
            "",
            "    if isinstance(data, (GradioRootModel, GradioModel)):",
            "        data = data.model_dump()",
            "",
            "    return await client_utils.async_traverse(",
            "        data, _move_to_cache, client_utils.is_file_obj",
            "    )",
            "",
            "",
            "def add_root_url(data: dict | list, root_url: str, previous_root_url: str | None):",
            "    def _add_root_url(file_dict: dict):",
            "        if previous_root_url and file_dict[\"url\"].startswith(previous_root_url):",
            "            file_dict[\"url\"] = file_dict[\"url\"][len(previous_root_url) :]",
            "        elif client_utils.is_http_url_like(file_dict[\"url\"]):",
            "            return file_dict",
            "        file_dict[\"url\"] = f'{root_url}{file_dict[\"url\"]}'",
            "        return file_dict",
            "",
            "    return client_utils.traverse(data, _add_root_url, client_utils.is_file_obj_with_url)",
            "",
            "",
            "def resize_and_crop(img, size, crop_type=\"center\"):",
            "    \"\"\"",
            "    Resize and crop an image to fit the specified size.",
            "    args:",
            "        size: `(width, height)` tuple. Pass `None` for either width or height",
            "        to only crop and resize the other.",
            "        crop_type: can be 'top', 'middle' or 'bottom', depending on this",
            "            value, the image will cropped getting the 'top/left', 'middle' or",
            "            'bottom/right' of the image to fit the size.",
            "    raises:",
            "        ValueError: if an invalid `crop_type` is provided.",
            "    \"\"\"",
            "    if crop_type == \"top\":",
            "        center = (0, 0)",
            "    elif crop_type == \"center\":",
            "        center = (0.5, 0.5)",
            "    else:",
            "        raise ValueError",
            "",
            "    resize = list(size)",
            "    if size[0] is None:",
            "        resize[0] = img.size[0]",
            "    if size[1] is None:",
            "        resize[1] = img.size[1]",
            "    return ImageOps.fit(img, resize, centering=center)  # type: ignore",
            "",
            "",
            "##################",
            "# Audio",
            "##################",
            "",
            "",
            "def audio_from_file(filename, crop_min=0, crop_max=100):",
            "    try:",
            "        audio = AudioSegment.from_file(filename)",
            "    except FileNotFoundError as e:",
            "        isfile = Path(filename).is_file()",
            "        msg = (",
            "            f\"Cannot load audio from file: `{'ffprobe' if isfile else filename}` not found.\"",
            "            + \" Please install `ffmpeg` in your system to use non-WAV audio file formats\"",
            "            \" and make sure `ffprobe` is in your PATH.\"",
            "            if isfile",
            "            else \"\"",
            "        )",
            "        raise RuntimeError(msg) from e",
            "    if crop_min != 0 or crop_max != 100:",
            "        audio_start = len(audio) * crop_min / 100",
            "        audio_end = len(audio) * crop_max / 100",
            "        audio = audio[audio_start:audio_end]",
            "    data = np.array(audio.get_array_of_samples())",
            "    if audio.channels > 1:",
            "        data = data.reshape(-1, audio.channels)",
            "    return audio.frame_rate, data",
            "",
            "",
            "def audio_to_file(sample_rate, data, filename, format=\"wav\"):",
            "    if format == \"wav\":",
            "        data = convert_to_16_bit_wav(data)",
            "    audio = AudioSegment(",
            "        data.tobytes(),",
            "        frame_rate=sample_rate,",
            "        sample_width=data.dtype.itemsize,",
            "        channels=(1 if len(data.shape) == 1 else data.shape[1]),",
            "    )",
            "    file = audio.export(filename, format=format)",
            "    file.close()  # type: ignore",
            "",
            "",
            "def convert_to_16_bit_wav(data):",
            "    # Based on: https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html",
            "    warning = \"Trying to convert audio automatically from {} to 16-bit int format.\"",
            "    if data.dtype in [np.float64, np.float32, np.float16]:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data / np.abs(data).max()",
            "        data = data * 32767",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.int32:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data / 65536",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.int16:",
            "        pass",
            "    elif data.dtype == np.uint16:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data - 32768",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.uint8:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data * 257 - 32768",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.int8:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data * 256",
            "        data = data.astype(np.int16)",
            "    else:",
            "        raise ValueError(",
            "            \"Audio data cannot be converted automatically from \"",
            "            f\"{data.dtype} to 16-bit int format.\"",
            "        )",
            "    return data",
            "",
            "",
            "##################",
            "# OUTPUT",
            "##################",
            "",
            "",
            "def _convert(image, dtype, force_copy=False, uniform=False):",
            "    \"\"\"",
            "    Adapted from: https://github.com/scikit-image/scikit-image/blob/main/skimage/util/dtype.py#L510-L531",
            "",
            "    Convert an image to the requested data-type.",
            "    Warnings are issued in case of precision loss, or when negative values",
            "    are clipped during conversion to unsigned integer types (sign loss).",
            "    Floating point values are expected to be normalized and will be clipped",
            "    to the range [0.0, 1.0] or [-1.0, 1.0] when converting to unsigned or",
            "    signed integers respectively.",
            "    Numbers are not shifted to the negative side when converting from",
            "    unsigned to signed integer types. Negative values will be clipped when",
            "    converting to unsigned integers.",
            "    Parameters",
            "    ----------",
            "    image : ndarray",
            "        Input image.",
            "    dtype : dtype",
            "        Target data-type.",
            "    force_copy : bool, optional",
            "        Force a copy of the data, irrespective of its current dtype.",
            "    uniform : bool, optional",
            "        Uniformly quantize the floating point range to the integer range.",
            "        By default (uniform=False) floating point values are scaled and",
            "        rounded to the nearest integers, which minimizes back and forth",
            "        conversion errors.",
            "    .. versionchanged :: 0.15",
            "        ``_convert`` no longer warns about possible precision or sign",
            "        information loss. See discussions on these warnings at:",
            "        https://github.com/scikit-image/scikit-image/issues/2602",
            "        https://github.com/scikit-image/scikit-image/issues/543#issuecomment-208202228",
            "        https://github.com/scikit-image/scikit-image/pull/3575",
            "    References",
            "    ----------",
            "    .. [1] DirectX data conversion rules.",
            "           https://msdn.microsoft.com/en-us/library/windows/desktop/dd607323%28v=vs.85%29.aspx",
            "    .. [2] Data Conversions. In \"OpenGL ES 2.0 Specification v2.0.25\",",
            "           pp 7-8. Khronos Group, 2010.",
            "    .. [3] Proper treatment of pixels as integers. A.W. Paeth.",
            "           In \"Graphics Gems I\", pp 249-256. Morgan Kaufmann, 1990.",
            "    .. [4] Dirty Pixels. J. Blinn. In \"Jim Blinn's corner: Dirty Pixels\",",
            "           pp 47-57. Morgan Kaufmann, 1998.",
            "    \"\"\"",
            "    dtype_range = {",
            "        bool: (False, True),",
            "        np.bool_: (False, True),",
            "        np.bool8: (False, True),  # type: ignore",
            "        float: (-1, 1),",
            "        np.float_: (-1, 1),",
            "        np.float16: (-1, 1),",
            "        np.float32: (-1, 1),",
            "        np.float64: (-1, 1),",
            "    }",
            "",
            "    def _dtype_itemsize(itemsize, *dtypes):",
            "        \"\"\"Return first of `dtypes` with itemsize greater than `itemsize`",
            "        Parameters",
            "        ----------",
            "        itemsize: int",
            "            The data type object element size.",
            "        Other Parameters",
            "        ----------------",
            "        *dtypes:",
            "            Any Object accepted by `np.dtype` to be converted to a data",
            "            type object",
            "        Returns",
            "        -------",
            "        dtype: data type object",
            "            First of `dtypes` with itemsize greater than `itemsize`.",
            "        \"\"\"",
            "        return next(dt for dt in dtypes if np.dtype(dt).itemsize >= itemsize)",
            "",
            "    def _dtype_bits(kind, bits, itemsize=1):",
            "        \"\"\"Return dtype of `kind` that can store a `bits` wide unsigned int",
            "        Parameters:",
            "        kind: str",
            "            Data type kind.",
            "        bits: int",
            "            Desired number of bits.",
            "        itemsize: int",
            "            The data type object element size.",
            "        Returns",
            "        -------",
            "        dtype: data type object",
            "            Data type of `kind` that can store a `bits` wide unsigned int",
            "        \"\"\"",
            "",
            "        s = next(",
            "            i",
            "            for i in (itemsize,) + (2, 4, 8)",
            "            if bits < (i * 8) or (bits == (i * 8) and kind == \"u\")",
            "        )",
            "",
            "        return np.dtype(kind + str(s))",
            "",
            "    def _scale(a, n, m, copy=True):",
            "        \"\"\"Scale an array of unsigned/positive integers from `n` to `m` bits.",
            "        Numbers can be represented exactly only if `m` is a multiple of `n`.",
            "        Parameters",
            "        ----------",
            "        a : ndarray",
            "            Input image array.",
            "        n : int",
            "            Number of bits currently used to encode the values in `a`.",
            "        m : int",
            "            Desired number of bits to encode the values in `out`.",
            "        copy : bool, optional",
            "            If True, allocates and returns new array. Otherwise, modifies",
            "            `a` in place.",
            "        Returns",
            "        -------",
            "        out : array",
            "            Output image array. Has the same kind as `a`.",
            "        \"\"\"",
            "        kind = a.dtype.kind",
            "        if n > m and a.max() < 2**m:",
            "            return a.astype(_dtype_bits(kind, m))",
            "        elif n == m:",
            "            return a.copy() if copy else a",
            "        elif n > m:",
            "            # downscale with precision loss",
            "            if copy:",
            "                b = np.empty(a.shape, _dtype_bits(kind, m))",
            "                np.floor_divide(a, 2 ** (n - m), out=b, dtype=a.dtype, casting=\"unsafe\")",
            "                return b",
            "            else:",
            "                a //= 2 ** (n - m)",
            "                return a",
            "        elif m % n == 0:",
            "            # exact upscale to a multiple of `n` bits",
            "            if copy:",
            "                b = np.empty(a.shape, _dtype_bits(kind, m))",
            "                np.multiply(a, (2**m - 1) // (2**n - 1), out=b, dtype=b.dtype)",
            "                return b",
            "            else:",
            "                a = a.astype(_dtype_bits(kind, m, a.dtype.itemsize), copy=False)",
            "                a *= (2**m - 1) // (2**n - 1)",
            "                return a",
            "        else:",
            "            # upscale to a multiple of `n` bits,",
            "            # then downscale with precision loss",
            "            o = (m // n + 1) * n",
            "            if copy:",
            "                b = np.empty(a.shape, _dtype_bits(kind, o))",
            "                np.multiply(a, (2**o - 1) // (2**n - 1), out=b, dtype=b.dtype)",
            "                b //= 2 ** (o - m)",
            "                return b",
            "            else:",
            "                a = a.astype(_dtype_bits(kind, o, a.dtype.itemsize), copy=False)",
            "                a *= (2**o - 1) // (2**n - 1)",
            "                a //= 2 ** (o - m)",
            "                return a",
            "",
            "    image = np.asarray(image)",
            "    dtypeobj_in = image.dtype",
            "    dtypeobj_out = np.dtype(\"float64\") if dtype is np.floating else np.dtype(dtype)",
            "    dtype_in = dtypeobj_in.type",
            "    dtype_out = dtypeobj_out.type",
            "    kind_in = dtypeobj_in.kind",
            "    kind_out = dtypeobj_out.kind",
            "    itemsize_in = dtypeobj_in.itemsize",
            "    itemsize_out = dtypeobj_out.itemsize",
            "",
            "    # Below, we do an `issubdtype` check.  Its purpose is to find out",
            "    # whether we can get away without doing any image conversion.  This happens",
            "    # when:",
            "    #",
            "    # - the output and input dtypes are the same or",
            "    # - when the output is specified as a type, and the input dtype",
            "    #   is a subclass of that type (e.g. `np.floating` will allow",
            "    #   `float32` and `float64` arrays through)",
            "",
            "    if np.issubdtype(dtype_in, np.obj2sctype(dtype)):",
            "        if force_copy:",
            "            image = image.copy()",
            "        return image",
            "",
            "    if kind_in in \"ui\":",
            "        imin_in = np.iinfo(dtype_in).min",
            "        imax_in = np.iinfo(dtype_in).max",
            "    if kind_out in \"ui\":",
            "        imin_out = np.iinfo(dtype_out).min  # type: ignore",
            "        imax_out = np.iinfo(dtype_out).max  # type: ignore",
            "",
            "    # any -> binary",
            "    if kind_out == \"b\":",
            "        return image > dtype_in(dtype_range[dtype_in][1] / 2)",
            "",
            "    # binary -> any",
            "    if kind_in == \"b\":",
            "        result = image.astype(dtype_out)",
            "        if kind_out != \"f\":",
            "            result *= dtype_out(dtype_range[dtype_out][1])",
            "        return result",
            "",
            "    # float -> any",
            "    if kind_in == \"f\":",
            "        if kind_out == \"f\":",
            "            # float -> float",
            "            return image.astype(dtype_out)",
            "",
            "        if np.min(image) < -1.0 or np.max(image) > 1.0:",
            "            raise ValueError(\"Images of type float must be between -1 and 1.\")",
            "        # floating point -> integer",
            "        # use float type that can represent output integer type",
            "        computation_type = _dtype_itemsize(",
            "            itemsize_out, dtype_in, np.float32, np.float64",
            "        )",
            "",
            "        if not uniform:",
            "            if kind_out == \"u\":",
            "                image_out = np.multiply(image, imax_out, dtype=computation_type)  # type: ignore",
            "            else:",
            "                image_out = np.multiply(",
            "                    image,",
            "                    (imax_out - imin_out) / 2,  # type: ignore",
            "                    dtype=computation_type,",
            "                )",
            "                image_out -= 1.0 / 2.0",
            "            np.rint(image_out, out=image_out)",
            "            np.clip(image_out, imin_out, imax_out, out=image_out)  # type: ignore",
            "        elif kind_out == \"u\":",
            "            image_out = np.multiply(image, imax_out + 1, dtype=computation_type)  # type: ignore",
            "            np.clip(image_out, 0, imax_out, out=image_out)  # type: ignore",
            "        else:",
            "            image_out = np.multiply(",
            "                image,",
            "                (imax_out - imin_out + 1.0) / 2.0,  # type: ignore",
            "                dtype=computation_type,",
            "            )",
            "            np.floor(image_out, out=image_out)",
            "            np.clip(image_out, imin_out, imax_out, out=image_out)  # type: ignore",
            "        return image_out.astype(dtype_out)",
            "",
            "    # signed/unsigned int -> float",
            "    if kind_out == \"f\":",
            "        # use float type that can exactly represent input integers",
            "        computation_type = _dtype_itemsize(",
            "            itemsize_in, dtype_out, np.float32, np.float64",
            "        )",
            "",
            "        if kind_in == \"u\":",
            "            # using np.divide or np.multiply doesn't copy the data",
            "            # until the computation time",
            "            image = np.multiply(image, 1.0 / imax_in, dtype=computation_type)  # type: ignore",
            "            # DirectX uses this conversion also for signed ints",
            "            # if imin_in:",
            "            #     np.maximum(image, -1.0, out=image)",
            "        else:",
            "            image = np.add(image, 0.5, dtype=computation_type)",
            "            image *= 2 / (imax_in - imin_in)  # type: ignore",
            "",
            "        return np.asarray(image, dtype_out)",
            "",
            "    # unsigned int -> signed/unsigned int",
            "    if kind_in == \"u\":",
            "        if kind_out == \"i\":",
            "            # unsigned int -> signed int",
            "            image = _scale(image, 8 * itemsize_in, 8 * itemsize_out - 1)",
            "            return image.view(dtype_out)",
            "        else:",
            "            # unsigned int -> unsigned int",
            "            return _scale(image, 8 * itemsize_in, 8 * itemsize_out)",
            "",
            "    # signed int -> unsigned int",
            "    if kind_out == \"u\":",
            "        image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)",
            "        result = np.empty(image.shape, dtype_out)",
            "        np.maximum(image, 0, out=result, dtype=image.dtype, casting=\"unsafe\")",
            "        return result",
            "",
            "    # signed int -> signed int",
            "    if itemsize_in > itemsize_out:",
            "        return _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out - 1)",
            "",
            "    image = image.astype(_dtype_bits(\"i\", itemsize_out * 8))",
            "    image -= imin_in  # type: ignore",
            "    image = _scale(image, 8 * itemsize_in, 8 * itemsize_out, copy=False)",
            "    image += imin_out  # type: ignore",
            "    return image.astype(dtype_out)",
            "",
            "",
            "def ffmpeg_installed() -> bool:",
            "    if wasm_utils.IS_WASM:",
            "        # TODO: Support ffmpeg in WASM",
            "        return False",
            "",
            "    return shutil.which(\"ffmpeg\") is not None",
            "",
            "",
            "def video_is_playable(video_filepath: str) -> bool:",
            "    \"\"\"Determines if a video is playable in the browser.",
            "",
            "    A video is playable if it has a playable container and codec.",
            "        .mp4 -> h264",
            "        .webm -> vp9",
            "        .ogg -> theora",
            "    \"\"\"",
            "    from ffmpy import FFprobe, FFRuntimeError",
            "",
            "    try:",
            "        container = Path(video_filepath).suffix.lower()",
            "        probe = FFprobe(",
            "            global_options=\"-show_format -show_streams -select_streams v -print_format json\",",
            "            inputs={video_filepath: None},",
            "        )",
            "        output = probe.run(stderr=subprocess.PIPE, stdout=subprocess.PIPE)",
            "        output = json.loads(output[0])",
            "        video_codec = output[\"streams\"][0][\"codec_name\"]",
            "        return (container, video_codec) in [",
            "            (\".mp4\", \"h264\"),",
            "            (\".ogg\", \"theora\"),",
            "            (\".webm\", \"vp9\"),",
            "        ]",
            "    # If anything goes wrong, assume the video can be played to not convert downstream",
            "    except (FFRuntimeError, IndexError, KeyError):",
            "        return True",
            "",
            "",
            "def convert_video_to_playable_mp4(video_path: str) -> str:",
            "    \"\"\"Convert the video to mp4. If something goes wrong return the original video.\"\"\"",
            "    from ffmpy import FFmpeg, FFRuntimeError",
            "",
            "    try:",
            "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:",
            "            output_path = Path(video_path).with_suffix(\".mp4\")",
            "            shutil.copy2(video_path, tmp_file.name)",
            "            # ffmpeg will automatically use h264 codec (playable in browser) when converting to mp4",
            "            ff = FFmpeg(",
            "                inputs={str(tmp_file.name): None},",
            "                outputs={str(output_path): None},",
            "                global_options=\"-y -loglevel quiet\",",
            "            )",
            "            ff.run()",
            "    except FFRuntimeError as e:",
            "        print(f\"Error converting video to browser-playable format {str(e)}\")",
            "        output_path = video_path",
            "    finally:",
            "        # Remove temp file",
            "        os.remove(tmp_file.name)  # type: ignore",
            "    return str(output_path)",
            "",
            "",
            "def get_video_length(video_path: str | Path):",
            "    if wasm_utils.IS_WASM:",
            "        raise wasm_utils.WasmUnsupportedError(",
            "            \"Video duration is not supported in the Wasm mode.\"",
            "        )",
            "    duration = subprocess.check_output(",
            "        [",
            "            \"ffprobe\",",
            "            \"-i\",",
            "            str(video_path),",
            "            \"-show_entries\",",
            "            \"format=duration\",",
            "            \"-v\",",
            "            \"quiet\",",
            "            \"-of\",",
            "            \"csv={}\".format(\"p=0\"),",
            "        ]",
            "    )",
            "    duration_str = duration.decode(\"utf-8\").strip()",
            "    duration_float = float(duration_str)",
            "",
            "    return duration_float"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "import base64",
            "import hashlib",
            "import json",
            "import logging",
            "import os",
            "import shutil",
            "import subprocess",
            "import tempfile",
            "import warnings",
            "from io import BytesIO",
            "from pathlib import Path",
            "from typing import TYPE_CHECKING, Any",
            "",
            "import aiofiles",
            "import httpx",
            "import numpy as np",
            "from gradio_client import utils as client_utils",
            "from PIL import Image, ImageOps, PngImagePlugin",
            "",
            "from gradio import utils, wasm_utils",
            "from gradio.data_classes import FileData, GradioModel, GradioRootModel, JsonData",
            "from gradio.exceptions import Error",
            "from gradio.utils import abspath, get_upload_folder, is_in_or_equal",
            "",
            "with warnings.catch_warnings():",
            "    warnings.simplefilter(\"ignore\")  # Ignore pydub warning if ffmpeg is not installed",
            "    from pydub import AudioSegment",
            "",
            "if wasm_utils.IS_WASM:",
            "    import pyodide.http  # type: ignore",
            "    import urllib3",
            "",
            "    # NOTE: In the Wasm env, we use urllib3 to make HTTP requests. See https://github.com/gradio-app/gradio/issues/6837.",
            "    class Urllib3ResponseSyncByteStream(httpx.SyncByteStream):",
            "        def __init__(self, response) -> None:",
            "            self.response = response",
            "",
            "        def __iter__(self):",
            "            yield from self.response.stream()",
            "",
            "    class Urllib3Transport(httpx.BaseTransport):",
            "        def __init__(self):",
            "            self.pool = urllib3.PoolManager()",
            "",
            "        def handle_request(self, request: httpx.Request) -> httpx.Response:",
            "            url = str(request.url)",
            "            method = request.method",
            "            headers = dict(request.headers)",
            "            body = None if method in [\"GET\", \"HEAD\"] else request.read()",
            "",
            "            response = self.pool.request(",
            "                headers=headers,",
            "                method=method,",
            "                url=url,",
            "                body=body,",
            "                preload_content=False,  # Stream the content",
            "            )",
            "",
            "            return httpx.Response(",
            "                status_code=response.status,",
            "                headers=response.headers,",
            "                stream=Urllib3ResponseSyncByteStream(response),",
            "            )",
            "",
            "    sync_transport = Urllib3Transport()",
            "",
            "    class PyodideHttpResponseAsyncByteStream(httpx.AsyncByteStream):",
            "        def __init__(self, response) -> None:",
            "            self.response = response",
            "",
            "        async def __aiter__(self):",
            "            yield await self.response.bytes()",
            "",
            "    class PyodideHttpTransport(httpx.AsyncBaseTransport):",
            "        async def handle_async_request(",
            "            self,",
            "            request: httpx.Request,",
            "        ) -> httpx.Response:",
            "            url = str(request.url)",
            "            method = request.method",
            "            headers = dict(request.headers)",
            "            body = None if method in [\"GET\", \"HEAD\"] else await request.aread()",
            "            response = await pyodide.http.pyfetch(",
            "                url, method=method, headers=headers, body=body",
            "            )",
            "            return httpx.Response(",
            "                status_code=response.status,",
            "                headers=response.headers,",
            "                stream=PyodideHttpResponseAsyncByteStream(response),",
            "            )",
            "",
            "    async_transport = PyodideHttpTransport()",
            "else:",
            "    sync_transport = None",
            "    async_transport = None",
            "",
            "sync_client = httpx.Client(transport=sync_transport)",
            "async_client = httpx.AsyncClient(transport=async_transport)",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "if TYPE_CHECKING:",
            "    from gradio.blocks import Block",
            "",
            "#########################",
            "# GENERAL",
            "#########################",
            "",
            "",
            "def to_binary(x: str | dict) -> bytes:",
            "    \"\"\"Converts a base64 string or dictionary to a binary string that can be sent in a POST.\"\"\"",
            "    if isinstance(x, dict):",
            "        if x.get(\"data\"):",
            "            base64str = x[\"data\"]",
            "        else:",
            "            base64str = client_utils.encode_url_or_file_to_base64(x[\"path\"])",
            "    else:",
            "        base64str = x",
            "    return base64.b64decode(extract_base64_data(base64str))",
            "",
            "",
            "def extract_base64_data(x: str) -> str:",
            "    \"\"\"Just extracts the base64 data from a general base64 string.\"\"\"",
            "    return x.rsplit(\",\", 1)[-1]",
            "",
            "",
            "#########################",
            "# IMAGE PRE-PROCESSING",
            "#########################",
            "",
            "",
            "def encode_plot_to_base64(plt, format: str = \"png\"):",
            "    fmt = format or \"png\"",
            "    with BytesIO() as output_bytes:",
            "        plt.savefig(output_bytes, format=fmt)",
            "        bytes_data = output_bytes.getvalue()",
            "    base64_str = str(base64.b64encode(bytes_data), \"utf-8\")",
            "    return output_base64(base64_str, fmt)",
            "",
            "",
            "def get_pil_exif_bytes(pil_image):",
            "    if \"exif\" in pil_image.info:",
            "        return pil_image.info[\"exif\"]",
            "",
            "",
            "def get_pil_metadata(pil_image):",
            "    # Copy any text-only metadata",
            "    metadata = PngImagePlugin.PngInfo()",
            "    for key, value in pil_image.info.items():",
            "        if isinstance(key, str) and isinstance(value, str):",
            "            metadata.add_text(key, value)",
            "",
            "    return metadata",
            "",
            "",
            "def encode_pil_to_bytes(pil_image, format=\"png\"):",
            "    with BytesIO() as output_bytes:",
            "        if format == \"png\":",
            "            params = {\"pnginfo\": get_pil_metadata(pil_image)}",
            "        else:",
            "            exif = get_pil_exif_bytes(pil_image)",
            "            params = {\"exif\": exif} if exif else {}",
            "        pil_image.save(output_bytes, format, **params)",
            "        return output_bytes.getvalue()",
            "",
            "",
            "def encode_pil_to_base64(pil_image, format=\"png\"):",
            "    bytes_data = encode_pil_to_bytes(pil_image, format)",
            "    base64_str = str(base64.b64encode(bytes_data), \"utf-8\")",
            "    return output_base64(base64_str, format)",
            "",
            "",
            "def encode_array_to_base64(image_array, format=\"png\"):",
            "    with BytesIO() as output_bytes:",
            "        pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))",
            "        pil_image.save(output_bytes, format)",
            "        bytes_data = output_bytes.getvalue()",
            "    base64_str = str(base64.b64encode(bytes_data), \"utf-8\")",
            "    return output_base64(base64_str, format)",
            "",
            "",
            "def output_base64(data, format=None) -> str:",
            "    return f\"data:image/{format or 'png'};base64,{data}\"",
            "",
            "",
            "def hash_file(file_path: str | Path, chunk_num_blocks: int = 128) -> str:",
            "    sha1 = hashlib.sha1()",
            "    with open(file_path, \"rb\") as f:",
            "        for chunk in iter(lambda: f.read(chunk_num_blocks * sha1.block_size), b\"\"):",
            "            sha1.update(chunk)",
            "    return sha1.hexdigest()",
            "",
            "",
            "def hash_url(url: str) -> str:",
            "    sha1 = hashlib.sha1()",
            "    sha1.update(url.encode(\"utf-8\"))",
            "    return sha1.hexdigest()",
            "",
            "",
            "def hash_bytes(bytes: bytes):",
            "    sha1 = hashlib.sha1()",
            "    sha1.update(bytes)",
            "    return sha1.hexdigest()",
            "",
            "",
            "def hash_base64(base64_encoding: str, chunk_num_blocks: int = 128) -> str:",
            "    sha1 = hashlib.sha1()",
            "    for i in range(0, len(base64_encoding), chunk_num_blocks * sha1.block_size):",
            "        data = base64_encoding[i : i + chunk_num_blocks * sha1.block_size]",
            "        sha1.update(data.encode(\"utf-8\"))",
            "    return sha1.hexdigest()",
            "",
            "",
            "def save_pil_to_cache(",
            "    img: Image.Image,",
            "    cache_dir: str,",
            "    name: str = \"image\",",
            "    format: str = \"webp\",",
            ") -> str:",
            "    bytes_data = encode_pil_to_bytes(img, format)",
            "    temp_dir = Path(cache_dir) / hash_bytes(bytes_data)",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    filename = str((temp_dir / f\"{name}.{format}\").resolve())",
            "    (temp_dir / f\"{name}.{format}\").resolve().write_bytes(bytes_data)",
            "    return filename",
            "",
            "",
            "def save_img_array_to_cache(",
            "    arr: np.ndarray, cache_dir: str, format: str = \"webp\"",
            ") -> str:",
            "    pil_image = Image.fromarray(_convert(arr, np.uint8, force_copy=False))",
            "    return save_pil_to_cache(pil_image, cache_dir, format=format)",
            "",
            "",
            "def save_audio_to_cache(",
            "    data: np.ndarray, sample_rate: int, format: str, cache_dir: str",
            ") -> str:",
            "    temp_dir = Path(cache_dir) / hash_bytes(data.tobytes())",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    filename = str((temp_dir / f\"audio.{format}\").resolve())",
            "    audio_to_file(sample_rate, data, filename, format=format)",
            "    return filename",
            "",
            "",
            "def save_bytes_to_cache(data: bytes, file_name: str, cache_dir: str) -> str:",
            "    path = Path(cache_dir) / hash_bytes(data)",
            "    path.mkdir(exist_ok=True, parents=True)",
            "    path = path / Path(file_name).name",
            "    path.write_bytes(data)",
            "    return str(path.resolve())",
            "",
            "",
            "def save_file_to_cache(file_path: str | Path, cache_dir: str) -> str:",
            "    \"\"\"Returns a temporary file path for a copy of the given file path if it does",
            "    not already exist. Otherwise returns the path to the existing temp file.\"\"\"",
            "    temp_dir = hash_file(file_path)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "",
            "    name = client_utils.strip_invalid_filename_characters(Path(file_path).name)",
            "    full_temp_file_path = str(abspath(temp_dir / name))",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        shutil.copy2(file_path, full_temp_file_path)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "def save_url_to_cache(url: str, cache_dir: str) -> str:",
            "    \"\"\"Downloads a file and makes a temporary file path for a copy if does not already",
            "    exist. Otherwise returns the path to the existing temp file.\"\"\"",
            "    temp_dir = hash_url(url)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    name = client_utils.strip_invalid_filename_characters(Path(url).name)",
            "    full_temp_file_path = str(abspath(temp_dir / name))",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        with sync_client.stream(\"GET\", url, follow_redirects=True) as r, open(",
            "            full_temp_file_path, \"wb\"",
            "        ) as f:",
            "            for chunk in r.iter_raw():",
            "                f.write(chunk)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "async def async_save_url_to_cache(url: str, cache_dir: str) -> str:",
            "    \"\"\"Downloads a file and makes a temporary file path for a copy if does not already",
            "    exist. Otherwise returns the path to the existing temp file. Uses async httpx.\"\"\"",
            "    temp_dir = hash_url(url)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "    name = client_utils.strip_invalid_filename_characters(Path(url).name)",
            "    full_temp_file_path = str(abspath(temp_dir / name))",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        async with async_client.stream(\"GET\", url, follow_redirects=True) as response:",
            "            async with aiofiles.open(full_temp_file_path, \"wb\") as f:",
            "                async for chunk in response.aiter_raw():",
            "                    await f.write(chunk)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "def save_base64_to_cache(",
            "    base64_encoding: str, cache_dir: str, file_name: str | None = None",
            ") -> str:",
            "    \"\"\"Converts a base64 encoding to a file and returns the path to the file if",
            "    the file doesn't already exist. Otherwise returns the path to the existing file.",
            "    \"\"\"",
            "    temp_dir = hash_base64(base64_encoding)",
            "    temp_dir = Path(cache_dir) / temp_dir",
            "    temp_dir.mkdir(exist_ok=True, parents=True)",
            "",
            "    guess_extension = client_utils.get_extension(base64_encoding)",
            "    if file_name:",
            "        file_name = client_utils.strip_invalid_filename_characters(file_name)",
            "    elif guess_extension:",
            "        file_name = f\"file.{guess_extension}\"",
            "    else:",
            "        file_name = \"file\"",
            "",
            "    full_temp_file_path = str(abspath(temp_dir / file_name))  # type: ignore",
            "",
            "    if not Path(full_temp_file_path).exists():",
            "        data, _ = client_utils.decode_base64_to_binary(base64_encoding)",
            "        with open(full_temp_file_path, \"wb\") as fb:",
            "            fb.write(data)",
            "",
            "    return full_temp_file_path",
            "",
            "",
            "def move_resource_to_block_cache(",
            "    url_or_file_path: str | Path | None, block: Block",
            ") -> str | None:",
            "    \"\"\"This method has been replaced by Block.move_resource_to_block_cache(), but is",
            "    left here for backwards compatibility for any custom components created in Gradio 4.2.0 or earlier.",
            "    \"\"\"",
            "    return block.move_resource_to_block_cache(url_or_file_path)",
            "",
            "",
            "def check_all_files_in_cache(data: JsonData):",
            "    def _in_cache(d: dict):",
            "        if (",
            "            (path := d.get(\"path\", \"\"))",
            "            and not client_utils.is_http_url_like(path)",
            "            and not is_in_or_equal(path, get_upload_folder())",
            "        ):",
            "            raise Error(",
            "                f\"File {path} is not in the cache folder and cannot be accessed.\"",
            "            )",
            "",
            "    client_utils.traverse(data, _in_cache, client_utils.is_file_obj)",
            "",
            "",
            "def move_files_to_cache(",
            "    data: Any,",
            "    block: Block,",
            "    postprocess: bool = False,",
            "    check_in_upload_folder=False,",
            "    keep_in_cache=False,",
            "):",
            "    \"\"\"Move any files in `data` to cache and (optionally), adds URL prefixes (/file=...) needed to access the cached file.",
            "    Also handles the case where the file is on an external Gradio app (/proxy=...).",
            "",
            "    Runs after .postprocess() and before .preprocess().",
            "",
            "    Args:",
            "        data: The input or output data for a component. Can be a dictionary or a dataclass",
            "        block: The component whose data is being processed",
            "        postprocess: Whether its running from postprocessing",
            "        check_in_upload_folder: If True, instead of moving the file to cache, checks if the file is in already in cache (exception if not).",
            "        keep_in_cache: If True, the file will not be deleted from cache when the server is shut down.",
            "    \"\"\"",
            "",
            "    def _move_to_cache(d: dict):",
            "        payload = FileData(**d)",
            "        # If the gradio app developer is returning a URL from",
            "        # postprocess, it means the component can display a URL",
            "        # without it being served from the gradio server",
            "        # This makes it so that the URL is not downloaded and speeds up event processing",
            "        if payload.url and postprocess and client_utils.is_http_url_like(payload.url):",
            "            payload.path = payload.url",
            "        elif utils.is_static_file(payload):",
            "            pass",
            "        elif not block.proxy_url:",
            "            # If the file is on a remote server, do not move it to cache.",
            "            if check_in_upload_folder and not client_utils.is_http_url_like(",
            "                payload.path",
            "            ):",
            "                path = os.path.abspath(payload.path)",
            "                if not is_in_or_equal(path, get_upload_folder()):",
            "                    raise ValueError(",
            "                        f\"File {path} is not in the upload folder and cannot be accessed.\"",
            "                    )",
            "            if not payload.is_stream:",
            "                temp_file_path = block.move_resource_to_block_cache(payload.path)",
            "                if temp_file_path is None:",
            "                    raise ValueError(\"Did not determine a file path for the resource.\")",
            "                payload.path = temp_file_path",
            "                if keep_in_cache:",
            "                    block.keep_in_cache.add(payload.path)",
            "",
            "        url_prefix = \"/stream/\" if payload.is_stream else \"/file=\"",
            "        if block.proxy_url:",
            "            proxy_url = block.proxy_url.rstrip(\"/\")",
            "            url = f\"/proxy={proxy_url}{url_prefix}{payload.path}\"",
            "        elif client_utils.is_http_url_like(payload.path) or payload.path.startswith(",
            "            f\"{url_prefix}\"",
            "        ):",
            "            url = payload.path",
            "        else:",
            "            url = f\"{url_prefix}{payload.path}\"",
            "        payload.url = url",
            "",
            "        return payload.model_dump()",
            "",
            "    if isinstance(data, (GradioRootModel, GradioModel)):",
            "        data = data.model_dump()",
            "",
            "    return client_utils.traverse(data, _move_to_cache, client_utils.is_file_obj)",
            "",
            "",
            "async def async_move_files_to_cache(",
            "    data: Any,",
            "    block: Block,",
            "    postprocess: bool = False,",
            "    check_in_upload_folder=False,",
            "    keep_in_cache=False,",
            ") -> dict:",
            "    \"\"\"Move any files in `data` to cache and (optionally), adds URL prefixes (/file=...) needed to access the cached file.",
            "    Also handles the case where the file is on an external Gradio app (/proxy=...).",
            "",
            "    Runs after .postprocess() and before .preprocess().",
            "",
            "    Args:",
            "        data: The input or output data for a component. Can be a dictionary or a dataclass",
            "        block: The component whose data is being processed",
            "        postprocess: Whether its running from postprocessing",
            "        check_in_upload_folder: If True, instead of moving the file to cache, checks if the file is in already in cache (exception if not).",
            "        keep_in_cache: If True, the file will not be deleted from cache when the server is shut down.",
            "    \"\"\"",
            "",
            "    async def _move_to_cache(d: dict):",
            "        payload = FileData(**d)",
            "        # If the gradio app developer is returning a URL from",
            "        # postprocess, it means the component can display a URL",
            "        # without it being served from the gradio server",
            "        # This makes it so that the URL is not downloaded and speeds up event processing",
            "        if payload.url and postprocess and client_utils.is_http_url_like(payload.url):",
            "            payload.path = payload.url",
            "        elif utils.is_static_file(payload):",
            "            pass",
            "        elif not block.proxy_url:",
            "            # If the file is on a remote server, do not move it to cache.",
            "            if check_in_upload_folder and not client_utils.is_http_url_like(",
            "                payload.path",
            "            ):",
            "                path = os.path.abspath(payload.path)",
            "                if not is_in_or_equal(path, get_upload_folder()):",
            "                    raise ValueError(",
            "                        f\"File {path} is not in the upload folder and cannot be accessed.\"",
            "                    )",
            "            if not payload.is_stream:",
            "                temp_file_path = await block.async_move_resource_to_block_cache(",
            "                    payload.path",
            "                )",
            "                if temp_file_path is None:",
            "                    raise ValueError(\"Did not determine a file path for the resource.\")",
            "                payload.path = temp_file_path",
            "                if keep_in_cache:",
            "                    block.keep_in_cache.add(payload.path)",
            "",
            "        url_prefix = \"/stream/\" if payload.is_stream else \"/file=\"",
            "        if block.proxy_url:",
            "            proxy_url = block.proxy_url.rstrip(\"/\")",
            "            url = f\"/proxy={proxy_url}{url_prefix}{payload.path}\"",
            "        elif client_utils.is_http_url_like(payload.path) or payload.path.startswith(",
            "            f\"{url_prefix}\"",
            "        ):",
            "            url = payload.path",
            "        else:",
            "            url = f\"{url_prefix}{payload.path}\"",
            "        payload.url = url",
            "",
            "        return payload.model_dump()",
            "",
            "    if isinstance(data, (GradioRootModel, GradioModel)):",
            "        data = data.model_dump()",
            "    return await client_utils.async_traverse(",
            "        data, _move_to_cache, client_utils.is_file_obj",
            "    )",
            "",
            "",
            "def add_root_url(data: dict | list, root_url: str, previous_root_url: str | None):",
            "    def _add_root_url(file_dict: dict):",
            "        if previous_root_url and file_dict[\"url\"].startswith(previous_root_url):",
            "            file_dict[\"url\"] = file_dict[\"url\"][len(previous_root_url) :]",
            "        elif client_utils.is_http_url_like(file_dict[\"url\"]):",
            "            return file_dict",
            "        file_dict[\"url\"] = f'{root_url}{file_dict[\"url\"]}'",
            "        return file_dict",
            "",
            "    return client_utils.traverse(data, _add_root_url, client_utils.is_file_obj_with_url)",
            "",
            "",
            "def resize_and_crop(img, size, crop_type=\"center\"):",
            "    \"\"\"",
            "    Resize and crop an image to fit the specified size.",
            "    args:",
            "        size: `(width, height)` tuple. Pass `None` for either width or height",
            "        to only crop and resize the other.",
            "        crop_type: can be 'top', 'middle' or 'bottom', depending on this",
            "            value, the image will cropped getting the 'top/left', 'middle' or",
            "            'bottom/right' of the image to fit the size.",
            "    raises:",
            "        ValueError: if an invalid `crop_type` is provided.",
            "    \"\"\"",
            "    if crop_type == \"top\":",
            "        center = (0, 0)",
            "    elif crop_type == \"center\":",
            "        center = (0.5, 0.5)",
            "    else:",
            "        raise ValueError",
            "",
            "    resize = list(size)",
            "    if size[0] is None:",
            "        resize[0] = img.size[0]",
            "    if size[1] is None:",
            "        resize[1] = img.size[1]",
            "    return ImageOps.fit(img, resize, centering=center)  # type: ignore",
            "",
            "",
            "##################",
            "# Audio",
            "##################",
            "",
            "",
            "def audio_from_file(filename, crop_min=0, crop_max=100):",
            "    try:",
            "        audio = AudioSegment.from_file(filename)",
            "    except FileNotFoundError as e:",
            "        isfile = Path(filename).is_file()",
            "        msg = (",
            "            f\"Cannot load audio from file: `{'ffprobe' if isfile else filename}` not found.\"",
            "            + \" Please install `ffmpeg` in your system to use non-WAV audio file formats\"",
            "            \" and make sure `ffprobe` is in your PATH.\"",
            "            if isfile",
            "            else \"\"",
            "        )",
            "        raise RuntimeError(msg) from e",
            "    if crop_min != 0 or crop_max != 100:",
            "        audio_start = len(audio) * crop_min / 100",
            "        audio_end = len(audio) * crop_max / 100",
            "        audio = audio[audio_start:audio_end]",
            "    data = np.array(audio.get_array_of_samples())",
            "    if audio.channels > 1:",
            "        data = data.reshape(-1, audio.channels)",
            "    return audio.frame_rate, data",
            "",
            "",
            "def audio_to_file(sample_rate, data, filename, format=\"wav\"):",
            "    if format == \"wav\":",
            "        data = convert_to_16_bit_wav(data)",
            "    audio = AudioSegment(",
            "        data.tobytes(),",
            "        frame_rate=sample_rate,",
            "        sample_width=data.dtype.itemsize,",
            "        channels=(1 if len(data.shape) == 1 else data.shape[1]),",
            "    )",
            "    file = audio.export(filename, format=format)",
            "    file.close()  # type: ignore",
            "",
            "",
            "def convert_to_16_bit_wav(data):",
            "    # Based on: https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html",
            "    warning = \"Trying to convert audio automatically from {} to 16-bit int format.\"",
            "    if data.dtype in [np.float64, np.float32, np.float16]:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data / np.abs(data).max()",
            "        data = data * 32767",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.int32:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data / 65536",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.int16:",
            "        pass",
            "    elif data.dtype == np.uint16:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data - 32768",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.uint8:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data * 257 - 32768",
            "        data = data.astype(np.int16)",
            "    elif data.dtype == np.int8:",
            "        warnings.warn(warning.format(data.dtype))",
            "        data = data * 256",
            "        data = data.astype(np.int16)",
            "    else:",
            "        raise ValueError(",
            "            \"Audio data cannot be converted automatically from \"",
            "            f\"{data.dtype} to 16-bit int format.\"",
            "        )",
            "    return data",
            "",
            "",
            "##################",
            "# OUTPUT",
            "##################",
            "",
            "",
            "def _convert(image, dtype, force_copy=False, uniform=False):",
            "    \"\"\"",
            "    Adapted from: https://github.com/scikit-image/scikit-image/blob/main/skimage/util/dtype.py#L510-L531",
            "",
            "    Convert an image to the requested data-type.",
            "    Warnings are issued in case of precision loss, or when negative values",
            "    are clipped during conversion to unsigned integer types (sign loss).",
            "    Floating point values are expected to be normalized and will be clipped",
            "    to the range [0.0, 1.0] or [-1.0, 1.0] when converting to unsigned or",
            "    signed integers respectively.",
            "    Numbers are not shifted to the negative side when converting from",
            "    unsigned to signed integer types. Negative values will be clipped when",
            "    converting to unsigned integers.",
            "    Parameters",
            "    ----------",
            "    image : ndarray",
            "        Input image.",
            "    dtype : dtype",
            "        Target data-type.",
            "    force_copy : bool, optional",
            "        Force a copy of the data, irrespective of its current dtype.",
            "    uniform : bool, optional",
            "        Uniformly quantize the floating point range to the integer range.",
            "        By default (uniform=False) floating point values are scaled and",
            "        rounded to the nearest integers, which minimizes back and forth",
            "        conversion errors.",
            "    .. versionchanged :: 0.15",
            "        ``_convert`` no longer warns about possible precision or sign",
            "        information loss. See discussions on these warnings at:",
            "        https://github.com/scikit-image/scikit-image/issues/2602",
            "        https://github.com/scikit-image/scikit-image/issues/543#issuecomment-208202228",
            "        https://github.com/scikit-image/scikit-image/pull/3575",
            "    References",
            "    ----------",
            "    .. [1] DirectX data conversion rules.",
            "           https://msdn.microsoft.com/en-us/library/windows/desktop/dd607323%28v=vs.85%29.aspx",
            "    .. [2] Data Conversions. In \"OpenGL ES 2.0 Specification v2.0.25\",",
            "           pp 7-8. Khronos Group, 2010.",
            "    .. [3] Proper treatment of pixels as integers. A.W. Paeth.",
            "           In \"Graphics Gems I\", pp 249-256. Morgan Kaufmann, 1990.",
            "    .. [4] Dirty Pixels. J. Blinn. In \"Jim Blinn's corner: Dirty Pixels\",",
            "           pp 47-57. Morgan Kaufmann, 1998.",
            "    \"\"\"",
            "    dtype_range = {",
            "        bool: (False, True),",
            "        np.bool_: (False, True),",
            "        np.bool8: (False, True),  # type: ignore",
            "        float: (-1, 1),",
            "        np.float_: (-1, 1),",
            "        np.float16: (-1, 1),",
            "        np.float32: (-1, 1),",
            "        np.float64: (-1, 1),",
            "    }",
            "",
            "    def _dtype_itemsize(itemsize, *dtypes):",
            "        \"\"\"Return first of `dtypes` with itemsize greater than `itemsize`",
            "        Parameters",
            "        ----------",
            "        itemsize: int",
            "            The data type object element size.",
            "        Other Parameters",
            "        ----------------",
            "        *dtypes:",
            "            Any Object accepted by `np.dtype` to be converted to a data",
            "            type object",
            "        Returns",
            "        -------",
            "        dtype: data type object",
            "            First of `dtypes` with itemsize greater than `itemsize`.",
            "        \"\"\"",
            "        return next(dt for dt in dtypes if np.dtype(dt).itemsize >= itemsize)",
            "",
            "    def _dtype_bits(kind, bits, itemsize=1):",
            "        \"\"\"Return dtype of `kind` that can store a `bits` wide unsigned int",
            "        Parameters:",
            "        kind: str",
            "            Data type kind.",
            "        bits: int",
            "            Desired number of bits.",
            "        itemsize: int",
            "            The data type object element size.",
            "        Returns",
            "        -------",
            "        dtype: data type object",
            "            Data type of `kind` that can store a `bits` wide unsigned int",
            "        \"\"\"",
            "",
            "        s = next(",
            "            i",
            "            for i in (itemsize,) + (2, 4, 8)",
            "            if bits < (i * 8) or (bits == (i * 8) and kind == \"u\")",
            "        )",
            "",
            "        return np.dtype(kind + str(s))",
            "",
            "    def _scale(a, n, m, copy=True):",
            "        \"\"\"Scale an array of unsigned/positive integers from `n` to `m` bits.",
            "        Numbers can be represented exactly only if `m` is a multiple of `n`.",
            "        Parameters",
            "        ----------",
            "        a : ndarray",
            "            Input image array.",
            "        n : int",
            "            Number of bits currently used to encode the values in `a`.",
            "        m : int",
            "            Desired number of bits to encode the values in `out`.",
            "        copy : bool, optional",
            "            If True, allocates and returns new array. Otherwise, modifies",
            "            `a` in place.",
            "        Returns",
            "        -------",
            "        out : array",
            "            Output image array. Has the same kind as `a`.",
            "        \"\"\"",
            "        kind = a.dtype.kind",
            "        if n > m and a.max() < 2**m:",
            "            return a.astype(_dtype_bits(kind, m))",
            "        elif n == m:",
            "            return a.copy() if copy else a",
            "        elif n > m:",
            "            # downscale with precision loss",
            "            if copy:",
            "                b = np.empty(a.shape, _dtype_bits(kind, m))",
            "                np.floor_divide(a, 2 ** (n - m), out=b, dtype=a.dtype, casting=\"unsafe\")",
            "                return b",
            "            else:",
            "                a //= 2 ** (n - m)",
            "                return a",
            "        elif m % n == 0:",
            "            # exact upscale to a multiple of `n` bits",
            "            if copy:",
            "                b = np.empty(a.shape, _dtype_bits(kind, m))",
            "                np.multiply(a, (2**m - 1) // (2**n - 1), out=b, dtype=b.dtype)",
            "                return b",
            "            else:",
            "                a = a.astype(_dtype_bits(kind, m, a.dtype.itemsize), copy=False)",
            "                a *= (2**m - 1) // (2**n - 1)",
            "                return a",
            "        else:",
            "            # upscale to a multiple of `n` bits,",
            "            # then downscale with precision loss",
            "            o = (m // n + 1) * n",
            "            if copy:",
            "                b = np.empty(a.shape, _dtype_bits(kind, o))",
            "                np.multiply(a, (2**o - 1) // (2**n - 1), out=b, dtype=b.dtype)",
            "                b //= 2 ** (o - m)",
            "                return b",
            "            else:",
            "                a = a.astype(_dtype_bits(kind, o, a.dtype.itemsize), copy=False)",
            "                a *= (2**o - 1) // (2**n - 1)",
            "                a //= 2 ** (o - m)",
            "                return a",
            "",
            "    image = np.asarray(image)",
            "    dtypeobj_in = image.dtype",
            "    dtypeobj_out = np.dtype(\"float64\") if dtype is np.floating else np.dtype(dtype)",
            "    dtype_in = dtypeobj_in.type",
            "    dtype_out = dtypeobj_out.type",
            "    kind_in = dtypeobj_in.kind",
            "    kind_out = dtypeobj_out.kind",
            "    itemsize_in = dtypeobj_in.itemsize",
            "    itemsize_out = dtypeobj_out.itemsize",
            "",
            "    # Below, we do an `issubdtype` check.  Its purpose is to find out",
            "    # whether we can get away without doing any image conversion.  This happens",
            "    # when:",
            "    #",
            "    # - the output and input dtypes are the same or",
            "    # - when the output is specified as a type, and the input dtype",
            "    #   is a subclass of that type (e.g. `np.floating` will allow",
            "    #   `float32` and `float64` arrays through)",
            "",
            "    if np.issubdtype(dtype_in, np.obj2sctype(dtype)):",
            "        if force_copy:",
            "            image = image.copy()",
            "        return image",
            "",
            "    if kind_in in \"ui\":",
            "        imin_in = np.iinfo(dtype_in).min",
            "        imax_in = np.iinfo(dtype_in).max",
            "    if kind_out in \"ui\":",
            "        imin_out = np.iinfo(dtype_out).min  # type: ignore",
            "        imax_out = np.iinfo(dtype_out).max  # type: ignore",
            "",
            "    # any -> binary",
            "    if kind_out == \"b\":",
            "        return image > dtype_in(dtype_range[dtype_in][1] / 2)",
            "",
            "    # binary -> any",
            "    if kind_in == \"b\":",
            "        result = image.astype(dtype_out)",
            "        if kind_out != \"f\":",
            "            result *= dtype_out(dtype_range[dtype_out][1])",
            "        return result",
            "",
            "    # float -> any",
            "    if kind_in == \"f\":",
            "        if kind_out == \"f\":",
            "            # float -> float",
            "            return image.astype(dtype_out)",
            "",
            "        if np.min(image) < -1.0 or np.max(image) > 1.0:",
            "            raise ValueError(\"Images of type float must be between -1 and 1.\")",
            "        # floating point -> integer",
            "        # use float type that can represent output integer type",
            "        computation_type = _dtype_itemsize(",
            "            itemsize_out, dtype_in, np.float32, np.float64",
            "        )",
            "",
            "        if not uniform:",
            "            if kind_out == \"u\":",
            "                image_out = np.multiply(image, imax_out, dtype=computation_type)  # type: ignore",
            "            else:",
            "                image_out = np.multiply(",
            "                    image,",
            "                    (imax_out - imin_out) / 2,  # type: ignore",
            "                    dtype=computation_type,",
            "                )",
            "                image_out -= 1.0 / 2.0",
            "            np.rint(image_out, out=image_out)",
            "            np.clip(image_out, imin_out, imax_out, out=image_out)  # type: ignore",
            "        elif kind_out == \"u\":",
            "            image_out = np.multiply(image, imax_out + 1, dtype=computation_type)  # type: ignore",
            "            np.clip(image_out, 0, imax_out, out=image_out)  # type: ignore",
            "        else:",
            "            image_out = np.multiply(",
            "                image,",
            "                (imax_out - imin_out + 1.0) / 2.0,  # type: ignore",
            "                dtype=computation_type,",
            "            )",
            "            np.floor(image_out, out=image_out)",
            "            np.clip(image_out, imin_out, imax_out, out=image_out)  # type: ignore",
            "        return image_out.astype(dtype_out)",
            "",
            "    # signed/unsigned int -> float",
            "    if kind_out == \"f\":",
            "        # use float type that can exactly represent input integers",
            "        computation_type = _dtype_itemsize(",
            "            itemsize_in, dtype_out, np.float32, np.float64",
            "        )",
            "",
            "        if kind_in == \"u\":",
            "            # using np.divide or np.multiply doesn't copy the data",
            "            # until the computation time",
            "            image = np.multiply(image, 1.0 / imax_in, dtype=computation_type)  # type: ignore",
            "            # DirectX uses this conversion also for signed ints",
            "            # if imin_in:",
            "            #     np.maximum(image, -1.0, out=image)",
            "        else:",
            "            image = np.add(image, 0.5, dtype=computation_type)",
            "            image *= 2 / (imax_in - imin_in)  # type: ignore",
            "",
            "        return np.asarray(image, dtype_out)",
            "",
            "    # unsigned int -> signed/unsigned int",
            "    if kind_in == \"u\":",
            "        if kind_out == \"i\":",
            "            # unsigned int -> signed int",
            "            image = _scale(image, 8 * itemsize_in, 8 * itemsize_out - 1)",
            "            return image.view(dtype_out)",
            "        else:",
            "            # unsigned int -> unsigned int",
            "            return _scale(image, 8 * itemsize_in, 8 * itemsize_out)",
            "",
            "    # signed int -> unsigned int",
            "    if kind_out == \"u\":",
            "        image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)",
            "        result = np.empty(image.shape, dtype_out)",
            "        np.maximum(image, 0, out=result, dtype=image.dtype, casting=\"unsafe\")",
            "        return result",
            "",
            "    # signed int -> signed int",
            "    if itemsize_in > itemsize_out:",
            "        return _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out - 1)",
            "",
            "    image = image.astype(_dtype_bits(\"i\", itemsize_out * 8))",
            "    image -= imin_in  # type: ignore",
            "    image = _scale(image, 8 * itemsize_in, 8 * itemsize_out, copy=False)",
            "    image += imin_out  # type: ignore",
            "    return image.astype(dtype_out)",
            "",
            "",
            "def ffmpeg_installed() -> bool:",
            "    if wasm_utils.IS_WASM:",
            "        # TODO: Support ffmpeg in WASM",
            "        return False",
            "",
            "    return shutil.which(\"ffmpeg\") is not None",
            "",
            "",
            "def video_is_playable(video_filepath: str) -> bool:",
            "    \"\"\"Determines if a video is playable in the browser.",
            "",
            "    A video is playable if it has a playable container and codec.",
            "        .mp4 -> h264",
            "        .webm -> vp9",
            "        .ogg -> theora",
            "    \"\"\"",
            "    from ffmpy import FFprobe, FFRuntimeError",
            "",
            "    try:",
            "        container = Path(video_filepath).suffix.lower()",
            "        probe = FFprobe(",
            "            global_options=\"-show_format -show_streams -select_streams v -print_format json\",",
            "            inputs={video_filepath: None},",
            "        )",
            "        output = probe.run(stderr=subprocess.PIPE, stdout=subprocess.PIPE)",
            "        output = json.loads(output[0])",
            "        video_codec = output[\"streams\"][0][\"codec_name\"]",
            "        return (container, video_codec) in [",
            "            (\".mp4\", \"h264\"),",
            "            (\".ogg\", \"theora\"),",
            "            (\".webm\", \"vp9\"),",
            "        ]",
            "    # If anything goes wrong, assume the video can be played to not convert downstream",
            "    except (FFRuntimeError, IndexError, KeyError):",
            "        return True",
            "",
            "",
            "def convert_video_to_playable_mp4(video_path: str) -> str:",
            "    \"\"\"Convert the video to mp4. If something goes wrong return the original video.\"\"\"",
            "    from ffmpy import FFmpeg, FFRuntimeError",
            "",
            "    try:",
            "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:",
            "            output_path = Path(video_path).with_suffix(\".mp4\")",
            "            shutil.copy2(video_path, tmp_file.name)",
            "            # ffmpeg will automatically use h264 codec (playable in browser) when converting to mp4",
            "            ff = FFmpeg(",
            "                inputs={str(tmp_file.name): None},",
            "                outputs={str(output_path): None},",
            "                global_options=\"-y -loglevel quiet\",",
            "            )",
            "            ff.run()",
            "    except FFRuntimeError as e:",
            "        print(f\"Error converting video to browser-playable format {str(e)}\")",
            "        output_path = video_path",
            "    finally:",
            "        # Remove temp file",
            "        os.remove(tmp_file.name)  # type: ignore",
            "    return str(output_path)",
            "",
            "",
            "def get_video_length(video_path: str | Path):",
            "    if wasm_utils.IS_WASM:",
            "        raise wasm_utils.WasmUnsupportedError(",
            "            \"Video duration is not supported in the Wasm mode.\"",
            "        )",
            "    duration = subprocess.check_output(",
            "        [",
            "            \"ffprobe\",",
            "            \"-i\",",
            "            str(video_path),",
            "            \"-show_entries\",",
            "            \"format=duration\",",
            "            \"-v\",",
            "            \"quiet\",",
            "            \"-of\",",
            "            \"csv={}\".format(\"p=0\"),",
            "        ]",
            "    )",
            "    duration_str = duration.decode(\"utf-8\").strip()",
            "    duration_float = float(duration_str)",
            "",
            "    return duration_float"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "23": [],
            "478": []
        },
        "addLocation": []
    }
}