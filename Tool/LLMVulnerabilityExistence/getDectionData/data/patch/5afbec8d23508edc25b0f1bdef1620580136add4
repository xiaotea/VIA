{
    "src/octoprint/plugins/appkeys/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": 356,
                "PatchRowcode": "                 # deprecated key based revoke?"
            },
            "1": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": 357,
                "PatchRowcode": "                 from flask import request"
            },
            "2": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": 358,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 359,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                from octoprint.server.util import get_remote_address"
            },
            "4": {
                "beforePatchRowNumber": 360,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "5": {
                "beforePatchRowNumber": 361,
                "afterPatchRowNumber": 359,
                "PatchRowcode": "                 self._logger.warning("
            },
            "6": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    \"Deprecated key based revoke command sent to /api/plugin/appkeys by {}, should be migrated to use app id/user tuple\".format("
            },
            "7": {
                "beforePatchRowNumber": 363,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        get_remote_address(request)"
            },
            "8": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    )"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+                    f\"Deprecated key based revoke command sent to /api/plugin/appkeys by {request.remote_addr}, should be migrated to use app id/user tuple\""
            },
            "10": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 361,
                "PatchRowcode": "                 )"
            },
            "11": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": 362,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 363,
                "PatchRowcode": "             else:"
            }
        },
        "frontPatchFile": [
            "import os",
            "import threading",
            "import time",
            "from collections import defaultdict",
            "",
            "import flask",
            "from flask_babel import gettext",
            "",
            "import octoprint.plugin",
            "from octoprint.access import ADMIN_GROUP, USER_GROUP",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.server import NO_CONTENT, current_user",
            "from octoprint.server.util import require_fresh_login_with",
            "from octoprint.server.util.flask import (",
            "    add_non_caching_response_headers,",
            "    credentials_checked_recently,",
            "    ensure_credentials_checked_recently,",
            "    no_firstrun_access,",
            "    restricted_access,",
            ")",
            "from octoprint.settings import valid_boolean_trues",
            "from octoprint.util import ResettableTimer, atomic_write, generate_api_key, yaml",
            "",
            "CUTOFF_TIME = 10 * 60  # 10min",
            "POLL_TIMEOUT = 5  # 5 seconds",
            "",
            "",
            "class AppAlreadyExists(Exception):",
            "    pass",
            "",
            "",
            "class PendingDecision:",
            "    def __init__(self, app_id, app_token, user_id, user_token, timeout_callback=None):",
            "        self.app_id = app_id",
            "        self.app_token = app_token",
            "        self.user_id = user_id",
            "        self.user_token = user_token",
            "        self.created = time.monotonic()",
            "",
            "        if callable(timeout_callback):",
            "            self.poll_timeout = ResettableTimer(",
            "                POLL_TIMEOUT, timeout_callback, [user_token]",
            "            )",
            "            self.poll_timeout.start()",
            "",
            "    def external(self):",
            "        return {",
            "            \"app_id\": self.app_id,",
            "            \"user_id\": self.user_id,",
            "            \"user_token\": self.user_token,",
            "        }",
            "",
            "    def __repr__(self):",
            "        return \"PendingDecision({!r}, {!r}, {!r}, {!r}, timeout_callback=...)\".format(",
            "            self.app_id, self.app_token, self.user_id, self.user_token",
            "        )",
            "",
            "",
            "class ReadyDecision:",
            "    def __init__(self, app_id, app_token, user_id):",
            "        self.app_id = app_id",
            "        self.app_token = app_token",
            "        self.user_id = user_id",
            "",
            "    @classmethod",
            "    def for_pending(cls, pending, user_id):",
            "        return cls(pending.app_id, pending.app_token, user_id)",
            "",
            "    def __repr__(self):",
            "        return \"ReadyDecision({!r}, {!r}, {!r})\".format(",
            "            self.app_id, self.app_token, self.user_id",
            "        )",
            "",
            "",
            "class ActiveKey:",
            "    def __init__(self, app_id, api_key, user_id):",
            "        self.app_id = app_id",
            "        self.api_key = api_key",
            "        self.user_id = user_id",
            "",
            "    def external(self, incl_key=False):",
            "        result = {\"app_id\": self.app_id, \"user_id\": self.user_id}",
            "        if incl_key:",
            "            result[\"api_key\"] = self.api_key",
            "        return result",
            "",
            "    def internal(self):",
            "        return {\"app_id\": self.app_id, \"api_key\": self.api_key}",
            "",
            "    @classmethod",
            "    def for_internal(cls, internal, user_id):",
            "        return cls(internal[\"app_id\"], internal[\"api_key\"], user_id)",
            "",
            "    def __repr__(self):",
            "        return \"ActiveKey({!r}, {!r}, {!r})\".format(",
            "            self.app_id, self.api_key, self.user_id",
            "        )",
            "",
            "",
            "class AppKeysPlugin(",
            "    octoprint.plugin.AssetPlugin,",
            "    octoprint.plugin.BlueprintPlugin,",
            "    octoprint.plugin.SimpleApiPlugin,",
            "    octoprint.plugin.TemplatePlugin,",
            "):",
            "    def __init__(self):",
            "        self._pending_decisions = []",
            "        self._pending_lock = threading.RLock()",
            "",
            "        self._ready_decisions = []",
            "        self._ready_lock = threading.RLock()",
            "",
            "        self._keys = defaultdict(list)",
            "        self._keys_lock = threading.RLock()",
            "",
            "        self._key_path = None",
            "",
            "    def initialize(self):",
            "        self._key_path = os.path.join(self.get_plugin_data_folder(), \"keys.yaml\")",
            "        self._load_keys()",
            "",
            "    # Additional permissions hook",
            "",
            "    def get_additional_permissions(self):",
            "        return [",
            "            {",
            "                \"key\": \"ADMIN\",",
            "                \"name\": \"Admin access\",",
            "                \"description\": gettext(\"Allows administrating all application keys\"),",
            "                \"roles\": [\"admin\"],",
            "                \"dangerous\": True,",
            "                \"default_groups\": [ADMIN_GROUP],",
            "            },",
            "            {",
            "                \"key\": \"GRANT\",",
            "                \"name\": \"Grant access\",",
            "                \"description\": gettext(\"Allows to grant app access\"),",
            "                \"roles\": [\"user\"],",
            "                \"default_groups\": [USER_GROUP],",
            "            },",
            "        ]",
            "",
            "    ##~~ TemplatePlugin",
            "",
            "    def get_template_configs(self):",
            "        return [",
            "            {\"type\": \"usersettings\", \"name\": gettext(\"Application Keys\")},",
            "            {\"type\": \"settings\", \"name\": gettext(\"Application Keys\")},",
            "        ]",
            "",
            "    ##~~ AssetPlugin",
            "",
            "    def get_assets(self):",
            "        return {",
            "            \"js\": [\"js/appkeys.js\"],",
            "            \"clientjs\": [\"clientjs/appkeys.js\"],",
            "            \"less\": [\"less/appkeys.less\"],",
            "            \"css\": [\"css/appkeys.css\"],",
            "        }",
            "",
            "    ##~~ BlueprintPlugin mixin",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/probe\", methods=[\"GET\"])",
            "    @no_firstrun_access",
            "    def handle_probe(self):",
            "        return NO_CONTENT",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/request\", methods=[\"POST\"])",
            "    @octoprint.plugin.BlueprintPlugin.csrf_exempt()",
            "    @no_firstrun_access",
            "    def handle_request(self):",
            "        data = flask.request.json",
            "        if data is None:",
            "            flask.abort(400, description=\"Missing key request\")",
            "",
            "        if \"app\" not in data:",
            "            flask.abort(400, description=\"No app name provided\")",
            "",
            "        app_name = data[\"app\"]",
            "        user_id = None",
            "        if \"user\" in data and data[\"user\"]:",
            "            user_id = data[\"user\"]",
            "",
            "        app_token, user_token = self._add_pending_decision(app_name, user_id=user_id)",
            "        auth_dialog = flask.url_for(",
            "            \"plugin.appkeys.handle_auth_dialog\", app_token=app_token, _external=True",
            "        ) + (f\"?user={user_id}\" if user_id else \"\")",
            "",
            "        self._plugin_manager.send_plugin_message(",
            "            self._identifier,",
            "            {",
            "                \"type\": \"request_access\",",
            "                \"app_name\": app_name,",
            "                \"user_token\": user_token,",
            "                \"user_id\": user_id,",
            "            },",
            "        )",
            "        response = flask.jsonify(app_token=app_token, auth_dialog=auth_dialog)",
            "        response.status_code = 201",
            "        response.headers[\"Location\"] = flask.url_for(",
            "            \".handle_decision_poll\", app_token=app_token, _external=True",
            "        )",
            "        return response",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/request/<app_token>\", methods=[\"GET\"])",
            "    @no_firstrun_access",
            "    def handle_decision_poll(self, app_token):",
            "        result = self._get_pending_by_app_token(app_token)",
            "        if result:",
            "            for pending_decision in result:",
            "                pending_decision.poll_timeout.reset()",
            "",
            "            response = flask.jsonify(message=\"Awaiting decision\")",
            "            response.status_code = 202",
            "            return response",
            "",
            "        result = self._get_decision(app_token)",
            "        if result:",
            "            return flask.jsonify(api_key=result)",
            "",
            "        return flask.abort(404)",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/auth/<app_token>\", methods=[\"GET\"])",
            "    @no_firstrun_access",
            "    def handle_auth_dialog(self, app_token):",
            "        from octoprint.server.util.csrf import add_csrf_cookie",
            "",
            "        user_id = current_user.get_name()",
            "        required_user = flask.request.args.get(\"user\", None)",
            "",
            "        pendings = self._get_pending_by_app_token(app_token)",
            "        if not pendings:",
            "            return flask.abort(404)",
            "",
            "        response = require_fresh_login_with(",
            "            permissions=[Permissions.PLUGIN_APPKEYS_GRANT], user_id=required_user",
            "        )",
            "        if response:",
            "            return response",
            "",
            "        pending = None",
            "        for p in pendings:",
            "            if p.user_id == required_user or (not required_user and p.user_id == user_id):",
            "                pending = p",
            "                break",
            "        else:",
            "            return flask.abort(404)",
            "",
            "        app_id = pending.app_id",
            "        user_token = pending.user_token",
            "        redirect_url = flask.request.args.get(\"redirect\", \"\")",
            "",
            "        response = flask.make_response(",
            "            flask.render_template(",
            "                \"plugin_appkeys/appkeys_authdialog.jinja2\",",
            "                app=app_id,",
            "                user=user_id,",
            "                user_token=user_token,",
            "                redirect_url=redirect_url,",
            "                theming=[],",
            "                request_text=gettext(",
            "                    '\"<strong>%(app)s</strong>\" has requested access to control OctoPrint through the API.'",
            "                ).replace(\"%(app)s\", app_id),",
            "            )",
            "        )",
            "        return add_csrf_cookie(add_non_caching_response_headers(response))",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/decision/<user_token>\", methods=[\"POST\"])",
            "    @restricted_access",
            "    def handle_decision(self, user_token):",
            "        data = flask.request.json",
            "        if \"decision\" not in data:",
            "            flask.abort(400, description=\"No decision provided\")",
            "",
            "        if not Permissions.PLUGIN_APPKEYS_GRANT.can():",
            "            flask.abort(403, description=\"No permission to grant app access\")",
            "",
            "        ensure_credentials_checked_recently()",
            "",
            "        decision = data[\"decision\"] in valid_boolean_trues",
            "        user_id = current_user.get_name()",
            "",
            "        result = self._set_decision(user_token, decision, user_id)",
            "        if not result:",
            "            return flask.abort(404)",
            "",
            "        # Close access_request dialog for this request on all open OctoPrint connections",
            "        self._plugin_manager.send_plugin_message(",
            "            self._identifier, {\"type\": \"end_request\", \"user_token\": user_token}",
            "        )",
            "",
            "        return NO_CONTENT",
            "",
            "    def is_blueprint_protected(self):",
            "        return False  # No API key required to request API access",
            "",
            "    def is_blueprint_csrf_protected(self):",
            "        return True  # protect anything that isn't explicitly marked as exempt",
            "",
            "    ##~~ SimpleApiPlugin mixin",
            "",
            "    def get_api_commands(self):",
            "        return {\"generate\": [\"app\"], \"revoke\": []}",
            "",
            "    def on_api_get(self, request):",
            "        user_id = current_user.get_name()",
            "        if not user_id:",
            "            return flask.abort(403)",
            "",
            "        # GET ?app_id=...[&user_id=...]",
            "        if request.values.get(\"app\"):",
            "            app_id = request.values.get(\"app\")",
            "            user_id = request.values.get(\"user\", user_id)",
            "            if (",
            "                user_id != current_user.get_name()",
            "                and not Permissions.PLUGIN_APPKEYS_ADMIN.can()",
            "            ):",
            "                return flask.abort(403)",
            "",
            "            key = self._api_key_for_user_and_app_id(user_id, app_id)",
            "            if not key:",
            "                return flask.abort(404)",
            "",
            "            return flask.jsonify(",
            "                key=key.external(incl_key=credentials_checked_recently())",
            "            )",
            "",
            "        # GET ?all=true (admin only)",
            "        if (",
            "            request.values.get(\"all\") in valid_boolean_trues",
            "            and Permissions.PLUGIN_APPKEYS_ADMIN.can()",
            "        ):",
            "            keys = self._all_api_keys()",
            "",
            "        else:",
            "            keys = self._api_keys_for_user(user_id)",
            "",
            "        return flask.jsonify(",
            "            keys=list(",
            "                map(lambda x: x.external(), keys),",
            "            ),",
            "            pending={",
            "                x.user_token: x.external() for x in self._get_pending_by_user_id(user_id)",
            "            },",
            "        )",
            "",
            "    def on_api_command(self, command, data):",
            "        user_id = current_user.get_name()",
            "        if not user_id:",
            "            return flask.abort(403)",
            "",
            "        if command == \"revoke\":",
            "            api_key = data.get(\"key\")",
            "",
            "            if api_key:",
            "                # deprecated key based revoke?",
            "                from flask import request",
            "",
            "                from octoprint.server.util import get_remote_address",
            "",
            "                self._logger.warning(",
            "                    \"Deprecated key based revoke command sent to /api/plugin/appkeys by {}, should be migrated to use app id/user tuple\".format(",
            "                        get_remote_address(request)",
            "                    )",
            "                )",
            "",
            "            else:",
            "                # newer app/user based revoke?",
            "                user = data.get(\"user\", user_id)",
            "                app = data.get(\"app\")",
            "                if not app:",
            "                    return flask.abort(400, description=\"Need either app or key\")",
            "",
            "                api_key = self._api_key_for_user_and_app_id(user, app)",
            "",
            "            if not api_key:",
            "                return flask.abort(400, description=\"Need either app or key\")",
            "",
            "            if not Permissions.PLUGIN_APPKEYS_ADMIN.can():",
            "                user_for_key = self._user_for_api_key(api_key)",
            "                if user_for_key is None or user_for_key.get_id() != user_id:",
            "                    return flask.abort(403)",
            "",
            "            ensure_credentials_checked_recently()",
            "",
            "            self._delete_api_key(api_key)",
            "",
            "        elif command == \"generate\":",
            "            # manual generateKey",
            "            app_name = data.get(\"app\")",
            "            if not app_name:",
            "                return flask.abort(400)",
            "",
            "            selected_user_id = data.get(\"user\", user_id)",
            "            if selected_user_id != user_id and not Permissions.PLUGIN_APPKEYS_ADMIN.can():",
            "                return flask.abort(403)",
            "",
            "            ensure_credentials_checked_recently()",
            "",
            "            key = self._add_api_key(selected_user_id, app_name.strip())",
            "            return flask.jsonify(user_id=selected_user_id, app_id=app_name, api_key=key)",
            "",
            "        return NO_CONTENT",
            "",
            "    ##~~ key validator hook",
            "",
            "    def validate_api_key(self, api_key, *args, **kwargs):",
            "        return self._user_for_api_key(api_key)",
            "",
            "    ##~~ Helpers",
            "",
            "    def _add_pending_decision(self, app_name, user_id=None):",
            "        app_token = self._generate_key()",
            "        user_token = self._generate_key()",
            "",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            self._pending_decisions.append(",
            "                PendingDecision(",
            "                    app_name,",
            "                    app_token,",
            "                    user_id,",
            "                    user_token,",
            "                    timeout_callback=self._expire_pending,",
            "                )",
            "            )",
            "",
            "        return app_token, user_token",
            "",
            "    def _get_pending_by_app_token(self, app_token):",
            "        result = []",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            for data in self._pending_decisions:",
            "                if data.app_token == app_token:",
            "                    result.append(data)",
            "        return result",
            "",
            "    def _get_pending_by_user_id(self, user_id):",
            "        result = []",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            for data in self._pending_decisions:",
            "                if data.user_id == user_id or data.user_id is None:",
            "                    result.append(data)",
            "        return result",
            "",
            "    def _expire_pending(self, user_token):",
            "        with self._pending_lock:",
            "            len_before = len(self._pending_decisions)",
            "            self._pending_decisions = list(",
            "                filter(lambda x: x.user_token != user_token, self._pending_decisions)",
            "            )",
            "            len_after = len(self._pending_decisions)",
            "",
            "            if len_after < len_before:",
            "                self._plugin_manager.send_plugin_message(",
            "                    self._identifier, {\"type\": \"end_request\", \"user_token\": user_token}",
            "                )",
            "",
            "    def _remove_stale_pending(self):",
            "        with self._pending_lock:",
            "            cutoff = time.monotonic() - CUTOFF_TIME",
            "            len_before = len(self._pending_decisions)",
            "            self._pending_decisions = list(",
            "                filter(lambda x: x.created >= cutoff, self._pending_decisions)",
            "            )",
            "            len_after = len(self._pending_decisions)",
            "            if len_after < len_before:",
            "                self._logger.info(",
            "                    \"Deleted {} stale pending authorization requests\".format(",
            "                        len_before - len_after",
            "                    )",
            "                )",
            "",
            "    def _set_decision(self, user_token, decision, user_id):",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            for data in self._pending_decisions:",
            "                if data.user_token == user_token and (",
            "                    data.user_id == user_id or data.user_id is None",
            "                ):",
            "                    pending = data",
            "                    break",
            "            else:",
            "                return False  # not found",
            "",
            "        if decision:",
            "            with self._ready_lock:",
            "                self._ready_decisions.append(ReadyDecision.for_pending(pending, user_id))",
            "",
            "        with self._pending_lock:",
            "            self._pending_decisions = list(",
            "                filter(lambda x: x.user_token != user_token, self._pending_decisions)",
            "            )",
            "",
            "        return True",
            "",
            "    def _get_decision(self, app_token):",
            "        self._remove_stale_pending()",
            "",
            "        with self._ready_lock:",
            "            for data in self._ready_decisions:",
            "                if data.app_token == app_token:",
            "                    decision = data",
            "                    break",
            "            else:",
            "                return False  # not found",
            "",
            "        api_key = self._add_api_key(decision.user_id, decision.app_id)",
            "",
            "        with self._ready_lock:",
            "            self._ready_decisions = list(",
            "                filter(lambda x: x.app_token != app_token, self._ready_decisions)",
            "            )",
            "",
            "        return api_key",
            "",
            "    def _add_api_key(self, user_id, app_name):",
            "        with self._keys_lock:",
            "            for key in self._keys[user_id]:",
            "                if key.app_id.lower() == app_name.lower():",
            "                    return key.api_key",
            "",
            "            key = ActiveKey(app_name, self._generate_key(), user_id)",
            "            self._keys[user_id].append(key)",
            "            self._save_keys()",
            "            return key.api_key",
            "",
            "    def _delete_api_key(self, api_key):",
            "        if isinstance(api_key, ActiveKey):",
            "            api_key = api_key.api_key",
            "",
            "        with self._keys_lock:",
            "            for user_id, data in self._keys.items():",
            "                self._keys[user_id] = list(filter(lambda x: x.api_key != api_key, data))",
            "            self._save_keys()",
            "",
            "    def _user_for_api_key(self, api_key):",
            "        if isinstance(api_key, ActiveKey):",
            "            api_key = api_key.api_key",
            "",
            "        with self._keys_lock:",
            "            for user_id, data in self._keys.items():",
            "                if any(filter(lambda x: x.api_key == api_key, data)):",
            "                    return self._user_manager.find_user(userid=user_id)",
            "        return None",
            "",
            "    def _api_keys_for_user(self, user_id):",
            "        with self._keys_lock:",
            "            return self._keys[user_id]",
            "",
            "    def _all_api_keys(self):",
            "        with self._keys_lock:",
            "            result = []",
            "            for keys in self._keys.values():",
            "                result += keys",
            "        return result",
            "",
            "    def _api_key_for_user_and_app_id(self, user_id, app_id):",
            "        with self._keys_lock:",
            "            if user_id not in self._keys:",
            "                return None",
            "",
            "            for key in self._keys[user_id]:",
            "                if key.app_id.lower() == app_id.lower():",
            "                    return key",
            "",
            "        return None",
            "",
            "    def _generate_key(self):",
            "        return generate_api_key()",
            "",
            "    def _load_keys(self):",
            "        with self._keys_lock:",
            "            if not os.path.exists(self._key_path):",
            "                return",
            "",
            "            try:",
            "                persisted = yaml.load_from_file(path=self._key_path)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Could not load application keys from {self._key_path}\"",
            "                )",
            "                return",
            "",
            "            if not isinstance(persisted, dict):",
            "                return",
            "",
            "            keys = defaultdict(list)",
            "            for user_id, persisted_keys in persisted.items():",
            "                keys[user_id] = [",
            "                    ActiveKey.for_internal(x, user_id) for x in persisted_keys",
            "                ]",
            "            self._keys = keys",
            "",
            "    def _save_keys(self):",
            "        with self._keys_lock:",
            "            to_persist = {}",
            "            for user_id, keys in self._keys.items():",
            "                to_persist[user_id] = [x.internal() for x in keys]",
            "",
            "            try:",
            "                with atomic_write(self._key_path, mode=\"wt\") as f:",
            "                    yaml.save_to_file(to_persist, file=f)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Could not write application keys to {self._key_path}\"",
            "                )",
            "",
            "",
            "__plugin_name__ = \"Application Keys Plugin\"",
            "__plugin_description__ = (",
            "    \"Implements a workflow for third party clients to obtain API keys\"",
            ")",
            "__plugin_author__ = \"Gina H\u00e4u\u00dfge, Aldo Hoeben\"",
            "__plugin_disabling_discouraged__ = gettext(",
            "    \"Without this plugin third party clients will no longer be able to \"",
            "    \"obtain an API key without you manually copy-pasting it.\"",
            ")",
            "__plugin_license__ = \"AGPLv3\"",
            "__plugin_pythoncompat__ = \">=3.7,<4\"",
            "__plugin_implementation__ = AppKeysPlugin()",
            "__plugin_hooks__ = {",
            "    \"octoprint.accesscontrol.keyvalidator\": __plugin_implementation__.validate_api_key,",
            "    \"octoprint.access.permissions\": __plugin_implementation__.get_additional_permissions,",
            "}"
        ],
        "afterPatchFile": [
            "import os",
            "import threading",
            "import time",
            "from collections import defaultdict",
            "",
            "import flask",
            "from flask_babel import gettext",
            "",
            "import octoprint.plugin",
            "from octoprint.access import ADMIN_GROUP, USER_GROUP",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.server import NO_CONTENT, current_user",
            "from octoprint.server.util import require_fresh_login_with",
            "from octoprint.server.util.flask import (",
            "    add_non_caching_response_headers,",
            "    credentials_checked_recently,",
            "    ensure_credentials_checked_recently,",
            "    no_firstrun_access,",
            "    restricted_access,",
            ")",
            "from octoprint.settings import valid_boolean_trues",
            "from octoprint.util import ResettableTimer, atomic_write, generate_api_key, yaml",
            "",
            "CUTOFF_TIME = 10 * 60  # 10min",
            "POLL_TIMEOUT = 5  # 5 seconds",
            "",
            "",
            "class AppAlreadyExists(Exception):",
            "    pass",
            "",
            "",
            "class PendingDecision:",
            "    def __init__(self, app_id, app_token, user_id, user_token, timeout_callback=None):",
            "        self.app_id = app_id",
            "        self.app_token = app_token",
            "        self.user_id = user_id",
            "        self.user_token = user_token",
            "        self.created = time.monotonic()",
            "",
            "        if callable(timeout_callback):",
            "            self.poll_timeout = ResettableTimer(",
            "                POLL_TIMEOUT, timeout_callback, [user_token]",
            "            )",
            "            self.poll_timeout.start()",
            "",
            "    def external(self):",
            "        return {",
            "            \"app_id\": self.app_id,",
            "            \"user_id\": self.user_id,",
            "            \"user_token\": self.user_token,",
            "        }",
            "",
            "    def __repr__(self):",
            "        return \"PendingDecision({!r}, {!r}, {!r}, {!r}, timeout_callback=...)\".format(",
            "            self.app_id, self.app_token, self.user_id, self.user_token",
            "        )",
            "",
            "",
            "class ReadyDecision:",
            "    def __init__(self, app_id, app_token, user_id):",
            "        self.app_id = app_id",
            "        self.app_token = app_token",
            "        self.user_id = user_id",
            "",
            "    @classmethod",
            "    def for_pending(cls, pending, user_id):",
            "        return cls(pending.app_id, pending.app_token, user_id)",
            "",
            "    def __repr__(self):",
            "        return \"ReadyDecision({!r}, {!r}, {!r})\".format(",
            "            self.app_id, self.app_token, self.user_id",
            "        )",
            "",
            "",
            "class ActiveKey:",
            "    def __init__(self, app_id, api_key, user_id):",
            "        self.app_id = app_id",
            "        self.api_key = api_key",
            "        self.user_id = user_id",
            "",
            "    def external(self, incl_key=False):",
            "        result = {\"app_id\": self.app_id, \"user_id\": self.user_id}",
            "        if incl_key:",
            "            result[\"api_key\"] = self.api_key",
            "        return result",
            "",
            "    def internal(self):",
            "        return {\"app_id\": self.app_id, \"api_key\": self.api_key}",
            "",
            "    @classmethod",
            "    def for_internal(cls, internal, user_id):",
            "        return cls(internal[\"app_id\"], internal[\"api_key\"], user_id)",
            "",
            "    def __repr__(self):",
            "        return \"ActiveKey({!r}, {!r}, {!r})\".format(",
            "            self.app_id, self.api_key, self.user_id",
            "        )",
            "",
            "",
            "class AppKeysPlugin(",
            "    octoprint.plugin.AssetPlugin,",
            "    octoprint.plugin.BlueprintPlugin,",
            "    octoprint.plugin.SimpleApiPlugin,",
            "    octoprint.plugin.TemplatePlugin,",
            "):",
            "    def __init__(self):",
            "        self._pending_decisions = []",
            "        self._pending_lock = threading.RLock()",
            "",
            "        self._ready_decisions = []",
            "        self._ready_lock = threading.RLock()",
            "",
            "        self._keys = defaultdict(list)",
            "        self._keys_lock = threading.RLock()",
            "",
            "        self._key_path = None",
            "",
            "    def initialize(self):",
            "        self._key_path = os.path.join(self.get_plugin_data_folder(), \"keys.yaml\")",
            "        self._load_keys()",
            "",
            "    # Additional permissions hook",
            "",
            "    def get_additional_permissions(self):",
            "        return [",
            "            {",
            "                \"key\": \"ADMIN\",",
            "                \"name\": \"Admin access\",",
            "                \"description\": gettext(\"Allows administrating all application keys\"),",
            "                \"roles\": [\"admin\"],",
            "                \"dangerous\": True,",
            "                \"default_groups\": [ADMIN_GROUP],",
            "            },",
            "            {",
            "                \"key\": \"GRANT\",",
            "                \"name\": \"Grant access\",",
            "                \"description\": gettext(\"Allows to grant app access\"),",
            "                \"roles\": [\"user\"],",
            "                \"default_groups\": [USER_GROUP],",
            "            },",
            "        ]",
            "",
            "    ##~~ TemplatePlugin",
            "",
            "    def get_template_configs(self):",
            "        return [",
            "            {\"type\": \"usersettings\", \"name\": gettext(\"Application Keys\")},",
            "            {\"type\": \"settings\", \"name\": gettext(\"Application Keys\")},",
            "        ]",
            "",
            "    ##~~ AssetPlugin",
            "",
            "    def get_assets(self):",
            "        return {",
            "            \"js\": [\"js/appkeys.js\"],",
            "            \"clientjs\": [\"clientjs/appkeys.js\"],",
            "            \"less\": [\"less/appkeys.less\"],",
            "            \"css\": [\"css/appkeys.css\"],",
            "        }",
            "",
            "    ##~~ BlueprintPlugin mixin",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/probe\", methods=[\"GET\"])",
            "    @no_firstrun_access",
            "    def handle_probe(self):",
            "        return NO_CONTENT",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/request\", methods=[\"POST\"])",
            "    @octoprint.plugin.BlueprintPlugin.csrf_exempt()",
            "    @no_firstrun_access",
            "    def handle_request(self):",
            "        data = flask.request.json",
            "        if data is None:",
            "            flask.abort(400, description=\"Missing key request\")",
            "",
            "        if \"app\" not in data:",
            "            flask.abort(400, description=\"No app name provided\")",
            "",
            "        app_name = data[\"app\"]",
            "        user_id = None",
            "        if \"user\" in data and data[\"user\"]:",
            "            user_id = data[\"user\"]",
            "",
            "        app_token, user_token = self._add_pending_decision(app_name, user_id=user_id)",
            "        auth_dialog = flask.url_for(",
            "            \"plugin.appkeys.handle_auth_dialog\", app_token=app_token, _external=True",
            "        ) + (f\"?user={user_id}\" if user_id else \"\")",
            "",
            "        self._plugin_manager.send_plugin_message(",
            "            self._identifier,",
            "            {",
            "                \"type\": \"request_access\",",
            "                \"app_name\": app_name,",
            "                \"user_token\": user_token,",
            "                \"user_id\": user_id,",
            "            },",
            "        )",
            "        response = flask.jsonify(app_token=app_token, auth_dialog=auth_dialog)",
            "        response.status_code = 201",
            "        response.headers[\"Location\"] = flask.url_for(",
            "            \".handle_decision_poll\", app_token=app_token, _external=True",
            "        )",
            "        return response",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/request/<app_token>\", methods=[\"GET\"])",
            "    @no_firstrun_access",
            "    def handle_decision_poll(self, app_token):",
            "        result = self._get_pending_by_app_token(app_token)",
            "        if result:",
            "            for pending_decision in result:",
            "                pending_decision.poll_timeout.reset()",
            "",
            "            response = flask.jsonify(message=\"Awaiting decision\")",
            "            response.status_code = 202",
            "            return response",
            "",
            "        result = self._get_decision(app_token)",
            "        if result:",
            "            return flask.jsonify(api_key=result)",
            "",
            "        return flask.abort(404)",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/auth/<app_token>\", methods=[\"GET\"])",
            "    @no_firstrun_access",
            "    def handle_auth_dialog(self, app_token):",
            "        from octoprint.server.util.csrf import add_csrf_cookie",
            "",
            "        user_id = current_user.get_name()",
            "        required_user = flask.request.args.get(\"user\", None)",
            "",
            "        pendings = self._get_pending_by_app_token(app_token)",
            "        if not pendings:",
            "            return flask.abort(404)",
            "",
            "        response = require_fresh_login_with(",
            "            permissions=[Permissions.PLUGIN_APPKEYS_GRANT], user_id=required_user",
            "        )",
            "        if response:",
            "            return response",
            "",
            "        pending = None",
            "        for p in pendings:",
            "            if p.user_id == required_user or (not required_user and p.user_id == user_id):",
            "                pending = p",
            "                break",
            "        else:",
            "            return flask.abort(404)",
            "",
            "        app_id = pending.app_id",
            "        user_token = pending.user_token",
            "        redirect_url = flask.request.args.get(\"redirect\", \"\")",
            "",
            "        response = flask.make_response(",
            "            flask.render_template(",
            "                \"plugin_appkeys/appkeys_authdialog.jinja2\",",
            "                app=app_id,",
            "                user=user_id,",
            "                user_token=user_token,",
            "                redirect_url=redirect_url,",
            "                theming=[],",
            "                request_text=gettext(",
            "                    '\"<strong>%(app)s</strong>\" has requested access to control OctoPrint through the API.'",
            "                ).replace(\"%(app)s\", app_id),",
            "            )",
            "        )",
            "        return add_csrf_cookie(add_non_caching_response_headers(response))",
            "",
            "    @octoprint.plugin.BlueprintPlugin.route(\"/decision/<user_token>\", methods=[\"POST\"])",
            "    @restricted_access",
            "    def handle_decision(self, user_token):",
            "        data = flask.request.json",
            "        if \"decision\" not in data:",
            "            flask.abort(400, description=\"No decision provided\")",
            "",
            "        if not Permissions.PLUGIN_APPKEYS_GRANT.can():",
            "            flask.abort(403, description=\"No permission to grant app access\")",
            "",
            "        ensure_credentials_checked_recently()",
            "",
            "        decision = data[\"decision\"] in valid_boolean_trues",
            "        user_id = current_user.get_name()",
            "",
            "        result = self._set_decision(user_token, decision, user_id)",
            "        if not result:",
            "            return flask.abort(404)",
            "",
            "        # Close access_request dialog for this request on all open OctoPrint connections",
            "        self._plugin_manager.send_plugin_message(",
            "            self._identifier, {\"type\": \"end_request\", \"user_token\": user_token}",
            "        )",
            "",
            "        return NO_CONTENT",
            "",
            "    def is_blueprint_protected(self):",
            "        return False  # No API key required to request API access",
            "",
            "    def is_blueprint_csrf_protected(self):",
            "        return True  # protect anything that isn't explicitly marked as exempt",
            "",
            "    ##~~ SimpleApiPlugin mixin",
            "",
            "    def get_api_commands(self):",
            "        return {\"generate\": [\"app\"], \"revoke\": []}",
            "",
            "    def on_api_get(self, request):",
            "        user_id = current_user.get_name()",
            "        if not user_id:",
            "            return flask.abort(403)",
            "",
            "        # GET ?app_id=...[&user_id=...]",
            "        if request.values.get(\"app\"):",
            "            app_id = request.values.get(\"app\")",
            "            user_id = request.values.get(\"user\", user_id)",
            "            if (",
            "                user_id != current_user.get_name()",
            "                and not Permissions.PLUGIN_APPKEYS_ADMIN.can()",
            "            ):",
            "                return flask.abort(403)",
            "",
            "            key = self._api_key_for_user_and_app_id(user_id, app_id)",
            "            if not key:",
            "                return flask.abort(404)",
            "",
            "            return flask.jsonify(",
            "                key=key.external(incl_key=credentials_checked_recently())",
            "            )",
            "",
            "        # GET ?all=true (admin only)",
            "        if (",
            "            request.values.get(\"all\") in valid_boolean_trues",
            "            and Permissions.PLUGIN_APPKEYS_ADMIN.can()",
            "        ):",
            "            keys = self._all_api_keys()",
            "",
            "        else:",
            "            keys = self._api_keys_for_user(user_id)",
            "",
            "        return flask.jsonify(",
            "            keys=list(",
            "                map(lambda x: x.external(), keys),",
            "            ),",
            "            pending={",
            "                x.user_token: x.external() for x in self._get_pending_by_user_id(user_id)",
            "            },",
            "        )",
            "",
            "    def on_api_command(self, command, data):",
            "        user_id = current_user.get_name()",
            "        if not user_id:",
            "            return flask.abort(403)",
            "",
            "        if command == \"revoke\":",
            "            api_key = data.get(\"key\")",
            "",
            "            if api_key:",
            "                # deprecated key based revoke?",
            "                from flask import request",
            "",
            "                self._logger.warning(",
            "                    f\"Deprecated key based revoke command sent to /api/plugin/appkeys by {request.remote_addr}, should be migrated to use app id/user tuple\"",
            "                )",
            "",
            "            else:",
            "                # newer app/user based revoke?",
            "                user = data.get(\"user\", user_id)",
            "                app = data.get(\"app\")",
            "                if not app:",
            "                    return flask.abort(400, description=\"Need either app or key\")",
            "",
            "                api_key = self._api_key_for_user_and_app_id(user, app)",
            "",
            "            if not api_key:",
            "                return flask.abort(400, description=\"Need either app or key\")",
            "",
            "            if not Permissions.PLUGIN_APPKEYS_ADMIN.can():",
            "                user_for_key = self._user_for_api_key(api_key)",
            "                if user_for_key is None or user_for_key.get_id() != user_id:",
            "                    return flask.abort(403)",
            "",
            "            ensure_credentials_checked_recently()",
            "",
            "            self._delete_api_key(api_key)",
            "",
            "        elif command == \"generate\":",
            "            # manual generateKey",
            "            app_name = data.get(\"app\")",
            "            if not app_name:",
            "                return flask.abort(400)",
            "",
            "            selected_user_id = data.get(\"user\", user_id)",
            "            if selected_user_id != user_id and not Permissions.PLUGIN_APPKEYS_ADMIN.can():",
            "                return flask.abort(403)",
            "",
            "            ensure_credentials_checked_recently()",
            "",
            "            key = self._add_api_key(selected_user_id, app_name.strip())",
            "            return flask.jsonify(user_id=selected_user_id, app_id=app_name, api_key=key)",
            "",
            "        return NO_CONTENT",
            "",
            "    ##~~ key validator hook",
            "",
            "    def validate_api_key(self, api_key, *args, **kwargs):",
            "        return self._user_for_api_key(api_key)",
            "",
            "    ##~~ Helpers",
            "",
            "    def _add_pending_decision(self, app_name, user_id=None):",
            "        app_token = self._generate_key()",
            "        user_token = self._generate_key()",
            "",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            self._pending_decisions.append(",
            "                PendingDecision(",
            "                    app_name,",
            "                    app_token,",
            "                    user_id,",
            "                    user_token,",
            "                    timeout_callback=self._expire_pending,",
            "                )",
            "            )",
            "",
            "        return app_token, user_token",
            "",
            "    def _get_pending_by_app_token(self, app_token):",
            "        result = []",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            for data in self._pending_decisions:",
            "                if data.app_token == app_token:",
            "                    result.append(data)",
            "        return result",
            "",
            "    def _get_pending_by_user_id(self, user_id):",
            "        result = []",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            for data in self._pending_decisions:",
            "                if data.user_id == user_id or data.user_id is None:",
            "                    result.append(data)",
            "        return result",
            "",
            "    def _expire_pending(self, user_token):",
            "        with self._pending_lock:",
            "            len_before = len(self._pending_decisions)",
            "            self._pending_decisions = list(",
            "                filter(lambda x: x.user_token != user_token, self._pending_decisions)",
            "            )",
            "            len_after = len(self._pending_decisions)",
            "",
            "            if len_after < len_before:",
            "                self._plugin_manager.send_plugin_message(",
            "                    self._identifier, {\"type\": \"end_request\", \"user_token\": user_token}",
            "                )",
            "",
            "    def _remove_stale_pending(self):",
            "        with self._pending_lock:",
            "            cutoff = time.monotonic() - CUTOFF_TIME",
            "            len_before = len(self._pending_decisions)",
            "            self._pending_decisions = list(",
            "                filter(lambda x: x.created >= cutoff, self._pending_decisions)",
            "            )",
            "            len_after = len(self._pending_decisions)",
            "            if len_after < len_before:",
            "                self._logger.info(",
            "                    \"Deleted {} stale pending authorization requests\".format(",
            "                        len_before - len_after",
            "                    )",
            "                )",
            "",
            "    def _set_decision(self, user_token, decision, user_id):",
            "        with self._pending_lock:",
            "            self._remove_stale_pending()",
            "            for data in self._pending_decisions:",
            "                if data.user_token == user_token and (",
            "                    data.user_id == user_id or data.user_id is None",
            "                ):",
            "                    pending = data",
            "                    break",
            "            else:",
            "                return False  # not found",
            "",
            "        if decision:",
            "            with self._ready_lock:",
            "                self._ready_decisions.append(ReadyDecision.for_pending(pending, user_id))",
            "",
            "        with self._pending_lock:",
            "            self._pending_decisions = list(",
            "                filter(lambda x: x.user_token != user_token, self._pending_decisions)",
            "            )",
            "",
            "        return True",
            "",
            "    def _get_decision(self, app_token):",
            "        self._remove_stale_pending()",
            "",
            "        with self._ready_lock:",
            "            for data in self._ready_decisions:",
            "                if data.app_token == app_token:",
            "                    decision = data",
            "                    break",
            "            else:",
            "                return False  # not found",
            "",
            "        api_key = self._add_api_key(decision.user_id, decision.app_id)",
            "",
            "        with self._ready_lock:",
            "            self._ready_decisions = list(",
            "                filter(lambda x: x.app_token != app_token, self._ready_decisions)",
            "            )",
            "",
            "        return api_key",
            "",
            "    def _add_api_key(self, user_id, app_name):",
            "        with self._keys_lock:",
            "            for key in self._keys[user_id]:",
            "                if key.app_id.lower() == app_name.lower():",
            "                    return key.api_key",
            "",
            "            key = ActiveKey(app_name, self._generate_key(), user_id)",
            "            self._keys[user_id].append(key)",
            "            self._save_keys()",
            "            return key.api_key",
            "",
            "    def _delete_api_key(self, api_key):",
            "        if isinstance(api_key, ActiveKey):",
            "            api_key = api_key.api_key",
            "",
            "        with self._keys_lock:",
            "            for user_id, data in self._keys.items():",
            "                self._keys[user_id] = list(filter(lambda x: x.api_key != api_key, data))",
            "            self._save_keys()",
            "",
            "    def _user_for_api_key(self, api_key):",
            "        if isinstance(api_key, ActiveKey):",
            "            api_key = api_key.api_key",
            "",
            "        with self._keys_lock:",
            "            for user_id, data in self._keys.items():",
            "                if any(filter(lambda x: x.api_key == api_key, data)):",
            "                    return self._user_manager.find_user(userid=user_id)",
            "        return None",
            "",
            "    def _api_keys_for_user(self, user_id):",
            "        with self._keys_lock:",
            "            return self._keys[user_id]",
            "",
            "    def _all_api_keys(self):",
            "        with self._keys_lock:",
            "            result = []",
            "            for keys in self._keys.values():",
            "                result += keys",
            "        return result",
            "",
            "    def _api_key_for_user_and_app_id(self, user_id, app_id):",
            "        with self._keys_lock:",
            "            if user_id not in self._keys:",
            "                return None",
            "",
            "            for key in self._keys[user_id]:",
            "                if key.app_id.lower() == app_id.lower():",
            "                    return key",
            "",
            "        return None",
            "",
            "    def _generate_key(self):",
            "        return generate_api_key()",
            "",
            "    def _load_keys(self):",
            "        with self._keys_lock:",
            "            if not os.path.exists(self._key_path):",
            "                return",
            "",
            "            try:",
            "                persisted = yaml.load_from_file(path=self._key_path)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Could not load application keys from {self._key_path}\"",
            "                )",
            "                return",
            "",
            "            if not isinstance(persisted, dict):",
            "                return",
            "",
            "            keys = defaultdict(list)",
            "            for user_id, persisted_keys in persisted.items():",
            "                keys[user_id] = [",
            "                    ActiveKey.for_internal(x, user_id) for x in persisted_keys",
            "                ]",
            "            self._keys = keys",
            "",
            "    def _save_keys(self):",
            "        with self._keys_lock:",
            "            to_persist = {}",
            "            for user_id, keys in self._keys.items():",
            "                to_persist[user_id] = [x.internal() for x in keys]",
            "",
            "            try:",
            "                with atomic_write(self._key_path, mode=\"wt\") as f:",
            "                    yaml.save_to_file(to_persist, file=f)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Could not write application keys to {self._key_path}\"",
            "                )",
            "",
            "",
            "__plugin_name__ = \"Application Keys Plugin\"",
            "__plugin_description__ = (",
            "    \"Implements a workflow for third party clients to obtain API keys\"",
            ")",
            "__plugin_author__ = \"Gina H\u00e4u\u00dfge, Aldo Hoeben\"",
            "__plugin_disabling_discouraged__ = gettext(",
            "    \"Without this plugin third party clients will no longer be able to \"",
            "    \"obtain an API key without you manually copy-pasting it.\"",
            ")",
            "__plugin_license__ = \"AGPLv3\"",
            "__plugin_pythoncompat__ = \">=3.7,<4\"",
            "__plugin_implementation__ = AppKeysPlugin()",
            "__plugin_hooks__ = {",
            "    \"octoprint.accesscontrol.keyvalidator\": __plugin_implementation__.validate_api_key,",
            "    \"octoprint.access.permissions\": __plugin_implementation__.get_additional_permissions,",
            "}"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "359": [
                "AppKeysPlugin",
                "on_api_command"
            ],
            "360": [
                "AppKeysPlugin",
                "on_api_command"
            ],
            "362": [
                "AppKeysPlugin",
                "on_api_command"
            ],
            "363": [
                "AppKeysPlugin",
                "on_api_command"
            ],
            "364": [
                "AppKeysPlugin",
                "on_api_command"
            ]
        },
        "addLocation": []
    },
    "src/octoprint/schema/config/access_control.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 36,
                "PatchRowcode": "     autologinAs: Optional[str] = None"
            },
            "1": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "     \"\"\"The name of the user to automatically log on clients originating from `localNetworks` as. Must be the name of one of your configured users.\"\"\""
            },
            "2": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+    autologinHeadsupAcknowledged: bool = False"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+    \"\"\"Whether the user has acknowledged the heads-up about the importance of a correct reverse proxy configuration in the presence of autologin.\"\"\""
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "     trustBasicAuthentication: bool = False"
            },
            "7": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "     \"\"\"Whether to trust Basic Authentication headers. If you have setup Basic Authentication in front of OctoPrint and the user names you use there match OctoPrint accounts, by setting this to true users will be logged into OctoPrint as the user during Basic Authentication. **ONLY ENABLE THIS** if your OctoPrint instance is only accessible through a connection locked down through Basic Authentication!\"\"\""
            },
            "8": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2022 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "from typing import List, Optional",
            "",
            "from octoprint.schema import BaseModel",
            "from octoprint.vendor.with_attrs_docs import with_attrs_docs",
            "",
            "",
            "@with_attrs_docs",
            "class AccessControlConfig(BaseModel):",
            "    salt: Optional[str] = None",
            "    \"\"\"Secret salt used for password hashing. **DO NOT TOUCH!** If changed you will no longer be able to log in with your existing accounts. Default unset, generated on first run.\"\"\"",
            "",
            "    userManager: str = \"octoprint.access.users.FilebasedUserManager\"",
            "    \"\"\"The user manager implementation to use for accessing user information. Currently only a filebased user manager is implemented which stores configured accounts in a YAML file (Default: `users.yaml` in the default configuration folder).\"\"\"",
            "",
            "    groupManager: str = \"octoprint.access.groups.FilebasedGroupManager\"",
            "    \"\"\"The group manager implementation to use for accessing group information. Currently only a filebased user manager is implemented which stores configured groups in a YAML file (Default: `groups.yaml` in the default configuration folder).\"\"\"",
            "",
            "    permissionManager: str = \"octoprint.access.permissions.PermissionManager\"",
            "    \"\"\"The permission manager implementation to use.\"\"\"",
            "",
            "    userfile: Optional[str] = None",
            "    \"\"\"The YAML user file to use. If left out defaults to `users.yaml` in the default configuration folder.\"\"\"",
            "",
            "    groupfile: Optional[str] = None",
            "    \"\"\"The YAML group file to use. If left out defaults to `groups.yaml` in the default configuration folder.\"\"\"",
            "",
            "    autologinLocal: bool = False",
            "    \"\"\"If set to true, will automatically log on clients originating from any of the networks defined in `localNetworks` as the user defined in `autologinAs`.\"\"\"",
            "",
            "    localNetworks: List[str] = [\"127.0.0.0/8\", \"::1/128\"]",
            "    \"\"\"A list of networks or IPs for which an automatic logon as the user defined in `autologinAs` will take place. If available OctoPrint will evaluate the `X-Forwarded-For` HTTP header for determining the client's IP address. Defaults to anything originating from localhost.\"\"\"",
            "",
            "    autologinAs: Optional[str] = None",
            "    \"\"\"The name of the user to automatically log on clients originating from `localNetworks` as. Must be the name of one of your configured users.\"\"\"",
            "",
            "    trustBasicAuthentication: bool = False",
            "    \"\"\"Whether to trust Basic Authentication headers. If you have setup Basic Authentication in front of OctoPrint and the user names you use there match OctoPrint accounts, by setting this to true users will be logged into OctoPrint as the user during Basic Authentication. **ONLY ENABLE THIS** if your OctoPrint instance is only accessible through a connection locked down through Basic Authentication!\"\"\"",
            "",
            "    checkBasicAuthenticationPassword: bool = True",
            "    \"\"\"Whether to also check the password provided through Basic Authentication, if the Basic Authentication header is to be trusted. Disabling this will only match the user name in the Basic Authentication header and login the user without further checks, thus disable with caution.\"\"\"",
            "",
            "    trustRemoteUser: bool = False",
            "    \"\"\"Whether to trust remote user headers. If you have setup authentication in front of OctoPrint and the user names you use there match OctoPrint accounts, by setting this to true users will be logged into OctoPrint as the user provided in the header. **ONLY ENABLE THIS** if your OctoPrint instance is only accessible through a connection locked down through an authenticating reverse proxy!\"\"\"",
            "",
            "    remoteUserHeader: str = \"REMOTE_USER\"",
            "    \"\"\"Header used by the reverse proxy to convey the authenticated user.\"\"\"",
            "",
            "    addRemoteUsers: bool = False",
            "    \"\"\"If a remote user is not found, add them. Use this only if all users from the remote system can use OctoPrint.\"\"\"",
            "",
            "    defaultReauthenticationTimeout: int = 5",
            "    \"\"\"Default timeout after which to require reauthentication by a user for dangerous changes, in minutes. Defaults to 5 minutes. Set to 0 to disable reauthentication requirements (SECURITY IMPACT!).\"\"\""
        ],
        "afterPatchFile": [
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2022 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "from typing import List, Optional",
            "",
            "from octoprint.schema import BaseModel",
            "from octoprint.vendor.with_attrs_docs import with_attrs_docs",
            "",
            "",
            "@with_attrs_docs",
            "class AccessControlConfig(BaseModel):",
            "    salt: Optional[str] = None",
            "    \"\"\"Secret salt used for password hashing. **DO NOT TOUCH!** If changed you will no longer be able to log in with your existing accounts. Default unset, generated on first run.\"\"\"",
            "",
            "    userManager: str = \"octoprint.access.users.FilebasedUserManager\"",
            "    \"\"\"The user manager implementation to use for accessing user information. Currently only a filebased user manager is implemented which stores configured accounts in a YAML file (Default: `users.yaml` in the default configuration folder).\"\"\"",
            "",
            "    groupManager: str = \"octoprint.access.groups.FilebasedGroupManager\"",
            "    \"\"\"The group manager implementation to use for accessing group information. Currently only a filebased user manager is implemented which stores configured groups in a YAML file (Default: `groups.yaml` in the default configuration folder).\"\"\"",
            "",
            "    permissionManager: str = \"octoprint.access.permissions.PermissionManager\"",
            "    \"\"\"The permission manager implementation to use.\"\"\"",
            "",
            "    userfile: Optional[str] = None",
            "    \"\"\"The YAML user file to use. If left out defaults to `users.yaml` in the default configuration folder.\"\"\"",
            "",
            "    groupfile: Optional[str] = None",
            "    \"\"\"The YAML group file to use. If left out defaults to `groups.yaml` in the default configuration folder.\"\"\"",
            "",
            "    autologinLocal: bool = False",
            "    \"\"\"If set to true, will automatically log on clients originating from any of the networks defined in `localNetworks` as the user defined in `autologinAs`.\"\"\"",
            "",
            "    localNetworks: List[str] = [\"127.0.0.0/8\", \"::1/128\"]",
            "    \"\"\"A list of networks or IPs for which an automatic logon as the user defined in `autologinAs` will take place. If available OctoPrint will evaluate the `X-Forwarded-For` HTTP header for determining the client's IP address. Defaults to anything originating from localhost.\"\"\"",
            "",
            "    autologinAs: Optional[str] = None",
            "    \"\"\"The name of the user to automatically log on clients originating from `localNetworks` as. Must be the name of one of your configured users.\"\"\"",
            "",
            "    autologinHeadsupAcknowledged: bool = False",
            "    \"\"\"Whether the user has acknowledged the heads-up about the importance of a correct reverse proxy configuration in the presence of autologin.\"\"\"",
            "",
            "    trustBasicAuthentication: bool = False",
            "    \"\"\"Whether to trust Basic Authentication headers. If you have setup Basic Authentication in front of OctoPrint and the user names you use there match OctoPrint accounts, by setting this to true users will be logged into OctoPrint as the user during Basic Authentication. **ONLY ENABLE THIS** if your OctoPrint instance is only accessible through a connection locked down through Basic Authentication!\"\"\"",
            "",
            "    checkBasicAuthenticationPassword: bool = True",
            "    \"\"\"Whether to also check the password provided through Basic Authentication, if the Basic Authentication header is to be trusted. Disabling this will only match the user name in the Basic Authentication header and login the user without further checks, thus disable with caution.\"\"\"",
            "",
            "    trustRemoteUser: bool = False",
            "    \"\"\"Whether to trust remote user headers. If you have setup authentication in front of OctoPrint and the user names you use there match OctoPrint accounts, by setting this to true users will be logged into OctoPrint as the user provided in the header. **ONLY ENABLE THIS** if your OctoPrint instance is only accessible through a connection locked down through an authenticating reverse proxy!\"\"\"",
            "",
            "    remoteUserHeader: str = \"REMOTE_USER\"",
            "    \"\"\"Header used by the reverse proxy to convey the authenticated user.\"\"\"",
            "",
            "    addRemoteUsers: bool = False",
            "    \"\"\"If a remote user is not found, add them. Use this only if all users from the remote system can use OctoPrint.\"\"\"",
            "",
            "    defaultReauthenticationTimeout: int = 5",
            "    \"\"\"Default timeout after which to require reauthentication by a user for dangerous changes, in minutes. Defaults to 5 minutes. Set to 0 to disable reauthentication requirements (SECURITY IMPACT!).\"\"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.octoprint.schema.config.access_control.AccessControlConfig.self"
        ]
    },
    "src/octoprint/schema/config/server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "     portFallback: Optional[str] = None"
            },
            "2": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 44,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    trustedDownstream: List[str] = []"
            },
            "4": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"List of trusted downstream servers for which to ignore the IP address when trying to determine the connecting client's IP address. If you have OctoPrint behind more than one reverse proxy you should add their IPs here so that they won't be interpreted as the client's IP. One reverse proxy will be handled correctly by default.\"\"\""
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+    trustedDownstream: List[str] = [\"127.0.0.1\", \"::1\"]"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+    \"\"\"List of trusted downstream servers for which to ignore the IP address when trying to determine the connecting client's IP address. A reverse proxy on the same machine as OctoPrint (e.g. as found on OctoPi) will be handled correctly by default, further proxies in front of that you'll have to add yourself.\"\"\""
            },
            "7": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 47,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 48,
                "afterPatchRowNumber": 48,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 49,
                "afterPatchRowNumber": 49,
                "PatchRowcode": " @with_attrs_docs"
            }
        },
        "frontPatchFile": [
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2022 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "from enum import Enum",
            "from typing import Dict, List, Optional",
            "",
            "from octoprint.schema import BaseModel",
            "from octoprint.vendor.with_attrs_docs import with_attrs_docs",
            "",
            "CONST_15MIN = 15 * 60",
            "CONST_1GB = 1024 * 1024 * 1024",
            "CONST_500MB = 500 * 1024 * 1024",
            "CONST_200MB = 200 * 1024 * 1024",
            "CONST_100KB = 100 * 1024",
            "",
            "",
            "@with_attrs_docs",
            "class ReverseProxyConfig(BaseModel):",
            "    prefixHeader: Optional[str] = None",
            "    \"\"\"The request header from which to determine the URL prefix under which OctoPrint is served by the reverse proxy.\"\"\"",
            "",
            "    schemeHeader: Optional[str] = None",
            "    \"\"\"The request header from which to determine the scheme (http or https) under which a specific request to OctoPrint was made to the reverse proxy.\"\"\"",
            "",
            "    hostHeader: Optional[str] = None",
            "    \"\"\"The request header from which to determine the host under which OctoPrint is served by the reverse proxy.\"\"\"",
            "",
            "    serverHeader: Optional[str] = None",
            "",
            "    portHeader: Optional[str] = None",
            "",
            "    prefixFallback: Optional[str] = None",
            "    \"\"\"Use this option to define an optional URL prefix (with a leading /, so absolute to your server's root) under which to run OctoPrint. This should only be needed if you want to run OctoPrint behind a reverse proxy under a different root endpoint than `/` and can't configure said reverse proxy to send a prefix HTTP header (X-Script-Name by default, see above) with forwarded requests.\"\"\"",
            "",
            "    schemeFallback: Optional[str] = None",
            "    \"\"\"Use this option to define an optional forced scheme (http or https) under which to run OctoPrint. This should only be needed if you want to run OctoPrint behind a reverse proxy that also does HTTPS determination but can't configure said reverse proxy to send a scheme HTTP header (X-Scheme by default, see above) with forwarded requests.\"\"\"",
            "",
            "    hostFallback: Optional[str] = None",
            "    \"\"\"Use this option to define an optional forced host under which to run OctoPrint. This should only be needed if you want to run OctoPrint behind a reverse proxy with a different hostname than OctoPrint itself but can't configure said reverse proxy to send a host HTTP header (X-Forwarded-Host by default, see above) with forwarded requests.\"\"\"",
            "",
            "    serverFallback: Optional[str] = None",
            "",
            "    portFallback: Optional[str] = None",
            "",
            "    trustedDownstream: List[str] = []",
            "    \"\"\"List of trusted downstream servers for which to ignore the IP address when trying to determine the connecting client's IP address. If you have OctoPrint behind more than one reverse proxy you should add their IPs here so that they won't be interpreted as the client's IP. One reverse proxy will be handled correctly by default.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class UploadsConfig(BaseModel):",
            "    maxSize: int = CONST_1GB",
            "    \"\"\"Maximum size of uploaded files in bytes, defaults to 1GB.\"\"\"",
            "",
            "    nameSuffix: str = \"name\"",
            "    \"\"\"Suffix used for storing the filename in the file upload headers when streaming uploads.\"\"\"",
            "",
            "    pathSuffix: str = \"path\"",
            "    \"\"\"Suffix used for storing the path to the temporary file in the file upload headers when streaming uploads.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class CommandsConfig(BaseModel):",
            "    systemShutdownCommand: Optional[str] = None",
            "    \"\"\"Command to shut down the system OctoPrint is running on.\"\"\"",
            "",
            "    systemRestartCommand: Optional[str] = None",
            "    \"\"\"Command to restart the system OctoPrint is running on.\"\"\"",
            "",
            "    serverRestartCommand: Optional[str] = None",
            "    \"\"\"Command to restart OctoPrint.\"\"\"",
            "",
            "    localPipCommand: Optional[str] = None",
            "    \"\"\"pip command associated with OctoPrint, used for installing plugins and updates, if unset (default) the command will be autodetected based on the current python executable - unless you have a really special setup this is the right way to do it and there should be no need to ever touch this setting.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class OnlineCheckConfig(BaseModel):",
            "    enabled: Optional[bool] = None",
            "    \"\"\"Whether the online check is enabled. Ships unset, the user will be asked to make a decision as part of the setup wizard.\"\"\"",
            "",
            "    interval: int = CONST_15MIN",
            "    \"\"\"Interval in which to check for online connectivity (in seconds), defaults to 15 minutes.\"\"\"",
            "",
            "    host: str = \"1.1.1.1\"",
            "    \"\"\"DNS host against which to check, defaults to Cloudflare's DNS.\"\"\"",
            "",
            "    port: int = 53",
            "    \"\"\"DNS port against which to check, defaults to the standard DNS port.\"\"\"",
            "",
            "    name: str = \"octoprint.org\"",
            "    \"\"\"Host name for which to check name resolution, defaults to OctoPrint's main domain.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class PluginBlacklistConfig(BaseModel):",
            "    enabled: Optional[bool] = None",
            "    \"\"\"Whether use of the blacklist is enabled. If unset, the user will be asked to make a decision as part of the setup wizard.\"\"\"",
            "",
            "    url: str = \"https://plugins.octoprint.org/blacklist.json\"",
            "    \"\"\"The URL from which to fetch the blacklist.\"\"\"",
            "",
            "    ttl: int = CONST_15MIN",
            "    \"\"\"Time to live of the cached blacklist, in seconds (default: 15 minutes).\"\"\"",
            "",
            "    timeout: float = 3.05",
            "    \"\"\"Timeout for fetching the blacklist, in seconds (default: 3.05 seconds).\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class DiskspaceConfig(BaseModel):",
            "    warning: int = CONST_500MB",
            "    \"\"\"Threshold (bytes) after which to consider disk space becoming sparse, defaults to 500MB.\"\"\"",
            "",
            "    critical: int = CONST_200MB",
            "    \"\"\"Threshold (bytes) after which to consider disk space becoming critical, defaults to 200MB.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class PreemptiveCacheConfig(BaseModel):",
            "    exceptions: List[str] = []",
            "    \"\"\"Which server paths to exclude from the preemptive cache, e.g. `/some/path`.\"\"\"",
            "",
            "    until: int = 7",
            "    \"\"\"How many days to leave unused entries in the preemptive cache config.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class IpCheckConfig(BaseModel):",
            "    enabled: bool = True",
            "    \"\"\"Whether to enable the check.\"\"\"",
            "",
            "    trustedSubnets: List[str] = []",
            "    \"\"\"Additional non-local subnets to consider trusted, in CIDR notation, e.g. `192.168.1.0/24`.\"\"\"",
            "",
            "",
            "class SameSiteEnum(str, Enum):",
            "    strict = \"Strict\"",
            "    lax = \"Lax\"",
            "    none = \"None\"",
            "",
            "",
            "@with_attrs_docs",
            "class CookiesConfig(BaseModel):",
            "    secure: bool = False",
            "    \"\"\"Whether to set the `Secure` flag to true on cookies. Only set to true if you are running OctoPrint behind a reverse proxy taking care of SSL termination.\"\"\"",
            "",
            "    samesite: Optional[SameSiteEnum] = SameSiteEnum.lax",
            "    \"\"\"`SameSite` setting to use on the cookies. Possible values are `None`, `Lax` and `Strict`. Defaults to `Lax`. Be advised that if forced unset, this has security implications as many browsers now default to `Lax` unless you configure cookies to be set with `Secure` flag set, explicitly set `SameSite` setting here and also serve OctoPrint over https. The `Lax` setting is known to cause with embedding OctoPrint in frames. See also [\"Feature: Cookies default to SameSite=Lax\"](https://www.chromestatus.com/feature/5088147346030592), [\"Feature: Reject insecure SameSite=None cookies\"](https://www.chromestatus.com/feature/5633521622188032) and [issue #3482](https://github.com/OctoPrint/OctoPrint/issues/3482).\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class ServerConfig(BaseModel):",
            "    host: Optional[str] = None",
            "    \"\"\"Use this option to define the host to which to bind the server. If unset, OctoPrint will attempt to bind on all available interfaces, IPv4 and v6 unless either is disabled.\"\"\"",
            "",
            "    port: int = 5000",
            "    \"\"\"Use this option to define the port to which to bind the server.\"\"\"",
            "",
            "    firstRun: bool = True",
            "    \"\"\"If this option is true, OctoPrint will show the First Run wizard and set the setting to false after that completes.\"\"\"",
            "",
            "    startOnceInSafeMode: bool = False",
            "    \"\"\"If this option is true, OctoPrint will enable safe mode on the next server start and reset the setting to false\"\"\"",
            "",
            "    ignoreIncompleteStartup: bool = False",
            "    \"\"\"Set this to true to make OctoPrint ignore incomplete startups. Helpful for development.\"\"\"",
            "",
            "    seenWizards: Dict[str, str] = {}",
            "",
            "    secretKey: Optional[str] = None",
            "    \"\"\"Secret key for encrypting cookies and such, randomly generated on first run.\"\"\"",
            "",
            "    heartbeat: int = CONST_15MIN",
            "",
            "    reverseProxy: ReverseProxyConfig = ReverseProxyConfig()",
            "    \"\"\"Settings if OctoPrint is running behind a reverse proxy (haproxy, nginx, apache, ...) that doesn't correctly set the [required headers](https://community.octoprint.org/t/reverse-proxy-configuration-examples/1107). These are necessary in order to make OctoPrint generate correct external URLs so that AJAX requests and download URLs work, and so that client IPs are read correctly.\"\"\"",
            "",
            "    uploads: UploadsConfig = UploadsConfig()",
            "    \"\"\"Settings for file uploads to OctoPrint, such as maximum allowed file size and header suffixes to use for streaming uploads. OctoPrint does some nifty things internally in order to allow streaming of large file uploads to the application rather than just storing them in memory. For that it needs to do some rewriting of the incoming upload HTTP requests, storing the uploaded file to a temporary location on disk and then sending an internal request to the application containing the original filename and the location of the temporary file.\"\"\"",
            "",
            "    maxSize: int = CONST_100KB",
            "    \"\"\"Maximum size of requests other than file uploads in bytes, defaults to 100KB.\"\"\"",
            "",
            "    commands: CommandsConfig = CommandsConfig()",
            "    \"\"\"Commands to restart/shutdown octoprint or the system it's running on.\"\"\"",
            "",
            "    onlineCheck: OnlineCheckConfig = OnlineCheckConfig()",
            "    \"\"\"Configuration of the regular online connectivity check.\"\"\"",
            "",
            "    pluginBlacklist: PluginBlacklistConfig = PluginBlacklistConfig()",
            "    \"\"\"Configuration of the plugin blacklist.\"\"\"",
            "",
            "    diskspace: DiskspaceConfig = DiskspaceConfig()",
            "    \"\"\"Settings of when to display what disk space warning.\"\"\"",
            "",
            "    preemptiveCache: PreemptiveCacheConfig = PreemptiveCacheConfig()",
            "    \"\"\"Configuration of the preemptive cache.\"\"\"",
            "",
            "    ipCheck: IpCheckConfig = IpCheckConfig()",
            "    \"\"\"Configuration of the client IP check to warn about connections from external networks.\"\"\"",
            "",
            "    allowFraming: bool = False",
            "    \"\"\"Whether to allow OctoPrint to be embedded in a frame or not. Note that depending on your setup you might have to set SameSite to None, Secure to true and serve OctoPrint through a reverse proxy that enables https for cookies and thus logging in to work.\"\"\"",
            "",
            "    cookies: CookiesConfig = CookiesConfig()",
            "    \"\"\"Settings for further configuration of the cookies that OctoPrint sets (login, remember me, ...).\"\"\"",
            "",
            "    allowedLoginRedirectPaths: List[str] = []",
            "    \"\"\"List of paths that are allowed to be used as redirect targets for the login page, in addition to the default ones (`/`, `/recovery/` and `/plugin/appkeys/auth/`)\"\"\""
        ],
        "afterPatchFile": [
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2022 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "from enum import Enum",
            "from typing import Dict, List, Optional",
            "",
            "from octoprint.schema import BaseModel",
            "from octoprint.vendor.with_attrs_docs import with_attrs_docs",
            "",
            "CONST_15MIN = 15 * 60",
            "CONST_1GB = 1024 * 1024 * 1024",
            "CONST_500MB = 500 * 1024 * 1024",
            "CONST_200MB = 200 * 1024 * 1024",
            "CONST_100KB = 100 * 1024",
            "",
            "",
            "@with_attrs_docs",
            "class ReverseProxyConfig(BaseModel):",
            "    prefixHeader: Optional[str] = None",
            "    \"\"\"The request header from which to determine the URL prefix under which OctoPrint is served by the reverse proxy.\"\"\"",
            "",
            "    schemeHeader: Optional[str] = None",
            "    \"\"\"The request header from which to determine the scheme (http or https) under which a specific request to OctoPrint was made to the reverse proxy.\"\"\"",
            "",
            "    hostHeader: Optional[str] = None",
            "    \"\"\"The request header from which to determine the host under which OctoPrint is served by the reverse proxy.\"\"\"",
            "",
            "    serverHeader: Optional[str] = None",
            "",
            "    portHeader: Optional[str] = None",
            "",
            "    prefixFallback: Optional[str] = None",
            "    \"\"\"Use this option to define an optional URL prefix (with a leading /, so absolute to your server's root) under which to run OctoPrint. This should only be needed if you want to run OctoPrint behind a reverse proxy under a different root endpoint than `/` and can't configure said reverse proxy to send a prefix HTTP header (X-Script-Name by default, see above) with forwarded requests.\"\"\"",
            "",
            "    schemeFallback: Optional[str] = None",
            "    \"\"\"Use this option to define an optional forced scheme (http or https) under which to run OctoPrint. This should only be needed if you want to run OctoPrint behind a reverse proxy that also does HTTPS determination but can't configure said reverse proxy to send a scheme HTTP header (X-Scheme by default, see above) with forwarded requests.\"\"\"",
            "",
            "    hostFallback: Optional[str] = None",
            "    \"\"\"Use this option to define an optional forced host under which to run OctoPrint. This should only be needed if you want to run OctoPrint behind a reverse proxy with a different hostname than OctoPrint itself but can't configure said reverse proxy to send a host HTTP header (X-Forwarded-Host by default, see above) with forwarded requests.\"\"\"",
            "",
            "    serverFallback: Optional[str] = None",
            "",
            "    portFallback: Optional[str] = None",
            "",
            "    trustedDownstream: List[str] = [\"127.0.0.1\", \"::1\"]",
            "    \"\"\"List of trusted downstream servers for which to ignore the IP address when trying to determine the connecting client's IP address. A reverse proxy on the same machine as OctoPrint (e.g. as found on OctoPi) will be handled correctly by default, further proxies in front of that you'll have to add yourself.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class UploadsConfig(BaseModel):",
            "    maxSize: int = CONST_1GB",
            "    \"\"\"Maximum size of uploaded files in bytes, defaults to 1GB.\"\"\"",
            "",
            "    nameSuffix: str = \"name\"",
            "    \"\"\"Suffix used for storing the filename in the file upload headers when streaming uploads.\"\"\"",
            "",
            "    pathSuffix: str = \"path\"",
            "    \"\"\"Suffix used for storing the path to the temporary file in the file upload headers when streaming uploads.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class CommandsConfig(BaseModel):",
            "    systemShutdownCommand: Optional[str] = None",
            "    \"\"\"Command to shut down the system OctoPrint is running on.\"\"\"",
            "",
            "    systemRestartCommand: Optional[str] = None",
            "    \"\"\"Command to restart the system OctoPrint is running on.\"\"\"",
            "",
            "    serverRestartCommand: Optional[str] = None",
            "    \"\"\"Command to restart OctoPrint.\"\"\"",
            "",
            "    localPipCommand: Optional[str] = None",
            "    \"\"\"pip command associated with OctoPrint, used for installing plugins and updates, if unset (default) the command will be autodetected based on the current python executable - unless you have a really special setup this is the right way to do it and there should be no need to ever touch this setting.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class OnlineCheckConfig(BaseModel):",
            "    enabled: Optional[bool] = None",
            "    \"\"\"Whether the online check is enabled. Ships unset, the user will be asked to make a decision as part of the setup wizard.\"\"\"",
            "",
            "    interval: int = CONST_15MIN",
            "    \"\"\"Interval in which to check for online connectivity (in seconds), defaults to 15 minutes.\"\"\"",
            "",
            "    host: str = \"1.1.1.1\"",
            "    \"\"\"DNS host against which to check, defaults to Cloudflare's DNS.\"\"\"",
            "",
            "    port: int = 53",
            "    \"\"\"DNS port against which to check, defaults to the standard DNS port.\"\"\"",
            "",
            "    name: str = \"octoprint.org\"",
            "    \"\"\"Host name for which to check name resolution, defaults to OctoPrint's main domain.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class PluginBlacklistConfig(BaseModel):",
            "    enabled: Optional[bool] = None",
            "    \"\"\"Whether use of the blacklist is enabled. If unset, the user will be asked to make a decision as part of the setup wizard.\"\"\"",
            "",
            "    url: str = \"https://plugins.octoprint.org/blacklist.json\"",
            "    \"\"\"The URL from which to fetch the blacklist.\"\"\"",
            "",
            "    ttl: int = CONST_15MIN",
            "    \"\"\"Time to live of the cached blacklist, in seconds (default: 15 minutes).\"\"\"",
            "",
            "    timeout: float = 3.05",
            "    \"\"\"Timeout for fetching the blacklist, in seconds (default: 3.05 seconds).\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class DiskspaceConfig(BaseModel):",
            "    warning: int = CONST_500MB",
            "    \"\"\"Threshold (bytes) after which to consider disk space becoming sparse, defaults to 500MB.\"\"\"",
            "",
            "    critical: int = CONST_200MB",
            "    \"\"\"Threshold (bytes) after which to consider disk space becoming critical, defaults to 200MB.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class PreemptiveCacheConfig(BaseModel):",
            "    exceptions: List[str] = []",
            "    \"\"\"Which server paths to exclude from the preemptive cache, e.g. `/some/path`.\"\"\"",
            "",
            "    until: int = 7",
            "    \"\"\"How many days to leave unused entries in the preemptive cache config.\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class IpCheckConfig(BaseModel):",
            "    enabled: bool = True",
            "    \"\"\"Whether to enable the check.\"\"\"",
            "",
            "    trustedSubnets: List[str] = []",
            "    \"\"\"Additional non-local subnets to consider trusted, in CIDR notation, e.g. `192.168.1.0/24`.\"\"\"",
            "",
            "",
            "class SameSiteEnum(str, Enum):",
            "    strict = \"Strict\"",
            "    lax = \"Lax\"",
            "    none = \"None\"",
            "",
            "",
            "@with_attrs_docs",
            "class CookiesConfig(BaseModel):",
            "    secure: bool = False",
            "    \"\"\"Whether to set the `Secure` flag to true on cookies. Only set to true if you are running OctoPrint behind a reverse proxy taking care of SSL termination.\"\"\"",
            "",
            "    samesite: Optional[SameSiteEnum] = SameSiteEnum.lax",
            "    \"\"\"`SameSite` setting to use on the cookies. Possible values are `None`, `Lax` and `Strict`. Defaults to `Lax`. Be advised that if forced unset, this has security implications as many browsers now default to `Lax` unless you configure cookies to be set with `Secure` flag set, explicitly set `SameSite` setting here and also serve OctoPrint over https. The `Lax` setting is known to cause with embedding OctoPrint in frames. See also [\"Feature: Cookies default to SameSite=Lax\"](https://www.chromestatus.com/feature/5088147346030592), [\"Feature: Reject insecure SameSite=None cookies\"](https://www.chromestatus.com/feature/5633521622188032) and [issue #3482](https://github.com/OctoPrint/OctoPrint/issues/3482).\"\"\"",
            "",
            "",
            "@with_attrs_docs",
            "class ServerConfig(BaseModel):",
            "    host: Optional[str] = None",
            "    \"\"\"Use this option to define the host to which to bind the server. If unset, OctoPrint will attempt to bind on all available interfaces, IPv4 and v6 unless either is disabled.\"\"\"",
            "",
            "    port: int = 5000",
            "    \"\"\"Use this option to define the port to which to bind the server.\"\"\"",
            "",
            "    firstRun: bool = True",
            "    \"\"\"If this option is true, OctoPrint will show the First Run wizard and set the setting to false after that completes.\"\"\"",
            "",
            "    startOnceInSafeMode: bool = False",
            "    \"\"\"If this option is true, OctoPrint will enable safe mode on the next server start and reset the setting to false\"\"\"",
            "",
            "    ignoreIncompleteStartup: bool = False",
            "    \"\"\"Set this to true to make OctoPrint ignore incomplete startups. Helpful for development.\"\"\"",
            "",
            "    seenWizards: Dict[str, str] = {}",
            "",
            "    secretKey: Optional[str] = None",
            "    \"\"\"Secret key for encrypting cookies and such, randomly generated on first run.\"\"\"",
            "",
            "    heartbeat: int = CONST_15MIN",
            "",
            "    reverseProxy: ReverseProxyConfig = ReverseProxyConfig()",
            "    \"\"\"Settings if OctoPrint is running behind a reverse proxy (haproxy, nginx, apache, ...) that doesn't correctly set the [required headers](https://community.octoprint.org/t/reverse-proxy-configuration-examples/1107). These are necessary in order to make OctoPrint generate correct external URLs so that AJAX requests and download URLs work, and so that client IPs are read correctly.\"\"\"",
            "",
            "    uploads: UploadsConfig = UploadsConfig()",
            "    \"\"\"Settings for file uploads to OctoPrint, such as maximum allowed file size and header suffixes to use for streaming uploads. OctoPrint does some nifty things internally in order to allow streaming of large file uploads to the application rather than just storing them in memory. For that it needs to do some rewriting of the incoming upload HTTP requests, storing the uploaded file to a temporary location on disk and then sending an internal request to the application containing the original filename and the location of the temporary file.\"\"\"",
            "",
            "    maxSize: int = CONST_100KB",
            "    \"\"\"Maximum size of requests other than file uploads in bytes, defaults to 100KB.\"\"\"",
            "",
            "    commands: CommandsConfig = CommandsConfig()",
            "    \"\"\"Commands to restart/shutdown octoprint or the system it's running on.\"\"\"",
            "",
            "    onlineCheck: OnlineCheckConfig = OnlineCheckConfig()",
            "    \"\"\"Configuration of the regular online connectivity check.\"\"\"",
            "",
            "    pluginBlacklist: PluginBlacklistConfig = PluginBlacklistConfig()",
            "    \"\"\"Configuration of the plugin blacklist.\"\"\"",
            "",
            "    diskspace: DiskspaceConfig = DiskspaceConfig()",
            "    \"\"\"Settings of when to display what disk space warning.\"\"\"",
            "",
            "    preemptiveCache: PreemptiveCacheConfig = PreemptiveCacheConfig()",
            "    \"\"\"Configuration of the preemptive cache.\"\"\"",
            "",
            "    ipCheck: IpCheckConfig = IpCheckConfig()",
            "    \"\"\"Configuration of the client IP check to warn about connections from external networks.\"\"\"",
            "",
            "    allowFraming: bool = False",
            "    \"\"\"Whether to allow OctoPrint to be embedded in a frame or not. Note that depending on your setup you might have to set SameSite to None, Secure to true and serve OctoPrint through a reverse proxy that enables https for cookies and thus logging in to work.\"\"\"",
            "",
            "    cookies: CookiesConfig = CookiesConfig()",
            "    \"\"\"Settings for further configuration of the cookies that OctoPrint sets (login, remember me, ...).\"\"\"",
            "",
            "    allowedLoginRedirectPaths: List[str] = []",
            "    \"\"\"List of paths that are allowed to be used as redirect targets for the login page, in addition to the default ones (`/`, `/recovery/` and `/plugin/appkeys/auth/`)\"\"\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "45": [
                "ReverseProxyConfig"
            ],
            "46": [
                "ReverseProxyConfig"
            ]
        },
        "addLocation": []
    },
    "src/octoprint/server/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 381,
                "PatchRowcode": "         util.tornado.fix_json_encode()"
            },
            "1": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": 382,
                "PatchRowcode": "         util.tornado.fix_websocket_check_origin()"
            },
            "2": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": 383,
                "PatchRowcode": "         util.tornado.enable_per_message_deflate_extension()"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 384,
                "PatchRowcode": "+        util.tornado.fix_tornado_xheader_handling()"
            },
            "4": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 385,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "         self._setup_mimetypes()"
            },
            "6": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 387,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import atexit",
            "import base64",
            "import functools",
            "import logging",
            "import logging.config",
            "import mimetypes",
            "import os",
            "import pathlib",
            "import re",
            "import signal",
            "import sys",
            "import time",
            "import uuid  # noqa: F401",
            "from collections import OrderedDict, defaultdict",
            "",
            "from babel import Locale",
            "from flask import (  # noqa: F401",
            "    Blueprint,",
            "    Flask,",
            "    Request,",
            "    Response,",
            "    current_app,",
            "    g,",
            "    make_response,",
            "    request,",
            "    session,",
            ")",
            "from flask_assets import Bundle, Environment",
            "from flask_babel import Babel, gettext, ngettext  # noqa: F401",
            "from flask_login import (  # noqa: F401",
            "    LoginManager,",
            "    current_user,",
            "    session_protected,",
            "    user_loaded_from_cookie,",
            "    user_logged_out,",
            ")",
            "from watchdog.observers import Observer",
            "from watchdog.observers.polling import PollingObserver",
            "from werkzeug.exceptions import HTTPException",
            "",
            "import octoprint.events",
            "import octoprint.filemanager",
            "import octoprint.util",
            "import octoprint.util.net",
            "from octoprint.server import util",
            "from octoprint.systemcommands import system_command_manager",
            "from octoprint.util.json import JsonEncoding",
            "from octoprint.vendor.flask_principal import (  # noqa: F401",
            "    AnonymousIdentity,",
            "    Identity,",
            "    Permission,",
            "    Principal,",
            "    RoleNeed,",
            "    UserNeed,",
            "    identity_changed,",
            "    identity_loaded,",
            ")",
            "from octoprint.vendor.sockjs.tornado import SockJSRouter",
            "",
            "try:",
            "    import fcntl",
            "except ImportError:",
            "    fcntl = None",
            "",
            "SUCCESS = {}",
            "NO_CONTENT = (\"\", 204, {\"Content-Type\": \"text/plain\"})",
            "NOT_MODIFIED = (\"Not Modified\", 304, {\"Content-Type\": \"text/plain\"})",
            "",
            "app = Flask(\"octoprint\")",
            "",
            "assets = None",
            "babel = None",
            "limiter = None",
            "debug = False",
            "safe_mode = False",
            "",
            "printer = None",
            "printerProfileManager = None",
            "fileManager = None",
            "slicingManager = None",
            "analysisQueue = None",
            "userManager = None",
            "permissionManager = None",
            "groupManager = None",
            "eventManager = None",
            "loginManager = None",
            "pluginManager = None",
            "pluginLifecycleManager = None",
            "preemptiveCache = None",
            "jsonEncoder = None",
            "jsonDecoder = None",
            "connectivityChecker = None",
            "environmentDetector = None",
            "",
            "",
            "class OctoPrintAnonymousIdentity(AnonymousIdentity):",
            "    def __init__(self):",
            "        super().__init__()",
            "",
            "        user = userManager.anonymous_user_factory()",
            "",
            "        self.provides.add(UserNeed(user.get_id()))",
            "        for need in user.needs:",
            "            self.provides.add(need)",
            "",
            "",
            "principals = Principal(app, anonymous_identity=OctoPrintAnonymousIdentity)",
            "",
            "import octoprint.access.groups as groups  # noqa: E402",
            "import octoprint.access.permissions as permissions  # noqa: E402",
            "",
            "# we set admin_permission to a GroupPermission with the default admin group",
            "admin_permission = octoprint.util.variable_deprecated(",
            "    \"admin_permission has been deprecated, \" \"please use individual Permissions instead\",",
            "    since=\"1.4.0\",",
            ")(groups.GroupPermission(groups.ADMIN_GROUP))",
            "",
            "# we set user_permission to a GroupPermission with the default user group",
            "user_permission = octoprint.util.variable_deprecated(",
            "    \"user_permission has been deprecated, \" \"please use individual Permissions instead\",",
            "    since=\"1.4.0\",",
            ")(groups.GroupPermission(groups.USER_GROUP))",
            "",
            "import octoprint._version  # noqa: E402",
            "import octoprint.access.groups as groups  # noqa: E402",
            "import octoprint.access.users as users  # noqa: E402",
            "import octoprint.events as events  # noqa: E402",
            "import octoprint.filemanager.analysis  # noqa: E402",
            "import octoprint.filemanager.storage  # noqa: E402",
            "import octoprint.plugin  # noqa: E402",
            "import octoprint.slicing  # noqa: E402",
            "import octoprint.timelapse  # noqa: E402",
            "",
            "# only import further octoprint stuff down here, as it might depend on things defined above to be initialized already",
            "from octoprint import __branch__, __display_version__, __revision__, __version__",
            "from octoprint.printer.profile import PrinterProfileManager",
            "from octoprint.printer.standard import Printer",
            "from octoprint.server.util import (",
            "    corsRequestHandler,",
            "    corsResponseHandler,",
            "    csrfRequestHandler,",
            "    loginFromApiKeyRequestHandler,",
            "    requireLoginRequestHandler,",
            ")",
            "from octoprint.server.util.flask import PreemptiveCache, validate_session_signature",
            "from octoprint.settings import settings",
            "",
            "VERSION = __version__",
            "BRANCH = __branch__",
            "DISPLAY_VERSION = __display_version__",
            "REVISION = __revision__",
            "",
            "LOCALES = []",
            "LANGUAGES = set()",
            "",
            "",
            "@identity_loaded.connect_via(app)",
            "def on_identity_loaded(sender, identity):",
            "    user = load_user(identity.id)",
            "    if user is None:",
            "        user = userManager.anonymous_user_factory()",
            "",
            "    identity.provides.add(UserNeed(user.get_id()))",
            "    for need in user.needs:",
            "        identity.provides.add(need)",
            "",
            "",
            "def _clear_identity(sender):",
            "    # Remove session keys set by Flask-Principal",
            "    for key in (\"identity.id\", \"identity.name\", \"identity.auth_type\"):",
            "        session.pop(key, None)",
            "",
            "    # switch to anonymous identity",
            "    identity_changed.send(sender, identity=AnonymousIdentity())",
            "",
            "",
            "@session_protected.connect_via(app)",
            "def on_session_protected(sender):",
            "    # session was deleted by session protection, that means the user is no more and we need to clear our identity",
            "    if session.get(\"remember\", None) == \"clear\":",
            "        _clear_identity(sender)",
            "",
            "",
            "@user_logged_out.connect_via(app)",
            "def on_user_logged_out(sender, user=None):",
            "    # user was logged out, clear identity",
            "    _clear_identity(sender)",
            "",
            "",
            "@user_loaded_from_cookie.connect_via(app)",
            "def on_user_loaded_from_cookie(sender, user=None):",
            "    if user:",
            "        session[\"login_mechanism\"] = util.LoginMechanism.REMEMBER_ME",
            "        session[\"credentials_seen\"] = False",
            "",
            "",
            "def load_user(id):",
            "    if id is None:",
            "        return None",
            "",
            "    if id == \"_api\":",
            "        return userManager.api_user_factory()",
            "",
            "    if session and \"usersession.id\" in session:",
            "        sessionid = session[\"usersession.id\"]",
            "    else:",
            "        sessionid = None",
            "",
            "    if session and \"usersession.signature\" in session:",
            "        sessionsig = session[\"usersession.signature\"]",
            "    else:",
            "        sessionsig = \"\"",
            "",
            "    if sessionid:",
            "        # session[\"_fresh\"] is False if the session comes from a remember me cookie,",
            "        # True if it came from a use of the login dialog",
            "        user = userManager.find_user(",
            "            userid=id, session=sessionid, fresh=session.get(\"_fresh\", False)",
            "        )",
            "    else:",
            "        user = userManager.find_user(userid=id)",
            "",
            "    if (",
            "        user",
            "        and user.is_active",
            "        and (not sessionid or validate_session_signature(sessionsig, id, sessionid))",
            "    ):",
            "        return user",
            "",
            "    return None",
            "",
            "",
            "def load_user_from_request(request):",
            "    user = None",
            "",
            "    if settings().getBoolean([\"accessControl\", \"trustBasicAuthentication\"]):",
            "        # Basic Authentication?",
            "        user = util.get_user_for_authorization_header(",
            "            request.headers.get(\"Authorization\")",
            "        )",
            "",
            "    if settings().getBoolean([\"accessControl\", \"trustRemoteUser\"]):",
            "        # Remote user header?",
            "        user = util.get_user_for_remote_user_header(request)",
            "",
            "    return user",
            "",
            "",
            "def unauthorized_user():",
            "    from flask import abort",
            "",
            "    abort(403)",
            "",
            "",
            "# ~~ startup code",
            "",
            "",
            "class Server:",
            "    def __init__(",
            "        self,",
            "        settings=None,",
            "        plugin_manager=None,",
            "        connectivity_checker=None,",
            "        environment_detector=None,",
            "        event_manager=None,",
            "        host=None,",
            "        port=None,",
            "        v6_only=False,",
            "        debug=False,",
            "        safe_mode=False,",
            "        allow_root=False,",
            "        octoprint_daemon=None,",
            "    ):",
            "        self._settings = settings",
            "        self._plugin_manager = plugin_manager",
            "        self._connectivity_checker = connectivity_checker",
            "        self._environment_detector = environment_detector",
            "        self._event_manager = event_manager",
            "        self._host = host",
            "        self._port = port",
            "        self._v6_only = v6_only",
            "        self._debug = debug",
            "        self._safe_mode = safe_mode",
            "        self._allow_root = allow_root",
            "        self._octoprint_daemon = octoprint_daemon",
            "        self._server = None",
            "",
            "        self._logger = None",
            "",
            "        self._lifecycle_callbacks = defaultdict(list)",
            "",
            "        self._intermediary_server = None",
            "",
            "    def run(self):",
            "        if not self._allow_root:",
            "            self._check_for_root()",
            "",
            "        if self._settings is None:",
            "            self._settings = settings()",
            "",
            "        incomplete_startup_flag = (",
            "            pathlib.Path(self._settings._basedir) / \".incomplete_startup\"",
            "        )",
            "        if not self._settings.getBoolean([\"server\", \"ignoreIncompleteStartup\"]):",
            "            try:",
            "                incomplete_startup_flag.touch()",
            "            except Exception:",
            "                self._logger.exception(\"Could not create startup triggered safemode flag\")",
            "",
            "        if self._plugin_manager is None:",
            "            self._plugin_manager = octoprint.plugin.plugin_manager()",
            "",
            "        global app",
            "        global babel",
            "",
            "        global printer",
            "        global printerProfileManager",
            "        global fileManager",
            "        global slicingManager",
            "        global analysisQueue",
            "        global userManager",
            "        global permissionManager",
            "        global groupManager",
            "        global eventManager",
            "        global loginManager",
            "        global pluginManager",
            "        global pluginLifecycleManager",
            "        global preemptiveCache",
            "        global jsonEncoder",
            "        global jsonDecoder",
            "        global connectivityChecker",
            "        global environmentDetector",
            "        global debug",
            "        global safe_mode",
            "",
            "        from tornado.ioloop import IOLoop",
            "        from tornado.web import Application",
            "",
            "        debug = self._debug",
            "        safe_mode = self._safe_mode",
            "",
            "        if safe_mode:",
            "            self._log_safe_mode_start(safe_mode)",
            "",
            "        if self._v6_only and not octoprint.util.net.HAS_V6:",
            "            raise RuntimeError(",
            "                \"IPv6 only mode configured but system doesn't support IPv6\"",
            "            )",
            "",
            "        if self._host is None:",
            "            host = self._settings.get([\"server\", \"host\"])",
            "            if host is None:",
            "                if octoprint.util.net.HAS_V6:",
            "                    host = \"::\"",
            "                else:",
            "                    host = \"0.0.0.0\"",
            "",
            "            self._host = host",
            "",
            "        if \":\" in self._host and not octoprint.util.net.HAS_V6:",
            "            raise RuntimeError(",
            "                \"IPv6 host address {!r} configured but system doesn't support IPv6\".format(",
            "                    self._host",
            "                )",
            "            )",
            "",
            "        if self._port is None:",
            "            self._port = self._settings.getInt([\"server\", \"port\"])",
            "            if self._port is None:",
            "                self._port = 5000",
            "",
            "        self._logger = logging.getLogger(__name__)",
            "        self._setup_heartbeat_logging()",
            "        pluginManager = self._plugin_manager",
            "",
            "        # monkey patch/fix some stuff",
            "        util.tornado.fix_json_encode()",
            "        util.tornado.fix_websocket_check_origin()",
            "        util.tornado.enable_per_message_deflate_extension()",
            "",
            "        self._setup_mimetypes()",
            "",
            "        # setup app",
            "        self._setup_app(app)",
            "",
            "        # setup i18n",
            "        additional_translation_folders = []",
            "        if not safe_mode:",
            "            additional_translation_folders += [",
            "                self._settings.getBaseFolder(\"translations\")",
            "            ]",
            "        self._setup_i18n(app, additional_folders=additional_translation_folders)",
            "",
            "        if self._settings.getBoolean([\"serial\", \"log\"]):",
            "            # enable debug logging to serial.log",
            "            logging.getLogger(\"SERIAL\").setLevel(logging.DEBUG)",
            "",
            "        if self._settings.getBoolean([\"devel\", \"pluginTimings\"]):",
            "            # enable plugin timings log",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").setLevel(logging.DEBUG)",
            "",
            "        # start the intermediary server",
            "        self._start_intermediary_server()",
            "",
            "        ### IMPORTANT!",
            "        ###",
            "        ### Best do not start any subprocesses until the intermediary server shuts down again or they MIGHT inherit the",
            "        ### open port and prevent us from firing up Tornado later.",
            "        ###",
            "        ### The intermediary server's socket should have the CLOSE_EXEC flag (or its equivalent) set where possible, but",
            "        ### we can only do that if fcntl is available or we are on Windows, so better safe than sorry.",
            "        ###",
            "        ### See also issues #2035 and #2090",
            "",
            "        systemCommandManager = system_command_manager()",
            "        printerProfileManager = PrinterProfileManager()",
            "        eventManager = self._event_manager",
            "",
            "        analysis_queue_factories = {",
            "            \"gcode\": octoprint.filemanager.analysis.GcodeAnalysisQueue",
            "        }",
            "        analysis_queue_hooks = pluginManager.get_hooks(",
            "            \"octoprint.filemanager.analysis.factory\"",
            "        )",
            "        for name, hook in analysis_queue_hooks.items():",
            "            try:",
            "                additional_factories = hook()",
            "                analysis_queue_factories.update(**additional_factories)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while processing analysis queues from {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "        analysisQueue = octoprint.filemanager.analysis.AnalysisQueue(",
            "            analysis_queue_factories",
            "        )",
            "",
            "        slicingManager = octoprint.slicing.SlicingManager(",
            "            self._settings.getBaseFolder(\"slicingProfiles\"), printerProfileManager",
            "        )",
            "",
            "        storage_managers = {}",
            "        storage_managers[",
            "            octoprint.filemanager.FileDestinations.LOCAL",
            "        ] = octoprint.filemanager.storage.LocalFileStorage(",
            "            self._settings.getBaseFolder(\"uploads\"),",
            "            really_universal=self._settings.getBoolean(",
            "                [\"feature\", \"enforceReallyUniversalFilenames\"]",
            "            ),",
            "        )",
            "",
            "        fileManager = octoprint.filemanager.FileManager(",
            "            analysisQueue,",
            "            slicingManager,",
            "            printerProfileManager,",
            "            initial_storage_managers=storage_managers,",
            "        )",
            "        pluginLifecycleManager = LifecycleManager(pluginManager)",
            "        preemptiveCache = PreemptiveCache(",
            "            os.path.join(",
            "                self._settings.getBaseFolder(\"data\"), \"preemptive_cache_config.yaml\"",
            "            )",
            "        )",
            "",
            "        JsonEncoding.add_encoder(users.User, lambda obj: obj.as_dict())",
            "        JsonEncoding.add_encoder(groups.Group, lambda obj: obj.as_dict())",
            "        JsonEncoding.add_encoder(",
            "            permissions.OctoPrintPermission, lambda obj: obj.as_dict()",
            "        )",
            "",
            "        # start regular check if we are connected to the internet",
            "        def on_connectivity_change(old_value, new_value):",
            "            eventManager.fire(",
            "                events.Events.CONNECTIVITY_CHANGED,",
            "                payload={\"old\": old_value, \"new\": new_value},",
            "            )",
            "",
            "        connectivityChecker = self._connectivity_checker",
            "        environmentDetector = self._environment_detector",
            "",
            "        def on_settings_update(*args, **kwargs):",
            "            # make sure our connectivity checker runs with the latest settings",
            "            connectivityEnabled = self._settings.getBoolean(",
            "                [\"server\", \"onlineCheck\", \"enabled\"]",
            "            )",
            "            connectivityInterval = self._settings.getInt(",
            "                [\"server\", \"onlineCheck\", \"interval\"]",
            "            )",
            "            connectivityHost = self._settings.get([\"server\", \"onlineCheck\", \"host\"])",
            "            connectivityPort = self._settings.getInt([\"server\", \"onlineCheck\", \"port\"])",
            "            connectivityName = self._settings.get([\"server\", \"onlineCheck\", \"name\"])",
            "",
            "            if (",
            "                connectivityChecker.enabled != connectivityEnabled",
            "                or connectivityChecker.interval != connectivityInterval",
            "                or connectivityChecker.host != connectivityHost",
            "                or connectivityChecker.port != connectivityPort",
            "                or connectivityChecker.name != connectivityName",
            "            ):",
            "                connectivityChecker.enabled = connectivityEnabled",
            "                connectivityChecker.interval = connectivityInterval",
            "                connectivityChecker.host = connectivityHost",
            "                connectivityChecker.port = connectivityPort",
            "                connectivityChecker.name = connectivityName",
            "                connectivityChecker.check_immediately()",
            "",
            "        eventManager.subscribe(events.Events.SETTINGS_UPDATED, on_settings_update)",
            "",
            "        components = {",
            "            \"plugin_manager\": pluginManager,",
            "            \"printer_profile_manager\": printerProfileManager,",
            "            \"event_bus\": eventManager,",
            "            \"analysis_queue\": analysisQueue,",
            "            \"slicing_manager\": slicingManager,",
            "            \"file_manager\": fileManager,",
            "            \"plugin_lifecycle_manager\": pluginLifecycleManager,",
            "            \"preemptive_cache\": preemptiveCache,",
            "            \"json_encoder\": jsonEncoder,",
            "            \"json_decoder\": jsonDecoder,",
            "            \"connectivity_checker\": connectivityChecker,",
            "            \"environment_detector\": self._environment_detector,",
            "            \"system_commands\": systemCommandManager,",
            "        }",
            "",
            "        # ~~ setup access control",
            "",
            "        # get additional permissions from plugins",
            "        self._setup_plugin_permissions()",
            "",
            "        # create group manager instance",
            "        group_manager_factories = pluginManager.get_hooks(",
            "            \"octoprint.access.groups.factory\"",
            "        )",
            "        for name, factory in group_manager_factories.items():",
            "            try:",
            "                groupManager = factory(components, self._settings)",
            "                if groupManager is not None:",
            "                    self._logger.debug(",
            "                        f\"Created group manager instance from factory {name}\"",
            "                    )",
            "                    break",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while creating group manager instance from factory {}\".format(",
            "                        name",
            "                    )",
            "                )",
            "        else:",
            "            group_manager_name = self._settings.get([\"accessControl\", \"groupManager\"])",
            "            try:",
            "                clazz = octoprint.util.get_class(group_manager_name)",
            "                groupManager = clazz()",
            "            except AttributeError:",
            "                self._logger.exception(",
            "                    \"Could not instantiate group manager {}, \"",
            "                    \"falling back to FilebasedGroupManager!\".format(group_manager_name)",
            "                )",
            "                groupManager = octoprint.access.groups.FilebasedGroupManager()",
            "        components.update({\"group_manager\": groupManager})",
            "",
            "        # create user manager instance",
            "        user_manager_factories = pluginManager.get_hooks(",
            "            \"octoprint.users.factory\"",
            "        )  # legacy, set first so that new wins",
            "        user_manager_factories.update(",
            "            pluginManager.get_hooks(\"octoprint.access.users.factory\")",
            "        )",
            "        for name, factory in user_manager_factories.items():",
            "            try:",
            "                userManager = factory(components, self._settings)",
            "                if userManager is not None:",
            "                    self._logger.debug(",
            "                        f\"Created user manager instance from factory {name}\"",
            "                    )",
            "                    break",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while creating user manager instance from factory {}\".format(",
            "                        name",
            "                    ),",
            "                    extra={\"plugin\": name},",
            "                )",
            "        else:",
            "            user_manager_name = self._settings.get([\"accessControl\", \"userManager\"])",
            "            try:",
            "                clazz = octoprint.util.get_class(user_manager_name)",
            "                userManager = clazz(groupManager)",
            "            except octoprint.access.users.CorruptUserStorage:",
            "                raise",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Could not instantiate user manager {}, \"",
            "                    \"falling back to FilebasedUserManager!\".format(user_manager_name)",
            "                )",
            "                userManager = octoprint.access.users.FilebasedUserManager(groupManager)",
            "        components.update({\"user_manager\": userManager})",
            "",
            "        # create printer instance",
            "        printer_factories = pluginManager.get_hooks(\"octoprint.printer.factory\")",
            "        for name, factory in printer_factories.items():",
            "            try:",
            "                printer = factory(components)",
            "                if printer is not None:",
            "                    self._logger.debug(f\"Created printer instance from factory {name}\")",
            "                    break",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while creating printer instance from factory {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "        else:",
            "            printer = Printer(fileManager, analysisQueue, printerProfileManager)",
            "        components.update({\"printer\": printer})",
            "",
            "        from octoprint import (",
            "            init_custom_events,",
            "            init_settings_plugin_config_migration_and_cleanup,",
            "            init_webcam_compat_overlay,",
            "        )",
            "        from octoprint import octoprint_plugin_inject_factory as opif",
            "        from octoprint import settings_plugin_inject_factory as spif",
            "",
            "        init_custom_events(pluginManager)",
            "",
            "        octoprint_plugin_inject_factory = opif(self._settings, components)",
            "        settings_plugin_inject_factory = spif(self._settings)",
            "",
            "        pluginManager.implementation_inject_factories = [",
            "            octoprint_plugin_inject_factory,",
            "            settings_plugin_inject_factory,",
            "        ]",
            "        pluginManager.initialize_implementations()",
            "",
            "        init_settings_plugin_config_migration_and_cleanup(pluginManager)",
            "        init_webcam_compat_overlay(self._settings, pluginManager)",
            "",
            "        pluginManager.log_all_plugins()",
            "",
            "        # log environment data now",
            "        self._environment_detector.log_detected_environment()",
            "",
            "        # initialize file manager and register it for changes in the registered plugins",
            "        fileManager.initialize()",
            "        pluginLifecycleManager.add_callback(",
            "            [\"enabled\", \"disabled\"], lambda name, plugin: fileManager.reload_plugins()",
            "        )",
            "",
            "        # initialize slicing manager and register it for changes in the registered plugins",
            "        slicingManager.initialize()",
            "        pluginLifecycleManager.add_callback(",
            "            [\"enabled\", \"disabled\"], lambda name, plugin: slicingManager.reload_slicers()",
            "        )",
            "",
            "        # setup jinja2",
            "        self._setup_jinja2()",
            "",
            "        # setup assets",
            "        self._setup_assets()",
            "",
            "        # configure timelapse",
            "        octoprint.timelapse.valid_timelapse(\"test\")",
            "        octoprint.timelapse.configure_timelapse()",
            "",
            "        # setup command triggers",
            "        events.CommandTrigger(printer)",
            "        if self._debug:",
            "            events.DebugEventListener()",
            "",
            "        # setup login manager",
            "        self._setup_login_manager()",
            "",
            "        # register API blueprint",
            "        self._setup_blueprints()",
            "",
            "        ## Tornado initialization starts here",
            "",
            "        ioloop = IOLoop.current()",
            "",
            "        enable_cors = settings().getBoolean([\"api\", \"allowCrossOrigin\"])",
            "",
            "        self._router = SockJSRouter(",
            "            self._create_socket_connection,",
            "            \"/sockjs\",",
            "            session_kls=util.sockjs.ThreadSafeSession,",
            "            user_settings={",
            "                \"websocket_allow_origin\": \"*\" if enable_cors else \"\",",
            "                \"jsessionid\": False,",
            "                \"sockjs_url\": \"../../static/js/lib/sockjs.min.js\",",
            "            },",
            "        )",
            "",
            "        upload_suffixes = {",
            "            \"name\": self._settings.get([\"server\", \"uploads\", \"nameSuffix\"]),",
            "            \"path\": self._settings.get([\"server\", \"uploads\", \"pathSuffix\"]),",
            "        }",
            "",
            "        def mime_type_guesser(path):",
            "            from octoprint.filemanager import get_mime_type",
            "",
            "            return get_mime_type(path)",
            "",
            "        def download_name_generator(path):",
            "            metadata = fileManager.get_metadata(\"local\", path)",
            "            if metadata and \"display\" in metadata:",
            "                return metadata[\"display\"]",
            "",
            "        download_handler_kwargs = {\"as_attachment\": True, \"allow_client_caching\": False}",
            "",
            "        additional_mime_types = {\"mime_type_guesser\": mime_type_guesser}",
            "",
            "        ##~~ Permission validators",
            "",
            "        access_validators_from_plugins = []",
            "        for plugin, hook in pluginManager.get_hooks(",
            "            \"octoprint.server.http.access_validator\"",
            "        ).items():",
            "            try:",
            "                access_validators_from_plugins.append(",
            "                    util.tornado.access_validation_factory(app, hook)",
            "                )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while adding tornado access validator from plugin {}\".format(",
            "                        plugin",
            "                    ),",
            "                    extra={\"plugin\": plugin},",
            "                )",
            "",
            "        timelapse_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app,",
            "                util.flask.permission_validator,",
            "                permissions.Permissions.TIMELAPSE_LIST,",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        download_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app,",
            "                util.flask.permission_validator,",
            "                permissions.Permissions.FILES_DOWNLOAD,",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        log_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app,",
            "                util.flask.permission_validator,",
            "                permissions.Permissions.PLUGIN_LOGGING_MANAGE,",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        camera_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app, util.flask.permission_validator, permissions.Permissions.WEBCAM",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        systeminfo_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app, util.flask.permission_validator, permissions.Permissions.SYSTEM",
            "            )",
            "        ] + access_validators_from_plugins",
            "",
            "        timelapse_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*timelapse_validators)",
            "        }",
            "        download_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*download_validators)",
            "        }",
            "        log_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*log_validators)",
            "        }",
            "        camera_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*camera_validators)",
            "        }",
            "        systeminfo_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*systeminfo_validators)",
            "        }",
            "",
            "        no_hidden_files_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: not octoprint.util.is_hidden_path(path), status_code=404",
            "            )",
            "        }",
            "",
            "        only_known_types_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: octoprint.filemanager.valid_file_type(",
            "                    os.path.basename(path)",
            "                ),",
            "                status_code=404,",
            "            )",
            "        }",
            "",
            "        valid_timelapse = lambda path: not octoprint.util.is_hidden_path(path) and (",
            "            octoprint.timelapse.valid_timelapse(path)",
            "            or octoprint.timelapse.valid_timelapse_thumbnail(path)",
            "        )",
            "        timelapse_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                valid_timelapse,",
            "                status_code=404,",
            "            )",
            "        }",
            "        timelapses_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: valid_timelapse(path)",
            "                and os.path.realpath(os.path.abspath(path)).startswith(",
            "                    settings().getBaseFolder(\"timelapse\")",
            "                ),",
            "                status_code=400,",
            "            )",
            "        }",
            "",
            "        valid_log = lambda path: not octoprint.util.is_hidden_path(",
            "            path",
            "        ) and path.endswith(\".log\")",
            "        log_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                valid_log,",
            "                status_code=404,",
            "            )",
            "        }",
            "        logs_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: valid_log(path)",
            "                and os.path.realpath(os.path.abspath(path)).startswith(",
            "                    settings().getBaseFolder(\"logs\")",
            "                ),",
            "                status_code=400,",
            "            )",
            "        }",
            "",
            "        def joined_dict(*dicts):",
            "            if not len(dicts):",
            "                return {}",
            "",
            "            joined = {}",
            "            for d in dicts:",
            "                joined.update(d)",
            "            return joined",
            "",
            "        util.tornado.RequestlessExceptionLoggingMixin.LOG_REQUEST = debug",
            "        util.tornado.CorsSupportMixin.ENABLE_CORS = enable_cors",
            "",
            "        server_routes = self._router.urls + [",
            "            # various downloads",
            "            # .mpg and .mp4 timelapses:",
            "            (",
            "                r\"/downloads/timelapse/(.*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                joined_dict(",
            "                    {\"path\": self._settings.getBaseFolder(\"timelapse\")},",
            "                    timelapse_permission_validator,",
            "                    download_handler_kwargs,",
            "                    timelapse_path_validator,",
            "                ),",
            "            ),",
            "            # zipped timelapse bundles",
            "            (",
            "                r\"/downloads/timelapses\",",
            "                util.tornado.DynamicZipBundleHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"as_attachment\": True,",
            "                        \"attachment_name\": \"octoprint-timelapses.zip\",",
            "                        \"path_processor\": lambda x: (",
            "                            x,",
            "                            os.path.join(self._settings.getBaseFolder(\"timelapse\"), x),",
            "                        ),",
            "                    },",
            "                    timelapse_permission_validator,",
            "                    timelapses_path_validator,",
            "                ),",
            "            ),",
            "            # uploaded printables",
            "            (",
            "                r\"/downloads/files/local/(.*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"path\": self._settings.getBaseFolder(\"uploads\"),",
            "                        \"as_attachment\": True,",
            "                        \"name_generator\": download_name_generator,",
            "                    },",
            "                    download_permission_validator,",
            "                    download_handler_kwargs,",
            "                    no_hidden_files_validator,",
            "                    only_known_types_validator,",
            "                    additional_mime_types,",
            "                ),",
            "            ),",
            "            # log files",
            "            (",
            "                r\"/downloads/logs/([^/]*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"path\": self._settings.getBaseFolder(\"logs\"),",
            "                        \"mime_type_guesser\": lambda *args, **kwargs: \"text/plain\",",
            "                        \"stream_body\": True,",
            "                    },",
            "                    download_handler_kwargs,",
            "                    log_permission_validator,",
            "                    log_path_validator,",
            "                ),",
            "            ),",
            "            # zipped log file bundles",
            "            (",
            "                r\"/downloads/logs\",",
            "                util.tornado.DynamicZipBundleHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"as_attachment\": True,",
            "                        \"attachment_name\": \"octoprint-logs.zip\",",
            "                        \"path_processor\": lambda x: (",
            "                            x,",
            "                            os.path.join(self._settings.getBaseFolder(\"logs\"), x),",
            "                        ),",
            "                    },",
            "                    log_permission_validator,",
            "                    logs_path_validator,",
            "                ),",
            "            ),",
            "            # system info bundle",
            "            (",
            "                r\"/downloads/systeminfo.zip\",",
            "                util.tornado.SystemInfoBundleHandler,",
            "                systeminfo_permission_validator,",
            "            ),",
            "            # camera snapshot",
            "            (",
            "                r\"/downloads/camera/current\",",
            "                util.tornado.WebcamSnapshotHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"as_attachment\": \"snapshot\",",
            "                    },",
            "                    camera_permission_validator,",
            "                ),",
            "            ),",
            "            # generated webassets",
            "            (",
            "                r\"/static/webassets/(.*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                {",
            "                    \"path\": os.path.join(",
            "                        self._settings.getBaseFolder(\"generated\"), \"webassets\"",
            "                    ),",
            "                    \"is_pre_compressed\": True,",
            "                },",
            "            ),",
            "            # online indicators - text file with \"online\" as content and a transparent gif",
            "            (r\"/online.txt\", util.tornado.StaticDataHandler, {\"data\": \"online\\n\"}),",
            "            (",
            "                r\"/online.gif\",",
            "                util.tornado.StaticDataHandler,",
            "                {",
            "                    \"data\": bytes(",
            "                        base64.b64decode(",
            "                            \"R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"",
            "                        )",
            "                    ),",
            "                    \"content_type\": \"image/gif\",",
            "                },",
            "            ),",
            "            # deprecated endpoints",
            "            (",
            "                r\"/api/logs\",",
            "                util.tornado.DeprecatedEndpointHandler,",
            "                {\"url\": \"/plugin/logging/logs\"},",
            "            ),",
            "            (",
            "                r\"/api/logs/(.*)\",",
            "                util.tornado.DeprecatedEndpointHandler,",
            "                {\"url\": \"/plugin/logging/logs/{0}\"},",
            "            ),",
            "        ]",
            "",
            "        # fetch additional routes from plugins",
            "        for name, hook in pluginManager.get_hooks(\"octoprint.server.http.routes\").items():",
            "            try:",
            "                result = hook(list(server_routes))",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"There was an error while retrieving additional \"",
            "                    f\"server routes from plugin hook {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "            else:",
            "                if isinstance(result, (list, tuple)):",
            "                    for entry in result:",
            "                        if not isinstance(entry, tuple) or not len(entry) == 3:",
            "                            continue",
            "                        if not isinstance(entry[0], str):",
            "                            continue",
            "                        if not isinstance(entry[2], dict):",
            "                            continue",
            "",
            "                        route, handler, kwargs = entry",
            "                        route = r\"/plugin/{name}/{route}\".format(",
            "                            name=name,",
            "                            route=route if not route.startswith(\"/\") else route[1:],",
            "                        )",
            "",
            "                        self._logger.debug(",
            "                            f\"Adding additional route {route} handled by handler {handler} and with additional arguments {kwargs!r}\"",
            "                        )",
            "                        server_routes.append((route, handler, kwargs))",
            "",
            "        headers = {",
            "            \"X-Robots-Tag\": \"noindex, nofollow, noimageindex\",",
            "            \"X-Content-Type-Options\": \"nosniff\",",
            "        }",
            "        if not settings().getBoolean([\"server\", \"allowFraming\"]):",
            "            headers[\"X-Frame-Options\"] = \"sameorigin\"",
            "",
            "        removed_headers = [\"Server\"]",
            "",
            "        from concurrent.futures import ThreadPoolExecutor",
            "",
            "        server_routes.append(",
            "            (",
            "                r\".*\",",
            "                util.tornado.UploadStorageFallbackHandler,",
            "                {",
            "                    \"fallback\": util.tornado.WsgiInputContainer(",
            "                        app.wsgi_app,",
            "                        executor=ThreadPoolExecutor(",
            "                            thread_name_prefix=\"WsgiRequestHandler\"",
            "                        ),",
            "                        headers=headers,",
            "                        removed_headers=removed_headers,",
            "                    ),",
            "                    \"file_prefix\": \"octoprint-file-upload-\",",
            "                    \"file_suffix\": \".tmp\",",
            "                    \"suffixes\": upload_suffixes,",
            "                },",
            "            )",
            "        )",
            "",
            "        transforms = [",
            "            util.tornado.GlobalHeaderTransform.for_headers(",
            "                \"OctoPrintGlobalHeaderTransform\",",
            "                headers=headers,",
            "                removed_headers=removed_headers,",
            "            )",
            "        ]",
            "",
            "        self._tornado_app = Application(handlers=server_routes, transforms=transforms)",
            "        max_body_sizes = [",
            "            (",
            "                \"POST\",",
            "                r\"/api/files/([^/]*)\",",
            "                self._settings.getInt([\"server\", \"uploads\", \"maxSize\"]),",
            "            ),",
            "            (\"POST\", r\"/api/languages\", 5 * 1024 * 1024),",
            "        ]",
            "",
            "        # allow plugins to extend allowed maximum body sizes",
            "        for name, hook in pluginManager.get_hooks(",
            "            \"octoprint.server.http.bodysize\"",
            "        ).items():",
            "            try:",
            "                result = hook(list(max_body_sizes))",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"There was an error while retrieving additional \"",
            "                    f\"upload sizes from plugin hook {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "            else:",
            "                if isinstance(result, (list, tuple)):",
            "                    for entry in result:",
            "                        if not isinstance(entry, tuple) or not len(entry) == 3:",
            "                            continue",
            "                        if (",
            "                            entry[0]",
            "                            not in util.tornado.UploadStorageFallbackHandler.BODY_METHODS",
            "                        ):",
            "                            continue",
            "                        if not isinstance(entry[2], int):",
            "                            continue",
            "",
            "                        method, route, size = entry",
            "                        route = r\"/plugin/{name}/{route}\".format(",
            "                            name=name,",
            "                            route=route if not route.startswith(\"/\") else route[1:],",
            "                        )",
            "",
            "                        self._logger.debug(",
            "                            f\"Adding maximum body size of {size}B for {method} requests to {route})\"",
            "                        )",
            "                        max_body_sizes.append((method, route, size))",
            "",
            "        self._stop_intermediary_server()",
            "",
            "        # initialize and bind the server",
            "        trusted_downstream = self._settings.get(",
            "            [\"server\", \"reverseProxy\", \"trustedDownstream\"]",
            "        )",
            "        if not isinstance(trusted_downstream, list):",
            "            self._logger.warning(",
            "                \"server.reverseProxy.trustedDownstream is not a list, skipping\"",
            "            )",
            "            trusted_downstream = []",
            "",
            "        server_kwargs = {",
            "            \"max_body_sizes\": max_body_sizes,",
            "            \"default_max_body_size\": self._settings.getInt([\"server\", \"maxSize\"]),",
            "            \"xheaders\": True,",
            "            \"trusted_downstream\": trusted_downstream,",
            "        }",
            "        if sys.platform == \"win32\":",
            "            # set 10min idle timeout under windows to hopefully make #2916 less likely",
            "            server_kwargs.update({\"idle_connection_timeout\": 600})",
            "",
            "        self._server = util.tornado.CustomHTTPServer(self._tornado_app, **server_kwargs)",
            "",
            "        listening_address = self._host",
            "        if self._host == \"::\" and not self._v6_only:",
            "            # special case - tornado only listens on v4 _and_ v6 if we use None as address",
            "            listening_address = None",
            "",
            "        self._server.listen(self._port, address=listening_address)",
            "",
            "        ### From now on it's ok to launch subprocesses again",
            "",
            "        eventManager.fire(events.Events.STARTUP)",
            "",
            "        # analysis backlog",
            "        fileManager.process_backlog()",
            "",
            "        # auto connect",
            "        if self._settings.getBoolean([\"serial\", \"autoconnect\"]):",
            "            self._logger.info(",
            "                \"Autoconnect on startup is configured, trying to connect to the printer...\"",
            "            )",
            "            try:",
            "                (port, baudrate) = (",
            "                    self._settings.get([\"serial\", \"port\"]),",
            "                    self._settings.getInt([\"serial\", \"baudrate\"]),",
            "                )",
            "                printer_profile = printerProfileManager.get_default()",
            "                connectionOptions = printer.__class__.get_connection_options()",
            "                if port in connectionOptions[\"ports\"] or port == \"AUTO\" or port is None:",
            "                    self._logger.info(",
            "                        f\"Trying to connect to configured serial port {port}\"",
            "                    )",
            "                    printer.connect(",
            "                        port=port,",
            "                        baudrate=baudrate,",
            "                        profile=printer_profile[\"id\"]",
            "                        if \"id\" in printer_profile",
            "                        else \"_default\",",
            "                    )",
            "                else:",
            "                    self._logger.info(",
            "                        \"Could not find configured serial port {} in the system, cannot automatically connect to a non existing printer. Is it plugged in and booted up yet?\"",
            "                    )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Something went wrong while attempting to automatically connect to the printer\"",
            "                )",
            "",
            "        # auto refresh serial ports while not connected",
            "        if self._settings.getBoolean([\"serial\", \"autorefresh\"]):",
            "            from octoprint.util.comm import serialList",
            "",
            "            last_ports = None",
            "            autorefresh = None",
            "",
            "            def refresh_serial_list():",
            "                nonlocal last_ports",
            "",
            "                new_ports = sorted(serialList())",
            "                if new_ports != last_ports:",
            "                    self._logger.info(",
            "                        \"Serial port list was updated, refreshing the port list in the frontend\"",
            "                    )",
            "                    eventManager.fire(",
            "                        events.Events.CONNECTIONS_AUTOREFRESHED,",
            "                        payload={\"ports\": new_ports},",
            "                    )",
            "                last_ports = new_ports",
            "",
            "            def autorefresh_active():",
            "                return printer.is_closed_or_error()",
            "",
            "            def autorefresh_stopped():",
            "                nonlocal autorefresh",
            "",
            "                self._logger.info(\"Autorefresh of serial port list stopped\")",
            "                autorefresh = None",
            "",
            "            def run_autorefresh():",
            "                nonlocal autorefresh",
            "",
            "                if autorefresh is not None:",
            "                    autorefresh.cancel()",
            "                    autorefresh = None",
            "",
            "                autorefresh = octoprint.util.RepeatedTimer(",
            "                    self._settings.getInt([\"serial\", \"autorefreshInterval\"]),",
            "                    refresh_serial_list,",
            "                    run_first=True,",
            "                    condition=autorefresh_active,",
            "                    on_finish=autorefresh_stopped,",
            "                )",
            "                autorefresh.name = \"Serial autorefresh worker\"",
            "",
            "                self._logger.info(\"Starting autorefresh of serial port list\")",
            "                autorefresh.start()",
            "",
            "            run_autorefresh()",
            "            eventManager.subscribe(",
            "                octoprint.events.Events.DISCONNECTED, lambda e, p: run_autorefresh()",
            "            )",
            "",
            "        # start up watchdogs",
            "        try:",
            "            watched = self._settings.getBaseFolder(\"watched\")",
            "            watchdog_handler = util.watchdog.GcodeWatchdogHandler(fileManager, printer)",
            "            watchdog_handler.initial_scan(watched)",
            "",
            "            if self._settings.getBoolean([\"feature\", \"pollWatched\"]):",
            "                # use less performant polling observer if explicitly configured",
            "                observer = PollingObserver()",
            "            else:",
            "                # use os default",
            "                observer = Observer()",
            "",
            "            observer.schedule(watchdog_handler, watched, recursive=True)",
            "            observer.start()",
            "        except Exception:",
            "            self._logger.exception(\"Error starting watched folder observer\")",
            "",
            "        # run our startup plugins",
            "        octoprint.plugin.call_plugin(",
            "            octoprint.plugin.StartupPlugin,",
            "            \"on_startup\",",
            "            args=(self._host, self._port),",
            "            sorting_context=\"StartupPlugin.on_startup\",",
            "        )",
            "",
            "        def call_on_startup(name, plugin):",
            "            implementation = plugin.get_implementation(octoprint.plugin.StartupPlugin)",
            "            if implementation is None:",
            "                return",
            "            implementation.on_startup(self._host, self._port)",
            "",
            "        pluginLifecycleManager.add_callback(\"enabled\", call_on_startup)",
            "",
            "        # prepare our after startup function",
            "        def on_after_startup():",
            "            if self._host == \"::\":",
            "                if self._v6_only:",
            "                    # only v6",
            "                    self._logger.info(f\"Listening on http://[::]:{self._port}\")",
            "                else:",
            "                    # all v4 and v6",
            "                    self._logger.info(",
            "                        \"Listening on http://0.0.0.0:{port} and http://[::]:{port}\".format(",
            "                            port=self._port",
            "                        )",
            "                    )",
            "            else:",
            "                self._logger.info(",
            "                    \"Listening on http://{}:{}\".format(",
            "                        self._host if \":\" not in self._host else \"[\" + self._host + \"]\",",
            "                        self._port,",
            "                    )",
            "                )",
            "",
            "            if safe_mode and self._settings.getBoolean([\"server\", \"startOnceInSafeMode\"]):",
            "                self._logger.info(",
            "                    \"Server started successfully in safe mode as requested from config, removing flag\"",
            "                )",
            "                self._settings.setBoolean([\"server\", \"startOnceInSafeMode\"], False)",
            "                self._settings.save()",
            "",
            "            # now this is somewhat ugly, but the issue is the following: startup plugins might want to do things for",
            "            # which they need the server to be already alive (e.g. for being able to resolve urls, such as favicons",
            "            # or service xmls or the like). While they are working though the ioloop would block. Therefore we'll",
            "            # create a single use thread in which to perform our after-startup-tasks, start that and hand back",
            "            # control to the ioloop",
            "            def work():",
            "                octoprint.plugin.call_plugin(",
            "                    octoprint.plugin.StartupPlugin,",
            "                    \"on_after_startup\",",
            "                    sorting_context=\"StartupPlugin.on_after_startup\",",
            "                )",
            "",
            "                def call_on_after_startup(name, plugin):",
            "                    implementation = plugin.get_implementation(",
            "                        octoprint.plugin.StartupPlugin",
            "                    )",
            "                    if implementation is None:",
            "                        return",
            "                    implementation.on_after_startup()",
            "",
            "                pluginLifecycleManager.add_callback(\"enabled\", call_on_after_startup)",
            "",
            "                # if there was a rogue plugin we wouldn't even have made it here, so remove startup triggered safe mode",
            "                # flag again...",
            "                try:",
            "                    if incomplete_startup_flag.exists():",
            "                        incomplete_startup_flag.unlink()",
            "                except Exception:",
            "                    self._logger.exception(",
            "                        \"Could not clear startup triggered safe mode flag\"",
            "                    )",
            "",
            "                # make a backup of the current config",
            "                self._settings.backup(ext=\"backup\")",
            "",
            "                # when we are through with that we also run our preemptive cache",
            "                if settings().getBoolean([\"devel\", \"cache\", \"preemptive\"]):",
            "                    self._execute_preemptive_flask_caching(preemptiveCache)",
            "",
            "            import threading",
            "",
            "            threading.Thread(target=work).start()",
            "",
            "        ioloop.add_callback(on_after_startup)",
            "",
            "        # prepare our shutdown function",
            "        def on_shutdown():",
            "            # will be called on clean system exit and shutdown the watchdog observer and call the on_shutdown methods",
            "            # on all registered ShutdownPlugins",
            "            self._logger.info(\"Shutting down...\")",
            "            observer.stop()",
            "            observer.join()",
            "            eventManager.fire(events.Events.SHUTDOWN)",
            "",
            "            self._logger.info(\"Calling on_shutdown on plugins\")",
            "            octoprint.plugin.call_plugin(",
            "                octoprint.plugin.ShutdownPlugin,",
            "                \"on_shutdown\",",
            "                sorting_context=\"ShutdownPlugin.on_shutdown\",",
            "            )",
            "",
            "            # wait for shutdown event to be processed, but maximally for 15s",
            "            event_timeout = 15.0",
            "            if eventManager.join(timeout=event_timeout):",
            "                self._logger.warning(",
            "                    \"Event loop was still busy processing after {}s, shutting down anyhow\".format(",
            "                        event_timeout",
            "                    )",
            "                )",
            "",
            "            if self._octoprint_daemon is not None:",
            "                self._logger.info(\"Cleaning up daemon pidfile\")",
            "                self._octoprint_daemon.terminated()",
            "",
            "            self._logger.info(\"Goodbye!\")",
            "",
            "        atexit.register(on_shutdown)",
            "",
            "        def sigterm_handler(*args, **kwargs):",
            "            # will stop tornado on SIGTERM, making the program exit cleanly",
            "            def shutdown_tornado():",
            "                self._logger.debug(\"Shutting down tornado's IOLoop...\")",
            "                ioloop.stop()",
            "",
            "            self._logger.debug(\"SIGTERM received...\")",
            "            ioloop.add_callback_from_signal(shutdown_tornado)",
            "",
            "        signal.signal(signal.SIGTERM, sigterm_handler)",
            "",
            "        try:",
            "            # this is the main loop - as long as tornado is running, OctoPrint is running",
            "            ioloop.start()",
            "            self._logger.debug(\"Tornado's IOLoop stopped\")",
            "        except (KeyboardInterrupt, SystemExit):",
            "            pass",
            "        except Exception:",
            "            self._logger.fatal(",
            "                \"Now that is embarrassing... Something went really really wrong here. Please report this including the stacktrace below in OctoPrint's bugtracker. Thanks!\"",
            "            )",
            "            self._logger.exception(\"Stacktrace follows:\")",
            "",
            "    def _log_safe_mode_start(self, self_mode):",
            "        self_mode_file = os.path.join(",
            "            self._settings.getBaseFolder(\"data\"), \"last_safe_mode\"",
            "        )",
            "        try:",
            "            with open(self_mode_file, \"w+\", encoding=\"utf-8\") as f:",
            "                f.write(self_mode)",
            "        except Exception as ex:",
            "            self._logger.warn(f\"Could not write safe mode file {self_mode_file}: {ex}\")",
            "",
            "    def _create_socket_connection(self, session):",
            "        global printer, fileManager, analysisQueue, userManager, eventManager, connectivityChecker",
            "        return util.sockjs.PrinterStateConnection(",
            "            printer,",
            "            fileManager,",
            "            analysisQueue,",
            "            userManager,",
            "            groupManager,",
            "            eventManager,",
            "            pluginManager,",
            "            connectivityChecker,",
            "            session,",
            "        )",
            "",
            "    def _check_for_root(self):",
            "        if \"geteuid\" in dir(os) and os.geteuid() == 0:",
            "            exit(\"You should not run OctoPrint as root!\")",
            "",
            "    def _get_locale(self):",
            "        global LANGUAGES",
            "",
            "        l10n = None",
            "        default_language = self._settings.get([\"appearance\", \"defaultLanguage\"])",
            "",
            "        if \"l10n\" in request.values:",
            "            # request: query param",
            "            l10n = request.values[\"l10n\"].split(\",\")",
            "",
            "        elif \"X-Locale\" in request.headers:",
            "            # request: header",
            "            l10n = request.headers[\"X-Locale\"].split(\",\")",
            "",
            "        elif hasattr(g, \"identity\") and g.identity:",
            "            # user setting",
            "            userid = g.identity.id",
            "            try:",
            "                user_language = userManager.get_user_setting(",
            "                    userid, (\"interface\", \"language\")",
            "                )",
            "                if user_language is not None and not user_language == \"_default\":",
            "                    l10n = [user_language]",
            "            except octoprint.access.users.UnknownUser:",
            "                pass",
            "",
            "        if (",
            "            not l10n",
            "            and default_language is not None",
            "            and not default_language == \"_default\"",
            "            and default_language in LANGUAGES",
            "        ):",
            "            # instance setting",
            "            l10n = [default_language]",
            "",
            "        if l10n:",
            "            # canonicalize and get rid of invalid language codes",
            "            l10n_canonicalized = []",
            "            for x in l10n:",
            "                try:",
            "                    l10n_canonicalized.append(str(Locale.parse(x)))",
            "                except Exception:",
            "                    # invalid language code, ignore",
            "                    continue",
            "            return Locale.negotiate(l10n_canonicalized, LANGUAGES)",
            "",
            "        # request: preference",
            "        return Locale.parse(request.accept_languages.best_match(LANGUAGES, default=\"en\"))",
            "",
            "    def _setup_heartbeat_logging(self):",
            "        logger = logging.getLogger(__name__ + \".heartbeat\")",
            "",
            "        def log_heartbeat():",
            "            logger.info(\"Server heartbeat <3\")",
            "",
            "        interval = settings().getFloat([\"server\", \"heartbeat\"])",
            "        logger.info(f\"Starting server heartbeat, {interval}s interval\")",
            "",
            "        timer = octoprint.util.RepeatedTimer(interval, log_heartbeat)",
            "        timer.start()",
            "",
            "    def _setup_app(self, app):",
            "        global limiter",
            "",
            "        from octoprint.server.util.flask import (",
            "            OctoPrintFlaskRequest,",
            "            OctoPrintFlaskResponse,",
            "            OctoPrintJsonProvider,",
            "            OctoPrintSessionInterface,",
            "            PrefixAwareJinjaEnvironment,",
            "            ReverseProxiedEnvironment,",
            "        )",
            "",
            "        # we must set this here because setting app.debug will access app.jinja_env",
            "        app.jinja_environment = PrefixAwareJinjaEnvironment",
            "",
            "        app.config[\"TEMPLATES_AUTO_RELOAD\"] = True",
            "        app.config[\"REMEMBER_COOKIE_DURATION\"] = 90 * 24 * 60 * 60  # 90 days",
            "        app.config[\"REMEMBER_COOKIE_HTTPONLY\"] = True",
            "        # REMEMBER_COOKIE_SECURE will be taken care of by our custom cookie handling",
            "",
            "        # we must not set this before TEMPLATES_AUTO_RELOAD is set to True or that won't take",
            "        app.debug = self._debug",
            "",
            "        # setup octoprint's flask json serialization/deserialization",
            "        app.json = OctoPrintJsonProvider(app)",
            "        app.json.compact = False",
            "",
            "        s = settings()",
            "",
            "        secret_key = s.get([\"server\", \"secretKey\"])",
            "        if not secret_key:",
            "            import string",
            "            from random import choice",
            "",
            "            chars = string.ascii_lowercase + string.ascii_uppercase + string.digits",
            "            secret_key = \"\".join(choice(chars) for _ in range(32))",
            "            s.set([\"server\", \"secretKey\"], secret_key)",
            "            s.save()",
            "",
            "        app.secret_key = secret_key",
            "",
            "        reverse_proxied = ReverseProxiedEnvironment(",
            "            header_prefix=s.get([\"server\", \"reverseProxy\", \"prefixHeader\"]),",
            "            header_scheme=s.get([\"server\", \"reverseProxy\", \"schemeHeader\"]),",
            "            header_host=s.get([\"server\", \"reverseProxy\", \"hostHeader\"]),",
            "            header_server=s.get([\"server\", \"reverseProxy\", \"serverHeader\"]),",
            "            header_port=s.get([\"server\", \"reverseProxy\", \"portHeader\"]),",
            "            prefix=s.get([\"server\", \"reverseProxy\", \"prefixFallback\"]),",
            "            scheme=s.get([\"server\", \"reverseProxy\", \"schemeFallback\"]),",
            "            host=s.get([\"server\", \"reverseProxy\", \"hostFallback\"]),",
            "            server=s.get([\"server\", \"reverseProxy\", \"serverFallback\"]),",
            "            port=s.get([\"server\", \"reverseProxy\", \"portFallback\"]),",
            "        )",
            "",
            "        OctoPrintFlaskRequest.environment_wrapper = reverse_proxied",
            "        app.request_class = OctoPrintFlaskRequest",
            "        app.response_class = OctoPrintFlaskResponse",
            "        app.session_interface = OctoPrintSessionInterface()",
            "",
            "        @app.before_request",
            "        def before_request():",
            "            g.locale = self._get_locale()",
            "",
            "            # used for performance measurement",
            "            g.start_time = time.monotonic()",
            "",
            "            if self._debug and \"perfprofile\" in request.args:",
            "                try:",
            "                    from pyinstrument import Profiler",
            "",
            "                    g.perfprofiler = Profiler()",
            "                    g.perfprofiler.start()",
            "                except ImportError:",
            "                    # profiler dependency not installed, ignore",
            "                    pass",
            "",
            "        @app.after_request",
            "        def after_request(response):",
            "            # send no-cache headers with all POST responses",
            "            if request.method == \"POST\":",
            "                response.cache_control.no_cache = True",
            "",
            "            response.headers.add(\"X-Clacks-Overhead\", \"GNU Terry Pratchett\")",
            "",
            "            if hasattr(g, \"perfprofiler\"):",
            "                g.perfprofiler.stop()",
            "                output_html = g.perfprofiler.output_html()",
            "                return make_response(output_html)",
            "",
            "            if hasattr(g, \"start_time\"):",
            "                end_time = time.monotonic()",
            "                duration_ms = int((end_time - g.start_time) * 1000)",
            "                response.headers.add(\"Server-Timing\", f\"app;dur={duration_ms}\")",
            "",
            "            return response",
            "",
            "        from octoprint.util.jinja import MarkdownFilter",
            "",
            "        MarkdownFilter(app)",
            "",
            "        from flask_limiter import Limiter",
            "        from flask_limiter.util import get_remote_address",
            "",
            "        app.config[\"RATELIMIT_STRATEGY\"] = \"fixed-window-elastic-expiry\"",
            "",
            "        limiter = Limiter(",
            "            key_func=get_remote_address,",
            "            app=app,",
            "            enabled=s.getBoolean([\"devel\", \"enableRateLimiter\"]),",
            "            storage_uri=\"memory://\",",
            "        )",
            "",
            "    def _setup_i18n(self, app, additional_folders=None):",
            "        global babel",
            "        global LOCALES",
            "        global LANGUAGES",
            "",
            "        if additional_folders is None:",
            "            additional_folders = []",
            "",
            "        dirs = additional_folders + [os.path.join(app.root_path, \"translations\")]",
            "",
            "        # translations from plugins",
            "        plugins = octoprint.plugin.plugin_manager().enabled_plugins",
            "        for plugin in plugins.values():",
            "            plugin_translation_dir = os.path.join(plugin.location, \"translations\")",
            "            if not os.path.isdir(plugin_translation_dir):",
            "                continue",
            "            dirs.append(plugin_translation_dir)",
            "",
            "        app.config[\"BABEL_TRANSLATION_DIRECTORIES\"] = \";\".join(dirs)",
            "",
            "        babel = Babel(app, locale_selector=self._get_locale)",
            "",
            "        def get_available_locale_identifiers(locales):",
            "            result = set()",
            "",
            "            # add available translations",
            "            for locale in locales:",
            "                result.add(str(locale))",
            "",
            "            return result",
            "",
            "        with app.app_context():",
            "            LOCALES = babel.list_translations()",
            "        LANGUAGES = get_available_locale_identifiers(LOCALES)",
            "",
            "    def _setup_jinja2(self):",
            "        import re",
            "",
            "        app.jinja_env.add_extension(\"jinja2.ext.do\")",
            "        app.jinja_env.add_extension(\"octoprint.util.jinja.trycatch\")",
            "",
            "        def regex_replace(s, find, replace):",
            "            return re.sub(find, replace, s)",
            "",
            "        html_header_regex = re.compile(",
            "            r\"<h(?P<number>[1-6])>(?P<content>.*?)</h(?P=number)>\"",
            "        )",
            "",
            "        def offset_html_headers(s, offset):",
            "            def repl(match):",
            "                number = int(match.group(\"number\"))",
            "                number += offset",
            "                if number > 6:",
            "                    number = 6",
            "                elif number < 1:",
            "                    number = 1",
            "                return \"<h{number}>{content}</h{number}>\".format(",
            "                    number=number, content=match.group(\"content\")",
            "                )",
            "",
            "            return html_header_regex.sub(repl, s)",
            "",
            "        markdown_header_regex = re.compile(",
            "            r\"^(?P<hashes>#+)\\s+(?P<content>.*)$\", flags=re.MULTILINE",
            "        )",
            "",
            "        def offset_markdown_headers(s, offset):",
            "            def repl(match):",
            "                number = len(match.group(\"hashes\"))",
            "                number += offset",
            "                if number > 6:",
            "                    number = 6",
            "                elif number < 1:",
            "                    number = 1",
            "                return \"{hashes} {content}\".format(",
            "                    hashes=\"#\" * number, content=match.group(\"content\")",
            "                )",
            "",
            "            return markdown_header_regex.sub(repl, s)",
            "",
            "        html_link_regex = re.compile(r\"<(?P<tag>a.*?)>(?P<content>.*?)</a>\")",
            "",
            "        def externalize_links(text):",
            "            def repl(match):",
            "                tag = match.group(\"tag\")",
            "                if \"href\" not in tag:",
            "                    return match.group(0)",
            "",
            "                if \"target=\" not in tag and \"rel=\" not in tag:",
            "                    tag += ' target=\"_blank\" rel=\"noreferrer noopener\"'",
            "",
            "                content = match.group(\"content\")",
            "                return f\"<{tag}>{content}</a>\"",
            "",
            "            return html_link_regex.sub(repl, text)",
            "",
            "        single_quote_regex = re.compile(\"(?<!\\\\\\\\)'\")",
            "",
            "        def escape_single_quote(text):",
            "            return single_quote_regex.sub(\"\\\\'\", text)",
            "",
            "        double_quote_regex = re.compile('(?<!\\\\\\\\)\"')",
            "",
            "        def escape_double_quote(text):",
            "            return double_quote_regex.sub('\\\\\"', text)",
            "",
            "        app.jinja_env.filters[\"regex_replace\"] = regex_replace",
            "        app.jinja_env.filters[\"offset_html_headers\"] = offset_html_headers",
            "        app.jinja_env.filters[\"offset_markdown_headers\"] = offset_markdown_headers",
            "        app.jinja_env.filters[\"externalize_links\"] = externalize_links",
            "        app.jinja_env.filters[\"escape_single_quote\"] = app.jinja_env.filters[",
            "            \"esq\"",
            "        ] = escape_single_quote",
            "        app.jinja_env.filters[\"escape_double_quote\"] = app.jinja_env.filters[",
            "            \"edq\"",
            "        ] = escape_double_quote",
            "",
            "        # configure additional template folders for jinja2",
            "        import jinja2",
            "",
            "        import octoprint.util.jinja",
            "",
            "        app.jinja_env.prefix_loader = jinja2.PrefixLoader({})",
            "",
            "        loaders = [app.jinja_loader, app.jinja_env.prefix_loader]",
            "        if octoprint.util.is_running_from_source():",
            "            root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../..\"))",
            "            allowed = [\"AUTHORS.md\", \"SUPPORTERS.md\", \"THIRDPARTYLICENSES.md\"]",
            "            files = {\"_data/\" + name: os.path.join(root, name) for name in allowed}",
            "            loaders.append(octoprint.util.jinja.SelectedFilesWithConversionLoader(files))",
            "",
            "        # TODO: Remove this in 2.0.0",
            "        warning_message = \"Loading plugin template '{template}' from '{filename}' without plugin prefix, this is deprecated and will soon no longer be supported.\"",
            "        loaders.append(",
            "            octoprint.util.jinja.WarningLoader(",
            "                octoprint.util.jinja.PrefixChoiceLoader(app.jinja_env.prefix_loader),",
            "                warning_message,",
            "            )",
            "        )",
            "",
            "        app.jinja_loader = jinja2.ChoiceLoader(loaders)",
            "",
            "        self._register_template_plugins()",
            "",
            "        # make sure plugin lifecycle events relevant for jinja2 are taken care of",
            "        def template_enabled(name, plugin):",
            "            if plugin.implementation is None or not isinstance(",
            "                plugin.implementation, octoprint.plugin.TemplatePlugin",
            "            ):",
            "                return",
            "            self._register_additional_template_plugin(plugin.implementation)",
            "",
            "        def template_disabled(name, plugin):",
            "            if plugin.implementation is None or not isinstance(",
            "                plugin.implementation, octoprint.plugin.TemplatePlugin",
            "            ):",
            "                return",
            "            self._unregister_additional_template_plugin(plugin.implementation)",
            "",
            "        pluginLifecycleManager.add_callback(\"enabled\", template_enabled)",
            "        pluginLifecycleManager.add_callback(\"disabled\", template_disabled)",
            "",
            "    def _execute_preemptive_flask_caching(self, preemptive_cache):",
            "        import time",
            "",
            "        from werkzeug.test import EnvironBuilder",
            "",
            "        # we clean up entries from our preemptive cache settings that haven't been",
            "        # accessed longer than server.preemptiveCache.until days",
            "        preemptive_cache_timeout = settings().getInt(",
            "            [\"server\", \"preemptiveCache\", \"until\"]",
            "        )",
            "        cutoff_timestamp = time.time() - preemptive_cache_timeout * 24 * 60 * 60",
            "",
            "        def filter_current_entries(entry):",
            "            \"\"\"Returns True for entries younger than the cutoff date\"\"\"",
            "            return \"_timestamp\" in entry and entry[\"_timestamp\"] > cutoff_timestamp",
            "",
            "        def filter_http_entries(entry):",
            "            \"\"\"Returns True for entries targeting http or https.\"\"\"",
            "            return (",
            "                \"base_url\" in entry",
            "                and entry[\"base_url\"]",
            "                and (",
            "                    entry[\"base_url\"].startswith(\"http://\")",
            "                    or entry[\"base_url\"].startswith(\"https://\")",
            "                )",
            "            )",
            "",
            "        def filter_entries(entry):",
            "            \"\"\"Combined filter.\"\"\"",
            "            filters = (filter_current_entries, filter_http_entries)",
            "            return all([f(entry) for f in filters])",
            "",
            "        # filter out all old and non-http entries",
            "        cache_data = preemptive_cache.clean_all_data(",
            "            lambda root, entries: list(filter(filter_entries, entries))",
            "        )",
            "        if not cache_data:",
            "            return",
            "",
            "        def execute_caching():",
            "            logger = logging.getLogger(__name__ + \".preemptive_cache\")",
            "",
            "            for route in sorted(cache_data.keys(), key=lambda x: (x.count(\"/\"), x)):",
            "                entries = reversed(",
            "                    sorted(cache_data[route], key=lambda x: x.get(\"_count\", 0))",
            "                )",
            "                for kwargs in entries:",
            "                    plugin = kwargs.get(\"plugin\", None)",
            "                    if plugin:",
            "                        try:",
            "                            plugin_info = pluginManager.get_plugin_info(",
            "                                plugin, require_enabled=True",
            "                            )",
            "                            if plugin_info is None:",
            "                                logger.info(",
            "                                    \"About to preemptively cache plugin {} but it is not installed or enabled, preemptive caching makes no sense\".format(",
            "                                        plugin",
            "                                    )",
            "                                )",
            "                                continue",
            "",
            "                            implementation = plugin_info.implementation",
            "                            if implementation is None or not isinstance(",
            "                                implementation, octoprint.plugin.UiPlugin",
            "                            ):",
            "                                logger.info(",
            "                                    \"About to preemptively cache plugin {} but it is not a UiPlugin, preemptive caching makes no sense\".format(",
            "                                        plugin",
            "                                    )",
            "                                )",
            "                                continue",
            "                            if not implementation.get_ui_preemptive_caching_enabled():",
            "                                logger.info(",
            "                                    \"About to preemptively cache plugin {} but it has disabled preemptive caching\".format(",
            "                                        plugin",
            "                                    )",
            "                                )",
            "                                continue",
            "                        except Exception:",
            "                            logger.exception(",
            "                                \"Error while trying to check if plugin {} has preemptive caching enabled, skipping entry\"",
            "                            )",
            "                            continue",
            "",
            "                    additional_request_data = kwargs.get(\"_additional_request_data\", {})",
            "                    kwargs = {",
            "                        k: v",
            "                        for k, v in kwargs.items()",
            "                        if not k.startswith(\"_\") and not k == \"plugin\"",
            "                    }",
            "                    kwargs.update(additional_request_data)",
            "",
            "                    try:",
            "                        start = time.monotonic()",
            "                        if plugin:",
            "                            logger.info(",
            "                                \"Preemptively caching {} (ui {}) for {!r}\".format(",
            "                                    route, plugin, kwargs",
            "                                )",
            "                            )",
            "                        else:",
            "                            logger.info(",
            "                                \"Preemptively caching {} (ui _default) for {!r}\".format(",
            "                                    route, kwargs",
            "                                )",
            "                            )",
            "",
            "                        headers = kwargs.get(\"headers\", {})",
            "                        headers[\"X-Force-View\"] = plugin if plugin else \"_default\"",
            "                        headers[\"X-Preemptive-Recording\"] = \"yes\"",
            "                        kwargs[\"headers\"] = headers",
            "",
            "                        builder = EnvironBuilder(**kwargs)",
            "                        app(builder.get_environ(), lambda *a, **kw: None)",
            "",
            "                        logger.info(f\"... done in {time.monotonic() - start:.2f}s\")",
            "                    except Exception:",
            "                        logger.exception(",
            "                            \"Error while trying to preemptively cache {} for {!r}\".format(",
            "                                route, kwargs",
            "                            )",
            "                        )",
            "",
            "        # asynchronous caching",
            "        import threading",
            "",
            "        cache_thread = threading.Thread(",
            "            target=execute_caching, name=\"Preemptive Cache Worker\"",
            "        )",
            "        cache_thread.daemon = True",
            "        cache_thread.start()",
            "",
            "    def _register_template_plugins(self):",
            "        template_plugins = pluginManager.get_implementations(",
            "            octoprint.plugin.TemplatePlugin",
            "        )",
            "        for plugin in template_plugins:",
            "            try:",
            "                self._register_additional_template_plugin(plugin)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while trying to register templates of plugin {}, ignoring it\".format(",
            "                        plugin._identifier",
            "                    )",
            "                )",
            "",
            "    def _register_additional_template_plugin(self, plugin):",
            "        import octoprint.util.jinja",
            "",
            "        folder = plugin.get_template_folder()",
            "        if (",
            "            folder is not None",
            "            and plugin.template_folder_key not in app.jinja_env.prefix_loader.mapping",
            "        ):",
            "            loader = octoprint.util.jinja.FilteredFileSystemLoader(",
            "                [plugin.get_template_folder()],",
            "                path_filter=lambda x: not octoprint.util.is_hidden_path(x),",
            "            )",
            "",
            "            app.jinja_env.prefix_loader.mapping[plugin.template_folder_key] = loader",
            "",
            "    def _unregister_additional_template_plugin(self, plugin):",
            "        folder = plugin.get_template_folder()",
            "        if (",
            "            folder is not None",
            "            and plugin.template_folder_key in app.jinja_env.prefix_loader.mapping",
            "        ):",
            "            del app.jinja_env.prefix_loader.mapping[plugin.template_folder_key]",
            "",
            "    def _setup_blueprints(self):",
            "        # do not remove or the index view won't be found",
            "        import octoprint.server.views  # noqa: F401",
            "        from octoprint.server.api import api",
            "        from octoprint.server.util.flask import make_api_error",
            "",
            "        blueprints = [api]",
            "        api_endpoints = [\"/api\"]",
            "        registrators = [functools.partial(app.register_blueprint, api, url_prefix=\"/api\")]",
            "",
            "        # also register any blueprints defined in BlueprintPlugins",
            "        (",
            "            blueprints_from_plugins,",
            "            api_endpoints_from_plugins,",
            "            registrators_from_plugins,",
            "        ) = self._prepare_blueprint_plugins()",
            "        blueprints += blueprints_from_plugins",
            "        api_endpoints += api_endpoints_from_plugins",
            "        registrators += registrators_from_plugins",
            "",
            "        # and register a blueprint for serving the static files of asset plugins which are not blueprint plugins themselves",
            "        (blueprints_from_assets, registrators_from_assets) = self._prepare_asset_plugins()",
            "        blueprints += blueprints_from_assets",
            "        registrators += registrators_from_assets",
            "",
            "        # make sure all before/after_request hook results are attached as well",
            "        self._add_plugin_request_handlers_to_blueprints(*blueprints)",
            "",
            "        # register everything with the system",
            "        for registrator in registrators:",
            "            registrator()",
            "",
            "        @app.errorhandler(HTTPException)",
            "        def _handle_api_error(ex):",
            "            if any(map(lambda x: request.path.startswith(x), api_endpoints)):",
            "                return make_api_error(ex.description, ex.code)",
            "            else:",
            "                return ex",
            "",
            "    def _prepare_blueprint_plugins(self):",
            "        def register_plugin_blueprint(plugin, blueprint, url_prefix):",
            "            try:",
            "                app.register_blueprint(",
            "                    blueprint, url_prefix=url_prefix, name_prefix=\"plugin\"",
            "                )",
            "                self._logger.debug(",
            "                    f\"Registered API of plugin {plugin} under URL prefix {url_prefix}\"",
            "                )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while registering blueprint of plugin {plugin}, ignoring it\",",
            "                    extra={\"plugin\": plugin},",
            "                )",
            "",
            "        blueprints = []",
            "        api_endpoints = []",
            "        registrators = []",
            "",
            "        blueprint_plugins = octoprint.plugin.plugin_manager().get_implementations(",
            "            octoprint.plugin.BlueprintPlugin",
            "        )",
            "        for plugin in blueprint_plugins:",
            "            blueprint, prefix = self._prepare_blueprint_plugin(plugin)",
            "",
            "            blueprints.append(blueprint)",
            "            api_endpoints += map(",
            "                lambda x: prefix + x, plugin.get_blueprint_api_prefixes()",
            "            )",
            "            registrators.append(",
            "                functools.partial(",
            "                    register_plugin_blueprint, plugin._identifier, blueprint, prefix",
            "                )",
            "            )",
            "",
            "        return blueprints, api_endpoints, registrators",
            "",
            "    def _prepare_asset_plugins(self):",
            "        def register_asset_blueprint(plugin, blueprint, url_prefix):",
            "            try:",
            "                app.register_blueprint(",
            "                    blueprint, url_prefix=url_prefix, name_prefix=\"plugin\"",
            "                )",
            "                self._logger.debug(",
            "                    f\"Registered assets of plugin {plugin} under URL prefix {url_prefix}\"",
            "                )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while registering blueprint of plugin {plugin}, ignoring it\",",
            "                    extra={\"plugin\": plugin},",
            "                )",
            "",
            "        blueprints = []",
            "        registrators = []",
            "",
            "        asset_plugins = octoprint.plugin.plugin_manager().get_implementations(",
            "            octoprint.plugin.AssetPlugin",
            "        )",
            "        for plugin in asset_plugins:",
            "            if isinstance(plugin, octoprint.plugin.BlueprintPlugin):",
            "                continue",
            "            blueprint, prefix = self._prepare_asset_plugin(plugin)",
            "",
            "            blueprints.append(blueprint)",
            "            registrators.append(",
            "                functools.partial(",
            "                    register_asset_blueprint, plugin._identifier, blueprint, prefix",
            "                )",
            "            )",
            "",
            "        return blueprints, registrators",
            "",
            "    def _prepare_blueprint_plugin(self, plugin):",
            "        name = plugin._identifier",
            "        blueprint = plugin.get_blueprint()",
            "        if blueprint is None:",
            "            return",
            "",
            "        blueprint.before_request(corsRequestHandler)",
            "        blueprint.before_request(loginFromApiKeyRequestHandler)",
            "        blueprint.after_request(corsResponseHandler)",
            "",
            "        if plugin.is_blueprint_csrf_protected():",
            "            self._logger.debug(",
            "                f\"CSRF Protection for Blueprint of plugin {name} is enabled\"",
            "            )",
            "            blueprint.before_request(csrfRequestHandler)",
            "        else:",
            "            self._logger.warning(",
            "                f\"CSRF Protection for Blueprint of plugin {name} is DISABLED\"",
            "            )",
            "",
            "        if plugin.is_blueprint_protected():",
            "            blueprint.before_request(requireLoginRequestHandler)",
            "",
            "        url_prefix = f\"/plugin/{name}\"",
            "        return blueprint, url_prefix",
            "",
            "    def _prepare_asset_plugin(self, plugin):",
            "        name = plugin._identifier",
            "",
            "        url_prefix = f\"/plugin/{name}\"",
            "        blueprint = Blueprint(name, name, static_folder=plugin.get_asset_folder())",
            "",
            "        blueprint.before_request(corsRequestHandler)",
            "        blueprint.after_request(corsResponseHandler)",
            "",
            "        return blueprint, url_prefix",
            "",
            "    def _add_plugin_request_handlers_to_blueprints(self, *blueprints):",
            "        before_hooks = octoprint.plugin.plugin_manager().get_hooks(",
            "            \"octoprint.server.api.before_request\"",
            "        )",
            "        after_hooks = octoprint.plugin.plugin_manager().get_hooks(",
            "            \"octoprint.server.api.after_request\"",
            "        )",
            "",
            "        for name, hook in before_hooks.items():",
            "            plugin = octoprint.plugin.plugin_manager().get_plugin(name)",
            "            for blueprint in blueprints:",
            "                try:",
            "                    result = hook(plugin=plugin)",
            "                    if isinstance(result, (list, tuple)):",
            "                        for h in result:",
            "                            blueprint.before_request(h)",
            "                except Exception:",
            "                    self._logger.exception(",
            "                        \"Error processing before_request hooks from plugin {}\".format(",
            "                            plugin",
            "                        ),",
            "                        extra={\"plugin\": name},",
            "                    )",
            "",
            "        for name, hook in after_hooks.items():",
            "            plugin = octoprint.plugin.plugin_manager().get_plugin(name)",
            "            for blueprint in blueprints:",
            "                try:",
            "                    result = hook(plugin=plugin)",
            "                    if isinstance(result, (list, tuple)):",
            "                        for h in result:",
            "                            blueprint.after_request(h)",
            "                except Exception:",
            "                    self._logger.exception(",
            "                        \"Error processing after_request hooks from plugin {}\".format(",
            "                            plugin",
            "                        ),",
            "                        extra={\"plugin\": name},",
            "                    )",
            "",
            "    def _setup_mimetypes(self):",
            "        # Safety measures for Windows... apparently the mimetypes module takes its translation from the windows",
            "        # registry, and if for some weird reason that gets borked the reported MIME types can be all over the place.",
            "        # Since at least in Chrome that can cause hilarious issues with JS files (refusal to run them and thus a",
            "        # borked UI) we make sure that .js always maps to the correct application/javascript, and also throw in a",
            "        # .css -> text/css for good measure.",
            "        #",
            "        # See #3367",
            "        mimetypes.add_type(\"application/javascript\", \".js\")",
            "        mimetypes.add_type(\"text/css\", \".css\")",
            "",
            "    def _setup_assets(self):",
            "        global app",
            "        global assets",
            "        global pluginManager",
            "",
            "        from octoprint.server.util.webassets import MemoryManifest  # noqa: F401",
            "",
            "        util.flask.fix_webassets_convert_item_to_flask_url()",
            "        util.flask.fix_webassets_filtertool()",
            "",
            "        base_folder = self._settings.getBaseFolder(\"generated\")",
            "",
            "        # clean the folder",
            "        if self._settings.getBoolean([\"devel\", \"webassets\", \"clean_on_startup\"]):",
            "            import errno",
            "            import shutil",
            "",
            "            for entry, recreate in (",
            "                (\"webassets\", True),",
            "                # no longer used, but clean up just in case",
            "                (\".webassets-cache\", False),",
            "                (\".webassets-manifest.json\", False),",
            "            ):",
            "                path = os.path.join(base_folder, entry)",
            "",
            "                # delete path if it exists",
            "                if os.path.exists(path):",
            "                    try:",
            "                        self._logger.debug(f\"Deleting {path}...\")",
            "                        if os.path.isdir(path):",
            "                            shutil.rmtree(path)",
            "                        else:",
            "                            os.remove(path)",
            "                    except Exception:",
            "                        self._logger.exception(",
            "                            f\"Error while trying to delete {path}, \" f\"leaving it alone\"",
            "                        )",
            "                        continue",
            "",
            "                # re-create path if necessary",
            "                if recreate:",
            "                    self._logger.debug(f\"Creating {path}...\")",
            "                    error_text = (",
            "                        f\"Error while trying to re-create {path}, that might cause \"",
            "                        f\"errors with the webassets cache\"",
            "                    )",
            "                    try:",
            "                        os.makedirs(path)",
            "                    except OSError as e:",
            "                        if e.errno == errno.EACCES:",
            "                            # that might be caused by the user still having the folder open somewhere, let's try again after",
            "                            # waiting a bit",
            "                            import time",
            "",
            "                            for n in range(3):",
            "                                time.sleep(0.5)",
            "                                self._logger.debug(",
            "                                    \"Creating {path}: Retry #{retry} after {time}s\".format(",
            "                                        path=path, retry=n + 1, time=(n + 1) * 0.5",
            "                                    )",
            "                                )",
            "                                try:",
            "                                    os.makedirs(path)",
            "                                    break",
            "                                except Exception:",
            "                                    if self._logger.isEnabledFor(logging.DEBUG):",
            "                                        self._logger.exception(",
            "                                            f\"Ignored error while creating \"",
            "                                            f\"directory {path}\"",
            "                                        )",
            "                                    pass",
            "                            else:",
            "                                # this will only get executed if we never did",
            "                                # successfully execute makedirs above",
            "                                self._logger.exception(error_text)",
            "                                continue",
            "                        else:",
            "                            # not an access error, so something we don't understand",
            "                            # went wrong -> log an error and stop",
            "                            self._logger.exception(error_text)",
            "                            continue",
            "                    except Exception:",
            "                        # not an OSError, so something we don't understand",
            "                        # went wrong -> log an error and stop",
            "                        self._logger.exception(error_text)",
            "                        continue",
            "",
            "                self._logger.info(f\"Reset webasset folder {path}...\")",
            "",
            "        AdjustedEnvironment = type(Environment)(",
            "            Environment.__name__,",
            "            (Environment,),",
            "            {\"resolver_class\": util.flask.PluginAssetResolver},",
            "        )",
            "",
            "        class CustomDirectoryEnvironment(AdjustedEnvironment):",
            "            @property",
            "            def directory(self):",
            "                return base_folder",
            "",
            "        assets = CustomDirectoryEnvironment(app)",
            "        assets.debug = not self._settings.getBoolean([\"devel\", \"webassets\", \"bundle\"])",
            "",
            "        # we should rarely if ever regenerate the webassets in production and can wait a",
            "        # few seconds for regeneration in development, if it means we can get rid of",
            "        # a whole monkey patch and in internal use of pickle with non-tamperproof files",
            "        assets.cache = False",
            "        assets.manifest = \"memory\"",
            "",
            "        UpdaterType = type(util.flask.SettingsCheckUpdater)(",
            "            util.flask.SettingsCheckUpdater.__name__,",
            "            (util.flask.SettingsCheckUpdater,),",
            "            {\"updater\": assets.updater},",
            "        )",
            "        assets.updater = UpdaterType",
            "",
            "        preferred_stylesheet = self._settings.get([\"devel\", \"stylesheet\"])",
            "",
            "        dynamic_core_assets = util.flask.collect_core_assets()",
            "        dynamic_plugin_assets = util.flask.collect_plugin_assets(",
            "            preferred_stylesheet=preferred_stylesheet",
            "        )",
            "",
            "        js_libs = [",
            "            \"js/lib/babel-polyfill.min.js\",",
            "            \"js/lib/jquery/jquery.min.js\",",
            "            \"js/lib/modernizr.custom.js\",",
            "            \"js/lib/lodash.min.js\",",
            "            \"js/lib/sprintf.min.js\",",
            "            \"js/lib/knockout.js\",",
            "            \"js/lib/knockout.mapping-latest.js\",",
            "            \"js/lib/babel.js\",",
            "            \"js/lib/bootstrap/bootstrap.js\",",
            "            \"js/lib/bootstrap/bootstrap-modalmanager.js\",",
            "            \"js/lib/bootstrap/bootstrap-modal.js\",",
            "            \"js/lib/bootstrap/bootstrap-slider.js\",",
            "            \"js/lib/bootstrap/bootstrap-tabdrop.js\",",
            "            \"js/lib/jquery/jquery-ui.js\",",
            "            \"js/lib/jquery/jquery.flot.js\",",
            "            \"js/lib/jquery/jquery.flot.time.js\",",
            "            \"js/lib/jquery/jquery.flot.crosshair.js\",",
            "            \"js/lib/jquery/jquery.flot.dashes.js\",",
            "            \"js/lib/jquery/jquery.flot.resize.js\",",
            "            \"js/lib/jquery/jquery.iframe-transport.js\",",
            "            \"js/lib/jquery/jquery.fileupload.js\",",
            "            \"js/lib/jquery/jquery.slimscroll.min.js\",",
            "            \"js/lib/jquery/jquery.qrcode.min.js\",",
            "            \"js/lib/jquery/jquery.bootstrap.wizard.js\",",
            "            \"js/lib/pnotify/pnotify.core.min.js\",",
            "            \"js/lib/pnotify/pnotify.buttons.min.js\",",
            "            \"js/lib/pnotify/pnotify.callbacks.min.js\",",
            "            \"js/lib/pnotify/pnotify.confirm.min.js\",",
            "            \"js/lib/pnotify/pnotify.desktop.min.js\",",
            "            \"js/lib/pnotify/pnotify.history.min.js\",",
            "            \"js/lib/pnotify/pnotify.mobile.min.js\",",
            "            \"js/lib/pnotify/pnotify.nonblock.min.js\",",
            "            \"js/lib/pnotify/pnotify.reference.min.js\",",
            "            \"js/lib/pnotify/pnotify.tooltip.min.js\",",
            "            \"js/lib/pnotify/pnotify.maxheight.js\",",
            "            \"js/lib/moment-with-locales.min.js\",",
            "            \"js/lib/pusher.color.min.js\",",
            "            \"js/lib/detectmobilebrowser.js\",",
            "            \"js/lib/ua-parser.min.js\",",
            "            \"js/lib/md5.min.js\",",
            "            \"js/lib/bootstrap-slider-knockout-binding.js\",",
            "            \"js/lib/loglevel.min.js\",",
            "            \"js/lib/sockjs.min.js\",",
            "            \"js/lib/hls.js\",",
            "            \"js/lib/less.js\",",
            "        ]",
            "",
            "        css_libs = [",
            "            \"css/bootstrap.min.css\",",
            "            \"css/bootstrap-modal.css\",",
            "            \"css/bootstrap-slider.css\",",
            "            \"css/bootstrap-tabdrop.css\",",
            "            \"vendor/font-awesome-3.2.1/css/font-awesome.min.css\",",
            "            \"vendor/fontawesome-6.1.1/css/all.min.css\",",
            "            \"vendor/fontawesome-6.1.1/css/v4-shims.min.css\",",
            "            \"vendor/fa5-power-transforms.min.css\",",
            "            \"css/jquery.fileupload-ui.css\",",
            "            \"css/pnotify.core.min.css\",",
            "            \"css/pnotify.buttons.min.css\",",
            "            \"css/pnotify.history.min.css\",",
            "        ]",
            "",
            "        # a couple of custom filters",
            "        from webassets.filter import register_filter",
            "",
            "        from octoprint.server.util.webassets import (",
            "            GzipFile,",
            "            JsDelimiterBundler,",
            "            JsPluginBundle,",
            "            LessImportRewrite,",
            "            RJSMinExtended,",
            "            SourceMapRemove,",
            "            SourceMapRewrite,",
            "        )",
            "",
            "        register_filter(LessImportRewrite)",
            "        register_filter(SourceMapRewrite)",
            "        register_filter(SourceMapRemove)",
            "        register_filter(JsDelimiterBundler)",
            "        register_filter(GzipFile)",
            "        register_filter(RJSMinExtended)",
            "",
            "        def all_assets_for_plugins(collection):",
            "            \"\"\"Gets all plugin assets for a dict of plugin->assets\"\"\"",
            "            result = []",
            "            for assets in collection.values():",
            "                result += assets",
            "            return result",
            "",
            "        # -- JS --------------------------------------------------------------------------------------------------------",
            "",
            "        filters = [\"sourcemap_remove\"]",
            "        if self._settings.getBoolean([\"devel\", \"webassets\", \"minify\"]):",
            "            filters += [\"rjsmin_extended\"]",
            "        filters += [\"js_delimiter_bundler\", \"gzip\"]",
            "",
            "        js_filters = filters",
            "        if self._settings.getBoolean([\"devel\", \"webassets\", \"minify_plugins\"]):",
            "            js_plugin_filters = js_filters",
            "        else:",
            "            js_plugin_filters = [x for x in js_filters if x not in (\"rjsmin_extended\",)]",
            "",
            "        def js_bundles_for_plugins(collection, filters=None):",
            "            \"\"\"Produces JsPluginBundle instances that output IIFE wrapped assets\"\"\"",
            "            result = OrderedDict()",
            "            for plugin, assets in collection.items():",
            "                if len(assets):",
            "                    result[plugin] = JsPluginBundle(plugin, *assets, filters=filters)",
            "            return result",
            "",
            "        js_core = (",
            "            dynamic_core_assets[\"js\"]",
            "            + all_assets_for_plugins(dynamic_plugin_assets[\"bundled\"][\"js\"])",
            "            + [\"js/app/dataupdater.js\", \"js/app/helpers.js\", \"js/app/main.js\"]",
            "        )",
            "        js_plugins = js_bundles_for_plugins(",
            "            dynamic_plugin_assets[\"external\"][\"js\"], filters=\"js_delimiter_bundler\"",
            "        )",
            "",
            "        clientjs_core = dynamic_core_assets[\"clientjs\"] + all_assets_for_plugins(",
            "            dynamic_plugin_assets[\"bundled\"][\"clientjs\"]",
            "        )",
            "        clientjs_plugins = js_bundles_for_plugins(",
            "            dynamic_plugin_assets[\"external\"][\"clientjs\"], filters=\"js_delimiter_bundler\"",
            "        )",
            "",
            "        js_libs_bundle = Bundle(",
            "            *js_libs, output=\"webassets/packed_libs.js\", filters=\",\".join(js_filters)",
            "        )",
            "",
            "        js_core_bundle = Bundle(",
            "            *js_core, output=\"webassets/packed_core.js\", filters=\",\".join(js_filters)",
            "        )",
            "",
            "        if len(js_plugins) == 0:",
            "            js_plugins_bundle = Bundle(*[])",
            "        else:",
            "            js_plugins_bundle = Bundle(",
            "                *js_plugins.values(),",
            "                output=\"webassets/packed_plugins.js\",",
            "                filters=\",\".join(js_plugin_filters),",
            "            )",
            "",
            "        js_app_bundle = Bundle(",
            "            js_plugins_bundle,",
            "            js_core_bundle,",
            "            output=\"webassets/packed_app.js\",",
            "            filters=\",\".join(js_plugin_filters),",
            "        )",
            "",
            "        js_client_core_bundle = Bundle(",
            "            *clientjs_core,",
            "            output=\"webassets/packed_client_core.js\",",
            "            filters=\",\".join(js_filters),",
            "        )",
            "",
            "        if len(clientjs_plugins) == 0:",
            "            js_client_plugins_bundle = Bundle(*[])",
            "        else:",
            "            js_client_plugins_bundle = Bundle(",
            "                *clientjs_plugins.values(),",
            "                output=\"webassets/packed_client_plugins.js\",",
            "                filters=\",\".join(js_plugin_filters),",
            "            )",
            "",
            "        js_client_bundle = Bundle(",
            "            js_client_core_bundle,",
            "            js_client_plugins_bundle,",
            "            output=\"webassets/packed_client.js\",",
            "            filters=\",\".join(js_plugin_filters),",
            "        )",
            "",
            "        # -- CSS -------------------------------------------------------------------------------------------------------",
            "",
            "        css_filters = [\"cssrewrite\", \"gzip\"]",
            "",
            "        css_core = list(dynamic_core_assets[\"css\"]) + all_assets_for_plugins(",
            "            dynamic_plugin_assets[\"bundled\"][\"css\"]",
            "        )",
            "        css_plugins = list(",
            "            all_assets_for_plugins(dynamic_plugin_assets[\"external\"][\"css\"])",
            "        )",
            "",
            "        css_libs_bundle = Bundle(",
            "            *css_libs, output=\"webassets/packed_libs.css\", filters=\",\".join(css_filters)",
            "        )",
            "",
            "        if len(css_core) == 0:",
            "            css_core_bundle = Bundle(*[])",
            "        else:",
            "            css_core_bundle = Bundle(",
            "                *css_core,",
            "                output=\"webassets/packed_core.css\",",
            "                filters=\",\".join(css_filters),",
            "            )",
            "",
            "        if len(css_plugins) == 0:",
            "            css_plugins_bundle = Bundle(*[])",
            "        else:",
            "            css_plugins_bundle = Bundle(",
            "                *css_plugins,",
            "                output=\"webassets/packed_plugins.css\",",
            "                filters=\",\".join(css_filters),",
            "            )",
            "",
            "        css_app_bundle = Bundle(",
            "            css_core,",
            "            css_plugins,",
            "            output=\"webassets/packed_app.css\",",
            "            filters=\",\".join(css_filters),",
            "        )",
            "",
            "        # -- LESS ------------------------------------------------------------------------------------------------------",
            "",
            "        less_filters = [\"cssrewrite\", \"less_importrewrite\", \"gzip\"]",
            "",
            "        less_core = list(dynamic_core_assets[\"less\"]) + all_assets_for_plugins(",
            "            dynamic_plugin_assets[\"bundled\"][\"less\"]",
            "        )",
            "        less_plugins = all_assets_for_plugins(dynamic_plugin_assets[\"external\"][\"less\"])",
            "",
            "        if len(less_core) == 0:",
            "            less_core_bundle = Bundle(*[])",
            "        else:",
            "            less_core_bundle = Bundle(",
            "                *less_core,",
            "                output=\"webassets/packed_core.less\",",
            "                filters=\",\".join(less_filters),",
            "            )",
            "",
            "        if len(less_plugins) == 0:",
            "            less_plugins_bundle = Bundle(*[])",
            "        else:",
            "            less_plugins_bundle = Bundle(",
            "                *less_plugins,",
            "                output=\"webassets/packed_plugins.less\",",
            "                filters=\",\".join(less_filters),",
            "            )",
            "",
            "        less_app_bundle = Bundle(",
            "            less_core,",
            "            less_plugins,",
            "            output=\"webassets/packed_app.less\",",
            "            filters=\",\".join(less_filters),",
            "        )",
            "",
            "        # -- asset registration ----------------------------------------------------------------------------------------",
            "",
            "        assets.register(\"js_libs\", js_libs_bundle)",
            "        assets.register(\"js_client_core\", js_client_core_bundle)",
            "        for plugin, bundle in clientjs_plugins.items():",
            "            # register our collected clientjs plugin bundles so that they are bound to the environment",
            "            assets.register(f\"js_client_plugin_{plugin}\", bundle)",
            "        assets.register(\"js_client_plugins\", js_client_plugins_bundle)",
            "        assets.register(\"js_client\", js_client_bundle)",
            "        assets.register(\"js_core\", js_core_bundle)",
            "        for plugin, bundle in js_plugins.items():",
            "            # register our collected plugin bundles so that they are bound to the environment",
            "            assets.register(f\"js_plugin_{plugin}\", bundle)",
            "        assets.register(\"js_plugins\", js_plugins_bundle)",
            "        assets.register(\"js_app\", js_app_bundle)",
            "        assets.register(\"css_libs\", css_libs_bundle)",
            "        assets.register(\"css_core\", css_core_bundle)",
            "        assets.register(\"css_plugins\", css_plugins_bundle)",
            "        assets.register(\"css_app\", css_app_bundle)",
            "        assets.register(\"less_core\", less_core_bundle)",
            "        assets.register(\"less_plugins\", less_plugins_bundle)",
            "        assets.register(\"less_app\", less_app_bundle)",
            "",
            "    def _setup_login_manager(self):",
            "        global loginManager",
            "",
            "        loginManager = LoginManager()",
            "",
            "        # \"strong\" is incompatible to remember me, see maxcountryman/flask-login#156. It also causes issues with",
            "        # clients toggling between IPv4 and IPv6 client addresses due to names being resolved one way or the other as",
            "        # at least observed on a Win10 client targeting \"localhost\", resolved as both \"127.0.0.1\" and \"::1\"",
            "        loginManager.session_protection = \"basic\"",
            "",
            "        loginManager.user_loader(load_user)",
            "        loginManager.unauthorized_handler(unauthorized_user)",
            "        loginManager.anonymous_user = userManager.anonymous_user_factory",
            "        loginManager.request_loader(load_user_from_request)",
            "",
            "        loginManager.init_app(app, add_context_processor=False)",
            "",
            "    def _start_intermediary_server(self):",
            "        import socket",
            "        import threading",
            "        from http.server import BaseHTTPRequestHandler, HTTPServer",
            "",
            "        host = self._host",
            "        port = self._port",
            "",
            "        class IntermediaryServerHandler(BaseHTTPRequestHandler):",
            "            def __init__(self, rules=None, *args, **kwargs):",
            "                if rules is None:",
            "                    rules = []",
            "                self.rules = rules",
            "                BaseHTTPRequestHandler.__init__(self, *args, **kwargs)",
            "",
            "            def do_GET(self):",
            "                request_path = self.path",
            "                if \"?\" in request_path:",
            "                    request_path = request_path[0 : request_path.find(\"?\")]",
            "",
            "                for rule in self.rules:",
            "                    path, data, content_type = rule",
            "                    if request_path == path:",
            "                        self.send_response(200)",
            "                        if content_type:",
            "                            self.send_header(\"Content-Type\", content_type)",
            "                        self.end_headers()",
            "                        if isinstance(data, str):",
            "                            data = data.encode(\"utf-8\")",
            "                        self.wfile.write(data)",
            "                        break",
            "                else:",
            "                    self.send_response(404)",
            "                    self.wfile.write(b\"Not found\")",
            "",
            "        base_path = os.path.realpath(",
            "            os.path.join(os.path.dirname(__file__), \"..\", \"static\")",
            "        )",
            "        rules = [",
            "            (",
            "                \"/\",",
            "                [",
            "                    \"intermediary.html\",",
            "                ],",
            "                \"text/html\",",
            "            ),",
            "            (\"/favicon.ico\", [\"img\", \"tentacle-20x20.png\"], \"image/png\"),",
            "            (",
            "                \"/intermediary.gif\",",
            "                bytes(",
            "                    base64.b64decode(",
            "                        \"R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"",
            "                    )",
            "                ),",
            "                \"image/gif\",",
            "            ),",
            "        ]",
            "",
            "        def contents(args):",
            "            path = os.path.join(base_path, *args)",
            "            if not os.path.isfile(path):",
            "                return \"\"",
            "",
            "            with open(path, \"rb\") as f:",
            "                data = f.read()",
            "            return data",
            "",
            "        def process(rule):",
            "            if len(rule) == 2:",
            "                path, data = rule",
            "                content_type = None",
            "            else:",
            "                path, data, content_type = rule",
            "",
            "            if isinstance(data, (list, tuple)):",
            "                data = contents(data)",
            "",
            "            return path, data, content_type",
            "",
            "        rules = list(",
            "            map(process, filter(lambda rule: len(rule) == 2 or len(rule) == 3, rules))",
            "        )",
            "",
            "        HTTPServerV4 = HTTPServer",
            "",
            "        class HTTPServerV6(HTTPServer):",
            "            address_family = socket.AF_INET6",
            "",
            "        class HTTPServerV6SingleStack(HTTPServerV6):",
            "            def __init__(self, *args, **kwargs):",
            "                HTTPServerV6.__init__(self, *args, **kwargs)",
            "",
            "                # explicitly set V6ONLY flag - seems to be the default, but just to make sure...",
            "                self.socket.setsockopt(",
            "                    octoprint.util.net.IPPROTO_IPV6, octoprint.util.net.IPV6_V6ONLY, 1",
            "                )",
            "",
            "        class HTTPServerV6DualStack(HTTPServerV6):",
            "            def __init__(self, *args, **kwargs):",
            "                HTTPServerV6.__init__(self, *args, **kwargs)",
            "",
            "                # explicitly unset V6ONLY flag",
            "                self.socket.setsockopt(",
            "                    octoprint.util.net.IPPROTO_IPV6, octoprint.util.net.IPV6_V6ONLY, 0",
            "                )",
            "",
            "        if \":\" in host:",
            "            # v6",
            "            if host == \"::\" and not self._v6_only:",
            "                ServerClass = HTTPServerV6DualStack",
            "            else:",
            "                ServerClass = HTTPServerV6SingleStack",
            "        else:",
            "            # v4",
            "            ServerClass = HTTPServerV4",
            "",
            "        if host == \"::\":",
            "            if self._v6_only:",
            "                self._logger.debug(f\"Starting intermediary server on http://[::]:{port}\")",
            "            else:",
            "                self._logger.debug(",
            "                    \"Starting intermediary server on http://0.0.0.0:{port} and http://[::]:{port}\".format(",
            "                        port=port",
            "                    )",
            "                )",
            "        else:",
            "            self._logger.debug(",
            "                \"Starting intermediary server on http://{}:{}\".format(",
            "                    host if \":\" not in host else \"[\" + host + \"]\", port",
            "                )",
            "            )",
            "",
            "        self._intermediary_server = ServerClass(",
            "            (host, port),",
            "            lambda *args, **kwargs: IntermediaryServerHandler(rules, *args, **kwargs),",
            "            bind_and_activate=False,",
            "        )",
            "",
            "        # if possible, make sure our socket's port descriptor isn't handed over to subprocesses",
            "        from octoprint.util.platform import set_close_exec",
            "",
            "        try:",
            "            set_close_exec(self._intermediary_server.fileno())",
            "        except Exception:",
            "            self._logger.exception(",
            "                \"Error while attempting to set_close_exec on intermediary server socket\"",
            "            )",
            "",
            "        # then bind the server and have it serve our handler until stopped",
            "        try:",
            "            self._intermediary_server.server_bind()",
            "            self._intermediary_server.server_activate()",
            "        except Exception as exc:",
            "            self._intermediary_server.server_close()",
            "",
            "            if isinstance(exc, UnicodeDecodeError) and sys.platform == \"win32\":",
            "                # we end up here if the hostname contains non-ASCII characters due to",
            "                # https://bugs.python.org/issue26227 - tell the user they need",
            "                # to either change their hostname or read up other options in",
            "                # https://github.com/OctoPrint/OctoPrint/issues/3963",
            "                raise CannotStartServerException(",
            "                    \"OctoPrint cannot start due to a Python bug \"",
            "                    \"(https://bugs.python.org/issue26227). Your \"",
            "                    \"computer's host name contains non-ASCII characters. \"",
            "                    \"Please either change your computer's host name to \"",
            "                    \"contain only ASCII characters, or take a look at \"",
            "                    \"https://github.com/OctoPrint/OctoPrint/issues/3963 for \"",
            "                    \"other options.\"",
            "                )",
            "            else:",
            "                raise",
            "",
            "        def serve():",
            "            try:",
            "                self._intermediary_server.serve_forever()",
            "            except Exception:",
            "                self._logger.exception(\"Error in intermediary server\")",
            "",
            "        thread = threading.Thread(target=serve)",
            "        thread.daemon = True",
            "        thread.start()",
            "",
            "        self._logger.info(\"Intermediary server started\")",
            "",
            "    def _stop_intermediary_server(self):",
            "        if self._intermediary_server is None:",
            "            return",
            "        self._logger.info(\"Shutting down intermediary server...\")",
            "        self._intermediary_server.shutdown()",
            "        self._intermediary_server.server_close()",
            "        self._logger.info(\"Intermediary server shut down\")",
            "",
            "    def _setup_plugin_permissions(self):",
            "        global pluginManager",
            "",
            "        from octoprint.access.permissions import PluginOctoPrintPermission",
            "",
            "        key_whitelist = re.compile(r\"[A-Za-z0-9_]*\")",
            "",
            "        def permission_key(plugin, definition):",
            "            return \"PLUGIN_{}_{}\".format(plugin.upper(), definition[\"key\"].upper())",
            "",
            "        def permission_name(plugin, definition):",
            "            return \"{}: {}\".format(plugin, definition[\"name\"])",
            "",
            "        def permission_role(plugin, role):",
            "            return f\"plugin_{plugin}_{role}\"",
            "",
            "        def process_regular_permission(plugin_info, definition):",
            "            permissions = []",
            "            for key in definition.get(\"permissions\", []):",
            "                permission = octoprint.access.permissions.Permissions.find(key)",
            "",
            "                if permission is None:",
            "                    # if there is still no permission found, postpone this - maybe it is a permission from",
            "                    # another plugin that hasn't been loaded yet",
            "                    return False",
            "",
            "                permissions.append(permission)",
            "",
            "            roles = definition.get(\"roles\", [])",
            "            description = definition.get(\"description\", \"\")",
            "            dangerous = definition.get(\"dangerous\", False)",
            "            default_groups = definition.get(\"default_groups\", [])",
            "",
            "            roles_and_permissions = [",
            "                permission_role(plugin_info.key, role) for role in roles",
            "            ] + permissions",
            "",
            "            key = permission_key(plugin_info.key, definition)",
            "            permission = PluginOctoPrintPermission(",
            "                permission_name(plugin_info.name, definition),",
            "                description,",
            "                *roles_and_permissions,",
            "                plugin=plugin_info.key,",
            "                dangerous=dangerous,",
            "                default_groups=default_groups,",
            "            )",
            "            setattr(",
            "                octoprint.access.permissions.Permissions,",
            "                key,",
            "                PluginOctoPrintPermission(",
            "                    permission_name(plugin_info.name, definition),",
            "                    description,",
            "                    *roles_and_permissions,",
            "                    plugin=plugin_info.key,",
            "                    dangerous=dangerous,",
            "                    default_groups=default_groups,",
            "                ),",
            "            )",
            "",
            "            self._logger.info(",
            "                \"Added new permission from plugin {}: {} (needs: {!r})\".format(",
            "                    plugin_info.key, key, \", \".join(map(repr, permission.needs))",
            "                )",
            "            )",
            "            return True",
            "",
            "        postponed = []",
            "",
            "        hooks = pluginManager.get_hooks(\"octoprint.access.permissions\")",
            "        for name, factory in hooks.items():",
            "            try:",
            "                if isinstance(factory, (tuple, list)):",
            "                    additional_permissions = list(factory)",
            "                elif callable(factory):",
            "                    additional_permissions = factory()",
            "                else:",
            "                    raise ValueError(\"factory must be either a callable, tuple or list\")",
            "",
            "                if not isinstance(additional_permissions, (tuple, list)):",
            "                    raise ValueError(",
            "                        \"factory result must be either a tuple or a list of permission definition dicts\"",
            "                    )",
            "",
            "                plugin_info = pluginManager.get_plugin_info(name)",
            "                for p in additional_permissions:",
            "                    if not isinstance(p, dict):",
            "                        continue",
            "",
            "                    if \"key\" not in p or \"name\" not in p:",
            "                        continue",
            "",
            "                    if not key_whitelist.match(p[\"key\"]):",
            "                        self._logger.warning(",
            "                            \"Got permission with invalid key from plugin {}: {}\".format(",
            "                                name, p[\"key\"]",
            "                            )",
            "                        )",
            "                        continue",
            "",
            "                    if not process_regular_permission(plugin_info, p):",
            "                        postponed.append((plugin_info, p))",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while creating permission instance/s from {name}\"",
            "                )",
            "",
            "        # final resolution passes",
            "        pass_number = 1",
            "        still_postponed = []",
            "        while len(postponed):",
            "            start_length = len(postponed)",
            "            self._logger.debug(",
            "                \"Plugin permission resolution pass #{}, \"",
            "                \"{} unresolved permissions...\".format(pass_number, start_length)",
            "            )",
            "",
            "            for plugin_info, definition in postponed:",
            "                if not process_regular_permission(plugin_info, definition):",
            "                    still_postponed.append((plugin_info, definition))",
            "",
            "            self._logger.debug(",
            "                \"... pass #{} done, {} permissions left to resolve\".format(",
            "                    pass_number, len(still_postponed)",
            "                )",
            "            )",
            "",
            "            if len(still_postponed) == start_length:",
            "                # no change, looks like some stuff is unresolvable - let's bail",
            "                for plugin_info, definition in still_postponed:",
            "                    self._logger.warning(",
            "                        \"Unable to resolve permission from {}: {!r}\".format(",
            "                            plugin_info.key, definition",
            "                        )",
            "                    )",
            "                break",
            "",
            "            postponed = still_postponed",
            "            still_postponed = []",
            "            pass_number += 1",
            "",
            "",
            "class LifecycleManager:",
            "    def __init__(self, plugin_manager):",
            "        self._plugin_manager = plugin_manager",
            "",
            "        self._plugin_lifecycle_callbacks = defaultdict(list)",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "        def wrap_plugin_event(lifecycle_event, new_handler):",
            "            orig_handler = getattr(self._plugin_manager, \"on_plugin_\" + lifecycle_event)",
            "",
            "            def handler(*args, **kwargs):",
            "                if callable(orig_handler):",
            "                    orig_handler(*args, **kwargs)",
            "                if callable(new_handler):",
            "                    new_handler(*args, **kwargs)",
            "",
            "            return handler",
            "",
            "        def on_plugin_event_factory(lifecycle_event):",
            "            def on_plugin_event(name, plugin):",
            "                self.on_plugin_event(lifecycle_event, name, plugin)",
            "",
            "            return on_plugin_event",
            "",
            "        for event in (\"loaded\", \"unloaded\", \"enabled\", \"disabled\"):",
            "            wrap_plugin_event(event, on_plugin_event_factory(event))",
            "",
            "    def on_plugin_event(self, event, name, plugin):",
            "        for lifecycle_callback in self._plugin_lifecycle_callbacks[event]:",
            "            lifecycle_callback(name, plugin)",
            "",
            "    def add_callback(self, events, callback):",
            "        if isinstance(events, str):",
            "            events = [events]",
            "",
            "        for event in events:",
            "            self._plugin_lifecycle_callbacks[event].append(callback)",
            "",
            "    def remove_callback(self, callback, events=None):",
            "        if events is None:",
            "            for event in self._plugin_lifecycle_callbacks:",
            "                if callback in self._plugin_lifecycle_callbacks[event]:",
            "                    self._plugin_lifecycle_callbacks[event].remove(callback)",
            "        else:",
            "            if isinstance(events, str):",
            "                events = [events]",
            "",
            "            for event in events:",
            "                if callback in self._plugin_lifecycle_callbacks[event]:",
            "                    self._plugin_lifecycle_callbacks[event].remove(callback)",
            "",
            "",
            "class CannotStartServerException(Exception):",
            "    pass"
        ],
        "afterPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import atexit",
            "import base64",
            "import functools",
            "import logging",
            "import logging.config",
            "import mimetypes",
            "import os",
            "import pathlib",
            "import re",
            "import signal",
            "import sys",
            "import time",
            "import uuid  # noqa: F401",
            "from collections import OrderedDict, defaultdict",
            "",
            "from babel import Locale",
            "from flask import (  # noqa: F401",
            "    Blueprint,",
            "    Flask,",
            "    Request,",
            "    Response,",
            "    current_app,",
            "    g,",
            "    make_response,",
            "    request,",
            "    session,",
            ")",
            "from flask_assets import Bundle, Environment",
            "from flask_babel import Babel, gettext, ngettext  # noqa: F401",
            "from flask_login import (  # noqa: F401",
            "    LoginManager,",
            "    current_user,",
            "    session_protected,",
            "    user_loaded_from_cookie,",
            "    user_logged_out,",
            ")",
            "from watchdog.observers import Observer",
            "from watchdog.observers.polling import PollingObserver",
            "from werkzeug.exceptions import HTTPException",
            "",
            "import octoprint.events",
            "import octoprint.filemanager",
            "import octoprint.util",
            "import octoprint.util.net",
            "from octoprint.server import util",
            "from octoprint.systemcommands import system_command_manager",
            "from octoprint.util.json import JsonEncoding",
            "from octoprint.vendor.flask_principal import (  # noqa: F401",
            "    AnonymousIdentity,",
            "    Identity,",
            "    Permission,",
            "    Principal,",
            "    RoleNeed,",
            "    UserNeed,",
            "    identity_changed,",
            "    identity_loaded,",
            ")",
            "from octoprint.vendor.sockjs.tornado import SockJSRouter",
            "",
            "try:",
            "    import fcntl",
            "except ImportError:",
            "    fcntl = None",
            "",
            "SUCCESS = {}",
            "NO_CONTENT = (\"\", 204, {\"Content-Type\": \"text/plain\"})",
            "NOT_MODIFIED = (\"Not Modified\", 304, {\"Content-Type\": \"text/plain\"})",
            "",
            "app = Flask(\"octoprint\")",
            "",
            "assets = None",
            "babel = None",
            "limiter = None",
            "debug = False",
            "safe_mode = False",
            "",
            "printer = None",
            "printerProfileManager = None",
            "fileManager = None",
            "slicingManager = None",
            "analysisQueue = None",
            "userManager = None",
            "permissionManager = None",
            "groupManager = None",
            "eventManager = None",
            "loginManager = None",
            "pluginManager = None",
            "pluginLifecycleManager = None",
            "preemptiveCache = None",
            "jsonEncoder = None",
            "jsonDecoder = None",
            "connectivityChecker = None",
            "environmentDetector = None",
            "",
            "",
            "class OctoPrintAnonymousIdentity(AnonymousIdentity):",
            "    def __init__(self):",
            "        super().__init__()",
            "",
            "        user = userManager.anonymous_user_factory()",
            "",
            "        self.provides.add(UserNeed(user.get_id()))",
            "        for need in user.needs:",
            "            self.provides.add(need)",
            "",
            "",
            "principals = Principal(app, anonymous_identity=OctoPrintAnonymousIdentity)",
            "",
            "import octoprint.access.groups as groups  # noqa: E402",
            "import octoprint.access.permissions as permissions  # noqa: E402",
            "",
            "# we set admin_permission to a GroupPermission with the default admin group",
            "admin_permission = octoprint.util.variable_deprecated(",
            "    \"admin_permission has been deprecated, \" \"please use individual Permissions instead\",",
            "    since=\"1.4.0\",",
            ")(groups.GroupPermission(groups.ADMIN_GROUP))",
            "",
            "# we set user_permission to a GroupPermission with the default user group",
            "user_permission = octoprint.util.variable_deprecated(",
            "    \"user_permission has been deprecated, \" \"please use individual Permissions instead\",",
            "    since=\"1.4.0\",",
            ")(groups.GroupPermission(groups.USER_GROUP))",
            "",
            "import octoprint._version  # noqa: E402",
            "import octoprint.access.groups as groups  # noqa: E402",
            "import octoprint.access.users as users  # noqa: E402",
            "import octoprint.events as events  # noqa: E402",
            "import octoprint.filemanager.analysis  # noqa: E402",
            "import octoprint.filemanager.storage  # noqa: E402",
            "import octoprint.plugin  # noqa: E402",
            "import octoprint.slicing  # noqa: E402",
            "import octoprint.timelapse  # noqa: E402",
            "",
            "# only import further octoprint stuff down here, as it might depend on things defined above to be initialized already",
            "from octoprint import __branch__, __display_version__, __revision__, __version__",
            "from octoprint.printer.profile import PrinterProfileManager",
            "from octoprint.printer.standard import Printer",
            "from octoprint.server.util import (",
            "    corsRequestHandler,",
            "    corsResponseHandler,",
            "    csrfRequestHandler,",
            "    loginFromApiKeyRequestHandler,",
            "    requireLoginRequestHandler,",
            ")",
            "from octoprint.server.util.flask import PreemptiveCache, validate_session_signature",
            "from octoprint.settings import settings",
            "",
            "VERSION = __version__",
            "BRANCH = __branch__",
            "DISPLAY_VERSION = __display_version__",
            "REVISION = __revision__",
            "",
            "LOCALES = []",
            "LANGUAGES = set()",
            "",
            "",
            "@identity_loaded.connect_via(app)",
            "def on_identity_loaded(sender, identity):",
            "    user = load_user(identity.id)",
            "    if user is None:",
            "        user = userManager.anonymous_user_factory()",
            "",
            "    identity.provides.add(UserNeed(user.get_id()))",
            "    for need in user.needs:",
            "        identity.provides.add(need)",
            "",
            "",
            "def _clear_identity(sender):",
            "    # Remove session keys set by Flask-Principal",
            "    for key in (\"identity.id\", \"identity.name\", \"identity.auth_type\"):",
            "        session.pop(key, None)",
            "",
            "    # switch to anonymous identity",
            "    identity_changed.send(sender, identity=AnonymousIdentity())",
            "",
            "",
            "@session_protected.connect_via(app)",
            "def on_session_protected(sender):",
            "    # session was deleted by session protection, that means the user is no more and we need to clear our identity",
            "    if session.get(\"remember\", None) == \"clear\":",
            "        _clear_identity(sender)",
            "",
            "",
            "@user_logged_out.connect_via(app)",
            "def on_user_logged_out(sender, user=None):",
            "    # user was logged out, clear identity",
            "    _clear_identity(sender)",
            "",
            "",
            "@user_loaded_from_cookie.connect_via(app)",
            "def on_user_loaded_from_cookie(sender, user=None):",
            "    if user:",
            "        session[\"login_mechanism\"] = util.LoginMechanism.REMEMBER_ME",
            "        session[\"credentials_seen\"] = False",
            "",
            "",
            "def load_user(id):",
            "    if id is None:",
            "        return None",
            "",
            "    if id == \"_api\":",
            "        return userManager.api_user_factory()",
            "",
            "    if session and \"usersession.id\" in session:",
            "        sessionid = session[\"usersession.id\"]",
            "    else:",
            "        sessionid = None",
            "",
            "    if session and \"usersession.signature\" in session:",
            "        sessionsig = session[\"usersession.signature\"]",
            "    else:",
            "        sessionsig = \"\"",
            "",
            "    if sessionid:",
            "        # session[\"_fresh\"] is False if the session comes from a remember me cookie,",
            "        # True if it came from a use of the login dialog",
            "        user = userManager.find_user(",
            "            userid=id, session=sessionid, fresh=session.get(\"_fresh\", False)",
            "        )",
            "    else:",
            "        user = userManager.find_user(userid=id)",
            "",
            "    if (",
            "        user",
            "        and user.is_active",
            "        and (not sessionid or validate_session_signature(sessionsig, id, sessionid))",
            "    ):",
            "        return user",
            "",
            "    return None",
            "",
            "",
            "def load_user_from_request(request):",
            "    user = None",
            "",
            "    if settings().getBoolean([\"accessControl\", \"trustBasicAuthentication\"]):",
            "        # Basic Authentication?",
            "        user = util.get_user_for_authorization_header(",
            "            request.headers.get(\"Authorization\")",
            "        )",
            "",
            "    if settings().getBoolean([\"accessControl\", \"trustRemoteUser\"]):",
            "        # Remote user header?",
            "        user = util.get_user_for_remote_user_header(request)",
            "",
            "    return user",
            "",
            "",
            "def unauthorized_user():",
            "    from flask import abort",
            "",
            "    abort(403)",
            "",
            "",
            "# ~~ startup code",
            "",
            "",
            "class Server:",
            "    def __init__(",
            "        self,",
            "        settings=None,",
            "        plugin_manager=None,",
            "        connectivity_checker=None,",
            "        environment_detector=None,",
            "        event_manager=None,",
            "        host=None,",
            "        port=None,",
            "        v6_only=False,",
            "        debug=False,",
            "        safe_mode=False,",
            "        allow_root=False,",
            "        octoprint_daemon=None,",
            "    ):",
            "        self._settings = settings",
            "        self._plugin_manager = plugin_manager",
            "        self._connectivity_checker = connectivity_checker",
            "        self._environment_detector = environment_detector",
            "        self._event_manager = event_manager",
            "        self._host = host",
            "        self._port = port",
            "        self._v6_only = v6_only",
            "        self._debug = debug",
            "        self._safe_mode = safe_mode",
            "        self._allow_root = allow_root",
            "        self._octoprint_daemon = octoprint_daemon",
            "        self._server = None",
            "",
            "        self._logger = None",
            "",
            "        self._lifecycle_callbacks = defaultdict(list)",
            "",
            "        self._intermediary_server = None",
            "",
            "    def run(self):",
            "        if not self._allow_root:",
            "            self._check_for_root()",
            "",
            "        if self._settings is None:",
            "            self._settings = settings()",
            "",
            "        incomplete_startup_flag = (",
            "            pathlib.Path(self._settings._basedir) / \".incomplete_startup\"",
            "        )",
            "        if not self._settings.getBoolean([\"server\", \"ignoreIncompleteStartup\"]):",
            "            try:",
            "                incomplete_startup_flag.touch()",
            "            except Exception:",
            "                self._logger.exception(\"Could not create startup triggered safemode flag\")",
            "",
            "        if self._plugin_manager is None:",
            "            self._plugin_manager = octoprint.plugin.plugin_manager()",
            "",
            "        global app",
            "        global babel",
            "",
            "        global printer",
            "        global printerProfileManager",
            "        global fileManager",
            "        global slicingManager",
            "        global analysisQueue",
            "        global userManager",
            "        global permissionManager",
            "        global groupManager",
            "        global eventManager",
            "        global loginManager",
            "        global pluginManager",
            "        global pluginLifecycleManager",
            "        global preemptiveCache",
            "        global jsonEncoder",
            "        global jsonDecoder",
            "        global connectivityChecker",
            "        global environmentDetector",
            "        global debug",
            "        global safe_mode",
            "",
            "        from tornado.ioloop import IOLoop",
            "        from tornado.web import Application",
            "",
            "        debug = self._debug",
            "        safe_mode = self._safe_mode",
            "",
            "        if safe_mode:",
            "            self._log_safe_mode_start(safe_mode)",
            "",
            "        if self._v6_only and not octoprint.util.net.HAS_V6:",
            "            raise RuntimeError(",
            "                \"IPv6 only mode configured but system doesn't support IPv6\"",
            "            )",
            "",
            "        if self._host is None:",
            "            host = self._settings.get([\"server\", \"host\"])",
            "            if host is None:",
            "                if octoprint.util.net.HAS_V6:",
            "                    host = \"::\"",
            "                else:",
            "                    host = \"0.0.0.0\"",
            "",
            "            self._host = host",
            "",
            "        if \":\" in self._host and not octoprint.util.net.HAS_V6:",
            "            raise RuntimeError(",
            "                \"IPv6 host address {!r} configured but system doesn't support IPv6\".format(",
            "                    self._host",
            "                )",
            "            )",
            "",
            "        if self._port is None:",
            "            self._port = self._settings.getInt([\"server\", \"port\"])",
            "            if self._port is None:",
            "                self._port = 5000",
            "",
            "        self._logger = logging.getLogger(__name__)",
            "        self._setup_heartbeat_logging()",
            "        pluginManager = self._plugin_manager",
            "",
            "        # monkey patch/fix some stuff",
            "        util.tornado.fix_json_encode()",
            "        util.tornado.fix_websocket_check_origin()",
            "        util.tornado.enable_per_message_deflate_extension()",
            "        util.tornado.fix_tornado_xheader_handling()",
            "",
            "        self._setup_mimetypes()",
            "",
            "        # setup app",
            "        self._setup_app(app)",
            "",
            "        # setup i18n",
            "        additional_translation_folders = []",
            "        if not safe_mode:",
            "            additional_translation_folders += [",
            "                self._settings.getBaseFolder(\"translations\")",
            "            ]",
            "        self._setup_i18n(app, additional_folders=additional_translation_folders)",
            "",
            "        if self._settings.getBoolean([\"serial\", \"log\"]):",
            "            # enable debug logging to serial.log",
            "            logging.getLogger(\"SERIAL\").setLevel(logging.DEBUG)",
            "",
            "        if self._settings.getBoolean([\"devel\", \"pluginTimings\"]):",
            "            # enable plugin timings log",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").setLevel(logging.DEBUG)",
            "",
            "        # start the intermediary server",
            "        self._start_intermediary_server()",
            "",
            "        ### IMPORTANT!",
            "        ###",
            "        ### Best do not start any subprocesses until the intermediary server shuts down again or they MIGHT inherit the",
            "        ### open port and prevent us from firing up Tornado later.",
            "        ###",
            "        ### The intermediary server's socket should have the CLOSE_EXEC flag (or its equivalent) set where possible, but",
            "        ### we can only do that if fcntl is available or we are on Windows, so better safe than sorry.",
            "        ###",
            "        ### See also issues #2035 and #2090",
            "",
            "        systemCommandManager = system_command_manager()",
            "        printerProfileManager = PrinterProfileManager()",
            "        eventManager = self._event_manager",
            "",
            "        analysis_queue_factories = {",
            "            \"gcode\": octoprint.filemanager.analysis.GcodeAnalysisQueue",
            "        }",
            "        analysis_queue_hooks = pluginManager.get_hooks(",
            "            \"octoprint.filemanager.analysis.factory\"",
            "        )",
            "        for name, hook in analysis_queue_hooks.items():",
            "            try:",
            "                additional_factories = hook()",
            "                analysis_queue_factories.update(**additional_factories)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while processing analysis queues from {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "        analysisQueue = octoprint.filemanager.analysis.AnalysisQueue(",
            "            analysis_queue_factories",
            "        )",
            "",
            "        slicingManager = octoprint.slicing.SlicingManager(",
            "            self._settings.getBaseFolder(\"slicingProfiles\"), printerProfileManager",
            "        )",
            "",
            "        storage_managers = {}",
            "        storage_managers[",
            "            octoprint.filemanager.FileDestinations.LOCAL",
            "        ] = octoprint.filemanager.storage.LocalFileStorage(",
            "            self._settings.getBaseFolder(\"uploads\"),",
            "            really_universal=self._settings.getBoolean(",
            "                [\"feature\", \"enforceReallyUniversalFilenames\"]",
            "            ),",
            "        )",
            "",
            "        fileManager = octoprint.filemanager.FileManager(",
            "            analysisQueue,",
            "            slicingManager,",
            "            printerProfileManager,",
            "            initial_storage_managers=storage_managers,",
            "        )",
            "        pluginLifecycleManager = LifecycleManager(pluginManager)",
            "        preemptiveCache = PreemptiveCache(",
            "            os.path.join(",
            "                self._settings.getBaseFolder(\"data\"), \"preemptive_cache_config.yaml\"",
            "            )",
            "        )",
            "",
            "        JsonEncoding.add_encoder(users.User, lambda obj: obj.as_dict())",
            "        JsonEncoding.add_encoder(groups.Group, lambda obj: obj.as_dict())",
            "        JsonEncoding.add_encoder(",
            "            permissions.OctoPrintPermission, lambda obj: obj.as_dict()",
            "        )",
            "",
            "        # start regular check if we are connected to the internet",
            "        def on_connectivity_change(old_value, new_value):",
            "            eventManager.fire(",
            "                events.Events.CONNECTIVITY_CHANGED,",
            "                payload={\"old\": old_value, \"new\": new_value},",
            "            )",
            "",
            "        connectivityChecker = self._connectivity_checker",
            "        environmentDetector = self._environment_detector",
            "",
            "        def on_settings_update(*args, **kwargs):",
            "            # make sure our connectivity checker runs with the latest settings",
            "            connectivityEnabled = self._settings.getBoolean(",
            "                [\"server\", \"onlineCheck\", \"enabled\"]",
            "            )",
            "            connectivityInterval = self._settings.getInt(",
            "                [\"server\", \"onlineCheck\", \"interval\"]",
            "            )",
            "            connectivityHost = self._settings.get([\"server\", \"onlineCheck\", \"host\"])",
            "            connectivityPort = self._settings.getInt([\"server\", \"onlineCheck\", \"port\"])",
            "            connectivityName = self._settings.get([\"server\", \"onlineCheck\", \"name\"])",
            "",
            "            if (",
            "                connectivityChecker.enabled != connectivityEnabled",
            "                or connectivityChecker.interval != connectivityInterval",
            "                or connectivityChecker.host != connectivityHost",
            "                or connectivityChecker.port != connectivityPort",
            "                or connectivityChecker.name != connectivityName",
            "            ):",
            "                connectivityChecker.enabled = connectivityEnabled",
            "                connectivityChecker.interval = connectivityInterval",
            "                connectivityChecker.host = connectivityHost",
            "                connectivityChecker.port = connectivityPort",
            "                connectivityChecker.name = connectivityName",
            "                connectivityChecker.check_immediately()",
            "",
            "        eventManager.subscribe(events.Events.SETTINGS_UPDATED, on_settings_update)",
            "",
            "        components = {",
            "            \"plugin_manager\": pluginManager,",
            "            \"printer_profile_manager\": printerProfileManager,",
            "            \"event_bus\": eventManager,",
            "            \"analysis_queue\": analysisQueue,",
            "            \"slicing_manager\": slicingManager,",
            "            \"file_manager\": fileManager,",
            "            \"plugin_lifecycle_manager\": pluginLifecycleManager,",
            "            \"preemptive_cache\": preemptiveCache,",
            "            \"json_encoder\": jsonEncoder,",
            "            \"json_decoder\": jsonDecoder,",
            "            \"connectivity_checker\": connectivityChecker,",
            "            \"environment_detector\": self._environment_detector,",
            "            \"system_commands\": systemCommandManager,",
            "        }",
            "",
            "        # ~~ setup access control",
            "",
            "        # get additional permissions from plugins",
            "        self._setup_plugin_permissions()",
            "",
            "        # create group manager instance",
            "        group_manager_factories = pluginManager.get_hooks(",
            "            \"octoprint.access.groups.factory\"",
            "        )",
            "        for name, factory in group_manager_factories.items():",
            "            try:",
            "                groupManager = factory(components, self._settings)",
            "                if groupManager is not None:",
            "                    self._logger.debug(",
            "                        f\"Created group manager instance from factory {name}\"",
            "                    )",
            "                    break",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while creating group manager instance from factory {}\".format(",
            "                        name",
            "                    )",
            "                )",
            "        else:",
            "            group_manager_name = self._settings.get([\"accessControl\", \"groupManager\"])",
            "            try:",
            "                clazz = octoprint.util.get_class(group_manager_name)",
            "                groupManager = clazz()",
            "            except AttributeError:",
            "                self._logger.exception(",
            "                    \"Could not instantiate group manager {}, \"",
            "                    \"falling back to FilebasedGroupManager!\".format(group_manager_name)",
            "                )",
            "                groupManager = octoprint.access.groups.FilebasedGroupManager()",
            "        components.update({\"group_manager\": groupManager})",
            "",
            "        # create user manager instance",
            "        user_manager_factories = pluginManager.get_hooks(",
            "            \"octoprint.users.factory\"",
            "        )  # legacy, set first so that new wins",
            "        user_manager_factories.update(",
            "            pluginManager.get_hooks(\"octoprint.access.users.factory\")",
            "        )",
            "        for name, factory in user_manager_factories.items():",
            "            try:",
            "                userManager = factory(components, self._settings)",
            "                if userManager is not None:",
            "                    self._logger.debug(",
            "                        f\"Created user manager instance from factory {name}\"",
            "                    )",
            "                    break",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while creating user manager instance from factory {}\".format(",
            "                        name",
            "                    ),",
            "                    extra={\"plugin\": name},",
            "                )",
            "        else:",
            "            user_manager_name = self._settings.get([\"accessControl\", \"userManager\"])",
            "            try:",
            "                clazz = octoprint.util.get_class(user_manager_name)",
            "                userManager = clazz(groupManager)",
            "            except octoprint.access.users.CorruptUserStorage:",
            "                raise",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Could not instantiate user manager {}, \"",
            "                    \"falling back to FilebasedUserManager!\".format(user_manager_name)",
            "                )",
            "                userManager = octoprint.access.users.FilebasedUserManager(groupManager)",
            "        components.update({\"user_manager\": userManager})",
            "",
            "        # create printer instance",
            "        printer_factories = pluginManager.get_hooks(\"octoprint.printer.factory\")",
            "        for name, factory in printer_factories.items():",
            "            try:",
            "                printer = factory(components)",
            "                if printer is not None:",
            "                    self._logger.debug(f\"Created printer instance from factory {name}\")",
            "                    break",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while creating printer instance from factory {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "        else:",
            "            printer = Printer(fileManager, analysisQueue, printerProfileManager)",
            "        components.update({\"printer\": printer})",
            "",
            "        from octoprint import (",
            "            init_custom_events,",
            "            init_settings_plugin_config_migration_and_cleanup,",
            "            init_webcam_compat_overlay,",
            "        )",
            "        from octoprint import octoprint_plugin_inject_factory as opif",
            "        from octoprint import settings_plugin_inject_factory as spif",
            "",
            "        init_custom_events(pluginManager)",
            "",
            "        octoprint_plugin_inject_factory = opif(self._settings, components)",
            "        settings_plugin_inject_factory = spif(self._settings)",
            "",
            "        pluginManager.implementation_inject_factories = [",
            "            octoprint_plugin_inject_factory,",
            "            settings_plugin_inject_factory,",
            "        ]",
            "        pluginManager.initialize_implementations()",
            "",
            "        init_settings_plugin_config_migration_and_cleanup(pluginManager)",
            "        init_webcam_compat_overlay(self._settings, pluginManager)",
            "",
            "        pluginManager.log_all_plugins()",
            "",
            "        # log environment data now",
            "        self._environment_detector.log_detected_environment()",
            "",
            "        # initialize file manager and register it for changes in the registered plugins",
            "        fileManager.initialize()",
            "        pluginLifecycleManager.add_callback(",
            "            [\"enabled\", \"disabled\"], lambda name, plugin: fileManager.reload_plugins()",
            "        )",
            "",
            "        # initialize slicing manager and register it for changes in the registered plugins",
            "        slicingManager.initialize()",
            "        pluginLifecycleManager.add_callback(",
            "            [\"enabled\", \"disabled\"], lambda name, plugin: slicingManager.reload_slicers()",
            "        )",
            "",
            "        # setup jinja2",
            "        self._setup_jinja2()",
            "",
            "        # setup assets",
            "        self._setup_assets()",
            "",
            "        # configure timelapse",
            "        octoprint.timelapse.valid_timelapse(\"test\")",
            "        octoprint.timelapse.configure_timelapse()",
            "",
            "        # setup command triggers",
            "        events.CommandTrigger(printer)",
            "        if self._debug:",
            "            events.DebugEventListener()",
            "",
            "        # setup login manager",
            "        self._setup_login_manager()",
            "",
            "        # register API blueprint",
            "        self._setup_blueprints()",
            "",
            "        ## Tornado initialization starts here",
            "",
            "        ioloop = IOLoop.current()",
            "",
            "        enable_cors = settings().getBoolean([\"api\", \"allowCrossOrigin\"])",
            "",
            "        self._router = SockJSRouter(",
            "            self._create_socket_connection,",
            "            \"/sockjs\",",
            "            session_kls=util.sockjs.ThreadSafeSession,",
            "            user_settings={",
            "                \"websocket_allow_origin\": \"*\" if enable_cors else \"\",",
            "                \"jsessionid\": False,",
            "                \"sockjs_url\": \"../../static/js/lib/sockjs.min.js\",",
            "            },",
            "        )",
            "",
            "        upload_suffixes = {",
            "            \"name\": self._settings.get([\"server\", \"uploads\", \"nameSuffix\"]),",
            "            \"path\": self._settings.get([\"server\", \"uploads\", \"pathSuffix\"]),",
            "        }",
            "",
            "        def mime_type_guesser(path):",
            "            from octoprint.filemanager import get_mime_type",
            "",
            "            return get_mime_type(path)",
            "",
            "        def download_name_generator(path):",
            "            metadata = fileManager.get_metadata(\"local\", path)",
            "            if metadata and \"display\" in metadata:",
            "                return metadata[\"display\"]",
            "",
            "        download_handler_kwargs = {\"as_attachment\": True, \"allow_client_caching\": False}",
            "",
            "        additional_mime_types = {\"mime_type_guesser\": mime_type_guesser}",
            "",
            "        ##~~ Permission validators",
            "",
            "        access_validators_from_plugins = []",
            "        for plugin, hook in pluginManager.get_hooks(",
            "            \"octoprint.server.http.access_validator\"",
            "        ).items():",
            "            try:",
            "                access_validators_from_plugins.append(",
            "                    util.tornado.access_validation_factory(app, hook)",
            "                )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while adding tornado access validator from plugin {}\".format(",
            "                        plugin",
            "                    ),",
            "                    extra={\"plugin\": plugin},",
            "                )",
            "",
            "        timelapse_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app,",
            "                util.flask.permission_validator,",
            "                permissions.Permissions.TIMELAPSE_LIST,",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        download_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app,",
            "                util.flask.permission_validator,",
            "                permissions.Permissions.FILES_DOWNLOAD,",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        log_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app,",
            "                util.flask.permission_validator,",
            "                permissions.Permissions.PLUGIN_LOGGING_MANAGE,",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        camera_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app, util.flask.permission_validator, permissions.Permissions.WEBCAM",
            "            ),",
            "        ] + access_validators_from_plugins",
            "        systeminfo_validators = [",
            "            util.tornado.access_validation_factory(",
            "                app, util.flask.permission_validator, permissions.Permissions.SYSTEM",
            "            )",
            "        ] + access_validators_from_plugins",
            "",
            "        timelapse_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*timelapse_validators)",
            "        }",
            "        download_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*download_validators)",
            "        }",
            "        log_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*log_validators)",
            "        }",
            "        camera_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*camera_validators)",
            "        }",
            "        systeminfo_permission_validator = {",
            "            \"access_validation\": util.tornado.validation_chain(*systeminfo_validators)",
            "        }",
            "",
            "        no_hidden_files_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: not octoprint.util.is_hidden_path(path), status_code=404",
            "            )",
            "        }",
            "",
            "        only_known_types_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: octoprint.filemanager.valid_file_type(",
            "                    os.path.basename(path)",
            "                ),",
            "                status_code=404,",
            "            )",
            "        }",
            "",
            "        valid_timelapse = lambda path: not octoprint.util.is_hidden_path(path) and (",
            "            octoprint.timelapse.valid_timelapse(path)",
            "            or octoprint.timelapse.valid_timelapse_thumbnail(path)",
            "        )",
            "        timelapse_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                valid_timelapse,",
            "                status_code=404,",
            "            )",
            "        }",
            "        timelapses_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: valid_timelapse(path)",
            "                and os.path.realpath(os.path.abspath(path)).startswith(",
            "                    settings().getBaseFolder(\"timelapse\")",
            "                ),",
            "                status_code=400,",
            "            )",
            "        }",
            "",
            "        valid_log = lambda path: not octoprint.util.is_hidden_path(",
            "            path",
            "        ) and path.endswith(\".log\")",
            "        log_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                valid_log,",
            "                status_code=404,",
            "            )",
            "        }",
            "        logs_path_validator = {",
            "            \"path_validation\": util.tornado.path_validation_factory(",
            "                lambda path: valid_log(path)",
            "                and os.path.realpath(os.path.abspath(path)).startswith(",
            "                    settings().getBaseFolder(\"logs\")",
            "                ),",
            "                status_code=400,",
            "            )",
            "        }",
            "",
            "        def joined_dict(*dicts):",
            "            if not len(dicts):",
            "                return {}",
            "",
            "            joined = {}",
            "            for d in dicts:",
            "                joined.update(d)",
            "            return joined",
            "",
            "        util.tornado.RequestlessExceptionLoggingMixin.LOG_REQUEST = debug",
            "        util.tornado.CorsSupportMixin.ENABLE_CORS = enable_cors",
            "",
            "        server_routes = self._router.urls + [",
            "            # various downloads",
            "            # .mpg and .mp4 timelapses:",
            "            (",
            "                r\"/downloads/timelapse/(.*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                joined_dict(",
            "                    {\"path\": self._settings.getBaseFolder(\"timelapse\")},",
            "                    timelapse_permission_validator,",
            "                    download_handler_kwargs,",
            "                    timelapse_path_validator,",
            "                ),",
            "            ),",
            "            # zipped timelapse bundles",
            "            (",
            "                r\"/downloads/timelapses\",",
            "                util.tornado.DynamicZipBundleHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"as_attachment\": True,",
            "                        \"attachment_name\": \"octoprint-timelapses.zip\",",
            "                        \"path_processor\": lambda x: (",
            "                            x,",
            "                            os.path.join(self._settings.getBaseFolder(\"timelapse\"), x),",
            "                        ),",
            "                    },",
            "                    timelapse_permission_validator,",
            "                    timelapses_path_validator,",
            "                ),",
            "            ),",
            "            # uploaded printables",
            "            (",
            "                r\"/downloads/files/local/(.*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"path\": self._settings.getBaseFolder(\"uploads\"),",
            "                        \"as_attachment\": True,",
            "                        \"name_generator\": download_name_generator,",
            "                    },",
            "                    download_permission_validator,",
            "                    download_handler_kwargs,",
            "                    no_hidden_files_validator,",
            "                    only_known_types_validator,",
            "                    additional_mime_types,",
            "                ),",
            "            ),",
            "            # log files",
            "            (",
            "                r\"/downloads/logs/([^/]*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"path\": self._settings.getBaseFolder(\"logs\"),",
            "                        \"mime_type_guesser\": lambda *args, **kwargs: \"text/plain\",",
            "                        \"stream_body\": True,",
            "                    },",
            "                    download_handler_kwargs,",
            "                    log_permission_validator,",
            "                    log_path_validator,",
            "                ),",
            "            ),",
            "            # zipped log file bundles",
            "            (",
            "                r\"/downloads/logs\",",
            "                util.tornado.DynamicZipBundleHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"as_attachment\": True,",
            "                        \"attachment_name\": \"octoprint-logs.zip\",",
            "                        \"path_processor\": lambda x: (",
            "                            x,",
            "                            os.path.join(self._settings.getBaseFolder(\"logs\"), x),",
            "                        ),",
            "                    },",
            "                    log_permission_validator,",
            "                    logs_path_validator,",
            "                ),",
            "            ),",
            "            # system info bundle",
            "            (",
            "                r\"/downloads/systeminfo.zip\",",
            "                util.tornado.SystemInfoBundleHandler,",
            "                systeminfo_permission_validator,",
            "            ),",
            "            # camera snapshot",
            "            (",
            "                r\"/downloads/camera/current\",",
            "                util.tornado.WebcamSnapshotHandler,",
            "                joined_dict(",
            "                    {",
            "                        \"as_attachment\": \"snapshot\",",
            "                    },",
            "                    camera_permission_validator,",
            "                ),",
            "            ),",
            "            # generated webassets",
            "            (",
            "                r\"/static/webassets/(.*)\",",
            "                util.tornado.LargeResponseHandler,",
            "                {",
            "                    \"path\": os.path.join(",
            "                        self._settings.getBaseFolder(\"generated\"), \"webassets\"",
            "                    ),",
            "                    \"is_pre_compressed\": True,",
            "                },",
            "            ),",
            "            # online indicators - text file with \"online\" as content and a transparent gif",
            "            (r\"/online.txt\", util.tornado.StaticDataHandler, {\"data\": \"online\\n\"}),",
            "            (",
            "                r\"/online.gif\",",
            "                util.tornado.StaticDataHandler,",
            "                {",
            "                    \"data\": bytes(",
            "                        base64.b64decode(",
            "                            \"R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"",
            "                        )",
            "                    ),",
            "                    \"content_type\": \"image/gif\",",
            "                },",
            "            ),",
            "            # deprecated endpoints",
            "            (",
            "                r\"/api/logs\",",
            "                util.tornado.DeprecatedEndpointHandler,",
            "                {\"url\": \"/plugin/logging/logs\"},",
            "            ),",
            "            (",
            "                r\"/api/logs/(.*)\",",
            "                util.tornado.DeprecatedEndpointHandler,",
            "                {\"url\": \"/plugin/logging/logs/{0}\"},",
            "            ),",
            "        ]",
            "",
            "        # fetch additional routes from plugins",
            "        for name, hook in pluginManager.get_hooks(\"octoprint.server.http.routes\").items():",
            "            try:",
            "                result = hook(list(server_routes))",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"There was an error while retrieving additional \"",
            "                    f\"server routes from plugin hook {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "            else:",
            "                if isinstance(result, (list, tuple)):",
            "                    for entry in result:",
            "                        if not isinstance(entry, tuple) or not len(entry) == 3:",
            "                            continue",
            "                        if not isinstance(entry[0], str):",
            "                            continue",
            "                        if not isinstance(entry[2], dict):",
            "                            continue",
            "",
            "                        route, handler, kwargs = entry",
            "                        route = r\"/plugin/{name}/{route}\".format(",
            "                            name=name,",
            "                            route=route if not route.startswith(\"/\") else route[1:],",
            "                        )",
            "",
            "                        self._logger.debug(",
            "                            f\"Adding additional route {route} handled by handler {handler} and with additional arguments {kwargs!r}\"",
            "                        )",
            "                        server_routes.append((route, handler, kwargs))",
            "",
            "        headers = {",
            "            \"X-Robots-Tag\": \"noindex, nofollow, noimageindex\",",
            "            \"X-Content-Type-Options\": \"nosniff\",",
            "        }",
            "        if not settings().getBoolean([\"server\", \"allowFraming\"]):",
            "            headers[\"X-Frame-Options\"] = \"sameorigin\"",
            "",
            "        removed_headers = [\"Server\"]",
            "",
            "        from concurrent.futures import ThreadPoolExecutor",
            "",
            "        server_routes.append(",
            "            (",
            "                r\".*\",",
            "                util.tornado.UploadStorageFallbackHandler,",
            "                {",
            "                    \"fallback\": util.tornado.WsgiInputContainer(",
            "                        app.wsgi_app,",
            "                        executor=ThreadPoolExecutor(",
            "                            thread_name_prefix=\"WsgiRequestHandler\"",
            "                        ),",
            "                        headers=headers,",
            "                        removed_headers=removed_headers,",
            "                    ),",
            "                    \"file_prefix\": \"octoprint-file-upload-\",",
            "                    \"file_suffix\": \".tmp\",",
            "                    \"suffixes\": upload_suffixes,",
            "                },",
            "            )",
            "        )",
            "",
            "        transforms = [",
            "            util.tornado.GlobalHeaderTransform.for_headers(",
            "                \"OctoPrintGlobalHeaderTransform\",",
            "                headers=headers,",
            "                removed_headers=removed_headers,",
            "            )",
            "        ]",
            "",
            "        self._tornado_app = Application(handlers=server_routes, transforms=transforms)",
            "        max_body_sizes = [",
            "            (",
            "                \"POST\",",
            "                r\"/api/files/([^/]*)\",",
            "                self._settings.getInt([\"server\", \"uploads\", \"maxSize\"]),",
            "            ),",
            "            (\"POST\", r\"/api/languages\", 5 * 1024 * 1024),",
            "        ]",
            "",
            "        # allow plugins to extend allowed maximum body sizes",
            "        for name, hook in pluginManager.get_hooks(",
            "            \"octoprint.server.http.bodysize\"",
            "        ).items():",
            "            try:",
            "                result = hook(list(max_body_sizes))",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"There was an error while retrieving additional \"",
            "                    f\"upload sizes from plugin hook {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "            else:",
            "                if isinstance(result, (list, tuple)):",
            "                    for entry in result:",
            "                        if not isinstance(entry, tuple) or not len(entry) == 3:",
            "                            continue",
            "                        if (",
            "                            entry[0]",
            "                            not in util.tornado.UploadStorageFallbackHandler.BODY_METHODS",
            "                        ):",
            "                            continue",
            "                        if not isinstance(entry[2], int):",
            "                            continue",
            "",
            "                        method, route, size = entry",
            "                        route = r\"/plugin/{name}/{route}\".format(",
            "                            name=name,",
            "                            route=route if not route.startswith(\"/\") else route[1:],",
            "                        )",
            "",
            "                        self._logger.debug(",
            "                            f\"Adding maximum body size of {size}B for {method} requests to {route})\"",
            "                        )",
            "                        max_body_sizes.append((method, route, size))",
            "",
            "        self._stop_intermediary_server()",
            "",
            "        # initialize and bind the server",
            "        trusted_downstream = self._settings.get(",
            "            [\"server\", \"reverseProxy\", \"trustedDownstream\"]",
            "        )",
            "        if not isinstance(trusted_downstream, list):",
            "            self._logger.warning(",
            "                \"server.reverseProxy.trustedDownstream is not a list, skipping\"",
            "            )",
            "            trusted_downstream = []",
            "",
            "        server_kwargs = {",
            "            \"max_body_sizes\": max_body_sizes,",
            "            \"default_max_body_size\": self._settings.getInt([\"server\", \"maxSize\"]),",
            "            \"xheaders\": True,",
            "            \"trusted_downstream\": trusted_downstream,",
            "        }",
            "        if sys.platform == \"win32\":",
            "            # set 10min idle timeout under windows to hopefully make #2916 less likely",
            "            server_kwargs.update({\"idle_connection_timeout\": 600})",
            "",
            "        self._server = util.tornado.CustomHTTPServer(self._tornado_app, **server_kwargs)",
            "",
            "        listening_address = self._host",
            "        if self._host == \"::\" and not self._v6_only:",
            "            # special case - tornado only listens on v4 _and_ v6 if we use None as address",
            "            listening_address = None",
            "",
            "        self._server.listen(self._port, address=listening_address)",
            "",
            "        ### From now on it's ok to launch subprocesses again",
            "",
            "        eventManager.fire(events.Events.STARTUP)",
            "",
            "        # analysis backlog",
            "        fileManager.process_backlog()",
            "",
            "        # auto connect",
            "        if self._settings.getBoolean([\"serial\", \"autoconnect\"]):",
            "            self._logger.info(",
            "                \"Autoconnect on startup is configured, trying to connect to the printer...\"",
            "            )",
            "            try:",
            "                (port, baudrate) = (",
            "                    self._settings.get([\"serial\", \"port\"]),",
            "                    self._settings.getInt([\"serial\", \"baudrate\"]),",
            "                )",
            "                printer_profile = printerProfileManager.get_default()",
            "                connectionOptions = printer.__class__.get_connection_options()",
            "                if port in connectionOptions[\"ports\"] or port == \"AUTO\" or port is None:",
            "                    self._logger.info(",
            "                        f\"Trying to connect to configured serial port {port}\"",
            "                    )",
            "                    printer.connect(",
            "                        port=port,",
            "                        baudrate=baudrate,",
            "                        profile=printer_profile[\"id\"]",
            "                        if \"id\" in printer_profile",
            "                        else \"_default\",",
            "                    )",
            "                else:",
            "                    self._logger.info(",
            "                        \"Could not find configured serial port {} in the system, cannot automatically connect to a non existing printer. Is it plugged in and booted up yet?\"",
            "                    )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Something went wrong while attempting to automatically connect to the printer\"",
            "                )",
            "",
            "        # auto refresh serial ports while not connected",
            "        if self._settings.getBoolean([\"serial\", \"autorefresh\"]):",
            "            from octoprint.util.comm import serialList",
            "",
            "            last_ports = None",
            "            autorefresh = None",
            "",
            "            def refresh_serial_list():",
            "                nonlocal last_ports",
            "",
            "                new_ports = sorted(serialList())",
            "                if new_ports != last_ports:",
            "                    self._logger.info(",
            "                        \"Serial port list was updated, refreshing the port list in the frontend\"",
            "                    )",
            "                    eventManager.fire(",
            "                        events.Events.CONNECTIONS_AUTOREFRESHED,",
            "                        payload={\"ports\": new_ports},",
            "                    )",
            "                last_ports = new_ports",
            "",
            "            def autorefresh_active():",
            "                return printer.is_closed_or_error()",
            "",
            "            def autorefresh_stopped():",
            "                nonlocal autorefresh",
            "",
            "                self._logger.info(\"Autorefresh of serial port list stopped\")",
            "                autorefresh = None",
            "",
            "            def run_autorefresh():",
            "                nonlocal autorefresh",
            "",
            "                if autorefresh is not None:",
            "                    autorefresh.cancel()",
            "                    autorefresh = None",
            "",
            "                autorefresh = octoprint.util.RepeatedTimer(",
            "                    self._settings.getInt([\"serial\", \"autorefreshInterval\"]),",
            "                    refresh_serial_list,",
            "                    run_first=True,",
            "                    condition=autorefresh_active,",
            "                    on_finish=autorefresh_stopped,",
            "                )",
            "                autorefresh.name = \"Serial autorefresh worker\"",
            "",
            "                self._logger.info(\"Starting autorefresh of serial port list\")",
            "                autorefresh.start()",
            "",
            "            run_autorefresh()",
            "            eventManager.subscribe(",
            "                octoprint.events.Events.DISCONNECTED, lambda e, p: run_autorefresh()",
            "            )",
            "",
            "        # start up watchdogs",
            "        try:",
            "            watched = self._settings.getBaseFolder(\"watched\")",
            "            watchdog_handler = util.watchdog.GcodeWatchdogHandler(fileManager, printer)",
            "            watchdog_handler.initial_scan(watched)",
            "",
            "            if self._settings.getBoolean([\"feature\", \"pollWatched\"]):",
            "                # use less performant polling observer if explicitly configured",
            "                observer = PollingObserver()",
            "            else:",
            "                # use os default",
            "                observer = Observer()",
            "",
            "            observer.schedule(watchdog_handler, watched, recursive=True)",
            "            observer.start()",
            "        except Exception:",
            "            self._logger.exception(\"Error starting watched folder observer\")",
            "",
            "        # run our startup plugins",
            "        octoprint.plugin.call_plugin(",
            "            octoprint.plugin.StartupPlugin,",
            "            \"on_startup\",",
            "            args=(self._host, self._port),",
            "            sorting_context=\"StartupPlugin.on_startup\",",
            "        )",
            "",
            "        def call_on_startup(name, plugin):",
            "            implementation = plugin.get_implementation(octoprint.plugin.StartupPlugin)",
            "            if implementation is None:",
            "                return",
            "            implementation.on_startup(self._host, self._port)",
            "",
            "        pluginLifecycleManager.add_callback(\"enabled\", call_on_startup)",
            "",
            "        # prepare our after startup function",
            "        def on_after_startup():",
            "            if self._host == \"::\":",
            "                if self._v6_only:",
            "                    # only v6",
            "                    self._logger.info(f\"Listening on http://[::]:{self._port}\")",
            "                else:",
            "                    # all v4 and v6",
            "                    self._logger.info(",
            "                        \"Listening on http://0.0.0.0:{port} and http://[::]:{port}\".format(",
            "                            port=self._port",
            "                        )",
            "                    )",
            "            else:",
            "                self._logger.info(",
            "                    \"Listening on http://{}:{}\".format(",
            "                        self._host if \":\" not in self._host else \"[\" + self._host + \"]\",",
            "                        self._port,",
            "                    )",
            "                )",
            "",
            "            if safe_mode and self._settings.getBoolean([\"server\", \"startOnceInSafeMode\"]):",
            "                self._logger.info(",
            "                    \"Server started successfully in safe mode as requested from config, removing flag\"",
            "                )",
            "                self._settings.setBoolean([\"server\", \"startOnceInSafeMode\"], False)",
            "                self._settings.save()",
            "",
            "            # now this is somewhat ugly, but the issue is the following: startup plugins might want to do things for",
            "            # which they need the server to be already alive (e.g. for being able to resolve urls, such as favicons",
            "            # or service xmls or the like). While they are working though the ioloop would block. Therefore we'll",
            "            # create a single use thread in which to perform our after-startup-tasks, start that and hand back",
            "            # control to the ioloop",
            "            def work():",
            "                octoprint.plugin.call_plugin(",
            "                    octoprint.plugin.StartupPlugin,",
            "                    \"on_after_startup\",",
            "                    sorting_context=\"StartupPlugin.on_after_startup\",",
            "                )",
            "",
            "                def call_on_after_startup(name, plugin):",
            "                    implementation = plugin.get_implementation(",
            "                        octoprint.plugin.StartupPlugin",
            "                    )",
            "                    if implementation is None:",
            "                        return",
            "                    implementation.on_after_startup()",
            "",
            "                pluginLifecycleManager.add_callback(\"enabled\", call_on_after_startup)",
            "",
            "                # if there was a rogue plugin we wouldn't even have made it here, so remove startup triggered safe mode",
            "                # flag again...",
            "                try:",
            "                    if incomplete_startup_flag.exists():",
            "                        incomplete_startup_flag.unlink()",
            "                except Exception:",
            "                    self._logger.exception(",
            "                        \"Could not clear startup triggered safe mode flag\"",
            "                    )",
            "",
            "                # make a backup of the current config",
            "                self._settings.backup(ext=\"backup\")",
            "",
            "                # when we are through with that we also run our preemptive cache",
            "                if settings().getBoolean([\"devel\", \"cache\", \"preemptive\"]):",
            "                    self._execute_preemptive_flask_caching(preemptiveCache)",
            "",
            "            import threading",
            "",
            "            threading.Thread(target=work).start()",
            "",
            "        ioloop.add_callback(on_after_startup)",
            "",
            "        # prepare our shutdown function",
            "        def on_shutdown():",
            "            # will be called on clean system exit and shutdown the watchdog observer and call the on_shutdown methods",
            "            # on all registered ShutdownPlugins",
            "            self._logger.info(\"Shutting down...\")",
            "            observer.stop()",
            "            observer.join()",
            "            eventManager.fire(events.Events.SHUTDOWN)",
            "",
            "            self._logger.info(\"Calling on_shutdown on plugins\")",
            "            octoprint.plugin.call_plugin(",
            "                octoprint.plugin.ShutdownPlugin,",
            "                \"on_shutdown\",",
            "                sorting_context=\"ShutdownPlugin.on_shutdown\",",
            "            )",
            "",
            "            # wait for shutdown event to be processed, but maximally for 15s",
            "            event_timeout = 15.0",
            "            if eventManager.join(timeout=event_timeout):",
            "                self._logger.warning(",
            "                    \"Event loop was still busy processing after {}s, shutting down anyhow\".format(",
            "                        event_timeout",
            "                    )",
            "                )",
            "",
            "            if self._octoprint_daemon is not None:",
            "                self._logger.info(\"Cleaning up daemon pidfile\")",
            "                self._octoprint_daemon.terminated()",
            "",
            "            self._logger.info(\"Goodbye!\")",
            "",
            "        atexit.register(on_shutdown)",
            "",
            "        def sigterm_handler(*args, **kwargs):",
            "            # will stop tornado on SIGTERM, making the program exit cleanly",
            "            def shutdown_tornado():",
            "                self._logger.debug(\"Shutting down tornado's IOLoop...\")",
            "                ioloop.stop()",
            "",
            "            self._logger.debug(\"SIGTERM received...\")",
            "            ioloop.add_callback_from_signal(shutdown_tornado)",
            "",
            "        signal.signal(signal.SIGTERM, sigterm_handler)",
            "",
            "        try:",
            "            # this is the main loop - as long as tornado is running, OctoPrint is running",
            "            ioloop.start()",
            "            self._logger.debug(\"Tornado's IOLoop stopped\")",
            "        except (KeyboardInterrupt, SystemExit):",
            "            pass",
            "        except Exception:",
            "            self._logger.fatal(",
            "                \"Now that is embarrassing... Something went really really wrong here. Please report this including the stacktrace below in OctoPrint's bugtracker. Thanks!\"",
            "            )",
            "            self._logger.exception(\"Stacktrace follows:\")",
            "",
            "    def _log_safe_mode_start(self, self_mode):",
            "        self_mode_file = os.path.join(",
            "            self._settings.getBaseFolder(\"data\"), \"last_safe_mode\"",
            "        )",
            "        try:",
            "            with open(self_mode_file, \"w+\", encoding=\"utf-8\") as f:",
            "                f.write(self_mode)",
            "        except Exception as ex:",
            "            self._logger.warn(f\"Could not write safe mode file {self_mode_file}: {ex}\")",
            "",
            "    def _create_socket_connection(self, session):",
            "        global printer, fileManager, analysisQueue, userManager, eventManager, connectivityChecker",
            "        return util.sockjs.PrinterStateConnection(",
            "            printer,",
            "            fileManager,",
            "            analysisQueue,",
            "            userManager,",
            "            groupManager,",
            "            eventManager,",
            "            pluginManager,",
            "            connectivityChecker,",
            "            session,",
            "        )",
            "",
            "    def _check_for_root(self):",
            "        if \"geteuid\" in dir(os) and os.geteuid() == 0:",
            "            exit(\"You should not run OctoPrint as root!\")",
            "",
            "    def _get_locale(self):",
            "        global LANGUAGES",
            "",
            "        l10n = None",
            "        default_language = self._settings.get([\"appearance\", \"defaultLanguage\"])",
            "",
            "        if \"l10n\" in request.values:",
            "            # request: query param",
            "            l10n = request.values[\"l10n\"].split(\",\")",
            "",
            "        elif \"X-Locale\" in request.headers:",
            "            # request: header",
            "            l10n = request.headers[\"X-Locale\"].split(\",\")",
            "",
            "        elif hasattr(g, \"identity\") and g.identity:",
            "            # user setting",
            "            userid = g.identity.id",
            "            try:",
            "                user_language = userManager.get_user_setting(",
            "                    userid, (\"interface\", \"language\")",
            "                )",
            "                if user_language is not None and not user_language == \"_default\":",
            "                    l10n = [user_language]",
            "            except octoprint.access.users.UnknownUser:",
            "                pass",
            "",
            "        if (",
            "            not l10n",
            "            and default_language is not None",
            "            and not default_language == \"_default\"",
            "            and default_language in LANGUAGES",
            "        ):",
            "            # instance setting",
            "            l10n = [default_language]",
            "",
            "        if l10n:",
            "            # canonicalize and get rid of invalid language codes",
            "            l10n_canonicalized = []",
            "            for x in l10n:",
            "                try:",
            "                    l10n_canonicalized.append(str(Locale.parse(x)))",
            "                except Exception:",
            "                    # invalid language code, ignore",
            "                    continue",
            "            return Locale.negotiate(l10n_canonicalized, LANGUAGES)",
            "",
            "        # request: preference",
            "        return Locale.parse(request.accept_languages.best_match(LANGUAGES, default=\"en\"))",
            "",
            "    def _setup_heartbeat_logging(self):",
            "        logger = logging.getLogger(__name__ + \".heartbeat\")",
            "",
            "        def log_heartbeat():",
            "            logger.info(\"Server heartbeat <3\")",
            "",
            "        interval = settings().getFloat([\"server\", \"heartbeat\"])",
            "        logger.info(f\"Starting server heartbeat, {interval}s interval\")",
            "",
            "        timer = octoprint.util.RepeatedTimer(interval, log_heartbeat)",
            "        timer.start()",
            "",
            "    def _setup_app(self, app):",
            "        global limiter",
            "",
            "        from octoprint.server.util.flask import (",
            "            OctoPrintFlaskRequest,",
            "            OctoPrintFlaskResponse,",
            "            OctoPrintJsonProvider,",
            "            OctoPrintSessionInterface,",
            "            PrefixAwareJinjaEnvironment,",
            "            ReverseProxiedEnvironment,",
            "        )",
            "",
            "        # we must set this here because setting app.debug will access app.jinja_env",
            "        app.jinja_environment = PrefixAwareJinjaEnvironment",
            "",
            "        app.config[\"TEMPLATES_AUTO_RELOAD\"] = True",
            "        app.config[\"REMEMBER_COOKIE_DURATION\"] = 90 * 24 * 60 * 60  # 90 days",
            "        app.config[\"REMEMBER_COOKIE_HTTPONLY\"] = True",
            "        # REMEMBER_COOKIE_SECURE will be taken care of by our custom cookie handling",
            "",
            "        # we must not set this before TEMPLATES_AUTO_RELOAD is set to True or that won't take",
            "        app.debug = self._debug",
            "",
            "        # setup octoprint's flask json serialization/deserialization",
            "        app.json = OctoPrintJsonProvider(app)",
            "        app.json.compact = False",
            "",
            "        s = settings()",
            "",
            "        secret_key = s.get([\"server\", \"secretKey\"])",
            "        if not secret_key:",
            "            import string",
            "            from random import choice",
            "",
            "            chars = string.ascii_lowercase + string.ascii_uppercase + string.digits",
            "            secret_key = \"\".join(choice(chars) for _ in range(32))",
            "            s.set([\"server\", \"secretKey\"], secret_key)",
            "            s.save()",
            "",
            "        app.secret_key = secret_key",
            "",
            "        reverse_proxied = ReverseProxiedEnvironment(",
            "            header_prefix=s.get([\"server\", \"reverseProxy\", \"prefixHeader\"]),",
            "            header_scheme=s.get([\"server\", \"reverseProxy\", \"schemeHeader\"]),",
            "            header_host=s.get([\"server\", \"reverseProxy\", \"hostHeader\"]),",
            "            header_server=s.get([\"server\", \"reverseProxy\", \"serverHeader\"]),",
            "            header_port=s.get([\"server\", \"reverseProxy\", \"portHeader\"]),",
            "            prefix=s.get([\"server\", \"reverseProxy\", \"prefixFallback\"]),",
            "            scheme=s.get([\"server\", \"reverseProxy\", \"schemeFallback\"]),",
            "            host=s.get([\"server\", \"reverseProxy\", \"hostFallback\"]),",
            "            server=s.get([\"server\", \"reverseProxy\", \"serverFallback\"]),",
            "            port=s.get([\"server\", \"reverseProxy\", \"portFallback\"]),",
            "        )",
            "",
            "        OctoPrintFlaskRequest.environment_wrapper = reverse_proxied",
            "        app.request_class = OctoPrintFlaskRequest",
            "        app.response_class = OctoPrintFlaskResponse",
            "        app.session_interface = OctoPrintSessionInterface()",
            "",
            "        @app.before_request",
            "        def before_request():",
            "            g.locale = self._get_locale()",
            "",
            "            # used for performance measurement",
            "            g.start_time = time.monotonic()",
            "",
            "            if self._debug and \"perfprofile\" in request.args:",
            "                try:",
            "                    from pyinstrument import Profiler",
            "",
            "                    g.perfprofiler = Profiler()",
            "                    g.perfprofiler.start()",
            "                except ImportError:",
            "                    # profiler dependency not installed, ignore",
            "                    pass",
            "",
            "        @app.after_request",
            "        def after_request(response):",
            "            # send no-cache headers with all POST responses",
            "            if request.method == \"POST\":",
            "                response.cache_control.no_cache = True",
            "",
            "            response.headers.add(\"X-Clacks-Overhead\", \"GNU Terry Pratchett\")",
            "",
            "            if hasattr(g, \"perfprofiler\"):",
            "                g.perfprofiler.stop()",
            "                output_html = g.perfprofiler.output_html()",
            "                return make_response(output_html)",
            "",
            "            if hasattr(g, \"start_time\"):",
            "                end_time = time.monotonic()",
            "                duration_ms = int((end_time - g.start_time) * 1000)",
            "                response.headers.add(\"Server-Timing\", f\"app;dur={duration_ms}\")",
            "",
            "            return response",
            "",
            "        from octoprint.util.jinja import MarkdownFilter",
            "",
            "        MarkdownFilter(app)",
            "",
            "        from flask_limiter import Limiter",
            "        from flask_limiter.util import get_remote_address",
            "",
            "        app.config[\"RATELIMIT_STRATEGY\"] = \"fixed-window-elastic-expiry\"",
            "",
            "        limiter = Limiter(",
            "            key_func=get_remote_address,",
            "            app=app,",
            "            enabled=s.getBoolean([\"devel\", \"enableRateLimiter\"]),",
            "            storage_uri=\"memory://\",",
            "        )",
            "",
            "    def _setup_i18n(self, app, additional_folders=None):",
            "        global babel",
            "        global LOCALES",
            "        global LANGUAGES",
            "",
            "        if additional_folders is None:",
            "            additional_folders = []",
            "",
            "        dirs = additional_folders + [os.path.join(app.root_path, \"translations\")]",
            "",
            "        # translations from plugins",
            "        plugins = octoprint.plugin.plugin_manager().enabled_plugins",
            "        for plugin in plugins.values():",
            "            plugin_translation_dir = os.path.join(plugin.location, \"translations\")",
            "            if not os.path.isdir(plugin_translation_dir):",
            "                continue",
            "            dirs.append(plugin_translation_dir)",
            "",
            "        app.config[\"BABEL_TRANSLATION_DIRECTORIES\"] = \";\".join(dirs)",
            "",
            "        babel = Babel(app, locale_selector=self._get_locale)",
            "",
            "        def get_available_locale_identifiers(locales):",
            "            result = set()",
            "",
            "            # add available translations",
            "            for locale in locales:",
            "                result.add(str(locale))",
            "",
            "            return result",
            "",
            "        with app.app_context():",
            "            LOCALES = babel.list_translations()",
            "        LANGUAGES = get_available_locale_identifiers(LOCALES)",
            "",
            "    def _setup_jinja2(self):",
            "        import re",
            "",
            "        app.jinja_env.add_extension(\"jinja2.ext.do\")",
            "        app.jinja_env.add_extension(\"octoprint.util.jinja.trycatch\")",
            "",
            "        def regex_replace(s, find, replace):",
            "            return re.sub(find, replace, s)",
            "",
            "        html_header_regex = re.compile(",
            "            r\"<h(?P<number>[1-6])>(?P<content>.*?)</h(?P=number)>\"",
            "        )",
            "",
            "        def offset_html_headers(s, offset):",
            "            def repl(match):",
            "                number = int(match.group(\"number\"))",
            "                number += offset",
            "                if number > 6:",
            "                    number = 6",
            "                elif number < 1:",
            "                    number = 1",
            "                return \"<h{number}>{content}</h{number}>\".format(",
            "                    number=number, content=match.group(\"content\")",
            "                )",
            "",
            "            return html_header_regex.sub(repl, s)",
            "",
            "        markdown_header_regex = re.compile(",
            "            r\"^(?P<hashes>#+)\\s+(?P<content>.*)$\", flags=re.MULTILINE",
            "        )",
            "",
            "        def offset_markdown_headers(s, offset):",
            "            def repl(match):",
            "                number = len(match.group(\"hashes\"))",
            "                number += offset",
            "                if number > 6:",
            "                    number = 6",
            "                elif number < 1:",
            "                    number = 1",
            "                return \"{hashes} {content}\".format(",
            "                    hashes=\"#\" * number, content=match.group(\"content\")",
            "                )",
            "",
            "            return markdown_header_regex.sub(repl, s)",
            "",
            "        html_link_regex = re.compile(r\"<(?P<tag>a.*?)>(?P<content>.*?)</a>\")",
            "",
            "        def externalize_links(text):",
            "            def repl(match):",
            "                tag = match.group(\"tag\")",
            "                if \"href\" not in tag:",
            "                    return match.group(0)",
            "",
            "                if \"target=\" not in tag and \"rel=\" not in tag:",
            "                    tag += ' target=\"_blank\" rel=\"noreferrer noopener\"'",
            "",
            "                content = match.group(\"content\")",
            "                return f\"<{tag}>{content}</a>\"",
            "",
            "            return html_link_regex.sub(repl, text)",
            "",
            "        single_quote_regex = re.compile(\"(?<!\\\\\\\\)'\")",
            "",
            "        def escape_single_quote(text):",
            "            return single_quote_regex.sub(\"\\\\'\", text)",
            "",
            "        double_quote_regex = re.compile('(?<!\\\\\\\\)\"')",
            "",
            "        def escape_double_quote(text):",
            "            return double_quote_regex.sub('\\\\\"', text)",
            "",
            "        app.jinja_env.filters[\"regex_replace\"] = regex_replace",
            "        app.jinja_env.filters[\"offset_html_headers\"] = offset_html_headers",
            "        app.jinja_env.filters[\"offset_markdown_headers\"] = offset_markdown_headers",
            "        app.jinja_env.filters[\"externalize_links\"] = externalize_links",
            "        app.jinja_env.filters[\"escape_single_quote\"] = app.jinja_env.filters[",
            "            \"esq\"",
            "        ] = escape_single_quote",
            "        app.jinja_env.filters[\"escape_double_quote\"] = app.jinja_env.filters[",
            "            \"edq\"",
            "        ] = escape_double_quote",
            "",
            "        # configure additional template folders for jinja2",
            "        import jinja2",
            "",
            "        import octoprint.util.jinja",
            "",
            "        app.jinja_env.prefix_loader = jinja2.PrefixLoader({})",
            "",
            "        loaders = [app.jinja_loader, app.jinja_env.prefix_loader]",
            "        if octoprint.util.is_running_from_source():",
            "            root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../..\"))",
            "            allowed = [\"AUTHORS.md\", \"SUPPORTERS.md\", \"THIRDPARTYLICENSES.md\"]",
            "            files = {\"_data/\" + name: os.path.join(root, name) for name in allowed}",
            "            loaders.append(octoprint.util.jinja.SelectedFilesWithConversionLoader(files))",
            "",
            "        # TODO: Remove this in 2.0.0",
            "        warning_message = \"Loading plugin template '{template}' from '{filename}' without plugin prefix, this is deprecated and will soon no longer be supported.\"",
            "        loaders.append(",
            "            octoprint.util.jinja.WarningLoader(",
            "                octoprint.util.jinja.PrefixChoiceLoader(app.jinja_env.prefix_loader),",
            "                warning_message,",
            "            )",
            "        )",
            "",
            "        app.jinja_loader = jinja2.ChoiceLoader(loaders)",
            "",
            "        self._register_template_plugins()",
            "",
            "        # make sure plugin lifecycle events relevant for jinja2 are taken care of",
            "        def template_enabled(name, plugin):",
            "            if plugin.implementation is None or not isinstance(",
            "                plugin.implementation, octoprint.plugin.TemplatePlugin",
            "            ):",
            "                return",
            "            self._register_additional_template_plugin(plugin.implementation)",
            "",
            "        def template_disabled(name, plugin):",
            "            if plugin.implementation is None or not isinstance(",
            "                plugin.implementation, octoprint.plugin.TemplatePlugin",
            "            ):",
            "                return",
            "            self._unregister_additional_template_plugin(plugin.implementation)",
            "",
            "        pluginLifecycleManager.add_callback(\"enabled\", template_enabled)",
            "        pluginLifecycleManager.add_callback(\"disabled\", template_disabled)",
            "",
            "    def _execute_preemptive_flask_caching(self, preemptive_cache):",
            "        import time",
            "",
            "        from werkzeug.test import EnvironBuilder",
            "",
            "        # we clean up entries from our preemptive cache settings that haven't been",
            "        # accessed longer than server.preemptiveCache.until days",
            "        preemptive_cache_timeout = settings().getInt(",
            "            [\"server\", \"preemptiveCache\", \"until\"]",
            "        )",
            "        cutoff_timestamp = time.time() - preemptive_cache_timeout * 24 * 60 * 60",
            "",
            "        def filter_current_entries(entry):",
            "            \"\"\"Returns True for entries younger than the cutoff date\"\"\"",
            "            return \"_timestamp\" in entry and entry[\"_timestamp\"] > cutoff_timestamp",
            "",
            "        def filter_http_entries(entry):",
            "            \"\"\"Returns True for entries targeting http or https.\"\"\"",
            "            return (",
            "                \"base_url\" in entry",
            "                and entry[\"base_url\"]",
            "                and (",
            "                    entry[\"base_url\"].startswith(\"http://\")",
            "                    or entry[\"base_url\"].startswith(\"https://\")",
            "                )",
            "            )",
            "",
            "        def filter_entries(entry):",
            "            \"\"\"Combined filter.\"\"\"",
            "            filters = (filter_current_entries, filter_http_entries)",
            "            return all([f(entry) for f in filters])",
            "",
            "        # filter out all old and non-http entries",
            "        cache_data = preemptive_cache.clean_all_data(",
            "            lambda root, entries: list(filter(filter_entries, entries))",
            "        )",
            "        if not cache_data:",
            "            return",
            "",
            "        def execute_caching():",
            "            logger = logging.getLogger(__name__ + \".preemptive_cache\")",
            "",
            "            for route in sorted(cache_data.keys(), key=lambda x: (x.count(\"/\"), x)):",
            "                entries = reversed(",
            "                    sorted(cache_data[route], key=lambda x: x.get(\"_count\", 0))",
            "                )",
            "                for kwargs in entries:",
            "                    plugin = kwargs.get(\"plugin\", None)",
            "                    if plugin:",
            "                        try:",
            "                            plugin_info = pluginManager.get_plugin_info(",
            "                                plugin, require_enabled=True",
            "                            )",
            "                            if plugin_info is None:",
            "                                logger.info(",
            "                                    \"About to preemptively cache plugin {} but it is not installed or enabled, preemptive caching makes no sense\".format(",
            "                                        plugin",
            "                                    )",
            "                                )",
            "                                continue",
            "",
            "                            implementation = plugin_info.implementation",
            "                            if implementation is None or not isinstance(",
            "                                implementation, octoprint.plugin.UiPlugin",
            "                            ):",
            "                                logger.info(",
            "                                    \"About to preemptively cache plugin {} but it is not a UiPlugin, preemptive caching makes no sense\".format(",
            "                                        plugin",
            "                                    )",
            "                                )",
            "                                continue",
            "                            if not implementation.get_ui_preemptive_caching_enabled():",
            "                                logger.info(",
            "                                    \"About to preemptively cache plugin {} but it has disabled preemptive caching\".format(",
            "                                        plugin",
            "                                    )",
            "                                )",
            "                                continue",
            "                        except Exception:",
            "                            logger.exception(",
            "                                \"Error while trying to check if plugin {} has preemptive caching enabled, skipping entry\"",
            "                            )",
            "                            continue",
            "",
            "                    additional_request_data = kwargs.get(\"_additional_request_data\", {})",
            "                    kwargs = {",
            "                        k: v",
            "                        for k, v in kwargs.items()",
            "                        if not k.startswith(\"_\") and not k == \"plugin\"",
            "                    }",
            "                    kwargs.update(additional_request_data)",
            "",
            "                    try:",
            "                        start = time.monotonic()",
            "                        if plugin:",
            "                            logger.info(",
            "                                \"Preemptively caching {} (ui {}) for {!r}\".format(",
            "                                    route, plugin, kwargs",
            "                                )",
            "                            )",
            "                        else:",
            "                            logger.info(",
            "                                \"Preemptively caching {} (ui _default) for {!r}\".format(",
            "                                    route, kwargs",
            "                                )",
            "                            )",
            "",
            "                        headers = kwargs.get(\"headers\", {})",
            "                        headers[\"X-Force-View\"] = plugin if plugin else \"_default\"",
            "                        headers[\"X-Preemptive-Recording\"] = \"yes\"",
            "                        kwargs[\"headers\"] = headers",
            "",
            "                        builder = EnvironBuilder(**kwargs)",
            "                        app(builder.get_environ(), lambda *a, **kw: None)",
            "",
            "                        logger.info(f\"... done in {time.monotonic() - start:.2f}s\")",
            "                    except Exception:",
            "                        logger.exception(",
            "                            \"Error while trying to preemptively cache {} for {!r}\".format(",
            "                                route, kwargs",
            "                            )",
            "                        )",
            "",
            "        # asynchronous caching",
            "        import threading",
            "",
            "        cache_thread = threading.Thread(",
            "            target=execute_caching, name=\"Preemptive Cache Worker\"",
            "        )",
            "        cache_thread.daemon = True",
            "        cache_thread.start()",
            "",
            "    def _register_template_plugins(self):",
            "        template_plugins = pluginManager.get_implementations(",
            "            octoprint.plugin.TemplatePlugin",
            "        )",
            "        for plugin in template_plugins:",
            "            try:",
            "                self._register_additional_template_plugin(plugin)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    \"Error while trying to register templates of plugin {}, ignoring it\".format(",
            "                        plugin._identifier",
            "                    )",
            "                )",
            "",
            "    def _register_additional_template_plugin(self, plugin):",
            "        import octoprint.util.jinja",
            "",
            "        folder = plugin.get_template_folder()",
            "        if (",
            "            folder is not None",
            "            and plugin.template_folder_key not in app.jinja_env.prefix_loader.mapping",
            "        ):",
            "            loader = octoprint.util.jinja.FilteredFileSystemLoader(",
            "                [plugin.get_template_folder()],",
            "                path_filter=lambda x: not octoprint.util.is_hidden_path(x),",
            "            )",
            "",
            "            app.jinja_env.prefix_loader.mapping[plugin.template_folder_key] = loader",
            "",
            "    def _unregister_additional_template_plugin(self, plugin):",
            "        folder = plugin.get_template_folder()",
            "        if (",
            "            folder is not None",
            "            and plugin.template_folder_key in app.jinja_env.prefix_loader.mapping",
            "        ):",
            "            del app.jinja_env.prefix_loader.mapping[plugin.template_folder_key]",
            "",
            "    def _setup_blueprints(self):",
            "        # do not remove or the index view won't be found",
            "        import octoprint.server.views  # noqa: F401",
            "        from octoprint.server.api import api",
            "        from octoprint.server.util.flask import make_api_error",
            "",
            "        blueprints = [api]",
            "        api_endpoints = [\"/api\"]",
            "        registrators = [functools.partial(app.register_blueprint, api, url_prefix=\"/api\")]",
            "",
            "        # also register any blueprints defined in BlueprintPlugins",
            "        (",
            "            blueprints_from_plugins,",
            "            api_endpoints_from_plugins,",
            "            registrators_from_plugins,",
            "        ) = self._prepare_blueprint_plugins()",
            "        blueprints += blueprints_from_plugins",
            "        api_endpoints += api_endpoints_from_plugins",
            "        registrators += registrators_from_plugins",
            "",
            "        # and register a blueprint for serving the static files of asset plugins which are not blueprint plugins themselves",
            "        (blueprints_from_assets, registrators_from_assets) = self._prepare_asset_plugins()",
            "        blueprints += blueprints_from_assets",
            "        registrators += registrators_from_assets",
            "",
            "        # make sure all before/after_request hook results are attached as well",
            "        self._add_plugin_request_handlers_to_blueprints(*blueprints)",
            "",
            "        # register everything with the system",
            "        for registrator in registrators:",
            "            registrator()",
            "",
            "        @app.errorhandler(HTTPException)",
            "        def _handle_api_error(ex):",
            "            if any(map(lambda x: request.path.startswith(x), api_endpoints)):",
            "                return make_api_error(ex.description, ex.code)",
            "            else:",
            "                return ex",
            "",
            "    def _prepare_blueprint_plugins(self):",
            "        def register_plugin_blueprint(plugin, blueprint, url_prefix):",
            "            try:",
            "                app.register_blueprint(",
            "                    blueprint, url_prefix=url_prefix, name_prefix=\"plugin\"",
            "                )",
            "                self._logger.debug(",
            "                    f\"Registered API of plugin {plugin} under URL prefix {url_prefix}\"",
            "                )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while registering blueprint of plugin {plugin}, ignoring it\",",
            "                    extra={\"plugin\": plugin},",
            "                )",
            "",
            "        blueprints = []",
            "        api_endpoints = []",
            "        registrators = []",
            "",
            "        blueprint_plugins = octoprint.plugin.plugin_manager().get_implementations(",
            "            octoprint.plugin.BlueprintPlugin",
            "        )",
            "        for plugin in blueprint_plugins:",
            "            blueprint, prefix = self._prepare_blueprint_plugin(plugin)",
            "",
            "            blueprints.append(blueprint)",
            "            api_endpoints += map(",
            "                lambda x: prefix + x, plugin.get_blueprint_api_prefixes()",
            "            )",
            "            registrators.append(",
            "                functools.partial(",
            "                    register_plugin_blueprint, plugin._identifier, blueprint, prefix",
            "                )",
            "            )",
            "",
            "        return blueprints, api_endpoints, registrators",
            "",
            "    def _prepare_asset_plugins(self):",
            "        def register_asset_blueprint(plugin, blueprint, url_prefix):",
            "            try:",
            "                app.register_blueprint(",
            "                    blueprint, url_prefix=url_prefix, name_prefix=\"plugin\"",
            "                )",
            "                self._logger.debug(",
            "                    f\"Registered assets of plugin {plugin} under URL prefix {url_prefix}\"",
            "                )",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while registering blueprint of plugin {plugin}, ignoring it\",",
            "                    extra={\"plugin\": plugin},",
            "                )",
            "",
            "        blueprints = []",
            "        registrators = []",
            "",
            "        asset_plugins = octoprint.plugin.plugin_manager().get_implementations(",
            "            octoprint.plugin.AssetPlugin",
            "        )",
            "        for plugin in asset_plugins:",
            "            if isinstance(plugin, octoprint.plugin.BlueprintPlugin):",
            "                continue",
            "            blueprint, prefix = self._prepare_asset_plugin(plugin)",
            "",
            "            blueprints.append(blueprint)",
            "            registrators.append(",
            "                functools.partial(",
            "                    register_asset_blueprint, plugin._identifier, blueprint, prefix",
            "                )",
            "            )",
            "",
            "        return blueprints, registrators",
            "",
            "    def _prepare_blueprint_plugin(self, plugin):",
            "        name = plugin._identifier",
            "        blueprint = plugin.get_blueprint()",
            "        if blueprint is None:",
            "            return",
            "",
            "        blueprint.before_request(corsRequestHandler)",
            "        blueprint.before_request(loginFromApiKeyRequestHandler)",
            "        blueprint.after_request(corsResponseHandler)",
            "",
            "        if plugin.is_blueprint_csrf_protected():",
            "            self._logger.debug(",
            "                f\"CSRF Protection for Blueprint of plugin {name} is enabled\"",
            "            )",
            "            blueprint.before_request(csrfRequestHandler)",
            "        else:",
            "            self._logger.warning(",
            "                f\"CSRF Protection for Blueprint of plugin {name} is DISABLED\"",
            "            )",
            "",
            "        if plugin.is_blueprint_protected():",
            "            blueprint.before_request(requireLoginRequestHandler)",
            "",
            "        url_prefix = f\"/plugin/{name}\"",
            "        return blueprint, url_prefix",
            "",
            "    def _prepare_asset_plugin(self, plugin):",
            "        name = plugin._identifier",
            "",
            "        url_prefix = f\"/plugin/{name}\"",
            "        blueprint = Blueprint(name, name, static_folder=plugin.get_asset_folder())",
            "",
            "        blueprint.before_request(corsRequestHandler)",
            "        blueprint.after_request(corsResponseHandler)",
            "",
            "        return blueprint, url_prefix",
            "",
            "    def _add_plugin_request_handlers_to_blueprints(self, *blueprints):",
            "        before_hooks = octoprint.plugin.plugin_manager().get_hooks(",
            "            \"octoprint.server.api.before_request\"",
            "        )",
            "        after_hooks = octoprint.plugin.plugin_manager().get_hooks(",
            "            \"octoprint.server.api.after_request\"",
            "        )",
            "",
            "        for name, hook in before_hooks.items():",
            "            plugin = octoprint.plugin.plugin_manager().get_plugin(name)",
            "            for blueprint in blueprints:",
            "                try:",
            "                    result = hook(plugin=plugin)",
            "                    if isinstance(result, (list, tuple)):",
            "                        for h in result:",
            "                            blueprint.before_request(h)",
            "                except Exception:",
            "                    self._logger.exception(",
            "                        \"Error processing before_request hooks from plugin {}\".format(",
            "                            plugin",
            "                        ),",
            "                        extra={\"plugin\": name},",
            "                    )",
            "",
            "        for name, hook in after_hooks.items():",
            "            plugin = octoprint.plugin.plugin_manager().get_plugin(name)",
            "            for blueprint in blueprints:",
            "                try:",
            "                    result = hook(plugin=plugin)",
            "                    if isinstance(result, (list, tuple)):",
            "                        for h in result:",
            "                            blueprint.after_request(h)",
            "                except Exception:",
            "                    self._logger.exception(",
            "                        \"Error processing after_request hooks from plugin {}\".format(",
            "                            plugin",
            "                        ),",
            "                        extra={\"plugin\": name},",
            "                    )",
            "",
            "    def _setup_mimetypes(self):",
            "        # Safety measures for Windows... apparently the mimetypes module takes its translation from the windows",
            "        # registry, and if for some weird reason that gets borked the reported MIME types can be all over the place.",
            "        # Since at least in Chrome that can cause hilarious issues with JS files (refusal to run them and thus a",
            "        # borked UI) we make sure that .js always maps to the correct application/javascript, and also throw in a",
            "        # .css -> text/css for good measure.",
            "        #",
            "        # See #3367",
            "        mimetypes.add_type(\"application/javascript\", \".js\")",
            "        mimetypes.add_type(\"text/css\", \".css\")",
            "",
            "    def _setup_assets(self):",
            "        global app",
            "        global assets",
            "        global pluginManager",
            "",
            "        from octoprint.server.util.webassets import MemoryManifest  # noqa: F401",
            "",
            "        util.flask.fix_webassets_convert_item_to_flask_url()",
            "        util.flask.fix_webassets_filtertool()",
            "",
            "        base_folder = self._settings.getBaseFolder(\"generated\")",
            "",
            "        # clean the folder",
            "        if self._settings.getBoolean([\"devel\", \"webassets\", \"clean_on_startup\"]):",
            "            import errno",
            "            import shutil",
            "",
            "            for entry, recreate in (",
            "                (\"webassets\", True),",
            "                # no longer used, but clean up just in case",
            "                (\".webassets-cache\", False),",
            "                (\".webassets-manifest.json\", False),",
            "            ):",
            "                path = os.path.join(base_folder, entry)",
            "",
            "                # delete path if it exists",
            "                if os.path.exists(path):",
            "                    try:",
            "                        self._logger.debug(f\"Deleting {path}...\")",
            "                        if os.path.isdir(path):",
            "                            shutil.rmtree(path)",
            "                        else:",
            "                            os.remove(path)",
            "                    except Exception:",
            "                        self._logger.exception(",
            "                            f\"Error while trying to delete {path}, \" f\"leaving it alone\"",
            "                        )",
            "                        continue",
            "",
            "                # re-create path if necessary",
            "                if recreate:",
            "                    self._logger.debug(f\"Creating {path}...\")",
            "                    error_text = (",
            "                        f\"Error while trying to re-create {path}, that might cause \"",
            "                        f\"errors with the webassets cache\"",
            "                    )",
            "                    try:",
            "                        os.makedirs(path)",
            "                    except OSError as e:",
            "                        if e.errno == errno.EACCES:",
            "                            # that might be caused by the user still having the folder open somewhere, let's try again after",
            "                            # waiting a bit",
            "                            import time",
            "",
            "                            for n in range(3):",
            "                                time.sleep(0.5)",
            "                                self._logger.debug(",
            "                                    \"Creating {path}: Retry #{retry} after {time}s\".format(",
            "                                        path=path, retry=n + 1, time=(n + 1) * 0.5",
            "                                    )",
            "                                )",
            "                                try:",
            "                                    os.makedirs(path)",
            "                                    break",
            "                                except Exception:",
            "                                    if self._logger.isEnabledFor(logging.DEBUG):",
            "                                        self._logger.exception(",
            "                                            f\"Ignored error while creating \"",
            "                                            f\"directory {path}\"",
            "                                        )",
            "                                    pass",
            "                            else:",
            "                                # this will only get executed if we never did",
            "                                # successfully execute makedirs above",
            "                                self._logger.exception(error_text)",
            "                                continue",
            "                        else:",
            "                            # not an access error, so something we don't understand",
            "                            # went wrong -> log an error and stop",
            "                            self._logger.exception(error_text)",
            "                            continue",
            "                    except Exception:",
            "                        # not an OSError, so something we don't understand",
            "                        # went wrong -> log an error and stop",
            "                        self._logger.exception(error_text)",
            "                        continue",
            "",
            "                self._logger.info(f\"Reset webasset folder {path}...\")",
            "",
            "        AdjustedEnvironment = type(Environment)(",
            "            Environment.__name__,",
            "            (Environment,),",
            "            {\"resolver_class\": util.flask.PluginAssetResolver},",
            "        )",
            "",
            "        class CustomDirectoryEnvironment(AdjustedEnvironment):",
            "            @property",
            "            def directory(self):",
            "                return base_folder",
            "",
            "        assets = CustomDirectoryEnvironment(app)",
            "        assets.debug = not self._settings.getBoolean([\"devel\", \"webassets\", \"bundle\"])",
            "",
            "        # we should rarely if ever regenerate the webassets in production and can wait a",
            "        # few seconds for regeneration in development, if it means we can get rid of",
            "        # a whole monkey patch and in internal use of pickle with non-tamperproof files",
            "        assets.cache = False",
            "        assets.manifest = \"memory\"",
            "",
            "        UpdaterType = type(util.flask.SettingsCheckUpdater)(",
            "            util.flask.SettingsCheckUpdater.__name__,",
            "            (util.flask.SettingsCheckUpdater,),",
            "            {\"updater\": assets.updater},",
            "        )",
            "        assets.updater = UpdaterType",
            "",
            "        preferred_stylesheet = self._settings.get([\"devel\", \"stylesheet\"])",
            "",
            "        dynamic_core_assets = util.flask.collect_core_assets()",
            "        dynamic_plugin_assets = util.flask.collect_plugin_assets(",
            "            preferred_stylesheet=preferred_stylesheet",
            "        )",
            "",
            "        js_libs = [",
            "            \"js/lib/babel-polyfill.min.js\",",
            "            \"js/lib/jquery/jquery.min.js\",",
            "            \"js/lib/modernizr.custom.js\",",
            "            \"js/lib/lodash.min.js\",",
            "            \"js/lib/sprintf.min.js\",",
            "            \"js/lib/knockout.js\",",
            "            \"js/lib/knockout.mapping-latest.js\",",
            "            \"js/lib/babel.js\",",
            "            \"js/lib/bootstrap/bootstrap.js\",",
            "            \"js/lib/bootstrap/bootstrap-modalmanager.js\",",
            "            \"js/lib/bootstrap/bootstrap-modal.js\",",
            "            \"js/lib/bootstrap/bootstrap-slider.js\",",
            "            \"js/lib/bootstrap/bootstrap-tabdrop.js\",",
            "            \"js/lib/jquery/jquery-ui.js\",",
            "            \"js/lib/jquery/jquery.flot.js\",",
            "            \"js/lib/jquery/jquery.flot.time.js\",",
            "            \"js/lib/jquery/jquery.flot.crosshair.js\",",
            "            \"js/lib/jquery/jquery.flot.dashes.js\",",
            "            \"js/lib/jquery/jquery.flot.resize.js\",",
            "            \"js/lib/jquery/jquery.iframe-transport.js\",",
            "            \"js/lib/jquery/jquery.fileupload.js\",",
            "            \"js/lib/jquery/jquery.slimscroll.min.js\",",
            "            \"js/lib/jquery/jquery.qrcode.min.js\",",
            "            \"js/lib/jquery/jquery.bootstrap.wizard.js\",",
            "            \"js/lib/pnotify/pnotify.core.min.js\",",
            "            \"js/lib/pnotify/pnotify.buttons.min.js\",",
            "            \"js/lib/pnotify/pnotify.callbacks.min.js\",",
            "            \"js/lib/pnotify/pnotify.confirm.min.js\",",
            "            \"js/lib/pnotify/pnotify.desktop.min.js\",",
            "            \"js/lib/pnotify/pnotify.history.min.js\",",
            "            \"js/lib/pnotify/pnotify.mobile.min.js\",",
            "            \"js/lib/pnotify/pnotify.nonblock.min.js\",",
            "            \"js/lib/pnotify/pnotify.reference.min.js\",",
            "            \"js/lib/pnotify/pnotify.tooltip.min.js\",",
            "            \"js/lib/pnotify/pnotify.maxheight.js\",",
            "            \"js/lib/moment-with-locales.min.js\",",
            "            \"js/lib/pusher.color.min.js\",",
            "            \"js/lib/detectmobilebrowser.js\",",
            "            \"js/lib/ua-parser.min.js\",",
            "            \"js/lib/md5.min.js\",",
            "            \"js/lib/bootstrap-slider-knockout-binding.js\",",
            "            \"js/lib/loglevel.min.js\",",
            "            \"js/lib/sockjs.min.js\",",
            "            \"js/lib/hls.js\",",
            "            \"js/lib/less.js\",",
            "        ]",
            "",
            "        css_libs = [",
            "            \"css/bootstrap.min.css\",",
            "            \"css/bootstrap-modal.css\",",
            "            \"css/bootstrap-slider.css\",",
            "            \"css/bootstrap-tabdrop.css\",",
            "            \"vendor/font-awesome-3.2.1/css/font-awesome.min.css\",",
            "            \"vendor/fontawesome-6.1.1/css/all.min.css\",",
            "            \"vendor/fontawesome-6.1.1/css/v4-shims.min.css\",",
            "            \"vendor/fa5-power-transforms.min.css\",",
            "            \"css/jquery.fileupload-ui.css\",",
            "            \"css/pnotify.core.min.css\",",
            "            \"css/pnotify.buttons.min.css\",",
            "            \"css/pnotify.history.min.css\",",
            "        ]",
            "",
            "        # a couple of custom filters",
            "        from webassets.filter import register_filter",
            "",
            "        from octoprint.server.util.webassets import (",
            "            GzipFile,",
            "            JsDelimiterBundler,",
            "            JsPluginBundle,",
            "            LessImportRewrite,",
            "            RJSMinExtended,",
            "            SourceMapRemove,",
            "            SourceMapRewrite,",
            "        )",
            "",
            "        register_filter(LessImportRewrite)",
            "        register_filter(SourceMapRewrite)",
            "        register_filter(SourceMapRemove)",
            "        register_filter(JsDelimiterBundler)",
            "        register_filter(GzipFile)",
            "        register_filter(RJSMinExtended)",
            "",
            "        def all_assets_for_plugins(collection):",
            "            \"\"\"Gets all plugin assets for a dict of plugin->assets\"\"\"",
            "            result = []",
            "            for assets in collection.values():",
            "                result += assets",
            "            return result",
            "",
            "        # -- JS --------------------------------------------------------------------------------------------------------",
            "",
            "        filters = [\"sourcemap_remove\"]",
            "        if self._settings.getBoolean([\"devel\", \"webassets\", \"minify\"]):",
            "            filters += [\"rjsmin_extended\"]",
            "        filters += [\"js_delimiter_bundler\", \"gzip\"]",
            "",
            "        js_filters = filters",
            "        if self._settings.getBoolean([\"devel\", \"webassets\", \"minify_plugins\"]):",
            "            js_plugin_filters = js_filters",
            "        else:",
            "            js_plugin_filters = [x for x in js_filters if x not in (\"rjsmin_extended\",)]",
            "",
            "        def js_bundles_for_plugins(collection, filters=None):",
            "            \"\"\"Produces JsPluginBundle instances that output IIFE wrapped assets\"\"\"",
            "            result = OrderedDict()",
            "            for plugin, assets in collection.items():",
            "                if len(assets):",
            "                    result[plugin] = JsPluginBundle(plugin, *assets, filters=filters)",
            "            return result",
            "",
            "        js_core = (",
            "            dynamic_core_assets[\"js\"]",
            "            + all_assets_for_plugins(dynamic_plugin_assets[\"bundled\"][\"js\"])",
            "            + [\"js/app/dataupdater.js\", \"js/app/helpers.js\", \"js/app/main.js\"]",
            "        )",
            "        js_plugins = js_bundles_for_plugins(",
            "            dynamic_plugin_assets[\"external\"][\"js\"], filters=\"js_delimiter_bundler\"",
            "        )",
            "",
            "        clientjs_core = dynamic_core_assets[\"clientjs\"] + all_assets_for_plugins(",
            "            dynamic_plugin_assets[\"bundled\"][\"clientjs\"]",
            "        )",
            "        clientjs_plugins = js_bundles_for_plugins(",
            "            dynamic_plugin_assets[\"external\"][\"clientjs\"], filters=\"js_delimiter_bundler\"",
            "        )",
            "",
            "        js_libs_bundle = Bundle(",
            "            *js_libs, output=\"webassets/packed_libs.js\", filters=\",\".join(js_filters)",
            "        )",
            "",
            "        js_core_bundle = Bundle(",
            "            *js_core, output=\"webassets/packed_core.js\", filters=\",\".join(js_filters)",
            "        )",
            "",
            "        if len(js_plugins) == 0:",
            "            js_plugins_bundle = Bundle(*[])",
            "        else:",
            "            js_plugins_bundle = Bundle(",
            "                *js_plugins.values(),",
            "                output=\"webassets/packed_plugins.js\",",
            "                filters=\",\".join(js_plugin_filters),",
            "            )",
            "",
            "        js_app_bundle = Bundle(",
            "            js_plugins_bundle,",
            "            js_core_bundle,",
            "            output=\"webassets/packed_app.js\",",
            "            filters=\",\".join(js_plugin_filters),",
            "        )",
            "",
            "        js_client_core_bundle = Bundle(",
            "            *clientjs_core,",
            "            output=\"webassets/packed_client_core.js\",",
            "            filters=\",\".join(js_filters),",
            "        )",
            "",
            "        if len(clientjs_plugins) == 0:",
            "            js_client_plugins_bundle = Bundle(*[])",
            "        else:",
            "            js_client_plugins_bundle = Bundle(",
            "                *clientjs_plugins.values(),",
            "                output=\"webassets/packed_client_plugins.js\",",
            "                filters=\",\".join(js_plugin_filters),",
            "            )",
            "",
            "        js_client_bundle = Bundle(",
            "            js_client_core_bundle,",
            "            js_client_plugins_bundle,",
            "            output=\"webassets/packed_client.js\",",
            "            filters=\",\".join(js_plugin_filters),",
            "        )",
            "",
            "        # -- CSS -------------------------------------------------------------------------------------------------------",
            "",
            "        css_filters = [\"cssrewrite\", \"gzip\"]",
            "",
            "        css_core = list(dynamic_core_assets[\"css\"]) + all_assets_for_plugins(",
            "            dynamic_plugin_assets[\"bundled\"][\"css\"]",
            "        )",
            "        css_plugins = list(",
            "            all_assets_for_plugins(dynamic_plugin_assets[\"external\"][\"css\"])",
            "        )",
            "",
            "        css_libs_bundle = Bundle(",
            "            *css_libs, output=\"webassets/packed_libs.css\", filters=\",\".join(css_filters)",
            "        )",
            "",
            "        if len(css_core) == 0:",
            "            css_core_bundle = Bundle(*[])",
            "        else:",
            "            css_core_bundle = Bundle(",
            "                *css_core,",
            "                output=\"webassets/packed_core.css\",",
            "                filters=\",\".join(css_filters),",
            "            )",
            "",
            "        if len(css_plugins) == 0:",
            "            css_plugins_bundle = Bundle(*[])",
            "        else:",
            "            css_plugins_bundle = Bundle(",
            "                *css_plugins,",
            "                output=\"webassets/packed_plugins.css\",",
            "                filters=\",\".join(css_filters),",
            "            )",
            "",
            "        css_app_bundle = Bundle(",
            "            css_core,",
            "            css_plugins,",
            "            output=\"webassets/packed_app.css\",",
            "            filters=\",\".join(css_filters),",
            "        )",
            "",
            "        # -- LESS ------------------------------------------------------------------------------------------------------",
            "",
            "        less_filters = [\"cssrewrite\", \"less_importrewrite\", \"gzip\"]",
            "",
            "        less_core = list(dynamic_core_assets[\"less\"]) + all_assets_for_plugins(",
            "            dynamic_plugin_assets[\"bundled\"][\"less\"]",
            "        )",
            "        less_plugins = all_assets_for_plugins(dynamic_plugin_assets[\"external\"][\"less\"])",
            "",
            "        if len(less_core) == 0:",
            "            less_core_bundle = Bundle(*[])",
            "        else:",
            "            less_core_bundle = Bundle(",
            "                *less_core,",
            "                output=\"webassets/packed_core.less\",",
            "                filters=\",\".join(less_filters),",
            "            )",
            "",
            "        if len(less_plugins) == 0:",
            "            less_plugins_bundle = Bundle(*[])",
            "        else:",
            "            less_plugins_bundle = Bundle(",
            "                *less_plugins,",
            "                output=\"webassets/packed_plugins.less\",",
            "                filters=\",\".join(less_filters),",
            "            )",
            "",
            "        less_app_bundle = Bundle(",
            "            less_core,",
            "            less_plugins,",
            "            output=\"webassets/packed_app.less\",",
            "            filters=\",\".join(less_filters),",
            "        )",
            "",
            "        # -- asset registration ----------------------------------------------------------------------------------------",
            "",
            "        assets.register(\"js_libs\", js_libs_bundle)",
            "        assets.register(\"js_client_core\", js_client_core_bundle)",
            "        for plugin, bundle in clientjs_plugins.items():",
            "            # register our collected clientjs plugin bundles so that they are bound to the environment",
            "            assets.register(f\"js_client_plugin_{plugin}\", bundle)",
            "        assets.register(\"js_client_plugins\", js_client_plugins_bundle)",
            "        assets.register(\"js_client\", js_client_bundle)",
            "        assets.register(\"js_core\", js_core_bundle)",
            "        for plugin, bundle in js_plugins.items():",
            "            # register our collected plugin bundles so that they are bound to the environment",
            "            assets.register(f\"js_plugin_{plugin}\", bundle)",
            "        assets.register(\"js_plugins\", js_plugins_bundle)",
            "        assets.register(\"js_app\", js_app_bundle)",
            "        assets.register(\"css_libs\", css_libs_bundle)",
            "        assets.register(\"css_core\", css_core_bundle)",
            "        assets.register(\"css_plugins\", css_plugins_bundle)",
            "        assets.register(\"css_app\", css_app_bundle)",
            "        assets.register(\"less_core\", less_core_bundle)",
            "        assets.register(\"less_plugins\", less_plugins_bundle)",
            "        assets.register(\"less_app\", less_app_bundle)",
            "",
            "    def _setup_login_manager(self):",
            "        global loginManager",
            "",
            "        loginManager = LoginManager()",
            "",
            "        # \"strong\" is incompatible to remember me, see maxcountryman/flask-login#156. It also causes issues with",
            "        # clients toggling between IPv4 and IPv6 client addresses due to names being resolved one way or the other as",
            "        # at least observed on a Win10 client targeting \"localhost\", resolved as both \"127.0.0.1\" and \"::1\"",
            "        loginManager.session_protection = \"basic\"",
            "",
            "        loginManager.user_loader(load_user)",
            "        loginManager.unauthorized_handler(unauthorized_user)",
            "        loginManager.anonymous_user = userManager.anonymous_user_factory",
            "        loginManager.request_loader(load_user_from_request)",
            "",
            "        loginManager.init_app(app, add_context_processor=False)",
            "",
            "    def _start_intermediary_server(self):",
            "        import socket",
            "        import threading",
            "        from http.server import BaseHTTPRequestHandler, HTTPServer",
            "",
            "        host = self._host",
            "        port = self._port",
            "",
            "        class IntermediaryServerHandler(BaseHTTPRequestHandler):",
            "            def __init__(self, rules=None, *args, **kwargs):",
            "                if rules is None:",
            "                    rules = []",
            "                self.rules = rules",
            "                BaseHTTPRequestHandler.__init__(self, *args, **kwargs)",
            "",
            "            def do_GET(self):",
            "                request_path = self.path",
            "                if \"?\" in request_path:",
            "                    request_path = request_path[0 : request_path.find(\"?\")]",
            "",
            "                for rule in self.rules:",
            "                    path, data, content_type = rule",
            "                    if request_path == path:",
            "                        self.send_response(200)",
            "                        if content_type:",
            "                            self.send_header(\"Content-Type\", content_type)",
            "                        self.end_headers()",
            "                        if isinstance(data, str):",
            "                            data = data.encode(\"utf-8\")",
            "                        self.wfile.write(data)",
            "                        break",
            "                else:",
            "                    self.send_response(404)",
            "                    self.wfile.write(b\"Not found\")",
            "",
            "        base_path = os.path.realpath(",
            "            os.path.join(os.path.dirname(__file__), \"..\", \"static\")",
            "        )",
            "        rules = [",
            "            (",
            "                \"/\",",
            "                [",
            "                    \"intermediary.html\",",
            "                ],",
            "                \"text/html\",",
            "            ),",
            "            (\"/favicon.ico\", [\"img\", \"tentacle-20x20.png\"], \"image/png\"),",
            "            (",
            "                \"/intermediary.gif\",",
            "                bytes(",
            "                    base64.b64decode(",
            "                        \"R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"",
            "                    )",
            "                ),",
            "                \"image/gif\",",
            "            ),",
            "        ]",
            "",
            "        def contents(args):",
            "            path = os.path.join(base_path, *args)",
            "            if not os.path.isfile(path):",
            "                return \"\"",
            "",
            "            with open(path, \"rb\") as f:",
            "                data = f.read()",
            "            return data",
            "",
            "        def process(rule):",
            "            if len(rule) == 2:",
            "                path, data = rule",
            "                content_type = None",
            "            else:",
            "                path, data, content_type = rule",
            "",
            "            if isinstance(data, (list, tuple)):",
            "                data = contents(data)",
            "",
            "            return path, data, content_type",
            "",
            "        rules = list(",
            "            map(process, filter(lambda rule: len(rule) == 2 or len(rule) == 3, rules))",
            "        )",
            "",
            "        HTTPServerV4 = HTTPServer",
            "",
            "        class HTTPServerV6(HTTPServer):",
            "            address_family = socket.AF_INET6",
            "",
            "        class HTTPServerV6SingleStack(HTTPServerV6):",
            "            def __init__(self, *args, **kwargs):",
            "                HTTPServerV6.__init__(self, *args, **kwargs)",
            "",
            "                # explicitly set V6ONLY flag - seems to be the default, but just to make sure...",
            "                self.socket.setsockopt(",
            "                    octoprint.util.net.IPPROTO_IPV6, octoprint.util.net.IPV6_V6ONLY, 1",
            "                )",
            "",
            "        class HTTPServerV6DualStack(HTTPServerV6):",
            "            def __init__(self, *args, **kwargs):",
            "                HTTPServerV6.__init__(self, *args, **kwargs)",
            "",
            "                # explicitly unset V6ONLY flag",
            "                self.socket.setsockopt(",
            "                    octoprint.util.net.IPPROTO_IPV6, octoprint.util.net.IPV6_V6ONLY, 0",
            "                )",
            "",
            "        if \":\" in host:",
            "            # v6",
            "            if host == \"::\" and not self._v6_only:",
            "                ServerClass = HTTPServerV6DualStack",
            "            else:",
            "                ServerClass = HTTPServerV6SingleStack",
            "        else:",
            "            # v4",
            "            ServerClass = HTTPServerV4",
            "",
            "        if host == \"::\":",
            "            if self._v6_only:",
            "                self._logger.debug(f\"Starting intermediary server on http://[::]:{port}\")",
            "            else:",
            "                self._logger.debug(",
            "                    \"Starting intermediary server on http://0.0.0.0:{port} and http://[::]:{port}\".format(",
            "                        port=port",
            "                    )",
            "                )",
            "        else:",
            "            self._logger.debug(",
            "                \"Starting intermediary server on http://{}:{}\".format(",
            "                    host if \":\" not in host else \"[\" + host + \"]\", port",
            "                )",
            "            )",
            "",
            "        self._intermediary_server = ServerClass(",
            "            (host, port),",
            "            lambda *args, **kwargs: IntermediaryServerHandler(rules, *args, **kwargs),",
            "            bind_and_activate=False,",
            "        )",
            "",
            "        # if possible, make sure our socket's port descriptor isn't handed over to subprocesses",
            "        from octoprint.util.platform import set_close_exec",
            "",
            "        try:",
            "            set_close_exec(self._intermediary_server.fileno())",
            "        except Exception:",
            "            self._logger.exception(",
            "                \"Error while attempting to set_close_exec on intermediary server socket\"",
            "            )",
            "",
            "        # then bind the server and have it serve our handler until stopped",
            "        try:",
            "            self._intermediary_server.server_bind()",
            "            self._intermediary_server.server_activate()",
            "        except Exception as exc:",
            "            self._intermediary_server.server_close()",
            "",
            "            if isinstance(exc, UnicodeDecodeError) and sys.platform == \"win32\":",
            "                # we end up here if the hostname contains non-ASCII characters due to",
            "                # https://bugs.python.org/issue26227 - tell the user they need",
            "                # to either change their hostname or read up other options in",
            "                # https://github.com/OctoPrint/OctoPrint/issues/3963",
            "                raise CannotStartServerException(",
            "                    \"OctoPrint cannot start due to a Python bug \"",
            "                    \"(https://bugs.python.org/issue26227). Your \"",
            "                    \"computer's host name contains non-ASCII characters. \"",
            "                    \"Please either change your computer's host name to \"",
            "                    \"contain only ASCII characters, or take a look at \"",
            "                    \"https://github.com/OctoPrint/OctoPrint/issues/3963 for \"",
            "                    \"other options.\"",
            "                )",
            "            else:",
            "                raise",
            "",
            "        def serve():",
            "            try:",
            "                self._intermediary_server.serve_forever()",
            "            except Exception:",
            "                self._logger.exception(\"Error in intermediary server\")",
            "",
            "        thread = threading.Thread(target=serve)",
            "        thread.daemon = True",
            "        thread.start()",
            "",
            "        self._logger.info(\"Intermediary server started\")",
            "",
            "    def _stop_intermediary_server(self):",
            "        if self._intermediary_server is None:",
            "            return",
            "        self._logger.info(\"Shutting down intermediary server...\")",
            "        self._intermediary_server.shutdown()",
            "        self._intermediary_server.server_close()",
            "        self._logger.info(\"Intermediary server shut down\")",
            "",
            "    def _setup_plugin_permissions(self):",
            "        global pluginManager",
            "",
            "        from octoprint.access.permissions import PluginOctoPrintPermission",
            "",
            "        key_whitelist = re.compile(r\"[A-Za-z0-9_]*\")",
            "",
            "        def permission_key(plugin, definition):",
            "            return \"PLUGIN_{}_{}\".format(plugin.upper(), definition[\"key\"].upper())",
            "",
            "        def permission_name(plugin, definition):",
            "            return \"{}: {}\".format(plugin, definition[\"name\"])",
            "",
            "        def permission_role(plugin, role):",
            "            return f\"plugin_{plugin}_{role}\"",
            "",
            "        def process_regular_permission(plugin_info, definition):",
            "            permissions = []",
            "            for key in definition.get(\"permissions\", []):",
            "                permission = octoprint.access.permissions.Permissions.find(key)",
            "",
            "                if permission is None:",
            "                    # if there is still no permission found, postpone this - maybe it is a permission from",
            "                    # another plugin that hasn't been loaded yet",
            "                    return False",
            "",
            "                permissions.append(permission)",
            "",
            "            roles = definition.get(\"roles\", [])",
            "            description = definition.get(\"description\", \"\")",
            "            dangerous = definition.get(\"dangerous\", False)",
            "            default_groups = definition.get(\"default_groups\", [])",
            "",
            "            roles_and_permissions = [",
            "                permission_role(plugin_info.key, role) for role in roles",
            "            ] + permissions",
            "",
            "            key = permission_key(plugin_info.key, definition)",
            "            permission = PluginOctoPrintPermission(",
            "                permission_name(plugin_info.name, definition),",
            "                description,",
            "                *roles_and_permissions,",
            "                plugin=plugin_info.key,",
            "                dangerous=dangerous,",
            "                default_groups=default_groups,",
            "            )",
            "            setattr(",
            "                octoprint.access.permissions.Permissions,",
            "                key,",
            "                PluginOctoPrintPermission(",
            "                    permission_name(plugin_info.name, definition),",
            "                    description,",
            "                    *roles_and_permissions,",
            "                    plugin=plugin_info.key,",
            "                    dangerous=dangerous,",
            "                    default_groups=default_groups,",
            "                ),",
            "            )",
            "",
            "            self._logger.info(",
            "                \"Added new permission from plugin {}: {} (needs: {!r})\".format(",
            "                    plugin_info.key, key, \", \".join(map(repr, permission.needs))",
            "                )",
            "            )",
            "            return True",
            "",
            "        postponed = []",
            "",
            "        hooks = pluginManager.get_hooks(\"octoprint.access.permissions\")",
            "        for name, factory in hooks.items():",
            "            try:",
            "                if isinstance(factory, (tuple, list)):",
            "                    additional_permissions = list(factory)",
            "                elif callable(factory):",
            "                    additional_permissions = factory()",
            "                else:",
            "                    raise ValueError(\"factory must be either a callable, tuple or list\")",
            "",
            "                if not isinstance(additional_permissions, (tuple, list)):",
            "                    raise ValueError(",
            "                        \"factory result must be either a tuple or a list of permission definition dicts\"",
            "                    )",
            "",
            "                plugin_info = pluginManager.get_plugin_info(name)",
            "                for p in additional_permissions:",
            "                    if not isinstance(p, dict):",
            "                        continue",
            "",
            "                    if \"key\" not in p or \"name\" not in p:",
            "                        continue",
            "",
            "                    if not key_whitelist.match(p[\"key\"]):",
            "                        self._logger.warning(",
            "                            \"Got permission with invalid key from plugin {}: {}\".format(",
            "                                name, p[\"key\"]",
            "                            )",
            "                        )",
            "                        continue",
            "",
            "                    if not process_regular_permission(plugin_info, p):",
            "                        postponed.append((plugin_info, p))",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error while creating permission instance/s from {name}\"",
            "                )",
            "",
            "        # final resolution passes",
            "        pass_number = 1",
            "        still_postponed = []",
            "        while len(postponed):",
            "            start_length = len(postponed)",
            "            self._logger.debug(",
            "                \"Plugin permission resolution pass #{}, \"",
            "                \"{} unresolved permissions...\".format(pass_number, start_length)",
            "            )",
            "",
            "            for plugin_info, definition in postponed:",
            "                if not process_regular_permission(plugin_info, definition):",
            "                    still_postponed.append((plugin_info, definition))",
            "",
            "            self._logger.debug(",
            "                \"... pass #{} done, {} permissions left to resolve\".format(",
            "                    pass_number, len(still_postponed)",
            "                )",
            "            )",
            "",
            "            if len(still_postponed) == start_length:",
            "                # no change, looks like some stuff is unresolvable - let's bail",
            "                for plugin_info, definition in still_postponed:",
            "                    self._logger.warning(",
            "                        \"Unable to resolve permission from {}: {!r}\".format(",
            "                            plugin_info.key, definition",
            "                        )",
            "                    )",
            "                break",
            "",
            "            postponed = still_postponed",
            "            still_postponed = []",
            "            pass_number += 1",
            "",
            "",
            "class LifecycleManager:",
            "    def __init__(self, plugin_manager):",
            "        self._plugin_manager = plugin_manager",
            "",
            "        self._plugin_lifecycle_callbacks = defaultdict(list)",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "        def wrap_plugin_event(lifecycle_event, new_handler):",
            "            orig_handler = getattr(self._plugin_manager, \"on_plugin_\" + lifecycle_event)",
            "",
            "            def handler(*args, **kwargs):",
            "                if callable(orig_handler):",
            "                    orig_handler(*args, **kwargs)",
            "                if callable(new_handler):",
            "                    new_handler(*args, **kwargs)",
            "",
            "            return handler",
            "",
            "        def on_plugin_event_factory(lifecycle_event):",
            "            def on_plugin_event(name, plugin):",
            "                self.on_plugin_event(lifecycle_event, name, plugin)",
            "",
            "            return on_plugin_event",
            "",
            "        for event in (\"loaded\", \"unloaded\", \"enabled\", \"disabled\"):",
            "            wrap_plugin_event(event, on_plugin_event_factory(event))",
            "",
            "    def on_plugin_event(self, event, name, plugin):",
            "        for lifecycle_callback in self._plugin_lifecycle_callbacks[event]:",
            "            lifecycle_callback(name, plugin)",
            "",
            "    def add_callback(self, events, callback):",
            "        if isinstance(events, str):",
            "            events = [events]",
            "",
            "        for event in events:",
            "            self._plugin_lifecycle_callbacks[event].append(callback)",
            "",
            "    def remove_callback(self, callback, events=None):",
            "        if events is None:",
            "            for event in self._plugin_lifecycle_callbacks:",
            "                if callback in self._plugin_lifecycle_callbacks[event]:",
            "                    self._plugin_lifecycle_callbacks[event].remove(callback)",
            "        else:",
            "            if isinstance(events, str):",
            "                events = [events]",
            "",
            "            for event in events:",
            "                if callback in self._plugin_lifecycle_callbacks[event]:",
            "                    self._plugin_lifecycle_callbacks[event].remove(callback)",
            "",
            "",
            "class CannotStartServerException(Exception):",
            "    pass"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.octoprint.server.Server.run.timelapse_permission_validator",
            "src.octoprint.server.Server.run.removed_headers",
            "src.octoprint.server.Server.run.components",
            "src.octoprint.server.Server.run.max_body_sizes",
            "src.octoprint.server.Server.run.valid_log",
            "src.octoprint.server.Server.run.log_permission_validator",
            "src.octoprint.server.Server._setup_i18n.additional_folders",
            "src.octoprint.server.Server.run.download_permission_validator",
            "cbor2._decoder",
            "src.octoprint.server.Server.run.transforms",
            "src.octoprint.server.Server.run.camera_permission_validator",
            "src.octoprint.server.Server.run.additional_translation_folders",
            "src.octoprint.server.Server.run.timelapse_validators",
            "src.octoprint.server.LifecycleManager.add_callback.callback",
            "src.octoprint.server.LifecycleManager.add_callback.events",
            "src.octoprint.server.Server.run.storage_managers",
            "src.octoprint.server.Server.run.download_handler_kwargs",
            "src.octoprint.server.Server.run.additional_mime_types",
            "src.octoprint.server.Server.run.logs_path_validator",
            "src.octoprint.server.Server.run.download_validators",
            "src.octoprint.server.Server.run.access_validators_from_plugins",
            "src.octoprint.server.Server.run.only_known_types_validator",
            "src.octoprint.server.Server.run.log_validators",
            "src.octoprint.server.Server.run.camera_validators",
            "src.octoprint.server.Server.run.no_hidden_files_validator",
            "src.octoprint.server.Server.run.server_kwargs",
            "src.octoprint.server.Server.run.headers",
            "src.octoprint.server.Server.run.upload_suffixes",
            "src.octoprint.server.Server.run.timelapses_path_validator",
            "src.octoprint.server.Server.run.systeminfo_validators",
            "src.octoprint.server.Server.run.log_path_validator",
            "src.octoprint.server.Server.run.analysis_queue_factories",
            "src.octoprint.server.Server.run.timelapse_path_validator",
            "src.octoprint.server.Server.run.valid_timelapse",
            "src.octoprint.server.Server.run.systeminfo_permission_validator",
            "src.octoprint.server.Server.run.trusted_downstream"
        ]
    },
    "src/octoprint/server/api/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " )"
            },
            "1": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": " from octoprint.server.util.flask import ("
            },
            "2": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": 40,
                "PatchRowcode": "     get_json_command_from_request,"
            },
            "3": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    get_remote_address,"
            },
            "4": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "     limit,"
            },
            "5": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "     no_firstrun_access,"
            },
            "6": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "     passive_login,"
            },
            "7": {
                "beforePatchRowNumber": 302,
                "afterPatchRowNumber": 301,
                "PatchRowcode": "     if \"user\" in data and \"pass\" in data:"
            },
            "8": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 302,
                "PatchRowcode": "         username = data[\"user\"]"
            },
            "9": {
                "beforePatchRowNumber": 304,
                "afterPatchRowNumber": 303,
                "PatchRowcode": "         password = data[\"pass\"]"
            },
            "10": {
                "beforePatchRowNumber": 305,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        remote_addr = get_remote_address(request)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 304,
                "PatchRowcode": "+        remote_addr = request.remote_addr"
            },
            "12": {
                "beforePatchRowNumber": 306,
                "afterPatchRowNumber": 305,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 307,
                "afterPatchRowNumber": 306,
                "PatchRowcode": "         if \"remember\" in data and data[\"remember\"] in valid_boolean_trues:"
            },
            "14": {
                "beforePatchRowNumber": 308,
                "afterPatchRowNumber": 307,
                "PatchRowcode": "             remember = True"
            },
            "15": {
                "beforePatchRowNumber": 398,
                "afterPatchRowNumber": 397,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 399,
                "afterPatchRowNumber": 398,
                "PatchRowcode": "     if username:"
            },
            "17": {
                "beforePatchRowNumber": 400,
                "afterPatchRowNumber": 399,
                "PatchRowcode": "         eventManager().fire(Events.USER_LOGGED_OUT, payload={\"username\": username})"
            },
            "18": {
                "beforePatchRowNumber": 401,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        auth_log(f\"Logging out user {username} from {get_remote_address(request)}\")"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 400,
                "PatchRowcode": "+        auth_log(f\"Logging out user {username} from {request.remote_addr}\")"
            },
            "20": {
                "beforePatchRowNumber": 402,
                "afterPatchRowNumber": 401,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 403,
                "afterPatchRowNumber": 402,
                "PatchRowcode": "     return r"
            },
            "22": {
                "beforePatchRowNumber": 404,
                "afterPatchRowNumber": 403,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 774,
                "afterPatchRowNumber": 773,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 775,
                "afterPatchRowNumber": 774,
                "PatchRowcode": "     remote_addr = data.get(\"address\")"
            },
            "25": {
                "beforePatchRowNumber": 776,
                "afterPatchRowNumber": 775,
                "PatchRowcode": "     if not remote_addr:"
            },
            "26": {
                "beforePatchRowNumber": 777,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        remote_addr = get_remote_address(request)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 776,
                "PatchRowcode": "+        remote_addr = request.remote_addr"
            },
            "28": {
                "beforePatchRowNumber": 778,
                "afterPatchRowNumber": 777,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 779,
                "afterPatchRowNumber": 778,
                "PatchRowcode": "     remote_addr = sanitize_address(remote_addr)"
            },
            "30": {
                "beforePatchRowNumber": 780,
                "afterPatchRowNumber": 779,
                "PatchRowcode": "     ip = netaddr.IPAddress(remote_addr)"
            }
        },
        "frontPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import datetime",
            "import logging",
            "",
            "from flask import (",
            "    Blueprint,",
            "    Response,",
            "    abort,",
            "    current_app,",
            "    g,",
            "    jsonify,",
            "    make_response,",
            "    request,",
            "    session,",
            ")",
            "from flask_login import current_user, login_user, logout_user",
            "from werkzeug.exceptions import HTTPException",
            "",
            "import octoprint.access.users",
            "import octoprint.plugin",
            "import octoprint.server",
            "import octoprint.util.net as util_net",
            "from octoprint.access import auth_log",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.events import Events, eventManager",
            "from octoprint.server import NO_CONTENT",
            "from octoprint.server.util import (",
            "    LoginMechanism,",
            "    corsRequestHandler,",
            "    corsResponseHandler,",
            "    csrfRequestHandler,",
            "    loginFromApiKeyRequestHandler,",
            "    loginFromAuthorizationHeaderRequestHandler,",
            "    noCachingExceptGetResponseHandler,",
            ")",
            "from octoprint.server.util.flask import (",
            "    get_json_command_from_request,",
            "    get_remote_address,",
            "    limit,",
            "    no_firstrun_access,",
            "    passive_login,",
            "    session_signature,",
            "    to_api_credentials_seen,",
            ")",
            "from octoprint.settings import settings as s",
            "from octoprint.settings import valid_boolean_trues",
            "from octoprint.vendor.flask_principal import Identity, identity_changed",
            "",
            "# ~~ init api blueprint, including sub modules",
            "",
            "api = Blueprint(\"api\", __name__)",
            "",
            "from . import access as api_access  # noqa: F401,E402",
            "from . import connection as api_connection  # noqa: F401,E402",
            "from . import files as api_files  # noqa: F401,E402",
            "from . import job as api_job  # noqa: F401,E402",
            "from . import languages as api_languages  # noqa: F401,E402",
            "from . import printer as api_printer  # noqa: F401,E402",
            "from . import printer_profiles as api_printer_profiles  # noqa: F401,E402",
            "from . import settings as api_settings  # noqa: F401,E402",
            "from . import slicing as api_slicing  # noqa: F401,E402",
            "from . import system as api_system  # noqa: F401,E402",
            "from . import timelapse as api_timelapse  # noqa: F401,E402",
            "from . import users as api_users  # noqa: F401,E402",
            "",
            "VERSION = \"0.1\"",
            "",
            "api.after_request(noCachingExceptGetResponseHandler)",
            "",
            "api.before_request(corsRequestHandler)",
            "api.before_request(loginFromAuthorizationHeaderRequestHandler)",
            "api.before_request(loginFromApiKeyRequestHandler)",
            "api.before_request(csrfRequestHandler)",
            "api.after_request(corsResponseHandler)",
            "",
            "# ~~ data from plugins",
            "",
            "",
            "@api.route(\"/plugin/<string:name>\", methods=[\"GET\"])",
            "def pluginData(name):",
            "    api_plugins = octoprint.plugin.plugin_manager().get_filtered_implementations(",
            "        lambda p: p._identifier == name, octoprint.plugin.SimpleApiPlugin",
            "    )",
            "    if not api_plugins:",
            "        abort(404)",
            "",
            "    if len(api_plugins) > 1:",
            "        abort(500, description=\"More than one api provider registered, can't proceed\")",
            "",
            "    try:",
            "        api_plugin = api_plugins[0]",
            "        if api_plugin.is_api_adminonly() and not current_user.is_admin:",
            "            abort(403)",
            "",
            "        response = api_plugin.on_api_get(request)",
            "",
            "        if response is not None:",
            "            message = (",
            "                \"Rewriting response from {} to use abort(msg, code) - please \"",
            "                \"consider upgrading the implementation accordingly\".format(name)",
            "            )",
            "            if (",
            "                isinstance(response, Response)",
            "                and response.mimetype == \"text/html\"",
            "                and response.status_code >= 300",
            "            ):",
            "                # this actually looks like an error response",
            "                logging.getLogger(__name__).info(message)",
            "                abort(response.status_code, description=response.data)",
            "            elif (",
            "                isinstance(response, tuple)",
            "                and len(response) == 2",
            "                and isinstance(response[0], (str, bytes))",
            "                and response[1] >= 300",
            "            ):",
            "                # this actually looks like an error response",
            "                logging.getLogger(__name__).info(message)",
            "                abort(response[1], response[0])",
            "            return response",
            "        return NO_CONTENT",
            "    except HTTPException:",
            "        raise",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(",
            "            f\"Error calling SimpleApiPlugin {name}\", extra={\"plugin\": name}",
            "        )",
            "        return abort(500)",
            "",
            "",
            "# ~~ commands for plugins",
            "",
            "",
            "@api.route(\"/plugin/<string:name>\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "def pluginCommand(name):",
            "    api_plugins = octoprint.plugin.plugin_manager().get_filtered_implementations(",
            "        lambda p: p._identifier == name, octoprint.plugin.SimpleApiPlugin",
            "    )",
            "",
            "    if not api_plugins:",
            "        abort(400)",
            "",
            "    if len(api_plugins) > 1:",
            "        abort(500, description=\"More than one api provider registered, can't proceed\")",
            "",
            "    api_plugin = api_plugins[0]",
            "    try:",
            "        valid_commands = api_plugin.get_api_commands()",
            "        if valid_commands is None:",
            "            abort(405)",
            "",
            "        if api_plugin.is_api_adminonly() and not Permissions.ADMIN.can():",
            "            abort(403)",
            "",
            "        command, data, response = get_json_command_from_request(request, valid_commands)",
            "        if response is not None:",
            "            return response",
            "",
            "        response = api_plugin.on_api_command(command, data)",
            "        if response is not None:",
            "            return response",
            "        return NO_CONTENT",
            "    except HTTPException:",
            "        raise",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(",
            "            f\"Error while executing SimpleApiPlugin {name}\",",
            "            extra={\"plugin\": name},",
            "        )",
            "        return abort(500)",
            "",
            "",
            "# ~~ first run setup",
            "",
            "",
            "@api.route(\"/setup/wizard\", methods=[\"GET\"])",
            "def wizardState():",
            "    if (",
            "        not s().getBoolean([\"server\", \"firstRun\"])",
            "        and octoprint.server.userManager.has_been_customized()",
            "        and not Permissions.ADMIN.can()",
            "    ):",
            "        abort(403)",
            "",
            "    seen_wizards = s().get([\"server\", \"seenWizards\"])",
            "",
            "    result = {}",
            "    wizard_plugins = octoprint.server.pluginManager.get_implementations(",
            "        octoprint.plugin.WizardPlugin",
            "    )",
            "    for implementation in wizard_plugins:",
            "        name = implementation._identifier",
            "        try:",
            "            required = implementation.is_wizard_required()",
            "            details = implementation.get_wizard_details()",
            "            version = implementation.get_wizard_version()",
            "            ignored = octoprint.plugin.WizardPlugin.is_wizard_ignored(",
            "                seen_wizards, implementation",
            "            )",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                \"There was an error fetching wizard \"",
            "                \"details for {}, ignoring\".format(name),",
            "                extra={\"plugin\": name},",
            "            )",
            "        else:",
            "            result[name] = {",
            "                \"required\": required,",
            "                \"details\": details,",
            "                \"version\": version,",
            "                \"ignored\": ignored,",
            "            }",
            "",
            "    return jsonify(result)",
            "",
            "",
            "@api.route(\"/setup/wizard\", methods=[\"POST\"])",
            "def wizardFinish():",
            "    if (",
            "        not s().getBoolean([\"server\", \"firstRun\"])",
            "        and octoprint.server.userManager.has_been_customized()",
            "        and not Permissions.ADMIN.can()",
            "    ):",
            "        abort(403)",
            "",
            "    data = {}",
            "    try:",
            "        data = request.get_json()",
            "    except Exception:",
            "        abort(400)",
            "",
            "    if data is None:",
            "        abort(400)",
            "",
            "    if \"handled\" not in data:",
            "        abort(400)",
            "    handled = data[\"handled\"]",
            "",
            "    if s().getBoolean([\"server\", \"firstRun\"]):",
            "        s().setBoolean([\"server\", \"firstRun\"], False)",
            "",
            "    seen_wizards = dict(s().get([\"server\", \"seenWizards\"]))",
            "",
            "    wizard_plugins = octoprint.server.pluginManager.get_implementations(",
            "        octoprint.plugin.WizardPlugin",
            "    )",
            "    for implementation in wizard_plugins:",
            "        name = implementation._identifier",
            "        try:",
            "            implementation.on_wizard_finish(name in handled)",
            "            if name in handled:",
            "                seen_wizards[name] = implementation.get_wizard_version()",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                \"There was an error finishing the \"",
            "                \"wizard for {}, ignoring\".format(name),",
            "                extra={\"plugin\": name},",
            "            )",
            "",
            "    s().set([\"server\", \"seenWizards\"], seen_wizards)",
            "    s().save()",
            "",
            "    return NO_CONTENT",
            "",
            "",
            "# ~~ system state",
            "",
            "",
            "@api.route(\"/version\", methods=[\"GET\"])",
            "@Permissions.STATUS.require(403)",
            "def apiVersion():",
            "    return jsonify(",
            "        server=octoprint.server.VERSION,",
            "        api=VERSION,",
            "        text=f\"OctoPrint {octoprint.server.DISPLAY_VERSION}\",",
            "    )",
            "",
            "",
            "@api.route(\"/server\", methods=[\"GET\"])",
            "@Permissions.STATUS.require(403)",
            "def serverStatus():",
            "    return jsonify(version=octoprint.server.VERSION, safemode=octoprint.server.safe_mode)",
            "",
            "",
            "# ~~ Login/user handling",
            "",
            "",
            "@api.route(\"/login\", methods=[\"POST\"])",
            "@limit(",
            "    \"3/minute;5/10 minutes;10/hour\",",
            "    deduct_when=lambda response: response.status_code == 403,",
            "    error_message=\"You have made too many failed login attempts. Please try again later.\",",
            ")",
            "def login():",
            "    data = request.get_json(silent=True)",
            "    if not data:",
            "        data = request.values",
            "",
            "    if \"user\" in data and \"pass\" in data:",
            "        username = data[\"user\"]",
            "        password = data[\"pass\"]",
            "        remote_addr = get_remote_address(request)",
            "",
            "        if \"remember\" in data and data[\"remember\"] in valid_boolean_trues:",
            "            remember = True",
            "        else:",
            "            remember = False",
            "",
            "        if \"usersession.id\" in session:",
            "            _logout(current_user)",
            "",
            "        user = octoprint.server.userManager.find_user(username)",
            "        if user is not None:",
            "            if octoprint.server.userManager.check_password(username, password):",
            "                if not user.is_active:",
            "                    auth_log(",
            "                        f\"Failed login attempt for user {username} from {remote_addr}, user is deactivated\"",
            "                    )",
            "                    abort(403)",
            "",
            "                user = octoprint.server.userManager.login_user(user)",
            "                session[\"usersession.id\"] = user.session",
            "                session[\"usersession.signature\"] = session_signature(",
            "                    username, user.session",
            "                )",
            "                g.user = user",
            "",
            "                login_user(user, remember=remember)",
            "                identity_changed.send(",
            "                    current_app._get_current_object(), identity=Identity(user.get_id())",
            "                )",
            "                session[\"login_mechanism\"] = LoginMechanism.PASSWORD",
            "                session[\"credentials_seen\"] = datetime.datetime.now().timestamp()",
            "",
            "                logging.getLogger(__name__).info(",
            "                    \"Actively logging in user {} from {}\".format(",
            "                        user.get_id(), remote_addr",
            "                    )",
            "                )",
            "",
            "                response = user.as_dict()",
            "                response[\"_is_external_client\"] = s().getBoolean(",
            "                    [\"server\", \"ipCheck\", \"enabled\"]",
            "                ) and not util_net.is_lan_address(",
            "                    remote_addr,",
            "                    additional_private=s().get([\"server\", \"ipCheck\", \"trustedSubnets\"]),",
            "                )",
            "                response[\"_login_mechanism\"] = session[\"login_mechanism\"]",
            "                response[\"_credentials_seen\"] = to_api_credentials_seen(",
            "                    session[\"credentials_seen\"]",
            "                )",
            "",
            "                r = make_response(jsonify(response))",
            "                r.delete_cookie(\"active_logout\")",
            "",
            "                eventManager().fire(",
            "                    Events.USER_LOGGED_IN, payload={\"username\": user.get_id()}",
            "                )",
            "                auth_log(f\"Logging in user {username} from {remote_addr} via credentials\")",
            "",
            "                return r",
            "",
            "            else:",
            "                auth_log(",
            "                    f\"Failed login attempt for user {username} from {remote_addr}, wrong password\"",
            "                )",
            "        else:",
            "            auth_log(",
            "                f\"Failed login attempt for user {username} from {remote_addr}, user is unknown\"",
            "            )",
            "",
            "        abort(403)",
            "",
            "    elif \"passive\" in data:",
            "        return passive_login()",
            "",
            "    abort(400, description=\"Neither user and pass attributes nor passive flag present\")",
            "",
            "",
            "@api.route(\"/logout\", methods=[\"POST\"])",
            "def logout():",
            "    username = None",
            "    if current_user:",
            "        username = current_user.get_id()",
            "",
            "    # logout from user manager...",
            "    _logout(current_user)",
            "",
            "    # ... and from flask login (and principal)",
            "    logout_user()",
            "",
            "    # ... and send an active logout session cookie",
            "    r = make_response(jsonify(octoprint.server.userManager.anonymous_user_factory()))",
            "    r.set_cookie(\"active_logout\", \"true\")",
            "",
            "    if username:",
            "        eventManager().fire(Events.USER_LOGGED_OUT, payload={\"username\": username})",
            "        auth_log(f\"Logging out user {username} from {get_remote_address(request)}\")",
            "",
            "    return r",
            "",
            "",
            "def _logout(user):",
            "    if \"usersession.id\" in session:",
            "        del session[\"usersession.id\"]",
            "    if \"login_mechanism\" in session:",
            "        del session[\"login_mechanism\"]",
            "    octoprint.server.userManager.logout_user(user)",
            "",
            "",
            "@api.route(\"/currentuser\", methods=[\"GET\"])",
            "def get_current_user():",
            "    return jsonify(",
            "        name=current_user.get_name(),",
            "        permissions=[permission.key for permission in current_user.effective_permissions],",
            "        groups=[group.key for group in current_user.groups],",
            "    )",
            "",
            "",
            "# ~~ Test utils",
            "",
            "",
            "@api.route(\"/util/test\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.ADMIN.require(403)",
            "def utilTest():",
            "    valid_commands = {",
            "        \"path\": [\"path\"],",
            "        \"url\": [\"url\"],",
            "        \"server\": [\"host\", \"port\"],",
            "        \"resolution\": [\"name\"],",
            "        \"address\": [],",
            "    }",
            "",
            "    command, data, response = get_json_command_from_request(request, valid_commands)",
            "    if response is not None:",
            "        return response",
            "",
            "    if command == \"path\":",
            "        return _test_path(data)",
            "    elif command == \"url\":",
            "        return _test_url(data)",
            "    elif command == \"server\":",
            "        return _test_server(data)",
            "    elif command == \"resolution\":",
            "        return _test_resolution(data)",
            "    elif command == \"address\":",
            "        return _test_address(data)",
            "",
            "",
            "def _test_path(data):",
            "    import os",
            "",
            "    from octoprint.util.paths import normalize",
            "",
            "    path = normalize(data[\"path\"], real=False)",
            "    if not path:",
            "        return jsonify(",
            "            path=path,",
            "            exists=False,",
            "            typeok=False,",
            "            broken_symlink=False,",
            "            access=False,",
            "            result=False,",
            "        )",
            "",
            "    unreal_path = path",
            "    path = os.path.realpath(path)",
            "",
            "    check_type = None",
            "    check_access = []",
            "",
            "    if \"check_type\" in data and data[\"check_type\"] in (\"file\", \"dir\"):",
            "        check_type = data[\"check_type\"]",
            "",
            "    if \"check_access\" in data:",
            "        request_check_access = data[\"check_access\"]",
            "        if not isinstance(request_check_access, list):",
            "            request_check_access = list(request_check_access)",
            "",
            "        check_access = [",
            "            check for check in request_check_access if check in (\"r\", \"w\", \"x\")",
            "        ]",
            "",
            "    allow_create_dir = data.get(\"allow_create_dir\", False) and check_type == \"dir\"",
            "    check_writable_dir = data.get(\"check_writable_dir\", False) and check_type == \"dir\"",
            "    if check_writable_dir and \"w\" not in check_access:",
            "        check_access.append(\"w\")",
            "",
            "    # check if path exists",
            "    exists = os.path.exists(path)",
            "    if not exists:",
            "        if os.path.islink(unreal_path):",
            "            # broken symlink, see #2644",
            "            logging.getLogger(__name__).error(",
            "                \"{} is a broken symlink pointing at non existing {}\".format(",
            "                    unreal_path, path",
            "                )",
            "            )",
            "            return jsonify(",
            "                path=unreal_path,",
            "                exists=False,",
            "                typeok=False,",
            "                broken_symlink=True,",
            "                access=False,",
            "                result=False,",
            "            )",
            "",
            "        elif check_type == \"dir\" and allow_create_dir:",
            "            try:",
            "                os.makedirs(path)",
            "            except Exception:",
            "                logging.getLogger(__name__).exception(",
            "                    f\"Error while trying to create {path}\"",
            "                )",
            "                return jsonify(",
            "                    path=path,",
            "                    exists=False,",
            "                    typeok=False,",
            "                    broken_symlink=False,",
            "                    access=False,",
            "                    result=False,",
            "                )",
            "            else:",
            "                exists = True",
            "",
            "    # check path type",
            "    type_mapping = {\"file\": os.path.isfile, \"dir\": os.path.isdir}",
            "    if check_type:",
            "        typeok = type_mapping[check_type](path)",
            "    else:",
            "        typeok = exists",
            "",
            "    # check if path allows requested access",
            "    access_mapping = {\"r\": os.R_OK, \"w\": os.W_OK, \"x\": os.X_OK}",
            "    if check_access:",
            "        mode = 0",
            "        for a in map(lambda x: access_mapping[x], check_access):",
            "            mode |= a",
            "        access = os.access(path, mode)",
            "    else:",
            "        access = exists",
            "",
            "    if check_writable_dir and check_type == \"dir\":",
            "        try:",
            "            test_path = os.path.join(path, \".testballoon.txt\")",
            "            with open(test_path, \"wb\") as f:",
            "                f.write(b\"Test\")",
            "            os.remove(test_path)",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                f\"Error while testing if {path} is really writable\"",
            "            )",
            "            return jsonify(",
            "                path=path,",
            "                exists=exists,",
            "                typeok=typeok,",
            "                broken_symlink=False,",
            "                access=False,",
            "                result=False,",
            "            )",
            "",
            "    return jsonify(",
            "        path=path,",
            "        exists=exists,",
            "        typeok=typeok,",
            "        broken_symlink=False,",
            "        access=access,",
            "        result=exists and typeok and access,",
            "    )",
            "",
            "",
            "def _test_url(data):",
            "    import requests",
            "",
            "    from octoprint import util as util",
            "",
            "    class StatusCodeRange:",
            "        def __init__(self, start=None, end=None):",
            "            self.start = start",
            "            self.end = end",
            "",
            "        def __contains__(self, item):",
            "            if not isinstance(item, int):",
            "                return False",
            "            if self.start and self.end:",
            "                return self.start <= item < self.end",
            "            elif self.start:",
            "                return self.start <= item",
            "            elif self.end:",
            "                return item < self.end",
            "            else:",
            "                return False",
            "",
            "        def as_dict(self):",
            "            return {\"start\": self.start, \"end\": self.end}",
            "",
            "    status_ranges = {",
            "        \"informational\": StatusCodeRange(start=100, end=200),",
            "        \"success\": StatusCodeRange(start=200, end=300),",
            "        \"redirection\": StatusCodeRange(start=300, end=400),",
            "        \"client_error\": StatusCodeRange(start=400, end=500),",
            "        \"server_error\": StatusCodeRange(start=500, end=600),",
            "        \"normal\": StatusCodeRange(end=400),",
            "        \"error\": StatusCodeRange(start=400, end=600),",
            "        \"any\": StatusCodeRange(start=100),",
            "        \"timeout\": StatusCodeRange(start=0, end=1),",
            "    }",
            "",
            "    url = data[\"url\"]",
            "    method = data.get(\"method\", \"HEAD\")",
            "    timeout = 3.0",
            "    valid_ssl = True",
            "    check_status = [status_ranges[\"normal\"]]",
            "    content_type_whitelist = None",
            "    content_type_blacklist = None",
            "",
            "    if \"timeout\" in data:",
            "        try:",
            "            timeout = float(data[\"timeout\"])",
            "        except Exception:",
            "            abort(400, description=\"timeout is invalid\")",
            "",
            "    if \"validSsl\" in data:",
            "        valid_ssl = data[\"validSsl\"] in valid_boolean_trues",
            "",
            "    if \"status\" in data:",
            "        request_status = data[\"status\"]",
            "        if not isinstance(request_status, list):",
            "            request_status = [request_status]",
            "",
            "        check_status = []",
            "        for rs in request_status:",
            "            if isinstance(rs, int):",
            "                check_status.append([rs])",
            "            else:",
            "                if rs in status_ranges:",
            "                    check_status.append(status_ranges[rs])",
            "                else:",
            "                    code = requests.codes[rs]",
            "                    if code is not None:",
            "                        check_status.append([code])",
            "",
            "    if \"content_type_whitelist\" in data:",
            "        if not isinstance(data[\"content_type_whitelist\"], (list, tuple)):",
            "            abort(400, description=\"content_type_whitelist must be a list of mime types\")",
            "        content_type_whitelist = list(",
            "            map(util.parse_mime_type, data[\"content_type_whitelist\"])",
            "        )",
            "    if \"content_type_blacklist\" in data:",
            "        if not isinstance(data[\"content_type_whitelist\"], (list, tuple)):",
            "            abort(400, description=\"content_type_blacklist must be a list of mime types\")",
            "        content_type_blacklist = list(",
            "            map(util.parse_mime_type, data[\"content_type_blacklist\"])",
            "        )",
            "",
            "    response_result = None",
            "    outcome = True",
            "    status = 0",
            "    try:",
            "        with requests.request(",
            "            method=method, url=url, timeout=timeout, verify=valid_ssl, stream=True",
            "        ) as response:",
            "            status = response.status_code",
            "            outcome = outcome and any(map(lambda x: status in x, check_status))",
            "            content_type = response.headers.get(\"content-type\")",
            "",
            "            response_result = {",
            "                \"headers\": dict(response.headers),",
            "                \"content_type\": content_type,",
            "            }",
            "",
            "            if not content_type and data.get(\"content_type_guess\") in valid_boolean_trues:",
            "                content = response.content",
            "                content_type = util.guess_mime_type(bytearray(content))",
            "",
            "            if not content_type:",
            "                content_type = \"application/octet-stream\"",
            "",
            "            response_result = {\"assumed_content_type\": content_type}",
            "",
            "            parsed_content_type = util.parse_mime_type(content_type)",
            "",
            "            in_whitelist = content_type_whitelist is None or any(",
            "                map(",
            "                    lambda x: util.mime_type_matches(parsed_content_type, x),",
            "                    content_type_whitelist,",
            "                )",
            "            )",
            "            in_blacklist = content_type_blacklist is not None and any(",
            "                map(",
            "                    lambda x: util.mime_type_matches(parsed_content_type, x),",
            "                    content_type_blacklist,",
            "                )",
            "            )",
            "",
            "            if not in_whitelist or in_blacklist:",
            "                # we don't support this content type",
            "                response.close()",
            "                outcome = False",
            "",
            "            elif \"response\" in data and (",
            "                data[\"response\"] in valid_boolean_trues",
            "                or data[\"response\"] in (\"json\", \"bytes\")",
            "            ):",
            "                if data[\"response\"] == \"json\":",
            "                    content = response.json()",
            "",
            "                else:",
            "                    import base64",
            "",
            "                    content = base64.standard_b64encode(response.content)",
            "",
            "                response_result[\"content\"] = content",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(",
            "            f\"Error while running a test {method} request on {url}\"",
            "        )",
            "        outcome = False",
            "",
            "    result = {\"url\": url, \"status\": status, \"result\": outcome}",
            "    if response_result:",
            "        result[\"response\"] = response_result",
            "",
            "    return jsonify(**result)",
            "",
            "",
            "def _test_server(data):",
            "    host = data[\"host\"]",
            "    try:",
            "        port = int(data[\"port\"])",
            "    except Exception:",
            "        abort(400, description=\"Invalid value for port\")",
            "",
            "    timeout = 3.05",
            "    if \"timeout\" in data:",
            "        try:",
            "            timeout = float(data[\"timeout\"])",
            "        except Exception:",
            "            abort(400, description=\"Invalid value for timeout\")",
            "",
            "    protocol = data.get(\"protocol\", \"tcp\")",
            "    if protocol not in (\"tcp\", \"udp\"):",
            "        abort(400, description=\"Invalid value for protocol\")",
            "",
            "    from octoprint.util import server_reachable",
            "",
            "    reachable = server_reachable(host, port, timeout=timeout, proto=protocol)",
            "",
            "    result = {\"host\": host, \"port\": port, \"protocol\": protocol, \"result\": reachable}",
            "",
            "    return jsonify(**result)",
            "",
            "",
            "def _test_resolution(data):",
            "    name = data[\"name\"]",
            "",
            "    from octoprint.util.net import resolve_host",
            "",
            "    resolvable = len(resolve_host(name)) > 0",
            "",
            "    result = {\"name\": name, \"result\": resolvable}",
            "",
            "    return jsonify(**result)",
            "",
            "",
            "def _test_address(data):",
            "    import netaddr",
            "",
            "    from octoprint.util.net import get_lan_ranges, sanitize_address",
            "",
            "    remote_addr = data.get(\"address\")",
            "    if not remote_addr:",
            "        remote_addr = get_remote_address(request)",
            "",
            "    remote_addr = sanitize_address(remote_addr)",
            "    ip = netaddr.IPAddress(remote_addr)",
            "",
            "    lan_subnets = get_lan_ranges()",
            "",
            "    detected_subnet = None",
            "    for subnet in lan_subnets:",
            "        if ip in subnet:",
            "            detected_subnet = subnet",
            "            break",
            "",
            "    result = {",
            "        \"is_lan_address\": detected_subnet is not None,",
            "        \"address\": remote_addr,",
            "    }",
            "",
            "    if detected_subnet is not None:",
            "        result[\"subnet\"] = str(detected_subnet)",
            "",
            "    return jsonify(**result)"
        ],
        "afterPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import datetime",
            "import logging",
            "",
            "from flask import (",
            "    Blueprint,",
            "    Response,",
            "    abort,",
            "    current_app,",
            "    g,",
            "    jsonify,",
            "    make_response,",
            "    request,",
            "    session,",
            ")",
            "from flask_login import current_user, login_user, logout_user",
            "from werkzeug.exceptions import HTTPException",
            "",
            "import octoprint.access.users",
            "import octoprint.plugin",
            "import octoprint.server",
            "import octoprint.util.net as util_net",
            "from octoprint.access import auth_log",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.events import Events, eventManager",
            "from octoprint.server import NO_CONTENT",
            "from octoprint.server.util import (",
            "    LoginMechanism,",
            "    corsRequestHandler,",
            "    corsResponseHandler,",
            "    csrfRequestHandler,",
            "    loginFromApiKeyRequestHandler,",
            "    loginFromAuthorizationHeaderRequestHandler,",
            "    noCachingExceptGetResponseHandler,",
            ")",
            "from octoprint.server.util.flask import (",
            "    get_json_command_from_request,",
            "    limit,",
            "    no_firstrun_access,",
            "    passive_login,",
            "    session_signature,",
            "    to_api_credentials_seen,",
            ")",
            "from octoprint.settings import settings as s",
            "from octoprint.settings import valid_boolean_trues",
            "from octoprint.vendor.flask_principal import Identity, identity_changed",
            "",
            "# ~~ init api blueprint, including sub modules",
            "",
            "api = Blueprint(\"api\", __name__)",
            "",
            "from . import access as api_access  # noqa: F401,E402",
            "from . import connection as api_connection  # noqa: F401,E402",
            "from . import files as api_files  # noqa: F401,E402",
            "from . import job as api_job  # noqa: F401,E402",
            "from . import languages as api_languages  # noqa: F401,E402",
            "from . import printer as api_printer  # noqa: F401,E402",
            "from . import printer_profiles as api_printer_profiles  # noqa: F401,E402",
            "from . import settings as api_settings  # noqa: F401,E402",
            "from . import slicing as api_slicing  # noqa: F401,E402",
            "from . import system as api_system  # noqa: F401,E402",
            "from . import timelapse as api_timelapse  # noqa: F401,E402",
            "from . import users as api_users  # noqa: F401,E402",
            "",
            "VERSION = \"0.1\"",
            "",
            "api.after_request(noCachingExceptGetResponseHandler)",
            "",
            "api.before_request(corsRequestHandler)",
            "api.before_request(loginFromAuthorizationHeaderRequestHandler)",
            "api.before_request(loginFromApiKeyRequestHandler)",
            "api.before_request(csrfRequestHandler)",
            "api.after_request(corsResponseHandler)",
            "",
            "# ~~ data from plugins",
            "",
            "",
            "@api.route(\"/plugin/<string:name>\", methods=[\"GET\"])",
            "def pluginData(name):",
            "    api_plugins = octoprint.plugin.plugin_manager().get_filtered_implementations(",
            "        lambda p: p._identifier == name, octoprint.plugin.SimpleApiPlugin",
            "    )",
            "    if not api_plugins:",
            "        abort(404)",
            "",
            "    if len(api_plugins) > 1:",
            "        abort(500, description=\"More than one api provider registered, can't proceed\")",
            "",
            "    try:",
            "        api_plugin = api_plugins[0]",
            "        if api_plugin.is_api_adminonly() and not current_user.is_admin:",
            "            abort(403)",
            "",
            "        response = api_plugin.on_api_get(request)",
            "",
            "        if response is not None:",
            "            message = (",
            "                \"Rewriting response from {} to use abort(msg, code) - please \"",
            "                \"consider upgrading the implementation accordingly\".format(name)",
            "            )",
            "            if (",
            "                isinstance(response, Response)",
            "                and response.mimetype == \"text/html\"",
            "                and response.status_code >= 300",
            "            ):",
            "                # this actually looks like an error response",
            "                logging.getLogger(__name__).info(message)",
            "                abort(response.status_code, description=response.data)",
            "            elif (",
            "                isinstance(response, tuple)",
            "                and len(response) == 2",
            "                and isinstance(response[0], (str, bytes))",
            "                and response[1] >= 300",
            "            ):",
            "                # this actually looks like an error response",
            "                logging.getLogger(__name__).info(message)",
            "                abort(response[1], response[0])",
            "            return response",
            "        return NO_CONTENT",
            "    except HTTPException:",
            "        raise",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(",
            "            f\"Error calling SimpleApiPlugin {name}\", extra={\"plugin\": name}",
            "        )",
            "        return abort(500)",
            "",
            "",
            "# ~~ commands for plugins",
            "",
            "",
            "@api.route(\"/plugin/<string:name>\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "def pluginCommand(name):",
            "    api_plugins = octoprint.plugin.plugin_manager().get_filtered_implementations(",
            "        lambda p: p._identifier == name, octoprint.plugin.SimpleApiPlugin",
            "    )",
            "",
            "    if not api_plugins:",
            "        abort(400)",
            "",
            "    if len(api_plugins) > 1:",
            "        abort(500, description=\"More than one api provider registered, can't proceed\")",
            "",
            "    api_plugin = api_plugins[0]",
            "    try:",
            "        valid_commands = api_plugin.get_api_commands()",
            "        if valid_commands is None:",
            "            abort(405)",
            "",
            "        if api_plugin.is_api_adminonly() and not Permissions.ADMIN.can():",
            "            abort(403)",
            "",
            "        command, data, response = get_json_command_from_request(request, valid_commands)",
            "        if response is not None:",
            "            return response",
            "",
            "        response = api_plugin.on_api_command(command, data)",
            "        if response is not None:",
            "            return response",
            "        return NO_CONTENT",
            "    except HTTPException:",
            "        raise",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(",
            "            f\"Error while executing SimpleApiPlugin {name}\",",
            "            extra={\"plugin\": name},",
            "        )",
            "        return abort(500)",
            "",
            "",
            "# ~~ first run setup",
            "",
            "",
            "@api.route(\"/setup/wizard\", methods=[\"GET\"])",
            "def wizardState():",
            "    if (",
            "        not s().getBoolean([\"server\", \"firstRun\"])",
            "        and octoprint.server.userManager.has_been_customized()",
            "        and not Permissions.ADMIN.can()",
            "    ):",
            "        abort(403)",
            "",
            "    seen_wizards = s().get([\"server\", \"seenWizards\"])",
            "",
            "    result = {}",
            "    wizard_plugins = octoprint.server.pluginManager.get_implementations(",
            "        octoprint.plugin.WizardPlugin",
            "    )",
            "    for implementation in wizard_plugins:",
            "        name = implementation._identifier",
            "        try:",
            "            required = implementation.is_wizard_required()",
            "            details = implementation.get_wizard_details()",
            "            version = implementation.get_wizard_version()",
            "            ignored = octoprint.plugin.WizardPlugin.is_wizard_ignored(",
            "                seen_wizards, implementation",
            "            )",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                \"There was an error fetching wizard \"",
            "                \"details for {}, ignoring\".format(name),",
            "                extra={\"plugin\": name},",
            "            )",
            "        else:",
            "            result[name] = {",
            "                \"required\": required,",
            "                \"details\": details,",
            "                \"version\": version,",
            "                \"ignored\": ignored,",
            "            }",
            "",
            "    return jsonify(result)",
            "",
            "",
            "@api.route(\"/setup/wizard\", methods=[\"POST\"])",
            "def wizardFinish():",
            "    if (",
            "        not s().getBoolean([\"server\", \"firstRun\"])",
            "        and octoprint.server.userManager.has_been_customized()",
            "        and not Permissions.ADMIN.can()",
            "    ):",
            "        abort(403)",
            "",
            "    data = {}",
            "    try:",
            "        data = request.get_json()",
            "    except Exception:",
            "        abort(400)",
            "",
            "    if data is None:",
            "        abort(400)",
            "",
            "    if \"handled\" not in data:",
            "        abort(400)",
            "    handled = data[\"handled\"]",
            "",
            "    if s().getBoolean([\"server\", \"firstRun\"]):",
            "        s().setBoolean([\"server\", \"firstRun\"], False)",
            "",
            "    seen_wizards = dict(s().get([\"server\", \"seenWizards\"]))",
            "",
            "    wizard_plugins = octoprint.server.pluginManager.get_implementations(",
            "        octoprint.plugin.WizardPlugin",
            "    )",
            "    for implementation in wizard_plugins:",
            "        name = implementation._identifier",
            "        try:",
            "            implementation.on_wizard_finish(name in handled)",
            "            if name in handled:",
            "                seen_wizards[name] = implementation.get_wizard_version()",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                \"There was an error finishing the \"",
            "                \"wizard for {}, ignoring\".format(name),",
            "                extra={\"plugin\": name},",
            "            )",
            "",
            "    s().set([\"server\", \"seenWizards\"], seen_wizards)",
            "    s().save()",
            "",
            "    return NO_CONTENT",
            "",
            "",
            "# ~~ system state",
            "",
            "",
            "@api.route(\"/version\", methods=[\"GET\"])",
            "@Permissions.STATUS.require(403)",
            "def apiVersion():",
            "    return jsonify(",
            "        server=octoprint.server.VERSION,",
            "        api=VERSION,",
            "        text=f\"OctoPrint {octoprint.server.DISPLAY_VERSION}\",",
            "    )",
            "",
            "",
            "@api.route(\"/server\", methods=[\"GET\"])",
            "@Permissions.STATUS.require(403)",
            "def serverStatus():",
            "    return jsonify(version=octoprint.server.VERSION, safemode=octoprint.server.safe_mode)",
            "",
            "",
            "# ~~ Login/user handling",
            "",
            "",
            "@api.route(\"/login\", methods=[\"POST\"])",
            "@limit(",
            "    \"3/minute;5/10 minutes;10/hour\",",
            "    deduct_when=lambda response: response.status_code == 403,",
            "    error_message=\"You have made too many failed login attempts. Please try again later.\",",
            ")",
            "def login():",
            "    data = request.get_json(silent=True)",
            "    if not data:",
            "        data = request.values",
            "",
            "    if \"user\" in data and \"pass\" in data:",
            "        username = data[\"user\"]",
            "        password = data[\"pass\"]",
            "        remote_addr = request.remote_addr",
            "",
            "        if \"remember\" in data and data[\"remember\"] in valid_boolean_trues:",
            "            remember = True",
            "        else:",
            "            remember = False",
            "",
            "        if \"usersession.id\" in session:",
            "            _logout(current_user)",
            "",
            "        user = octoprint.server.userManager.find_user(username)",
            "        if user is not None:",
            "            if octoprint.server.userManager.check_password(username, password):",
            "                if not user.is_active:",
            "                    auth_log(",
            "                        f\"Failed login attempt for user {username} from {remote_addr}, user is deactivated\"",
            "                    )",
            "                    abort(403)",
            "",
            "                user = octoprint.server.userManager.login_user(user)",
            "                session[\"usersession.id\"] = user.session",
            "                session[\"usersession.signature\"] = session_signature(",
            "                    username, user.session",
            "                )",
            "                g.user = user",
            "",
            "                login_user(user, remember=remember)",
            "                identity_changed.send(",
            "                    current_app._get_current_object(), identity=Identity(user.get_id())",
            "                )",
            "                session[\"login_mechanism\"] = LoginMechanism.PASSWORD",
            "                session[\"credentials_seen\"] = datetime.datetime.now().timestamp()",
            "",
            "                logging.getLogger(__name__).info(",
            "                    \"Actively logging in user {} from {}\".format(",
            "                        user.get_id(), remote_addr",
            "                    )",
            "                )",
            "",
            "                response = user.as_dict()",
            "                response[\"_is_external_client\"] = s().getBoolean(",
            "                    [\"server\", \"ipCheck\", \"enabled\"]",
            "                ) and not util_net.is_lan_address(",
            "                    remote_addr,",
            "                    additional_private=s().get([\"server\", \"ipCheck\", \"trustedSubnets\"]),",
            "                )",
            "                response[\"_login_mechanism\"] = session[\"login_mechanism\"]",
            "                response[\"_credentials_seen\"] = to_api_credentials_seen(",
            "                    session[\"credentials_seen\"]",
            "                )",
            "",
            "                r = make_response(jsonify(response))",
            "                r.delete_cookie(\"active_logout\")",
            "",
            "                eventManager().fire(",
            "                    Events.USER_LOGGED_IN, payload={\"username\": user.get_id()}",
            "                )",
            "                auth_log(f\"Logging in user {username} from {remote_addr} via credentials\")",
            "",
            "                return r",
            "",
            "            else:",
            "                auth_log(",
            "                    f\"Failed login attempt for user {username} from {remote_addr}, wrong password\"",
            "                )",
            "        else:",
            "            auth_log(",
            "                f\"Failed login attempt for user {username} from {remote_addr}, user is unknown\"",
            "            )",
            "",
            "        abort(403)",
            "",
            "    elif \"passive\" in data:",
            "        return passive_login()",
            "",
            "    abort(400, description=\"Neither user and pass attributes nor passive flag present\")",
            "",
            "",
            "@api.route(\"/logout\", methods=[\"POST\"])",
            "def logout():",
            "    username = None",
            "    if current_user:",
            "        username = current_user.get_id()",
            "",
            "    # logout from user manager...",
            "    _logout(current_user)",
            "",
            "    # ... and from flask login (and principal)",
            "    logout_user()",
            "",
            "    # ... and send an active logout session cookie",
            "    r = make_response(jsonify(octoprint.server.userManager.anonymous_user_factory()))",
            "    r.set_cookie(\"active_logout\", \"true\")",
            "",
            "    if username:",
            "        eventManager().fire(Events.USER_LOGGED_OUT, payload={\"username\": username})",
            "        auth_log(f\"Logging out user {username} from {request.remote_addr}\")",
            "",
            "    return r",
            "",
            "",
            "def _logout(user):",
            "    if \"usersession.id\" in session:",
            "        del session[\"usersession.id\"]",
            "    if \"login_mechanism\" in session:",
            "        del session[\"login_mechanism\"]",
            "    octoprint.server.userManager.logout_user(user)",
            "",
            "",
            "@api.route(\"/currentuser\", methods=[\"GET\"])",
            "def get_current_user():",
            "    return jsonify(",
            "        name=current_user.get_name(),",
            "        permissions=[permission.key for permission in current_user.effective_permissions],",
            "        groups=[group.key for group in current_user.groups],",
            "    )",
            "",
            "",
            "# ~~ Test utils",
            "",
            "",
            "@api.route(\"/util/test\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.ADMIN.require(403)",
            "def utilTest():",
            "    valid_commands = {",
            "        \"path\": [\"path\"],",
            "        \"url\": [\"url\"],",
            "        \"server\": [\"host\", \"port\"],",
            "        \"resolution\": [\"name\"],",
            "        \"address\": [],",
            "    }",
            "",
            "    command, data, response = get_json_command_from_request(request, valid_commands)",
            "    if response is not None:",
            "        return response",
            "",
            "    if command == \"path\":",
            "        return _test_path(data)",
            "    elif command == \"url\":",
            "        return _test_url(data)",
            "    elif command == \"server\":",
            "        return _test_server(data)",
            "    elif command == \"resolution\":",
            "        return _test_resolution(data)",
            "    elif command == \"address\":",
            "        return _test_address(data)",
            "",
            "",
            "def _test_path(data):",
            "    import os",
            "",
            "    from octoprint.util.paths import normalize",
            "",
            "    path = normalize(data[\"path\"], real=False)",
            "    if not path:",
            "        return jsonify(",
            "            path=path,",
            "            exists=False,",
            "            typeok=False,",
            "            broken_symlink=False,",
            "            access=False,",
            "            result=False,",
            "        )",
            "",
            "    unreal_path = path",
            "    path = os.path.realpath(path)",
            "",
            "    check_type = None",
            "    check_access = []",
            "",
            "    if \"check_type\" in data and data[\"check_type\"] in (\"file\", \"dir\"):",
            "        check_type = data[\"check_type\"]",
            "",
            "    if \"check_access\" in data:",
            "        request_check_access = data[\"check_access\"]",
            "        if not isinstance(request_check_access, list):",
            "            request_check_access = list(request_check_access)",
            "",
            "        check_access = [",
            "            check for check in request_check_access if check in (\"r\", \"w\", \"x\")",
            "        ]",
            "",
            "    allow_create_dir = data.get(\"allow_create_dir\", False) and check_type == \"dir\"",
            "    check_writable_dir = data.get(\"check_writable_dir\", False) and check_type == \"dir\"",
            "    if check_writable_dir and \"w\" not in check_access:",
            "        check_access.append(\"w\")",
            "",
            "    # check if path exists",
            "    exists = os.path.exists(path)",
            "    if not exists:",
            "        if os.path.islink(unreal_path):",
            "            # broken symlink, see #2644",
            "            logging.getLogger(__name__).error(",
            "                \"{} is a broken symlink pointing at non existing {}\".format(",
            "                    unreal_path, path",
            "                )",
            "            )",
            "            return jsonify(",
            "                path=unreal_path,",
            "                exists=False,",
            "                typeok=False,",
            "                broken_symlink=True,",
            "                access=False,",
            "                result=False,",
            "            )",
            "",
            "        elif check_type == \"dir\" and allow_create_dir:",
            "            try:",
            "                os.makedirs(path)",
            "            except Exception:",
            "                logging.getLogger(__name__).exception(",
            "                    f\"Error while trying to create {path}\"",
            "                )",
            "                return jsonify(",
            "                    path=path,",
            "                    exists=False,",
            "                    typeok=False,",
            "                    broken_symlink=False,",
            "                    access=False,",
            "                    result=False,",
            "                )",
            "            else:",
            "                exists = True",
            "",
            "    # check path type",
            "    type_mapping = {\"file\": os.path.isfile, \"dir\": os.path.isdir}",
            "    if check_type:",
            "        typeok = type_mapping[check_type](path)",
            "    else:",
            "        typeok = exists",
            "",
            "    # check if path allows requested access",
            "    access_mapping = {\"r\": os.R_OK, \"w\": os.W_OK, \"x\": os.X_OK}",
            "    if check_access:",
            "        mode = 0",
            "        for a in map(lambda x: access_mapping[x], check_access):",
            "            mode |= a",
            "        access = os.access(path, mode)",
            "    else:",
            "        access = exists",
            "",
            "    if check_writable_dir and check_type == \"dir\":",
            "        try:",
            "            test_path = os.path.join(path, \".testballoon.txt\")",
            "            with open(test_path, \"wb\") as f:",
            "                f.write(b\"Test\")",
            "            os.remove(test_path)",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                f\"Error while testing if {path} is really writable\"",
            "            )",
            "            return jsonify(",
            "                path=path,",
            "                exists=exists,",
            "                typeok=typeok,",
            "                broken_symlink=False,",
            "                access=False,",
            "                result=False,",
            "            )",
            "",
            "    return jsonify(",
            "        path=path,",
            "        exists=exists,",
            "        typeok=typeok,",
            "        broken_symlink=False,",
            "        access=access,",
            "        result=exists and typeok and access,",
            "    )",
            "",
            "",
            "def _test_url(data):",
            "    import requests",
            "",
            "    from octoprint import util as util",
            "",
            "    class StatusCodeRange:",
            "        def __init__(self, start=None, end=None):",
            "            self.start = start",
            "            self.end = end",
            "",
            "        def __contains__(self, item):",
            "            if not isinstance(item, int):",
            "                return False",
            "            if self.start and self.end:",
            "                return self.start <= item < self.end",
            "            elif self.start:",
            "                return self.start <= item",
            "            elif self.end:",
            "                return item < self.end",
            "            else:",
            "                return False",
            "",
            "        def as_dict(self):",
            "            return {\"start\": self.start, \"end\": self.end}",
            "",
            "    status_ranges = {",
            "        \"informational\": StatusCodeRange(start=100, end=200),",
            "        \"success\": StatusCodeRange(start=200, end=300),",
            "        \"redirection\": StatusCodeRange(start=300, end=400),",
            "        \"client_error\": StatusCodeRange(start=400, end=500),",
            "        \"server_error\": StatusCodeRange(start=500, end=600),",
            "        \"normal\": StatusCodeRange(end=400),",
            "        \"error\": StatusCodeRange(start=400, end=600),",
            "        \"any\": StatusCodeRange(start=100),",
            "        \"timeout\": StatusCodeRange(start=0, end=1),",
            "    }",
            "",
            "    url = data[\"url\"]",
            "    method = data.get(\"method\", \"HEAD\")",
            "    timeout = 3.0",
            "    valid_ssl = True",
            "    check_status = [status_ranges[\"normal\"]]",
            "    content_type_whitelist = None",
            "    content_type_blacklist = None",
            "",
            "    if \"timeout\" in data:",
            "        try:",
            "            timeout = float(data[\"timeout\"])",
            "        except Exception:",
            "            abort(400, description=\"timeout is invalid\")",
            "",
            "    if \"validSsl\" in data:",
            "        valid_ssl = data[\"validSsl\"] in valid_boolean_trues",
            "",
            "    if \"status\" in data:",
            "        request_status = data[\"status\"]",
            "        if not isinstance(request_status, list):",
            "            request_status = [request_status]",
            "",
            "        check_status = []",
            "        for rs in request_status:",
            "            if isinstance(rs, int):",
            "                check_status.append([rs])",
            "            else:",
            "                if rs in status_ranges:",
            "                    check_status.append(status_ranges[rs])",
            "                else:",
            "                    code = requests.codes[rs]",
            "                    if code is not None:",
            "                        check_status.append([code])",
            "",
            "    if \"content_type_whitelist\" in data:",
            "        if not isinstance(data[\"content_type_whitelist\"], (list, tuple)):",
            "            abort(400, description=\"content_type_whitelist must be a list of mime types\")",
            "        content_type_whitelist = list(",
            "            map(util.parse_mime_type, data[\"content_type_whitelist\"])",
            "        )",
            "    if \"content_type_blacklist\" in data:",
            "        if not isinstance(data[\"content_type_whitelist\"], (list, tuple)):",
            "            abort(400, description=\"content_type_blacklist must be a list of mime types\")",
            "        content_type_blacklist = list(",
            "            map(util.parse_mime_type, data[\"content_type_blacklist\"])",
            "        )",
            "",
            "    response_result = None",
            "    outcome = True",
            "    status = 0",
            "    try:",
            "        with requests.request(",
            "            method=method, url=url, timeout=timeout, verify=valid_ssl, stream=True",
            "        ) as response:",
            "            status = response.status_code",
            "            outcome = outcome and any(map(lambda x: status in x, check_status))",
            "            content_type = response.headers.get(\"content-type\")",
            "",
            "            response_result = {",
            "                \"headers\": dict(response.headers),",
            "                \"content_type\": content_type,",
            "            }",
            "",
            "            if not content_type and data.get(\"content_type_guess\") in valid_boolean_trues:",
            "                content = response.content",
            "                content_type = util.guess_mime_type(bytearray(content))",
            "",
            "            if not content_type:",
            "                content_type = \"application/octet-stream\"",
            "",
            "            response_result = {\"assumed_content_type\": content_type}",
            "",
            "            parsed_content_type = util.parse_mime_type(content_type)",
            "",
            "            in_whitelist = content_type_whitelist is None or any(",
            "                map(",
            "                    lambda x: util.mime_type_matches(parsed_content_type, x),",
            "                    content_type_whitelist,",
            "                )",
            "            )",
            "            in_blacklist = content_type_blacklist is not None and any(",
            "                map(",
            "                    lambda x: util.mime_type_matches(parsed_content_type, x),",
            "                    content_type_blacklist,",
            "                )",
            "            )",
            "",
            "            if not in_whitelist or in_blacklist:",
            "                # we don't support this content type",
            "                response.close()",
            "                outcome = False",
            "",
            "            elif \"response\" in data and (",
            "                data[\"response\"] in valid_boolean_trues",
            "                or data[\"response\"] in (\"json\", \"bytes\")",
            "            ):",
            "                if data[\"response\"] == \"json\":",
            "                    content = response.json()",
            "",
            "                else:",
            "                    import base64",
            "",
            "                    content = base64.standard_b64encode(response.content)",
            "",
            "                response_result[\"content\"] = content",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(",
            "            f\"Error while running a test {method} request on {url}\"",
            "        )",
            "        outcome = False",
            "",
            "    result = {\"url\": url, \"status\": status, \"result\": outcome}",
            "    if response_result:",
            "        result[\"response\"] = response_result",
            "",
            "    return jsonify(**result)",
            "",
            "",
            "def _test_server(data):",
            "    host = data[\"host\"]",
            "    try:",
            "        port = int(data[\"port\"])",
            "    except Exception:",
            "        abort(400, description=\"Invalid value for port\")",
            "",
            "    timeout = 3.05",
            "    if \"timeout\" in data:",
            "        try:",
            "            timeout = float(data[\"timeout\"])",
            "        except Exception:",
            "            abort(400, description=\"Invalid value for timeout\")",
            "",
            "    protocol = data.get(\"protocol\", \"tcp\")",
            "    if protocol not in (\"tcp\", \"udp\"):",
            "        abort(400, description=\"Invalid value for protocol\")",
            "",
            "    from octoprint.util import server_reachable",
            "",
            "    reachable = server_reachable(host, port, timeout=timeout, proto=protocol)",
            "",
            "    result = {\"host\": host, \"port\": port, \"protocol\": protocol, \"result\": reachable}",
            "",
            "    return jsonify(**result)",
            "",
            "",
            "def _test_resolution(data):",
            "    name = data[\"name\"]",
            "",
            "    from octoprint.util.net import resolve_host",
            "",
            "    resolvable = len(resolve_host(name)) > 0",
            "",
            "    result = {\"name\": name, \"result\": resolvable}",
            "",
            "    return jsonify(**result)",
            "",
            "",
            "def _test_address(data):",
            "    import netaddr",
            "",
            "    from octoprint.util.net import get_lan_ranges, sanitize_address",
            "",
            "    remote_addr = data.get(\"address\")",
            "    if not remote_addr:",
            "        remote_addr = request.remote_addr",
            "",
            "    remote_addr = sanitize_address(remote_addr)",
            "    ip = netaddr.IPAddress(remote_addr)",
            "",
            "    lan_subnets = get_lan_ranges()",
            "",
            "    detected_subnet = None",
            "    for subnet in lan_subnets:",
            "        if ip in subnet:",
            "            detected_subnet = subnet",
            "            break",
            "",
            "    result = {",
            "        \"is_lan_address\": detected_subnet is not None,",
            "        \"address\": remote_addr,",
            "    }",
            "",
            "    if detected_subnet is not None:",
            "        result[\"subnet\"] = str(detected_subnet)",
            "",
            "    return jsonify(**result)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "41": [],
            "305": [
                "login"
            ],
            "401": [
                "logout"
            ],
            "777": [
                "_test_address"
            ]
        },
        "addLocation": []
    },
    "src/octoprint/server/api/settings.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 125,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "     data = {"
            },
            "2": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 127,
                "PatchRowcode": "         \"api\": {"
            },
            "3": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"key\": s.get([\"api\", \"key\"])"
            },
            "4": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if Permissions.ADMIN.can() and credentials_checked_recently()"
            },
            "5": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            else None,"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+            \"key\": ("
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+                s.get([\"api\", \"key\"])"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+                if Permissions.ADMIN.can() and credentials_checked_recently()"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+                else None"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+            ),"
            },
            "11": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "             \"allowCrossOrigin\": s.get([\"api\", \"allowCrossOrigin\"]),"
            },
            "12": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "         },"
            },
            "13": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "         \"appearance\": {"
            },
            "14": {
                "beforePatchRowNumber": 410,
                "afterPatchRowNumber": 412,
                "PatchRowcode": "     else:"
            },
            "15": {
                "beforePatchRowNumber": 411,
                "afterPatchRowNumber": 413,
                "PatchRowcode": "         data[\"webcam\"] = {}"
            },
            "16": {
                "beforePatchRowNumber": 412,
                "afterPatchRowNumber": 414,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 415,
                "PatchRowcode": "+    if Permissions.ADMIN.can():"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 416,
                "PatchRowcode": "+        data[\"accessControl\"] = {"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 417,
                "PatchRowcode": "+            \"autologinLocal\": s.getBoolean([\"accessControl\", \"autologinLocal\"]),"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 418,
                "PatchRowcode": "+            \"autologinHeadsupAcknowledged\": s.getBoolean("
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 419,
                "PatchRowcode": "+                [\"accessControl\", \"autologinHeadsupAcknowledged\"]"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 420,
                "PatchRowcode": "+            ),"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 421,
                "PatchRowcode": "+        }"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 422,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": 413,
                "afterPatchRowNumber": 423,
                "PatchRowcode": "     return jsonify(data)"
            },
            "26": {
                "beforePatchRowNumber": 414,
                "afterPatchRowNumber": 424,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 415,
                "afterPatchRowNumber": 425,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 557,
                "afterPatchRowNumber": 567,
                "PatchRowcode": "         if \"allowCrossOrigin\" in data[\"api\"]:"
            },
            "29": {
                "beforePatchRowNumber": 558,
                "afterPatchRowNumber": 568,
                "PatchRowcode": "             s.setBoolean([\"api\", \"allowCrossOrigin\"], data[\"api\"][\"allowCrossOrigin\"])"
            },
            "30": {
                "beforePatchRowNumber": 559,
                "afterPatchRowNumber": 569,
                "PatchRowcode": " "
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 570,
                "PatchRowcode": "+    if \"accessControl\" in data:"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 571,
                "PatchRowcode": "+        if \"autologinHeadsupAcknowledged\" in data[\"accessControl\"]:"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 572,
                "PatchRowcode": "+            s.setBoolean("
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 573,
                "PatchRowcode": "+                [\"accessControl\", \"autologinHeadsupAcknowledged\"],"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 574,
                "PatchRowcode": "+                data[\"accessControl\"][\"autologinHeadsupAcknowledged\"],"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 575,
                "PatchRowcode": "+            )"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 576,
                "PatchRowcode": "+"
            },
            "38": {
                "beforePatchRowNumber": 560,
                "afterPatchRowNumber": 577,
                "PatchRowcode": "     if \"appearance\" in data:"
            },
            "39": {
                "beforePatchRowNumber": 561,
                "afterPatchRowNumber": 578,
                "PatchRowcode": "         if \"name\" in data[\"appearance\"]:"
            },
            "40": {
                "beforePatchRowNumber": 562,
                "afterPatchRowNumber": 579,
                "PatchRowcode": "             s.set([\"appearance\", \"name\"], data[\"appearance\"][\"name\"])"
            }
        },
        "frontPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import logging",
            "import re",
            "",
            "from flask import abort, jsonify, request",
            "from flask_login import current_user",
            "",
            "import octoprint.plugin",
            "import octoprint.util",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.server import pluginManager, printer, userManager",
            "from octoprint.server.api import NO_CONTENT, api",
            "from octoprint.server.util.flask import (",
            "    credentials_checked_recently,",
            "    no_firstrun_access,",
            "    with_revalidation_checking,",
            ")",
            "from octoprint.settings import settings, valid_boolean_trues",
            "from octoprint.timelapse import configure_timelapse",
            "from octoprint.webcams import (",
            "    get_default_webcam,",
            "    get_snapshot_webcam,",
            "    get_webcams_as_dicts,",
            ")",
            "",
            "# ~~ settings",
            "",
            "FOLDER_TYPES = (\"uploads\", \"timelapse\", \"watched\")",
            "TIMELAPSE_BITRATE_PATTERN = re.compile(r\"\\d+[KMGTPEZY]?i?B?\", flags=re.IGNORECASE)",
            "DEPRECATED_WEBCAM_KEYS = (",
            "    \"streamUrl\",",
            "    \"streamRatio\",",
            "    \"streamTimeout\",",
            "    \"streamWebrtcIceServers\",",
            "    \"snapshotUrl\",",
            "    \"snapshotTimeout\",",
            "    \"snapshotSslValidation\",",
            "    \"cacheBuster\",",
            "    \"flipH\",",
            "    \"flipV\",",
            "    \"rotate90\",",
            ")",
            "",
            "",
            "def _lastmodified():",
            "    return settings().last_modified",
            "",
            "",
            "def _etag(lm=None):",
            "    if lm is None:",
            "        lm = _lastmodified()",
            "",
            "    connection_options = printer.__class__.get_connection_options()",
            "    plugins = sorted(octoprint.plugin.plugin_manager().enabled_plugins)",
            "    plugin_settings = _get_plugin_settings()",
            "",
            "    from collections import OrderedDict",
            "",
            "    sorted_plugin_settings = OrderedDict()",
            "    for key in sorted(plugin_settings.keys()):",
            "        sorted_plugin_settings[key] = plugin_settings.get(key, {})",
            "",
            "    if current_user is not None and not current_user.is_anonymous:",
            "        roles = sorted(current_user.permissions, key=lambda x: x.key)",
            "    else:",
            "        roles = []",
            "",
            "    import hashlib",
            "",
            "    hash = hashlib.sha1()",
            "",
            "    def hash_update(value):",
            "        value = value.encode(\"utf-8\")",
            "        hash.update(value)",
            "",
            "    # last modified timestamp",
            "    hash_update(str(lm))",
            "",
            "    # effective config from config.yaml + overlays",
            "    hash_update(repr(settings().effective))",
            "",
            "    # might duplicate settings().effective, but plugins might also inject additional keys into the settings",
            "    # output that are not stored in config.yaml",
            "    hash_update(repr(sorted_plugin_settings))",
            "",
            "    # connection options are also part of the settings",
            "    hash_update(repr(connection_options))",
            "",
            "    # if the list of plugins changes, the settings structure changes too",
            "    hash_update(repr(plugins))",
            "",
            "    # and likewise if the role of the user changes",
            "    hash_update(repr(roles))",
            "",
            "    # of if the user reauthenticates",
            "    hash_update(repr(credentials_checked_recently()))",
            "",
            "    return hash.hexdigest()",
            "",
            "",
            "@api.route(\"/settings\", methods=[\"GET\"])",
            "@with_revalidation_checking(",
            "    etag_factory=_etag,",
            "    lastmodified_factory=_lastmodified,",
            "    unless=lambda: request.values.get(\"force\", \"false\") in valid_boolean_trues",
            "    or settings().getBoolean([\"server\", \"firstRun\"])",
            "    or not userManager.has_been_customized(),",
            ")",
            "def getSettings():",
            "    if not Permissions.SETTINGS_READ.can() and not (",
            "        settings().getBoolean([\"server\", \"firstRun\"])",
            "        or not userManager.has_been_customized()",
            "    ):",
            "        abort(403)",
            "",
            "    s = settings()",
            "",
            "    connectionOptions = printer.__class__.get_connection_options()",
            "",
            "    # NOTE: Remember to adjust the docs of the data model on the Settings API if anything",
            "    # is changed, added or removed here",
            "",
            "    data = {",
            "        \"api\": {",
            "            \"key\": s.get([\"api\", \"key\"])",
            "            if Permissions.ADMIN.can() and credentials_checked_recently()",
            "            else None,",
            "            \"allowCrossOrigin\": s.get([\"api\", \"allowCrossOrigin\"]),",
            "        },",
            "        \"appearance\": {",
            "            \"name\": s.get([\"appearance\", \"name\"]),",
            "            \"color\": s.get([\"appearance\", \"color\"]),",
            "            \"colorTransparent\": s.getBoolean([\"appearance\", \"colorTransparent\"]),",
            "            \"colorIcon\": s.getBoolean([\"appearance\", \"colorIcon\"]),",
            "            \"defaultLanguage\": s.get([\"appearance\", \"defaultLanguage\"]),",
            "            \"showFahrenheitAlso\": s.getBoolean([\"appearance\", \"showFahrenheitAlso\"]),",
            "            \"fuzzyTimes\": s.getBoolean([\"appearance\", \"fuzzyTimes\"]),",
            "            \"closeModalsWithClick\": s.getBoolean([\"appearance\", \"closeModalsWithClick\"]),",
            "            \"showInternalFilename\": s.getBoolean([\"appearance\", \"showInternalFilename\"]),",
            "        },",
            "        \"feature\": {",
            "            \"temperatureGraph\": s.getBoolean([\"feature\", \"temperatureGraph\"]),",
            "            \"sdSupport\": s.getBoolean([\"feature\", \"sdSupport\"]),",
            "            \"keyboardControl\": s.getBoolean([\"feature\", \"keyboardControl\"]),",
            "            \"pollWatched\": s.getBoolean([\"feature\", \"pollWatched\"]),",
            "            \"modelSizeDetection\": s.getBoolean([\"feature\", \"modelSizeDetection\"]),",
            "            \"rememberFileFolder\": s.getBoolean([\"feature\", \"rememberFileFolder\"]),",
            "            \"printStartConfirmation\": s.getBoolean([\"feature\", \"printStartConfirmation\"]),",
            "            \"printCancelConfirmation\": s.getBoolean(",
            "                [\"feature\", \"printCancelConfirmation\"]",
            "            ),",
            "            \"uploadOverwriteConfirmation\": s.getBoolean(",
            "                [\"feature\", \"uploadOverwriteConfirmation\"]",
            "            ),",
            "            \"g90InfluencesExtruder\": s.getBoolean([\"feature\", \"g90InfluencesExtruder\"]),",
            "            \"autoUppercaseBlacklist\": s.get([\"feature\", \"autoUppercaseBlacklist\"]),",
            "            \"enableDragDropUpload\": s.getBoolean([\"feature\", \"enableDragDropUpload\"]),",
            "        },",
            "        \"gcodeAnalysis\": {",
            "            \"runAt\": s.get([\"gcodeAnalysis\", \"runAt\"]),",
            "            \"bedZ\": s.getFloat([\"gcodeAnalysis\", \"bedZ\"]),",
            "        },",
            "        \"serial\": {",
            "            \"port\": connectionOptions[\"portPreference\"],",
            "            \"baudrate\": connectionOptions[\"baudratePreference\"],",
            "            \"exclusive\": s.getBoolean([\"serial\", \"exclusive\"]),",
            "            \"lowLatency\": s.getBoolean([\"serial\", \"lowLatency\"]),",
            "            \"portOptions\": connectionOptions[\"ports\"],",
            "            \"baudrateOptions\": connectionOptions[\"baudrates\"],",
            "            \"autoconnect\": s.getBoolean([\"serial\", \"autoconnect\"]),",
            "            \"timeoutConnection\": s.getFloat([\"serial\", \"timeout\", \"connection\"]),",
            "            \"timeoutDetectionFirst\": s.getFloat([\"serial\", \"timeout\", \"detectionFirst\"]),",
            "            \"timeoutDetectionConsecutive\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"detectionConsecutive\"]",
            "            ),",
            "            \"timeoutCommunication\": s.getFloat([\"serial\", \"timeout\", \"communication\"]),",
            "            \"timeoutCommunicationBusy\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"communicationBusy\"]",
            "            ),",
            "            \"timeoutTemperature\": s.getFloat([\"serial\", \"timeout\", \"temperature\"]),",
            "            \"timeoutTemperatureTargetSet\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"temperatureTargetSet\"]",
            "            ),",
            "            \"timeoutTemperatureAutoreport\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"temperatureAutoreport\"]",
            "            ),",
            "            \"timeoutSdStatus\": s.getFloat([\"serial\", \"timeout\", \"sdStatus\"]),",
            "            \"timeoutSdStatusAutoreport\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"sdStatusAutoreport\"]",
            "            ),",
            "            \"timeoutPosAutoreport\": s.getFloat([\"serial\", \"timeout\", \"posAutoreport\"]),",
            "            \"timeoutBaudrateDetectionPause\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"baudrateDetectionPause\"]",
            "            ),",
            "            \"timeoutPositionLogWait\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"positionLogWait\"]",
            "            ),",
            "            \"log\": s.getBoolean([\"serial\", \"log\"]),",
            "            \"additionalPorts\": s.get([\"serial\", \"additionalPorts\"]),",
            "            \"additionalBaudrates\": s.get([\"serial\", \"additionalBaudrates\"]),",
            "            \"blacklistedPorts\": s.get([\"serial\", \"blacklistedPorts\"]),",
            "            \"blacklistedBaudrates\": s.get([\"serial\", \"blacklistedBaudrates\"]),",
            "            \"longRunningCommands\": s.get([\"serial\", \"longRunningCommands\"]),",
            "            \"checksumRequiringCommands\": s.get([\"serial\", \"checksumRequiringCommands\"]),",
            "            \"blockedCommands\": s.get([\"serial\", \"blockedCommands\"]),",
            "            \"ignoredCommands\": s.get([\"serial\", \"ignoredCommands\"]),",
            "            \"pausingCommands\": s.get([\"serial\", \"pausingCommands\"]),",
            "            \"sdCancelCommand\": s.get([\"serial\", \"sdCancelCommand\"]),",
            "            \"emergencyCommands\": s.get([\"serial\", \"emergencyCommands\"]),",
            "            \"helloCommand\": s.get([\"serial\", \"helloCommand\"]),",
            "            \"ignoreErrorsFromFirmware\": s.getBoolean(",
            "                [\"serial\", \"ignoreErrorsFromFirmware\"]",
            "            ),",
            "            \"disconnectOnErrors\": s.getBoolean([\"serial\", \"disconnectOnErrors\"]),",
            "            \"triggerOkForM29\": s.getBoolean([\"serial\", \"triggerOkForM29\"]),",
            "            \"logPositionOnPause\": s.getBoolean([\"serial\", \"logPositionOnPause\"]),",
            "            \"logPositionOnCancel\": s.getBoolean([\"serial\", \"logPositionOnCancel\"]),",
            "            \"abortHeatupOnCancel\": s.getBoolean([\"serial\", \"abortHeatupOnCancel\"]),",
            "            \"supportResendsWithoutOk\": s.get([\"serial\", \"supportResendsWithoutOk\"]),",
            "            \"waitForStart\": s.getBoolean([\"serial\", \"waitForStartOnConnect\"]),",
            "            \"waitToLoadSdFileList\": s.getBoolean([\"serial\", \"waitToLoadSdFileList\"]),",
            "            \"alwaysSendChecksum\": s.getBoolean([\"serial\", \"alwaysSendChecksum\"]),",
            "            \"neverSendChecksum\": s.getBoolean([\"serial\", \"neverSendChecksum\"]),",
            "            \"sendChecksumWithUnknownCommands\": s.getBoolean(",
            "                [\"serial\", \"sendChecksumWithUnknownCommands\"]",
            "            ),",
            "            \"unknownCommandsNeedAck\": s.getBoolean([\"serial\", \"unknownCommandsNeedAck\"]),",
            "            \"sdRelativePath\": s.getBoolean([\"serial\", \"sdRelativePath\"]),",
            "            \"sdAlwaysAvailable\": s.getBoolean([\"serial\", \"sdAlwaysAvailable\"]),",
            "            \"sdLowerCase\": s.getBoolean([\"serial\", \"sdLowerCase\"]),",
            "            \"swallowOkAfterResend\": s.getBoolean([\"serial\", \"swallowOkAfterResend\"]),",
            "            \"repetierTargetTemp\": s.getBoolean([\"serial\", \"repetierTargetTemp\"]),",
            "            \"externalHeatupDetection\": s.getBoolean(",
            "                [\"serial\", \"externalHeatupDetection\"]",
            "            ),",
            "            \"ignoreIdenticalResends\": s.getBoolean([\"serial\", \"ignoreIdenticalResends\"]),",
            "            \"firmwareDetection\": s.getBoolean([\"serial\", \"firmwareDetection\"]),",
            "            \"blockWhileDwelling\": s.getBoolean([\"serial\", \"blockWhileDwelling\"]),",
            "            \"useParityWorkaround\": s.get([\"serial\", \"useParityWorkaround\"]),",
            "            \"sanityCheckTools\": s.getBoolean([\"serial\", \"sanityCheckTools\"]),",
            "            \"notifySuppressedCommands\": s.get([\"serial\", \"notifySuppressedCommands\"]),",
            "            \"sendM112OnError\": s.getBoolean([\"serial\", \"sendM112OnError\"]),",
            "            \"disableSdPrintingDetection\": s.getBoolean(",
            "                [\"serial\", \"disableSdPrintingDetection\"]",
            "            ),",
            "            \"ackMax\": s.getInt([\"serial\", \"ackMax\"]),",
            "            \"maxTimeoutsIdle\": s.getInt([\"serial\", \"maxCommunicationTimeouts\", \"idle\"]),",
            "            \"maxTimeoutsPrinting\": s.getInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"printing\"]",
            "            ),",
            "            \"maxTimeoutsLong\": s.getInt([\"serial\", \"maxCommunicationTimeouts\", \"long\"]),",
            "            \"capAutoreportTemp\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_temp\"]",
            "            ),",
            "            \"capAutoreportSdStatus\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_sdstatus\"]",
            "            ),",
            "            \"capAutoreportPos\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_pos\"]",
            "            ),",
            "            \"capBusyProtocol\": s.getBoolean([\"serial\", \"capabilities\", \"busy_protocol\"]),",
            "            \"capEmergencyParser\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"emergency_parser\"]",
            "            ),",
            "            \"capExtendedM20\": s.getBoolean([\"serial\", \"capabilities\", \"extended_m20\"]),",
            "            \"capLfnWrite\": s.getBoolean([\"serial\", \"capabilities\", \"lfn_write\"]),",
            "            \"resendRatioThreshold\": s.getInt([\"serial\", \"resendRatioThreshold\"]),",
            "            \"resendRatioStart\": s.getInt([\"serial\", \"resendRatioStart\"]),",
            "            \"ignoreEmptyPorts\": s.getBoolean([\"serial\", \"ignoreEmptyPorts\"]),",
            "            \"encoding\": s.get([\"serial\", \"encoding\"]),",
            "            \"enableShutdownActionCommand\": s.get(",
            "                [\"serial\", \"enableShutdownActionCommand\"]",
            "            ),",
            "        },",
            "        \"folder\": {",
            "            \"uploads\": s.getBaseFolder(\"uploads\"),",
            "            \"timelapse\": s.getBaseFolder(\"timelapse\"),",
            "            \"watched\": s.getBaseFolder(\"watched\"),",
            "        },",
            "        \"temperature\": {",
            "            \"profiles\": s.get([\"temperature\", \"profiles\"]),",
            "            \"cutoff\": s.getInt([\"temperature\", \"cutoff\"]),",
            "            \"sendAutomatically\": s.getBoolean([\"temperature\", \"sendAutomatically\"]),",
            "            \"sendAutomaticallyAfter\": s.getInt(",
            "                [\"temperature\", \"sendAutomaticallyAfter\"], min=0, max=30",
            "            ),",
            "        },",
            "        \"system\": {",
            "            \"actions\": s.get([\"system\", \"actions\"]),",
            "            \"events\": s.get([\"system\", \"events\"]),",
            "        },",
            "        \"terminalFilters\": s.get([\"terminalFilters\"]),",
            "        \"scripts\": {",
            "            \"gcode\": {",
            "                \"afterPrinterConnected\": None,",
            "                \"beforePrinterDisconnected\": None,",
            "                \"beforePrintStarted\": None,",
            "                \"afterPrintCancelled\": None,",
            "                \"afterPrintDone\": None,",
            "                \"beforePrintPaused\": None,",
            "                \"afterPrintResumed\": None,",
            "                \"beforeToolChange\": None,",
            "                \"afterToolChange\": None,",
            "                \"snippets\": {},",
            "            }",
            "        },",
            "        \"server\": {",
            "            \"commands\": {",
            "                \"systemShutdownCommand\": s.get(",
            "                    [\"server\", \"commands\", \"systemShutdownCommand\"]",
            "                ),",
            "                \"systemRestartCommand\": s.get(",
            "                    [\"server\", \"commands\", \"systemRestartCommand\"]",
            "                ),",
            "                \"serverRestartCommand\": s.get(",
            "                    [\"server\", \"commands\", \"serverRestartCommand\"]",
            "                ),",
            "            },",
            "            \"diskspace\": {",
            "                \"warning\": s.getInt([\"server\", \"diskspace\", \"warning\"]),",
            "                \"critical\": s.getInt([\"server\", \"diskspace\", \"critical\"]),",
            "            },",
            "            \"onlineCheck\": {",
            "                \"enabled\": s.getBoolean([\"server\", \"onlineCheck\", \"enabled\"]),",
            "                \"interval\": int(s.getInt([\"server\", \"onlineCheck\", \"interval\"]) / 60),",
            "                \"host\": s.get([\"server\", \"onlineCheck\", \"host\"]),",
            "                \"port\": s.getInt([\"server\", \"onlineCheck\", \"port\"]),",
            "                \"name\": s.get([\"server\", \"onlineCheck\", \"name\"]),",
            "            },",
            "            \"pluginBlacklist\": {",
            "                \"enabled\": s.getBoolean([\"server\", \"pluginBlacklist\", \"enabled\"]),",
            "                \"url\": s.get([\"server\", \"pluginBlacklist\", \"url\"]),",
            "                \"ttl\": int(s.getInt([\"server\", \"pluginBlacklist\", \"ttl\"]) / 60),",
            "            },",
            "            \"allowFraming\": s.getBoolean([\"server\", \"allowFraming\"]),",
            "        },",
            "        \"devel\": {\"pluginTimings\": s.getBoolean([\"devel\", \"pluginTimings\"])},",
            "        \"slicing\": {\"defaultSlicer\": s.get([\"slicing\", \"defaultSlicer\"])},",
            "    }",
            "",
            "    gcode_scripts = s.listScripts(\"gcode\")",
            "    if gcode_scripts:",
            "        data[\"scripts\"] = {\"gcode\": {}}",
            "        for name in gcode_scripts:",
            "            data[\"scripts\"][\"gcode\"][name] = s.loadScript(\"gcode\", name, source=True)",
            "",
            "    plugin_settings = _get_plugin_settings()",
            "    if len(plugin_settings):",
            "        data[\"plugins\"] = plugin_settings",
            "",
            "    if Permissions.WEBCAM.can() or (",
            "        settings().getBoolean([\"server\", \"firstRun\"])",
            "        and not userManager.has_been_customized()",
            "    ):",
            "        webcamsDict = get_webcams_as_dicts()",
            "        data[\"webcam\"] = {",
            "            \"webcamEnabled\": s.getBoolean([\"webcam\", \"webcamEnabled\"]),",
            "            \"timelapseEnabled\": s.getBoolean([\"webcam\", \"timelapseEnabled\"]),",
            "            \"ffmpegPath\": s.get([\"webcam\", \"ffmpeg\"]),",
            "            \"ffmpegCommandline\": s.get([\"webcam\", \"ffmpegCommandline\"]),",
            "            \"bitrate\": s.get([\"webcam\", \"bitrate\"]),",
            "            \"ffmpegThreads\": s.get([\"webcam\", \"ffmpegThreads\"]),",
            "            \"ffmpegVideoCodec\": s.get([\"webcam\", \"ffmpegVideoCodec\"]),",
            "            \"watermark\": s.getBoolean([\"webcam\", \"watermark\"]),",
            "            # webcams & defaults",
            "            \"webcams\": webcamsDict,",
            "            \"defaultWebcam\": None,",
            "            \"snapshotWebcam\": None,",
            "        }",
            "",
            "        for key in DEPRECATED_WEBCAM_KEYS:",
            "            data[\"webcam\"][key] = None",
            "",
            "        defaultWebcam = get_default_webcam()",
            "        if defaultWebcam:",
            "            data[\"webcam\"].update(",
            "                {",
            "                    \"flipH\": defaultWebcam.config.flipH,",
            "                    \"flipV\": defaultWebcam.config.flipV,",
            "                    \"rotate90\": defaultWebcam.config.rotate90,",
            "                    \"defaultWebcam\": defaultWebcam.config.name,",
            "                }",
            "            )",
            "",
            "        compatWebcam = defaultWebcam.config.compat if defaultWebcam is not None else None",
            "        if compatWebcam:",
            "            data[\"webcam\"].update(",
            "                {",
            "                    \"streamUrl\": compatWebcam.stream,",
            "                    \"streamRatio\": compatWebcam.streamRatio,",
            "                    \"streamTimeout\": compatWebcam.streamTimeout,",
            "                    \"streamWebrtcIceServers\": compatWebcam.streamWebrtcIceServers,",
            "                    \"snapshotUrl\": compatWebcam.snapshot,",
            "                    \"snapshotTimeout\": compatWebcam.snapshotTimeout,",
            "                    \"snapshotSslValidation\": compatWebcam.snapshotSslValidation,",
            "                    \"cacheBuster\": compatWebcam.cacheBuster,",
            "                }",
            "            )",
            "",
            "        snapshotWebcam = get_snapshot_webcam()",
            "        if snapshotWebcam:",
            "            data[\"webcam\"].update(",
            "                {",
            "                    \"snapshotWebcam\": snapshotWebcam.config.name,",
            "                }",
            "            )",
            "    else:",
            "        data[\"webcam\"] = {}",
            "",
            "    return jsonify(data)",
            "",
            "",
            "def _get_plugin_settings():",
            "    logger = logging.getLogger(__name__)",
            "",
            "    data = {}",
            "",
            "    def process_plugin_result(name, result):",
            "        if result:",
            "            try:",
            "                jsonify(test=result)",
            "            except Exception:",
            "                logger.exception(",
            "                    \"Error while jsonifying settings from plugin {}, please contact the plugin author about this\".format(",
            "                        name",
            "                    )",
            "                )",
            "                raise",
            "            else:",
            "                if \"__enabled\" in result:",
            "                    del result[\"__enabled\"]",
            "                data[name] = result",
            "",
            "    for plugin in octoprint.plugin.plugin_manager().get_implementations(",
            "        octoprint.plugin.SettingsPlugin",
            "    ):",
            "        try:",
            "            result = plugin.on_settings_load()",
            "            process_plugin_result(plugin._identifier, result)",
            "        except Exception:",
            "            logger.exception(",
            "                \"Could not load settings for plugin {name} ({version})\".format(",
            "                    version=plugin._plugin_version, name=plugin._plugin_name",
            "                ),",
            "                extra={\"plugin\": plugin._identifier},",
            "            )",
            "",
            "    return data",
            "",
            "",
            "@api.route(\"/settings\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.SETTINGS.require(403)",
            "def setSettings():",
            "    data = request.get_json()",
            "    if not isinstance(data, dict):",
            "        abort(400, description=\"Malformed JSON body in request\")",
            "",
            "    response = _saveSettings(data)",
            "    if response:",
            "        return response",
            "    return getSettings()",
            "",
            "",
            "@api.route(\"/settings/apikey\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.ADMIN.require(403)",
            "def generateApiKey():",
            "    apikey = settings().generateApiKey()",
            "    return jsonify(apikey=apikey)",
            "",
            "",
            "@api.route(\"/settings/apikey\", methods=[\"DELETE\"])",
            "@no_firstrun_access",
            "@Permissions.ADMIN.require(403)",
            "def deleteApiKey():",
            "    settings().deleteApiKey()",
            "    return NO_CONTENT",
            "",
            "",
            "@api.route(\"/settings/templates\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SETTINGS.require(403)",
            "def fetchTemplateData():",
            "    from octoprint.server.views import fetch_template_data",
            "",
            "    refresh = request.values.get(\"refresh\", \"false\") in valid_boolean_trues",
            "    templates, _, _ = fetch_template_data(refresh=refresh)",
            "",
            "    result = {}",
            "    for tt in templates:",
            "        result[tt] = []",
            "        for key in templates[tt][\"order\"]:",
            "            entry = templates[tt][\"entries\"].get(key)",
            "            if not entry:",
            "                continue",
            "",
            "            if isinstance(entry, dict):",
            "                name = key",
            "            else:",
            "                name, entry = entry",
            "",
            "            data = {\"id\": key, \"name\": name}",
            "",
            "            if entry and \"_plugin\" in entry:",
            "                plugin = pluginManager.get_plugin_info(",
            "                    entry[\"_plugin\"], require_enabled=False",
            "                )",
            "                data[\"plugin_id\"] = plugin.key",
            "                data[\"plugin_name\"] = plugin.name",
            "",
            "            result[tt].append(data)",
            "",
            "    return jsonify(order=result)",
            "",
            "",
            "def _saveSettings(data):",
            "    logger = logging.getLogger(__name__)",
            "",
            "    s = settings()",
            "",
            "    # NOTE: Remember to adjust the docs of the data model on the Settings API if anything",
            "    # is changed, added or removed here",
            "",
            "    if \"folder\" in data:",
            "        try:",
            "            folders = data[\"folder\"]",
            "            future = {}",
            "            for folder in FOLDER_TYPES:",
            "                future[folder] = s.getBaseFolder(folder)",
            "                if folder in folders:",
            "                    future[folder] = folders[folder]",
            "",
            "            for folder in folders:",
            "                if folder not in FOLDER_TYPES:",
            "                    continue",
            "                for other_folder in FOLDER_TYPES:",
            "                    if folder == other_folder:",
            "                        continue",
            "                    if future[folder] == future[other_folder]:",
            "                        # duplicate detected, raise",
            "                        raise ValueError(",
            "                            \"Duplicate folder path for {} and {}\".format(",
            "                                folder, other_folder",
            "                            )",
            "                        )",
            "",
            "                s.setBaseFolder(folder, future[folder])",
            "        except Exception:",
            "            logger.exception(\"Something went wrong while saving a folder path\")",
            "            abort(400, description=\"At least one of the configured folders is invalid\")",
            "",
            "    if \"api\" in data:",
            "        if \"allowCrossOrigin\" in data[\"api\"]:",
            "            s.setBoolean([\"api\", \"allowCrossOrigin\"], data[\"api\"][\"allowCrossOrigin\"])",
            "",
            "    if \"appearance\" in data:",
            "        if \"name\" in data[\"appearance\"]:",
            "            s.set([\"appearance\", \"name\"], data[\"appearance\"][\"name\"])",
            "        if \"color\" in data[\"appearance\"]:",
            "            s.set([\"appearance\", \"color\"], data[\"appearance\"][\"color\"])",
            "        if \"colorTransparent\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"colorTransparent\"], data[\"appearance\"][\"colorTransparent\"]",
            "            )",
            "        if \"colorIcon\" in data[\"appearance\"]:",
            "            s.setBoolean([\"appearance\", \"colorIcon\"], data[\"appearance\"][\"colorIcon\"])",
            "        if \"defaultLanguage\" in data[\"appearance\"]:",
            "            s.set(",
            "                [\"appearance\", \"defaultLanguage\"], data[\"appearance\"][\"defaultLanguage\"]",
            "            )",
            "        if \"showFahrenheitAlso\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"showFahrenheitAlso\"],",
            "                data[\"appearance\"][\"showFahrenheitAlso\"],",
            "            )",
            "        if \"fuzzyTimes\" in data[\"appearance\"]:",
            "            s.setBoolean([\"appearance\", \"fuzzyTimes\"], data[\"appearance\"][\"fuzzyTimes\"])",
            "        if \"closeModalsWithClick\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"closeModalsWithClick\"],",
            "                data[\"appearance\"][\"closeModalsWithClick\"],",
            "            )",
            "        if \"showInternalFilename\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"showInternalFilename\"],",
            "                data[\"appearance\"][\"showInternalFilename\"],",
            "            )",
            "",
            "    if \"printer\" in data:",
            "        if \"defaultExtrusionLength\" in data[\"printer\"]:",
            "            s.setInt(",
            "                [\"printerParameters\", \"defaultExtrusionLength\"],",
            "                data[\"printer\"][\"defaultExtrusionLength\"],",
            "            )",
            "",
            "    if \"webcam\" in data:",
            "        for key in DEPRECATED_WEBCAM_KEYS:",
            "            if key in data[\"webcam\"]:",
            "                logger.warning(",
            "                    f\"Setting webcam.{key} via the API is no longer supported, please use the individual settings of the default webcam instead.\"",
            "                )",
            "",
            "        if \"webcamEnabled\" in data[\"webcam\"]:",
            "            s.setBoolean([\"webcam\", \"webcamEnabled\"], data[\"webcam\"][\"webcamEnabled\"])",
            "        if \"timelapseEnabled\" in data[\"webcam\"]:",
            "            s.setBoolean(",
            "                [\"webcam\", \"timelapseEnabled\"], data[\"webcam\"][\"timelapseEnabled\"]",
            "            )",
            "        if \"snapshotTimeout\" in data[\"webcam\"]:",
            "            s.setInt([\"webcam\", \"snapshotTimeout\"], data[\"webcam\"][\"snapshotTimeout\"])",
            "        if \"snapshotSslValidation\" in data[\"webcam\"]:",
            "            s.setBoolean(",
            "                [\"webcam\", \"snapshotSslValidation\"],",
            "                data[\"webcam\"][\"snapshotSslValidation\"],",
            "            )",
            "        if \"ffmpegPath\" in data[\"webcam\"]:",
            "            s.set([\"webcam\", \"ffmpeg\"], data[\"webcam\"][\"ffmpegPath\"])",
            "        if \"ffmpegCommandline\" in data[\"webcam\"]:",
            "            commandline = data[\"webcam\"][\"ffmpegCommandline\"]",
            "            if not all(",
            "                map(lambda x: \"{\" + x + \"}\" in commandline, (\"ffmpeg\", \"input\", \"output\"))",
            "            ):",
            "                abort(",
            "                    400,",
            "                    description=\"Invalid webcam.ffmpegCommandline setting, lacks mandatory {ffmpeg}, {input} or {output}\",",
            "                )",
            "            try:",
            "                commandline.format(",
            "                    ffmpeg=\"ffmpeg\",",
            "                    fps=\"fps\",",
            "                    bitrate=\"bitrate\",",
            "                    threads=\"threads\",",
            "                    input=\"input\",",
            "                    output=\"output\",",
            "                    videocodec=\"videocodec\",",
            "                    containerformat=\"containerformat\",",
            "                    filters=\"filters\",",
            "                )",
            "            except Exception:",
            "                # some invalid data we'll refuse to set",
            "                logger.exception(\"Invalid webcam.ffmpegCommandline setting\")",
            "                abort(400, description=\"Invalid webcam.ffmpegCommandline setting\")",
            "            else:",
            "                s.set([\"webcam\", \"ffmpegCommandline\"], commandline)",
            "        if \"bitrate\" in data[\"webcam\"] and data[\"webcam\"][\"bitrate\"]:",
            "            bitrate = str(data[\"webcam\"][\"bitrate\"])",
            "            if not TIMELAPSE_BITRATE_PATTERN.match(bitrate):",
            "                abort(",
            "                    400,",
            "                    description=\"Invalid webcam.bitrate setting, needs to be a valid ffmpeg bitrate\",",
            "                )",
            "            s.set([\"webcam\", \"bitrate\"], bitrate)",
            "        if \"ffmpegThreads\" in data[\"webcam\"]:",
            "            s.setInt([\"webcam\", \"ffmpegThreads\"], data[\"webcam\"][\"ffmpegThreads\"])",
            "        if \"ffmpegVideoCodec\" in data[\"webcam\"] and data[\"webcam\"][",
            "            \"ffmpegVideoCodec\"",
            "        ] in (\"mpeg2video\", \"libx264\"):",
            "            s.set([\"webcam\", \"ffmpegVideoCodec\"], data[\"webcam\"][\"ffmpegVideoCodec\"])",
            "        if \"watermark\" in data[\"webcam\"]:",
            "            s.setBoolean([\"webcam\", \"watermark\"], data[\"webcam\"][\"watermark\"])",
            "        if \"defaultWebcam\" in data[\"webcam\"]:",
            "            s.set([\"webcam\", \"defaultWebcam\"], data[\"webcam\"][\"defaultWebcam\"])",
            "        if \"snapshotWebcam\" in data[\"webcam\"]:",
            "            s.set([\"webcam\", \"snapshotWebcam\"], data[\"webcam\"][\"snapshotWebcam\"])",
            "",
            "            # timelapse needs to be reconfigured now since it depends on the current snapshot webcam",
            "            configure_timelapse()",
            "",
            "    if \"feature\" in data:",
            "        if \"temperatureGraph\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"temperatureGraph\"], data[\"feature\"][\"temperatureGraph\"]",
            "            )",
            "        if \"sdSupport\" in data[\"feature\"]:",
            "            s.setBoolean([\"feature\", \"sdSupport\"], data[\"feature\"][\"sdSupport\"])",
            "        if \"keyboardControl\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"keyboardControl\"], data[\"feature\"][\"keyboardControl\"]",
            "            )",
            "        if \"pollWatched\" in data[\"feature\"]:",
            "            s.setBoolean([\"feature\", \"pollWatched\"], data[\"feature\"][\"pollWatched\"])",
            "        if \"modelSizeDetection\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"modelSizeDetection\"], data[\"feature\"][\"modelSizeDetection\"]",
            "            )",
            "        if \"rememberFileFolder\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"rememberFileFolder\"],",
            "                data[\"feature\"][\"rememberFileFolder\"],",
            "            )",
            "        if \"printStartConfirmation\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"printStartConfirmation\"],",
            "                data[\"feature\"][\"printStartConfirmation\"],",
            "            )",
            "        if \"printCancelConfirmation\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"printCancelConfirmation\"],",
            "                data[\"feature\"][\"printCancelConfirmation\"],",
            "            )",
            "        if \"uploadOverwriteConfirmation\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"uploadOverwriteConfirmation\"],",
            "                data[\"feature\"][\"uploadOverwriteConfirmation\"],",
            "            )",
            "        if \"g90InfluencesExtruder\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"g90InfluencesExtruder\"],",
            "                data[\"feature\"][\"g90InfluencesExtruder\"],",
            "            )",
            "        if \"autoUppercaseBlacklist\" in data[\"feature\"] and isinstance(",
            "            data[\"feature\"][\"autoUppercaseBlacklist\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"feature\", \"autoUppercaseBlacklist\"],",
            "                data[\"feature\"][\"autoUppercaseBlacklist\"],",
            "            )",
            "        if \"enableDragDropUpload\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"enableDragDropUpload\"],",
            "                data[\"feature\"][\"enableDragDropUpload\"],",
            "            )",
            "",
            "    if \"gcodeAnalysis\" in data:",
            "        if \"runAt\" in data[\"gcodeAnalysis\"]:",
            "            s.set([\"gcodeAnalysis\", \"runAt\"], data[\"gcodeAnalysis\"][\"runAt\"])",
            "        if \"bedZ\" in data[\"gcodeAnalysis\"]:",
            "            s.setFloat([\"gcodeAnalysis\", \"bedZ\"], data[\"gcodeAnalysis\"][\"bedZ\"])",
            "",
            "    if \"serial\" in data:",
            "        if \"autoconnect\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"autoconnect\"], data[\"serial\"][\"autoconnect\"])",
            "        if \"port\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"port\"], data[\"serial\"][\"port\"])",
            "        if \"baudrate\" in data[\"serial\"]:",
            "            s.setInt([\"serial\", \"baudrate\"], data[\"serial\"][\"baudrate\"])",
            "        if \"exclusive\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"exclusive\"], data[\"serial\"][\"exclusive\"])",
            "        if \"lowLatency\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"lowLatency\"], data[\"serial\"][\"lowLatency\"])",
            "        if \"timeoutConnection\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"connection\"],",
            "                data[\"serial\"][\"timeoutConnection\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutDetectionFirst\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"detectionFirst\"],",
            "                data[\"serial\"][\"timeoutDetectionFirst\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutDetectionConsecutive\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"detectionConsecutive\"],",
            "                data[\"serial\"][\"timeoutDetectionConsecutive\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutCommunication\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"communication\"],",
            "                data[\"serial\"][\"timeoutCommunication\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutCommunicationBusy\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"communicationBusy\"],",
            "                data[\"serial\"][\"timeoutCommunicationBusy\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutTemperature\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"temperature\"],",
            "                data[\"serial\"][\"timeoutTemperature\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutTemperatureTargetSet\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"temperatureTargetSet\"],",
            "                data[\"serial\"][\"timeoutTemperatureTargetSet\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutTemperatureAutoreport\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"temperatureAutoreport\"],",
            "                data[\"serial\"][\"timeoutTemperatureAutoreport\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutSdStatus\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"sdStatus\"],",
            "                data[\"serial\"][\"timeoutSdStatus\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutSdStatusAutoreport\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"sdStatusAutoreport\"],",
            "                data[\"serial\"][\"timeoutSdStatusAutoreport\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutPosAutoreport\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"posAutoreport\"],",
            "                data[\"serial\"][\"timeoutPosAutoreport\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutBaudrateDetectionPause\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"baudrateDetectionPause\"],",
            "                data[\"serial\"][\"timeoutBaudrateDetectionPause\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutPositionLogWait\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"positionLogWait\"],",
            "                data[\"serial\"][\"timeoutPositionLogWait\"],",
            "                min=1.0,",
            "            )",
            "        if \"additionalPorts\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"additionalPorts\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"additionalPorts\"], data[\"serial\"][\"additionalPorts\"])",
            "        if \"additionalBaudrates\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"additionalBaudrates\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"additionalBaudrates\"], data[\"serial\"][\"additionalBaudrates\"]",
            "            )",
            "        if \"blacklistedPorts\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"blacklistedPorts\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"blacklistedPorts\"], data[\"serial\"][\"blacklistedPorts\"])",
            "        if \"blacklistedBaudrates\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"blacklistedBaudrates\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"blacklistedBaudrates\"], data[\"serial\"][\"blacklistedBaudrates\"]",
            "            )",
            "        if \"longRunningCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"longRunningCommands\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"longRunningCommands\"], data[\"serial\"][\"longRunningCommands\"]",
            "            )",
            "        if \"checksumRequiringCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"checksumRequiringCommands\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"checksumRequiringCommands\"],",
            "                data[\"serial\"][\"checksumRequiringCommands\"],",
            "            )",
            "        if \"blockedCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"blockedCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"blockedCommands\"], data[\"serial\"][\"blockedCommands\"])",
            "        if \"ignoredCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"ignoredCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"ignoredCommands\"], data[\"serial\"][\"ignoredCommands\"])",
            "        if \"pausingCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"pausingCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"pausingCommands\"], data[\"serial\"][\"pausingCommands\"])",
            "        if \"sdCancelCommand\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"sdCancelCommand\"], data[\"serial\"][\"sdCancelCommand\"])",
            "        if \"emergencyCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"emergencyCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"emergencyCommands\"], data[\"serial\"][\"emergencyCommands\"])",
            "        if \"helloCommand\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"helloCommand\"], data[\"serial\"][\"helloCommand\"])",
            "        if \"ignoreErrorsFromFirmware\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"ignoreErrorsFromFirmware\"],",
            "                data[\"serial\"][\"ignoreErrorsFromFirmware\"],",
            "            )",
            "        if \"disconnectOnErrors\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"disconnectOnErrors\"], data[\"serial\"][\"disconnectOnErrors\"]",
            "            )",
            "        if \"triggerOkForM29\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"triggerOkForM29\"], data[\"serial\"][\"triggerOkForM29\"])",
            "        if \"supportResendsWithoutOk\" in data[\"serial\"]:",
            "            value = data[\"serial\"][\"supportResendsWithoutOk\"]",
            "            if value in (\"always\", \"detect\", \"never\"):",
            "                s.set([\"serial\", \"supportResendsWithoutOk\"], value)",
            "        if \"waitForStart\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"waitForStartOnConnect\"], data[\"serial\"][\"waitForStart\"]",
            "            )",
            "        if \"waitToLoadSdFileList\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"waitToLoadSdFileList\"],",
            "                data[\"serial\"][\"waitToLoadSdFileList\"],",
            "            )",
            "        if \"alwaysSendChecksum\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"alwaysSendChecksum\"], data[\"serial\"][\"alwaysSendChecksum\"]",
            "            )",
            "        if \"neverSendChecksum\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"neverSendChecksum\"], data[\"serial\"][\"neverSendChecksum\"]",
            "            )",
            "        if \"sendChecksumWithUnknownCommands\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"sendChecksumWithUnknownCommands\"],",
            "                data[\"serial\"][\"sendChecksumWithUnknownCommands\"],",
            "            )",
            "        if \"unknownCommandsNeedAck\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"unknownCommandsNeedAck\"],",
            "                data[\"serial\"][\"unknownCommandsNeedAck\"],",
            "            )",
            "        if \"sdRelativePath\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"sdRelativePath\"], data[\"serial\"][\"sdRelativePath\"])",
            "        if \"sdAlwaysAvailable\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"sdAlwaysAvailable\"], data[\"serial\"][\"sdAlwaysAvailable\"]",
            "            )",
            "        if \"sdLowerCase\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"sdLowerCase\"], data[\"serial\"][\"sdLowerCase\"])",
            "        if \"swallowOkAfterResend\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"swallowOkAfterResend\"], data[\"serial\"][\"swallowOkAfterResend\"]",
            "            )",
            "        if \"repetierTargetTemp\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"repetierTargetTemp\"], data[\"serial\"][\"repetierTargetTemp\"]",
            "            )",
            "        if \"externalHeatupDetection\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"externalHeatupDetection\"],",
            "                data[\"serial\"][\"externalHeatupDetection\"],",
            "            )",
            "        if \"ignoreIdenticalResends\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"ignoreIdenticalResends\"],",
            "                data[\"serial\"][\"ignoreIdenticalResends\"],",
            "            )",
            "        if \"firmwareDetection\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"firmwareDetection\"], data[\"serial\"][\"firmwareDetection\"]",
            "            )",
            "        if \"blockWhileDwelling\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"blockWhileDwelling\"], data[\"serial\"][\"blockWhileDwelling\"]",
            "            )",
            "        if \"useParityWorkaround\" in data[\"serial\"]:",
            "            value = data[\"serial\"][\"useParityWorkaround\"]",
            "            if value in (\"always\", \"detect\", \"never\"):",
            "                s.set([\"serial\", \"useParityWorkaround\"], value)",
            "        if \"sanityCheckTools\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"sanityCheckTools\"], data[\"serial\"][\"sanityCheckTools\"]",
            "            )",
            "        if \"notifySuppressedCommands\" in data[\"serial\"]:",
            "            value = data[\"serial\"][\"notifySuppressedCommands\"]",
            "            if value in (\"info\", \"warn\", \"never\"):",
            "                s.set([\"serial\", \"notifySuppressedCommands\"], value)",
            "        if \"sendM112OnError\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"sendM112OnError\"], data[\"serial\"][\"sendM112OnError\"])",
            "        if \"disableSdPrintingDetection\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"disableSdPrintingDetection\"],",
            "                data[\"serial\"][\"disableSdPrintingDetection\"],",
            "            )",
            "        if \"ackMax\" in data[\"serial\"]:",
            "            s.setInt([\"serial\", \"ackMax\"], data[\"serial\"][\"ackMax\"])",
            "        if \"logPositionOnPause\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"logPositionOnPause\"], data[\"serial\"][\"logPositionOnPause\"]",
            "            )",
            "        if \"logPositionOnCancel\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"logPositionOnCancel\"], data[\"serial\"][\"logPositionOnCancel\"]",
            "            )",
            "        if \"abortHeatupOnCancel\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"abortHeatupOnCancel\"], data[\"serial\"][\"abortHeatupOnCancel\"]",
            "            )",
            "        if \"maxTimeoutsIdle\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"idle\"],",
            "                data[\"serial\"][\"maxTimeoutsIdle\"],",
            "            )",
            "        if \"maxTimeoutsPrinting\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"printing\"],",
            "                data[\"serial\"][\"maxTimeoutsPrinting\"],",
            "            )",
            "        if \"maxTimeoutsLong\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"long\"],",
            "                data[\"serial\"][\"maxTimeoutsLong\"],",
            "            )",
            "        if \"capAutoreportTemp\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_temp\"],",
            "                data[\"serial\"][\"capAutoreportTemp\"],",
            "            )",
            "        if \"capAutoreportSdStatus\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_sdstatus\"],",
            "                data[\"serial\"][\"capAutoreportSdStatus\"],",
            "            )",
            "        if \"capAutoreportPos\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_pos\"],",
            "                data[\"serial\"][\"capAutoreportPos\"],",
            "            )",
            "        if \"capBusyProtocol\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"busy_protocol\"],",
            "                data[\"serial\"][\"capBusyProtocol\"],",
            "            )",
            "        if \"capEmergencyParser\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"emergency_parser\"],",
            "                data[\"serial\"][\"capEmergencyParser\"],",
            "            )",
            "        if \"capExtendedM20\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"extended_m20\"],",
            "                data[\"serial\"][\"capExtendedM20\"],",
            "            ),",
            "        if \"capLfnWrite\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"lfn_write\"],",
            "                data[\"serial\"][\"capLfnWrite\"],",
            "            )",
            "        if \"resendRatioThreshold\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"resendRatioThreshold\"], data[\"serial\"][\"resendRatioThreshold\"]",
            "            )",
            "        if \"resendRatioStart\" in data[\"serial\"]:",
            "            s.setInt([\"serial\", \"resendRatioStart\"], data[\"serial\"][\"resendRatioStart\"])",
            "        if \"ignoreEmptyPorts\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"ignoreEmptyPorts\"], data[\"serial\"][\"ignoreEmptyPorts\"]",
            "            )",
            "",
            "        if \"encoding\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"encoding\"], data[\"serial\"][\"encoding\"])",
            "",
            "        if \"enableShutdownActionCommand\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"enableShutdownActionCommand\"],",
            "                data[\"serial\"][\"enableShutdownActionCommand\"],",
            "            )",
            "",
            "        oldLog = s.getBoolean([\"serial\", \"log\"])",
            "        if \"log\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"log\"], data[\"serial\"][\"log\"])",
            "        if oldLog and not s.getBoolean([\"serial\", \"log\"]):",
            "            # disable debug logging to serial.log",
            "            logging.getLogger(\"SERIAL\").debug(\"Disabling serial logging\")",
            "            logging.getLogger(\"SERIAL\").setLevel(logging.CRITICAL)",
            "        elif not oldLog and s.getBoolean([\"serial\", \"log\"]):",
            "            # enable debug logging to serial.log",
            "            logging.getLogger(\"SERIAL\").setLevel(logging.DEBUG)",
            "            logging.getLogger(\"SERIAL\").debug(\"Enabling serial logging\")",
            "",
            "    if \"temperature\" in data:",
            "        if \"profiles\" in data[\"temperature\"]:",
            "            result = []",
            "            for profile in data[\"temperature\"][\"profiles\"]:",
            "                try:",
            "                    profile[\"bed\"] = int(profile[\"bed\"])",
            "                    profile[\"extruder\"] = int(profile[\"extruder\"])",
            "                except ValueError:",
            "                    pass",
            "                result.append(profile)",
            "            s.set([\"temperature\", \"profiles\"], result)",
            "        if \"cutoff\" in data[\"temperature\"]:",
            "            try:",
            "                cutoff = int(data[\"temperature\"][\"cutoff\"])",
            "                if cutoff > 1:",
            "                    s.setInt([\"temperature\", \"cutoff\"], cutoff)",
            "            except ValueError:",
            "                pass",
            "        if \"sendAutomatically\" in data[\"temperature\"]:",
            "            s.setBoolean(",
            "                [\"temperature\", \"sendAutomatically\"],",
            "                data[\"temperature\"][\"sendAutomatically\"],",
            "            )",
            "        if \"sendAutomaticallyAfter\" in data[\"temperature\"]:",
            "            s.setInt(",
            "                [\"temperature\", \"sendAutomaticallyAfter\"],",
            "                data[\"temperature\"][\"sendAutomaticallyAfter\"],",
            "                min=0,",
            "                max=30,",
            "            )",
            "",
            "    if \"terminalFilters\" in data:",
            "        s.set([\"terminalFilters\"], data[\"terminalFilters\"])",
            "",
            "    if \"system\" in data:",
            "        if \"actions\" in data[\"system\"]:",
            "            s.set([\"system\", \"actions\"], data[\"system\"][\"actions\"])",
            "        if \"events\" in data[\"system\"]:",
            "            s.set([\"system\", \"events\"], data[\"system\"][\"events\"])",
            "",
            "    if \"scripts\" in data:",
            "        if \"gcode\" in data[\"scripts\"] and isinstance(data[\"scripts\"][\"gcode\"], dict):",
            "            for name, script in data[\"scripts\"][\"gcode\"].items():",
            "                if name == \"snippets\":",
            "                    continue",
            "                if not isinstance(script, str):",
            "                    continue",
            "                s.saveScript(",
            "                    \"gcode\", name, script.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")",
            "                )",
            "",
            "    if \"server\" in data:",
            "        if \"commands\" in data[\"server\"]:",
            "            if \"systemShutdownCommand\" in data[\"server\"][\"commands\"]:",
            "                s.set(",
            "                    [\"server\", \"commands\", \"systemShutdownCommand\"],",
            "                    data[\"server\"][\"commands\"][\"systemShutdownCommand\"],",
            "                )",
            "            if \"systemRestartCommand\" in data[\"server\"][\"commands\"]:",
            "                s.set(",
            "                    [\"server\", \"commands\", \"systemRestartCommand\"],",
            "                    data[\"server\"][\"commands\"][\"systemRestartCommand\"],",
            "                )",
            "            if \"serverRestartCommand\" in data[\"server\"][\"commands\"]:",
            "                s.set(",
            "                    [\"server\", \"commands\", \"serverRestartCommand\"],",
            "                    data[\"server\"][\"commands\"][\"serverRestartCommand\"],",
            "                )",
            "        if \"diskspace\" in data[\"server\"]:",
            "            if \"warning\" in data[\"server\"][\"diskspace\"]:",
            "                s.setInt(",
            "                    [\"server\", \"diskspace\", \"warning\"],",
            "                    data[\"server\"][\"diskspace\"][\"warning\"],",
            "                )",
            "            if \"critical\" in data[\"server\"][\"diskspace\"]:",
            "                s.setInt(",
            "                    [\"server\", \"diskspace\", \"critical\"],",
            "                    data[\"server\"][\"diskspace\"][\"critical\"],",
            "                )",
            "        if \"onlineCheck\" in data[\"server\"]:",
            "            if \"enabled\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.setBoolean(",
            "                    [\"server\", \"onlineCheck\", \"enabled\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"enabled\"],",
            "                )",
            "            if \"interval\" in data[\"server\"][\"onlineCheck\"]:",
            "                try:",
            "                    interval = int(data[\"server\"][\"onlineCheck\"][\"interval\"])",
            "                    s.setInt([\"server\", \"onlineCheck\", \"interval\"], interval * 60)",
            "                except ValueError:",
            "                    pass",
            "            if \"host\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.set(",
            "                    [\"server\", \"onlineCheck\", \"host\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"host\"],",
            "                )",
            "            if \"port\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.setInt(",
            "                    [\"server\", \"onlineCheck\", \"port\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"port\"],",
            "                )",
            "            if \"name\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.set(",
            "                    [\"server\", \"onlineCheck\", \"name\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"name\"],",
            "                )",
            "        if \"pluginBlacklist\" in data[\"server\"]:",
            "            if \"enabled\" in data[\"server\"][\"pluginBlacklist\"]:",
            "                s.setBoolean(",
            "                    [\"server\", \"pluginBlacklist\", \"enabled\"],",
            "                    data[\"server\"][\"pluginBlacklist\"][\"enabled\"],",
            "                )",
            "            if \"url\" in data[\"server\"][\"pluginBlacklist\"]:",
            "                s.set(",
            "                    [\"server\", \"pluginBlacklist\", \"url\"],",
            "                    data[\"server\"][\"pluginBlacklist\"][\"url\"],",
            "                )",
            "            if \"ttl\" in data[\"server\"][\"pluginBlacklist\"]:",
            "                try:",
            "                    ttl = int(data[\"server\"][\"pluginBlacklist\"][\"ttl\"])",
            "                    s.setInt([\"server\", \"pluginBlacklist\", \"ttl\"], ttl * 60)",
            "                except ValueError:",
            "                    pass",
            "        if \"allowFraming\" in data[\"server\"]:",
            "            s.setBoolean([\"server\", \"allowFraming\"], data[\"server\"][\"allowFraming\"])",
            "",
            "    if \"devel\" in data:",
            "        oldLog = s.getBoolean([\"devel\", \"pluginTimings\"])",
            "        if \"pluginTimings\" in data[\"devel\"]:",
            "            s.setBoolean([\"devel\", \"pluginTimings\"], data[\"devel\"][\"pluginTimings\"])",
            "        if oldLog and not s.getBoolean([\"devel\", \"pluginTimings\"]):",
            "            # disable plugin timing logging to plugintimings.log",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").debug(\"Disabling plugin timings logging\")",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").setLevel(logging.INFO)",
            "        elif not oldLog and s.getBoolean([\"devel\", \"pluginTimings\"]):",
            "            # enable plugin timing logging to plugintimings.log",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").setLevel(logging.DEBUG)",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").debug(\"Enabling plugin timings logging\")",
            "",
            "    if \"slicing\" in data:",
            "        if \"defaultSlicer\" in data[\"slicing\"]:",
            "            s.set([\"slicing\", \"defaultSlicer\"], data[\"slicing\"][\"defaultSlicer\"])",
            "",
            "    if \"plugins\" in data:",
            "        for plugin in octoprint.plugin.plugin_manager().get_implementations(",
            "            octoprint.plugin.SettingsPlugin",
            "        ):",
            "            plugin_id = plugin._identifier",
            "            if plugin_id in data[\"plugins\"]:",
            "                try:",
            "                    plugin.on_settings_save(data[\"plugins\"][plugin_id])",
            "                except TypeError:",
            "                    logger.warning(",
            "                        \"Could not save settings for plugin {name} ({version}). It may have called super(...)\".format(",
            "                            name=plugin._plugin_name, version=plugin._plugin_version",
            "                        )",
            "                    )",
            "                    logger.warning(",
            "                        \"in a way which has issues due to OctoPrint's dynamic reloading after plugin operations.\"",
            "                    )",
            "                    logger.warning(",
            "                        \"Please contact the plugin's author and ask to update the plugin to use a direct call like\"",
            "                    )",
            "                    logger.warning(",
            "                        \"octoprint.plugin.SettingsPlugin.on_settings_save(self, data) instead.\",",
            "                        exc_info=True,",
            "                    )",
            "                except Exception:",
            "                    logger.exception(",
            "                        \"Could not save settings for plugin {name} ({version})\".format(",
            "                            version=plugin._plugin_version, name=plugin._plugin_name",
            "                        ),",
            "                        extra={\"plugin\": plugin._identifier},",
            "                    )",
            "",
            "    s.save(trigger_event=True)"
        ],
        "afterPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import logging",
            "import re",
            "",
            "from flask import abort, jsonify, request",
            "from flask_login import current_user",
            "",
            "import octoprint.plugin",
            "import octoprint.util",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.server import pluginManager, printer, userManager",
            "from octoprint.server.api import NO_CONTENT, api",
            "from octoprint.server.util.flask import (",
            "    credentials_checked_recently,",
            "    no_firstrun_access,",
            "    with_revalidation_checking,",
            ")",
            "from octoprint.settings import settings, valid_boolean_trues",
            "from octoprint.timelapse import configure_timelapse",
            "from octoprint.webcams import (",
            "    get_default_webcam,",
            "    get_snapshot_webcam,",
            "    get_webcams_as_dicts,",
            ")",
            "",
            "# ~~ settings",
            "",
            "FOLDER_TYPES = (\"uploads\", \"timelapse\", \"watched\")",
            "TIMELAPSE_BITRATE_PATTERN = re.compile(r\"\\d+[KMGTPEZY]?i?B?\", flags=re.IGNORECASE)",
            "DEPRECATED_WEBCAM_KEYS = (",
            "    \"streamUrl\",",
            "    \"streamRatio\",",
            "    \"streamTimeout\",",
            "    \"streamWebrtcIceServers\",",
            "    \"snapshotUrl\",",
            "    \"snapshotTimeout\",",
            "    \"snapshotSslValidation\",",
            "    \"cacheBuster\",",
            "    \"flipH\",",
            "    \"flipV\",",
            "    \"rotate90\",",
            ")",
            "",
            "",
            "def _lastmodified():",
            "    return settings().last_modified",
            "",
            "",
            "def _etag(lm=None):",
            "    if lm is None:",
            "        lm = _lastmodified()",
            "",
            "    connection_options = printer.__class__.get_connection_options()",
            "    plugins = sorted(octoprint.plugin.plugin_manager().enabled_plugins)",
            "    plugin_settings = _get_plugin_settings()",
            "",
            "    from collections import OrderedDict",
            "",
            "    sorted_plugin_settings = OrderedDict()",
            "    for key in sorted(plugin_settings.keys()):",
            "        sorted_plugin_settings[key] = plugin_settings.get(key, {})",
            "",
            "    if current_user is not None and not current_user.is_anonymous:",
            "        roles = sorted(current_user.permissions, key=lambda x: x.key)",
            "    else:",
            "        roles = []",
            "",
            "    import hashlib",
            "",
            "    hash = hashlib.sha1()",
            "",
            "    def hash_update(value):",
            "        value = value.encode(\"utf-8\")",
            "        hash.update(value)",
            "",
            "    # last modified timestamp",
            "    hash_update(str(lm))",
            "",
            "    # effective config from config.yaml + overlays",
            "    hash_update(repr(settings().effective))",
            "",
            "    # might duplicate settings().effective, but plugins might also inject additional keys into the settings",
            "    # output that are not stored in config.yaml",
            "    hash_update(repr(sorted_plugin_settings))",
            "",
            "    # connection options are also part of the settings",
            "    hash_update(repr(connection_options))",
            "",
            "    # if the list of plugins changes, the settings structure changes too",
            "    hash_update(repr(plugins))",
            "",
            "    # and likewise if the role of the user changes",
            "    hash_update(repr(roles))",
            "",
            "    # of if the user reauthenticates",
            "    hash_update(repr(credentials_checked_recently()))",
            "",
            "    return hash.hexdigest()",
            "",
            "",
            "@api.route(\"/settings\", methods=[\"GET\"])",
            "@with_revalidation_checking(",
            "    etag_factory=_etag,",
            "    lastmodified_factory=_lastmodified,",
            "    unless=lambda: request.values.get(\"force\", \"false\") in valid_boolean_trues",
            "    or settings().getBoolean([\"server\", \"firstRun\"])",
            "    or not userManager.has_been_customized(),",
            ")",
            "def getSettings():",
            "    if not Permissions.SETTINGS_READ.can() and not (",
            "        settings().getBoolean([\"server\", \"firstRun\"])",
            "        or not userManager.has_been_customized()",
            "    ):",
            "        abort(403)",
            "",
            "    s = settings()",
            "",
            "    connectionOptions = printer.__class__.get_connection_options()",
            "",
            "    # NOTE: Remember to adjust the docs of the data model on the Settings API if anything",
            "    # is changed, added or removed here",
            "",
            "    data = {",
            "        \"api\": {",
            "            \"key\": (",
            "                s.get([\"api\", \"key\"])",
            "                if Permissions.ADMIN.can() and credentials_checked_recently()",
            "                else None",
            "            ),",
            "            \"allowCrossOrigin\": s.get([\"api\", \"allowCrossOrigin\"]),",
            "        },",
            "        \"appearance\": {",
            "            \"name\": s.get([\"appearance\", \"name\"]),",
            "            \"color\": s.get([\"appearance\", \"color\"]),",
            "            \"colorTransparent\": s.getBoolean([\"appearance\", \"colorTransparent\"]),",
            "            \"colorIcon\": s.getBoolean([\"appearance\", \"colorIcon\"]),",
            "            \"defaultLanguage\": s.get([\"appearance\", \"defaultLanguage\"]),",
            "            \"showFahrenheitAlso\": s.getBoolean([\"appearance\", \"showFahrenheitAlso\"]),",
            "            \"fuzzyTimes\": s.getBoolean([\"appearance\", \"fuzzyTimes\"]),",
            "            \"closeModalsWithClick\": s.getBoolean([\"appearance\", \"closeModalsWithClick\"]),",
            "            \"showInternalFilename\": s.getBoolean([\"appearance\", \"showInternalFilename\"]),",
            "        },",
            "        \"feature\": {",
            "            \"temperatureGraph\": s.getBoolean([\"feature\", \"temperatureGraph\"]),",
            "            \"sdSupport\": s.getBoolean([\"feature\", \"sdSupport\"]),",
            "            \"keyboardControl\": s.getBoolean([\"feature\", \"keyboardControl\"]),",
            "            \"pollWatched\": s.getBoolean([\"feature\", \"pollWatched\"]),",
            "            \"modelSizeDetection\": s.getBoolean([\"feature\", \"modelSizeDetection\"]),",
            "            \"rememberFileFolder\": s.getBoolean([\"feature\", \"rememberFileFolder\"]),",
            "            \"printStartConfirmation\": s.getBoolean([\"feature\", \"printStartConfirmation\"]),",
            "            \"printCancelConfirmation\": s.getBoolean(",
            "                [\"feature\", \"printCancelConfirmation\"]",
            "            ),",
            "            \"uploadOverwriteConfirmation\": s.getBoolean(",
            "                [\"feature\", \"uploadOverwriteConfirmation\"]",
            "            ),",
            "            \"g90InfluencesExtruder\": s.getBoolean([\"feature\", \"g90InfluencesExtruder\"]),",
            "            \"autoUppercaseBlacklist\": s.get([\"feature\", \"autoUppercaseBlacklist\"]),",
            "            \"enableDragDropUpload\": s.getBoolean([\"feature\", \"enableDragDropUpload\"]),",
            "        },",
            "        \"gcodeAnalysis\": {",
            "            \"runAt\": s.get([\"gcodeAnalysis\", \"runAt\"]),",
            "            \"bedZ\": s.getFloat([\"gcodeAnalysis\", \"bedZ\"]),",
            "        },",
            "        \"serial\": {",
            "            \"port\": connectionOptions[\"portPreference\"],",
            "            \"baudrate\": connectionOptions[\"baudratePreference\"],",
            "            \"exclusive\": s.getBoolean([\"serial\", \"exclusive\"]),",
            "            \"lowLatency\": s.getBoolean([\"serial\", \"lowLatency\"]),",
            "            \"portOptions\": connectionOptions[\"ports\"],",
            "            \"baudrateOptions\": connectionOptions[\"baudrates\"],",
            "            \"autoconnect\": s.getBoolean([\"serial\", \"autoconnect\"]),",
            "            \"timeoutConnection\": s.getFloat([\"serial\", \"timeout\", \"connection\"]),",
            "            \"timeoutDetectionFirst\": s.getFloat([\"serial\", \"timeout\", \"detectionFirst\"]),",
            "            \"timeoutDetectionConsecutive\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"detectionConsecutive\"]",
            "            ),",
            "            \"timeoutCommunication\": s.getFloat([\"serial\", \"timeout\", \"communication\"]),",
            "            \"timeoutCommunicationBusy\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"communicationBusy\"]",
            "            ),",
            "            \"timeoutTemperature\": s.getFloat([\"serial\", \"timeout\", \"temperature\"]),",
            "            \"timeoutTemperatureTargetSet\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"temperatureTargetSet\"]",
            "            ),",
            "            \"timeoutTemperatureAutoreport\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"temperatureAutoreport\"]",
            "            ),",
            "            \"timeoutSdStatus\": s.getFloat([\"serial\", \"timeout\", \"sdStatus\"]),",
            "            \"timeoutSdStatusAutoreport\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"sdStatusAutoreport\"]",
            "            ),",
            "            \"timeoutPosAutoreport\": s.getFloat([\"serial\", \"timeout\", \"posAutoreport\"]),",
            "            \"timeoutBaudrateDetectionPause\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"baudrateDetectionPause\"]",
            "            ),",
            "            \"timeoutPositionLogWait\": s.getFloat(",
            "                [\"serial\", \"timeout\", \"positionLogWait\"]",
            "            ),",
            "            \"log\": s.getBoolean([\"serial\", \"log\"]),",
            "            \"additionalPorts\": s.get([\"serial\", \"additionalPorts\"]),",
            "            \"additionalBaudrates\": s.get([\"serial\", \"additionalBaudrates\"]),",
            "            \"blacklistedPorts\": s.get([\"serial\", \"blacklistedPorts\"]),",
            "            \"blacklistedBaudrates\": s.get([\"serial\", \"blacklistedBaudrates\"]),",
            "            \"longRunningCommands\": s.get([\"serial\", \"longRunningCommands\"]),",
            "            \"checksumRequiringCommands\": s.get([\"serial\", \"checksumRequiringCommands\"]),",
            "            \"blockedCommands\": s.get([\"serial\", \"blockedCommands\"]),",
            "            \"ignoredCommands\": s.get([\"serial\", \"ignoredCommands\"]),",
            "            \"pausingCommands\": s.get([\"serial\", \"pausingCommands\"]),",
            "            \"sdCancelCommand\": s.get([\"serial\", \"sdCancelCommand\"]),",
            "            \"emergencyCommands\": s.get([\"serial\", \"emergencyCommands\"]),",
            "            \"helloCommand\": s.get([\"serial\", \"helloCommand\"]),",
            "            \"ignoreErrorsFromFirmware\": s.getBoolean(",
            "                [\"serial\", \"ignoreErrorsFromFirmware\"]",
            "            ),",
            "            \"disconnectOnErrors\": s.getBoolean([\"serial\", \"disconnectOnErrors\"]),",
            "            \"triggerOkForM29\": s.getBoolean([\"serial\", \"triggerOkForM29\"]),",
            "            \"logPositionOnPause\": s.getBoolean([\"serial\", \"logPositionOnPause\"]),",
            "            \"logPositionOnCancel\": s.getBoolean([\"serial\", \"logPositionOnCancel\"]),",
            "            \"abortHeatupOnCancel\": s.getBoolean([\"serial\", \"abortHeatupOnCancel\"]),",
            "            \"supportResendsWithoutOk\": s.get([\"serial\", \"supportResendsWithoutOk\"]),",
            "            \"waitForStart\": s.getBoolean([\"serial\", \"waitForStartOnConnect\"]),",
            "            \"waitToLoadSdFileList\": s.getBoolean([\"serial\", \"waitToLoadSdFileList\"]),",
            "            \"alwaysSendChecksum\": s.getBoolean([\"serial\", \"alwaysSendChecksum\"]),",
            "            \"neverSendChecksum\": s.getBoolean([\"serial\", \"neverSendChecksum\"]),",
            "            \"sendChecksumWithUnknownCommands\": s.getBoolean(",
            "                [\"serial\", \"sendChecksumWithUnknownCommands\"]",
            "            ),",
            "            \"unknownCommandsNeedAck\": s.getBoolean([\"serial\", \"unknownCommandsNeedAck\"]),",
            "            \"sdRelativePath\": s.getBoolean([\"serial\", \"sdRelativePath\"]),",
            "            \"sdAlwaysAvailable\": s.getBoolean([\"serial\", \"sdAlwaysAvailable\"]),",
            "            \"sdLowerCase\": s.getBoolean([\"serial\", \"sdLowerCase\"]),",
            "            \"swallowOkAfterResend\": s.getBoolean([\"serial\", \"swallowOkAfterResend\"]),",
            "            \"repetierTargetTemp\": s.getBoolean([\"serial\", \"repetierTargetTemp\"]),",
            "            \"externalHeatupDetection\": s.getBoolean(",
            "                [\"serial\", \"externalHeatupDetection\"]",
            "            ),",
            "            \"ignoreIdenticalResends\": s.getBoolean([\"serial\", \"ignoreIdenticalResends\"]),",
            "            \"firmwareDetection\": s.getBoolean([\"serial\", \"firmwareDetection\"]),",
            "            \"blockWhileDwelling\": s.getBoolean([\"serial\", \"blockWhileDwelling\"]),",
            "            \"useParityWorkaround\": s.get([\"serial\", \"useParityWorkaround\"]),",
            "            \"sanityCheckTools\": s.getBoolean([\"serial\", \"sanityCheckTools\"]),",
            "            \"notifySuppressedCommands\": s.get([\"serial\", \"notifySuppressedCommands\"]),",
            "            \"sendM112OnError\": s.getBoolean([\"serial\", \"sendM112OnError\"]),",
            "            \"disableSdPrintingDetection\": s.getBoolean(",
            "                [\"serial\", \"disableSdPrintingDetection\"]",
            "            ),",
            "            \"ackMax\": s.getInt([\"serial\", \"ackMax\"]),",
            "            \"maxTimeoutsIdle\": s.getInt([\"serial\", \"maxCommunicationTimeouts\", \"idle\"]),",
            "            \"maxTimeoutsPrinting\": s.getInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"printing\"]",
            "            ),",
            "            \"maxTimeoutsLong\": s.getInt([\"serial\", \"maxCommunicationTimeouts\", \"long\"]),",
            "            \"capAutoreportTemp\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_temp\"]",
            "            ),",
            "            \"capAutoreportSdStatus\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_sdstatus\"]",
            "            ),",
            "            \"capAutoreportPos\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_pos\"]",
            "            ),",
            "            \"capBusyProtocol\": s.getBoolean([\"serial\", \"capabilities\", \"busy_protocol\"]),",
            "            \"capEmergencyParser\": s.getBoolean(",
            "                [\"serial\", \"capabilities\", \"emergency_parser\"]",
            "            ),",
            "            \"capExtendedM20\": s.getBoolean([\"serial\", \"capabilities\", \"extended_m20\"]),",
            "            \"capLfnWrite\": s.getBoolean([\"serial\", \"capabilities\", \"lfn_write\"]),",
            "            \"resendRatioThreshold\": s.getInt([\"serial\", \"resendRatioThreshold\"]),",
            "            \"resendRatioStart\": s.getInt([\"serial\", \"resendRatioStart\"]),",
            "            \"ignoreEmptyPorts\": s.getBoolean([\"serial\", \"ignoreEmptyPorts\"]),",
            "            \"encoding\": s.get([\"serial\", \"encoding\"]),",
            "            \"enableShutdownActionCommand\": s.get(",
            "                [\"serial\", \"enableShutdownActionCommand\"]",
            "            ),",
            "        },",
            "        \"folder\": {",
            "            \"uploads\": s.getBaseFolder(\"uploads\"),",
            "            \"timelapse\": s.getBaseFolder(\"timelapse\"),",
            "            \"watched\": s.getBaseFolder(\"watched\"),",
            "        },",
            "        \"temperature\": {",
            "            \"profiles\": s.get([\"temperature\", \"profiles\"]),",
            "            \"cutoff\": s.getInt([\"temperature\", \"cutoff\"]),",
            "            \"sendAutomatically\": s.getBoolean([\"temperature\", \"sendAutomatically\"]),",
            "            \"sendAutomaticallyAfter\": s.getInt(",
            "                [\"temperature\", \"sendAutomaticallyAfter\"], min=0, max=30",
            "            ),",
            "        },",
            "        \"system\": {",
            "            \"actions\": s.get([\"system\", \"actions\"]),",
            "            \"events\": s.get([\"system\", \"events\"]),",
            "        },",
            "        \"terminalFilters\": s.get([\"terminalFilters\"]),",
            "        \"scripts\": {",
            "            \"gcode\": {",
            "                \"afterPrinterConnected\": None,",
            "                \"beforePrinterDisconnected\": None,",
            "                \"beforePrintStarted\": None,",
            "                \"afterPrintCancelled\": None,",
            "                \"afterPrintDone\": None,",
            "                \"beforePrintPaused\": None,",
            "                \"afterPrintResumed\": None,",
            "                \"beforeToolChange\": None,",
            "                \"afterToolChange\": None,",
            "                \"snippets\": {},",
            "            }",
            "        },",
            "        \"server\": {",
            "            \"commands\": {",
            "                \"systemShutdownCommand\": s.get(",
            "                    [\"server\", \"commands\", \"systemShutdownCommand\"]",
            "                ),",
            "                \"systemRestartCommand\": s.get(",
            "                    [\"server\", \"commands\", \"systemRestartCommand\"]",
            "                ),",
            "                \"serverRestartCommand\": s.get(",
            "                    [\"server\", \"commands\", \"serverRestartCommand\"]",
            "                ),",
            "            },",
            "            \"diskspace\": {",
            "                \"warning\": s.getInt([\"server\", \"diskspace\", \"warning\"]),",
            "                \"critical\": s.getInt([\"server\", \"diskspace\", \"critical\"]),",
            "            },",
            "            \"onlineCheck\": {",
            "                \"enabled\": s.getBoolean([\"server\", \"onlineCheck\", \"enabled\"]),",
            "                \"interval\": int(s.getInt([\"server\", \"onlineCheck\", \"interval\"]) / 60),",
            "                \"host\": s.get([\"server\", \"onlineCheck\", \"host\"]),",
            "                \"port\": s.getInt([\"server\", \"onlineCheck\", \"port\"]),",
            "                \"name\": s.get([\"server\", \"onlineCheck\", \"name\"]),",
            "            },",
            "            \"pluginBlacklist\": {",
            "                \"enabled\": s.getBoolean([\"server\", \"pluginBlacklist\", \"enabled\"]),",
            "                \"url\": s.get([\"server\", \"pluginBlacklist\", \"url\"]),",
            "                \"ttl\": int(s.getInt([\"server\", \"pluginBlacklist\", \"ttl\"]) / 60),",
            "            },",
            "            \"allowFraming\": s.getBoolean([\"server\", \"allowFraming\"]),",
            "        },",
            "        \"devel\": {\"pluginTimings\": s.getBoolean([\"devel\", \"pluginTimings\"])},",
            "        \"slicing\": {\"defaultSlicer\": s.get([\"slicing\", \"defaultSlicer\"])},",
            "    }",
            "",
            "    gcode_scripts = s.listScripts(\"gcode\")",
            "    if gcode_scripts:",
            "        data[\"scripts\"] = {\"gcode\": {}}",
            "        for name in gcode_scripts:",
            "            data[\"scripts\"][\"gcode\"][name] = s.loadScript(\"gcode\", name, source=True)",
            "",
            "    plugin_settings = _get_plugin_settings()",
            "    if len(plugin_settings):",
            "        data[\"plugins\"] = plugin_settings",
            "",
            "    if Permissions.WEBCAM.can() or (",
            "        settings().getBoolean([\"server\", \"firstRun\"])",
            "        and not userManager.has_been_customized()",
            "    ):",
            "        webcamsDict = get_webcams_as_dicts()",
            "        data[\"webcam\"] = {",
            "            \"webcamEnabled\": s.getBoolean([\"webcam\", \"webcamEnabled\"]),",
            "            \"timelapseEnabled\": s.getBoolean([\"webcam\", \"timelapseEnabled\"]),",
            "            \"ffmpegPath\": s.get([\"webcam\", \"ffmpeg\"]),",
            "            \"ffmpegCommandline\": s.get([\"webcam\", \"ffmpegCommandline\"]),",
            "            \"bitrate\": s.get([\"webcam\", \"bitrate\"]),",
            "            \"ffmpegThreads\": s.get([\"webcam\", \"ffmpegThreads\"]),",
            "            \"ffmpegVideoCodec\": s.get([\"webcam\", \"ffmpegVideoCodec\"]),",
            "            \"watermark\": s.getBoolean([\"webcam\", \"watermark\"]),",
            "            # webcams & defaults",
            "            \"webcams\": webcamsDict,",
            "            \"defaultWebcam\": None,",
            "            \"snapshotWebcam\": None,",
            "        }",
            "",
            "        for key in DEPRECATED_WEBCAM_KEYS:",
            "            data[\"webcam\"][key] = None",
            "",
            "        defaultWebcam = get_default_webcam()",
            "        if defaultWebcam:",
            "            data[\"webcam\"].update(",
            "                {",
            "                    \"flipH\": defaultWebcam.config.flipH,",
            "                    \"flipV\": defaultWebcam.config.flipV,",
            "                    \"rotate90\": defaultWebcam.config.rotate90,",
            "                    \"defaultWebcam\": defaultWebcam.config.name,",
            "                }",
            "            )",
            "",
            "        compatWebcam = defaultWebcam.config.compat if defaultWebcam is not None else None",
            "        if compatWebcam:",
            "            data[\"webcam\"].update(",
            "                {",
            "                    \"streamUrl\": compatWebcam.stream,",
            "                    \"streamRatio\": compatWebcam.streamRatio,",
            "                    \"streamTimeout\": compatWebcam.streamTimeout,",
            "                    \"streamWebrtcIceServers\": compatWebcam.streamWebrtcIceServers,",
            "                    \"snapshotUrl\": compatWebcam.snapshot,",
            "                    \"snapshotTimeout\": compatWebcam.snapshotTimeout,",
            "                    \"snapshotSslValidation\": compatWebcam.snapshotSslValidation,",
            "                    \"cacheBuster\": compatWebcam.cacheBuster,",
            "                }",
            "            )",
            "",
            "        snapshotWebcam = get_snapshot_webcam()",
            "        if snapshotWebcam:",
            "            data[\"webcam\"].update(",
            "                {",
            "                    \"snapshotWebcam\": snapshotWebcam.config.name,",
            "                }",
            "            )",
            "    else:",
            "        data[\"webcam\"] = {}",
            "",
            "    if Permissions.ADMIN.can():",
            "        data[\"accessControl\"] = {",
            "            \"autologinLocal\": s.getBoolean([\"accessControl\", \"autologinLocal\"]),",
            "            \"autologinHeadsupAcknowledged\": s.getBoolean(",
            "                [\"accessControl\", \"autologinHeadsupAcknowledged\"]",
            "            ),",
            "        }",
            "",
            "    return jsonify(data)",
            "",
            "",
            "def _get_plugin_settings():",
            "    logger = logging.getLogger(__name__)",
            "",
            "    data = {}",
            "",
            "    def process_plugin_result(name, result):",
            "        if result:",
            "            try:",
            "                jsonify(test=result)",
            "            except Exception:",
            "                logger.exception(",
            "                    \"Error while jsonifying settings from plugin {}, please contact the plugin author about this\".format(",
            "                        name",
            "                    )",
            "                )",
            "                raise",
            "            else:",
            "                if \"__enabled\" in result:",
            "                    del result[\"__enabled\"]",
            "                data[name] = result",
            "",
            "    for plugin in octoprint.plugin.plugin_manager().get_implementations(",
            "        octoprint.plugin.SettingsPlugin",
            "    ):",
            "        try:",
            "            result = plugin.on_settings_load()",
            "            process_plugin_result(plugin._identifier, result)",
            "        except Exception:",
            "            logger.exception(",
            "                \"Could not load settings for plugin {name} ({version})\".format(",
            "                    version=plugin._plugin_version, name=plugin._plugin_name",
            "                ),",
            "                extra={\"plugin\": plugin._identifier},",
            "            )",
            "",
            "    return data",
            "",
            "",
            "@api.route(\"/settings\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.SETTINGS.require(403)",
            "def setSettings():",
            "    data = request.get_json()",
            "    if not isinstance(data, dict):",
            "        abort(400, description=\"Malformed JSON body in request\")",
            "",
            "    response = _saveSettings(data)",
            "    if response:",
            "        return response",
            "    return getSettings()",
            "",
            "",
            "@api.route(\"/settings/apikey\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.ADMIN.require(403)",
            "def generateApiKey():",
            "    apikey = settings().generateApiKey()",
            "    return jsonify(apikey=apikey)",
            "",
            "",
            "@api.route(\"/settings/apikey\", methods=[\"DELETE\"])",
            "@no_firstrun_access",
            "@Permissions.ADMIN.require(403)",
            "def deleteApiKey():",
            "    settings().deleteApiKey()",
            "    return NO_CONTENT",
            "",
            "",
            "@api.route(\"/settings/templates\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SETTINGS.require(403)",
            "def fetchTemplateData():",
            "    from octoprint.server.views import fetch_template_data",
            "",
            "    refresh = request.values.get(\"refresh\", \"false\") in valid_boolean_trues",
            "    templates, _, _ = fetch_template_data(refresh=refresh)",
            "",
            "    result = {}",
            "    for tt in templates:",
            "        result[tt] = []",
            "        for key in templates[tt][\"order\"]:",
            "            entry = templates[tt][\"entries\"].get(key)",
            "            if not entry:",
            "                continue",
            "",
            "            if isinstance(entry, dict):",
            "                name = key",
            "            else:",
            "                name, entry = entry",
            "",
            "            data = {\"id\": key, \"name\": name}",
            "",
            "            if entry and \"_plugin\" in entry:",
            "                plugin = pluginManager.get_plugin_info(",
            "                    entry[\"_plugin\"], require_enabled=False",
            "                )",
            "                data[\"plugin_id\"] = plugin.key",
            "                data[\"plugin_name\"] = plugin.name",
            "",
            "            result[tt].append(data)",
            "",
            "    return jsonify(order=result)",
            "",
            "",
            "def _saveSettings(data):",
            "    logger = logging.getLogger(__name__)",
            "",
            "    s = settings()",
            "",
            "    # NOTE: Remember to adjust the docs of the data model on the Settings API if anything",
            "    # is changed, added or removed here",
            "",
            "    if \"folder\" in data:",
            "        try:",
            "            folders = data[\"folder\"]",
            "            future = {}",
            "            for folder in FOLDER_TYPES:",
            "                future[folder] = s.getBaseFolder(folder)",
            "                if folder in folders:",
            "                    future[folder] = folders[folder]",
            "",
            "            for folder in folders:",
            "                if folder not in FOLDER_TYPES:",
            "                    continue",
            "                for other_folder in FOLDER_TYPES:",
            "                    if folder == other_folder:",
            "                        continue",
            "                    if future[folder] == future[other_folder]:",
            "                        # duplicate detected, raise",
            "                        raise ValueError(",
            "                            \"Duplicate folder path for {} and {}\".format(",
            "                                folder, other_folder",
            "                            )",
            "                        )",
            "",
            "                s.setBaseFolder(folder, future[folder])",
            "        except Exception:",
            "            logger.exception(\"Something went wrong while saving a folder path\")",
            "            abort(400, description=\"At least one of the configured folders is invalid\")",
            "",
            "    if \"api\" in data:",
            "        if \"allowCrossOrigin\" in data[\"api\"]:",
            "            s.setBoolean([\"api\", \"allowCrossOrigin\"], data[\"api\"][\"allowCrossOrigin\"])",
            "",
            "    if \"accessControl\" in data:",
            "        if \"autologinHeadsupAcknowledged\" in data[\"accessControl\"]:",
            "            s.setBoolean(",
            "                [\"accessControl\", \"autologinHeadsupAcknowledged\"],",
            "                data[\"accessControl\"][\"autologinHeadsupAcknowledged\"],",
            "            )",
            "",
            "    if \"appearance\" in data:",
            "        if \"name\" in data[\"appearance\"]:",
            "            s.set([\"appearance\", \"name\"], data[\"appearance\"][\"name\"])",
            "        if \"color\" in data[\"appearance\"]:",
            "            s.set([\"appearance\", \"color\"], data[\"appearance\"][\"color\"])",
            "        if \"colorTransparent\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"colorTransparent\"], data[\"appearance\"][\"colorTransparent\"]",
            "            )",
            "        if \"colorIcon\" in data[\"appearance\"]:",
            "            s.setBoolean([\"appearance\", \"colorIcon\"], data[\"appearance\"][\"colorIcon\"])",
            "        if \"defaultLanguage\" in data[\"appearance\"]:",
            "            s.set(",
            "                [\"appearance\", \"defaultLanguage\"], data[\"appearance\"][\"defaultLanguage\"]",
            "            )",
            "        if \"showFahrenheitAlso\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"showFahrenheitAlso\"],",
            "                data[\"appearance\"][\"showFahrenheitAlso\"],",
            "            )",
            "        if \"fuzzyTimes\" in data[\"appearance\"]:",
            "            s.setBoolean([\"appearance\", \"fuzzyTimes\"], data[\"appearance\"][\"fuzzyTimes\"])",
            "        if \"closeModalsWithClick\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"closeModalsWithClick\"],",
            "                data[\"appearance\"][\"closeModalsWithClick\"],",
            "            )",
            "        if \"showInternalFilename\" in data[\"appearance\"]:",
            "            s.setBoolean(",
            "                [\"appearance\", \"showInternalFilename\"],",
            "                data[\"appearance\"][\"showInternalFilename\"],",
            "            )",
            "",
            "    if \"printer\" in data:",
            "        if \"defaultExtrusionLength\" in data[\"printer\"]:",
            "            s.setInt(",
            "                [\"printerParameters\", \"defaultExtrusionLength\"],",
            "                data[\"printer\"][\"defaultExtrusionLength\"],",
            "            )",
            "",
            "    if \"webcam\" in data:",
            "        for key in DEPRECATED_WEBCAM_KEYS:",
            "            if key in data[\"webcam\"]:",
            "                logger.warning(",
            "                    f\"Setting webcam.{key} via the API is no longer supported, please use the individual settings of the default webcam instead.\"",
            "                )",
            "",
            "        if \"webcamEnabled\" in data[\"webcam\"]:",
            "            s.setBoolean([\"webcam\", \"webcamEnabled\"], data[\"webcam\"][\"webcamEnabled\"])",
            "        if \"timelapseEnabled\" in data[\"webcam\"]:",
            "            s.setBoolean(",
            "                [\"webcam\", \"timelapseEnabled\"], data[\"webcam\"][\"timelapseEnabled\"]",
            "            )",
            "        if \"snapshotTimeout\" in data[\"webcam\"]:",
            "            s.setInt([\"webcam\", \"snapshotTimeout\"], data[\"webcam\"][\"snapshotTimeout\"])",
            "        if \"snapshotSslValidation\" in data[\"webcam\"]:",
            "            s.setBoolean(",
            "                [\"webcam\", \"snapshotSslValidation\"],",
            "                data[\"webcam\"][\"snapshotSslValidation\"],",
            "            )",
            "        if \"ffmpegPath\" in data[\"webcam\"]:",
            "            s.set([\"webcam\", \"ffmpeg\"], data[\"webcam\"][\"ffmpegPath\"])",
            "        if \"ffmpegCommandline\" in data[\"webcam\"]:",
            "            commandline = data[\"webcam\"][\"ffmpegCommandline\"]",
            "            if not all(",
            "                map(lambda x: \"{\" + x + \"}\" in commandline, (\"ffmpeg\", \"input\", \"output\"))",
            "            ):",
            "                abort(",
            "                    400,",
            "                    description=\"Invalid webcam.ffmpegCommandline setting, lacks mandatory {ffmpeg}, {input} or {output}\",",
            "                )",
            "            try:",
            "                commandline.format(",
            "                    ffmpeg=\"ffmpeg\",",
            "                    fps=\"fps\",",
            "                    bitrate=\"bitrate\",",
            "                    threads=\"threads\",",
            "                    input=\"input\",",
            "                    output=\"output\",",
            "                    videocodec=\"videocodec\",",
            "                    containerformat=\"containerformat\",",
            "                    filters=\"filters\",",
            "                )",
            "            except Exception:",
            "                # some invalid data we'll refuse to set",
            "                logger.exception(\"Invalid webcam.ffmpegCommandline setting\")",
            "                abort(400, description=\"Invalid webcam.ffmpegCommandline setting\")",
            "            else:",
            "                s.set([\"webcam\", \"ffmpegCommandline\"], commandline)",
            "        if \"bitrate\" in data[\"webcam\"] and data[\"webcam\"][\"bitrate\"]:",
            "            bitrate = str(data[\"webcam\"][\"bitrate\"])",
            "            if not TIMELAPSE_BITRATE_PATTERN.match(bitrate):",
            "                abort(",
            "                    400,",
            "                    description=\"Invalid webcam.bitrate setting, needs to be a valid ffmpeg bitrate\",",
            "                )",
            "            s.set([\"webcam\", \"bitrate\"], bitrate)",
            "        if \"ffmpegThreads\" in data[\"webcam\"]:",
            "            s.setInt([\"webcam\", \"ffmpegThreads\"], data[\"webcam\"][\"ffmpegThreads\"])",
            "        if \"ffmpegVideoCodec\" in data[\"webcam\"] and data[\"webcam\"][",
            "            \"ffmpegVideoCodec\"",
            "        ] in (\"mpeg2video\", \"libx264\"):",
            "            s.set([\"webcam\", \"ffmpegVideoCodec\"], data[\"webcam\"][\"ffmpegVideoCodec\"])",
            "        if \"watermark\" in data[\"webcam\"]:",
            "            s.setBoolean([\"webcam\", \"watermark\"], data[\"webcam\"][\"watermark\"])",
            "        if \"defaultWebcam\" in data[\"webcam\"]:",
            "            s.set([\"webcam\", \"defaultWebcam\"], data[\"webcam\"][\"defaultWebcam\"])",
            "        if \"snapshotWebcam\" in data[\"webcam\"]:",
            "            s.set([\"webcam\", \"snapshotWebcam\"], data[\"webcam\"][\"snapshotWebcam\"])",
            "",
            "            # timelapse needs to be reconfigured now since it depends on the current snapshot webcam",
            "            configure_timelapse()",
            "",
            "    if \"feature\" in data:",
            "        if \"temperatureGraph\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"temperatureGraph\"], data[\"feature\"][\"temperatureGraph\"]",
            "            )",
            "        if \"sdSupport\" in data[\"feature\"]:",
            "            s.setBoolean([\"feature\", \"sdSupport\"], data[\"feature\"][\"sdSupport\"])",
            "        if \"keyboardControl\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"keyboardControl\"], data[\"feature\"][\"keyboardControl\"]",
            "            )",
            "        if \"pollWatched\" in data[\"feature\"]:",
            "            s.setBoolean([\"feature\", \"pollWatched\"], data[\"feature\"][\"pollWatched\"])",
            "        if \"modelSizeDetection\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"modelSizeDetection\"], data[\"feature\"][\"modelSizeDetection\"]",
            "            )",
            "        if \"rememberFileFolder\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"rememberFileFolder\"],",
            "                data[\"feature\"][\"rememberFileFolder\"],",
            "            )",
            "        if \"printStartConfirmation\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"printStartConfirmation\"],",
            "                data[\"feature\"][\"printStartConfirmation\"],",
            "            )",
            "        if \"printCancelConfirmation\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"printCancelConfirmation\"],",
            "                data[\"feature\"][\"printCancelConfirmation\"],",
            "            )",
            "        if \"uploadOverwriteConfirmation\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"uploadOverwriteConfirmation\"],",
            "                data[\"feature\"][\"uploadOverwriteConfirmation\"],",
            "            )",
            "        if \"g90InfluencesExtruder\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"g90InfluencesExtruder\"],",
            "                data[\"feature\"][\"g90InfluencesExtruder\"],",
            "            )",
            "        if \"autoUppercaseBlacklist\" in data[\"feature\"] and isinstance(",
            "            data[\"feature\"][\"autoUppercaseBlacklist\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"feature\", \"autoUppercaseBlacklist\"],",
            "                data[\"feature\"][\"autoUppercaseBlacklist\"],",
            "            )",
            "        if \"enableDragDropUpload\" in data[\"feature\"]:",
            "            s.setBoolean(",
            "                [\"feature\", \"enableDragDropUpload\"],",
            "                data[\"feature\"][\"enableDragDropUpload\"],",
            "            )",
            "",
            "    if \"gcodeAnalysis\" in data:",
            "        if \"runAt\" in data[\"gcodeAnalysis\"]:",
            "            s.set([\"gcodeAnalysis\", \"runAt\"], data[\"gcodeAnalysis\"][\"runAt\"])",
            "        if \"bedZ\" in data[\"gcodeAnalysis\"]:",
            "            s.setFloat([\"gcodeAnalysis\", \"bedZ\"], data[\"gcodeAnalysis\"][\"bedZ\"])",
            "",
            "    if \"serial\" in data:",
            "        if \"autoconnect\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"autoconnect\"], data[\"serial\"][\"autoconnect\"])",
            "        if \"port\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"port\"], data[\"serial\"][\"port\"])",
            "        if \"baudrate\" in data[\"serial\"]:",
            "            s.setInt([\"serial\", \"baudrate\"], data[\"serial\"][\"baudrate\"])",
            "        if \"exclusive\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"exclusive\"], data[\"serial\"][\"exclusive\"])",
            "        if \"lowLatency\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"lowLatency\"], data[\"serial\"][\"lowLatency\"])",
            "        if \"timeoutConnection\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"connection\"],",
            "                data[\"serial\"][\"timeoutConnection\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutDetectionFirst\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"detectionFirst\"],",
            "                data[\"serial\"][\"timeoutDetectionFirst\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutDetectionConsecutive\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"detectionConsecutive\"],",
            "                data[\"serial\"][\"timeoutDetectionConsecutive\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutCommunication\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"communication\"],",
            "                data[\"serial\"][\"timeoutCommunication\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutCommunicationBusy\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"communicationBusy\"],",
            "                data[\"serial\"][\"timeoutCommunicationBusy\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutTemperature\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"temperature\"],",
            "                data[\"serial\"][\"timeoutTemperature\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutTemperatureTargetSet\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"temperatureTargetSet\"],",
            "                data[\"serial\"][\"timeoutTemperatureTargetSet\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutTemperatureAutoreport\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"temperatureAutoreport\"],",
            "                data[\"serial\"][\"timeoutTemperatureAutoreport\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutSdStatus\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"sdStatus\"],",
            "                data[\"serial\"][\"timeoutSdStatus\"],",
            "                min=1.0,",
            "            )",
            "        if \"timeoutSdStatusAutoreport\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"sdStatusAutoreport\"],",
            "                data[\"serial\"][\"timeoutSdStatusAutoreport\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutPosAutoreport\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"posAutoreport\"],",
            "                data[\"serial\"][\"timeoutPosAutoreport\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutBaudrateDetectionPause\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"baudrateDetectionPause\"],",
            "                data[\"serial\"][\"timeoutBaudrateDetectionPause\"],",
            "                min=0.0,",
            "            )",
            "        if \"timeoutPositionLogWait\" in data[\"serial\"]:",
            "            s.setFloat(",
            "                [\"serial\", \"timeout\", \"positionLogWait\"],",
            "                data[\"serial\"][\"timeoutPositionLogWait\"],",
            "                min=1.0,",
            "            )",
            "        if \"additionalPorts\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"additionalPorts\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"additionalPorts\"], data[\"serial\"][\"additionalPorts\"])",
            "        if \"additionalBaudrates\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"additionalBaudrates\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"additionalBaudrates\"], data[\"serial\"][\"additionalBaudrates\"]",
            "            )",
            "        if \"blacklistedPorts\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"blacklistedPorts\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"blacklistedPorts\"], data[\"serial\"][\"blacklistedPorts\"])",
            "        if \"blacklistedBaudrates\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"blacklistedBaudrates\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"blacklistedBaudrates\"], data[\"serial\"][\"blacklistedBaudrates\"]",
            "            )",
            "        if \"longRunningCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"longRunningCommands\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"longRunningCommands\"], data[\"serial\"][\"longRunningCommands\"]",
            "            )",
            "        if \"checksumRequiringCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"checksumRequiringCommands\"], (list, tuple)",
            "        ):",
            "            s.set(",
            "                [\"serial\", \"checksumRequiringCommands\"],",
            "                data[\"serial\"][\"checksumRequiringCommands\"],",
            "            )",
            "        if \"blockedCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"blockedCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"blockedCommands\"], data[\"serial\"][\"blockedCommands\"])",
            "        if \"ignoredCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"ignoredCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"ignoredCommands\"], data[\"serial\"][\"ignoredCommands\"])",
            "        if \"pausingCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"pausingCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"pausingCommands\"], data[\"serial\"][\"pausingCommands\"])",
            "        if \"sdCancelCommand\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"sdCancelCommand\"], data[\"serial\"][\"sdCancelCommand\"])",
            "        if \"emergencyCommands\" in data[\"serial\"] and isinstance(",
            "            data[\"serial\"][\"emergencyCommands\"], (list, tuple)",
            "        ):",
            "            s.set([\"serial\", \"emergencyCommands\"], data[\"serial\"][\"emergencyCommands\"])",
            "        if \"helloCommand\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"helloCommand\"], data[\"serial\"][\"helloCommand\"])",
            "        if \"ignoreErrorsFromFirmware\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"ignoreErrorsFromFirmware\"],",
            "                data[\"serial\"][\"ignoreErrorsFromFirmware\"],",
            "            )",
            "        if \"disconnectOnErrors\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"disconnectOnErrors\"], data[\"serial\"][\"disconnectOnErrors\"]",
            "            )",
            "        if \"triggerOkForM29\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"triggerOkForM29\"], data[\"serial\"][\"triggerOkForM29\"])",
            "        if \"supportResendsWithoutOk\" in data[\"serial\"]:",
            "            value = data[\"serial\"][\"supportResendsWithoutOk\"]",
            "            if value in (\"always\", \"detect\", \"never\"):",
            "                s.set([\"serial\", \"supportResendsWithoutOk\"], value)",
            "        if \"waitForStart\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"waitForStartOnConnect\"], data[\"serial\"][\"waitForStart\"]",
            "            )",
            "        if \"waitToLoadSdFileList\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"waitToLoadSdFileList\"],",
            "                data[\"serial\"][\"waitToLoadSdFileList\"],",
            "            )",
            "        if \"alwaysSendChecksum\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"alwaysSendChecksum\"], data[\"serial\"][\"alwaysSendChecksum\"]",
            "            )",
            "        if \"neverSendChecksum\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"neverSendChecksum\"], data[\"serial\"][\"neverSendChecksum\"]",
            "            )",
            "        if \"sendChecksumWithUnknownCommands\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"sendChecksumWithUnknownCommands\"],",
            "                data[\"serial\"][\"sendChecksumWithUnknownCommands\"],",
            "            )",
            "        if \"unknownCommandsNeedAck\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"unknownCommandsNeedAck\"],",
            "                data[\"serial\"][\"unknownCommandsNeedAck\"],",
            "            )",
            "        if \"sdRelativePath\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"sdRelativePath\"], data[\"serial\"][\"sdRelativePath\"])",
            "        if \"sdAlwaysAvailable\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"sdAlwaysAvailable\"], data[\"serial\"][\"sdAlwaysAvailable\"]",
            "            )",
            "        if \"sdLowerCase\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"sdLowerCase\"], data[\"serial\"][\"sdLowerCase\"])",
            "        if \"swallowOkAfterResend\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"swallowOkAfterResend\"], data[\"serial\"][\"swallowOkAfterResend\"]",
            "            )",
            "        if \"repetierTargetTemp\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"repetierTargetTemp\"], data[\"serial\"][\"repetierTargetTemp\"]",
            "            )",
            "        if \"externalHeatupDetection\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"externalHeatupDetection\"],",
            "                data[\"serial\"][\"externalHeatupDetection\"],",
            "            )",
            "        if \"ignoreIdenticalResends\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"ignoreIdenticalResends\"],",
            "                data[\"serial\"][\"ignoreIdenticalResends\"],",
            "            )",
            "        if \"firmwareDetection\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"firmwareDetection\"], data[\"serial\"][\"firmwareDetection\"]",
            "            )",
            "        if \"blockWhileDwelling\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"blockWhileDwelling\"], data[\"serial\"][\"blockWhileDwelling\"]",
            "            )",
            "        if \"useParityWorkaround\" in data[\"serial\"]:",
            "            value = data[\"serial\"][\"useParityWorkaround\"]",
            "            if value in (\"always\", \"detect\", \"never\"):",
            "                s.set([\"serial\", \"useParityWorkaround\"], value)",
            "        if \"sanityCheckTools\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"sanityCheckTools\"], data[\"serial\"][\"sanityCheckTools\"]",
            "            )",
            "        if \"notifySuppressedCommands\" in data[\"serial\"]:",
            "            value = data[\"serial\"][\"notifySuppressedCommands\"]",
            "            if value in (\"info\", \"warn\", \"never\"):",
            "                s.set([\"serial\", \"notifySuppressedCommands\"], value)",
            "        if \"sendM112OnError\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"sendM112OnError\"], data[\"serial\"][\"sendM112OnError\"])",
            "        if \"disableSdPrintingDetection\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"disableSdPrintingDetection\"],",
            "                data[\"serial\"][\"disableSdPrintingDetection\"],",
            "            )",
            "        if \"ackMax\" in data[\"serial\"]:",
            "            s.setInt([\"serial\", \"ackMax\"], data[\"serial\"][\"ackMax\"])",
            "        if \"logPositionOnPause\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"logPositionOnPause\"], data[\"serial\"][\"logPositionOnPause\"]",
            "            )",
            "        if \"logPositionOnCancel\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"logPositionOnCancel\"], data[\"serial\"][\"logPositionOnCancel\"]",
            "            )",
            "        if \"abortHeatupOnCancel\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"abortHeatupOnCancel\"], data[\"serial\"][\"abortHeatupOnCancel\"]",
            "            )",
            "        if \"maxTimeoutsIdle\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"idle\"],",
            "                data[\"serial\"][\"maxTimeoutsIdle\"],",
            "            )",
            "        if \"maxTimeoutsPrinting\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"printing\"],",
            "                data[\"serial\"][\"maxTimeoutsPrinting\"],",
            "            )",
            "        if \"maxTimeoutsLong\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"maxCommunicationTimeouts\", \"long\"],",
            "                data[\"serial\"][\"maxTimeoutsLong\"],",
            "            )",
            "        if \"capAutoreportTemp\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_temp\"],",
            "                data[\"serial\"][\"capAutoreportTemp\"],",
            "            )",
            "        if \"capAutoreportSdStatus\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_sdstatus\"],",
            "                data[\"serial\"][\"capAutoreportSdStatus\"],",
            "            )",
            "        if \"capAutoreportPos\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"autoreport_pos\"],",
            "                data[\"serial\"][\"capAutoreportPos\"],",
            "            )",
            "        if \"capBusyProtocol\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"busy_protocol\"],",
            "                data[\"serial\"][\"capBusyProtocol\"],",
            "            )",
            "        if \"capEmergencyParser\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"emergency_parser\"],",
            "                data[\"serial\"][\"capEmergencyParser\"],",
            "            )",
            "        if \"capExtendedM20\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"extended_m20\"],",
            "                data[\"serial\"][\"capExtendedM20\"],",
            "            ),",
            "        if \"capLfnWrite\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"capabilities\", \"lfn_write\"],",
            "                data[\"serial\"][\"capLfnWrite\"],",
            "            )",
            "        if \"resendRatioThreshold\" in data[\"serial\"]:",
            "            s.setInt(",
            "                [\"serial\", \"resendRatioThreshold\"], data[\"serial\"][\"resendRatioThreshold\"]",
            "            )",
            "        if \"resendRatioStart\" in data[\"serial\"]:",
            "            s.setInt([\"serial\", \"resendRatioStart\"], data[\"serial\"][\"resendRatioStart\"])",
            "        if \"ignoreEmptyPorts\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"ignoreEmptyPorts\"], data[\"serial\"][\"ignoreEmptyPorts\"]",
            "            )",
            "",
            "        if \"encoding\" in data[\"serial\"]:",
            "            s.set([\"serial\", \"encoding\"], data[\"serial\"][\"encoding\"])",
            "",
            "        if \"enableShutdownActionCommand\" in data[\"serial\"]:",
            "            s.setBoolean(",
            "                [\"serial\", \"enableShutdownActionCommand\"],",
            "                data[\"serial\"][\"enableShutdownActionCommand\"],",
            "            )",
            "",
            "        oldLog = s.getBoolean([\"serial\", \"log\"])",
            "        if \"log\" in data[\"serial\"]:",
            "            s.setBoolean([\"serial\", \"log\"], data[\"serial\"][\"log\"])",
            "        if oldLog and not s.getBoolean([\"serial\", \"log\"]):",
            "            # disable debug logging to serial.log",
            "            logging.getLogger(\"SERIAL\").debug(\"Disabling serial logging\")",
            "            logging.getLogger(\"SERIAL\").setLevel(logging.CRITICAL)",
            "        elif not oldLog and s.getBoolean([\"serial\", \"log\"]):",
            "            # enable debug logging to serial.log",
            "            logging.getLogger(\"SERIAL\").setLevel(logging.DEBUG)",
            "            logging.getLogger(\"SERIAL\").debug(\"Enabling serial logging\")",
            "",
            "    if \"temperature\" in data:",
            "        if \"profiles\" in data[\"temperature\"]:",
            "            result = []",
            "            for profile in data[\"temperature\"][\"profiles\"]:",
            "                try:",
            "                    profile[\"bed\"] = int(profile[\"bed\"])",
            "                    profile[\"extruder\"] = int(profile[\"extruder\"])",
            "                except ValueError:",
            "                    pass",
            "                result.append(profile)",
            "            s.set([\"temperature\", \"profiles\"], result)",
            "        if \"cutoff\" in data[\"temperature\"]:",
            "            try:",
            "                cutoff = int(data[\"temperature\"][\"cutoff\"])",
            "                if cutoff > 1:",
            "                    s.setInt([\"temperature\", \"cutoff\"], cutoff)",
            "            except ValueError:",
            "                pass",
            "        if \"sendAutomatically\" in data[\"temperature\"]:",
            "            s.setBoolean(",
            "                [\"temperature\", \"sendAutomatically\"],",
            "                data[\"temperature\"][\"sendAutomatically\"],",
            "            )",
            "        if \"sendAutomaticallyAfter\" in data[\"temperature\"]:",
            "            s.setInt(",
            "                [\"temperature\", \"sendAutomaticallyAfter\"],",
            "                data[\"temperature\"][\"sendAutomaticallyAfter\"],",
            "                min=0,",
            "                max=30,",
            "            )",
            "",
            "    if \"terminalFilters\" in data:",
            "        s.set([\"terminalFilters\"], data[\"terminalFilters\"])",
            "",
            "    if \"system\" in data:",
            "        if \"actions\" in data[\"system\"]:",
            "            s.set([\"system\", \"actions\"], data[\"system\"][\"actions\"])",
            "        if \"events\" in data[\"system\"]:",
            "            s.set([\"system\", \"events\"], data[\"system\"][\"events\"])",
            "",
            "    if \"scripts\" in data:",
            "        if \"gcode\" in data[\"scripts\"] and isinstance(data[\"scripts\"][\"gcode\"], dict):",
            "            for name, script in data[\"scripts\"][\"gcode\"].items():",
            "                if name == \"snippets\":",
            "                    continue",
            "                if not isinstance(script, str):",
            "                    continue",
            "                s.saveScript(",
            "                    \"gcode\", name, script.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")",
            "                )",
            "",
            "    if \"server\" in data:",
            "        if \"commands\" in data[\"server\"]:",
            "            if \"systemShutdownCommand\" in data[\"server\"][\"commands\"]:",
            "                s.set(",
            "                    [\"server\", \"commands\", \"systemShutdownCommand\"],",
            "                    data[\"server\"][\"commands\"][\"systemShutdownCommand\"],",
            "                )",
            "            if \"systemRestartCommand\" in data[\"server\"][\"commands\"]:",
            "                s.set(",
            "                    [\"server\", \"commands\", \"systemRestartCommand\"],",
            "                    data[\"server\"][\"commands\"][\"systemRestartCommand\"],",
            "                )",
            "            if \"serverRestartCommand\" in data[\"server\"][\"commands\"]:",
            "                s.set(",
            "                    [\"server\", \"commands\", \"serverRestartCommand\"],",
            "                    data[\"server\"][\"commands\"][\"serverRestartCommand\"],",
            "                )",
            "        if \"diskspace\" in data[\"server\"]:",
            "            if \"warning\" in data[\"server\"][\"diskspace\"]:",
            "                s.setInt(",
            "                    [\"server\", \"diskspace\", \"warning\"],",
            "                    data[\"server\"][\"diskspace\"][\"warning\"],",
            "                )",
            "            if \"critical\" in data[\"server\"][\"diskspace\"]:",
            "                s.setInt(",
            "                    [\"server\", \"diskspace\", \"critical\"],",
            "                    data[\"server\"][\"diskspace\"][\"critical\"],",
            "                )",
            "        if \"onlineCheck\" in data[\"server\"]:",
            "            if \"enabled\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.setBoolean(",
            "                    [\"server\", \"onlineCheck\", \"enabled\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"enabled\"],",
            "                )",
            "            if \"interval\" in data[\"server\"][\"onlineCheck\"]:",
            "                try:",
            "                    interval = int(data[\"server\"][\"onlineCheck\"][\"interval\"])",
            "                    s.setInt([\"server\", \"onlineCheck\", \"interval\"], interval * 60)",
            "                except ValueError:",
            "                    pass",
            "            if \"host\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.set(",
            "                    [\"server\", \"onlineCheck\", \"host\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"host\"],",
            "                )",
            "            if \"port\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.setInt(",
            "                    [\"server\", \"onlineCheck\", \"port\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"port\"],",
            "                )",
            "            if \"name\" in data[\"server\"][\"onlineCheck\"]:",
            "                s.set(",
            "                    [\"server\", \"onlineCheck\", \"name\"],",
            "                    data[\"server\"][\"onlineCheck\"][\"name\"],",
            "                )",
            "        if \"pluginBlacklist\" in data[\"server\"]:",
            "            if \"enabled\" in data[\"server\"][\"pluginBlacklist\"]:",
            "                s.setBoolean(",
            "                    [\"server\", \"pluginBlacklist\", \"enabled\"],",
            "                    data[\"server\"][\"pluginBlacklist\"][\"enabled\"],",
            "                )",
            "            if \"url\" in data[\"server\"][\"pluginBlacklist\"]:",
            "                s.set(",
            "                    [\"server\", \"pluginBlacklist\", \"url\"],",
            "                    data[\"server\"][\"pluginBlacklist\"][\"url\"],",
            "                )",
            "            if \"ttl\" in data[\"server\"][\"pluginBlacklist\"]:",
            "                try:",
            "                    ttl = int(data[\"server\"][\"pluginBlacklist\"][\"ttl\"])",
            "                    s.setInt([\"server\", \"pluginBlacklist\", \"ttl\"], ttl * 60)",
            "                except ValueError:",
            "                    pass",
            "        if \"allowFraming\" in data[\"server\"]:",
            "            s.setBoolean([\"server\", \"allowFraming\"], data[\"server\"][\"allowFraming\"])",
            "",
            "    if \"devel\" in data:",
            "        oldLog = s.getBoolean([\"devel\", \"pluginTimings\"])",
            "        if \"pluginTimings\" in data[\"devel\"]:",
            "            s.setBoolean([\"devel\", \"pluginTimings\"], data[\"devel\"][\"pluginTimings\"])",
            "        if oldLog and not s.getBoolean([\"devel\", \"pluginTimings\"]):",
            "            # disable plugin timing logging to plugintimings.log",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").debug(\"Disabling plugin timings logging\")",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").setLevel(logging.INFO)",
            "        elif not oldLog and s.getBoolean([\"devel\", \"pluginTimings\"]):",
            "            # enable plugin timing logging to plugintimings.log",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").setLevel(logging.DEBUG)",
            "            logging.getLogger(\"PLUGIN_TIMINGS\").debug(\"Enabling plugin timings logging\")",
            "",
            "    if \"slicing\" in data:",
            "        if \"defaultSlicer\" in data[\"slicing\"]:",
            "            s.set([\"slicing\", \"defaultSlicer\"], data[\"slicing\"][\"defaultSlicer\"])",
            "",
            "    if \"plugins\" in data:",
            "        for plugin in octoprint.plugin.plugin_manager().get_implementations(",
            "            octoprint.plugin.SettingsPlugin",
            "        ):",
            "            plugin_id = plugin._identifier",
            "            if plugin_id in data[\"plugins\"]:",
            "                try:",
            "                    plugin.on_settings_save(data[\"plugins\"][plugin_id])",
            "                except TypeError:",
            "                    logger.warning(",
            "                        \"Could not save settings for plugin {name} ({version}). It may have called super(...)\".format(",
            "                            name=plugin._plugin_name, version=plugin._plugin_version",
            "                        )",
            "                    )",
            "                    logger.warning(",
            "                        \"in a way which has issues due to OctoPrint's dynamic reloading after plugin operations.\"",
            "                    )",
            "                    logger.warning(",
            "                        \"Please contact the plugin's author and ask to update the plugin to use a direct call like\"",
            "                    )",
            "                    logger.warning(",
            "                        \"octoprint.plugin.SettingsPlugin.on_settings_save(self, data) instead.\",",
            "                        exc_info=True,",
            "                    )",
            "                except Exception:",
            "                    logger.exception(",
            "                        \"Could not save settings for plugin {name} ({version})\".format(",
            "                            version=plugin._plugin_version, name=plugin._plugin_name",
            "                        ),",
            "                        extra={\"plugin\": plugin._identifier},",
            "                    )",
            "",
            "    s.save(trigger_event=True)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "128": [
                "getSettings"
            ],
            "129": [
                "getSettings"
            ],
            "130": [
                "getSettings"
            ]
        },
        "addLocation": []
    },
    "src/octoprint/server/api/system.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " from octoprint.plugin import plugin_manager"
            },
            "1": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " from octoprint.server import NO_CONTENT"
            },
            "2": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " from octoprint.server.api import api"
            },
            "3": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from octoprint.server.util.flask import get_remote_address, no_firstrun_access"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+from octoprint.server.util.flask import no_firstrun_access"
            },
            "5": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from octoprint.settings import settings as s"
            },
            "6": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " from octoprint.systemcommands import system_command_manager"
            },
            "7": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from octoprint.util.commandline import CommandlineCaller"
            },
            "8": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 96,
                "PatchRowcode": " @Permissions.SYSTEM.require(403)"
            },
            "9": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 97,
                "PatchRowcode": " def performSystemAction():"
            },
            "10": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "     logging.getLogger(__name__).warning("
            },
            "11": {
                "beforePatchRowNumber": 99,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        \"Deprecated API call to /api/system made by {}, should be migrated to use /system/commands/custom/<action>\".format("
            },
            "12": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            get_remote_address(request)"
            },
            "13": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        )"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+        f\"Deprecated API call to /api/system made by {request.remote_addr}, should be migrated to use /system/commands/custom/<action>\""
            },
            "15": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 100,
                "PatchRowcode": "     )"
            },
            "16": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 101,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 102,
                "PatchRowcode": "     data = request.get_json(silent=True)"
            }
        },
        "frontPatchFile": [
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2015 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import collections",
            "import logging",
            "import re",
            "import threading",
            "",
            "import psutil",
            "from flask import abort, jsonify, request, url_for",
            "from flask_babel import gettext",
            "",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.logging import prefix_multilines",
            "from octoprint.plugin import plugin_manager",
            "from octoprint.server import NO_CONTENT",
            "from octoprint.server.api import api",
            "from octoprint.server.util.flask import get_remote_address, no_firstrun_access",
            "from octoprint.settings import settings as s",
            "from octoprint.systemcommands import system_command_manager",
            "from octoprint.util.commandline import CommandlineCaller",
            "",
            "",
            "@api.route(\"/system/usage\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def readUsageForFolders():",
            "    return jsonify(usage=_usageForFolders())",
            "",
            "",
            "@api.route(\"/system/info\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def getSystemInfo():",
            "    from octoprint.cli.systeminfo import get_systeminfo",
            "    from octoprint.server import (",
            "        connectivityChecker,",
            "        environmentDetector,",
            "        printer,",
            "        safe_mode,",
            "    )",
            "    from octoprint.util import dict_flatten",
            "",
            "    systeminfo = get_systeminfo(",
            "        environmentDetector,",
            "        connectivityChecker,",
            "        s(),",
            "        {",
            "            \"browser.user_agent\": request.headers.get(\"User-Agent\"),",
            "            \"octoprint.safe_mode\": safe_mode is not None,",
            "            \"systeminfo.generator\": \"systemapi\",",
            "        },",
            "    )",
            "",
            "    if printer and printer.is_operational():",
            "        firmware_info = printer.firmware_info",
            "        if firmware_info:",
            "            systeminfo.update(",
            "                dict_flatten({\"firmware\": firmware_info[\"name\"]}, prefix=\"printer\")",
            "            )",
            "",
            "    return jsonify(systeminfo=systeminfo)",
            "",
            "",
            "@api.route(\"/system/startup\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def getStartupInformation():",
            "    from octoprint.server import safe_mode",
            "    from octoprint.settings import settings",
            "",
            "    result = {}",
            "",
            "    if safe_mode is not None:",
            "        result[\"safe_mode\"] = safe_mode",
            "",
            "    flagged_basefolders = settings().flagged_basefolders",
            "    if flagged_basefolders:",
            "        result[\"flagged_basefolders\"] = flagged_basefolders",
            "",
            "    return jsonify(startup=result)",
            "",
            "",
            "def _usageForFolders():",
            "    data = {}",
            "    for folder_name in s().get([\"folder\"]).keys():",
            "        path = s().getBaseFolder(folder_name, check_writable=False)",
            "        if path is not None:",
            "            usage = psutil.disk_usage(path)",
            "            data[folder_name] = {\"free\": usage.free, \"total\": usage.total}",
            "    return data",
            "",
            "",
            "@api.route(\"/system\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def performSystemAction():",
            "    logging.getLogger(__name__).warning(",
            "        \"Deprecated API call to /api/system made by {}, should be migrated to use /system/commands/custom/<action>\".format(",
            "            get_remote_address(request)",
            "        )",
            "    )",
            "",
            "    data = request.get_json(silent=True)",
            "    if data is None:",
            "        data = request.values",
            "",
            "    if \"action\" not in data:",
            "        abort(400, description=\"action is missing\")",
            "",
            "    return executeSystemCommand(\"custom\", data[\"action\"])",
            "",
            "",
            "@api.route(\"/system/commands\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def retrieveSystemCommands():",
            "    return jsonify(",
            "        core=_to_client_specs(_get_core_command_specs()),",
            "        plugin=_to_client_specs(_get_plugin_command_specs()),",
            "        custom=_to_client_specs(_get_custom_command_specs()),",
            "    )",
            "",
            "",
            "@api.route(\"/system/commands/<string:source>\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def retrieveSystemCommandsForSource(source):",
            "    if source == \"core\":",
            "        specs = _get_core_command_specs()",
            "    elif source == \"custom\":",
            "        specs = _get_custom_command_specs()",
            "    elif source == \"plugin\":",
            "        specs = _get_plugin_command_specs()",
            "    else:",
            "        abort(404)",
            "",
            "    return jsonify(_to_client_specs(specs))",
            "",
            "",
            "@api.route(\"/system/commands/<string:source>/<string:command>\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def executeSystemCommand(source, command):",
            "    logger = logging.getLogger(__name__)",
            "",
            "    if command == \"divider\":",
            "        abort(400, description=\"Dividers cannot be executed\")",
            "",
            "    command_spec = _get_command_spec(source, command)",
            "    if not command_spec:",
            "        abort(404)",
            "",
            "    if \"command\" not in command_spec:",
            "        abort(",
            "            500, description=\"Command does not define a command to execute, can't proceed\"",
            "        )",
            "",
            "    do_async = command_spec.get(\"async\", False)",
            "    do_ignore = command_spec.get(\"ignore\", False)",
            "    debug = command_spec.get(\"debug\", False)",
            "",
            "    if logger.isEnabledFor(logging.DEBUG) or debug:",
            "        logger.info(",
            "            \"Performing command for {}:{}: {}\".format(",
            "                source, command, command_spec[\"command\"]",
            "            )",
            "        )",
            "    else:",
            "        logger.info(f\"Performing command for {source}:{command}\")",
            "",
            "    try:",
            "        if \"before\" in command_spec and callable(command_spec[\"before\"]):",
            "            command_spec[\"before\"]()",
            "    except Exception as e:",
            "        if not do_ignore:",
            "            error = f'Command \"before\" for {source}:{command} failed: {e}'",
            "            logger.warning(error)",
            "            abort(500, description=error)",
            "",
            "    try:",
            "",
            "        def execute():",
            "            # we run this with shell=True since we have to trust whatever",
            "            # our admin configured as command and since we want to allow",
            "            # shell-alike handling here...",
            "            return_code, stdout_lines, stderr_lines = CommandlineCaller().call(",
            "                command_spec[\"command\"], shell=True",
            "            )",
            "",
            "            if not do_ignore and return_code != 0:",
            "                stdout = \"\\n\".join(stdout_lines)",
            "                stderr = \"\\n\".join(stderr_lines)",
            "                error = f\"Command for {source}:{command} failed with return code {return_code}:\\n\\nSTDOUT:\\n{stdout}\\n\\nSTDERR:\\n{stderr}\"",
            "                logger.warning(prefix_multilines(error, prefix=\"! \"))",
            "                if not do_async:",
            "                    raise CommandFailed(error)",
            "",
            "        if do_async:",
            "            thread = threading.Thread(target=execute)",
            "            thread.daemon = True",
            "            thread.start()",
            "",
            "        else:",
            "            try:",
            "                execute()",
            "            except CommandFailed as exc:",
            "                abort(500, exc.error)",
            "",
            "    except Exception as e:",
            "        if not do_ignore:",
            "            error = f\"Command for {source}:{command} failed: {e}\"",
            "            logger.warning(error)",
            "            abort(500, error)",
            "",
            "    return NO_CONTENT",
            "",
            "",
            "def _to_client_specs(specs):",
            "    result = list()",
            "    for spec in specs.values():",
            "        if \"action\" not in spec or \"source\" not in spec:",
            "            continue",
            "        copied = {",
            "            k: v for k, v in spec.items() if k in (\"source\", \"action\", \"name\", \"confirm\")",
            "        }",
            "        copied[\"resource\"] = url_for(",
            "            \".executeSystemCommand\",",
            "            source=spec[\"source\"],",
            "            command=spec[\"action\"],",
            "            _external=True,",
            "        )",
            "        result.append(copied)",
            "    return result",
            "",
            "",
            "def _get_command_spec(source, action):",
            "    if source == \"core\":",
            "        return _get_core_command_spec(action)",
            "    elif source == \"custom\":",
            "        return _get_custom_command_spec(action)",
            "    elif source == \"plugin\":",
            "        return _get_plugin_command_spec(action)",
            "    else:",
            "        return None",
            "",
            "",
            "def _get_core_command_specs():",
            "    def enable_safe_mode():",
            "        s().set([\"server\", \"startOnceInSafeMode\"], True)",
            "        s().save()",
            "",
            "    commands = collections.OrderedDict(",
            "        shutdown={",
            "            \"command\": system_command_manager().get_system_shutdown_command(),",
            "            \"name\": gettext(\"Shutdown system\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to shutdown the system.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "        },",
            "        reboot={",
            "            \"command\": system_command_manager().get_system_restart_command(),",
            "            \"name\": gettext(\"Reboot system\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to reboot the system.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "        },",
            "        restart={",
            "            \"command\": system_command_manager().get_server_restart_command(),",
            "            \"name\": gettext(\"Restart OctoPrint\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to restart the OctoPrint server.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "        },",
            "        restart_safe={",
            "            \"command\": system_command_manager().get_server_restart_command(),",
            "            \"name\": gettext(\"Restart OctoPrint in safe mode\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to restart the OctoPrint server in safe mode.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "            \"before\": enable_safe_mode,",
            "        },",
            "    )",
            "",
            "    available_commands = collections.OrderedDict()",
            "    for action, spec in commands.items():",
            "        if not spec[\"command\"]:",
            "            continue",
            "        spec.update({\"action\": action, \"source\": \"core\", \"async\": True, \"debug\": True})",
            "        available_commands[action] = spec",
            "    return available_commands",
            "",
            "",
            "def _get_core_command_spec(action):",
            "    available_actions = _get_core_command_specs()",
            "    if action not in available_actions:",
            "        logging.getLogger(__name__).warning(",
            "            \"Command for core action {} is not configured, you need to configure the command before it can be used\".format(",
            "                action",
            "            )",
            "        )",
            "        return None",
            "",
            "    return available_actions[action]",
            "",
            "",
            "_plugin_action_regex = re.compile(r\"[a-z0-9_-]+\")",
            "",
            "",
            "def _get_plugin_command_specs(plugin=None):",
            "    specs = collections.OrderedDict()",
            "",
            "    hooks = plugin_manager().get_hooks(\"octoprint.system.additional_commands\")",
            "    if plugin is not None:",
            "        if plugin in hooks:",
            "            hooks = {plugin: hooks[plugin]}",
            "        else:",
            "            hooks = {}",
            "",
            "    for name, hook in hooks.items():",
            "        try:",
            "            plugin_specs = hook()",
            "            for spec in plugin_specs:",
            "                action = spec.get(\"action\")",
            "                if (",
            "                    not action",
            "                    or action == \"divider\"",
            "                    or not _plugin_action_regex.match(action)",
            "                ):",
            "                    continue",
            "                action = name.lower() + \":\" + action",
            "",
            "                copied = dict(spec)",
            "                copied[\"source\"] = \"plugin\"",
            "                copied[\"action\"] = action",
            "                specs[action] = copied",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                f\"Error while fetching additional actions from plugin {name}\",",
            "                extra={\"plugin\": name},",
            "            )",
            "    return specs",
            "",
            "",
            "def _get_plugin_command_spec(action):",
            "    plugin = action.split(\":\", 1)[0]",
            "    available_actions = _get_plugin_command_specs(plugin=plugin)",
            "    return available_actions.get(action)",
            "",
            "",
            "def _get_custom_command_specs():",
            "    specs = collections.OrderedDict()",
            "    dividers = 0",
            "    for spec in s().get([\"system\", \"actions\"]):",
            "        if \"action\" not in spec:",
            "            continue",
            "        copied = dict(spec)",
            "        copied[\"source\"] = \"custom\"",
            "",
            "        action = spec[\"action\"]",
            "        if action == \"divider\":",
            "            dividers += 1",
            "            action = f\"divider_{dividers}\"",
            "        specs[action] = copied",
            "    return specs",
            "",
            "",
            "def _get_custom_command_spec(action):",
            "    available_actions = _get_custom_command_specs()",
            "    return available_actions.get(action)",
            "",
            "",
            "class CommandFailed(Exception):",
            "    def __init__(self, error):",
            "        self.error = error"
        ],
        "afterPatchFile": [
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2015 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import collections",
            "import logging",
            "import re",
            "import threading",
            "",
            "import psutil",
            "from flask import abort, jsonify, request, url_for",
            "from flask_babel import gettext",
            "",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.logging import prefix_multilines",
            "from octoprint.plugin import plugin_manager",
            "from octoprint.server import NO_CONTENT",
            "from octoprint.server.api import api",
            "from octoprint.server.util.flask import no_firstrun_access",
            "from octoprint.settings import settings as s",
            "from octoprint.systemcommands import system_command_manager",
            "from octoprint.util.commandline import CommandlineCaller",
            "",
            "",
            "@api.route(\"/system/usage\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def readUsageForFolders():",
            "    return jsonify(usage=_usageForFolders())",
            "",
            "",
            "@api.route(\"/system/info\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def getSystemInfo():",
            "    from octoprint.cli.systeminfo import get_systeminfo",
            "    from octoprint.server import (",
            "        connectivityChecker,",
            "        environmentDetector,",
            "        printer,",
            "        safe_mode,",
            "    )",
            "    from octoprint.util import dict_flatten",
            "",
            "    systeminfo = get_systeminfo(",
            "        environmentDetector,",
            "        connectivityChecker,",
            "        s(),",
            "        {",
            "            \"browser.user_agent\": request.headers.get(\"User-Agent\"),",
            "            \"octoprint.safe_mode\": safe_mode is not None,",
            "            \"systeminfo.generator\": \"systemapi\",",
            "        },",
            "    )",
            "",
            "    if printer and printer.is_operational():",
            "        firmware_info = printer.firmware_info",
            "        if firmware_info:",
            "            systeminfo.update(",
            "                dict_flatten({\"firmware\": firmware_info[\"name\"]}, prefix=\"printer\")",
            "            )",
            "",
            "    return jsonify(systeminfo=systeminfo)",
            "",
            "",
            "@api.route(\"/system/startup\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def getStartupInformation():",
            "    from octoprint.server import safe_mode",
            "    from octoprint.settings import settings",
            "",
            "    result = {}",
            "",
            "    if safe_mode is not None:",
            "        result[\"safe_mode\"] = safe_mode",
            "",
            "    flagged_basefolders = settings().flagged_basefolders",
            "    if flagged_basefolders:",
            "        result[\"flagged_basefolders\"] = flagged_basefolders",
            "",
            "    return jsonify(startup=result)",
            "",
            "",
            "def _usageForFolders():",
            "    data = {}",
            "    for folder_name in s().get([\"folder\"]).keys():",
            "        path = s().getBaseFolder(folder_name, check_writable=False)",
            "        if path is not None:",
            "            usage = psutil.disk_usage(path)",
            "            data[folder_name] = {\"free\": usage.free, \"total\": usage.total}",
            "    return data",
            "",
            "",
            "@api.route(\"/system\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def performSystemAction():",
            "    logging.getLogger(__name__).warning(",
            "        f\"Deprecated API call to /api/system made by {request.remote_addr}, should be migrated to use /system/commands/custom/<action>\"",
            "    )",
            "",
            "    data = request.get_json(silent=True)",
            "    if data is None:",
            "        data = request.values",
            "",
            "    if \"action\" not in data:",
            "        abort(400, description=\"action is missing\")",
            "",
            "    return executeSystemCommand(\"custom\", data[\"action\"])",
            "",
            "",
            "@api.route(\"/system/commands\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def retrieveSystemCommands():",
            "    return jsonify(",
            "        core=_to_client_specs(_get_core_command_specs()),",
            "        plugin=_to_client_specs(_get_plugin_command_specs()),",
            "        custom=_to_client_specs(_get_custom_command_specs()),",
            "    )",
            "",
            "",
            "@api.route(\"/system/commands/<string:source>\", methods=[\"GET\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def retrieveSystemCommandsForSource(source):",
            "    if source == \"core\":",
            "        specs = _get_core_command_specs()",
            "    elif source == \"custom\":",
            "        specs = _get_custom_command_specs()",
            "    elif source == \"plugin\":",
            "        specs = _get_plugin_command_specs()",
            "    else:",
            "        abort(404)",
            "",
            "    return jsonify(_to_client_specs(specs))",
            "",
            "",
            "@api.route(\"/system/commands/<string:source>/<string:command>\", methods=[\"POST\"])",
            "@no_firstrun_access",
            "@Permissions.SYSTEM.require(403)",
            "def executeSystemCommand(source, command):",
            "    logger = logging.getLogger(__name__)",
            "",
            "    if command == \"divider\":",
            "        abort(400, description=\"Dividers cannot be executed\")",
            "",
            "    command_spec = _get_command_spec(source, command)",
            "    if not command_spec:",
            "        abort(404)",
            "",
            "    if \"command\" not in command_spec:",
            "        abort(",
            "            500, description=\"Command does not define a command to execute, can't proceed\"",
            "        )",
            "",
            "    do_async = command_spec.get(\"async\", False)",
            "    do_ignore = command_spec.get(\"ignore\", False)",
            "    debug = command_spec.get(\"debug\", False)",
            "",
            "    if logger.isEnabledFor(logging.DEBUG) or debug:",
            "        logger.info(",
            "            \"Performing command for {}:{}: {}\".format(",
            "                source, command, command_spec[\"command\"]",
            "            )",
            "        )",
            "    else:",
            "        logger.info(f\"Performing command for {source}:{command}\")",
            "",
            "    try:",
            "        if \"before\" in command_spec and callable(command_spec[\"before\"]):",
            "            command_spec[\"before\"]()",
            "    except Exception as e:",
            "        if not do_ignore:",
            "            error = f'Command \"before\" for {source}:{command} failed: {e}'",
            "            logger.warning(error)",
            "            abort(500, description=error)",
            "",
            "    try:",
            "",
            "        def execute():",
            "            # we run this with shell=True since we have to trust whatever",
            "            # our admin configured as command and since we want to allow",
            "            # shell-alike handling here...",
            "            return_code, stdout_lines, stderr_lines = CommandlineCaller().call(",
            "                command_spec[\"command\"], shell=True",
            "            )",
            "",
            "            if not do_ignore and return_code != 0:",
            "                stdout = \"\\n\".join(stdout_lines)",
            "                stderr = \"\\n\".join(stderr_lines)",
            "                error = f\"Command for {source}:{command} failed with return code {return_code}:\\n\\nSTDOUT:\\n{stdout}\\n\\nSTDERR:\\n{stderr}\"",
            "                logger.warning(prefix_multilines(error, prefix=\"! \"))",
            "                if not do_async:",
            "                    raise CommandFailed(error)",
            "",
            "        if do_async:",
            "            thread = threading.Thread(target=execute)",
            "            thread.daemon = True",
            "            thread.start()",
            "",
            "        else:",
            "            try:",
            "                execute()",
            "            except CommandFailed as exc:",
            "                abort(500, exc.error)",
            "",
            "    except Exception as e:",
            "        if not do_ignore:",
            "            error = f\"Command for {source}:{command} failed: {e}\"",
            "            logger.warning(error)",
            "            abort(500, error)",
            "",
            "    return NO_CONTENT",
            "",
            "",
            "def _to_client_specs(specs):",
            "    result = list()",
            "    for spec in specs.values():",
            "        if \"action\" not in spec or \"source\" not in spec:",
            "            continue",
            "        copied = {",
            "            k: v for k, v in spec.items() if k in (\"source\", \"action\", \"name\", \"confirm\")",
            "        }",
            "        copied[\"resource\"] = url_for(",
            "            \".executeSystemCommand\",",
            "            source=spec[\"source\"],",
            "            command=spec[\"action\"],",
            "            _external=True,",
            "        )",
            "        result.append(copied)",
            "    return result",
            "",
            "",
            "def _get_command_spec(source, action):",
            "    if source == \"core\":",
            "        return _get_core_command_spec(action)",
            "    elif source == \"custom\":",
            "        return _get_custom_command_spec(action)",
            "    elif source == \"plugin\":",
            "        return _get_plugin_command_spec(action)",
            "    else:",
            "        return None",
            "",
            "",
            "def _get_core_command_specs():",
            "    def enable_safe_mode():",
            "        s().set([\"server\", \"startOnceInSafeMode\"], True)",
            "        s().save()",
            "",
            "    commands = collections.OrderedDict(",
            "        shutdown={",
            "            \"command\": system_command_manager().get_system_shutdown_command(),",
            "            \"name\": gettext(\"Shutdown system\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to shutdown the system.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "        },",
            "        reboot={",
            "            \"command\": system_command_manager().get_system_restart_command(),",
            "            \"name\": gettext(\"Reboot system\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to reboot the system.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "        },",
            "        restart={",
            "            \"command\": system_command_manager().get_server_restart_command(),",
            "            \"name\": gettext(\"Restart OctoPrint\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to restart the OctoPrint server.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "        },",
            "        restart_safe={",
            "            \"command\": system_command_manager().get_server_restart_command(),",
            "            \"name\": gettext(\"Restart OctoPrint in safe mode\"),",
            "            \"confirm\": gettext(",
            "                \"<strong>You are about to restart the OctoPrint server in safe mode.</strong></p><p>This action may disrupt any ongoing print jobs (depending on your printer's controller and general setup that might also apply to prints run directly from your printer's internal storage).\"",
            "            ),",
            "            \"before\": enable_safe_mode,",
            "        },",
            "    )",
            "",
            "    available_commands = collections.OrderedDict()",
            "    for action, spec in commands.items():",
            "        if not spec[\"command\"]:",
            "            continue",
            "        spec.update({\"action\": action, \"source\": \"core\", \"async\": True, \"debug\": True})",
            "        available_commands[action] = spec",
            "    return available_commands",
            "",
            "",
            "def _get_core_command_spec(action):",
            "    available_actions = _get_core_command_specs()",
            "    if action not in available_actions:",
            "        logging.getLogger(__name__).warning(",
            "            \"Command for core action {} is not configured, you need to configure the command before it can be used\".format(",
            "                action",
            "            )",
            "        )",
            "        return None",
            "",
            "    return available_actions[action]",
            "",
            "",
            "_plugin_action_regex = re.compile(r\"[a-z0-9_-]+\")",
            "",
            "",
            "def _get_plugin_command_specs(plugin=None):",
            "    specs = collections.OrderedDict()",
            "",
            "    hooks = plugin_manager().get_hooks(\"octoprint.system.additional_commands\")",
            "    if plugin is not None:",
            "        if plugin in hooks:",
            "            hooks = {plugin: hooks[plugin]}",
            "        else:",
            "            hooks = {}",
            "",
            "    for name, hook in hooks.items():",
            "        try:",
            "            plugin_specs = hook()",
            "            for spec in plugin_specs:",
            "                action = spec.get(\"action\")",
            "                if (",
            "                    not action",
            "                    or action == \"divider\"",
            "                    or not _plugin_action_regex.match(action)",
            "                ):",
            "                    continue",
            "                action = name.lower() + \":\" + action",
            "",
            "                copied = dict(spec)",
            "                copied[\"source\"] = \"plugin\"",
            "                copied[\"action\"] = action",
            "                specs[action] = copied",
            "        except Exception:",
            "            logging.getLogger(__name__).exception(",
            "                f\"Error while fetching additional actions from plugin {name}\",",
            "                extra={\"plugin\": name},",
            "            )",
            "    return specs",
            "",
            "",
            "def _get_plugin_command_spec(action):",
            "    plugin = action.split(\":\", 1)[0]",
            "    available_actions = _get_plugin_command_specs(plugin=plugin)",
            "    return available_actions.get(action)",
            "",
            "",
            "def _get_custom_command_specs():",
            "    specs = collections.OrderedDict()",
            "    dividers = 0",
            "    for spec in s().get([\"system\", \"actions\"]):",
            "        if \"action\" not in spec:",
            "            continue",
            "        copied = dict(spec)",
            "        copied[\"source\"] = \"custom\"",
            "",
            "        action = spec[\"action\"]",
            "        if action == \"divider\":",
            "            dividers += 1",
            "            action = f\"divider_{dividers}\"",
            "        specs[action] = copied",
            "    return specs",
            "",
            "",
            "def _get_custom_command_spec(action):",
            "    available_actions = _get_custom_command_specs()",
            "    return available_actions.get(action)",
            "",
            "",
            "class CommandFailed(Exception):",
            "    def __init__(self, error):",
            "        self.error = error"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "18": [],
            "99": [
                "performSystemAction"
            ],
            "100": [
                "performSystemAction"
            ],
            "101": [
                "performSystemAction"
            ]
        },
        "addLocation": []
    },
    "src/octoprint/server/util/flask.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " import threading"
            },
            "1": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import time"
            },
            "2": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " from datetime import datetime, timedelta, timezone"
            },
            "3": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from typing import Any, Union"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 15,
                "PatchRowcode": "+from typing import Any, Dict, List, Union"
            },
            "5": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import flask"
            },
            "7": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " import flask.json"
            },
            "8": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " from flask import current_app"
            },
            "9": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 30,
                "PatchRowcode": " from flask_login import COOKIE_NAME as REMEMBER_COOKIE_NAME"
            },
            "10": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " from flask_login.utils import decode_cookie, encode_cookie"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+from pydantic import BaseModel"
            },
            "12": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " from werkzeug.local import LocalProxy"
            },
            "13": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " from werkzeug.utils import cached_property"
            },
            "14": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 666,
                "afterPatchRowNumber": 667,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 667,
                "afterPatchRowNumber": 668,
                "PatchRowcode": "     user = flask_login.current_user"
            },
            "17": {
                "beforePatchRowNumber": 668,
                "afterPatchRowNumber": 669,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 669,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    remote_address = get_remote_address(flask.request)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 670,
                "PatchRowcode": "+    remote_address = flask.request.remote_addr"
            },
            "20": {
                "beforePatchRowNumber": 670,
                "afterPatchRowNumber": 671,
                "PatchRowcode": "     ip_check_enabled = settings().getBoolean([\"server\", \"ipCheck\", \"enabled\"])"
            },
            "21": {
                "beforePatchRowNumber": 671,
                "afterPatchRowNumber": 672,
                "PatchRowcode": "     ip_check_trusted = settings().get([\"server\", \"ipCheck\", \"trustedSubnets\"])"
            },
            "22": {
                "beforePatchRowNumber": 672,
                "afterPatchRowNumber": 673,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 1713,
                "afterPatchRowNumber": 1714,
                "PatchRowcode": "     return decorated_view"
            },
            "24": {
                "beforePatchRowNumber": 1714,
                "afterPatchRowNumber": 1715,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 1715,
                "afterPatchRowNumber": 1716,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1717,
                "PatchRowcode": "+@deprecated("
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1718,
                "PatchRowcode": "+    \"get_remote_address is no longer required and deprecated, you can just use flask.request.remote_addr instead\","
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1719,
                "PatchRowcode": "+    since=\"1.10.0\","
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1720,
                "PatchRowcode": "+)"
            },
            "30": {
                "beforePatchRowNumber": 1716,
                "afterPatchRowNumber": 1721,
                "PatchRowcode": " def get_remote_address(request):"
            },
            "31": {
                "beforePatchRowNumber": 1717,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    forwardedFor = request.headers.get(\"X-Forwarded-For\", None)"
            },
            "32": {
                "beforePatchRowNumber": 1718,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if forwardedFor is not None:"
            },
            "33": {
                "beforePatchRowNumber": 1719,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return forwardedFor.split(\",\")[0]"
            },
            "34": {
                "beforePatchRowNumber": 1720,
                "afterPatchRowNumber": 1722,
                "PatchRowcode": "     return request.remote_addr"
            },
            "35": {
                "beforePatchRowNumber": 1721,
                "afterPatchRowNumber": 1723,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": 1722,
                "afterPatchRowNumber": 1724,
                "PatchRowcode": " "
            },
            "37": {
                "beforePatchRowNumber": 2012,
                "afterPatchRowNumber": 2014,
                "PatchRowcode": " def validate_session_signature(sig, user, session):"
            },
            "38": {
                "beforePatchRowNumber": 2013,
                "afterPatchRowNumber": 2015,
                "PatchRowcode": "     user_sig = session_signature(user, session)"
            },
            "39": {
                "beforePatchRowNumber": 2014,
                "afterPatchRowNumber": 2016,
                "PatchRowcode": "     return len(user_sig) == len(sig) and hmac.compare_digest(sig, user_sig)"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2017,
                "PatchRowcode": "+"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2018,
                "PatchRowcode": "+"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2019,
                "PatchRowcode": "+##~~ Reverse proxy info"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2020,
                "PatchRowcode": "+"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2021,
                "PatchRowcode": "+"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2022,
                "PatchRowcode": "+class ReverseProxyInfo(BaseModel):"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2023,
                "PatchRowcode": "+    client_ip: str"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2024,
                "PatchRowcode": "+    server_protocol: str"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2025,
                "PatchRowcode": "+    server_name: str"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2026,
                "PatchRowcode": "+    server_port: int"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2027,
                "PatchRowcode": "+    server_path: str"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2028,
                "PatchRowcode": "+    cookie_suffix: str"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2029,
                "PatchRowcode": "+    trusted_proxies: List[str] = []"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2030,
                "PatchRowcode": "+    headers: Dict[str, str] = {}"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2031,
                "PatchRowcode": "+"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2032,
                "PatchRowcode": "+"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2033,
                "PatchRowcode": "+def get_reverse_proxy_info():"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2034,
                "PatchRowcode": "+    headers = {}"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2035,
                "PatchRowcode": "+    for header in sorted("
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2036,
                "PatchRowcode": "+        ("
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2037,
                "PatchRowcode": "+            \"X-Forwarded-For\","
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2038,
                "PatchRowcode": "+            \"X-Forwarded-Protocol\","
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2039,
                "PatchRowcode": "+            \"X-Scheme\","
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2040,
                "PatchRowcode": "+            \"X-Forwarded-Host\","
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2041,
                "PatchRowcode": "+            \"X-Forwarded-Port\","
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2042,
                "PatchRowcode": "+            \"X-Forwarded-Server\","
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2043,
                "PatchRowcode": "+            \"Host\","
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2044,
                "PatchRowcode": "+            \"X-Script-Name\","
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2045,
                "PatchRowcode": "+        )"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2046,
                "PatchRowcode": "+    ):"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2047,
                "PatchRowcode": "+        if header in flask.request.headers:"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2048,
                "PatchRowcode": "+            headers[header] = flask.request.headers[header]"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2049,
                "PatchRowcode": "+"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2050,
                "PatchRowcode": "+    trusted_downstreams = settings().get([\"server\", \"reverseProxy\", \"trustedDownstream\"])"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2051,
                "PatchRowcode": "+    if not trusted_downstreams:"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2052,
                "PatchRowcode": "+        trusted_downstreams = []"
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2053,
                "PatchRowcode": "+"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2054,
                "PatchRowcode": "+    return ReverseProxyInfo("
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2055,
                "PatchRowcode": "+        client_ip=flask.request.remote_addr,"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2056,
                "PatchRowcode": "+        server_protocol=flask.request.environ.get(\"wsgi.url_scheme\"),"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2057,
                "PatchRowcode": "+        server_name=flask.request.environ.get(\"SERVER_NAME\"),"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2058,
                "PatchRowcode": "+        server_port=int(flask.request.environ.get(\"SERVER_PORT\")),"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2059,
                "PatchRowcode": "+        server_path=flask.request.script_root if flask.request.script_root else \"/\","
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2060,
                "PatchRowcode": "+        cookie_suffix=get_cookie_suffix(flask.request),"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2061,
                "PatchRowcode": "+        trusted_proxies=trusted_downstreams,"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2062,
                "PatchRowcode": "+        headers=headers,"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2063,
                "PatchRowcode": "+    )"
            }
        },
        "frontPatchFile": [
            "from flask import make_response",
            "",
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import functools",
            "import hashlib",
            "import hmac",
            "import logging",
            "import os",
            "import threading",
            "import time",
            "from datetime import datetime, timedelta, timezone",
            "from typing import Any, Union",
            "",
            "import flask",
            "import flask.json",
            "import flask.json.provider",
            "import flask.sessions",
            "import flask.templating",
            "import flask_assets",
            "import flask_login",
            "import netaddr",
            "import tornado.web",
            "import webassets.updater",
            "import webassets.utils",
            "from cachelib import BaseCache",
            "from flask import current_app",
            "from flask_login import COOKIE_NAME as REMEMBER_COOKIE_NAME",
            "from flask_login.utils import decode_cookie, encode_cookie",
            "from werkzeug.local import LocalProxy",
            "from werkzeug.utils import cached_property",
            "",
            "import octoprint.access.users",
            "import octoprint.plugin",
            "import octoprint.server",
            "import octoprint.vendor.flask_principal as flask_principal",
            "from octoprint.access import auth_log",
            "from octoprint.events import Events, eventManager",
            "from octoprint.settings import settings",
            "from octoprint.util import DefaultOrderedDict, deprecated, yaml",
            "from octoprint.util.json import JsonEncoding",
            "from octoprint.util.net import is_lan_address",
            "from octoprint.util.tz import UTC_TZ, is_timezone_aware",
            "",
            "# ~~ monkey patching",
            "",
            "",
            "def enable_additional_translations(default_locale=\"en\", additional_folders=None):",
            "    import os",
            "",
            "    import flask_babel",
            "    from babel import Locale, support",
            "",
            "    if additional_folders is None:",
            "        additional_folders = []",
            "",
            "    logger = logging.getLogger(__name__)",
            "",
            "    def fixed_list_translations(self):",
            "        \"\"\"Returns a list of all the locales translations exist for.  The",
            "        list returned will be filled with actual locale objects and not just",
            "        strings.",
            "        \"\"\"",
            "",
            "        def list_translations(dirname):",
            "            if not os.path.isdir(dirname):",
            "                return []",
            "            result = []",
            "            for entry in os.scandir(dirname):",
            "                locale_dir = os.path.join(entry.path, \"LC_MESSAGES\")",
            "                if not os.path.isdir(locale_dir):",
            "                    continue",
            "                if any(filter(lambda x: x.name.endswith(\".mo\"), os.scandir(locale_dir))):",
            "                    result.append(Locale.parse(entry.name))",
            "            return result",
            "",
            "        dirs = additional_folders + [os.path.join(self.app.root_path, \"translations\")]",
            "",
            "        # translations from plugins",
            "        plugins = octoprint.plugin.plugin_manager().enabled_plugins",
            "        for plugin in plugins.values():",
            "            plugin_translation_dir = os.path.join(plugin.location, \"translations\")",
            "            if not os.path.isdir(plugin_translation_dir):",
            "                continue",
            "            dirs.append(plugin_translation_dir)",
            "",
            "        result = {Locale.parse(default_locale)}",
            "",
            "        for dir in dirs:",
            "            result.update(list_translations(dir))",
            "        return list(result)",
            "",
            "    def fixed_get_translations():",
            "        \"\"\"Returns the correct gettext translations that should be used for",
            "        this request.  This will never fail and return a dummy translation",
            "        object if used outside of the request or if a translation cannot be",
            "        found.",
            "        \"\"\"",
            "        if flask.g is None:",
            "            return None",
            "        translations = getattr(flask.g, \"babel_translations\", None)",
            "        if translations is None:",
            "            locale = flask_babel.get_locale()",
            "            translations = support.Translations()",
            "",
            "            if str(locale) != default_locale:",
            "                # plugin translations",
            "                plugins = octoprint.plugin.plugin_manager().enabled_plugins",
            "                for name, plugin in plugins.items():",
            "                    dirs = list(",
            "                        map(",
            "                            lambda x: os.path.join(x, \"_plugins\", name),",
            "                            additional_folders,",
            "                        )",
            "                    ) + [os.path.join(plugin.location, \"translations\")]",
            "                    for dirname in dirs:",
            "                        if not os.path.isdir(dirname):",
            "                            continue",
            "",
            "                        try:",
            "                            plugin_translations = support.Translations.load(",
            "                                dirname, [locale]",
            "                            )",
            "                        except Exception:",
            "                            logger.exception(",
            "                                f\"Error while trying to load translations \"",
            "                                f\"for plugin {name}\"",
            "                            )",
            "                        else:",
            "                            if isinstance(plugin_translations, support.Translations):",
            "                                translations = translations.merge(plugin_translations)",
            "                                logger.debug(",
            "                                    f\"Using translation plugin folder {dirname} from \"",
            "                                    f\"plugin {name} for locale {locale}\"",
            "                                )",
            "                                break",
            "                    else:",
            "                        logger.debug(",
            "                            f\"No translations for locale {locale} \" f\"from plugin {name}\"",
            "                        )",
            "",
            "                # core translations",
            "                dirs = additional_folders + [",
            "                    os.path.join(flask.current_app.root_path, \"translations\")",
            "                ]",
            "                for dirname in dirs:",
            "                    core_translations = support.Translations.load(dirname, [locale])",
            "                    if isinstance(core_translations, support.Translations):",
            "                        logger.debug(",
            "                            f\"Using translation core folder {dirname} \"",
            "                            f\"for locale {locale}\"",
            "                        )",
            "                        break",
            "                else:",
            "                    logger.debug(f\"No translations for locale {locale} in core folders\")",
            "                translations = translations.merge(core_translations)",
            "",
            "            flask.g.babel_translations = translations",
            "        return translations",
            "",
            "    flask_babel.Babel.list_translations = fixed_list_translations",
            "    flask_babel.get_translations = fixed_get_translations",
            "",
            "",
            "def fix_webassets_filtertool():",
            "    from webassets.merge import FilterTool, MemoryHunk, log",
            "",
            "    error_logger = logging.getLogger(__name__ + \".fix_webassets_filtertool\")",
            "",
            "    def fixed_wrap_cache(self, key, func):",
            "        \"\"\"Return cache value ``key``, or run ``func``.\"\"\"",
            "        if self.cache:",
            "            if not self.no_cache_read:",
            "                log.debug(\"Checking cache for key %s\", key)",
            "                content = self.cache.get(key)",
            "                if content not in (False, None):",
            "                    log.debug(\"Using cached result for %s\", key)",
            "                    return MemoryHunk(content)",
            "",
            "        try:",
            "            content = func().getvalue()",
            "            if self.cache:",
            "                try:",
            "                    log.debug(",
            "                        \"Storing result in cache with key %s\",",
            "                        key,",
            "                    )",
            "                    self.cache.set(key, content)",
            "                except Exception:",
            "                    error_logger.exception(",
            "                        \"Got an exception while trying to save file to cache, not caching\"",
            "                    )",
            "            return MemoryHunk(content)",
            "        except Exception:",
            "            error_logger.exception(",
            "                \"Got an exception while trying to apply filter, ignoring file\"",
            "            )",
            "            return MemoryHunk(\"\")",
            "",
            "    FilterTool._wrap_cache = fixed_wrap_cache",
            "",
            "",
            "def fix_webassets_convert_item_to_flask_url():",
            "    import flask_assets",
            "",
            "    def fixed_convert_item_to_flask_url(self, ctx, item, filepath=None):",
            "        from flask import url_for",
            "",
            "        directory, rel_path, endpoint = self.split_prefix(ctx, item)",
            "",
            "        if filepath is not None:",
            "            filename = filepath[len(directory) + 1 :]",
            "        else:",
            "            filename = rel_path",
            "",
            "        flask_ctx = None",
            "        if not flask.has_request_context():  # fixed, was _request_ctx.top",
            "            flask_ctx = ctx.environment._app.test_request_context()",
            "            flask_ctx.push()",
            "        try:",
            "            url = url_for(endpoint, filename=filename)",
            "            # In some cases, url will be an absolute url with a scheme and hostname.",
            "            # (for example, when using werkzeug's host matching).",
            "            # In general, url_for() will return a http url. During assets build, we",
            "            # we don't know yet if the assets will be served over http, https or both.",
            "            # Let's use // instead. url_for takes a _scheme argument, but only together",
            "            # with external=True, which we do not want to force every time. Further,",
            "            # this _scheme argument is not able to render // - it always forces a colon.",
            "            if url and url.startswith(\"http:\"):",
            "                url = url[5:]",
            "            return url",
            "        finally:",
            "            if flask_ctx:",
            "                flask_ctx.pop()",
            "",
            "    flask_assets.FlaskResolver.convert_item_to_flask_url = fixed_convert_item_to_flask_url",
            "",
            "",
            "# ~~ WSGI environment wrapper for reverse proxying",
            "",
            "",
            "class ReverseProxiedEnvironment:",
            "    @staticmethod",
            "    def to_header_candidates(values):",
            "        if values is None:",
            "            return []",
            "        if not isinstance(values, (list, tuple)):",
            "            values = [values]",
            "        to_wsgi_format = lambda header: \"HTTP_\" + header.upper().replace(\"-\", \"_\")",
            "        return list(map(to_wsgi_format, values))",
            "",
            "    @staticmethod",
            "    def valid_ip(address):",
            "        import netaddr",
            "",
            "        try:",
            "            netaddr.IPAddress(address)",
            "            return True",
            "        except Exception:",
            "            return False",
            "",
            "    def __init__(",
            "        self,",
            "        header_prefix=None,",
            "        header_scheme=None,",
            "        header_host=None,",
            "        header_server=None,",
            "        header_port=None,",
            "        prefix=None,",
            "        scheme=None,",
            "        host=None,",
            "        server=None,",
            "        port=None,",
            "    ):",
            "        # sensible defaults",
            "        if header_prefix is None:",
            "            header_prefix = [\"x-script-name\", \"x-forwarded-prefix\"]",
            "        if header_scheme is None:",
            "            header_scheme = [\"x-forwarded-proto\", \"x-scheme\"]",
            "        if header_host is None:",
            "            header_host = [\"x-forwarded-host\"]",
            "        if header_server is None:",
            "            header_server = [\"x-forwarded-server\"]",
            "        if header_port is None:",
            "            header_port = [\"x-forwarded-port\"]",
            "",
            "        # header candidates",
            "        self._headers_prefix = self.to_header_candidates(header_prefix)",
            "        self._headers_scheme = self.to_header_candidates(header_scheme)",
            "        self._headers_host = self.to_header_candidates(header_host)",
            "        self._headers_server = self.to_header_candidates(header_server)",
            "        self._headers_port = self.to_header_candidates(header_port)",
            "",
            "        # fallback prefix & scheme & host from config",
            "        self._fallback_prefix = prefix",
            "        self._fallback_scheme = scheme",
            "        self._fallback_host = host",
            "        self._fallback_server = server",
            "        self._fallback_port = port",
            "",
            "    def __call__(self, environ):",
            "        def retrieve_header(header_type):",
            "            candidates = getattr(self, \"_headers_\" + header_type, [])",
            "            fallback = getattr(self, \"_fallback_\" + header_type, None)",
            "",
            "            for candidate in candidates:",
            "                value = environ.get(candidate, None)",
            "                if value is not None:",
            "                    return value",
            "            else:",
            "                return fallback",
            "",
            "        def host_to_server_and_port(host, scheme):",
            "            if host is None:",
            "                return None, None",
            "",
            "            default_port = \"443\" if scheme == \"https\" else \"80\"",
            "            host = host.strip()",
            "",
            "            if \":\" in host:",
            "                # we might have an ipv6 address here, or a port, or both",
            "",
            "                if host[0] == \"[\":",
            "                    # that looks like an ipv6 address with port, e.g. [fec1::1]:80",
            "                    address_end = host.find(\"]\")",
            "                    if address_end == -1:",
            "                        # no ], that looks like a seriously broken address",
            "                        return None, None",
            "",
            "                    # extract server ip, skip enclosing [ and ]",
            "                    server = host[1:address_end]",
            "                    tail = host[address_end + 1 :]",
            "",
            "                    # now check if there's also a port",
            "                    if len(tail) and tail[0] == \":\":",
            "                        # port included as well",
            "                        port = tail[1:]",
            "                    else:",
            "                        # no port, use default one",
            "                        port = default_port",
            "",
            "                elif self.__class__.valid_ip(host):",
            "                    # ipv6 address without port",
            "                    server = host",
            "                    port = default_port",
            "",
            "                else:",
            "                    # ipv4 address with port",
            "                    server, port = host.rsplit(\":\", 1)",
            "",
            "            else:",
            "                server = host",
            "                port = default_port",
            "",
            "            return server, port",
            "",
            "        # determine prefix",
            "        prefix = retrieve_header(\"prefix\")",
            "        if prefix is not None:",
            "            environ[\"SCRIPT_NAME\"] = prefix",
            "            path_info = environ[\"PATH_INFO\"]",
            "            if path_info.startswith(prefix):",
            "                environ[\"PATH_INFO\"] = path_info[len(prefix) :]",
            "",
            "        # determine scheme",
            "        scheme = retrieve_header(\"scheme\")",
            "        if scheme is not None and \",\" in scheme:",
            "            # Scheme might be something like \"https,https\" if doubly-reverse-proxied",
            "            # without stripping original scheme header first, make sure to only use",
            "            # the first entry in such a case. See #1391.",
            "            scheme, _ = map(lambda x: x.strip(), scheme.split(\",\", 1))",
            "        if scheme is not None:",
            "            environ[\"wsgi.url_scheme\"] = scheme",
            "",
            "        # determine host",
            "        url_scheme = environ[\"wsgi.url_scheme\"]",
            "        host = retrieve_header(\"host\")",
            "        if host is not None:",
            "            # if we have a host, we take server_name and server_port from it",
            "            server, port = host_to_server_and_port(host, url_scheme)",
            "            environ[\"HTTP_HOST\"] = host",
            "            environ[\"SERVER_NAME\"] = server",
            "            environ[\"SERVER_PORT\"] = port",
            "",
            "        elif environ.get(\"HTTP_HOST\", None) is not None:",
            "            # if we have a Host header, we use that and make sure our server name and port properties match it",
            "            host = environ[\"HTTP_HOST\"]",
            "            server, port = host_to_server_and_port(host, url_scheme)",
            "            environ[\"SERVER_NAME\"] = server",
            "            environ[\"SERVER_PORT\"] = port",
            "",
            "        else:",
            "            # else we take a look at the server and port headers and if we have",
            "            # something there we derive the host from it",
            "",
            "            # determine server - should usually not be used",
            "            server = retrieve_header(\"server\")",
            "            if server is not None:",
            "                environ[\"SERVER_NAME\"] = server",
            "",
            "            # determine port - should usually not be used",
            "            port = retrieve_header(\"port\")",
            "            if port is not None:",
            "                environ[\"SERVER_PORT\"] = port",
            "",
            "            # reconstruct host header",
            "            if (",
            "                url_scheme == \"http\"",
            "                and environ[\"SERVER_PORT\"] == \"80\"",
            "                or url_scheme == \"https\"",
            "                and environ[\"SERVER_PORT\"] == \"443\"",
            "            ):",
            "                # default port for scheme, can be skipped",
            "                environ[\"HTTP_HOST\"] = environ[\"SERVER_NAME\"]",
            "            else:",
            "                server_name_component = environ[\"SERVER_NAME\"]",
            "                if \":\" in server_name_component and self.__class__.valid_ip(",
            "                    server_name_component",
            "                ):",
            "                    # this is an ipv6 address, we need to wrap that in [ and ] before appending the port",
            "                    server_name_component = \"[\" + server_name_component + \"]\"",
            "",
            "                environ[\"HTTP_HOST\"] = (",
            "                    server_name_component + \":\" + environ[\"SERVER_PORT\"]",
            "                )",
            "",
            "        # call wrapped app with rewritten environment",
            "        return environ",
            "",
            "",
            "# ~~ request and response versions",
            "",
            "",
            "def encode_remember_me_cookie(value):",
            "    from octoprint.server import userManager",
            "",
            "    name = value.split(\"|\")[0]",
            "    try:",
            "        remember_key = userManager.signature_key_for_user(",
            "            name, current_app.config[\"SECRET_KEY\"]",
            "        )",
            "        timestamp = datetime.utcnow().timestamp()",
            "        return encode_cookie(f\"{name}|{timestamp}\", key=remember_key)",
            "    except Exception:",
            "        pass",
            "",
            "    return \"\"",
            "",
            "",
            "def decode_remember_me_cookie(value):",
            "    from octoprint.server import userManager",
            "",
            "    parts = value.split(\"|\")",
            "    if len(parts) == 3:",
            "        name, created, _ = parts",
            "",
            "        try:",
            "            # valid signature?",
            "            signature_key = userManager.signature_key_for_user(",
            "                name, current_app.config[\"SECRET_KEY\"]",
            "            )",
            "            cookie = decode_cookie(value, key=signature_key)",
            "            if cookie:",
            "                # still valid?",
            "                if (",
            "                    datetime.fromtimestamp(float(created))",
            "                    + timedelta(seconds=current_app.config[\"REMEMBER_COOKIE_DURATION\"])",
            "                    > datetime.utcnow()",
            "                ):",
            "                    return encode_cookie(name)",
            "        except Exception:",
            "            pass",
            "",
            "    raise ValueError(\"Invalid remember me cookie\")",
            "",
            "",
            "def get_cookie_suffix(request):",
            "    \"\"\"",
            "    Request specific suffix for set and read cookies",
            "",
            "    We need this because cookies are not port-specific and we don't want to overwrite our",
            "    session and other cookies from one OctoPrint instance on our machine with those of another",
            "    one who happens to listen on the same address albeit a different port or script root.",
            "    \"\"\"",
            "    result = \"_P\" + request.server_port",
            "    if request.script_root:",
            "        return result + \"_R\" + request.script_root.replace(\"/\", \"|\")",
            "    return result",
            "",
            "",
            "class OctoPrintFlaskRequest(flask.Request):",
            "    environment_wrapper = staticmethod(lambda x: x)",
            "",
            "    def __init__(self, environ, *args, **kwargs):",
            "        # apply environment wrapper to provided WSGI environment",
            "        flask.Request.__init__(self, self.environment_wrapper(environ), *args, **kwargs)",
            "",
            "    @cached_property",
            "    def cookies(self):",
            "        # strip cookie_suffix from all cookies in the request, return result",
            "        cookies = flask.Request.cookies.__get__(self)",
            "",
            "        result = {}",
            "        desuffixed = {}",
            "        for key, value in cookies.items():",
            "",
            "            def process_value(k, v):",
            "                if k == current_app.config.get(",
            "                    \"REMEMBER_COOKIE_NAME\", REMEMBER_COOKIE_NAME",
            "                ):",
            "                    return decode_remember_me_cookie(v)",
            "                return v",
            "",
            "            try:",
            "                if key.endswith(self.cookie_suffix):",
            "                    key = key[: -len(self.cookie_suffix)]",
            "                    desuffixed[key] = process_value(key, value)",
            "                else:",
            "                    result[key] = process_value(key, value)",
            "            except ValueError:",
            "                # ignore broken cookies",
            "                pass",
            "",
            "        result.update(desuffixed)",
            "        return result",
            "",
            "    @cached_property",
            "    def server_name(self):",
            "        \"\"\"Short cut to the request's server name header\"\"\"",
            "        return self.environ.get(\"SERVER_NAME\")",
            "",
            "    @cached_property",
            "    def server_port(self):",
            "        \"\"\"Short cut to the request's server port header\"\"\"",
            "        return self.environ.get(\"SERVER_PORT\")",
            "",
            "    @cached_property",
            "    def cookie_suffix(self):",
            "        return get_cookie_suffix(self)",
            "",
            "",
            "class OctoPrintFlaskResponse(flask.Response):",
            "    def set_cookie(self, key, value=\"\", *args, **kwargs):",
            "        # restrict cookie path to script root",
            "        kwargs[\"path\"] = flask.request.script_root + kwargs.get(\"path\", \"/\")",
            "",
            "        # set same-site header",
            "        samesite = settings().get([\"server\", \"cookies\", \"samesite\"])",
            "        if samesite is not None:",
            "            samesite = samesite.lower()",
            "        if samesite == \"none\":",
            "            # Must be string \"None\"",
            "            samesite = \"None\"",
            "        if samesite not in (\"None\", \"strict\", \"lax\"):",
            "            # If NoneType, the cookie is not set",
            "            samesite = None",
            "        kwargs[\"samesite\"] = samesite",
            "",
            "        # set secure if necessary",
            "        kwargs[\"secure\"] = flask.request.environ.get(",
            "            \"wsgi.url_scheme\"",
            "        ) == \"https\" or settings().getBoolean([\"server\", \"cookies\", \"secure\"])",
            "",
            "        # tie account properties to remember me cookie (e.g. current password hash)",
            "        if key == current_app.config.get(\"REMEMBER_COOKIE_NAME\", REMEMBER_COOKIE_NAME):",
            "            value = encode_remember_me_cookie(value)",
            "",
            "        # add request specific cookie suffix to name",
            "        flask.Response.set_cookie(",
            "            self, key + flask.request.cookie_suffix, value=value, *args, **kwargs",
            "        )",
            "",
            "    def delete_cookie(self, key, path=\"/\", domain=None):",
            "        flask.Response.delete_cookie(self, key, path=path, domain=domain)",
            "",
            "        # we also still might have a cookie left over from before we started prefixing, delete that manually",
            "        # without any pre processing (no path prefix, no key suffix)",
            "        flask.Response.set_cookie(",
            "            self, key, expires=0, max_age=0, path=path, domain=domain",
            "        )",
            "",
            "",
            "class OctoPrintSessionInterface(flask.sessions.SecureCookieSessionInterface):",
            "    def should_set_cookie(self, app, session):",
            "        return flask.request.endpoint != \"static\"",
            "",
            "    def save_session(self, app, session, response):",
            "        if flask.g.get(\"login_via_apikey\", False):",
            "            return",
            "        return super().save_session(app, session, response)",
            "",
            "",
            "# ~~ jinja environment",
            "",
            "",
            "class PrefixAwareJinjaEnvironment(flask.templating.Environment):",
            "    def __init__(self, *args, **kwargs):",
            "        flask.templating.Environment.__init__(self, *args, **kwargs)",
            "        self.prefix_loader = None",
            "        self._cached_templates = {}",
            "",
            "    def join_path(self, template, parent):",
            "        if parent and \"/\" in parent:",
            "            prefix, _ = parent.split(\"/\", 1)",
            "            if template in self._templates_for_prefix(prefix) and not template.startswith(",
            "                prefix + \"/\"",
            "            ):",
            "                return prefix + \"/\" + template",
            "",
            "        return template",
            "",
            "    def _templates_for_prefix(self, prefix):",
            "        if prefix in self._cached_templates:",
            "            return self._cached_templates[prefix]",
            "",
            "        templates = []",
            "        if prefix in self.prefix_loader.mapping:",
            "            templates = self.prefix_loader.mapping[prefix].list_templates()",
            "        self._cached_templates[prefix] = templates",
            "        return templates",
            "",
            "",
            "# ~~ passive login helper",
            "",
            "_cached_local_networks = None",
            "",
            "",
            "def _local_networks():",
            "    global _cached_local_networks",
            "",
            "    if _cached_local_networks is None:",
            "        logger = logging.getLogger(__name__)",
            "        local_networks = netaddr.IPSet([])",
            "        for entry in settings().get([\"accessControl\", \"localNetworks\"]):",
            "            try:",
            "                network = netaddr.IPNetwork(entry)",
            "            except Exception:",
            "                logger.warning(",
            "                    \"Invalid network definition configured in localNetworks: {}\".format(",
            "                        entry",
            "                    )",
            "                )",
            "                continue",
            "",
            "            local_networks.add(network)",
            "            logger.debug(f\"Added network {network} to localNetworks\")",
            "",
            "            if network.version == 4:",
            "                network_v6 = network.ipv6()",
            "                local_networks.add(network_v6)",
            "                logger.debug(",
            "                    \"Also added v6 representation of v4 network {} = {} to localNetworks\".format(",
            "                        network, network_v6",
            "                    )",
            "                )",
            "",
            "        _cached_local_networks = local_networks",
            "",
            "    return _cached_local_networks",
            "",
            "",
            "def passive_login():",
            "    logger = logging.getLogger(__name__)",
            "",
            "    user = flask_login.current_user",
            "",
            "    remote_address = get_remote_address(flask.request)",
            "    ip_check_enabled = settings().getBoolean([\"server\", \"ipCheck\", \"enabled\"])",
            "    ip_check_trusted = settings().get([\"server\", \"ipCheck\", \"trustedSubnets\"])",
            "",
            "    if isinstance(user, LocalProxy):",
            "        # noinspection PyProtectedMember",
            "        user = user._get_current_object()",
            "",
            "    def login(u):",
            "        # login known user",
            "        if not u.is_anonymous:",
            "            if not flask.g.identity or not flask.g.identity.id:",
            "                # the user was just now found",
            "                login_mechanism = octoprint.server.util.LoginMechanism.to_log(",
            "                    flask.session.get(\"login_mechanism\", \"unknown\")",
            "                )",
            "                auth_log(",
            "                    f\"Logging in user {u.get_id()} from {remote_address} via {login_mechanism}\"",
            "                )",
            "            u = octoprint.server.userManager.login_user(u)",
            "",
            "        flask_login.login_user(u)",
            "        flask_principal.identity_changed.send(",
            "            flask.current_app._get_current_object(),",
            "            identity=flask_principal.Identity(u.get_id()),",
            "        )",
            "        if hasattr(u, \"session\"):",
            "            flask.session[\"usersession.id\"] = u.session",
            "            flask.session[\"usersession.signature\"] = session_signature(",
            "                u.get_id(), u.session",
            "            )",
            "        flask.g.user = u",
            "",
            "        eventManager().fire(Events.USER_LOGGED_IN, payload={\"username\": u.get_id()})",
            "",
            "        return u",
            "",
            "    def determine_user(u):",
            "        if not u.is_anonymous and u.is_active:",
            "            # known active user",
            "            logger.info(f\"Passively logging in user {u.get_id()} from {remote_address}\")",
            "",
            "        elif (",
            "            settings().getBoolean([\"accessControl\", \"autologinLocal\"])",
            "            and settings().get([\"accessControl\", \"autologinAs\"]) is not None",
            "            and settings().get([\"accessControl\", \"localNetworks\"]) is not None",
            "            and \"active_logout\" not in flask.request.cookies",
            "            and remote_address",
            "        ):",
            "            # attempt local autologin",
            "            autologin_as = settings().get([\"accessControl\", \"autologinAs\"])",
            "            local_networks = _local_networks()",
            "            logger.debug(",
            "                \"Checking if remote address {} is in localNetworks ({!r})\".format(",
            "                    remote_address, local_networks",
            "                )",
            "            )",
            "",
            "            try:",
            "                if netaddr.IPAddress(remote_address) in local_networks:",
            "                    autologin_user = octoprint.server.userManager.find_user(autologin_as)",
            "                    if autologin_user is not None and autologin_user.is_active:",
            "                        logger.info(",
            "                            f\"Logging in user {autologin_as} from {remote_address} via autologin\"",
            "                        )",
            "                        flask.session[",
            "                            \"login_mechanism\"",
            "                        ] = octoprint.server.util.LoginMechanism.AUTOLOGIN",
            "                        flask.session[\"credentials_seen\"] = False",
            "                        return autologin_user",
            "            except Exception:",
            "                logger.exception(",
            "                    \"Could not autologin user {} from {} for networks {}\".format(",
            "                        autologin_as, remote_address, local_networks",
            "                    )",
            "                )",
            "",
            "        if not u.is_active:",
            "            # inactive user, switch to anonymous",
            "            u = octoprint.server.userManager.anonymous_user_factory()",
            "",
            "        return u",
            "",
            "    user = login(determine_user(user))",
            "    response = user.as_dict()",
            "    response[\"_is_external_client\"] = ip_check_enabled and not is_lan_address(",
            "        remote_address, additional_private=ip_check_trusted",
            "    )",
            "    if flask.session.get(\"login_mechanism\") is not None:",
            "        response[\"_login_mechanism\"] = flask.session.get(\"login_mechanism\")",
            "    response[\"_credentials_seen\"] = to_api_credentials_seen(",
            "        flask.session.get(\"credentials_seen\", False)",
            "    )",
            "    return flask.jsonify(response)",
            "",
            "",
            "def to_api_credentials_seen(credentials_seen):",
            "    if not credentials_seen:",
            "        return False",
            "",
            "    return (",
            "        datetime.fromtimestamp(credentials_seen, tz=timezone.utc)",
            "        .replace(microsecond=0)",
            "        .isoformat()",
            "    )",
            "",
            "",
            "# ~~ rate limiting helper",
            "",
            "",
            "def limit(*args, **kwargs):",
            "    if octoprint.server.limiter:",
            "        return octoprint.server.limiter.limit(*args, **kwargs)",
            "    else:",
            "",
            "        def decorator(f):",
            "            @functools.wraps(f)",
            "            def decorated_function(*args, **kwargs):",
            "                return f(*args, **kwargs)",
            "",
            "            return decorated_function",
            "",
            "        return decorator",
            "",
            "",
            "# ~~ cache decorator for cacheable views",
            "",
            "",
            "class LessSimpleCache(BaseCache):",
            "    \"\"\"",
            "    Slightly improved version of :class:`SimpleCache`.",
            "",
            "    Setting ``default_timeout`` or ``timeout`` to ``-1`` will have no timeout be applied at all.",
            "    \"\"\"",
            "",
            "    def __init__(self, threshold=500, default_timeout=300):",
            "        BaseCache.__init__(self, default_timeout=default_timeout)",
            "        self._mutex = threading.RLock()",
            "        self._cache = {}",
            "        self._bypassed = set()",
            "        self.clear = self._cache.clear",
            "        self._threshold = threshold",
            "",
            "    def _prune(self):",
            "        if self.over_threshold():",
            "            now = time.time()",
            "            for idx, (key, (expires, _)) in enumerate(self._cache.items()):",
            "                if expires is not None and expires <= now or idx % 3 == 0:",
            "                    with self._mutex:",
            "                        self._cache.pop(key, None)",
            "",
            "    def get(self, key):",
            "        import pickle",
            "",
            "        now = time.time()",
            "        with self._mutex:",
            "            expires, value = self._cache.get(key, (0, None))",
            "        if expires is None or expires > now:",
            "            return pickle.loads(value)",
            "",
            "    def set(self, key, value, timeout=None):",
            "        import pickle",
            "",
            "        with self._mutex:",
            "            self._prune()",
            "            self._cache[key] = (",
            "                self.calculate_timeout(timeout=timeout),",
            "                pickle.dumps(value, pickle.HIGHEST_PROTOCOL),",
            "            )",
            "            if key in self._bypassed:",
            "                self._bypassed.remove(key)",
            "",
            "    def add(self, key, value, timeout=None):",
            "        with self._mutex:",
            "            self.set(key, value, timeout=None)",
            "            self._cache.setdefault(key, self._cache[key])",
            "",
            "    def delete(self, key):",
            "        with self._mutex:",
            "            self._cache.pop(key, None)",
            "",
            "    def calculate_timeout(self, timeout=None):",
            "        if timeout is None:",
            "            timeout = self.default_timeout",
            "        if timeout == -1:",
            "            return None",
            "        return time.time() + timeout",
            "",
            "    def over_threshold(self):",
            "        if self._threshold is None:",
            "            return False",
            "        with self._mutex:",
            "            return len(self._cache) > self._threshold",
            "",
            "    def __getitem__(self, key):",
            "        return self.get(key)",
            "",
            "    def __setitem__(self, key, value):",
            "        return self.set(key, value)",
            "",
            "    def __delitem__(self, key):",
            "        return self.delete(key)",
            "",
            "    def __contains__(self, key):",
            "        with self._mutex:",
            "            return key in self._cache",
            "",
            "    def set_bypassed(self, key):",
            "        with self._mutex:",
            "            self._bypassed.add(key)",
            "",
            "    def is_bypassed(self, key):",
            "        with self._mutex:",
            "            return key in self._bypassed",
            "",
            "",
            "_cache = LessSimpleCache()",
            "",
            "",
            "def cached(",
            "    timeout=5 * 60,",
            "    key=lambda: \"view:%s\" % flask.request.path,",
            "    unless=None,",
            "    refreshif=None,",
            "    unless_response=None,",
            "):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            logger = logging.getLogger(__name__)",
            "",
            "            cache_key = key()",
            "",
            "            def f_with_duration(*args, **kwargs):",
            "                start_time = time.time()",
            "                try:",
            "                    return f(*args, **kwargs)",
            "                finally:",
            "                    elapsed = time.time() - start_time",
            "                    logger.debug(",
            "                        \"Needed {elapsed:.2f}s to render {path} (key: {key})\".format(",
            "                            elapsed=elapsed, path=flask.request.path, key=cache_key",
            "                        )",
            "                    )",
            "",
            "            # bypass the cache if \"unless\" condition is true",
            "            if callable(unless) and unless():",
            "                logger.debug(",
            "                    \"Cache for {path} bypassed, calling wrapped function\".format(",
            "                        path=flask.request.path",
            "                    )",
            "                )",
            "                _cache.set_bypassed(cache_key)",
            "                return f_with_duration(*args, **kwargs)",
            "",
            "            # also bypass the cache if it's disabled completely",
            "            if not settings().getBoolean([\"devel\", \"cache\", \"enabled\"]):",
            "                logger.debug(",
            "                    \"Cache for {path} disabled, calling wrapped function\".format(",
            "                        path=flask.request.path",
            "                    )",
            "                )",
            "                _cache.set_bypassed(cache_key)",
            "                return f_with_duration(*args, **kwargs)",
            "",
            "            rv = _cache.get(cache_key)",
            "",
            "            # only take the value from the cache if we are not required to refresh it from the wrapped function",
            "            if rv is not None and (not callable(refreshif) or not refreshif(rv)):",
            "                logger.debug(",
            "                    \"Serving entry for {path} from cache (key: {key})\".format(",
            "                        path=flask.request.path, key=cache_key",
            "                    )",
            "                )",
            "                if \"X-From-Cache\" not in rv.headers:",
            "                    rv.headers[\"X-From-Cache\"] = \"true\"",
            "                return rv",
            "",
            "            # get value from wrapped function",
            "            logger.debug(",
            "                \"No cache entry or refreshing cache for {path} (key: {key}), calling wrapped function\".format(",
            "                    path=flask.request.path, key=cache_key",
            "                )",
            "            )",
            "            rv = f_with_duration(*args, **kwargs)",
            "",
            "            # do not store if the \"unless_response\" condition is true",
            "            if callable(unless_response) and unless_response(rv):",
            "                logger.debug(",
            "                    \"Not caching result for {path} (key: {key}), bypassed\".format(",
            "                        path=flask.request.path, key=cache_key",
            "                    )",
            "                )",
            "                _cache.set_bypassed(cache_key)",
            "                return rv",
            "",
            "            # store it in the cache",
            "            _cache.set(cache_key, rv, timeout=timeout)",
            "",
            "            return rv",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def is_in_cache(key=lambda: \"view:%s\" % flask.request.path):",
            "    if callable(key):",
            "        key = key()",
            "    return key in _cache",
            "",
            "",
            "def is_cache_bypassed(key=lambda: \"view:%s\" % flask.request.path):",
            "    if callable(key):",
            "        key = key()",
            "    return _cache.is_bypassed(key)",
            "",
            "",
            "def cache_check_headers():",
            "    return \"no-cache\" in flask.request.cache_control or \"no-cache\" in flask.request.pragma",
            "",
            "",
            "def cache_check_response_headers(response):",
            "    if not isinstance(response, flask.Response):",
            "        return False",
            "",
            "    headers = response.headers",
            "",
            "    if \"Cache-Control\" in headers and (",
            "        \"no-cache\" in headers[\"Cache-Control\"] or \"no-store\" in headers[\"Cache-Control\"]",
            "    ):",
            "        return True",
            "",
            "    if \"Pragma\" in headers and \"no-cache\" in headers[\"Pragma\"]:",
            "        return True",
            "",
            "    if \"Expires\" in headers and headers[\"Expires\"] in (\"0\", \"-1\"):",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def cache_check_status_code(response, valid):",
            "    if not isinstance(response, flask.Response):",
            "        return False",
            "",
            "    if callable(valid):",
            "        return not valid(response.status_code)",
            "    else:",
            "        return response.status_code not in valid",
            "",
            "",
            "class PreemptiveCache:",
            "    def __init__(self, cachefile):",
            "        self.cachefile = cachefile",
            "        self.environment = None",
            "",
            "        self._logger = logging.getLogger(__name__ + \".\" + self.__class__.__name__)",
            "",
            "        self._lock = threading.RLock()",
            "",
            "    def record(self, data, unless=None, root=None):",
            "        if callable(unless) and unless():",
            "            return",
            "",
            "        entry_data = data",
            "        if callable(entry_data):",
            "            entry_data = entry_data()",
            "",
            "        if entry_data is not None:",
            "            if root is None:",
            "                from flask import request",
            "",
            "                root = request.path",
            "            self.add_data(root, entry_data)",
            "",
            "    def has_record(self, data, root=None):",
            "        if callable(data):",
            "            data = data()",
            "",
            "        if data is None:",
            "            return False",
            "",
            "        if root is None:",
            "            from flask import request",
            "",
            "            root = request.path",
            "",
            "        all_data = self.get_data(root)",
            "        for existing in all_data:",
            "            if self._compare_data(data, existing):",
            "                return True",
            "",
            "        return False",
            "",
            "    def clean_all_data(self, cleanup_function):",
            "        assert callable(cleanup_function)",
            "",
            "        with self._lock:",
            "            all_data = self.get_all_data()",
            "            for root, entries in list(all_data.items()):",
            "                old_count = len(entries)",
            "                entries = cleanup_function(root, entries)",
            "                if not entries:",
            "                    del all_data[root]",
            "                    self._logger.debug(f\"Removed root {root} from preemptive cache\")",
            "                elif len(entries) < old_count:",
            "                    all_data[root] = entries",
            "                    self._logger.debug(",
            "                        \"Removed {} entries from preemptive cache for root {}\".format(",
            "                            old_count - len(entries), root",
            "                        )",
            "                    )",
            "            self.set_all_data(all_data)",
            "",
            "        return all_data",
            "",
            "    def get_all_data(self):",
            "        cache_data = None",
            "        with self._lock:",
            "            try:",
            "                cache_data = yaml.load_from_file(path=self.cachefile)",
            "            except OSError as e:",
            "                import errno",
            "",
            "                if e.errno != errno.ENOENT:",
            "                    raise",
            "            except Exception:",
            "                self._logger.exception(f\"Error while reading {self.cachefile}\")",
            "",
            "        if cache_data is None:",
            "            cache_data = {}",
            "",
            "        if not self._validate_data(cache_data):",
            "            self._logger.warning(\"Preemptive cache data was invalid, ignoring it\")",
            "            cache_data = {}",
            "",
            "        return cache_data",
            "",
            "    def get_data(self, root):",
            "        cache_data = self.get_all_data()",
            "        return cache_data.get(root, list())",
            "",
            "    def set_all_data(self, data):",
            "        from octoprint.util import atomic_write",
            "",
            "        with self._lock:",
            "            try:",
            "                with atomic_write(self.cachefile, \"wt\", max_permissions=0o666) as handle:",
            "                    yaml.save_to_file(data, file=handle, pretty=True)",
            "            except Exception:",
            "                self._logger.exception(f\"Error while writing {self.cachefile}\")",
            "",
            "    def set_data(self, root, data):",
            "        with self._lock:",
            "            all_data = self.get_all_data()",
            "            all_data[root] = data",
            "            self.set_all_data(all_data)",
            "",
            "    def add_data(self, root, data):",
            "        def split_matched_and_unmatched(entry, entries):",
            "            matched = []",
            "            unmatched = []",
            "",
            "            for e in entries:",
            "                if self._compare_data(e, entry):",
            "                    matched.append(e)",
            "                else:",
            "                    unmatched.append(e)",
            "",
            "            return matched, unmatched",
            "",
            "        with self._lock:",
            "            cache_data = self.get_all_data()",
            "",
            "            if root not in cache_data:",
            "                cache_data[root] = []",
            "",
            "            existing, other = split_matched_and_unmatched(data, cache_data[root])",
            "",
            "            def get_newest(entries):",
            "                result = None",
            "                for entry in entries:",
            "                    if \"_timestamp\" in entry and (",
            "                        result is None",
            "                        or (",
            "                            \"_timestamp\" in result",
            "                            and result[\"_timestamp\"] < entry[\"_timestamp\"]",
            "                        )",
            "                    ):",
            "                        result = entry",
            "                return result",
            "",
            "            to_persist = get_newest(existing)",
            "            if not to_persist:",
            "                import copy",
            "",
            "                to_persist = copy.deepcopy(data)",
            "                to_persist[\"_timestamp\"] = time.time()",
            "                to_persist[\"_count\"] = 1",
            "                self._logger.info(f\"Adding entry for {root} and {to_persist!r}\")",
            "            else:",
            "                to_persist[\"_timestamp\"] = time.time()",
            "                to_persist[\"_count\"] = to_persist.get(\"_count\", 0) + 1",
            "                self._logger.debug(",
            "                    f\"Updating timestamp and counter for {root} and {data!r}\"",
            "                )",
            "",
            "            self.set_data(root, [to_persist] + other)",
            "",
            "    def _compare_data(self, a, b):",
            "        from octoprint.util import dict_filter",
            "",
            "        def strip_ignored(d):",
            "            return dict_filter(d, lambda k, v: not k.startswith(\"_\"))",
            "",
            "        return set(strip_ignored(a).items()) == set(strip_ignored(b).items())",
            "",
            "    def _validate_data(self, data):",
            "        if not isinstance(data, dict):",
            "            return False",
            "",
            "        for entries in data.values():",
            "            if not isinstance(entries, list):",
            "                return False",
            "",
            "            for entry in entries:",
            "                if not self._validate_entry(entry):",
            "                    return False",
            "",
            "        return True",
            "",
            "    def _validate_entry(self, entry):",
            "        return isinstance(entry, dict) and \"_timestamp\" in entry and \"_count\" in entry",
            "",
            "",
            "def preemptively_cached(cache, data, unless=None):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            try:",
            "                cache.record(data, unless=unless)",
            "            except Exception:",
            "                logging.getLogger(__name__).exception(",
            "                    f\"Error while recording preemptive cache entry: {data!r}\"",
            "                )",
            "            return f(*args, **kwargs)",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def etagged(etag):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            rv = f(*args, **kwargs)",
            "            if isinstance(rv, flask.Response):",
            "                try:",
            "                    result = etag",
            "                    if callable(result):",
            "                        result = result(rv)",
            "                    if result:",
            "                        rv.set_etag(result)",
            "                except Exception:",
            "                    logging.getLogger(__name__).exception(",
            "                        \"Error while calculating the etag value for response {!r}\".format(",
            "                            rv",
            "                        )",
            "                    )",
            "            return rv",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def lastmodified(date):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            rv = f(*args, **kwargs)",
            "            if \"Last-Modified\" not in rv.headers:",
            "                try:",
            "                    result = date",
            "                    if callable(result):",
            "                        result = result(rv)",
            "",
            "                    if not isinstance(result, str):",
            "                        from werkzeug.http import http_date",
            "",
            "                        result = http_date(result)",
            "",
            "                    if result:",
            "                        rv.headers[\"Last-Modified\"] = result",
            "                except Exception:",
            "                    logging.getLogger(__name__).exception(",
            "                        \"Error while calculating the lastmodified value for response {!r}\".format(",
            "                            rv",
            "                        )",
            "                    )",
            "            return rv",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def conditional(condition, met):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            try:",
            "                if callable(condition) and condition():",
            "                    # condition has been met, return met-response",
            "                    rv = met",
            "                    if callable(met):",
            "                        rv = met()",
            "                    return rv",
            "            except Exception:",
            "                logging.getLogger(__name__).exception(",
            "                    \"Error while evaluating conditional {!r} or met {!r}\".format(",
            "                        condition, met",
            "                    )",
            "                )",
            "",
            "            # condition hasn't been met, call decorated function",
            "            return f(*args, **kwargs)",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def with_client_revalidation(f):",
            "    @functools.wraps(f)",
            "    def decorated_function(*args, **kwargs):",
            "        r = f(*args, **kwargs)",
            "",
            "        if isinstance(r, flask.Response):",
            "            r = add_revalidation_response_headers(r)",
            "",
            "        return r",
            "",
            "    return decorated_function",
            "",
            "",
            "def with_revalidation_checking(",
            "    etag_factory=None, lastmodified_factory=None, condition=None, unless=None",
            "):",
            "    if etag_factory is None:",
            "",
            "        def etag_factory(lm=None):",
            "            return None",
            "",
            "    if lastmodified_factory is None:",
            "",
            "        def lastmodified_factory():",
            "            return None",
            "",
            "    if condition is None:",
            "",
            "        def condition(lm=None, etag=None):",
            "            if lm is None:",
            "                lm = lastmodified_factory()",
            "",
            "            if etag is None:",
            "                etag = etag_factory(lm=lm)",
            "",
            "            if flask.request.if_none_match and flask.request.if_modified_since:",
            "                # use both",
            "                return check_lastmodified(lm) and check_etag(etag)",
            "            elif flask.request.if_none_match:",
            "                # use only ETag",
            "                return check_etag(etag)",
            "            elif flask.request.if_modified_since:",
            "                # use only Last-Modified",
            "                return check_lastmodified(lm)",
            "            else:",
            "                # assume stale cache",
            "                return False",
            "",
            "    if unless is None:",
            "",
            "        def unless():",
            "            return False",
            "",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            from octoprint.server import NOT_MODIFIED",
            "",
            "            lm = lastmodified_factory()",
            "            etag = etag_factory(lm)",
            "",
            "            if condition(lm, etag) and not unless():",
            "                return NOT_MODIFIED",
            "",
            "            # generate response",
            "            response = f(*args, **kwargs)",
            "",
            "            # set etag header if not already set",
            "            if etag and response.get_etag()[0] is None:",
            "                response.set_etag(etag)",
            "",
            "            # set last modified header if not already set",
            "            if lm and response.headers.get(\"Last-Modified\", None) is None:",
            "                if not isinstance(lm, str):",
            "                    from werkzeug.http import http_date",
            "",
            "                    lm = http_date(lm)",
            "                response.headers[\"Last-Modified\"] = lm",
            "",
            "            response = add_no_max_age_response_headers(response)",
            "            return response",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def check_etag(etag):",
            "    if etag is None:",
            "        return False",
            "",
            "    return (",
            "        flask.request.method in (\"GET\", \"HEAD\")",
            "        and flask.request.if_none_match is not None",
            "        and etag in flask.request.if_none_match",
            "    )",
            "",
            "",
            "def check_lastmodified(lastmodified: Union[int, float, datetime]) -> bool:",
            "    \"\"\"Compares the provided lastmodified value with the value of the If-Modified-Since header.",
            "",
            "    If ``lastmodified`` is an int or float, it's assumed to be a Unix timestamp and converted",
            "    to a timezone aware datetime instance in UTC.",
            "",
            "    If ``lastmodified`` is a datetime instance, it needs to be timezone aware or the",
            "    result will always be ``False``.",
            "",
            "    Args:",
            "        lastmodified (Union[int, float, datetime]): The last modified value to compare against",
            "",
            "    Raises:",
            "        ValueError: If anything but an int, float or datetime instance is passed",
            "",
            "    Returns:",
            "        bool: true if the values indicate that the document is still up to date",
            "    \"\"\"",
            "",
            "    if lastmodified is None:",
            "        return False",
            "",
            "    if isinstance(lastmodified, (int, float)):",
            "        # max(86400, lastmodified) is workaround for https://bugs.python.org/issue29097,",
            "        # present in CPython 3.6.x up to 3.7.1.",
            "        #",
            "        # I think it's fair to say that we'll never encounter lastmodified values older than",
            "        # 1970-01-02 so this is a safe workaround.",
            "        #",
            "        # Timestamps are defined as seconds since epoch aka 1970/01/01 00:00:00Z, so we",
            "        # use UTC as timezone here.",
            "        lastmodified = datetime.fromtimestamp(",
            "            max(86400, lastmodified), tz=UTC_TZ",
            "        ).replace(microsecond=0)",
            "",
            "    if not isinstance(lastmodified, datetime):",
            "        raise ValueError(",
            "            \"lastmodified must be a datetime or float or int instance but, got {} instead\".format(",
            "                lastmodified.__class__",
            "            )",
            "        )",
            "",
            "    if not is_timezone_aware(lastmodified):",
            "        # datetime object is not timezone aware, we can't check lastmodified with that",
            "        logger = logging.getLogger(__name__)",
            "        logger.warning(",
            "            \"lastmodified is not timezone aware, cannot check against If-Modified-Since. In the future this will become an error!\",",
            "            stack_info=logger.isEnabledFor(logging.DEBUG),",
            "        )",
            "        return False",
            "",
            "    return (",
            "        flask.request.method in (\"GET\", \"HEAD\")",
            "        and flask.request.if_modified_since is not None",
            "        and lastmodified <= flask.request.if_modified_since",
            "    )",
            "",
            "",
            "def add_revalidation_response_headers(response):",
            "    import werkzeug.http",
            "",
            "    cache_control = werkzeug.http.parse_dict_header(",
            "        response.headers.get(\"Cache-Control\", \"\")",
            "    )",
            "    if \"no-cache\" not in cache_control:",
            "        cache_control[\"no-cache\"] = None",
            "    if \"must-revalidate\" not in cache_control:",
            "        cache_control[\"must-revalidate\"] = None",
            "    response.headers[\"Cache-Control\"] = werkzeug.http.dump_header(cache_control)",
            "",
            "    return response",
            "",
            "",
            "def add_non_caching_response_headers(response):",
            "    import werkzeug.http",
            "",
            "    cache_control = werkzeug.http.parse_dict_header(",
            "        response.headers.get(\"Cache-Control\", \"\")",
            "    )",
            "    if \"no-store\" not in cache_control:",
            "        cache_control[\"no-store\"] = None",
            "    if \"no-cache\" not in cache_control:",
            "        cache_control[\"no-cache\"] = None",
            "    if \"must-revalidate\" not in cache_control:",
            "        cache_control[\"must-revalidate\"] = None",
            "    if \"post-check\" not in cache_control or cache_control[\"post-check\"] != \"0\":",
            "        cache_control[\"post-check\"] = \"0\"",
            "    if \"pre-check\" not in cache_control or cache_control[\"pre-check\"] != \"0\":",
            "        cache_control[\"pre-check\"] = \"0\"",
            "    if \"max-age\" not in cache_control or cache_control[\"max-age\"] != \"0\":",
            "        cache_control[\"max-age\"] = \"0\"",
            "    response.headers[\"Cache-Control\"] = werkzeug.http.dump_header(cache_control)",
            "",
            "    response.headers[\"Pragma\"] = \"no-cache\"",
            "    response.headers[\"Expires\"] = \"-1\"",
            "    return response",
            "",
            "",
            "def add_no_max_age_response_headers(response):",
            "    import werkzeug.http",
            "",
            "    cache_control = werkzeug.http.parse_dict_header(",
            "        response.headers.get(\"Cache-Control\", \"\")",
            "    )",
            "    if \"max-age\" not in cache_control or cache_control[\"max-age\"] != \"0\":",
            "        cache_control[\"max-age\"] = \"0\"",
            "    response.headers[\"Cache-Control\"] = werkzeug.http.dump_header(cache_control)",
            "",
            "    return response",
            "",
            "",
            "# ~~ access validators for use with tornado",
            "",
            "",
            "def permission_validator(request, permission):",
            "    \"\"\"",
            "    Validates that the given request is made by an authorized user, identified either by API key or existing Flask",
            "    session.",
            "",
            "    Must be executed in an existing Flask request context!",
            "",
            "    :param request: The Flask request object",
            "    :param request: The required permission",
            "    \"\"\"",
            "",
            "    user = get_flask_user_from_request(request)",
            "    if not user.has_permission(permission):",
            "        raise tornado.web.HTTPError(403)",
            "",
            "",
            "def permission_and_fresh_credentials_validator(request, permission):",
            "    \"\"\"",
            "    Validates that the given request is made by an authorized user, identified either by API key or existing Flask",
            "    session, and that the credentials have been checked recently if it's a Flask session.",
            "",
            "    Must be executed in an existing Flask request context!",
            "",
            "    :param request: The Flask request object",
            "    :param request: The required permission",
            "    \"\"\"",
            "",
            "    permission_validator(request, permission)",
            "    ensure_credentials_checked_recently()",
            "",
            "",
            "@deprecated(",
            "    \"admin_validator is deprecated, please use new permission_validator\", since=\"\"",
            ")",
            "def admin_validator(request):",
            "    from octoprint.access.permissions import Permissions",
            "",
            "    return permission_validator(request, Permissions.ADMIN)",
            "",
            "",
            "@deprecated(\"user_validator is deprecated, please use new permission_validator\", since=\"\")",
            "def user_validator(request):",
            "    return True",
            "",
            "",
            "def get_flask_user_from_request(request):",
            "    \"\"\"",
            "    Retrieves the current flask user from the request context. Uses API key if available, otherwise the current",
            "    user session if available.",
            "",
            "    :param request: flask request from which to retrieve the current user",
            "    :return: the user (might be an anonymous user)",
            "    \"\"\"",
            "    import flask_login",
            "",
            "    import octoprint.server.util",
            "",
            "    user = None",
            "",
            "    apikey = octoprint.server.util.get_api_key(request)",
            "    if apikey is not None:",
            "        # user from api key?",
            "        user = octoprint.server.util.get_user_for_apikey(apikey)",
            "",
            "    if user is None:",
            "        # user still None -> current session user",
            "        user = flask_login.current_user",
            "",
            "    if user is None:",
            "        # user still None -> anonymous",
            "        from octoprint.server import userManager",
            "",
            "        user = userManager.anonymous_user_factory()",
            "",
            "    return user",
            "",
            "",
            "def redirect_to_tornado(request, target, code=302):",
            "    \"\"\"",
            "    Redirects from flask to tornado, flask request context must exist.",
            "",
            "    :param request:",
            "    :param target:",
            "    :param code:",
            "    :return:",
            "    \"\"\"",
            "",
            "    import flask",
            "",
            "    requestUrl = request.url",
            "    appBaseUrl = requestUrl[: requestUrl.find(flask.url_for(\"index\") + \"api\")]",
            "",
            "    redirectUrl = appBaseUrl + target",
            "    if \"?\" in requestUrl:",
            "        fragment = requestUrl[requestUrl.rfind(\"?\") :]",
            "        redirectUrl += fragment",
            "    return flask.redirect(redirectUrl, code=code)",
            "",
            "",
            "def restricted_access(func):",
            "    \"\"\"",
            "    This combines :py:func:`no_firstrun_access` and ``login_required``.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        return no_firstrun_access(flask_login.login_required(func))(*args, **kwargs)",
            "",
            "    return decorated_view",
            "",
            "",
            "def no_firstrun_access(func):",
            "    \"\"\"",
            "    If you decorate a view with this, it will ensure that first setup has been",
            "    done for OctoPrint's Access Control.",
            "",
            "    If OctoPrint's Access Control has not been setup yet (indicated by the userManager",
            "    not reporting that its user database has been customized from default), the decorator",
            "    will cause a HTTP 403 status code to be returned by the decorated resource.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        # if OctoPrint hasn't been set up yet, abort",
            "        if settings().getBoolean([\"server\", \"firstRun\"]) and (",
            "            octoprint.server.userManager is None",
            "            or not octoprint.server.userManager.has_been_customized()",
            "        ):",
            "            flask.abort(403)",
            "        return func(*args, **kwargs)",
            "",
            "    return decorated_view",
            "",
            "",
            "def firstrun_only_access(func):",
            "    \"\"\"",
            "    If you decorate a view with this, it will ensure that first setup has _not_ been",
            "    done for OctoPrint's Access Control. Otherwise it",
            "    will cause a HTTP 403 status code to be returned by the decorated resource.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        # if OctoPrint has been set up yet, abort",
            "        if settings().getBoolean([\"server\", \"firstRun\"]) and (",
            "            octoprint.server.userManager is None",
            "            or not octoprint.server.userManager.has_been_customized()",
            "        ):",
            "            return func(*args, **kwargs)",
            "        else:",
            "            flask.abort(403)",
            "",
            "    return decorated_view",
            "",
            "",
            "def credentials_checked_recently():",
            "    minutes = settings().getInt([\"accessControl\", \"defaultReauthenticationTimeout\"])",
            "    if not minutes:",
            "        return True",
            "",
            "    login_mechanism = flask.session.get(\"login_mechanism\")",
            "    if not octoprint.server.util.LoginMechanism.reauthentication_enabled(login_mechanism):",
            "        return True",
            "",
            "    credentials_seen = flask.session.get(\"credentials_seen\")",
            "    now = datetime.now()",
            "",
            "    try:",
            "        if credentials_seen and datetime.fromtimestamp(",
            "            credentials_seen",
            "        ) > now - timedelta(minutes=minutes):",
            "            # credentials seen less than the set minutes ago, proceed",
            "            return True",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(\"Error while checking for seen credentials\")",
            "        pass",
            "",
            "    return False",
            "",
            "",
            "def ensure_credentials_checked_recently():",
            "    if not credentials_checked_recently():",
            "        flask.abort(403, description=\"Please reauthenticate with your credentials\")",
            "",
            "",
            "def require_credentials_checked_recently(func):",
            "    \"\"\"",
            "    If you decorate a view with this, it will ensure that only users who entered their password",
            "    recently in this login session are allowed to proceed. Otherwise it will cause a HTTP 403 status code",
            "    to be returned by the decorated resource.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        ensure_credentials_checked_recently()",
            "        return func(*args, **kwargs)",
            "",
            "    return decorated_view",
            "",
            "",
            "def get_remote_address(request):",
            "    forwardedFor = request.headers.get(\"X-Forwarded-For\", None)",
            "    if forwardedFor is not None:",
            "        return forwardedFor.split(\",\")[0]",
            "    return request.remote_addr",
            "",
            "",
            "def get_json_command_from_request(request, valid_commands):",
            "    data = request.get_json()",
            "",
            "    if \"command\" not in data or data[\"command\"] not in valid_commands:",
            "        flask.abort(400, description=\"command is invalid\")",
            "",
            "    command = data[\"command\"]",
            "    if any(map(lambda x: x not in data, valid_commands[command])):",
            "        flask.abort(400, description=\"Mandatory parameters missing\")",
            "",
            "    return command, data, None",
            "",
            "",
            "def make_text_response(message, status):",
            "    \"\"\"",
            "    Helper to generate basic text responses.",
            "",
            "    Response will have the provided message as body, the provided status code, and",
            "    a content type of \"text/plain\".",
            "",
            "    Args:",
            "        message: The message in the response body",
            "        status: The HTTP status code",
            "",
            "    Returns:",
            "",
            "    \"\"\"",
            "    return make_response(message, status, {\"Content-Type\": \"text/plain\"})",
            "",
            "",
            "def make_api_error(message, status):",
            "    \"\"\"",
            "    Helper to generate API error responses in JSON format.",
            "",
            "    Turns something like ``make_api_error(\"Not Found\", 404)`` into a JSON response",
            "    with body ``{\"error\": \"Not Found\"}``.",
            "",
            "    Args:",
            "        message: The error message to put into the response",
            "        status: The HTTP status code",
            "",
            "    Returns: a flask response to return to the client",
            "    \"\"\"",
            "    return make_response(flask.jsonify(error=message), status)",
            "",
            "",
            "##~~ Flask-Assets resolver with plugin asset support",
            "",
            "",
            "class PluginAssetResolver(flask_assets.FlaskResolver):",
            "    def split_prefix(self, ctx, item):",
            "        app = ctx.environment._app",
            "        if item.startswith(\"plugin/\"):",
            "            try:",
            "                prefix, plugin, name = item.split(\"/\", 2)",
            "                blueprint = prefix + \".\" + plugin",
            "",
            "                directory = flask_assets.get_static_folder(app.blueprints[blueprint])",
            "                item = name",
            "                endpoint = blueprint + \".static\"",
            "                return directory, item, endpoint",
            "            except (ValueError, KeyError):",
            "                pass",
            "",
            "        return flask_assets.FlaskResolver.split_prefix(self, ctx, item)",
            "",
            "    def resolve_output_to_path(self, ctx, target, bundle):",
            "        import os",
            "",
            "        return os.path.normpath(os.path.join(ctx.environment.directory, target))",
            "",
            "",
            "##~~ Webassets updater that takes changes in the configuration into account",
            "",
            "",
            "class SettingsCheckUpdater(webassets.updater.BaseUpdater):",
            "    updater = \"always\"",
            "",
            "    def __init__(self):",
            "        self._delegate = webassets.updater.get_updater(self.__class__.updater)",
            "",
            "    def needs_rebuild(self, bundle, ctx):",
            "        return self._delegate.needs_rebuild(bundle, ctx) or self.changed_settings(ctx)",
            "",
            "    def changed_settings(self, ctx):",
            "        if not ctx.cache:",
            "            return False",
            "",
            "        cache_key = (\"octo\", \"settings\")",
            "        current_hash = settings().effective_hash",
            "        cached_hash = ctx.cache.get(cache_key)",
            "        # This may seem counter-intuitive, but if no cache entry is found",
            "        # then we actually return \"no update needed\". This is because",
            "        # otherwise if no cache / a dummy cache is used, then we would be",
            "        # rebuilding every single time.",
            "        if cached_hash is not None:",
            "            return cached_hash != current_hash",
            "        return False",
            "",
            "    def build_done(self, bundle, ctx):",
            "        self._delegate.build_done(bundle, ctx)",
            "        if not ctx.cache:",
            "            return",
            "",
            "        cache_key = (\"octo\", \"settings\")",
            "        ctx.cache.set(cache_key, settings().effective_hash)",
            "",
            "",
            "##~~ core assets collector",
            "def collect_core_assets(preferred_stylesheet=\"css\"):",
            "    assets = {\"js\": [], \"clientjs\": [], \"css\": [], \"less\": []}",
            "    assets[\"js\"] = [",
            "        \"js/app/bindings/allowbindings.js\",",
            "        \"js/app/bindings/contextmenu.js\",",
            "        \"js/app/bindings/gettext.js\",",
            "        \"js/app/bindings/invisible.js\",",
            "        \"js/app/bindings/popover.js\",",
            "        \"js/app/bindings/qrcode.js\",",
            "        \"js/app/bindings/slimscrolledforeach.js\",",
            "        \"js/app/bindings/toggle.js\",",
            "        \"js/app/bindings/togglecontent.js\",",
            "        \"js/app/bindings/valuewithinit.js\",",
            "        \"js/app/viewmodels/access.js\",",
            "        \"js/app/viewmodels/appearance.js\",",
            "        \"js/app/viewmodels/connection.js\",",
            "        \"js/app/viewmodels/control.js\",",
            "        \"js/app/viewmodels/files.js\",",
            "        \"js/app/viewmodels/firstrun_wizard.js\",",
            "        \"js/app/viewmodels/loginstate.js\",",
            "        \"js/app/viewmodels/loginui.js\",",
            "        \"js/app/viewmodels/navigation.js\",",
            "        \"js/app/viewmodels/printerstate.js\",",
            "        \"js/app/viewmodels/printerprofiles.js\",",
            "        \"js/app/viewmodels/settings.js\",",
            "        \"js/app/viewmodels/slicing.js\",",
            "        \"js/app/viewmodels/system.js\",",
            "        \"js/app/viewmodels/temperature.js\",",
            "        \"js/app/viewmodels/terminal.js\",",
            "        \"js/app/viewmodels/timelapse.js\",",
            "        \"js/app/viewmodels/uistate.js\",",
            "        \"js/app/viewmodels/users.js\",",
            "        \"js/app/viewmodels/usersettings.js\",",
            "        \"js/app/viewmodels/wizard.js\",",
            "        \"js/app/viewmodels/about.js\",",
            "    ]",
            "",
            "    assets[\"clientjs\"] = [",
            "        \"js/app/client/base.js\",",
            "        \"js/app/client/socket.js\",",
            "        \"js/app/client/access.js\",",
            "        \"js/app/client/browser.js\",",
            "        \"js/app/client/connection.js\",",
            "        \"js/app/client/control.js\",",
            "        \"js/app/client/files.js\",",
            "        \"js/app/client/job.js\",",
            "        \"js/app/client/languages.js\",",
            "        \"js/app/client/printer.js\",",
            "        \"js/app/client/printerprofiles.js\",",
            "        \"js/app/client/settings.js\",",
            "        \"js/app/client/slicing.js\",",
            "        \"js/app/client/system.js\",",
            "        \"js/app/client/timelapse.js\",",
            "        \"js/app/client/users.js\",",
            "        \"js/app/client/util.js\",",
            "        \"js/app/client/wizard.js\",",
            "    ]",
            "",
            "    if preferred_stylesheet == \"less\":",
            "        assets[\"less\"].append(\"less/octoprint.less\")",
            "    elif preferred_stylesheet == \"css\":",
            "        assets[\"css\"].append(\"css/octoprint.css\")",
            "",
            "    return assets",
            "",
            "",
            "##~~ plugin assets collector",
            "",
            "",
            "def collect_plugin_assets(preferred_stylesheet=\"css\"):",
            "    logger = logging.getLogger(__name__ + \".collect_plugin_assets\")",
            "",
            "    supported_stylesheets = (\"css\", \"less\")",
            "    assets = {",
            "        \"bundled\": {",
            "            \"js\": DefaultOrderedDict(list),",
            "            \"clientjs\": DefaultOrderedDict(list),",
            "            \"css\": DefaultOrderedDict(list),",
            "            \"less\": DefaultOrderedDict(list),",
            "        },",
            "        \"external\": {",
            "            \"js\": DefaultOrderedDict(list),",
            "            \"clientjs\": DefaultOrderedDict(list),",
            "            \"css\": DefaultOrderedDict(list),",
            "            \"less\": DefaultOrderedDict(list),",
            "        },",
            "    }",
            "",
            "    asset_plugins = octoprint.plugin.plugin_manager().get_implementations(",
            "        octoprint.plugin.AssetPlugin",
            "    )",
            "    for implementation in asset_plugins:",
            "        name = implementation._identifier",
            "        is_bundled = implementation._plugin_info.bundled",
            "",
            "        asset_key = \"bundled\" if is_bundled else \"external\"",
            "",
            "        try:",
            "            all_assets = implementation.get_assets()",
            "            basefolder = implementation.get_asset_folder()",
            "        except Exception:",
            "            logger.exception(",
            "                \"Got an error while trying to collect assets from {}, ignoring assets from the plugin\".format(",
            "                    name",
            "                ),",
            "                extra={\"plugin\": name},",
            "            )",
            "            continue",
            "",
            "        def asset_exists(category, asset):",
            "            exists = os.path.exists(os.path.join(basefolder, asset))",
            "            if not exists:",
            "                logger.warning(",
            "                    \"Plugin {} is referring to non existing {} asset {}\".format(",
            "                        name, category, asset",
            "                    )",
            "                )",
            "            return exists",
            "",
            "        if \"js\" in all_assets:",
            "            for asset in all_assets[\"js\"]:",
            "                if not asset_exists(\"js\", asset):",
            "                    continue",
            "                assets[asset_key][\"js\"][name].append(f\"plugin/{name}/{asset}\")",
            "",
            "        if \"clientjs\" in all_assets:",
            "            for asset in all_assets[\"clientjs\"]:",
            "                if not asset_exists(\"clientjs\", asset):",
            "                    continue",
            "                assets[asset_key][\"clientjs\"][name].append(f\"plugin/{name}/{asset}\")",
            "",
            "        if preferred_stylesheet in all_assets:",
            "            for asset in all_assets[preferred_stylesheet]:",
            "                if not asset_exists(preferred_stylesheet, asset):",
            "                    continue",
            "                assets[asset_key][preferred_stylesheet][name].append(",
            "                    f\"plugin/{name}/{asset}\"",
            "                )",
            "        else:",
            "            for stylesheet in supported_stylesheets:",
            "                if stylesheet not in all_assets:",
            "                    continue",
            "",
            "                for asset in all_assets[stylesheet]:",
            "                    if not asset_exists(stylesheet, asset):",
            "                        continue",
            "                    assets[asset_key][stylesheet][name].append(f\"plugin/{name}/{asset}\")",
            "                break",
            "",
            "    return assets",
            "",
            "",
            "##~~ JSON encoding",
            "",
            "",
            "class OctoPrintJsonProvider(flask.json.provider.DefaultJSONProvider):",
            "    @staticmethod",
            "    def default(object_):",
            "        try:",
            "            return JsonEncoding.encode(object_)",
            "        except TypeError:",
            "            return flask.json.provider.DefaultJSONProvider.default(object_)",
            "",
            "    def dumps(self, obj: Any, **kwargs: Any) -> str:",
            "        kwargs.setdefault(\"allow_nan\", False)",
            "        return super().dumps(obj, **kwargs)",
            "",
            "",
            "##~~ Session signing",
            "",
            "",
            "def session_signature(user, session):",
            "    from octoprint.server import userManager",
            "",
            "    key = userManager.signature_key_for_user(user, current_app.config[\"SECRET_KEY\"])",
            "    return hmac.new(",
            "        key.encode(\"utf-8\"), session.encode(\"utf-8\"), hashlib.sha512",
            "    ).hexdigest()",
            "",
            "",
            "def validate_session_signature(sig, user, session):",
            "    user_sig = session_signature(user, session)",
            "    return len(user_sig) == len(sig) and hmac.compare_digest(sig, user_sig)"
        ],
        "afterPatchFile": [
            "from flask import make_response",
            "",
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import functools",
            "import hashlib",
            "import hmac",
            "import logging",
            "import os",
            "import threading",
            "import time",
            "from datetime import datetime, timedelta, timezone",
            "from typing import Any, Dict, List, Union",
            "",
            "import flask",
            "import flask.json",
            "import flask.json.provider",
            "import flask.sessions",
            "import flask.templating",
            "import flask_assets",
            "import flask_login",
            "import netaddr",
            "import tornado.web",
            "import webassets.updater",
            "import webassets.utils",
            "from cachelib import BaseCache",
            "from flask import current_app",
            "from flask_login import COOKIE_NAME as REMEMBER_COOKIE_NAME",
            "from flask_login.utils import decode_cookie, encode_cookie",
            "from pydantic import BaseModel",
            "from werkzeug.local import LocalProxy",
            "from werkzeug.utils import cached_property",
            "",
            "import octoprint.access.users",
            "import octoprint.plugin",
            "import octoprint.server",
            "import octoprint.vendor.flask_principal as flask_principal",
            "from octoprint.access import auth_log",
            "from octoprint.events import Events, eventManager",
            "from octoprint.settings import settings",
            "from octoprint.util import DefaultOrderedDict, deprecated, yaml",
            "from octoprint.util.json import JsonEncoding",
            "from octoprint.util.net import is_lan_address",
            "from octoprint.util.tz import UTC_TZ, is_timezone_aware",
            "",
            "# ~~ monkey patching",
            "",
            "",
            "def enable_additional_translations(default_locale=\"en\", additional_folders=None):",
            "    import os",
            "",
            "    import flask_babel",
            "    from babel import Locale, support",
            "",
            "    if additional_folders is None:",
            "        additional_folders = []",
            "",
            "    logger = logging.getLogger(__name__)",
            "",
            "    def fixed_list_translations(self):",
            "        \"\"\"Returns a list of all the locales translations exist for.  The",
            "        list returned will be filled with actual locale objects and not just",
            "        strings.",
            "        \"\"\"",
            "",
            "        def list_translations(dirname):",
            "            if not os.path.isdir(dirname):",
            "                return []",
            "            result = []",
            "            for entry in os.scandir(dirname):",
            "                locale_dir = os.path.join(entry.path, \"LC_MESSAGES\")",
            "                if not os.path.isdir(locale_dir):",
            "                    continue",
            "                if any(filter(lambda x: x.name.endswith(\".mo\"), os.scandir(locale_dir))):",
            "                    result.append(Locale.parse(entry.name))",
            "            return result",
            "",
            "        dirs = additional_folders + [os.path.join(self.app.root_path, \"translations\")]",
            "",
            "        # translations from plugins",
            "        plugins = octoprint.plugin.plugin_manager().enabled_plugins",
            "        for plugin in plugins.values():",
            "            plugin_translation_dir = os.path.join(plugin.location, \"translations\")",
            "            if not os.path.isdir(plugin_translation_dir):",
            "                continue",
            "            dirs.append(plugin_translation_dir)",
            "",
            "        result = {Locale.parse(default_locale)}",
            "",
            "        for dir in dirs:",
            "            result.update(list_translations(dir))",
            "        return list(result)",
            "",
            "    def fixed_get_translations():",
            "        \"\"\"Returns the correct gettext translations that should be used for",
            "        this request.  This will never fail and return a dummy translation",
            "        object if used outside of the request or if a translation cannot be",
            "        found.",
            "        \"\"\"",
            "        if flask.g is None:",
            "            return None",
            "        translations = getattr(flask.g, \"babel_translations\", None)",
            "        if translations is None:",
            "            locale = flask_babel.get_locale()",
            "            translations = support.Translations()",
            "",
            "            if str(locale) != default_locale:",
            "                # plugin translations",
            "                plugins = octoprint.plugin.plugin_manager().enabled_plugins",
            "                for name, plugin in plugins.items():",
            "                    dirs = list(",
            "                        map(",
            "                            lambda x: os.path.join(x, \"_plugins\", name),",
            "                            additional_folders,",
            "                        )",
            "                    ) + [os.path.join(plugin.location, \"translations\")]",
            "                    for dirname in dirs:",
            "                        if not os.path.isdir(dirname):",
            "                            continue",
            "",
            "                        try:",
            "                            plugin_translations = support.Translations.load(",
            "                                dirname, [locale]",
            "                            )",
            "                        except Exception:",
            "                            logger.exception(",
            "                                f\"Error while trying to load translations \"",
            "                                f\"for plugin {name}\"",
            "                            )",
            "                        else:",
            "                            if isinstance(plugin_translations, support.Translations):",
            "                                translations = translations.merge(plugin_translations)",
            "                                logger.debug(",
            "                                    f\"Using translation plugin folder {dirname} from \"",
            "                                    f\"plugin {name} for locale {locale}\"",
            "                                )",
            "                                break",
            "                    else:",
            "                        logger.debug(",
            "                            f\"No translations for locale {locale} \" f\"from plugin {name}\"",
            "                        )",
            "",
            "                # core translations",
            "                dirs = additional_folders + [",
            "                    os.path.join(flask.current_app.root_path, \"translations\")",
            "                ]",
            "                for dirname in dirs:",
            "                    core_translations = support.Translations.load(dirname, [locale])",
            "                    if isinstance(core_translations, support.Translations):",
            "                        logger.debug(",
            "                            f\"Using translation core folder {dirname} \"",
            "                            f\"for locale {locale}\"",
            "                        )",
            "                        break",
            "                else:",
            "                    logger.debug(f\"No translations for locale {locale} in core folders\")",
            "                translations = translations.merge(core_translations)",
            "",
            "            flask.g.babel_translations = translations",
            "        return translations",
            "",
            "    flask_babel.Babel.list_translations = fixed_list_translations",
            "    flask_babel.get_translations = fixed_get_translations",
            "",
            "",
            "def fix_webassets_filtertool():",
            "    from webassets.merge import FilterTool, MemoryHunk, log",
            "",
            "    error_logger = logging.getLogger(__name__ + \".fix_webassets_filtertool\")",
            "",
            "    def fixed_wrap_cache(self, key, func):",
            "        \"\"\"Return cache value ``key``, or run ``func``.\"\"\"",
            "        if self.cache:",
            "            if not self.no_cache_read:",
            "                log.debug(\"Checking cache for key %s\", key)",
            "                content = self.cache.get(key)",
            "                if content not in (False, None):",
            "                    log.debug(\"Using cached result for %s\", key)",
            "                    return MemoryHunk(content)",
            "",
            "        try:",
            "            content = func().getvalue()",
            "            if self.cache:",
            "                try:",
            "                    log.debug(",
            "                        \"Storing result in cache with key %s\",",
            "                        key,",
            "                    )",
            "                    self.cache.set(key, content)",
            "                except Exception:",
            "                    error_logger.exception(",
            "                        \"Got an exception while trying to save file to cache, not caching\"",
            "                    )",
            "            return MemoryHunk(content)",
            "        except Exception:",
            "            error_logger.exception(",
            "                \"Got an exception while trying to apply filter, ignoring file\"",
            "            )",
            "            return MemoryHunk(\"\")",
            "",
            "    FilterTool._wrap_cache = fixed_wrap_cache",
            "",
            "",
            "def fix_webassets_convert_item_to_flask_url():",
            "    import flask_assets",
            "",
            "    def fixed_convert_item_to_flask_url(self, ctx, item, filepath=None):",
            "        from flask import url_for",
            "",
            "        directory, rel_path, endpoint = self.split_prefix(ctx, item)",
            "",
            "        if filepath is not None:",
            "            filename = filepath[len(directory) + 1 :]",
            "        else:",
            "            filename = rel_path",
            "",
            "        flask_ctx = None",
            "        if not flask.has_request_context():  # fixed, was _request_ctx.top",
            "            flask_ctx = ctx.environment._app.test_request_context()",
            "            flask_ctx.push()",
            "        try:",
            "            url = url_for(endpoint, filename=filename)",
            "            # In some cases, url will be an absolute url with a scheme and hostname.",
            "            # (for example, when using werkzeug's host matching).",
            "            # In general, url_for() will return a http url. During assets build, we",
            "            # we don't know yet if the assets will be served over http, https or both.",
            "            # Let's use // instead. url_for takes a _scheme argument, but only together",
            "            # with external=True, which we do not want to force every time. Further,",
            "            # this _scheme argument is not able to render // - it always forces a colon.",
            "            if url and url.startswith(\"http:\"):",
            "                url = url[5:]",
            "            return url",
            "        finally:",
            "            if flask_ctx:",
            "                flask_ctx.pop()",
            "",
            "    flask_assets.FlaskResolver.convert_item_to_flask_url = fixed_convert_item_to_flask_url",
            "",
            "",
            "# ~~ WSGI environment wrapper for reverse proxying",
            "",
            "",
            "class ReverseProxiedEnvironment:",
            "    @staticmethod",
            "    def to_header_candidates(values):",
            "        if values is None:",
            "            return []",
            "        if not isinstance(values, (list, tuple)):",
            "            values = [values]",
            "        to_wsgi_format = lambda header: \"HTTP_\" + header.upper().replace(\"-\", \"_\")",
            "        return list(map(to_wsgi_format, values))",
            "",
            "    @staticmethod",
            "    def valid_ip(address):",
            "        import netaddr",
            "",
            "        try:",
            "            netaddr.IPAddress(address)",
            "            return True",
            "        except Exception:",
            "            return False",
            "",
            "    def __init__(",
            "        self,",
            "        header_prefix=None,",
            "        header_scheme=None,",
            "        header_host=None,",
            "        header_server=None,",
            "        header_port=None,",
            "        prefix=None,",
            "        scheme=None,",
            "        host=None,",
            "        server=None,",
            "        port=None,",
            "    ):",
            "        # sensible defaults",
            "        if header_prefix is None:",
            "            header_prefix = [\"x-script-name\", \"x-forwarded-prefix\"]",
            "        if header_scheme is None:",
            "            header_scheme = [\"x-forwarded-proto\", \"x-scheme\"]",
            "        if header_host is None:",
            "            header_host = [\"x-forwarded-host\"]",
            "        if header_server is None:",
            "            header_server = [\"x-forwarded-server\"]",
            "        if header_port is None:",
            "            header_port = [\"x-forwarded-port\"]",
            "",
            "        # header candidates",
            "        self._headers_prefix = self.to_header_candidates(header_prefix)",
            "        self._headers_scheme = self.to_header_candidates(header_scheme)",
            "        self._headers_host = self.to_header_candidates(header_host)",
            "        self._headers_server = self.to_header_candidates(header_server)",
            "        self._headers_port = self.to_header_candidates(header_port)",
            "",
            "        # fallback prefix & scheme & host from config",
            "        self._fallback_prefix = prefix",
            "        self._fallback_scheme = scheme",
            "        self._fallback_host = host",
            "        self._fallback_server = server",
            "        self._fallback_port = port",
            "",
            "    def __call__(self, environ):",
            "        def retrieve_header(header_type):",
            "            candidates = getattr(self, \"_headers_\" + header_type, [])",
            "            fallback = getattr(self, \"_fallback_\" + header_type, None)",
            "",
            "            for candidate in candidates:",
            "                value = environ.get(candidate, None)",
            "                if value is not None:",
            "                    return value",
            "            else:",
            "                return fallback",
            "",
            "        def host_to_server_and_port(host, scheme):",
            "            if host is None:",
            "                return None, None",
            "",
            "            default_port = \"443\" if scheme == \"https\" else \"80\"",
            "            host = host.strip()",
            "",
            "            if \":\" in host:",
            "                # we might have an ipv6 address here, or a port, or both",
            "",
            "                if host[0] == \"[\":",
            "                    # that looks like an ipv6 address with port, e.g. [fec1::1]:80",
            "                    address_end = host.find(\"]\")",
            "                    if address_end == -1:",
            "                        # no ], that looks like a seriously broken address",
            "                        return None, None",
            "",
            "                    # extract server ip, skip enclosing [ and ]",
            "                    server = host[1:address_end]",
            "                    tail = host[address_end + 1 :]",
            "",
            "                    # now check if there's also a port",
            "                    if len(tail) and tail[0] == \":\":",
            "                        # port included as well",
            "                        port = tail[1:]",
            "                    else:",
            "                        # no port, use default one",
            "                        port = default_port",
            "",
            "                elif self.__class__.valid_ip(host):",
            "                    # ipv6 address without port",
            "                    server = host",
            "                    port = default_port",
            "",
            "                else:",
            "                    # ipv4 address with port",
            "                    server, port = host.rsplit(\":\", 1)",
            "",
            "            else:",
            "                server = host",
            "                port = default_port",
            "",
            "            return server, port",
            "",
            "        # determine prefix",
            "        prefix = retrieve_header(\"prefix\")",
            "        if prefix is not None:",
            "            environ[\"SCRIPT_NAME\"] = prefix",
            "            path_info = environ[\"PATH_INFO\"]",
            "            if path_info.startswith(prefix):",
            "                environ[\"PATH_INFO\"] = path_info[len(prefix) :]",
            "",
            "        # determine scheme",
            "        scheme = retrieve_header(\"scheme\")",
            "        if scheme is not None and \",\" in scheme:",
            "            # Scheme might be something like \"https,https\" if doubly-reverse-proxied",
            "            # without stripping original scheme header first, make sure to only use",
            "            # the first entry in such a case. See #1391.",
            "            scheme, _ = map(lambda x: x.strip(), scheme.split(\",\", 1))",
            "        if scheme is not None:",
            "            environ[\"wsgi.url_scheme\"] = scheme",
            "",
            "        # determine host",
            "        url_scheme = environ[\"wsgi.url_scheme\"]",
            "        host = retrieve_header(\"host\")",
            "        if host is not None:",
            "            # if we have a host, we take server_name and server_port from it",
            "            server, port = host_to_server_and_port(host, url_scheme)",
            "            environ[\"HTTP_HOST\"] = host",
            "            environ[\"SERVER_NAME\"] = server",
            "            environ[\"SERVER_PORT\"] = port",
            "",
            "        elif environ.get(\"HTTP_HOST\", None) is not None:",
            "            # if we have a Host header, we use that and make sure our server name and port properties match it",
            "            host = environ[\"HTTP_HOST\"]",
            "            server, port = host_to_server_and_port(host, url_scheme)",
            "            environ[\"SERVER_NAME\"] = server",
            "            environ[\"SERVER_PORT\"] = port",
            "",
            "        else:",
            "            # else we take a look at the server and port headers and if we have",
            "            # something there we derive the host from it",
            "",
            "            # determine server - should usually not be used",
            "            server = retrieve_header(\"server\")",
            "            if server is not None:",
            "                environ[\"SERVER_NAME\"] = server",
            "",
            "            # determine port - should usually not be used",
            "            port = retrieve_header(\"port\")",
            "            if port is not None:",
            "                environ[\"SERVER_PORT\"] = port",
            "",
            "            # reconstruct host header",
            "            if (",
            "                url_scheme == \"http\"",
            "                and environ[\"SERVER_PORT\"] == \"80\"",
            "                or url_scheme == \"https\"",
            "                and environ[\"SERVER_PORT\"] == \"443\"",
            "            ):",
            "                # default port for scheme, can be skipped",
            "                environ[\"HTTP_HOST\"] = environ[\"SERVER_NAME\"]",
            "            else:",
            "                server_name_component = environ[\"SERVER_NAME\"]",
            "                if \":\" in server_name_component and self.__class__.valid_ip(",
            "                    server_name_component",
            "                ):",
            "                    # this is an ipv6 address, we need to wrap that in [ and ] before appending the port",
            "                    server_name_component = \"[\" + server_name_component + \"]\"",
            "",
            "                environ[\"HTTP_HOST\"] = (",
            "                    server_name_component + \":\" + environ[\"SERVER_PORT\"]",
            "                )",
            "",
            "        # call wrapped app with rewritten environment",
            "        return environ",
            "",
            "",
            "# ~~ request and response versions",
            "",
            "",
            "def encode_remember_me_cookie(value):",
            "    from octoprint.server import userManager",
            "",
            "    name = value.split(\"|\")[0]",
            "    try:",
            "        remember_key = userManager.signature_key_for_user(",
            "            name, current_app.config[\"SECRET_KEY\"]",
            "        )",
            "        timestamp = datetime.utcnow().timestamp()",
            "        return encode_cookie(f\"{name}|{timestamp}\", key=remember_key)",
            "    except Exception:",
            "        pass",
            "",
            "    return \"\"",
            "",
            "",
            "def decode_remember_me_cookie(value):",
            "    from octoprint.server import userManager",
            "",
            "    parts = value.split(\"|\")",
            "    if len(parts) == 3:",
            "        name, created, _ = parts",
            "",
            "        try:",
            "            # valid signature?",
            "            signature_key = userManager.signature_key_for_user(",
            "                name, current_app.config[\"SECRET_KEY\"]",
            "            )",
            "            cookie = decode_cookie(value, key=signature_key)",
            "            if cookie:",
            "                # still valid?",
            "                if (",
            "                    datetime.fromtimestamp(float(created))",
            "                    + timedelta(seconds=current_app.config[\"REMEMBER_COOKIE_DURATION\"])",
            "                    > datetime.utcnow()",
            "                ):",
            "                    return encode_cookie(name)",
            "        except Exception:",
            "            pass",
            "",
            "    raise ValueError(\"Invalid remember me cookie\")",
            "",
            "",
            "def get_cookie_suffix(request):",
            "    \"\"\"",
            "    Request specific suffix for set and read cookies",
            "",
            "    We need this because cookies are not port-specific and we don't want to overwrite our",
            "    session and other cookies from one OctoPrint instance on our machine with those of another",
            "    one who happens to listen on the same address albeit a different port or script root.",
            "    \"\"\"",
            "    result = \"_P\" + request.server_port",
            "    if request.script_root:",
            "        return result + \"_R\" + request.script_root.replace(\"/\", \"|\")",
            "    return result",
            "",
            "",
            "class OctoPrintFlaskRequest(flask.Request):",
            "    environment_wrapper = staticmethod(lambda x: x)",
            "",
            "    def __init__(self, environ, *args, **kwargs):",
            "        # apply environment wrapper to provided WSGI environment",
            "        flask.Request.__init__(self, self.environment_wrapper(environ), *args, **kwargs)",
            "",
            "    @cached_property",
            "    def cookies(self):",
            "        # strip cookie_suffix from all cookies in the request, return result",
            "        cookies = flask.Request.cookies.__get__(self)",
            "",
            "        result = {}",
            "        desuffixed = {}",
            "        for key, value in cookies.items():",
            "",
            "            def process_value(k, v):",
            "                if k == current_app.config.get(",
            "                    \"REMEMBER_COOKIE_NAME\", REMEMBER_COOKIE_NAME",
            "                ):",
            "                    return decode_remember_me_cookie(v)",
            "                return v",
            "",
            "            try:",
            "                if key.endswith(self.cookie_suffix):",
            "                    key = key[: -len(self.cookie_suffix)]",
            "                    desuffixed[key] = process_value(key, value)",
            "                else:",
            "                    result[key] = process_value(key, value)",
            "            except ValueError:",
            "                # ignore broken cookies",
            "                pass",
            "",
            "        result.update(desuffixed)",
            "        return result",
            "",
            "    @cached_property",
            "    def server_name(self):",
            "        \"\"\"Short cut to the request's server name header\"\"\"",
            "        return self.environ.get(\"SERVER_NAME\")",
            "",
            "    @cached_property",
            "    def server_port(self):",
            "        \"\"\"Short cut to the request's server port header\"\"\"",
            "        return self.environ.get(\"SERVER_PORT\")",
            "",
            "    @cached_property",
            "    def cookie_suffix(self):",
            "        return get_cookie_suffix(self)",
            "",
            "",
            "class OctoPrintFlaskResponse(flask.Response):",
            "    def set_cookie(self, key, value=\"\", *args, **kwargs):",
            "        # restrict cookie path to script root",
            "        kwargs[\"path\"] = flask.request.script_root + kwargs.get(\"path\", \"/\")",
            "",
            "        # set same-site header",
            "        samesite = settings().get([\"server\", \"cookies\", \"samesite\"])",
            "        if samesite is not None:",
            "            samesite = samesite.lower()",
            "        if samesite == \"none\":",
            "            # Must be string \"None\"",
            "            samesite = \"None\"",
            "        if samesite not in (\"None\", \"strict\", \"lax\"):",
            "            # If NoneType, the cookie is not set",
            "            samesite = None",
            "        kwargs[\"samesite\"] = samesite",
            "",
            "        # set secure if necessary",
            "        kwargs[\"secure\"] = flask.request.environ.get(",
            "            \"wsgi.url_scheme\"",
            "        ) == \"https\" or settings().getBoolean([\"server\", \"cookies\", \"secure\"])",
            "",
            "        # tie account properties to remember me cookie (e.g. current password hash)",
            "        if key == current_app.config.get(\"REMEMBER_COOKIE_NAME\", REMEMBER_COOKIE_NAME):",
            "            value = encode_remember_me_cookie(value)",
            "",
            "        # add request specific cookie suffix to name",
            "        flask.Response.set_cookie(",
            "            self, key + flask.request.cookie_suffix, value=value, *args, **kwargs",
            "        )",
            "",
            "    def delete_cookie(self, key, path=\"/\", domain=None):",
            "        flask.Response.delete_cookie(self, key, path=path, domain=domain)",
            "",
            "        # we also still might have a cookie left over from before we started prefixing, delete that manually",
            "        # without any pre processing (no path prefix, no key suffix)",
            "        flask.Response.set_cookie(",
            "            self, key, expires=0, max_age=0, path=path, domain=domain",
            "        )",
            "",
            "",
            "class OctoPrintSessionInterface(flask.sessions.SecureCookieSessionInterface):",
            "    def should_set_cookie(self, app, session):",
            "        return flask.request.endpoint != \"static\"",
            "",
            "    def save_session(self, app, session, response):",
            "        if flask.g.get(\"login_via_apikey\", False):",
            "            return",
            "        return super().save_session(app, session, response)",
            "",
            "",
            "# ~~ jinja environment",
            "",
            "",
            "class PrefixAwareJinjaEnvironment(flask.templating.Environment):",
            "    def __init__(self, *args, **kwargs):",
            "        flask.templating.Environment.__init__(self, *args, **kwargs)",
            "        self.prefix_loader = None",
            "        self._cached_templates = {}",
            "",
            "    def join_path(self, template, parent):",
            "        if parent and \"/\" in parent:",
            "            prefix, _ = parent.split(\"/\", 1)",
            "            if template in self._templates_for_prefix(prefix) and not template.startswith(",
            "                prefix + \"/\"",
            "            ):",
            "                return prefix + \"/\" + template",
            "",
            "        return template",
            "",
            "    def _templates_for_prefix(self, prefix):",
            "        if prefix in self._cached_templates:",
            "            return self._cached_templates[prefix]",
            "",
            "        templates = []",
            "        if prefix in self.prefix_loader.mapping:",
            "            templates = self.prefix_loader.mapping[prefix].list_templates()",
            "        self._cached_templates[prefix] = templates",
            "        return templates",
            "",
            "",
            "# ~~ passive login helper",
            "",
            "_cached_local_networks = None",
            "",
            "",
            "def _local_networks():",
            "    global _cached_local_networks",
            "",
            "    if _cached_local_networks is None:",
            "        logger = logging.getLogger(__name__)",
            "        local_networks = netaddr.IPSet([])",
            "        for entry in settings().get([\"accessControl\", \"localNetworks\"]):",
            "            try:",
            "                network = netaddr.IPNetwork(entry)",
            "            except Exception:",
            "                logger.warning(",
            "                    \"Invalid network definition configured in localNetworks: {}\".format(",
            "                        entry",
            "                    )",
            "                )",
            "                continue",
            "",
            "            local_networks.add(network)",
            "            logger.debug(f\"Added network {network} to localNetworks\")",
            "",
            "            if network.version == 4:",
            "                network_v6 = network.ipv6()",
            "                local_networks.add(network_v6)",
            "                logger.debug(",
            "                    \"Also added v6 representation of v4 network {} = {} to localNetworks\".format(",
            "                        network, network_v6",
            "                    )",
            "                )",
            "",
            "        _cached_local_networks = local_networks",
            "",
            "    return _cached_local_networks",
            "",
            "",
            "def passive_login():",
            "    logger = logging.getLogger(__name__)",
            "",
            "    user = flask_login.current_user",
            "",
            "    remote_address = flask.request.remote_addr",
            "    ip_check_enabled = settings().getBoolean([\"server\", \"ipCheck\", \"enabled\"])",
            "    ip_check_trusted = settings().get([\"server\", \"ipCheck\", \"trustedSubnets\"])",
            "",
            "    if isinstance(user, LocalProxy):",
            "        # noinspection PyProtectedMember",
            "        user = user._get_current_object()",
            "",
            "    def login(u):",
            "        # login known user",
            "        if not u.is_anonymous:",
            "            if not flask.g.identity or not flask.g.identity.id:",
            "                # the user was just now found",
            "                login_mechanism = octoprint.server.util.LoginMechanism.to_log(",
            "                    flask.session.get(\"login_mechanism\", \"unknown\")",
            "                )",
            "                auth_log(",
            "                    f\"Logging in user {u.get_id()} from {remote_address} via {login_mechanism}\"",
            "                )",
            "            u = octoprint.server.userManager.login_user(u)",
            "",
            "        flask_login.login_user(u)",
            "        flask_principal.identity_changed.send(",
            "            flask.current_app._get_current_object(),",
            "            identity=flask_principal.Identity(u.get_id()),",
            "        )",
            "        if hasattr(u, \"session\"):",
            "            flask.session[\"usersession.id\"] = u.session",
            "            flask.session[\"usersession.signature\"] = session_signature(",
            "                u.get_id(), u.session",
            "            )",
            "        flask.g.user = u",
            "",
            "        eventManager().fire(Events.USER_LOGGED_IN, payload={\"username\": u.get_id()})",
            "",
            "        return u",
            "",
            "    def determine_user(u):",
            "        if not u.is_anonymous and u.is_active:",
            "            # known active user",
            "            logger.info(f\"Passively logging in user {u.get_id()} from {remote_address}\")",
            "",
            "        elif (",
            "            settings().getBoolean([\"accessControl\", \"autologinLocal\"])",
            "            and settings().get([\"accessControl\", \"autologinAs\"]) is not None",
            "            and settings().get([\"accessControl\", \"localNetworks\"]) is not None",
            "            and \"active_logout\" not in flask.request.cookies",
            "            and remote_address",
            "        ):",
            "            # attempt local autologin",
            "            autologin_as = settings().get([\"accessControl\", \"autologinAs\"])",
            "            local_networks = _local_networks()",
            "            logger.debug(",
            "                \"Checking if remote address {} is in localNetworks ({!r})\".format(",
            "                    remote_address, local_networks",
            "                )",
            "            )",
            "",
            "            try:",
            "                if netaddr.IPAddress(remote_address) in local_networks:",
            "                    autologin_user = octoprint.server.userManager.find_user(autologin_as)",
            "                    if autologin_user is not None and autologin_user.is_active:",
            "                        logger.info(",
            "                            f\"Logging in user {autologin_as} from {remote_address} via autologin\"",
            "                        )",
            "                        flask.session[",
            "                            \"login_mechanism\"",
            "                        ] = octoprint.server.util.LoginMechanism.AUTOLOGIN",
            "                        flask.session[\"credentials_seen\"] = False",
            "                        return autologin_user",
            "            except Exception:",
            "                logger.exception(",
            "                    \"Could not autologin user {} from {} for networks {}\".format(",
            "                        autologin_as, remote_address, local_networks",
            "                    )",
            "                )",
            "",
            "        if not u.is_active:",
            "            # inactive user, switch to anonymous",
            "            u = octoprint.server.userManager.anonymous_user_factory()",
            "",
            "        return u",
            "",
            "    user = login(determine_user(user))",
            "    response = user.as_dict()",
            "    response[\"_is_external_client\"] = ip_check_enabled and not is_lan_address(",
            "        remote_address, additional_private=ip_check_trusted",
            "    )",
            "    if flask.session.get(\"login_mechanism\") is not None:",
            "        response[\"_login_mechanism\"] = flask.session.get(\"login_mechanism\")",
            "    response[\"_credentials_seen\"] = to_api_credentials_seen(",
            "        flask.session.get(\"credentials_seen\", False)",
            "    )",
            "    return flask.jsonify(response)",
            "",
            "",
            "def to_api_credentials_seen(credentials_seen):",
            "    if not credentials_seen:",
            "        return False",
            "",
            "    return (",
            "        datetime.fromtimestamp(credentials_seen, tz=timezone.utc)",
            "        .replace(microsecond=0)",
            "        .isoformat()",
            "    )",
            "",
            "",
            "# ~~ rate limiting helper",
            "",
            "",
            "def limit(*args, **kwargs):",
            "    if octoprint.server.limiter:",
            "        return octoprint.server.limiter.limit(*args, **kwargs)",
            "    else:",
            "",
            "        def decorator(f):",
            "            @functools.wraps(f)",
            "            def decorated_function(*args, **kwargs):",
            "                return f(*args, **kwargs)",
            "",
            "            return decorated_function",
            "",
            "        return decorator",
            "",
            "",
            "# ~~ cache decorator for cacheable views",
            "",
            "",
            "class LessSimpleCache(BaseCache):",
            "    \"\"\"",
            "    Slightly improved version of :class:`SimpleCache`.",
            "",
            "    Setting ``default_timeout`` or ``timeout`` to ``-1`` will have no timeout be applied at all.",
            "    \"\"\"",
            "",
            "    def __init__(self, threshold=500, default_timeout=300):",
            "        BaseCache.__init__(self, default_timeout=default_timeout)",
            "        self._mutex = threading.RLock()",
            "        self._cache = {}",
            "        self._bypassed = set()",
            "        self.clear = self._cache.clear",
            "        self._threshold = threshold",
            "",
            "    def _prune(self):",
            "        if self.over_threshold():",
            "            now = time.time()",
            "            for idx, (key, (expires, _)) in enumerate(self._cache.items()):",
            "                if expires is not None and expires <= now or idx % 3 == 0:",
            "                    with self._mutex:",
            "                        self._cache.pop(key, None)",
            "",
            "    def get(self, key):",
            "        import pickle",
            "",
            "        now = time.time()",
            "        with self._mutex:",
            "            expires, value = self._cache.get(key, (0, None))",
            "        if expires is None or expires > now:",
            "            return pickle.loads(value)",
            "",
            "    def set(self, key, value, timeout=None):",
            "        import pickle",
            "",
            "        with self._mutex:",
            "            self._prune()",
            "            self._cache[key] = (",
            "                self.calculate_timeout(timeout=timeout),",
            "                pickle.dumps(value, pickle.HIGHEST_PROTOCOL),",
            "            )",
            "            if key in self._bypassed:",
            "                self._bypassed.remove(key)",
            "",
            "    def add(self, key, value, timeout=None):",
            "        with self._mutex:",
            "            self.set(key, value, timeout=None)",
            "            self._cache.setdefault(key, self._cache[key])",
            "",
            "    def delete(self, key):",
            "        with self._mutex:",
            "            self._cache.pop(key, None)",
            "",
            "    def calculate_timeout(self, timeout=None):",
            "        if timeout is None:",
            "            timeout = self.default_timeout",
            "        if timeout == -1:",
            "            return None",
            "        return time.time() + timeout",
            "",
            "    def over_threshold(self):",
            "        if self._threshold is None:",
            "            return False",
            "        with self._mutex:",
            "            return len(self._cache) > self._threshold",
            "",
            "    def __getitem__(self, key):",
            "        return self.get(key)",
            "",
            "    def __setitem__(self, key, value):",
            "        return self.set(key, value)",
            "",
            "    def __delitem__(self, key):",
            "        return self.delete(key)",
            "",
            "    def __contains__(self, key):",
            "        with self._mutex:",
            "            return key in self._cache",
            "",
            "    def set_bypassed(self, key):",
            "        with self._mutex:",
            "            self._bypassed.add(key)",
            "",
            "    def is_bypassed(self, key):",
            "        with self._mutex:",
            "            return key in self._bypassed",
            "",
            "",
            "_cache = LessSimpleCache()",
            "",
            "",
            "def cached(",
            "    timeout=5 * 60,",
            "    key=lambda: \"view:%s\" % flask.request.path,",
            "    unless=None,",
            "    refreshif=None,",
            "    unless_response=None,",
            "):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            logger = logging.getLogger(__name__)",
            "",
            "            cache_key = key()",
            "",
            "            def f_with_duration(*args, **kwargs):",
            "                start_time = time.time()",
            "                try:",
            "                    return f(*args, **kwargs)",
            "                finally:",
            "                    elapsed = time.time() - start_time",
            "                    logger.debug(",
            "                        \"Needed {elapsed:.2f}s to render {path} (key: {key})\".format(",
            "                            elapsed=elapsed, path=flask.request.path, key=cache_key",
            "                        )",
            "                    )",
            "",
            "            # bypass the cache if \"unless\" condition is true",
            "            if callable(unless) and unless():",
            "                logger.debug(",
            "                    \"Cache for {path} bypassed, calling wrapped function\".format(",
            "                        path=flask.request.path",
            "                    )",
            "                )",
            "                _cache.set_bypassed(cache_key)",
            "                return f_with_duration(*args, **kwargs)",
            "",
            "            # also bypass the cache if it's disabled completely",
            "            if not settings().getBoolean([\"devel\", \"cache\", \"enabled\"]):",
            "                logger.debug(",
            "                    \"Cache for {path} disabled, calling wrapped function\".format(",
            "                        path=flask.request.path",
            "                    )",
            "                )",
            "                _cache.set_bypassed(cache_key)",
            "                return f_with_duration(*args, **kwargs)",
            "",
            "            rv = _cache.get(cache_key)",
            "",
            "            # only take the value from the cache if we are not required to refresh it from the wrapped function",
            "            if rv is not None and (not callable(refreshif) or not refreshif(rv)):",
            "                logger.debug(",
            "                    \"Serving entry for {path} from cache (key: {key})\".format(",
            "                        path=flask.request.path, key=cache_key",
            "                    )",
            "                )",
            "                if \"X-From-Cache\" not in rv.headers:",
            "                    rv.headers[\"X-From-Cache\"] = \"true\"",
            "                return rv",
            "",
            "            # get value from wrapped function",
            "            logger.debug(",
            "                \"No cache entry or refreshing cache for {path} (key: {key}), calling wrapped function\".format(",
            "                    path=flask.request.path, key=cache_key",
            "                )",
            "            )",
            "            rv = f_with_duration(*args, **kwargs)",
            "",
            "            # do not store if the \"unless_response\" condition is true",
            "            if callable(unless_response) and unless_response(rv):",
            "                logger.debug(",
            "                    \"Not caching result for {path} (key: {key}), bypassed\".format(",
            "                        path=flask.request.path, key=cache_key",
            "                    )",
            "                )",
            "                _cache.set_bypassed(cache_key)",
            "                return rv",
            "",
            "            # store it in the cache",
            "            _cache.set(cache_key, rv, timeout=timeout)",
            "",
            "            return rv",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def is_in_cache(key=lambda: \"view:%s\" % flask.request.path):",
            "    if callable(key):",
            "        key = key()",
            "    return key in _cache",
            "",
            "",
            "def is_cache_bypassed(key=lambda: \"view:%s\" % flask.request.path):",
            "    if callable(key):",
            "        key = key()",
            "    return _cache.is_bypassed(key)",
            "",
            "",
            "def cache_check_headers():",
            "    return \"no-cache\" in flask.request.cache_control or \"no-cache\" in flask.request.pragma",
            "",
            "",
            "def cache_check_response_headers(response):",
            "    if not isinstance(response, flask.Response):",
            "        return False",
            "",
            "    headers = response.headers",
            "",
            "    if \"Cache-Control\" in headers and (",
            "        \"no-cache\" in headers[\"Cache-Control\"] or \"no-store\" in headers[\"Cache-Control\"]",
            "    ):",
            "        return True",
            "",
            "    if \"Pragma\" in headers and \"no-cache\" in headers[\"Pragma\"]:",
            "        return True",
            "",
            "    if \"Expires\" in headers and headers[\"Expires\"] in (\"0\", \"-1\"):",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def cache_check_status_code(response, valid):",
            "    if not isinstance(response, flask.Response):",
            "        return False",
            "",
            "    if callable(valid):",
            "        return not valid(response.status_code)",
            "    else:",
            "        return response.status_code not in valid",
            "",
            "",
            "class PreemptiveCache:",
            "    def __init__(self, cachefile):",
            "        self.cachefile = cachefile",
            "        self.environment = None",
            "",
            "        self._logger = logging.getLogger(__name__ + \".\" + self.__class__.__name__)",
            "",
            "        self._lock = threading.RLock()",
            "",
            "    def record(self, data, unless=None, root=None):",
            "        if callable(unless) and unless():",
            "            return",
            "",
            "        entry_data = data",
            "        if callable(entry_data):",
            "            entry_data = entry_data()",
            "",
            "        if entry_data is not None:",
            "            if root is None:",
            "                from flask import request",
            "",
            "                root = request.path",
            "            self.add_data(root, entry_data)",
            "",
            "    def has_record(self, data, root=None):",
            "        if callable(data):",
            "            data = data()",
            "",
            "        if data is None:",
            "            return False",
            "",
            "        if root is None:",
            "            from flask import request",
            "",
            "            root = request.path",
            "",
            "        all_data = self.get_data(root)",
            "        for existing in all_data:",
            "            if self._compare_data(data, existing):",
            "                return True",
            "",
            "        return False",
            "",
            "    def clean_all_data(self, cleanup_function):",
            "        assert callable(cleanup_function)",
            "",
            "        with self._lock:",
            "            all_data = self.get_all_data()",
            "            for root, entries in list(all_data.items()):",
            "                old_count = len(entries)",
            "                entries = cleanup_function(root, entries)",
            "                if not entries:",
            "                    del all_data[root]",
            "                    self._logger.debug(f\"Removed root {root} from preemptive cache\")",
            "                elif len(entries) < old_count:",
            "                    all_data[root] = entries",
            "                    self._logger.debug(",
            "                        \"Removed {} entries from preemptive cache for root {}\".format(",
            "                            old_count - len(entries), root",
            "                        )",
            "                    )",
            "            self.set_all_data(all_data)",
            "",
            "        return all_data",
            "",
            "    def get_all_data(self):",
            "        cache_data = None",
            "        with self._lock:",
            "            try:",
            "                cache_data = yaml.load_from_file(path=self.cachefile)",
            "            except OSError as e:",
            "                import errno",
            "",
            "                if e.errno != errno.ENOENT:",
            "                    raise",
            "            except Exception:",
            "                self._logger.exception(f\"Error while reading {self.cachefile}\")",
            "",
            "        if cache_data is None:",
            "            cache_data = {}",
            "",
            "        if not self._validate_data(cache_data):",
            "            self._logger.warning(\"Preemptive cache data was invalid, ignoring it\")",
            "            cache_data = {}",
            "",
            "        return cache_data",
            "",
            "    def get_data(self, root):",
            "        cache_data = self.get_all_data()",
            "        return cache_data.get(root, list())",
            "",
            "    def set_all_data(self, data):",
            "        from octoprint.util import atomic_write",
            "",
            "        with self._lock:",
            "            try:",
            "                with atomic_write(self.cachefile, \"wt\", max_permissions=0o666) as handle:",
            "                    yaml.save_to_file(data, file=handle, pretty=True)",
            "            except Exception:",
            "                self._logger.exception(f\"Error while writing {self.cachefile}\")",
            "",
            "    def set_data(self, root, data):",
            "        with self._lock:",
            "            all_data = self.get_all_data()",
            "            all_data[root] = data",
            "            self.set_all_data(all_data)",
            "",
            "    def add_data(self, root, data):",
            "        def split_matched_and_unmatched(entry, entries):",
            "            matched = []",
            "            unmatched = []",
            "",
            "            for e in entries:",
            "                if self._compare_data(e, entry):",
            "                    matched.append(e)",
            "                else:",
            "                    unmatched.append(e)",
            "",
            "            return matched, unmatched",
            "",
            "        with self._lock:",
            "            cache_data = self.get_all_data()",
            "",
            "            if root not in cache_data:",
            "                cache_data[root] = []",
            "",
            "            existing, other = split_matched_and_unmatched(data, cache_data[root])",
            "",
            "            def get_newest(entries):",
            "                result = None",
            "                for entry in entries:",
            "                    if \"_timestamp\" in entry and (",
            "                        result is None",
            "                        or (",
            "                            \"_timestamp\" in result",
            "                            and result[\"_timestamp\"] < entry[\"_timestamp\"]",
            "                        )",
            "                    ):",
            "                        result = entry",
            "                return result",
            "",
            "            to_persist = get_newest(existing)",
            "            if not to_persist:",
            "                import copy",
            "",
            "                to_persist = copy.deepcopy(data)",
            "                to_persist[\"_timestamp\"] = time.time()",
            "                to_persist[\"_count\"] = 1",
            "                self._logger.info(f\"Adding entry for {root} and {to_persist!r}\")",
            "            else:",
            "                to_persist[\"_timestamp\"] = time.time()",
            "                to_persist[\"_count\"] = to_persist.get(\"_count\", 0) + 1",
            "                self._logger.debug(",
            "                    f\"Updating timestamp and counter for {root} and {data!r}\"",
            "                )",
            "",
            "            self.set_data(root, [to_persist] + other)",
            "",
            "    def _compare_data(self, a, b):",
            "        from octoprint.util import dict_filter",
            "",
            "        def strip_ignored(d):",
            "            return dict_filter(d, lambda k, v: not k.startswith(\"_\"))",
            "",
            "        return set(strip_ignored(a).items()) == set(strip_ignored(b).items())",
            "",
            "    def _validate_data(self, data):",
            "        if not isinstance(data, dict):",
            "            return False",
            "",
            "        for entries in data.values():",
            "            if not isinstance(entries, list):",
            "                return False",
            "",
            "            for entry in entries:",
            "                if not self._validate_entry(entry):",
            "                    return False",
            "",
            "        return True",
            "",
            "    def _validate_entry(self, entry):",
            "        return isinstance(entry, dict) and \"_timestamp\" in entry and \"_count\" in entry",
            "",
            "",
            "def preemptively_cached(cache, data, unless=None):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            try:",
            "                cache.record(data, unless=unless)",
            "            except Exception:",
            "                logging.getLogger(__name__).exception(",
            "                    f\"Error while recording preemptive cache entry: {data!r}\"",
            "                )",
            "            return f(*args, **kwargs)",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def etagged(etag):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            rv = f(*args, **kwargs)",
            "            if isinstance(rv, flask.Response):",
            "                try:",
            "                    result = etag",
            "                    if callable(result):",
            "                        result = result(rv)",
            "                    if result:",
            "                        rv.set_etag(result)",
            "                except Exception:",
            "                    logging.getLogger(__name__).exception(",
            "                        \"Error while calculating the etag value for response {!r}\".format(",
            "                            rv",
            "                        )",
            "                    )",
            "            return rv",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def lastmodified(date):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            rv = f(*args, **kwargs)",
            "            if \"Last-Modified\" not in rv.headers:",
            "                try:",
            "                    result = date",
            "                    if callable(result):",
            "                        result = result(rv)",
            "",
            "                    if not isinstance(result, str):",
            "                        from werkzeug.http import http_date",
            "",
            "                        result = http_date(result)",
            "",
            "                    if result:",
            "                        rv.headers[\"Last-Modified\"] = result",
            "                except Exception:",
            "                    logging.getLogger(__name__).exception(",
            "                        \"Error while calculating the lastmodified value for response {!r}\".format(",
            "                            rv",
            "                        )",
            "                    )",
            "            return rv",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def conditional(condition, met):",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            try:",
            "                if callable(condition) and condition():",
            "                    # condition has been met, return met-response",
            "                    rv = met",
            "                    if callable(met):",
            "                        rv = met()",
            "                    return rv",
            "            except Exception:",
            "                logging.getLogger(__name__).exception(",
            "                    \"Error while evaluating conditional {!r} or met {!r}\".format(",
            "                        condition, met",
            "                    )",
            "                )",
            "",
            "            # condition hasn't been met, call decorated function",
            "            return f(*args, **kwargs)",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def with_client_revalidation(f):",
            "    @functools.wraps(f)",
            "    def decorated_function(*args, **kwargs):",
            "        r = f(*args, **kwargs)",
            "",
            "        if isinstance(r, flask.Response):",
            "            r = add_revalidation_response_headers(r)",
            "",
            "        return r",
            "",
            "    return decorated_function",
            "",
            "",
            "def with_revalidation_checking(",
            "    etag_factory=None, lastmodified_factory=None, condition=None, unless=None",
            "):",
            "    if etag_factory is None:",
            "",
            "        def etag_factory(lm=None):",
            "            return None",
            "",
            "    if lastmodified_factory is None:",
            "",
            "        def lastmodified_factory():",
            "            return None",
            "",
            "    if condition is None:",
            "",
            "        def condition(lm=None, etag=None):",
            "            if lm is None:",
            "                lm = lastmodified_factory()",
            "",
            "            if etag is None:",
            "                etag = etag_factory(lm=lm)",
            "",
            "            if flask.request.if_none_match and flask.request.if_modified_since:",
            "                # use both",
            "                return check_lastmodified(lm) and check_etag(etag)",
            "            elif flask.request.if_none_match:",
            "                # use only ETag",
            "                return check_etag(etag)",
            "            elif flask.request.if_modified_since:",
            "                # use only Last-Modified",
            "                return check_lastmodified(lm)",
            "            else:",
            "                # assume stale cache",
            "                return False",
            "",
            "    if unless is None:",
            "",
            "        def unless():",
            "            return False",
            "",
            "    def decorator(f):",
            "        @functools.wraps(f)",
            "        def decorated_function(*args, **kwargs):",
            "            from octoprint.server import NOT_MODIFIED",
            "",
            "            lm = lastmodified_factory()",
            "            etag = etag_factory(lm)",
            "",
            "            if condition(lm, etag) and not unless():",
            "                return NOT_MODIFIED",
            "",
            "            # generate response",
            "            response = f(*args, **kwargs)",
            "",
            "            # set etag header if not already set",
            "            if etag and response.get_etag()[0] is None:",
            "                response.set_etag(etag)",
            "",
            "            # set last modified header if not already set",
            "            if lm and response.headers.get(\"Last-Modified\", None) is None:",
            "                if not isinstance(lm, str):",
            "                    from werkzeug.http import http_date",
            "",
            "                    lm = http_date(lm)",
            "                response.headers[\"Last-Modified\"] = lm",
            "",
            "            response = add_no_max_age_response_headers(response)",
            "            return response",
            "",
            "        return decorated_function",
            "",
            "    return decorator",
            "",
            "",
            "def check_etag(etag):",
            "    if etag is None:",
            "        return False",
            "",
            "    return (",
            "        flask.request.method in (\"GET\", \"HEAD\")",
            "        and flask.request.if_none_match is not None",
            "        and etag in flask.request.if_none_match",
            "    )",
            "",
            "",
            "def check_lastmodified(lastmodified: Union[int, float, datetime]) -> bool:",
            "    \"\"\"Compares the provided lastmodified value with the value of the If-Modified-Since header.",
            "",
            "    If ``lastmodified`` is an int or float, it's assumed to be a Unix timestamp and converted",
            "    to a timezone aware datetime instance in UTC.",
            "",
            "    If ``lastmodified`` is a datetime instance, it needs to be timezone aware or the",
            "    result will always be ``False``.",
            "",
            "    Args:",
            "        lastmodified (Union[int, float, datetime]): The last modified value to compare against",
            "",
            "    Raises:",
            "        ValueError: If anything but an int, float or datetime instance is passed",
            "",
            "    Returns:",
            "        bool: true if the values indicate that the document is still up to date",
            "    \"\"\"",
            "",
            "    if lastmodified is None:",
            "        return False",
            "",
            "    if isinstance(lastmodified, (int, float)):",
            "        # max(86400, lastmodified) is workaround for https://bugs.python.org/issue29097,",
            "        # present in CPython 3.6.x up to 3.7.1.",
            "        #",
            "        # I think it's fair to say that we'll never encounter lastmodified values older than",
            "        # 1970-01-02 so this is a safe workaround.",
            "        #",
            "        # Timestamps are defined as seconds since epoch aka 1970/01/01 00:00:00Z, so we",
            "        # use UTC as timezone here.",
            "        lastmodified = datetime.fromtimestamp(",
            "            max(86400, lastmodified), tz=UTC_TZ",
            "        ).replace(microsecond=0)",
            "",
            "    if not isinstance(lastmodified, datetime):",
            "        raise ValueError(",
            "            \"lastmodified must be a datetime or float or int instance but, got {} instead\".format(",
            "                lastmodified.__class__",
            "            )",
            "        )",
            "",
            "    if not is_timezone_aware(lastmodified):",
            "        # datetime object is not timezone aware, we can't check lastmodified with that",
            "        logger = logging.getLogger(__name__)",
            "        logger.warning(",
            "            \"lastmodified is not timezone aware, cannot check against If-Modified-Since. In the future this will become an error!\",",
            "            stack_info=logger.isEnabledFor(logging.DEBUG),",
            "        )",
            "        return False",
            "",
            "    return (",
            "        flask.request.method in (\"GET\", \"HEAD\")",
            "        and flask.request.if_modified_since is not None",
            "        and lastmodified <= flask.request.if_modified_since",
            "    )",
            "",
            "",
            "def add_revalidation_response_headers(response):",
            "    import werkzeug.http",
            "",
            "    cache_control = werkzeug.http.parse_dict_header(",
            "        response.headers.get(\"Cache-Control\", \"\")",
            "    )",
            "    if \"no-cache\" not in cache_control:",
            "        cache_control[\"no-cache\"] = None",
            "    if \"must-revalidate\" not in cache_control:",
            "        cache_control[\"must-revalidate\"] = None",
            "    response.headers[\"Cache-Control\"] = werkzeug.http.dump_header(cache_control)",
            "",
            "    return response",
            "",
            "",
            "def add_non_caching_response_headers(response):",
            "    import werkzeug.http",
            "",
            "    cache_control = werkzeug.http.parse_dict_header(",
            "        response.headers.get(\"Cache-Control\", \"\")",
            "    )",
            "    if \"no-store\" not in cache_control:",
            "        cache_control[\"no-store\"] = None",
            "    if \"no-cache\" not in cache_control:",
            "        cache_control[\"no-cache\"] = None",
            "    if \"must-revalidate\" not in cache_control:",
            "        cache_control[\"must-revalidate\"] = None",
            "    if \"post-check\" not in cache_control or cache_control[\"post-check\"] != \"0\":",
            "        cache_control[\"post-check\"] = \"0\"",
            "    if \"pre-check\" not in cache_control or cache_control[\"pre-check\"] != \"0\":",
            "        cache_control[\"pre-check\"] = \"0\"",
            "    if \"max-age\" not in cache_control or cache_control[\"max-age\"] != \"0\":",
            "        cache_control[\"max-age\"] = \"0\"",
            "    response.headers[\"Cache-Control\"] = werkzeug.http.dump_header(cache_control)",
            "",
            "    response.headers[\"Pragma\"] = \"no-cache\"",
            "    response.headers[\"Expires\"] = \"-1\"",
            "    return response",
            "",
            "",
            "def add_no_max_age_response_headers(response):",
            "    import werkzeug.http",
            "",
            "    cache_control = werkzeug.http.parse_dict_header(",
            "        response.headers.get(\"Cache-Control\", \"\")",
            "    )",
            "    if \"max-age\" not in cache_control or cache_control[\"max-age\"] != \"0\":",
            "        cache_control[\"max-age\"] = \"0\"",
            "    response.headers[\"Cache-Control\"] = werkzeug.http.dump_header(cache_control)",
            "",
            "    return response",
            "",
            "",
            "# ~~ access validators for use with tornado",
            "",
            "",
            "def permission_validator(request, permission):",
            "    \"\"\"",
            "    Validates that the given request is made by an authorized user, identified either by API key or existing Flask",
            "    session.",
            "",
            "    Must be executed in an existing Flask request context!",
            "",
            "    :param request: The Flask request object",
            "    :param request: The required permission",
            "    \"\"\"",
            "",
            "    user = get_flask_user_from_request(request)",
            "    if not user.has_permission(permission):",
            "        raise tornado.web.HTTPError(403)",
            "",
            "",
            "def permission_and_fresh_credentials_validator(request, permission):",
            "    \"\"\"",
            "    Validates that the given request is made by an authorized user, identified either by API key or existing Flask",
            "    session, and that the credentials have been checked recently if it's a Flask session.",
            "",
            "    Must be executed in an existing Flask request context!",
            "",
            "    :param request: The Flask request object",
            "    :param request: The required permission",
            "    \"\"\"",
            "",
            "    permission_validator(request, permission)",
            "    ensure_credentials_checked_recently()",
            "",
            "",
            "@deprecated(",
            "    \"admin_validator is deprecated, please use new permission_validator\", since=\"\"",
            ")",
            "def admin_validator(request):",
            "    from octoprint.access.permissions import Permissions",
            "",
            "    return permission_validator(request, Permissions.ADMIN)",
            "",
            "",
            "@deprecated(\"user_validator is deprecated, please use new permission_validator\", since=\"\")",
            "def user_validator(request):",
            "    return True",
            "",
            "",
            "def get_flask_user_from_request(request):",
            "    \"\"\"",
            "    Retrieves the current flask user from the request context. Uses API key if available, otherwise the current",
            "    user session if available.",
            "",
            "    :param request: flask request from which to retrieve the current user",
            "    :return: the user (might be an anonymous user)",
            "    \"\"\"",
            "    import flask_login",
            "",
            "    import octoprint.server.util",
            "",
            "    user = None",
            "",
            "    apikey = octoprint.server.util.get_api_key(request)",
            "    if apikey is not None:",
            "        # user from api key?",
            "        user = octoprint.server.util.get_user_for_apikey(apikey)",
            "",
            "    if user is None:",
            "        # user still None -> current session user",
            "        user = flask_login.current_user",
            "",
            "    if user is None:",
            "        # user still None -> anonymous",
            "        from octoprint.server import userManager",
            "",
            "        user = userManager.anonymous_user_factory()",
            "",
            "    return user",
            "",
            "",
            "def redirect_to_tornado(request, target, code=302):",
            "    \"\"\"",
            "    Redirects from flask to tornado, flask request context must exist.",
            "",
            "    :param request:",
            "    :param target:",
            "    :param code:",
            "    :return:",
            "    \"\"\"",
            "",
            "    import flask",
            "",
            "    requestUrl = request.url",
            "    appBaseUrl = requestUrl[: requestUrl.find(flask.url_for(\"index\") + \"api\")]",
            "",
            "    redirectUrl = appBaseUrl + target",
            "    if \"?\" in requestUrl:",
            "        fragment = requestUrl[requestUrl.rfind(\"?\") :]",
            "        redirectUrl += fragment",
            "    return flask.redirect(redirectUrl, code=code)",
            "",
            "",
            "def restricted_access(func):",
            "    \"\"\"",
            "    This combines :py:func:`no_firstrun_access` and ``login_required``.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        return no_firstrun_access(flask_login.login_required(func))(*args, **kwargs)",
            "",
            "    return decorated_view",
            "",
            "",
            "def no_firstrun_access(func):",
            "    \"\"\"",
            "    If you decorate a view with this, it will ensure that first setup has been",
            "    done for OctoPrint's Access Control.",
            "",
            "    If OctoPrint's Access Control has not been setup yet (indicated by the userManager",
            "    not reporting that its user database has been customized from default), the decorator",
            "    will cause a HTTP 403 status code to be returned by the decorated resource.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        # if OctoPrint hasn't been set up yet, abort",
            "        if settings().getBoolean([\"server\", \"firstRun\"]) and (",
            "            octoprint.server.userManager is None",
            "            or not octoprint.server.userManager.has_been_customized()",
            "        ):",
            "            flask.abort(403)",
            "        return func(*args, **kwargs)",
            "",
            "    return decorated_view",
            "",
            "",
            "def firstrun_only_access(func):",
            "    \"\"\"",
            "    If you decorate a view with this, it will ensure that first setup has _not_ been",
            "    done for OctoPrint's Access Control. Otherwise it",
            "    will cause a HTTP 403 status code to be returned by the decorated resource.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        # if OctoPrint has been set up yet, abort",
            "        if settings().getBoolean([\"server\", \"firstRun\"]) and (",
            "            octoprint.server.userManager is None",
            "            or not octoprint.server.userManager.has_been_customized()",
            "        ):",
            "            return func(*args, **kwargs)",
            "        else:",
            "            flask.abort(403)",
            "",
            "    return decorated_view",
            "",
            "",
            "def credentials_checked_recently():",
            "    minutes = settings().getInt([\"accessControl\", \"defaultReauthenticationTimeout\"])",
            "    if not minutes:",
            "        return True",
            "",
            "    login_mechanism = flask.session.get(\"login_mechanism\")",
            "    if not octoprint.server.util.LoginMechanism.reauthentication_enabled(login_mechanism):",
            "        return True",
            "",
            "    credentials_seen = flask.session.get(\"credentials_seen\")",
            "    now = datetime.now()",
            "",
            "    try:",
            "        if credentials_seen and datetime.fromtimestamp(",
            "            credentials_seen",
            "        ) > now - timedelta(minutes=minutes):",
            "            # credentials seen less than the set minutes ago, proceed",
            "            return True",
            "    except Exception:",
            "        logging.getLogger(__name__).exception(\"Error while checking for seen credentials\")",
            "        pass",
            "",
            "    return False",
            "",
            "",
            "def ensure_credentials_checked_recently():",
            "    if not credentials_checked_recently():",
            "        flask.abort(403, description=\"Please reauthenticate with your credentials\")",
            "",
            "",
            "def require_credentials_checked_recently(func):",
            "    \"\"\"",
            "    If you decorate a view with this, it will ensure that only users who entered their password",
            "    recently in this login session are allowed to proceed. Otherwise it will cause a HTTP 403 status code",
            "    to be returned by the decorated resource.",
            "    \"\"\"",
            "",
            "    @functools.wraps(func)",
            "    def decorated_view(*args, **kwargs):",
            "        ensure_credentials_checked_recently()",
            "        return func(*args, **kwargs)",
            "",
            "    return decorated_view",
            "",
            "",
            "@deprecated(",
            "    \"get_remote_address is no longer required and deprecated, you can just use flask.request.remote_addr instead\",",
            "    since=\"1.10.0\",",
            ")",
            "def get_remote_address(request):",
            "    return request.remote_addr",
            "",
            "",
            "def get_json_command_from_request(request, valid_commands):",
            "    data = request.get_json()",
            "",
            "    if \"command\" not in data or data[\"command\"] not in valid_commands:",
            "        flask.abort(400, description=\"command is invalid\")",
            "",
            "    command = data[\"command\"]",
            "    if any(map(lambda x: x not in data, valid_commands[command])):",
            "        flask.abort(400, description=\"Mandatory parameters missing\")",
            "",
            "    return command, data, None",
            "",
            "",
            "def make_text_response(message, status):",
            "    \"\"\"",
            "    Helper to generate basic text responses.",
            "",
            "    Response will have the provided message as body, the provided status code, and",
            "    a content type of \"text/plain\".",
            "",
            "    Args:",
            "        message: The message in the response body",
            "        status: The HTTP status code",
            "",
            "    Returns:",
            "",
            "    \"\"\"",
            "    return make_response(message, status, {\"Content-Type\": \"text/plain\"})",
            "",
            "",
            "def make_api_error(message, status):",
            "    \"\"\"",
            "    Helper to generate API error responses in JSON format.",
            "",
            "    Turns something like ``make_api_error(\"Not Found\", 404)`` into a JSON response",
            "    with body ``{\"error\": \"Not Found\"}``.",
            "",
            "    Args:",
            "        message: The error message to put into the response",
            "        status: The HTTP status code",
            "",
            "    Returns: a flask response to return to the client",
            "    \"\"\"",
            "    return make_response(flask.jsonify(error=message), status)",
            "",
            "",
            "##~~ Flask-Assets resolver with plugin asset support",
            "",
            "",
            "class PluginAssetResolver(flask_assets.FlaskResolver):",
            "    def split_prefix(self, ctx, item):",
            "        app = ctx.environment._app",
            "        if item.startswith(\"plugin/\"):",
            "            try:",
            "                prefix, plugin, name = item.split(\"/\", 2)",
            "                blueprint = prefix + \".\" + plugin",
            "",
            "                directory = flask_assets.get_static_folder(app.blueprints[blueprint])",
            "                item = name",
            "                endpoint = blueprint + \".static\"",
            "                return directory, item, endpoint",
            "            except (ValueError, KeyError):",
            "                pass",
            "",
            "        return flask_assets.FlaskResolver.split_prefix(self, ctx, item)",
            "",
            "    def resolve_output_to_path(self, ctx, target, bundle):",
            "        import os",
            "",
            "        return os.path.normpath(os.path.join(ctx.environment.directory, target))",
            "",
            "",
            "##~~ Webassets updater that takes changes in the configuration into account",
            "",
            "",
            "class SettingsCheckUpdater(webassets.updater.BaseUpdater):",
            "    updater = \"always\"",
            "",
            "    def __init__(self):",
            "        self._delegate = webassets.updater.get_updater(self.__class__.updater)",
            "",
            "    def needs_rebuild(self, bundle, ctx):",
            "        return self._delegate.needs_rebuild(bundle, ctx) or self.changed_settings(ctx)",
            "",
            "    def changed_settings(self, ctx):",
            "        if not ctx.cache:",
            "            return False",
            "",
            "        cache_key = (\"octo\", \"settings\")",
            "        current_hash = settings().effective_hash",
            "        cached_hash = ctx.cache.get(cache_key)",
            "        # This may seem counter-intuitive, but if no cache entry is found",
            "        # then we actually return \"no update needed\". This is because",
            "        # otherwise if no cache / a dummy cache is used, then we would be",
            "        # rebuilding every single time.",
            "        if cached_hash is not None:",
            "            return cached_hash != current_hash",
            "        return False",
            "",
            "    def build_done(self, bundle, ctx):",
            "        self._delegate.build_done(bundle, ctx)",
            "        if not ctx.cache:",
            "            return",
            "",
            "        cache_key = (\"octo\", \"settings\")",
            "        ctx.cache.set(cache_key, settings().effective_hash)",
            "",
            "",
            "##~~ core assets collector",
            "def collect_core_assets(preferred_stylesheet=\"css\"):",
            "    assets = {\"js\": [], \"clientjs\": [], \"css\": [], \"less\": []}",
            "    assets[\"js\"] = [",
            "        \"js/app/bindings/allowbindings.js\",",
            "        \"js/app/bindings/contextmenu.js\",",
            "        \"js/app/bindings/gettext.js\",",
            "        \"js/app/bindings/invisible.js\",",
            "        \"js/app/bindings/popover.js\",",
            "        \"js/app/bindings/qrcode.js\",",
            "        \"js/app/bindings/slimscrolledforeach.js\",",
            "        \"js/app/bindings/toggle.js\",",
            "        \"js/app/bindings/togglecontent.js\",",
            "        \"js/app/bindings/valuewithinit.js\",",
            "        \"js/app/viewmodels/access.js\",",
            "        \"js/app/viewmodels/appearance.js\",",
            "        \"js/app/viewmodels/connection.js\",",
            "        \"js/app/viewmodels/control.js\",",
            "        \"js/app/viewmodels/files.js\",",
            "        \"js/app/viewmodels/firstrun_wizard.js\",",
            "        \"js/app/viewmodels/loginstate.js\",",
            "        \"js/app/viewmodels/loginui.js\",",
            "        \"js/app/viewmodels/navigation.js\",",
            "        \"js/app/viewmodels/printerstate.js\",",
            "        \"js/app/viewmodels/printerprofiles.js\",",
            "        \"js/app/viewmodels/settings.js\",",
            "        \"js/app/viewmodels/slicing.js\",",
            "        \"js/app/viewmodels/system.js\",",
            "        \"js/app/viewmodels/temperature.js\",",
            "        \"js/app/viewmodels/terminal.js\",",
            "        \"js/app/viewmodels/timelapse.js\",",
            "        \"js/app/viewmodels/uistate.js\",",
            "        \"js/app/viewmodels/users.js\",",
            "        \"js/app/viewmodels/usersettings.js\",",
            "        \"js/app/viewmodels/wizard.js\",",
            "        \"js/app/viewmodels/about.js\",",
            "    ]",
            "",
            "    assets[\"clientjs\"] = [",
            "        \"js/app/client/base.js\",",
            "        \"js/app/client/socket.js\",",
            "        \"js/app/client/access.js\",",
            "        \"js/app/client/browser.js\",",
            "        \"js/app/client/connection.js\",",
            "        \"js/app/client/control.js\",",
            "        \"js/app/client/files.js\",",
            "        \"js/app/client/job.js\",",
            "        \"js/app/client/languages.js\",",
            "        \"js/app/client/printer.js\",",
            "        \"js/app/client/printerprofiles.js\",",
            "        \"js/app/client/settings.js\",",
            "        \"js/app/client/slicing.js\",",
            "        \"js/app/client/system.js\",",
            "        \"js/app/client/timelapse.js\",",
            "        \"js/app/client/users.js\",",
            "        \"js/app/client/util.js\",",
            "        \"js/app/client/wizard.js\",",
            "    ]",
            "",
            "    if preferred_stylesheet == \"less\":",
            "        assets[\"less\"].append(\"less/octoprint.less\")",
            "    elif preferred_stylesheet == \"css\":",
            "        assets[\"css\"].append(\"css/octoprint.css\")",
            "",
            "    return assets",
            "",
            "",
            "##~~ plugin assets collector",
            "",
            "",
            "def collect_plugin_assets(preferred_stylesheet=\"css\"):",
            "    logger = logging.getLogger(__name__ + \".collect_plugin_assets\")",
            "",
            "    supported_stylesheets = (\"css\", \"less\")",
            "    assets = {",
            "        \"bundled\": {",
            "            \"js\": DefaultOrderedDict(list),",
            "            \"clientjs\": DefaultOrderedDict(list),",
            "            \"css\": DefaultOrderedDict(list),",
            "            \"less\": DefaultOrderedDict(list),",
            "        },",
            "        \"external\": {",
            "            \"js\": DefaultOrderedDict(list),",
            "            \"clientjs\": DefaultOrderedDict(list),",
            "            \"css\": DefaultOrderedDict(list),",
            "            \"less\": DefaultOrderedDict(list),",
            "        },",
            "    }",
            "",
            "    asset_plugins = octoprint.plugin.plugin_manager().get_implementations(",
            "        octoprint.plugin.AssetPlugin",
            "    )",
            "    for implementation in asset_plugins:",
            "        name = implementation._identifier",
            "        is_bundled = implementation._plugin_info.bundled",
            "",
            "        asset_key = \"bundled\" if is_bundled else \"external\"",
            "",
            "        try:",
            "            all_assets = implementation.get_assets()",
            "            basefolder = implementation.get_asset_folder()",
            "        except Exception:",
            "            logger.exception(",
            "                \"Got an error while trying to collect assets from {}, ignoring assets from the plugin\".format(",
            "                    name",
            "                ),",
            "                extra={\"plugin\": name},",
            "            )",
            "            continue",
            "",
            "        def asset_exists(category, asset):",
            "            exists = os.path.exists(os.path.join(basefolder, asset))",
            "            if not exists:",
            "                logger.warning(",
            "                    \"Plugin {} is referring to non existing {} asset {}\".format(",
            "                        name, category, asset",
            "                    )",
            "                )",
            "            return exists",
            "",
            "        if \"js\" in all_assets:",
            "            for asset in all_assets[\"js\"]:",
            "                if not asset_exists(\"js\", asset):",
            "                    continue",
            "                assets[asset_key][\"js\"][name].append(f\"plugin/{name}/{asset}\")",
            "",
            "        if \"clientjs\" in all_assets:",
            "            for asset in all_assets[\"clientjs\"]:",
            "                if not asset_exists(\"clientjs\", asset):",
            "                    continue",
            "                assets[asset_key][\"clientjs\"][name].append(f\"plugin/{name}/{asset}\")",
            "",
            "        if preferred_stylesheet in all_assets:",
            "            for asset in all_assets[preferred_stylesheet]:",
            "                if not asset_exists(preferred_stylesheet, asset):",
            "                    continue",
            "                assets[asset_key][preferred_stylesheet][name].append(",
            "                    f\"plugin/{name}/{asset}\"",
            "                )",
            "        else:",
            "            for stylesheet in supported_stylesheets:",
            "                if stylesheet not in all_assets:",
            "                    continue",
            "",
            "                for asset in all_assets[stylesheet]:",
            "                    if not asset_exists(stylesheet, asset):",
            "                        continue",
            "                    assets[asset_key][stylesheet][name].append(f\"plugin/{name}/{asset}\")",
            "                break",
            "",
            "    return assets",
            "",
            "",
            "##~~ JSON encoding",
            "",
            "",
            "class OctoPrintJsonProvider(flask.json.provider.DefaultJSONProvider):",
            "    @staticmethod",
            "    def default(object_):",
            "        try:",
            "            return JsonEncoding.encode(object_)",
            "        except TypeError:",
            "            return flask.json.provider.DefaultJSONProvider.default(object_)",
            "",
            "    def dumps(self, obj: Any, **kwargs: Any) -> str:",
            "        kwargs.setdefault(\"allow_nan\", False)",
            "        return super().dumps(obj, **kwargs)",
            "",
            "",
            "##~~ Session signing",
            "",
            "",
            "def session_signature(user, session):",
            "    from octoprint.server import userManager",
            "",
            "    key = userManager.signature_key_for_user(user, current_app.config[\"SECRET_KEY\"])",
            "    return hmac.new(",
            "        key.encode(\"utf-8\"), session.encode(\"utf-8\"), hashlib.sha512",
            "    ).hexdigest()",
            "",
            "",
            "def validate_session_signature(sig, user, session):",
            "    user_sig = session_signature(user, session)",
            "    return len(user_sig) == len(sig) and hmac.compare_digest(sig, user_sig)",
            "",
            "",
            "##~~ Reverse proxy info",
            "",
            "",
            "class ReverseProxyInfo(BaseModel):",
            "    client_ip: str",
            "    server_protocol: str",
            "    server_name: str",
            "    server_port: int",
            "    server_path: str",
            "    cookie_suffix: str",
            "    trusted_proxies: List[str] = []",
            "    headers: Dict[str, str] = {}",
            "",
            "",
            "def get_reverse_proxy_info():",
            "    headers = {}",
            "    for header in sorted(",
            "        (",
            "            \"X-Forwarded-For\",",
            "            \"X-Forwarded-Protocol\",",
            "            \"X-Scheme\",",
            "            \"X-Forwarded-Host\",",
            "            \"X-Forwarded-Port\",",
            "            \"X-Forwarded-Server\",",
            "            \"Host\",",
            "            \"X-Script-Name\",",
            "        )",
            "    ):",
            "        if header in flask.request.headers:",
            "            headers[header] = flask.request.headers[header]",
            "",
            "    trusted_downstreams = settings().get([\"server\", \"reverseProxy\", \"trustedDownstream\"])",
            "    if not trusted_downstreams:",
            "        trusted_downstreams = []",
            "",
            "    return ReverseProxyInfo(",
            "        client_ip=flask.request.remote_addr,",
            "        server_protocol=flask.request.environ.get(\"wsgi.url_scheme\"),",
            "        server_name=flask.request.environ.get(\"SERVER_NAME\"),",
            "        server_port=int(flask.request.environ.get(\"SERVER_PORT\")),",
            "        server_path=flask.request.script_root if flask.request.script_root else \"/\",",
            "        cookie_suffix=get_cookie_suffix(flask.request),",
            "        trusted_proxies=trusted_downstreams,",
            "        headers=headers,",
            "    )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "15": [],
            "669": [
                "passive_login"
            ],
            "1717": [
                "get_remote_address"
            ],
            "1718": [
                "get_remote_address"
            ],
            "1719": [
                "get_remote_address"
            ]
        },
        "addLocation": []
    },
    "src/octoprint/server/util/sockjs.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 85,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 86,
                "PatchRowcode": "     _event_payload_processors = {"
            },
            "2": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "         Events.CLIENT_OPENED: ["
            },
            "3": {
                "beforePatchRowNumber": 88,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            lambda user, payload: payload"
            },
            "4": {
                "beforePatchRowNumber": 89,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if user.has_permission(Permissions.ADMIN)"
            },
            "5": {
                "beforePatchRowNumber": 90,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            else {}"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 88,
                "PatchRowcode": "+            lambda user, payload: ("
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 89,
                "PatchRowcode": "+                payload if user.has_permission(Permissions.ADMIN) else {}"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+            )"
            },
            "9": {
                "beforePatchRowNumber": 91,
                "afterPatchRowNumber": 91,
                "PatchRowcode": "         ],"
            },
            "10": {
                "beforePatchRowNumber": 92,
                "afterPatchRowNumber": 92,
                "PatchRowcode": "         Events.CLIENT_AUTHED: ["
            },
            "11": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            lambda user, payload: payload"
            },
            "12": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if user.has_permission(Permissions.ADMIN)"
            },
            "13": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            else {}"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+            lambda user, payload: ("
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+                payload if user.has_permission(Permissions.ADMIN) else {}"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 95,
                "PatchRowcode": "+            )"
            },
            "17": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 96,
                "PatchRowcode": "         ],"
            },
            "18": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 97,
                "PatchRowcode": "         \"*\": [],"
            },
            "19": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 98,
                "PatchRowcode": "     }"
            },
            "20": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 101,
                "PatchRowcode": "     _emit_permissions = {"
            },
            "21": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 102,
                "PatchRowcode": "         \"connected\": [],"
            },
            "22": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": 103,
                "PatchRowcode": "         \"reauthRequired\": [],"
            },
            "23": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        \"plugin\": lambda payload: []"
            },
            "24": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if payload.get(\"plugin\") in (\"backup\", \"softwareupdate\")"
            },
            "25": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        and settings().getBoolean([\"server\", \"firstRun\"])"
            },
            "26": {
                "beforePatchRowNumber": 107,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        else [Permissions.STATUS],"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+        \"plugin\": lambda payload: ("
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+            []"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+            if payload.get(\"plugin\") in (\"backup\", \"softwareupdate\")"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+            and settings().getBoolean([\"server\", \"firstRun\"])"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+            else [Permissions.STATUS]"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+        ),"
            },
            "33": {
                "beforePatchRowNumber": 108,
                "afterPatchRowNumber": 110,
                "PatchRowcode": "         \"*\": [Permissions.STATUS],"
            },
            "34": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 111,
                "PatchRowcode": "     }"
            },
            "35": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 112,
                "PatchRowcode": " "
            },
            "36": {
                "beforePatchRowNumber": 179,
                "afterPatchRowNumber": 181,
                "PatchRowcode": " "
            },
            "37": {
                "beforePatchRowNumber": 180,
                "afterPatchRowNumber": 182,
                "PatchRowcode": "     @staticmethod"
            },
            "38": {
                "beforePatchRowNumber": 181,
                "afterPatchRowNumber": 183,
                "PatchRowcode": "     def _get_remote_address(info):"
            },
            "39": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        forwarded_for = info.headers.get(\"X-Forwarded-For\")"
            },
            "40": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if forwarded_for is not None:"
            },
            "41": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return forwarded_for.split(\",\")[0]"
            },
            "42": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return info.ip"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 184,
                "PatchRowcode": "+        from octoprint.util.net import get_http_client_ip"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 185,
                "PatchRowcode": "+"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 186,
                "PatchRowcode": "+        trusted_proxies = settings().get([\"server\", \"reverseProxy\", \"trustedUpstream\"])"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 187,
                "PatchRowcode": "+        if not isinstance(trusted_proxies, list):"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 188,
                "PatchRowcode": "+            trusted_proxies = [\"127.0.0.1\"]"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 189,
                "PatchRowcode": "+"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 190,
                "PatchRowcode": "+        return get_http_client_ip("
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 191,
                "PatchRowcode": "+            info.ip, info.headers.get(\"X-Forwarded-For\"), trusted_proxies"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 192,
                "PatchRowcode": "+        )"
            },
            "52": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 193,
                "PatchRowcode": " "
            },
            "53": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 194,
                "PatchRowcode": "     def _keep_alive_callback(self):"
            },
            "54": {
                "beforePatchRowNumber": 188,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "         if not self._authed:"
            }
        },
        "frontPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import logging",
            "import re",
            "import threading",
            "import time",
            "",
            "import wrapt",
            "",
            "import octoprint.access.users",
            "import octoprint.events",
            "import octoprint.plugin",
            "import octoprint.printer",
            "import octoprint.server",
            "import octoprint.timelapse",
            "import octoprint.vendor.sockjs.tornado",
            "import octoprint.vendor.sockjs.tornado.proto",
            "import octoprint.vendor.sockjs.tornado.session",
            "import octoprint.vendor.sockjs.tornado.util",
            "from octoprint.access.groups import GroupChangeListener",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.access.users import LoginStatusListener, SessionUser",
            "from octoprint.events import Events",
            "from octoprint.settings import settings",
            "from octoprint.util import RepeatedTimer",
            "from octoprint.util.json import dumps as json_dumps",
            "from octoprint.util.version import get_python_version_string",
            "",
            "",
            "class ThreadSafeSession(octoprint.vendor.sockjs.tornado.session.Session):",
            "    def __init__(self, conn, server, session_id, expiry=None):",
            "        octoprint.vendor.sockjs.tornado.session.Session.__init__(",
            "            self, conn, server, session_id, expiry=expiry",
            "        )",
            "",
            "    def set_handler(self, handler, start_heartbeat=True):",
            "        if getattr(handler, \"__orig_send_pack\", None) is None:",
            "            orig_send_pack = handler.send_pack",
            "            mutex = threading.RLock()",
            "",
            "            def send_pack(*args, **kwargs):",
            "                with mutex:",
            "                    return orig_send_pack(*args, **kwargs)",
            "",
            "            handler.send_pack = send_pack",
            "            handler.__orig_send_pack = orig_send_pack",
            "",
            "        return octoprint.vendor.sockjs.tornado.session.Session.set_handler(",
            "            self, handler, start_heartbeat=start_heartbeat",
            "        )",
            "",
            "    def remove_handler(self, handler):",
            "        result = octoprint.vendor.sockjs.tornado.session.Session.remove_handler(",
            "            self, handler",
            "        )",
            "",
            "        if getattr(handler, \"__orig_send_pack\", None) is not None:",
            "            handler.send_pack = handler.__orig_send_pack",
            "            delattr(handler, \"__orig_send_pack\")",
            "",
            "        return result",
            "",
            "",
            "class JsonEncodingSessionWrapper(wrapt.ObjectProxy):",
            "    def send_message(self, msg, stats=True, binary=False):",
            "        self.send_jsonified(",
            "            json_dumps(octoprint.vendor.sockjs.tornado.util.bytes_to_str(msg)),",
            "            stats,",
            "        )",
            "",
            "",
            "class PrinterStateConnection(",
            "    octoprint.vendor.sockjs.tornado.SockJSConnection,",
            "    octoprint.printer.PrinterCallback,",
            "    LoginStatusListener,",
            "    GroupChangeListener,",
            "):",
            "    _event_permissions = {",
            "        Events.USER_LOGGED_IN: [Permissions.ADMIN],",
            "        Events.USER_LOGGED_OUT: [Permissions.ADMIN],",
            "        \"*\": [],",
            "    }",
            "",
            "    _event_payload_processors = {",
            "        Events.CLIENT_OPENED: [",
            "            lambda user, payload: payload",
            "            if user.has_permission(Permissions.ADMIN)",
            "            else {}",
            "        ],",
            "        Events.CLIENT_AUTHED: [",
            "            lambda user, payload: payload",
            "            if user.has_permission(Permissions.ADMIN)",
            "            else {}",
            "        ],",
            "        \"*\": [],",
            "    }",
            "",
            "    # TODO: Permissions should be overridable from plugins, this special case stuff here is a hack",
            "    _emit_permissions = {",
            "        \"connected\": [],",
            "        \"reauthRequired\": [],",
            "        \"plugin\": lambda payload: []",
            "        if payload.get(\"plugin\") in (\"backup\", \"softwareupdate\")",
            "        and settings().getBoolean([\"server\", \"firstRun\"])",
            "        else [Permissions.STATUS],",
            "        \"*\": [Permissions.STATUS],",
            "    }",
            "",
            "    _unauthed_backlog_max = 100",
            "",
            "    def __init__(",
            "        self,",
            "        printer,",
            "        fileManager,",
            "        analysisQueue,",
            "        userManager,",
            "        groupManager,",
            "        eventManager,",
            "        pluginManager,",
            "        connectivityChecker,",
            "        session,",
            "    ):",
            "        if isinstance(session, octoprint.vendor.sockjs.tornado.session.Session):",
            "            session = JsonEncodingSessionWrapper(session)",
            "",
            "        octoprint.vendor.sockjs.tornado.SockJSConnection.__init__(self, session)",
            "",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "        self._temperatureBacklog = []",
            "        self._temperatureBacklogMutex = threading.Lock()",
            "        self._logBacklog = []",
            "        self._logBacklogMutex = threading.Lock()",
            "        self._messageBacklog = []",
            "        self._messageBacklogMutex = threading.Lock()",
            "",
            "        self._unauthed_backlog = []",
            "        self._unauthed_backlog_mutex = threading.RLock()",
            "",
            "        self._printer = printer",
            "        self._fileManager = fileManager",
            "        self._analysisQueue = analysisQueue",
            "        self._userManager = userManager",
            "        self._groupManager = groupManager",
            "        self._eventManager = eventManager",
            "        self._pluginManager = pluginManager",
            "        self._connectivityChecker = connectivityChecker",
            "",
            "        self._remoteAddress = None",
            "        self._user = self._userManager.anonymous_user_factory()",
            "",
            "        self._throttle_factor = 1",
            "        self._last_current = 0",
            "        self._base_rate_limit = 0.5",
            "",
            "        self._held_back_current = None",
            "        self._held_back_mutex = threading.RLock()",
            "",
            "        self._register_hooks = self._pluginManager.get_hooks(",
            "            \"octoprint.server.sockjs.register\"",
            "        )",
            "        self._authed_hooks = self._pluginManager.get_hooks(",
            "            \"octoprint.server.sockjs.authed\"",
            "        )",
            "        self._emit_hooks = self._pluginManager.get_hooks(\"octoprint.server.sockjs.emit\")",
            "",
            "        self._registered = False",
            "        self._authed = False",
            "        self._initial_data_sent = False",
            "",
            "        self._subscriptions_active = False",
            "        self._subscriptions = {\"state\": False, \"plugins\": [], \"events\": []}",
            "",
            "        self._keep_alive = RepeatedTimer(",
            "            60, self._keep_alive_callback, condition=lambda: self._authed",
            "        )",
            "",
            "    @staticmethod",
            "    def _get_remote_address(info):",
            "        forwarded_for = info.headers.get(\"X-Forwarded-For\")",
            "        if forwarded_for is not None:",
            "            return forwarded_for.split(\",\")[0]",
            "        return info.ip",
            "",
            "    def _keep_alive_callback(self):",
            "        if not self._authed:",
            "            return",
            "        if not isinstance(self._user, SessionUser):",
            "            return",
            "        self._user.touch()",
            "",
            "    def __str__(self):",
            "        if self._remoteAddress:",
            "            return f\"{self!r} connected to {self._remoteAddress}\"",
            "        else:",
            "            return f\"Unconnected {self!r}\"",
            "",
            "    def on_open(self, info):",
            "        self._pluginManager.register_message_receiver(self.on_plugin_message)",
            "        self._remoteAddress = self._get_remote_address(info)",
            "        self._logger.info(\"New connection from client: %s\" % self._remoteAddress)",
            "",
            "        self._userManager.register_login_status_listener(self)",
            "        self._groupManager.register_listener(self)",
            "",
            "        plugin_signature = lambda impl: \"{}:{}\".format(",
            "            impl._identifier, impl._plugin_version",
            "        )",
            "        template_plugins = list(",
            "            map(",
            "                plugin_signature,",
            "                self._pluginManager.get_implementations(octoprint.plugin.TemplatePlugin),",
            "            )",
            "        )",
            "        asset_plugins = list(",
            "            map(",
            "                plugin_signature,",
            "                self._pluginManager.get_implementations(octoprint.plugin.AssetPlugin),",
            "            )",
            "        )",
            "        ui_plugins = sorted(set(template_plugins + asset_plugins))",
            "",
            "        import hashlib",
            "",
            "        plugin_hash = hashlib.md5()",
            "        plugin_hash.update(\",\".join(ui_plugins).encode(\"utf-8\"))",
            "",
            "        config_hash = settings().config_hash",
            "",
            "        # connected => update the API key, might be necessary if the client was left open while the server restarted",
            "        self._emit(",
            "            \"connected\",",
            "            {",
            "                \"version\": octoprint.server.VERSION,",
            "                \"display_version\": octoprint.server.DISPLAY_VERSION,",
            "                \"branch\": octoprint.server.BRANCH,",
            "                \"python_version\": get_python_version_string(),",
            "                \"plugin_hash\": plugin_hash.hexdigest(),",
            "                \"config_hash\": config_hash,",
            "                \"debug\": octoprint.server.debug,",
            "                \"safe_mode\": octoprint.server.safe_mode,",
            "                \"online\": self._connectivityChecker.online,",
            "                \"permissions\": [permission.as_dict() for permission in Permissions.all()],",
            "            },",
            "        )",
            "",
            "        self._eventManager.fire(",
            "            Events.CLIENT_OPENED, {\"remoteAddress\": self._remoteAddress}",
            "        )",
            "        self._register()",
            "",
            "    def on_close(self):",
            "        self._user = self._userManager.anonymous_user_factory()",
            "        self._groupManager.unregister_listener(self)",
            "        self._userManager.unregister_login_status_listener(self)",
            "",
            "        self._unregister()",
            "        self._eventManager.fire(",
            "            Events.CLIENT_CLOSED, {\"remoteAddress\": self._remoteAddress}",
            "        )",
            "",
            "        self._logger.info(\"Client connection closed: %s\" % self._remoteAddress)",
            "",
            "        self._on_logout()",
            "        self._remoteAddress = None",
            "        self._pluginManager.unregister_message_receiver(self.on_plugin_message)",
            "",
            "    def on_message(self, message):",
            "        try:",
            "            import json",
            "",
            "            message = json.loads(message)",
            "        except Exception:",
            "            self._logger.warning(",
            "                \"Invalid JSON received from client {}, ignoring: {!r}\".format(",
            "                    self._remoteAddress, message",
            "                )",
            "            )",
            "            return",
            "",
            "        if \"auth\" in message:",
            "            try:",
            "                parts = message[\"auth\"].split(\":\")",
            "                if not len(parts) == 2:",
            "                    raise ValueError()",
            "            except ValueError:",
            "                self._logger.warning(",
            "                    \"Got invalid auth message from client {}, ignoring: {!r}\".format(",
            "                        self._remoteAddress, message[\"auth\"]",
            "                    )",
            "                )",
            "            else:",
            "                user_id, user_session = parts",
            "",
            "                if self._userManager.validate_user_session(user_id, user_session):",
            "                    user = self._userManager.find_user(",
            "                        userid=user_id, session=user_session",
            "                    )",
            "                    self._on_login(user)",
            "                else:",
            "                    self._logger.warning(",
            "                        f\"Unknown user/session combo: {user_id}:{user_session}\"",
            "                    )",
            "                    self._on_logout()",
            "                    self._sendReauthRequired(\"stale\")",
            "",
            "            self._register()",
            "",
            "        elif \"throttle\" in message:",
            "            try:",
            "                throttle = int(message[\"throttle\"])",
            "                if throttle < 1:",
            "                    raise ValueError()",
            "            except ValueError:",
            "                self._logger.warning(",
            "                    \"Got invalid throttle factor from client {}, ignoring: {!r}\".format(",
            "                        self._remoteAddress, message[\"throttle\"]",
            "                    )",
            "                )",
            "            else:",
            "                self._throttle_factor = throttle",
            "                self._logger.debug(",
            "                    \"Set throttle factor for client {} to {}\".format(",
            "                        self._remoteAddress, self._throttle_factor",
            "                    )",
            "                )",
            "",
            "        elif \"subscribe\" in message:",
            "            if not self._subscriptions_active:",
            "                self._subscriptions_active = True",
            "                self._logger.debug(\"Client makes use of subscriptions\")",
            "",
            "            def list_or_boolean(value):",
            "                if isinstance(value, list):",
            "                    return value",
            "                elif isinstance(value, bool):",
            "                    return [] if not value else None",
            "                else:",
            "                    raise ValueError(\"value must be a list or boolean\")",
            "",
            "            def regex_or_boolean(value):",
            "                if isinstance(value, str):",
            "                    try:",
            "                        return re.compile(value)",
            "                    except Exception:",
            "                        raise ValueError(\"value must be a valid regex\")",
            "                elif isinstance(value, bool):",
            "                    return value",
            "                else:",
            "                    raise ValueError(\"value must be a string or boolean\")",
            "",
            "            try:",
            "                subscribe = message[\"subscribe\"]",
            "",
            "                state = subscribe.get(\"state\", False)",
            "                if isinstance(state, bool):",
            "                    if state:",
            "                        state = {\"logs\": True, \"messages\": False}",
            "                elif isinstance(state, dict):",
            "                    logs = regex_or_boolean(state.get(\"logs\", False))",
            "                    messages = regex_or_boolean(state.get(\"messages\", False))",
            "                    state = {",
            "                        \"logs\": logs,",
            "                        \"messages\": messages,",
            "                    }",
            "",
            "                plugins = list_or_boolean(subscribe.get(\"plugins\", []))",
            "                events = list_or_boolean(subscribe.get(\"events\", []))",
            "",
            "            except ValueError as e:",
            "                self._logger.warning(",
            "                    \"Got invalid subscription message from client {}, ignoring: {!r} ({}) \".format(",
            "                        self._remoteAddress, message[\"subscribe\"], str(e)",
            "                    )",
            "                )",
            "            else:",
            "                old_state = self._subscriptions[\"state\"]",
            "                self._subscriptions[\"state\"] = state",
            "                self._subscriptions[\"plugins\"] = plugins",
            "                self._subscriptions[\"events\"] = events",
            "",
            "                if state and state != old_state:",
            "                    # state is requested and was changed from previous state",
            "                    # we should send a history message to send the update data",
            "                    self._printer.send_initial_callback(self)",
            "                elif old_state and not state:",
            "                    # we no longer should send state updates",
            "                    self._initial_data_sent = False",
            "",
            "    def on_printer_send_current_data(self, data):",
            "        if not self._user.has_permission(Permissions.STATUS):",
            "            return",
            "",
            "        if self._subscriptions_active and not self._subscriptions[\"state\"]:",
            "            return",
            "",
            "        if not self._initial_data_sent:",
            "            self._logger.debug(\"Initial data not yet send, dropping current message\")",
            "            return",
            "",
            "        # make sure we rate limit the updates according to our throttle factor",
            "        with self._held_back_mutex:",
            "            if self._held_back_current is not None:",
            "                self._held_back_current.cancel()",
            "                self._held_back_current = None",
            "",
            "            now = time.time()",
            "            delta = (",
            "                self._last_current + self._base_rate_limit * self._throttle_factor - now",
            "            )",
            "            if delta > 0:",
            "                self._held_back_current = threading.Timer(",
            "                    delta, lambda: self.on_printer_send_current_data(data)",
            "                )",
            "                self._held_back_current.start()",
            "                return",
            "",
            "        self._last_current = now",
            "",
            "        # add current temperature, log and message backlogs to sent data",
            "        with self._temperatureBacklogMutex:",
            "            temperatures = self._temperatureBacklog",
            "            self._temperatureBacklog = []",
            "",
            "        with self._logBacklogMutex:",
            "            logs = self._filter_logs(self._logBacklog)",
            "            self._logBacklog = []",
            "",
            "        with self._messageBacklogMutex:",
            "            messages = self._filter_messages(self._messageBacklog)",
            "            self._messageBacklog = []",
            "",
            "        busy_files = [",
            "            {\"origin\": v[0], \"path\": v[1]} for v in self._fileManager.get_busy_files()",
            "        ]",
            "        if (",
            "            \"job\" in data",
            "            and data[\"job\"] is not None",
            "            and \"file\" in data[\"job\"]",
            "            and \"path\" in data[\"job\"][\"file\"]",
            "            and \"origin\" in data[\"job\"][\"file\"]",
            "            and data[\"job\"][\"file\"][\"path\"] is not None",
            "            and data[\"job\"][\"file\"][\"origin\"] is not None",
            "            and (self._printer.is_printing() or self._printer.is_paused())",
            "        ):",
            "            busy_files.append(",
            "                {",
            "                    \"origin\": data[\"job\"][\"file\"][\"origin\"],",
            "                    \"path\": data[\"job\"][\"file\"][\"path\"],",
            "                }",
            "            )",
            "",
            "        data.update(",
            "            {",
            "                \"serverTime\": time.time(),",
            "                \"temps\": temperatures,",
            "                \"busyFiles\": busy_files,",
            "                \"markings\": list(self._printer.get_markings()),",
            "            }",
            "        )",
            "        if self._user.has_permission(Permissions.MONITOR_TERMINAL):",
            "            data.update(",
            "                {",
            "                    \"logs\": self._filter_logs(logs),",
            "                    \"messages\": messages,",
            "                }",
            "            )",
            "        self._emit(\"current\", payload=data)",
            "",
            "    def on_printer_send_initial_data(self, data):",
            "        self._initial_data_sent = True",
            "        if self._subscriptions_active and not self._subscriptions[\"state\"]:",
            "            self._logger.debug(\"Not subscribed to state, dropping history\")",
            "            return",
            "",
            "        data_to_send = dict(data)",
            "",
            "        data_to_send[\"serverTime\"] = time.time()",
            "        if self._user.has_permission(Permissions.MONITOR_TERMINAL):",
            "            data_to_send[\"logs\"] = self._filter_logs(data_to_send.get(\"logs\", []))",
            "            data_to_send[\"messages\"] = self._filter_messages(",
            "                data_to_send.get(\"messages\", [])",
            "            )",
            "        self._emit(\"history\", payload=data_to_send)",
            "",
            "    def _filter_state_subscription(self, sub, values):",
            "        if not self._subscriptions_active or self._subscriptions[\"state\"][sub] is True:",
            "            return values",
            "",
            "        if self._subscriptions[\"state\"][sub] is False:",
            "            return []",
            "",
            "        return [line for line in values if self._subscriptions[\"state\"][sub].search(line)]",
            "",
            "    def _filter_logs(self, logs):",
            "        return self._filter_state_subscription(\"logs\", logs)",
            "",
            "    def _filter_messages(self, messages):",
            "        return self._filter_state_subscription(\"messages\", messages)",
            "",
            "    def sendEvent(self, type, payload=None):",
            "        permissions = self._event_permissions.get(type, self._event_permissions[\"*\"])",
            "        permissions = [x(self._user) if callable(x) else x for x in permissions]",
            "        if not self._user or not all(",
            "            map(lambda p: self._user.has_permission(p), permissions)",
            "        ):",
            "            return",
            "",
            "        processors = self._event_payload_processors.get(",
            "            type, self._event_payload_processors[\"*\"]",
            "        )",
            "        for processor in processors:",
            "            payload = processor(self._user, payload)",
            "",
            "        self._emit(\"event\", payload={\"type\": type, \"payload\": payload})",
            "",
            "    def sendTimelapseConfig(self, timelapseConfig):",
            "        self._emit(\"timelapse\", payload=timelapseConfig)",
            "",
            "    def sendSlicingProgress(",
            "        self, slicer, source_location, source_path, dest_location, dest_path, progress",
            "    ):",
            "        self._emit(",
            "            \"slicingProgress\",",
            "            payload={",
            "                \"slicer\": slicer,",
            "                \"source_location\": source_location,",
            "                \"source_path\": source_path,",
            "                \"dest_location\": dest_location,",
            "                \"dest_path\": dest_path,",
            "                \"progress\": progress,",
            "            },",
            "        )",
            "",
            "    def sendRenderProgress(self, progress):",
            "        self._emit(\"renderProgress\", {\"progress\": progress})",
            "",
            "    def on_plugin_message(self, plugin, data, permissions=None):",
            "        if (",
            "            self._subscriptions_active",
            "            and self._subscriptions[\"plugins\"] is not None",
            "            and plugin not in self._subscriptions[\"plugins\"]",
            "        ):",
            "            return",
            "",
            "        self._emit(",
            "            \"plugin\", payload={\"plugin\": plugin, \"data\": data}, permissions=permissions",
            "        )",
            "",
            "    def on_printer_add_log(self, data):",
            "        with self._logBacklogMutex:",
            "            self._logBacklog.append(data)",
            "",
            "    def on_printer_add_message(self, data):",
            "        with self._messageBacklogMutex:",
            "            self._messageBacklog.append(data)",
            "",
            "    def on_printer_add_temperature(self, data):",
            "        with self._temperatureBacklogMutex:",
            "            self._temperatureBacklog.append(data)",
            "",
            "    def on_user_logged_out(self, user, stale=False):",
            "        if (",
            "            user.get_id() == self._user.get_id()",
            "            and hasattr(user, \"session\")",
            "            and hasattr(self._user, \"session\")",
            "            and user.session == self._user.session",
            "        ):",
            "            self._logger.info(f\"User {user.get_id()} logged out, logging out on socket\")",
            "            self._on_logout()",
            "",
            "            if stale:",
            "                self._sendReauthRequired(\"stale\")",
            "            else:",
            "                self._sendReauthRequired(\"logout\")",
            "",
            "    def on_user_modified(self, user):",
            "        if user.get_id() == self._user.get_id():",
            "            self._sendReauthRequired(\"modified\")",
            "",
            "    def on_user_removed(self, userid):",
            "        if self._user.get_id() == userid:",
            "            self._logger.info(f\"User {userid} deleted, logging out on socket\")",
            "            self._on_logout()",
            "            self._sendReauthRequired(\"removed\")",
            "",
            "    def on_group_permissions_changed(self, group, added=None, removed=None):",
            "        if self._user.is_anonymous and group == self._groupManager.guest_group:",
            "            self._sendReauthRequired(\"modified\")",
            "",
            "    def on_group_subgroups_changed(self, group, added=None, removed=None):",
            "        if self._user.is_anonymous and group == self._groupManager.guest_group:",
            "            self._sendReauthRequired(\"modified\")",
            "",
            "    def _onEvent(self, event, payload):",
            "        if (",
            "            self._subscriptions_active",
            "            and self._subscriptions[\"events\"] is not None",
            "            and event not in self._subscriptions[\"events\"]",
            "        ):",
            "            return",
            "",
            "        self.sendEvent(event, payload)",
            "",
            "    def _register(self):",
            "        \"\"\"Register this socket with the system if STATUS permission is available.\"\"\"",
            "",
            "        proceed = True",
            "        for name, hook in self._register_hooks.items():",
            "            try:",
            "                proceed = proceed and hook(self, self._user)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing register hook handler for plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "",
            "        if not proceed:",
            "            return",
            "",
            "        if self._registered:",
            "            return",
            "",
            "        if not self._user.has_permission(Permissions.STATUS):",
            "            return",
            "",
            "        # printer",
            "        self._printer.register_callback(self)",
            "        self._printer.send_initial_callback(self)",
            "",
            "        # files",
            "        self._fileManager.register_slicingprogress_callback(self)",
            "",
            "        # events",
            "        for event in octoprint.events.all_events():",
            "            self._eventManager.subscribe(event, self._onEvent)",
            "",
            "        # timelapse",
            "        octoprint.timelapse.register_callback(self)",
            "        octoprint.timelapse.notify_callback(self, timelapse=octoprint.timelapse.current)",
            "        if octoprint.timelapse.current_render_job is not None:",
            "            # This is a horrible hack for now to allow displaying a notification that a render job is still",
            "            # active in the backend on a fresh connect of a client. This needs to be substituted with a proper",
            "            # job management for timelapse rendering, analysis stuff etc that also gets cancelled when prints",
            "            # start and so on.",
            "            #",
            "            # For now this is the easiest way though to at least inform the user that a timelapse is still ongoing.",
            "            #",
            "            # TODO remove when central job management becomes available and takes care of this for us",
            "            self.sendEvent(",
            "                Events.MOVIE_RENDERING, payload=octoprint.timelapse.current_render_job",
            "            )",
            "        self._registered = True",
            "",
            "    def _unregister(self):",
            "        \"\"\"Unregister this socket from the system\"\"\"",
            "",
            "        self._printer.unregister_callback(self)",
            "        self._fileManager.unregister_slicingprogress_callback(self)",
            "        octoprint.timelapse.unregister_callback(self)",
            "        for event in octoprint.events.all_events():",
            "            self._eventManager.unsubscribe(event, self._onEvent)",
            "",
            "    def _reregister(self):",
            "        \"\"\"Unregister and register again\"\"\"",
            "        self._unregister()",
            "        self._register()",
            "",
            "    def _sendReauthRequired(self, reason):",
            "        self._emit(\"reauthRequired\", payload={\"reason\": reason})",
            "",
            "    def _emit(self, type, payload=None, permissions=None):",
            "        proceed = True",
            "        for name, hook in self._emit_hooks.items():",
            "            try:",
            "                proceed = proceed and hook(self, self._user, type, payload)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing emit hook handler from plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "",
            "        if not proceed:",
            "            return",
            "",
            "        if permissions is None:",
            "            permissions = self._emit_permissions.get(type, self._emit_permissions[\"*\"])",
            "            permissions = (",
            "                permissions(payload)",
            "                if callable(permissions)",
            "                else [x for x in permissions]",
            "            )",
            "",
            "        if not self._user or not all(",
            "            map(lambda p: self._user.has_permission(p), permissions)",
            "        ):",
            "            if not self._authed:",
            "                with self._unauthed_backlog_mutex:",
            "                    if len(self._unauthed_backlog) < self._unauthed_backlog_max:",
            "                        self._unauthed_backlog.append((type, payload))",
            "                        self._logger.debug(",
            "                            \"Socket message held back until permissions cleared, added to backlog: {}\".format(",
            "                                type",
            "                            )",
            "                        )",
            "                    else:",
            "                        self._logger.debug(",
            "                            \"Socket message held back, but backlog full. Throwing message away: {}\".format(",
            "                                type",
            "                            )",
            "                        )",
            "            return",
            "",
            "        self._do_emit(type, payload)",
            "",
            "    def _do_emit(self, type, payload):",
            "        try:",
            "            self.send({type: payload})",
            "        except Exception as e:",
            "            if self._logger.isEnabledFor(logging.DEBUG):",
            "                self._logger.exception(",
            "                    f\"Could not send message to client {self._remoteAddress}\"",
            "                )",
            "            else:",
            "                self._logger.warning(",
            "                    \"Could not send message to client {}: {}\".format(",
            "                        self._remoteAddress, e",
            "                    )",
            "                )",
            "",
            "    def _on_login(self, user):",
            "        self._user = user",
            "        self._logger.info(",
            "            \"User {} logged in on the socket from client {}\".format(",
            "                user.get_name(), self._remoteAddress",
            "            )",
            "        )",
            "        self._authed = True",
            "",
            "        self._keep_alive.start()",
            "",
            "        for name, hook in self._authed_hooks.items():",
            "            try:",
            "                hook(self, self._user)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing authed hook handler for plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "",
            "        # if we have a backlog from being unauthed, process that now",
            "        with self._unauthed_backlog_mutex:",
            "            backlog = self._unauthed_backlog",
            "            self._unauthed_backlog = []",
            "",
            "        if len(backlog):",
            "            self._logger.debug(",
            "                \"Sending {} messages on the socket that were held back\".format(",
            "                    len(backlog)",
            "                )",
            "            )",
            "            for message, payload in backlog:",
            "                self._do_emit(message, payload)",
            "",
            "        # trigger ClientAuthed event",
            "        octoprint.events.eventManager().fire(",
            "            octoprint.events.Events.CLIENT_AUTHED,",
            "            payload={\"username\": user.get_name(), \"remoteAddress\": self._remoteAddress},",
            "        )",
            "",
            "    def _on_logout(self):",
            "        self._user = self._userManager.anonymous_user_factory()",
            "        self._authed = False",
            "",
            "        for name, hook in self._authed_hooks.items():",
            "            try:",
            "                hook(self, self._user)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing authed hook handler for plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )"
        ],
        "afterPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import logging",
            "import re",
            "import threading",
            "import time",
            "",
            "import wrapt",
            "",
            "import octoprint.access.users",
            "import octoprint.events",
            "import octoprint.plugin",
            "import octoprint.printer",
            "import octoprint.server",
            "import octoprint.timelapse",
            "import octoprint.vendor.sockjs.tornado",
            "import octoprint.vendor.sockjs.tornado.proto",
            "import octoprint.vendor.sockjs.tornado.session",
            "import octoprint.vendor.sockjs.tornado.util",
            "from octoprint.access.groups import GroupChangeListener",
            "from octoprint.access.permissions import Permissions",
            "from octoprint.access.users import LoginStatusListener, SessionUser",
            "from octoprint.events import Events",
            "from octoprint.settings import settings",
            "from octoprint.util import RepeatedTimer",
            "from octoprint.util.json import dumps as json_dumps",
            "from octoprint.util.version import get_python_version_string",
            "",
            "",
            "class ThreadSafeSession(octoprint.vendor.sockjs.tornado.session.Session):",
            "    def __init__(self, conn, server, session_id, expiry=None):",
            "        octoprint.vendor.sockjs.tornado.session.Session.__init__(",
            "            self, conn, server, session_id, expiry=expiry",
            "        )",
            "",
            "    def set_handler(self, handler, start_heartbeat=True):",
            "        if getattr(handler, \"__orig_send_pack\", None) is None:",
            "            orig_send_pack = handler.send_pack",
            "            mutex = threading.RLock()",
            "",
            "            def send_pack(*args, **kwargs):",
            "                with mutex:",
            "                    return orig_send_pack(*args, **kwargs)",
            "",
            "            handler.send_pack = send_pack",
            "            handler.__orig_send_pack = orig_send_pack",
            "",
            "        return octoprint.vendor.sockjs.tornado.session.Session.set_handler(",
            "            self, handler, start_heartbeat=start_heartbeat",
            "        )",
            "",
            "    def remove_handler(self, handler):",
            "        result = octoprint.vendor.sockjs.tornado.session.Session.remove_handler(",
            "            self, handler",
            "        )",
            "",
            "        if getattr(handler, \"__orig_send_pack\", None) is not None:",
            "            handler.send_pack = handler.__orig_send_pack",
            "            delattr(handler, \"__orig_send_pack\")",
            "",
            "        return result",
            "",
            "",
            "class JsonEncodingSessionWrapper(wrapt.ObjectProxy):",
            "    def send_message(self, msg, stats=True, binary=False):",
            "        self.send_jsonified(",
            "            json_dumps(octoprint.vendor.sockjs.tornado.util.bytes_to_str(msg)),",
            "            stats,",
            "        )",
            "",
            "",
            "class PrinterStateConnection(",
            "    octoprint.vendor.sockjs.tornado.SockJSConnection,",
            "    octoprint.printer.PrinterCallback,",
            "    LoginStatusListener,",
            "    GroupChangeListener,",
            "):",
            "    _event_permissions = {",
            "        Events.USER_LOGGED_IN: [Permissions.ADMIN],",
            "        Events.USER_LOGGED_OUT: [Permissions.ADMIN],",
            "        \"*\": [],",
            "    }",
            "",
            "    _event_payload_processors = {",
            "        Events.CLIENT_OPENED: [",
            "            lambda user, payload: (",
            "                payload if user.has_permission(Permissions.ADMIN) else {}",
            "            )",
            "        ],",
            "        Events.CLIENT_AUTHED: [",
            "            lambda user, payload: (",
            "                payload if user.has_permission(Permissions.ADMIN) else {}",
            "            )",
            "        ],",
            "        \"*\": [],",
            "    }",
            "",
            "    # TODO: Permissions should be overridable from plugins, this special case stuff here is a hack",
            "    _emit_permissions = {",
            "        \"connected\": [],",
            "        \"reauthRequired\": [],",
            "        \"plugin\": lambda payload: (",
            "            []",
            "            if payload.get(\"plugin\") in (\"backup\", \"softwareupdate\")",
            "            and settings().getBoolean([\"server\", \"firstRun\"])",
            "            else [Permissions.STATUS]",
            "        ),",
            "        \"*\": [Permissions.STATUS],",
            "    }",
            "",
            "    _unauthed_backlog_max = 100",
            "",
            "    def __init__(",
            "        self,",
            "        printer,",
            "        fileManager,",
            "        analysisQueue,",
            "        userManager,",
            "        groupManager,",
            "        eventManager,",
            "        pluginManager,",
            "        connectivityChecker,",
            "        session,",
            "    ):",
            "        if isinstance(session, octoprint.vendor.sockjs.tornado.session.Session):",
            "            session = JsonEncodingSessionWrapper(session)",
            "",
            "        octoprint.vendor.sockjs.tornado.SockJSConnection.__init__(self, session)",
            "",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "        self._temperatureBacklog = []",
            "        self._temperatureBacklogMutex = threading.Lock()",
            "        self._logBacklog = []",
            "        self._logBacklogMutex = threading.Lock()",
            "        self._messageBacklog = []",
            "        self._messageBacklogMutex = threading.Lock()",
            "",
            "        self._unauthed_backlog = []",
            "        self._unauthed_backlog_mutex = threading.RLock()",
            "",
            "        self._printer = printer",
            "        self._fileManager = fileManager",
            "        self._analysisQueue = analysisQueue",
            "        self._userManager = userManager",
            "        self._groupManager = groupManager",
            "        self._eventManager = eventManager",
            "        self._pluginManager = pluginManager",
            "        self._connectivityChecker = connectivityChecker",
            "",
            "        self._remoteAddress = None",
            "        self._user = self._userManager.anonymous_user_factory()",
            "",
            "        self._throttle_factor = 1",
            "        self._last_current = 0",
            "        self._base_rate_limit = 0.5",
            "",
            "        self._held_back_current = None",
            "        self._held_back_mutex = threading.RLock()",
            "",
            "        self._register_hooks = self._pluginManager.get_hooks(",
            "            \"octoprint.server.sockjs.register\"",
            "        )",
            "        self._authed_hooks = self._pluginManager.get_hooks(",
            "            \"octoprint.server.sockjs.authed\"",
            "        )",
            "        self._emit_hooks = self._pluginManager.get_hooks(\"octoprint.server.sockjs.emit\")",
            "",
            "        self._registered = False",
            "        self._authed = False",
            "        self._initial_data_sent = False",
            "",
            "        self._subscriptions_active = False",
            "        self._subscriptions = {\"state\": False, \"plugins\": [], \"events\": []}",
            "",
            "        self._keep_alive = RepeatedTimer(",
            "            60, self._keep_alive_callback, condition=lambda: self._authed",
            "        )",
            "",
            "    @staticmethod",
            "    def _get_remote_address(info):",
            "        from octoprint.util.net import get_http_client_ip",
            "",
            "        trusted_proxies = settings().get([\"server\", \"reverseProxy\", \"trustedUpstream\"])",
            "        if not isinstance(trusted_proxies, list):",
            "            trusted_proxies = [\"127.0.0.1\"]",
            "",
            "        return get_http_client_ip(",
            "            info.ip, info.headers.get(\"X-Forwarded-For\"), trusted_proxies",
            "        )",
            "",
            "    def _keep_alive_callback(self):",
            "        if not self._authed:",
            "            return",
            "        if not isinstance(self._user, SessionUser):",
            "            return",
            "        self._user.touch()",
            "",
            "    def __str__(self):",
            "        if self._remoteAddress:",
            "            return f\"{self!r} connected to {self._remoteAddress}\"",
            "        else:",
            "            return f\"Unconnected {self!r}\"",
            "",
            "    def on_open(self, info):",
            "        self._pluginManager.register_message_receiver(self.on_plugin_message)",
            "        self._remoteAddress = self._get_remote_address(info)",
            "        self._logger.info(\"New connection from client: %s\" % self._remoteAddress)",
            "",
            "        self._userManager.register_login_status_listener(self)",
            "        self._groupManager.register_listener(self)",
            "",
            "        plugin_signature = lambda impl: \"{}:{}\".format(",
            "            impl._identifier, impl._plugin_version",
            "        )",
            "        template_plugins = list(",
            "            map(",
            "                plugin_signature,",
            "                self._pluginManager.get_implementations(octoprint.plugin.TemplatePlugin),",
            "            )",
            "        )",
            "        asset_plugins = list(",
            "            map(",
            "                plugin_signature,",
            "                self._pluginManager.get_implementations(octoprint.plugin.AssetPlugin),",
            "            )",
            "        )",
            "        ui_plugins = sorted(set(template_plugins + asset_plugins))",
            "",
            "        import hashlib",
            "",
            "        plugin_hash = hashlib.md5()",
            "        plugin_hash.update(\",\".join(ui_plugins).encode(\"utf-8\"))",
            "",
            "        config_hash = settings().config_hash",
            "",
            "        # connected => update the API key, might be necessary if the client was left open while the server restarted",
            "        self._emit(",
            "            \"connected\",",
            "            {",
            "                \"version\": octoprint.server.VERSION,",
            "                \"display_version\": octoprint.server.DISPLAY_VERSION,",
            "                \"branch\": octoprint.server.BRANCH,",
            "                \"python_version\": get_python_version_string(),",
            "                \"plugin_hash\": plugin_hash.hexdigest(),",
            "                \"config_hash\": config_hash,",
            "                \"debug\": octoprint.server.debug,",
            "                \"safe_mode\": octoprint.server.safe_mode,",
            "                \"online\": self._connectivityChecker.online,",
            "                \"permissions\": [permission.as_dict() for permission in Permissions.all()],",
            "            },",
            "        )",
            "",
            "        self._eventManager.fire(",
            "            Events.CLIENT_OPENED, {\"remoteAddress\": self._remoteAddress}",
            "        )",
            "        self._register()",
            "",
            "    def on_close(self):",
            "        self._user = self._userManager.anonymous_user_factory()",
            "        self._groupManager.unregister_listener(self)",
            "        self._userManager.unregister_login_status_listener(self)",
            "",
            "        self._unregister()",
            "        self._eventManager.fire(",
            "            Events.CLIENT_CLOSED, {\"remoteAddress\": self._remoteAddress}",
            "        )",
            "",
            "        self._logger.info(\"Client connection closed: %s\" % self._remoteAddress)",
            "",
            "        self._on_logout()",
            "        self._remoteAddress = None",
            "        self._pluginManager.unregister_message_receiver(self.on_plugin_message)",
            "",
            "    def on_message(self, message):",
            "        try:",
            "            import json",
            "",
            "            message = json.loads(message)",
            "        except Exception:",
            "            self._logger.warning(",
            "                \"Invalid JSON received from client {}, ignoring: {!r}\".format(",
            "                    self._remoteAddress, message",
            "                )",
            "            )",
            "            return",
            "",
            "        if \"auth\" in message:",
            "            try:",
            "                parts = message[\"auth\"].split(\":\")",
            "                if not len(parts) == 2:",
            "                    raise ValueError()",
            "            except ValueError:",
            "                self._logger.warning(",
            "                    \"Got invalid auth message from client {}, ignoring: {!r}\".format(",
            "                        self._remoteAddress, message[\"auth\"]",
            "                    )",
            "                )",
            "            else:",
            "                user_id, user_session = parts",
            "",
            "                if self._userManager.validate_user_session(user_id, user_session):",
            "                    user = self._userManager.find_user(",
            "                        userid=user_id, session=user_session",
            "                    )",
            "                    self._on_login(user)",
            "                else:",
            "                    self._logger.warning(",
            "                        f\"Unknown user/session combo: {user_id}:{user_session}\"",
            "                    )",
            "                    self._on_logout()",
            "                    self._sendReauthRequired(\"stale\")",
            "",
            "            self._register()",
            "",
            "        elif \"throttle\" in message:",
            "            try:",
            "                throttle = int(message[\"throttle\"])",
            "                if throttle < 1:",
            "                    raise ValueError()",
            "            except ValueError:",
            "                self._logger.warning(",
            "                    \"Got invalid throttle factor from client {}, ignoring: {!r}\".format(",
            "                        self._remoteAddress, message[\"throttle\"]",
            "                    )",
            "                )",
            "            else:",
            "                self._throttle_factor = throttle",
            "                self._logger.debug(",
            "                    \"Set throttle factor for client {} to {}\".format(",
            "                        self._remoteAddress, self._throttle_factor",
            "                    )",
            "                )",
            "",
            "        elif \"subscribe\" in message:",
            "            if not self._subscriptions_active:",
            "                self._subscriptions_active = True",
            "                self._logger.debug(\"Client makes use of subscriptions\")",
            "",
            "            def list_or_boolean(value):",
            "                if isinstance(value, list):",
            "                    return value",
            "                elif isinstance(value, bool):",
            "                    return [] if not value else None",
            "                else:",
            "                    raise ValueError(\"value must be a list or boolean\")",
            "",
            "            def regex_or_boolean(value):",
            "                if isinstance(value, str):",
            "                    try:",
            "                        return re.compile(value)",
            "                    except Exception:",
            "                        raise ValueError(\"value must be a valid regex\")",
            "                elif isinstance(value, bool):",
            "                    return value",
            "                else:",
            "                    raise ValueError(\"value must be a string or boolean\")",
            "",
            "            try:",
            "                subscribe = message[\"subscribe\"]",
            "",
            "                state = subscribe.get(\"state\", False)",
            "                if isinstance(state, bool):",
            "                    if state:",
            "                        state = {\"logs\": True, \"messages\": False}",
            "                elif isinstance(state, dict):",
            "                    logs = regex_or_boolean(state.get(\"logs\", False))",
            "                    messages = regex_or_boolean(state.get(\"messages\", False))",
            "                    state = {",
            "                        \"logs\": logs,",
            "                        \"messages\": messages,",
            "                    }",
            "",
            "                plugins = list_or_boolean(subscribe.get(\"plugins\", []))",
            "                events = list_or_boolean(subscribe.get(\"events\", []))",
            "",
            "            except ValueError as e:",
            "                self._logger.warning(",
            "                    \"Got invalid subscription message from client {}, ignoring: {!r} ({}) \".format(",
            "                        self._remoteAddress, message[\"subscribe\"], str(e)",
            "                    )",
            "                )",
            "            else:",
            "                old_state = self._subscriptions[\"state\"]",
            "                self._subscriptions[\"state\"] = state",
            "                self._subscriptions[\"plugins\"] = plugins",
            "                self._subscriptions[\"events\"] = events",
            "",
            "                if state and state != old_state:",
            "                    # state is requested and was changed from previous state",
            "                    # we should send a history message to send the update data",
            "                    self._printer.send_initial_callback(self)",
            "                elif old_state and not state:",
            "                    # we no longer should send state updates",
            "                    self._initial_data_sent = False",
            "",
            "    def on_printer_send_current_data(self, data):",
            "        if not self._user.has_permission(Permissions.STATUS):",
            "            return",
            "",
            "        if self._subscriptions_active and not self._subscriptions[\"state\"]:",
            "            return",
            "",
            "        if not self._initial_data_sent:",
            "            self._logger.debug(\"Initial data not yet send, dropping current message\")",
            "            return",
            "",
            "        # make sure we rate limit the updates according to our throttle factor",
            "        with self._held_back_mutex:",
            "            if self._held_back_current is not None:",
            "                self._held_back_current.cancel()",
            "                self._held_back_current = None",
            "",
            "            now = time.time()",
            "            delta = (",
            "                self._last_current + self._base_rate_limit * self._throttle_factor - now",
            "            )",
            "            if delta > 0:",
            "                self._held_back_current = threading.Timer(",
            "                    delta, lambda: self.on_printer_send_current_data(data)",
            "                )",
            "                self._held_back_current.start()",
            "                return",
            "",
            "        self._last_current = now",
            "",
            "        # add current temperature, log and message backlogs to sent data",
            "        with self._temperatureBacklogMutex:",
            "            temperatures = self._temperatureBacklog",
            "            self._temperatureBacklog = []",
            "",
            "        with self._logBacklogMutex:",
            "            logs = self._filter_logs(self._logBacklog)",
            "            self._logBacklog = []",
            "",
            "        with self._messageBacklogMutex:",
            "            messages = self._filter_messages(self._messageBacklog)",
            "            self._messageBacklog = []",
            "",
            "        busy_files = [",
            "            {\"origin\": v[0], \"path\": v[1]} for v in self._fileManager.get_busy_files()",
            "        ]",
            "        if (",
            "            \"job\" in data",
            "            and data[\"job\"] is not None",
            "            and \"file\" in data[\"job\"]",
            "            and \"path\" in data[\"job\"][\"file\"]",
            "            and \"origin\" in data[\"job\"][\"file\"]",
            "            and data[\"job\"][\"file\"][\"path\"] is not None",
            "            and data[\"job\"][\"file\"][\"origin\"] is not None",
            "            and (self._printer.is_printing() or self._printer.is_paused())",
            "        ):",
            "            busy_files.append(",
            "                {",
            "                    \"origin\": data[\"job\"][\"file\"][\"origin\"],",
            "                    \"path\": data[\"job\"][\"file\"][\"path\"],",
            "                }",
            "            )",
            "",
            "        data.update(",
            "            {",
            "                \"serverTime\": time.time(),",
            "                \"temps\": temperatures,",
            "                \"busyFiles\": busy_files,",
            "                \"markings\": list(self._printer.get_markings()),",
            "            }",
            "        )",
            "        if self._user.has_permission(Permissions.MONITOR_TERMINAL):",
            "            data.update(",
            "                {",
            "                    \"logs\": self._filter_logs(logs),",
            "                    \"messages\": messages,",
            "                }",
            "            )",
            "        self._emit(\"current\", payload=data)",
            "",
            "    def on_printer_send_initial_data(self, data):",
            "        self._initial_data_sent = True",
            "        if self._subscriptions_active and not self._subscriptions[\"state\"]:",
            "            self._logger.debug(\"Not subscribed to state, dropping history\")",
            "            return",
            "",
            "        data_to_send = dict(data)",
            "",
            "        data_to_send[\"serverTime\"] = time.time()",
            "        if self._user.has_permission(Permissions.MONITOR_TERMINAL):",
            "            data_to_send[\"logs\"] = self._filter_logs(data_to_send.get(\"logs\", []))",
            "            data_to_send[\"messages\"] = self._filter_messages(",
            "                data_to_send.get(\"messages\", [])",
            "            )",
            "        self._emit(\"history\", payload=data_to_send)",
            "",
            "    def _filter_state_subscription(self, sub, values):",
            "        if not self._subscriptions_active or self._subscriptions[\"state\"][sub] is True:",
            "            return values",
            "",
            "        if self._subscriptions[\"state\"][sub] is False:",
            "            return []",
            "",
            "        return [line for line in values if self._subscriptions[\"state\"][sub].search(line)]",
            "",
            "    def _filter_logs(self, logs):",
            "        return self._filter_state_subscription(\"logs\", logs)",
            "",
            "    def _filter_messages(self, messages):",
            "        return self._filter_state_subscription(\"messages\", messages)",
            "",
            "    def sendEvent(self, type, payload=None):",
            "        permissions = self._event_permissions.get(type, self._event_permissions[\"*\"])",
            "        permissions = [x(self._user) if callable(x) else x for x in permissions]",
            "        if not self._user or not all(",
            "            map(lambda p: self._user.has_permission(p), permissions)",
            "        ):",
            "            return",
            "",
            "        processors = self._event_payload_processors.get(",
            "            type, self._event_payload_processors[\"*\"]",
            "        )",
            "        for processor in processors:",
            "            payload = processor(self._user, payload)",
            "",
            "        self._emit(\"event\", payload={\"type\": type, \"payload\": payload})",
            "",
            "    def sendTimelapseConfig(self, timelapseConfig):",
            "        self._emit(\"timelapse\", payload=timelapseConfig)",
            "",
            "    def sendSlicingProgress(",
            "        self, slicer, source_location, source_path, dest_location, dest_path, progress",
            "    ):",
            "        self._emit(",
            "            \"slicingProgress\",",
            "            payload={",
            "                \"slicer\": slicer,",
            "                \"source_location\": source_location,",
            "                \"source_path\": source_path,",
            "                \"dest_location\": dest_location,",
            "                \"dest_path\": dest_path,",
            "                \"progress\": progress,",
            "            },",
            "        )",
            "",
            "    def sendRenderProgress(self, progress):",
            "        self._emit(\"renderProgress\", {\"progress\": progress})",
            "",
            "    def on_plugin_message(self, plugin, data, permissions=None):",
            "        if (",
            "            self._subscriptions_active",
            "            and self._subscriptions[\"plugins\"] is not None",
            "            and plugin not in self._subscriptions[\"plugins\"]",
            "        ):",
            "            return",
            "",
            "        self._emit(",
            "            \"plugin\", payload={\"plugin\": plugin, \"data\": data}, permissions=permissions",
            "        )",
            "",
            "    def on_printer_add_log(self, data):",
            "        with self._logBacklogMutex:",
            "            self._logBacklog.append(data)",
            "",
            "    def on_printer_add_message(self, data):",
            "        with self._messageBacklogMutex:",
            "            self._messageBacklog.append(data)",
            "",
            "    def on_printer_add_temperature(self, data):",
            "        with self._temperatureBacklogMutex:",
            "            self._temperatureBacklog.append(data)",
            "",
            "    def on_user_logged_out(self, user, stale=False):",
            "        if (",
            "            user.get_id() == self._user.get_id()",
            "            and hasattr(user, \"session\")",
            "            and hasattr(self._user, \"session\")",
            "            and user.session == self._user.session",
            "        ):",
            "            self._logger.info(f\"User {user.get_id()} logged out, logging out on socket\")",
            "            self._on_logout()",
            "",
            "            if stale:",
            "                self._sendReauthRequired(\"stale\")",
            "            else:",
            "                self._sendReauthRequired(\"logout\")",
            "",
            "    def on_user_modified(self, user):",
            "        if user.get_id() == self._user.get_id():",
            "            self._sendReauthRequired(\"modified\")",
            "",
            "    def on_user_removed(self, userid):",
            "        if self._user.get_id() == userid:",
            "            self._logger.info(f\"User {userid} deleted, logging out on socket\")",
            "            self._on_logout()",
            "            self._sendReauthRequired(\"removed\")",
            "",
            "    def on_group_permissions_changed(self, group, added=None, removed=None):",
            "        if self._user.is_anonymous and group == self._groupManager.guest_group:",
            "            self._sendReauthRequired(\"modified\")",
            "",
            "    def on_group_subgroups_changed(self, group, added=None, removed=None):",
            "        if self._user.is_anonymous and group == self._groupManager.guest_group:",
            "            self._sendReauthRequired(\"modified\")",
            "",
            "    def _onEvent(self, event, payload):",
            "        if (",
            "            self._subscriptions_active",
            "            and self._subscriptions[\"events\"] is not None",
            "            and event not in self._subscriptions[\"events\"]",
            "        ):",
            "            return",
            "",
            "        self.sendEvent(event, payload)",
            "",
            "    def _register(self):",
            "        \"\"\"Register this socket with the system if STATUS permission is available.\"\"\"",
            "",
            "        proceed = True",
            "        for name, hook in self._register_hooks.items():",
            "            try:",
            "                proceed = proceed and hook(self, self._user)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing register hook handler for plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "",
            "        if not proceed:",
            "            return",
            "",
            "        if self._registered:",
            "            return",
            "",
            "        if not self._user.has_permission(Permissions.STATUS):",
            "            return",
            "",
            "        # printer",
            "        self._printer.register_callback(self)",
            "        self._printer.send_initial_callback(self)",
            "",
            "        # files",
            "        self._fileManager.register_slicingprogress_callback(self)",
            "",
            "        # events",
            "        for event in octoprint.events.all_events():",
            "            self._eventManager.subscribe(event, self._onEvent)",
            "",
            "        # timelapse",
            "        octoprint.timelapse.register_callback(self)",
            "        octoprint.timelapse.notify_callback(self, timelapse=octoprint.timelapse.current)",
            "        if octoprint.timelapse.current_render_job is not None:",
            "            # This is a horrible hack for now to allow displaying a notification that a render job is still",
            "            # active in the backend on a fresh connect of a client. This needs to be substituted with a proper",
            "            # job management for timelapse rendering, analysis stuff etc that also gets cancelled when prints",
            "            # start and so on.",
            "            #",
            "            # For now this is the easiest way though to at least inform the user that a timelapse is still ongoing.",
            "            #",
            "            # TODO remove when central job management becomes available and takes care of this for us",
            "            self.sendEvent(",
            "                Events.MOVIE_RENDERING, payload=octoprint.timelapse.current_render_job",
            "            )",
            "        self._registered = True",
            "",
            "    def _unregister(self):",
            "        \"\"\"Unregister this socket from the system\"\"\"",
            "",
            "        self._printer.unregister_callback(self)",
            "        self._fileManager.unregister_slicingprogress_callback(self)",
            "        octoprint.timelapse.unregister_callback(self)",
            "        for event in octoprint.events.all_events():",
            "            self._eventManager.unsubscribe(event, self._onEvent)",
            "",
            "    def _reregister(self):",
            "        \"\"\"Unregister and register again\"\"\"",
            "        self._unregister()",
            "        self._register()",
            "",
            "    def _sendReauthRequired(self, reason):",
            "        self._emit(\"reauthRequired\", payload={\"reason\": reason})",
            "",
            "    def _emit(self, type, payload=None, permissions=None):",
            "        proceed = True",
            "        for name, hook in self._emit_hooks.items():",
            "            try:",
            "                proceed = proceed and hook(self, self._user, type, payload)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing emit hook handler from plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "",
            "        if not proceed:",
            "            return",
            "",
            "        if permissions is None:",
            "            permissions = self._emit_permissions.get(type, self._emit_permissions[\"*\"])",
            "            permissions = (",
            "                permissions(payload)",
            "                if callable(permissions)",
            "                else [x for x in permissions]",
            "            )",
            "",
            "        if not self._user or not all(",
            "            map(lambda p: self._user.has_permission(p), permissions)",
            "        ):",
            "            if not self._authed:",
            "                with self._unauthed_backlog_mutex:",
            "                    if len(self._unauthed_backlog) < self._unauthed_backlog_max:",
            "                        self._unauthed_backlog.append((type, payload))",
            "                        self._logger.debug(",
            "                            \"Socket message held back until permissions cleared, added to backlog: {}\".format(",
            "                                type",
            "                            )",
            "                        )",
            "                    else:",
            "                        self._logger.debug(",
            "                            \"Socket message held back, but backlog full. Throwing message away: {}\".format(",
            "                                type",
            "                            )",
            "                        )",
            "            return",
            "",
            "        self._do_emit(type, payload)",
            "",
            "    def _do_emit(self, type, payload):",
            "        try:",
            "            self.send({type: payload})",
            "        except Exception as e:",
            "            if self._logger.isEnabledFor(logging.DEBUG):",
            "                self._logger.exception(",
            "                    f\"Could not send message to client {self._remoteAddress}\"",
            "                )",
            "            else:",
            "                self._logger.warning(",
            "                    \"Could not send message to client {}: {}\".format(",
            "                        self._remoteAddress, e",
            "                    )",
            "                )",
            "",
            "    def _on_login(self, user):",
            "        self._user = user",
            "        self._logger.info(",
            "            \"User {} logged in on the socket from client {}\".format(",
            "                user.get_name(), self._remoteAddress",
            "            )",
            "        )",
            "        self._authed = True",
            "",
            "        self._keep_alive.start()",
            "",
            "        for name, hook in self._authed_hooks.items():",
            "            try:",
            "                hook(self, self._user)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing authed hook handler for plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )",
            "",
            "        # if we have a backlog from being unauthed, process that now",
            "        with self._unauthed_backlog_mutex:",
            "            backlog = self._unauthed_backlog",
            "            self._unauthed_backlog = []",
            "",
            "        if len(backlog):",
            "            self._logger.debug(",
            "                \"Sending {} messages on the socket that were held back\".format(",
            "                    len(backlog)",
            "                )",
            "            )",
            "            for message, payload in backlog:",
            "                self._do_emit(message, payload)",
            "",
            "        # trigger ClientAuthed event",
            "        octoprint.events.eventManager().fire(",
            "            octoprint.events.Events.CLIENT_AUTHED,",
            "            payload={\"username\": user.get_name(), \"remoteAddress\": self._remoteAddress},",
            "        )",
            "",
            "    def _on_logout(self):",
            "        self._user = self._userManager.anonymous_user_factory()",
            "        self._authed = False",
            "",
            "        for name, hook in self._authed_hooks.items():",
            "            try:",
            "                hook(self, self._user)",
            "            except Exception:",
            "                self._logger.exception(",
            "                    f\"Error processing authed hook handler for plugin {name}\",",
            "                    extra={\"plugin\": name},",
            "                )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "88": [
                "PrinterStateConnection"
            ],
            "89": [
                "PrinterStateConnection"
            ],
            "90": [
                "PrinterStateConnection"
            ],
            "93": [
                "PrinterStateConnection"
            ],
            "94": [
                "PrinterStateConnection"
            ],
            "95": [
                "PrinterStateConnection"
            ],
            "104": [
                "PrinterStateConnection"
            ],
            "105": [
                "PrinterStateConnection"
            ],
            "106": [
                "PrinterStateConnection"
            ],
            "107": [
                "PrinterStateConnection"
            ],
            "182": [
                "PrinterStateConnection",
                "_get_remote_address"
            ],
            "183": [
                "PrinterStateConnection",
                "_get_remote_address"
            ],
            "184": [
                "PrinterStateConnection",
                "_get_remote_address"
            ],
            "185": [
                "PrinterStateConnection",
                "_get_remote_address"
            ]
        },
        "addLocation": []
    },
    "src/octoprint/server/util/tornado.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " import tornado.httpserver"
            },
            "1": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import tornado.httputil"
            },
            "2": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " import tornado.iostream"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+import tornado.netutil"
            },
            "4": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " import tornado.tcpserver"
            },
            "5": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " import tornado.util"
            },
            "6": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " import tornado.web"
            },
            "7": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from zipstream.ng import ZIP_DEFLATED, ZipStream"
            },
            "8": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " import octoprint.util"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+import octoprint.util.net"
            },
            "11": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 31,
                "PatchRowcode": " "
            },
            "12": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 33,
                "PatchRowcode": " def fix_json_encode():"
            },
            "14": {
                "beforePatchRowNumber": 93,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "     tornado.websocket.WebSocketHandler.check_origin = patched_check_origin"
            },
            "15": {
                "beforePatchRowNumber": 94,
                "afterPatchRowNumber": 96,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 95,
                "afterPatchRowNumber": 97,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 98,
                "PatchRowcode": "+def fix_tornado_xheader_handling():"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 99,
                "PatchRowcode": "+    \"\"\""
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 100,
                "PatchRowcode": "+    This fixes tornado.httpserver._HTTPRequestContext._apply_xheaders to only use \"X-Forwarded-For\" header"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 101,
                "PatchRowcode": "+    for rewriting the ``remote_ip`` field, utilizing the set of trusted downstreams, instead of blindly"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 102,
                "PatchRowcode": "+    trusting ``X-Real-Ip``, and to also fetch the scheme from \"X-Forwarded-Proto\" if available."
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+    \"\"\""
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 104,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 105,
                "PatchRowcode": "+    def patched_apply_xheaders(self, headers: \"tornado.httputil.HTTPHeaders\") -> None:"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 106,
                "PatchRowcode": "+        \"\"\"Rewrite the ``remote_ip`` and ``protocol`` fields.\"\"\""
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 107,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 108,
                "PatchRowcode": "+        # other than the default implementation, we only use \"X-Forwarded-For\" here, not \"X-Real-Ip\""
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 109,
                "PatchRowcode": "+        ip = octoprint.util.net.get_http_client_ip("
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 110,
                "PatchRowcode": "+            self.remote_ip, headers.get(\"X-Forwarded-For\"), self.trusted_downstream"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 111,
                "PatchRowcode": "+        )"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+        if tornado.netutil.is_valid_ip(ip):"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+            self.remote_ip = ip"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 115,
                "PatchRowcode": "+        # also fetch scheme from \"X-Forwarded-Proto\" if available"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+        proto_header = headers.get(\"X-Scheme\", headers.get(\"X-Forwarded-Proto\"))"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+        if proto_header:"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 118,
                "PatchRowcode": "+            # use only the last proto entry if there is more than one"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 119,
                "PatchRowcode": "+            proto_header = proto_header.split(\",\")[-1].strip()"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 120,
                "PatchRowcode": "+        if proto_header in (\"http\", \"https\"):"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 121,
                "PatchRowcode": "+            self.protocol = proto_header"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 122,
                "PatchRowcode": "+"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 123,
                "PatchRowcode": "+    import tornado.httpserver"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 124,
                "PatchRowcode": "+"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 125,
                "PatchRowcode": "+    tornado.httpserver._HTTPRequestContext._apply_xheaders = patched_apply_xheaders"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 126,
                "PatchRowcode": "+"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+"
            },
            "47": {
                "beforePatchRowNumber": 96,
                "afterPatchRowNumber": 128,
                "PatchRowcode": " # ~~ More sensible logging"
            },
            "48": {
                "beforePatchRowNumber": 97,
                "afterPatchRowNumber": 129,
                "PatchRowcode": " "
            },
            "49": {
                "beforePatchRowNumber": 98,
                "afterPatchRowNumber": 130,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import asyncio",
            "import logging",
            "import mimetypes",
            "import os",
            "import re",
            "import sys",
            "from urllib.parse import urlparse",
            "",
            "import tornado",
            "import tornado.escape",
            "import tornado.gen",
            "import tornado.http1connection",
            "import tornado.httpclient",
            "import tornado.httpserver",
            "import tornado.httputil",
            "import tornado.iostream",
            "import tornado.tcpserver",
            "import tornado.util",
            "import tornado.web",
            "from tornado.concurrent import dummy_executor",
            "from tornado.ioloop import IOLoop",
            "from zipstream.ng import ZIP_DEFLATED, ZipStream",
            "",
            "import octoprint.util",
            "",
            "",
            "def fix_json_encode():",
            "    \"\"\"",
            "    This makes tornado.escape.json_encode use octoprint.util.JsonEncoding.encode as fallback in order to allow",
            "    serialization of globally registered types like frozendict and others.",
            "    \"\"\"",
            "",
            "    import json",
            "",
            "    from octoprint.util.json import JsonEncoding",
            "",
            "    def fixed_json_encode(value):",
            "        return json.dumps(value, default=JsonEncoding.encode, allow_nan=False).replace(",
            "            \"</\", \"<\\\\/\"",
            "        )",
            "",
            "    import tornado.escape",
            "",
            "    tornado.escape.json_encode = fixed_json_encode",
            "",
            "",
            "def enable_per_message_deflate_extension():",
            "    \"\"\"",
            "    This configures tornado.websocket.WebSocketHandler.get_compression_options to support the permessage-deflate extension",
            "    to the websocket protocol, minimizing data bandwidth if clients support the extension as well",
            "    \"\"\"",
            "",
            "    def get_compression_options(self):",
            "        return {\"compression_level\": 1, \"mem_level\": 1}",
            "",
            "    tornado.websocket.WebSocketHandler.get_compression_options = get_compression_options",
            "",
            "",
            "def fix_websocket_check_origin():",
            "    \"\"\"",
            "    This fixes tornado.websocket.WebSocketHandler.check_origin to do the same origin check against the Host",
            "    header case-insensitively, as defined in RFC6454, Section 4, item 5.",
            "    \"\"\"",
            "",
            "    scheme_translation = {\"wss\": \"https\", \"ws\": \"http\"}",
            "",
            "    def patched_check_origin(self, origin):",
            "        def get_check_tuple(urlstring):",
            "            parsed = urlparse(urlstring)",
            "            scheme = scheme_translation.get(parsed.scheme, parsed.scheme)",
            "            return (",
            "                scheme,",
            "                parsed.hostname,",
            "                (",
            "                    parsed.port",
            "                    if parsed.port",
            "                    else 80",
            "                    if scheme == \"http\"",
            "                    else 443",
            "                    if scheme == \"https\"",
            "                    else None",
            "                ),",
            "            )",
            "",
            "        return get_check_tuple(origin) == get_check_tuple(self.request.full_url())",
            "",
            "    import tornado.websocket",
            "",
            "    tornado.websocket.WebSocketHandler.check_origin = patched_check_origin",
            "",
            "",
            "# ~~ More sensible logging",
            "",
            "",
            "class RequestlessExceptionLoggingMixin(tornado.web.RequestHandler):",
            "    LOG_REQUEST = False",
            "",
            "    def log_exception(self, typ, value, tb, *args, **kwargs):",
            "        if isinstance(value, tornado.web.HTTPError):",
            "            if value.log_message:",
            "                format = \"%d %s: \" + value.log_message",
            "                args = [value.status_code, self._request_summary()] + list(value.args)",
            "                tornado.web.gen_log.warning(format, *args)",
            "        else:",
            "            if self.LOG_REQUEST:",
            "                tornado.web.app_log.error(",
            "                    \"Uncaught exception %s\\n%r\",",
            "                    self._request_summary(),",
            "                    self.request,",
            "                    exc_info=(typ, value, tb),",
            "                )",
            "            else:",
            "                tornado.web.app_log.error(",
            "                    \"Uncaught exception %s\",",
            "                    self._request_summary(),",
            "                    exc_info=(typ, value, tb),",
            "                )",
            "",
            "",
            "# ~~ CORS support",
            "",
            "",
            "class CorsSupportMixin(tornado.web.RequestHandler):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ mixin that",
            "    makes sure to set CORS headers similarly to the Flask backed API endpoints.",
            "    \"\"\"",
            "",
            "    ENABLE_CORS = False",
            "",
            "    def set_default_headers(self):",
            "        origin = self.request.headers.get(\"Origin\")",
            "        if self.request.method != \"OPTIONS\" and origin and self.ENABLE_CORS:",
            "            self.set_header(\"Access-Control-Allow-Origin\", origin)",
            "",
            "    @tornado.gen.coroutine",
            "    def options(self, *args, **kwargs):",
            "        if self.ENABLE_CORS:",
            "            origin = self.request.headers.get(\"Origin\")",
            "            method = self.request.headers.get(\"Access-Control-Request-Method\")",
            "",
            "            # Allow the origin which made the XHR",
            "            self.set_header(\"Access-Control-Allow-Origin\", origin)",
            "            # Allow the actual method",
            "            self.set_header(\"Access-Control-Allow-Methods\", method)",
            "            # Allow for 10 seconds",
            "            self.set_header(\"Access-Control-Max-Age\", \"10\")",
            "",
            "            # 'preflight' request contains the non-standard headers the real request will have (like X-Api-Key)",
            "            custom_headers = self.request.headers.get(\"Access-Control-Request-Headers\")",
            "            if custom_headers is not None:",
            "                self.set_header(\"Access-Control-Allow-Headers\", custom_headers)",
            "",
            "        self.set_status(204)",
            "        self.finish()",
            "",
            "",
            "# ~~ WSGI middleware",
            "",
            "",
            "@tornado.web.stream_request_body",
            "class UploadStorageFallbackHandler(RequestlessExceptionLoggingMixin, CorsSupportMixin):",
            "    \"\"\"",
            "    A ``RequestHandler`` similar to ``tornado.web.FallbackHandler`` which fetches any files contained in the request bodies",
            "    of content type ``multipart``, stores them in temporary files and supplies the ``fallback`` with the file's ``name``,",
            "    ``content_type``, ``path`` and ``size`` instead via a rewritten body.",
            "",
            "    Basically similar to what the nginx upload module does.",
            "",
            "    Basic request body example:",
            "",
            "    .. code-block:: none",
            "",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file\"; filename=\"test.gcode\"",
            "        Content-Type: application/octet-stream",
            "",
            "        ...",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"apikey\"",
            "",
            "        my_funny_apikey",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"select\"",
            "",
            "        true",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C--",
            "",
            "    That would get turned into:",
            "",
            "    .. code-block:: none",
            "",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"apikey\"",
            "",
            "        my_funny_apikey",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"select\"",
            "",
            "        true",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.path\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        /tmp/tmpzupkro",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.name\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        test.gcode",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.content_type\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        application/octet-stream",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.size\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        349182",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C--",
            "",
            "    The underlying application can then access the contained files via their respective paths and just move them",
            "    where necessary.",
            "    \"\"\"",
            "",
            "    BODY_METHODS = (\"POST\", \"PATCH\", \"PUT\")",
            "    \"\"\" The request methods that may contain a request body. \"\"\"",
            "",
            "    def initialize(",
            "        self, fallback, file_prefix=\"tmp\", file_suffix=\"\", path=None, suffixes=None",
            "    ):",
            "        if not suffixes:",
            "            suffixes = {}",
            "",
            "        self._fallback = fallback",
            "        self._file_prefix = file_prefix",
            "        self._file_suffix = file_suffix",
            "        self._path = path",
            "",
            "        self._suffixes = {key: key for key in (\"name\", \"path\", \"content_type\", \"size\")}",
            "        for suffix_type, suffix in suffixes.items():",
            "            if suffix_type in self._suffixes and suffix is not None:",
            "                self._suffixes[suffix_type] = suffix",
            "",
            "        # multipart boundary",
            "        self._multipart_boundary = None",
            "",
            "        # Parts, files and values will be stored here",
            "        self._parts = {}",
            "        self._files = []",
            "",
            "        # Part currently being processed",
            "        self._current_part = None",
            "",
            "        # content type of request body",
            "        self._content_type = None",
            "",
            "        # bytes left to read according to content_length of request body",
            "        self._bytes_left = 0",
            "",
            "        # buffer needed for identifying form data parts",
            "        self._buffer = b\"\"",
            "",
            "        # buffer for new body",
            "        self._new_body = b\"\"",
            "",
            "        # logger",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "    def prepare(self):",
            "        \"\"\"",
            "        Prepares the processing of the request. If it's a request that may contain a request body (as defined in",
            "        :attr:`UploadStorageFallbackHandler.BODY_METHODS`) prepares the multipart parsing if content type fits. If it's a",
            "        body-less request, just calls the ``fallback`` with an empty body and finishes the request.",
            "        \"\"\"",
            "        if self.request.method in UploadStorageFallbackHandler.BODY_METHODS:",
            "            self._bytes_left = self.request.headers.get(\"Content-Length\", 0)",
            "            self._content_type = self.request.headers.get(\"Content-Type\", None)",
            "",
            "            # request might contain a body",
            "            if self.is_multipart():",
            "                if not self._bytes_left:",
            "                    # we don't support requests without a content-length",
            "                    raise tornado.web.HTTPError(",
            "                        411, log_message=\"No Content-Length supplied\"",
            "                    )",
            "",
            "                # extract the multipart boundary",
            "                fields = self._content_type.split(\";\")",
            "                for field in fields:",
            "                    k, sep, v = field.strip().partition(\"=\")",
            "                    if k == \"boundary\" and v:",
            "                        if v.startswith('\"') and v.endswith('\"'):",
            "                            self._multipart_boundary = tornado.escape.utf8(v[1:-1])",
            "                        else:",
            "                            self._multipart_boundary = tornado.escape.utf8(v)",
            "                        break",
            "                else:",
            "                    # RFC2046 section 5.1 (as referred to from RFC 7578) defines the boundary",
            "                    # parameter as mandatory for multipart requests:",
            "                    #",
            "                    #     The only mandatory global parameter for the \"multipart\" media type is",
            "                    #     the boundary parameter, which consists of 1 to 70 characters [...]",
            "                    #",
            "                    # So no boundary? 400 Bad Request",
            "                    raise tornado.web.HTTPError(",
            "                        400, log_message=\"No multipart boundary supplied\"",
            "                    )",
            "        else:",
            "            self._fallback(self.request, b\"\")",
            "            self._finished = True",
            "            self.on_finish()",
            "",
            "    def data_received(self, chunk):",
            "        \"\"\"",
            "        Called by Tornado on receiving a chunk of the request body. If request is a multipart request, takes care of",
            "        processing the multipart data structure via :func:`_process_multipart_data`. If not, just adds the chunk to",
            "        internal in-memory buffer.",
            "",
            "        :param chunk: chunk of data received from Tornado",
            "        \"\"\"",
            "",
            "        data = self._buffer + chunk",
            "        if self.is_multipart():",
            "            self._process_multipart_data(data)",
            "        else:",
            "            self._buffer = data",
            "",
            "    def is_multipart(self):",
            "        \"\"\"Checks whether this request is a ``multipart`` request\"\"\"",
            "        return self._content_type is not None and self._content_type.startswith(",
            "            \"multipart\"",
            "        )",
            "",
            "    def _process_multipart_data(self, data):",
            "        \"\"\"",
            "        Processes the given data, parsing it for multipart definitions and calling the appropriate methods.",
            "",
            "        :param data: the data to process as a string",
            "        \"\"\"",
            "",
            "        # check for boundary",
            "        delimiter = b\"--%s\" % self._multipart_boundary",
            "        delimiter_loc = data.find(delimiter)",
            "        delimiter_len = len(delimiter)",
            "        end_of_header = -1",
            "        if delimiter_loc != -1:",
            "            # found the delimiter in the currently available data",
            "            delimiter_data_end = 0 if delimiter_loc == 0 else delimiter_loc - 2",
            "            data, self._buffer = data[0:delimiter_data_end], data[delimiter_loc:]",
            "            end_of_header = self._buffer.find(b\"\\r\\n\\r\\n\")",
            "        else:",
            "            # make sure any boundary (with single or double ==) contained at the end of chunk does not get",
            "            # truncated by this processing round => save it to the buffer for next round",
            "            endlen = len(self._multipart_boundary) + 4",
            "            data, self._buffer = data[0:-endlen], data[-endlen:]",
            "",
            "        # stream data to part handler",
            "        if data and self._current_part:",
            "            self._on_part_data(self._current_part, data)",
            "",
            "        if end_of_header >= 0:",
            "            self._on_part_header(self._buffer[delimiter_len + 2 : end_of_header])",
            "            self._buffer = self._buffer[end_of_header + 4 :]",
            "",
            "        if delimiter_loc != -1 and self._buffer.strip() == delimiter + b\"--\":",
            "            # we saw the last boundary and are at the end of our request",
            "            if self._current_part:",
            "                self._on_part_finish(self._current_part)",
            "                self._current_part = None",
            "            self._buffer = b\"\"",
            "            self._on_request_body_finish()",
            "",
            "    def _on_part_header(self, header):",
            "        \"\"\"",
            "        Called for a new multipart header, takes care of parsing the header and calling :func:`_on_part` with the",
            "        relevant data, setting the current part in the process.",
            "",
            "        :param header: header to parse",
            "        \"\"\"",
            "",
            "        # close any open parts",
            "        if self._current_part:",
            "            self._on_part_finish(self._current_part)",
            "            self._current_part = None",
            "",
            "        header_check = header.find(self._multipart_boundary)",
            "        if header_check != -1:",
            "            self._logger.warning(",
            "                \"Header still contained multipart boundary, stripping it...\"",
            "            )",
            "            header = header[header_check:]",
            "",
            "        # convert to dict",
            "        try:",
            "            header = tornado.httputil.HTTPHeaders.parse(header.decode(\"utf-8\"))",
            "        except UnicodeDecodeError:",
            "            try:",
            "                header = tornado.httputil.HTTPHeaders.parse(header.decode(\"iso-8859-1\"))",
            "            except Exception:",
            "                # looks like we couldn't decode something here neither as UTF-8 nor ISO-8859-1",
            "                self._logger.warning(",
            "                    \"Could not decode multipart headers in request, should be either UTF-8 or ISO-8859-1\"",
            "                )",
            "                self.send_error(400)",
            "                return",
            "",
            "        disp_header = header.get(\"Content-Disposition\", \"\")",
            "        disposition, disp_params = _parse_header(disp_header, strip_quotes=False)",
            "",
            "        if disposition != \"form-data\":",
            "            self._logger.warning(",
            "                \"Got a multipart header without form-data content disposition, ignoring that one\"",
            "            )",
            "            return",
            "        if not disp_params.get(\"name\"):",
            "            self._logger.warning(\"Got a multipart header without name, ignoring that one\")",
            "            return",
            "",
            "        filename = disp_params.get(\"filename*\", None)  # RFC 5987 header present?",
            "        if filename is not None:",
            "            try:",
            "                filename = _extended_header_value(filename)",
            "            except Exception:",
            "                # parse error, this is not RFC 5987 compliant after all",
            "                self._logger.warning(",
            "                    \"extended filename* value {!r} is not RFC 5987 compliant\".format(",
            "                        filename",
            "                    )",
            "                )",
            "                self.send_error(400)",
            "                return",
            "        else:",
            "            # no filename* header, just strip quotes from filename header then and be done",
            "            filename = _strip_value_quotes(disp_params.get(\"filename\", None))",
            "",
            "        self._current_part = self._on_part_start(",
            "            _strip_value_quotes(disp_params[\"name\"]),",
            "            header.get(\"Content-Type\", None),",
            "            filename=filename,",
            "        )",
            "",
            "    def _on_part_start(self, name, content_type, filename=None):",
            "        \"\"\"",
            "        Called for new parts in the multipart stream. If ``filename`` is given creates new ``file`` part (which leads",
            "        to storage of the data as temporary file on disk), if not creates a new ``data`` part (which stores",
            "        incoming data in memory).",
            "",
            "        Structure of ``file`` parts:",
            "",
            "        * ``name``: name of the part",
            "        * ``filename``: filename associated with the part",
            "        * ``path``: path to the temporary file storing the file's data",
            "        * ``content_type``: content type of the part",
            "        * ``file``: file handle for the temporary file (mode \"wb\", not deleted on close, will be deleted however after",
            "          handling of the request has finished in :func:`_handle_method`)",
            "",
            "        Structure of ``data`` parts:",
            "",
            "        * ``name``: name of the part",
            "        * ``content_type``: content type of the part",
            "        * ``data``: bytes of the part (initialized to an empty string)",
            "",
            "        :param name: name of the part",
            "        :param content_type: content type of the part",
            "        :param filename: filename associated with the part.",
            "        :return: dict describing the new part",
            "        \"\"\"",
            "        if filename is not None:",
            "            # this is a file",
            "            import tempfile",
            "",
            "            handle = tempfile.NamedTemporaryFile(",
            "                mode=\"wb\",",
            "                prefix=self._file_prefix,",
            "                suffix=self._file_suffix,",
            "                dir=self._path,",
            "                delete=False,",
            "            )",
            "            return {",
            "                \"name\": tornado.escape.utf8(name),",
            "                \"filename\": tornado.escape.utf8(filename),",
            "                \"path\": tornado.escape.utf8(handle.name),",
            "                \"content_type\": tornado.escape.utf8(content_type),",
            "                \"file\": handle,",
            "            }",
            "",
            "        else:",
            "            return {",
            "                \"name\": tornado.escape.utf8(name),",
            "                \"content_type\": tornado.escape.utf8(content_type),",
            "                \"data\": b\"\",",
            "            }",
            "",
            "    def _on_part_data(self, part, data):",
            "        \"\"\"",
            "        Called when new bytes are received for the given ``part``, takes care of writing them to their storage.",
            "",
            "        :param part: part for which data was received",
            "        :param data: data chunk which was received",
            "        \"\"\"",
            "        if \"file\" in part:",
            "            part[\"file\"].write(data)",
            "        else:",
            "            part[\"data\"] += data",
            "",
            "    def _on_part_finish(self, part):",
            "        \"\"\"",
            "        Called when a part gets closed, takes care of storing the finished part in the internal parts storage and for",
            "        ``file`` parts closing the temporary file and storing the part in the internal files storage.",
            "",
            "        :param part: part which was closed",
            "        \"\"\"",
            "        name = part[\"name\"]",
            "        self._parts[name] = part",
            "        if \"file\" in part:",
            "            self._files.append(part[\"path\"])",
            "            part[\"file\"].close()",
            "            del part[\"file\"]",
            "",
            "    def _on_request_body_finish(self):",
            "        \"\"\"",
            "        Called when the request body has been read completely. Takes care of creating the replacement body out of the",
            "        logged parts, turning ``file`` parts into new ``data`` parts.",
            "        \"\"\"",
            "",
            "        self._new_body = b\"\"",
            "        for name, part in self._parts.items():",
            "            if \"filename\" in part:",
            "                # add form fields for filename, path, size and content_type for all files contained in the request",
            "                if \"path\" not in part:",
            "                    continue",
            "",
            "                parameters = {",
            "                    \"name\": part[\"filename\"],",
            "                    \"path\": part[\"path\"],",
            "                    \"size\": str(os.stat(part[\"path\"]).st_size),",
            "                }",
            "                if \"content_type\" in part:",
            "                    parameters[\"content_type\"] = part[\"content_type\"]",
            "",
            "                fields = {",
            "                    self._suffixes[key]: value for (key, value) in parameters.items()",
            "                }",
            "                for n, p in fields.items():",
            "                    if n is None or p is None:",
            "                        continue",
            "                    key = name + b\".\" + octoprint.util.to_bytes(n)",
            "                    self._new_body += b\"--%s\\r\\n\" % self._multipart_boundary",
            "                    self._new_body += (",
            "                        b'Content-Disposition: form-data; name=\"%s\"\\r\\n' % key",
            "                    )",
            "                    self._new_body += b\"Content-Type: text/plain; charset=utf-8\\r\\n\"",
            "                    self._new_body += b\"\\r\\n\"",
            "                    self._new_body += octoprint.util.to_bytes(p) + b\"\\r\\n\"",
            "            elif \"data\" in part:",
            "                self._new_body += b\"--%s\\r\\n\" % self._multipart_boundary",
            "                value = part[\"data\"]",
            "                self._new_body += b'Content-Disposition: form-data; name=\"%s\"\\r\\n' % name",
            "                if \"content_type\" in part and part[\"content_type\"] is not None:",
            "                    self._new_body += b\"Content-Type: %s\\r\\n\" % part[\"content_type\"]",
            "                self._new_body += b\"\\r\\n\"",
            "                self._new_body += value + b\"\\r\\n\"",
            "        self._new_body += b\"--%s--\\r\\n\" % self._multipart_boundary",
            "",
            "    async def _handle_method(self, *args, **kwargs):",
            "        \"\"\"",
            "        Takes care of defining the new request body if necessary and forwarding",
            "        the current request and changed body to the ``fallback``.",
            "        \"\"\"",
            "",
            "        # determine which body to supply",
            "        body = b\"\"",
            "        if self.is_multipart():",
            "            # make sure we really processed all data in the buffer",
            "            while len(self._buffer):",
            "                self._process_multipart_data(self._buffer)",
            "",
            "            # use rewritten body",
            "            body = self._new_body",
            "",
            "        elif self.request.method in UploadStorageFallbackHandler.BODY_METHODS:",
            "            # directly use data from buffer",
            "            body = self._buffer",
            "",
            "        self.request.headers[\"Content-Length\"] = len(body)",
            "",
            "        try:",
            "            # call the configured fallback with request and body to use",
            "            result = self._fallback(self.request, body)",
            "            if result is not None:",
            "                await result",
            "        finally:",
            "            self._finished = True",
            "            self.on_finish()",
            "",
            "    def on_finish(self):",
            "        self._cleanup_files()",
            "",
            "    def _cleanup_files(self):",
            "        \"\"\"",
            "        Removes all temporary files created by this handler.",
            "        \"\"\"",
            "        for f in self._files:",
            "            octoprint.util.silent_remove(f)",
            "",
            "    # make all http methods trigger _handle_method",
            "    get = _handle_method",
            "    post = _handle_method",
            "    put = _handle_method",
            "    patch = _handle_method",
            "    delete = _handle_method",
            "    head = _handle_method",
            "    options = _handle_method",
            "",
            "",
            "def _parse_header(line, strip_quotes=True):",
            "    parts = tornado.httputil._parseparam(\";\" + line)",
            "    key = next(parts)",
            "    pdict = {}",
            "    for p in parts:",
            "        i = p.find(\"=\")",
            "        if i >= 0:",
            "            name = p[:i].strip().lower()",
            "            value = p[i + 1 :].strip()",
            "            if strip_quotes:",
            "                value = _strip_value_quotes(value)",
            "            pdict[name] = value",
            "    return key, pdict",
            "",
            "",
            "def _strip_value_quotes(value):",
            "    if not value:",
            "        return value",
            "",
            "    if len(value) >= 2 and value[0] == value[-1] == '\"':",
            "        value = value[1:-1]",
            "        value = value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')",
            "",
            "    return value",
            "",
            "",
            "def _extended_header_value(value):",
            "    if not value:",
            "        return value",
            "",
            "    if value.lower().startswith(\"iso-8859-1'\") or value.lower().startswith(\"utf-8'\"):",
            "        # RFC 5987 section 3.2",
            "        from urllib.parse import unquote",
            "",
            "        encoding, _, value = value.split(\"'\", 2)",
            "        return unquote(value, encoding=encoding)",
            "    else:",
            "        # no encoding provided, strip potentially present quotes and call it a day",
            "        return octoprint.util.to_unicode(_strip_value_quotes(value), encoding=\"utf-8\")",
            "",
            "",
            "class WsgiInputContainer:",
            "    \"\"\"",
            "    A WSGI container for use with Tornado that allows supplying the request body to be used for ``wsgi.input`` in the",
            "    generated WSGI environment upon call.",
            "",
            "    A ``RequestHandler`` can thus provide the WSGI application with a stream for the request body, or a modified body.",
            "",
            "    Example usage:",
            "",
            "    .. code-block:: python",
            "",
            "       wsgi_app = octoprint.server.util.WsgiInputContainer(octoprint_app)",
            "       application = tornado.web.Application([",
            "           (r\".*\", UploadStorageFallbackHandler, dict(fallback=wsgi_app),",
            "       ])",
            "",
            "    The implementation logic is basically the same as ``tornado.wsgi.WSGIContainer`` but the ``__call__`` and ``environ``",
            "    methods have been adjusted to allow for an optionally supplied ``body`` argument which is then used for ``wsgi.input``.",
            "",
            "    Additionally, some headers can be added or removed from the response by supplying ``forced_headers`` and",
            "    ``removed_headers`` arguments. ``forced_headers`` will be added to the response, ``removed_headers`` will be removed.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        wsgi_application,",
            "        executor=None,",
            "        headers=None,",
            "        forced_headers=None,",
            "        removed_headers=None,",
            "    ):",
            "        self.wsgi_application = wsgi_application",
            "        self.executor = dummy_executor if executor is None else executor",
            "",
            "        if headers is None:",
            "            headers = {}",
            "        if forced_headers is None:",
            "            forced_headers = {}",
            "        if removed_headers is None:",
            "            removed_headers = []",
            "",
            "        self.headers = headers",
            "        self.forced_headers = forced_headers",
            "        self.removed_headers = removed_headers",
            "",
            "    def __call__(self, request, body=None):",
            "        future = tornado.concurrent.Future()",
            "        IOLoop.current().spawn_callback(",
            "            self.handle_request, request, body=body, future=future",
            "        )",
            "        return future",
            "",
            "    async def handle_request(self, request, body=None, future=None):",
            "        \"\"\"",
            "        Wraps the call against the WSGI app, deriving the WSGI environment from the supplied Tornado ``HTTPServerRequest``.",
            "",
            "        :param request: the ``tornado.httpserver.HTTPServerRequest`` to derive the WSGI environment from",
            "        :param body: an optional body  to use as ``wsgi.input`` instead of ``request.body``, can be a string or a stream",
            "        :param future: a future to complete after the request has been handled",
            "        \"\"\"",
            "",
            "        data = {}",
            "        response = []",
            "",
            "        def start_response(status, response_headers, exc_info=None):",
            "            data[\"status\"] = status",
            "            data[\"headers\"] = response_headers",
            "            return response.append",
            "",
            "        try:",
            "            loop = IOLoop.current()",
            "            app_response = await loop.run_in_executor(",
            "                self.executor,",
            "                self.wsgi_application,",
            "                self.environ(request, body),",
            "                start_response,",
            "            )",
            "            try:",
            "                app_response_iter = iter(app_response)",
            "",
            "                def next_chunk():",
            "                    try:",
            "                        return next(app_response_iter)",
            "                    except StopIteration:",
            "                        return None",
            "",
            "                while True:",
            "                    chunk = await loop.run_in_executor(self.executor, next_chunk)",
            "                    if chunk is None:",
            "                        break",
            "                    response.append(chunk)",
            "            finally:",
            "                if hasattr(app_response, \"close\"):",
            "                    app_response.close()",
            "            body = b\"\".join(response)",
            "            if not data:",
            "                raise Exception(\"WSGI app did not call start_response\")",
            "",
            "            status_code_str, reason = data[\"status\"].split(\" \", 1)",
            "            status_code = int(status_code_str)",
            "            headers = data[\"headers\"]",
            "            header_set = {k.lower() for (k, v) in headers}",
            "            body = tornado.escape.utf8(body)",
            "            if status_code != 304:",
            "                if \"content-length\" not in header_set:",
            "                    headers.append((\"Content-Length\", str(len(body))))",
            "                if \"content-type\" not in header_set:",
            "                    headers.append((\"Content-Type\", \"text/html; charset=UTF-8\"))",
            "",
            "            header_set = {k.lower() for (k, v) in headers}",
            "            for header, value in self.headers.items():",
            "                if header.lower() not in header_set:",
            "                    headers.append((header, value))",
            "            for header, value in self.forced_headers.items():",
            "                headers.append((header, value))",
            "            headers = [",
            "                (header, value)",
            "                for header, value in headers",
            "                if header.lower() not in self.removed_headers",
            "            ]",
            "",
            "            start_line = tornado.httputil.ResponseStartLine(",
            "                \"HTTP/1.1\", status_code, reason",
            "            )",
            "            header_obj = tornado.httputil.HTTPHeaders()",
            "            for key, value in headers:",
            "                header_obj.add(key, value)",
            "            assert request.connection is not None",
            "            request.connection.write_headers(start_line, header_obj, chunk=body)",
            "            request.connection.finish()",
            "            self._log(status_code, request)",
            "",
            "        finally:",
            "            if future is not None:",
            "                future.set_result(None)",
            "",
            "    @staticmethod",
            "    def environ(request, body=None):",
            "        \"\"\"",
            "        Converts a ``tornado.httputil.HTTPServerRequest`` to a WSGI environment.",
            "",
            "        An optional ``body`` to be used for populating ``wsgi.input`` can be supplied (either a string or a stream). If not",
            "        supplied, ``request.body`` will be wrapped into a ``io.BytesIO`` stream and used instead.",
            "",
            "        :param request: the ``tornado.httpserver.HTTPServerRequest`` to derive the WSGI environment from",
            "        :param body: an optional body  to use as ``wsgi.input`` instead of ``request.body``, can be a string or a stream",
            "        \"\"\"",
            "        import io",
            "",
            "        from tornado.wsgi import to_wsgi_str",
            "",
            "        # determine the request_body to supply as wsgi.input",
            "        if body is not None:",
            "            if isinstance(body, (bytes, str)):",
            "                request_body = io.BytesIO(tornado.escape.utf8(body))",
            "            else:",
            "                request_body = body",
            "        else:",
            "            request_body = io.BytesIO(tornado.escape.utf8(request.body))",
            "",
            "        hostport = request.host.split(\":\")",
            "        if len(hostport) == 2:",
            "            host = hostport[0]",
            "            port = int(hostport[1])",
            "        else:",
            "            host = request.host",
            "            port = 443 if request.protocol == \"https\" else 80",
            "        environ = {",
            "            \"REQUEST_METHOD\": request.method,",
            "            \"SCRIPT_NAME\": \"\",",
            "            \"PATH_INFO\": to_wsgi_str(",
            "                tornado.escape.url_unescape(request.path, encoding=None, plus=False)",
            "            ),",
            "            \"QUERY_STRING\": request.query,",
            "            \"REMOTE_ADDR\": request.remote_ip,",
            "            \"SERVER_NAME\": host,",
            "            \"SERVER_PORT\": str(port),",
            "            \"SERVER_PROTOCOL\": request.version,",
            "            \"wsgi.version\": (1, 0),",
            "            \"wsgi.url_scheme\": request.protocol,",
            "            \"wsgi.input\": request_body,",
            "            \"wsgi.errors\": sys.stderr,",
            "            \"wsgi.multithread\": False,",
            "            \"wsgi.multiprocess\": True,",
            "            \"wsgi.run_once\": False,",
            "        }",
            "        if \"Content-Type\" in request.headers:",
            "            environ[\"CONTENT_TYPE\"] = request.headers.pop(\"Content-Type\")",
            "        if \"Content-Length\" in request.headers:",
            "            environ[\"CONTENT_LENGTH\"] = request.headers.pop(\"Content-Length\")",
            "",
            "        # remove transfer encoding header if chunked, otherwise flask wsgi entrypoint makes input empty",
            "        if (",
            "            \"Transfer-Encoding\" in request.headers",
            "            and request.headers.get(\"Transfer-Encoding\") == \"chunked\"",
            "        ):",
            "            request.headers.pop(\"Transfer-Encoding\")",
            "",
            "        for key, value in request.headers.items():",
            "            environ[\"HTTP_\" + key.replace(\"-\", \"_\").upper()] = value",
            "        return environ",
            "",
            "    def _log(self, status_code, request):",
            "        access_log = logging.getLogger(\"tornado.access\")",
            "",
            "        if status_code < 400:",
            "            log_method = access_log.info",
            "        elif status_code < 500:",
            "            log_method = access_log.warning",
            "        else:",
            "            log_method = access_log.error",
            "        request_time = 1000 * request.request_time()",
            "        summary = request.method + \" \" + request.uri + \" (\" + request.remote_ip + \")\"",
            "        log_method(\"%d %s %.2fms\", status_code, summary, request_time)",
            "",
            "",
            "# ~~ customized HTTP1Connection implementation",
            "",
            "",
            "class CustomHTTPServer(tornado.httpserver.HTTPServer):",
            "    \"\"\"",
            "    Custom implementation of ``tornado.httpserver.HTTPServer`` that allows defining max body sizes depending on path and",
            "    method.",
            "",
            "    The implementation is mostly taken from ``tornado.httpserver.HTTPServer``, the only difference is the creation",
            "    of a ``CustomHTTP1ConnectionParameters`` instance instead of ``tornado.http1connection.HTTP1ConnectionParameters``",
            "    which is supplied with the two new constructor arguments ``max_body_sizes`` and ``max_default_body_size`` and the",
            "    creation of a ``CustomHTTP1ServerConnection`` instead of a ``tornado.http1connection.HTTP1ServerConnection`` upon",
            "    connection by a client.",
            "",
            "    ``max_body_sizes`` is expected to be an iterable containing tuples of the form (method, path regex, maximum body size),",
            "    with method and path regex having to match in order for maximum body size to take affect.",
            "",
            "    ``default_max_body_size`` is the default maximum body size to apply if no specific one from ``max_body_sizes`` matches.",
            "    \"\"\"",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        pass",
            "",
            "    def initialize(self, *args, **kwargs):",
            "        default_max_body_size = kwargs.pop(\"default_max_body_size\", None)",
            "        max_body_sizes = kwargs.pop(\"max_body_sizes\", None)",
            "",
            "        tornado.httpserver.HTTPServer.initialize(self, *args, **kwargs)",
            "",
            "        additional = {",
            "            \"default_max_body_size\": default_max_body_size,",
            "            \"max_body_sizes\": max_body_sizes,",
            "        }",
            "        self.conn_params = CustomHTTP1ConnectionParameters.from_stock_params(",
            "            self.conn_params, **additional",
            "        )",
            "",
            "    def handle_stream(self, stream, address):",
            "        context = tornado.httpserver._HTTPRequestContext(",
            "            stream, address, self.protocol, self.trusted_downstream",
            "        )",
            "        conn = CustomHTTP1ServerConnection(stream, self.conn_params, context)",
            "        self._connections.add(conn)",
            "        conn.start_serving(self)",
            "",
            "",
            "class CustomHTTP1ServerConnection(tornado.http1connection.HTTP1ServerConnection):",
            "    \"\"\"",
            "    A custom implementation of ``tornado.http1connection.HTTP1ServerConnection`` which utilizes a ``CustomHTTP1Connection``",
            "    instead of a ``tornado.http1connection.HTTP1Connection`` in ``_server_request_loop``. The implementation logic is",
            "    otherwise the same as ``tornado.http1connection.HTTP1ServerConnection``.",
            "    \"\"\"",
            "",
            "    async def _server_request_loop(self, delegate):",
            "        try:",
            "            while True:",
            "                conn = CustomHTTP1Connection(",
            "                    self.stream, False, self.params, self.context",
            "                )",
            "                request_delegate = delegate.start_request(self, conn)",
            "                try:",
            "                    ret = await conn.read_response(request_delegate)",
            "                except (",
            "                    tornado.iostream.StreamClosedError,",
            "                    tornado.iostream.UnsatisfiableReadError,",
            "                    asyncio.CancelledError,",
            "                ):",
            "                    return",
            "                except tornado.http1connection._QuietException:",
            "                    # This exception was already logged.",
            "                    conn.close()",
            "                    return",
            "                except Exception:",
            "                    tornado.http1connection.gen_log.error(",
            "                        \"Uncaught exception\", exc_info=True",
            "                    )",
            "                    conn.close()",
            "                    return",
            "                if not ret:",
            "                    return",
            "                await asyncio.sleep(0)",
            "        finally:",
            "            delegate.on_close(self)",
            "",
            "",
            "class CustomHTTP1Connection(tornado.http1connection.HTTP1Connection):",
            "    \"\"\"",
            "    A custom implementation of ``tornado.http1connection.HTTP1Connection`` which upon checking the ``Content-Length`` of",
            "    the request against the configured maximum utilizes ``max_body_sizes`` and ``default_max_body_size`` as a fallback.",
            "    \"\"\"",
            "",
            "    def __init__(self, stream, is_client, params=None, context=None):",
            "        if params is None:",
            "            params = CustomHTTP1ConnectionParameters()",
            "",
            "        tornado.http1connection.HTTP1Connection.__init__(",
            "            self, stream, is_client, params=params, context=context",
            "        )",
            "",
            "        import re",
            "",
            "        self._max_body_sizes = list(",
            "            map(",
            "                lambda x: (x[0], re.compile(x[1]), x[2]),",
            "                self.params.max_body_sizes or [],",
            "            )",
            "        )",
            "        self._default_max_body_size = (",
            "            self.params.default_max_body_size or self.stream.max_buffer_size",
            "        )",
            "",
            "    def _read_body(self, code, headers, delegate):",
            "        \"\"\"",
            "        Basically the same as ``tornado.http1connection.HTTP1Connection._read_body``, but determines the maximum",
            "        content length individually for the request (utilizing ``._get_max_content_length``).",
            "",
            "        If the individual max content length is 0 or smaller no content length is checked. If the content length of the",
            "        current request exceeds the individual max content length, the request processing is aborted and an",
            "        ``HTTPInputError`` is raised.",
            "        \"\"\"",
            "        if \"Content-Length\" in headers:",
            "            if \"Transfer-Encoding\" in headers:",
            "                # Response cannot contain both Content-Length and",
            "                # Transfer-Encoding headers.",
            "                # http://tools.ietf.org/html/rfc7230#section-3.3.3",
            "                raise tornado.httputil.HTTPInputError(",
            "                    \"Response with both Transfer-Encoding and Content-Length\"",
            "                )",
            "            if \",\" in headers[\"Content-Length\"]:",
            "                # Proxies sometimes cause Content-Length headers to get",
            "                # duplicated.  If all the values are identical then we can",
            "                # use them but if they differ it's an error.",
            "                pieces = re.split(r\",\\s*\", headers[\"Content-Length\"])",
            "                if any(i != pieces[0] for i in pieces):",
            "                    raise tornado.httputil.HTTPInputError(",
            "                        \"Multiple unequal Content-Lengths: %r\" % headers[\"Content-Length\"]",
            "                    )",
            "                headers[\"Content-Length\"] = pieces[0]",
            "",
            "            try:",
            "                content_length = int(headers[\"Content-Length\"])",
            "            except ValueError:",
            "                # Handles non-integer Content-Length value.",
            "                raise tornado.httputil.HTTPInputError(",
            "                    \"Only integer Content-Length is allowed: %s\"",
            "                    % headers[\"Content-Length\"]",
            "                )",
            "",
            "            max_content_length = self._get_max_content_length(",
            "                self._request_start_line.method, self._request_start_line.path",
            "            )",
            "            if (",
            "                max_content_length is not None",
            "                and 0 <= max_content_length < content_length",
            "            ):",
            "                raise tornado.httputil.HTTPInputError(\"Content-Length too long\")",
            "        else:",
            "            content_length = None",
            "",
            "        if code == 204:",
            "            # This response code is not allowed to have a non-empty body,",
            "            # and has an implicit length of zero instead of read-until-close.",
            "            # http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.3",
            "            if \"Transfer-Encoding\" in headers or content_length not in (None, 0):",
            "                raise tornado.httputil.HTTPInputError(",
            "                    \"Response with code %d should not have body\" % code",
            "                )",
            "            content_length = 0",
            "",
            "        if content_length is not None:",
            "            return self._read_fixed_body(content_length, delegate)",
            "        if headers.get(\"Transfer-Encoding\") == \"chunked\":",
            "            return self._read_chunked_body(delegate)",
            "        if self.is_client:",
            "            return self._read_body_until_close(delegate)",
            "        return None",
            "",
            "    def _get_max_content_length(self, method, path):",
            "        \"\"\"",
            "        Gets the max content length for the given method and path. Checks whether method and path match against any",
            "        of the specific maximum content lengths supplied in ``max_body_sizes`` and returns that as the maximum content",
            "        length if available, otherwise returns ``default_max_body_size``.",
            "",
            "        :param method: method of the request to match against",
            "        :param path: path of the request to match against",
            "        :return: determine maximum content length to apply to this request, max return 0 for unlimited allowed content",
            "                 length",
            "        \"\"\"",
            "",
            "        for m, p, s in self._max_body_sizes:",
            "            if method == m and p.match(path):",
            "                return s",
            "        return self._default_max_body_size",
            "",
            "",
            "class CustomHTTP1ConnectionParameters(tornado.http1connection.HTTP1ConnectionParameters):",
            "    \"\"\"",
            "    An implementation of ``tornado.http1connection.HTTP1ConnectionParameters`` that adds two new parameters",
            "    ``max_body_sizes`` and ``default_max_body_size``.",
            "",
            "    For a description of these please see the documentation of ``CustomHTTPServer`` above.",
            "    \"\"\"",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        max_body_sizes = kwargs.pop(\"max_body_sizes\", list())",
            "        default_max_body_size = kwargs.pop(\"default_max_body_size\", None)",
            "",
            "        tornado.http1connection.HTTP1ConnectionParameters.__init__(self, *args, **kwargs)",
            "",
            "        self.max_body_sizes = max_body_sizes",
            "        self.default_max_body_size = default_max_body_size",
            "",
            "    @classmethod",
            "    def from_stock_params(cls, other, **additional):",
            "        kwargs = dict(other.__dict__)",
            "        for key, value in additional.items():",
            "            kwargs[key] = value",
            "        return cls(**kwargs)",
            "",
            "",
            "# ~~ customized large response handler",
            "",
            "",
            "class LargeResponseHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.StaticFileHandler",
            "):",
            "    \"\"\"",
            "    Customized `tornado.web.StaticFileHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#tornado.web.StaticFileHandler>`_",
            "    that allows delivery of the requested resource as attachment and access and request path validation through",
            "    optional callbacks. Note that access validation takes place before path validation.",
            "",
            "    Arguments:",
            "       path (str): The system path from which to serve files (this will be forwarded to the ``initialize`` method of",
            "           :class:``~tornado.web.StaticFileHandler``)",
            "       default_filename (str): The default filename to serve if none is explicitly specified and the request references",
            "           a subdirectory of the served path (this will be forwarded to the ``initialize`` method of",
            "           :class:``~tornado.web.StaticFileHandler`` as the ``default_filename`` keyword parameter). Defaults to ``None``.",
            "       as_attachment (bool): Whether to serve requested files with ``Content-Disposition: attachment`` header (``True``)",
            "           or not. Defaults to ``False``.",
            "       allow_client_caching (bool): Whether to allow the client to cache (by not setting any ``Cache-Control`` or",
            "           ``Expires`` headers on the response) or not.",
            "       access_validation (function): Callback to call in the ``get`` method to validate access to the resource. Will",
            "           be called with ``self.request`` as parameter which contains the full tornado request object. Should raise",
            "           a ``tornado.web.HTTPError`` if access is not allowed in which case the request will not be further processed.",
            "           Defaults to ``None`` and hence no access validation being performed.",
            "       path_validation (function): Callback to call in the ``get`` method to validate the requested path. Will be called",
            "           with the requested path as parameter. Should raise a ``tornado.web.HTTPError`` (e.g. an 404) if the requested",
            "           path does not pass validation in which case the request will not be further processed.",
            "           Defaults to ``None`` and hence no path validation being performed.",
            "       etag_generator (function): Callback to call for generating the value of the ETag response header. Will be",
            "           called with the response handler as parameter. May return ``None`` to prevent the ETag response header",
            "           from being set. If not provided the last modified time of the file in question will be used as returned",
            "           by ``get_content_version``.",
            "       name_generator (function): Callback to call for generating the value of the attachment file name header. Will be",
            "           called with the requested path as parameter.",
            "       mime_type_guesser (function): Callback to guess the mime type to use for the content type encoding of the",
            "           response. Will be called with the requested path on disk as parameter.",
            "       is_pre_compressed (bool): if the file is expected to be pre-compressed, i.e, if there is a file in the same",
            "           directory with the same name, but with '.gz' appended and gzip-encoded",
            "    \"\"\"",
            "",
            "    def initialize(",
            "        self,",
            "        path,",
            "        default_filename=None,",
            "        as_attachment=False,",
            "        allow_client_caching=True,",
            "        access_validation=None,",
            "        path_validation=None,",
            "        etag_generator=None,",
            "        name_generator=None,",
            "        mime_type_guesser=None,",
            "        is_pre_compressed=False,",
            "        stream_body=False,",
            "    ):",
            "        tornado.web.StaticFileHandler.initialize(",
            "            self, os.path.abspath(path), default_filename",
            "        )",
            "        self._as_attachment = as_attachment",
            "        self._allow_client_caching = allow_client_caching",
            "        self._access_validation = access_validation",
            "        self._path_validation = path_validation",
            "        self._etag_generator = etag_generator",
            "        self._name_generator = name_generator",
            "        self._mime_type_guesser = mime_type_guesser",
            "        self._is_pre_compressed = is_pre_compressed",
            "        self._stream_body = stream_body",
            "",
            "    def should_use_precompressed(self):",
            "        return self._is_pre_compressed and \"gzip\" in self.request.headers.get(",
            "            \"Accept-Encoding\", \"\"",
            "        )",
            "",
            "    def get(self, path, include_body=True):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "        if self._path_validation is not None:",
            "            self._path_validation(path)",
            "",
            "        if \"cookie\" in self.request.arguments:",
            "            self.set_cookie(self.request.arguments[\"cookie\"][0], \"true\", path=\"/\")",
            "",
            "        if self.should_use_precompressed():",
            "            if os.path.exists(os.path.join(self.root, path + \".gz\")):",
            "                self.set_header(\"Content-Encoding\", \"gzip\")",
            "                path = path + \".gz\"",
            "            else:",
            "                logging.getLogger(__name__).warning(",
            "                    \"Precompressed assets expected but {}.gz does not exist \"",
            "                    \"in {}, using plain file instead.\".format(path, self.root)",
            "                )",
            "",
            "        if self._stream_body:",
            "            return self.streamed_get(path, include_body=include_body)",
            "        else:",
            "            return tornado.web.StaticFileHandler.get(",
            "                self, path, include_body=include_body",
            "            )",
            "",
            "    @tornado.gen.coroutine",
            "    def streamed_get(self, path, include_body=True):",
            "        \"\"\"",
            "        Version of StaticFileHandler.get that doesn't support ranges or ETag but streams the content. Helpful for files",
            "        that might still change while being transmitted (e.g. log files)",
            "        \"\"\"",
            "",
            "        # Set up our path instance variables.",
            "        self.path = self.parse_url_path(path)",
            "        del path  # make sure we don't refer to path instead of self.path again",
            "        absolute_path = self.get_absolute_path(self.root, self.path)",
            "        self.absolute_path = self.validate_absolute_path(self.root, absolute_path)",
            "        if self.absolute_path is None:",
            "            return",
            "",
            "        content_type = self.get_content_type()",
            "        if content_type:",
            "            self.set_header(\"Content-Type\", content_type)",
            "        self.set_extra_headers(self.path)",
            "",
            "        if include_body:",
            "            content = self.get_content(self.absolute_path)",
            "            if isinstance(content, bytes):",
            "                content = [content]",
            "            for chunk in content:",
            "                try:",
            "                    self.write(chunk)",
            "                    yield self.flush()",
            "                except tornado.iostream.StreamClosedError:",
            "                    return",
            "        else:",
            "            assert self.request.method == \"HEAD\"",
            "",
            "    def set_extra_headers(self, path):",
            "        if self._as_attachment:",
            "            filename = None",
            "            if callable(self._name_generator):",
            "                filename = self._name_generator(path)",
            "            if filename is None:",
            "                filename = os.path.basename(path)",
            "",
            "            filename = tornado.escape.url_escape(filename, plus=False)",
            "            self.set_header(",
            "                \"Content-Disposition\",",
            "                \"attachment; filename=\\\"{}\\\"; filename*=UTF-8''{}\".format(",
            "                    filename, filename",
            "                ),",
            "            )",
            "",
            "        if not self._allow_client_caching:",
            "            self.set_header(\"Cache-Control\", \"max-age=0, must-revalidate, private\")",
            "            self.set_header(\"Expires\", \"-1\")",
            "",
            "        self.set_header(\"X-Original-Content-Length\", str(self.get_content_size()))",
            "",
            "    @property",
            "    def original_absolute_path(self):",
            "        \"\"\"The path of the uncompressed file corresponding to the compressed file\"\"\"",
            "        if self._is_pre_compressed:",
            "            return self.absolute_path.rstrip(\".gz\")",
            "        return self.absolute_path",
            "",
            "    def compute_etag(self):",
            "        if self._etag_generator is not None:",
            "            etag = self._etag_generator(self)",
            "        else:",
            "            etag = str(self.get_content_version(self.absolute_path))",
            "",
            "        if not etag.endswith('\"'):",
            "            etag = f'\"{etag}\"'",
            "        return etag",
            "",
            "    # noinspection PyAttributeOutsideInit",
            "    def get_content_type(self):",
            "        if self._mime_type_guesser is not None:",
            "            type = self._mime_type_guesser(self.original_absolute_path)",
            "            if type is not None:",
            "                return type",
            "",
            "        correct_absolute_path = None",
            "        try:",
            "            # reset self.absolute_path temporarily",
            "            if self.should_use_precompressed():",
            "                correct_absolute_path = self.absolute_path",
            "                self.absolute_path = self.original_absolute_path",
            "            return tornado.web.StaticFileHandler.get_content_type(self)",
            "        finally:",
            "            # restore self.absolute_path",
            "            if self.should_use_precompressed() and correct_absolute_path is not None:",
            "                self.absolute_path = correct_absolute_path",
            "",
            "    @classmethod",
            "    def get_content_version(cls, abspath):",
            "        import os",
            "        import stat",
            "",
            "        return os.stat(abspath)[stat.ST_MTIME]",
            "",
            "",
            "##~~ URL Forward Handler for forwarding requests to a preconfigured static URL",
            "",
            "",
            "class UrlProxyHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.RequestHandler",
            "):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ that proxies",
            "    requests to a preconfigured url and returns the response. Allows delivery of the requested content as attachment",
            "    and access validation through an optional callback.",
            "",
            "    This will use `tornado.httpclient.AsyncHTTPClient <http://tornado.readthedocs.org/en/branch4.0/httpclient.html#tornado.httpclient.AsyncHTTPClient>`_",
            "    for making the request to the configured endpoint and return the body of the client response with the status code",
            "    from the client response and the following headers:",
            "",
            "      * ``Date``, ``Cache-Control``, ``Expires``, ``ETag``, ``Server``, ``Content-Type`` and ``Location`` will be copied over.",
            "      * If ``as_attachment`` is set to True, ``Content-Disposition`` will be set to ``attachment``. If ``basename`` is",
            "        set including the attachment's ``filename`` attribute will be set to the base name followed by the extension",
            "        guessed based on the MIME type from the ``Content-Type`` header of the response. If no extension can be guessed",
            "        no ``filename`` attribute will be set.",
            "",
            "    Arguments:",
            "       url (str): URL to forward any requests to. A 404 response will be returned if this is not set. Defaults to ``None``.",
            "       as_attachment (bool): Whether to serve files with ``Content-Disposition: attachment`` header (``True``)",
            "           or not. Defaults to ``False``.",
            "       basename (str): base name of file names to return as part of the attachment header, see above. Defaults to ``None``.",
            "       access_validation (function): Callback to call in the ``get`` method to validate access to the resource. Will",
            "           be called with ``self.request`` as parameter which contains the full tornado request object. Should raise",
            "           a ``tornado.web.HTTPError`` if access is not allowed in which case the request will not be further processed.",
            "           Defaults to ``None`` and hence no access validation being performed.",
            "    \"\"\"",
            "",
            "    def initialize(",
            "        self, url=None, as_attachment=False, basename=None, access_validation=None",
            "    ):",
            "        tornado.web.RequestHandler.initialize(self)",
            "        self._url = url",
            "        self._as_attachment = as_attachment",
            "        self._basename = basename",
            "        self._access_validation = access_validation",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "",
            "        if self._url is None:",
            "            raise tornado.web.HTTPError(404)",
            "",
            "        client = tornado.httpclient.AsyncHTTPClient()",
            "        r = tornado.httpclient.HTTPRequest(",
            "            url=self._url,",
            "            method=self.request.method,",
            "            body=self.request.body,",
            "            headers=self.request.headers,",
            "            follow_redirects=False,",
            "            allow_nonstandard_methods=True,",
            "        )",
            "",
            "        try:",
            "            return client.fetch(r, self.handle_response)",
            "        except tornado.web.HTTPError as e:",
            "            if hasattr(e, \"response\") and e.response:",
            "                self.handle_response(e.response)",
            "            else:",
            "                raise tornado.web.HTTPError(500)",
            "",
            "    def handle_response(self, response):",
            "        if response.error and not isinstance(response.error, tornado.web.HTTPError):",
            "            raise tornado.web.HTTPError(500)",
            "",
            "        filename = None",
            "",
            "        self.set_status(response.code)",
            "        for name in (",
            "            \"Date\",",
            "            \"Cache-Control\",",
            "            \"Server\",",
            "            \"Content-Type\",",
            "            \"Location\",",
            "            \"Expires\",",
            "            \"ETag\",",
            "        ):",
            "            value = response.headers.get(name)",
            "            if value:",
            "                self.set_header(name, value)",
            "",
            "                if name == \"Content-Type\":",
            "                    filename = self.get_filename(value)",
            "",
            "        if self._as_attachment:",
            "            if filename is not None:",
            "                self.set_header(",
            "                    \"Content-Disposition\", \"attachment; filename=%s\" % filename",
            "                )",
            "            else:",
            "                self.set_header(\"Content-Disposition\", \"attachment\")",
            "",
            "        if response.body:",
            "            self.write(response.body)",
            "        self.finish()",
            "",
            "    def get_filename(self, content_type):",
            "        if not self._basename:",
            "            return None",
            "",
            "        typeValue = list(x.strip() for x in content_type.split(\";\"))",
            "        if len(typeValue) == 0:",
            "            return None",
            "",
            "        extension = mimetypes.guess_extension(typeValue[0])",
            "        if not extension:",
            "            return None",
            "",
            "        return f\"{self._basename}{extension}\"",
            "",
            "",
            "class StaticDataHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.RequestHandler",
            "):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ that returns",
            "    static ``data`` of a configured ``content_type``.",
            "",
            "    Arguments:",
            "       data (str): The data with which to respond",
            "       content_type (str): The content type with which to respond. Defaults to ``text/plain``",
            "    \"\"\"",
            "",
            "    def initialize(self, data=\"\", content_type=\"text/plain\"):",
            "        self.data = data",
            "        self.content_type = content_type",
            "",
            "    def get(self, *args, **kwargs):",
            "        self.set_status(200)",
            "        self.set_header(\"Content-Type\", self.content_type)",
            "        self.write(self.data)",
            "        self.flush()",
            "        self.finish()",
            "",
            "",
            "class GeneratingDataHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.RequestHandler",
            "):",
            "    \"\"\"",
            "    A `RequestHandler` that generates data from a generator function and returns it to the client.",
            "",
            "    Arguments:",
            "        generator (function): A generator function that returns the data to be written to the client. The function",
            "            will be called without any parameters.",
            "        content_type (str): The content type with which to respond. Defaults to `text/plain`",
            "        as_attachment (bool | str): Whether to serve files with `Content-Disposition: attachment` header (`True`)",
            "            or not. Defaults to `False`. If a string is given it will be used as the filename of the attachment.",
            "        access_validation (function): Callback to call in the `get` method to validate access to the resource. Will",
            "            be called with `self.request` as parameter which contains the full tornado request object. Should raise",
            "            a `tornado.web.HTTPError` if access is not allowed in which case the request will not be further processed.",
            "            Defaults to `None` and hence no access validation being performed.",
            "    \"\"\"",
            "",
            "    def initialize(",
            "        self,",
            "        generator=None,",
            "        content_type=\"text/plain\",",
            "        as_attachment=False,",
            "        access_validation=None,",
            "    ):",
            "        super().initialize()",
            "        self._generator = generator",
            "        self._content_type = content_type",
            "        self._as_attachment = as_attachment",
            "        self._access_validation = access_validation",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "",
            "        self.set_status(200)",
            "        self.set_header(\"Content-Type\", self._content_type)",
            "        self.set_content_disposition()",
            "        for data in self._generator():",
            "            self.write(data)",
            "            yield self.flush()",
            "        self.finish()",
            "",
            "    def set_content_disposition(self):",
            "        if self._as_attachment:",
            "            if isinstance(self._as_attachment, str):",
            "                self.set_header(",
            "                    \"Content-Disposition\", f\"attachment; filename={self._as_attachment}\"",
            "                )",
            "            else:",
            "                self.set_header(\"Content-Disposition\", \"attachment\")",
            "",
            "",
            "class WebcamSnapshotHandler(GeneratingDataHandler):",
            "    \"\"\"",
            "    `GeneratingDataHandler` that returns a snapshot from the configured webcam.",
            "",
            "    Arguments:",
            "        as_attachment (bool | str): Whether to serve files with `Content-Disposition: attachment` header (`True`)",
            "            or not. Defaults to `False`. If a string is given it will be used as the filename of the attachment.",
            "        access_validation (function): Callback to call in the `get` method to validate access to the resource. Will",
            "            be called with `self.request` as parameter which contains the full tornado request object. Should raise",
            "            a `tornado.web.HTTPError` if access is not allowed in which case the request will not be further processed.",
            "            Defaults to `None` and hence no access validation being performed.",
            "    \"\"\"",
            "",
            "    def initialize(self, as_attachment=False, access_validation=None):",
            "        super().initialize(",
            "            content_type=\"image/jpeg\",",
            "            as_attachment=as_attachment,",
            "            access_validation=access_validation,",
            "        )",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "",
            "        import functools",
            "",
            "        from octoprint.webcams import get_snapshot_webcam",
            "",
            "        webcam = get_snapshot_webcam()",
            "        if not webcam:",
            "            raise tornado.web.HTTPError(404)",
            "",
            "        generator = functools.partial(",
            "            webcam.providerPlugin.take_webcam_snapshot, webcam.config.name",
            "        )",
            "",
            "        self.set_status(200)",
            "        self.set_header(\"Content-Type\", self._content_type)",
            "        self.set_content_disposition()",
            "        for data in generator():",
            "            self.write(data)",
            "            yield self.flush()",
            "        self.finish()",
            "",
            "",
            "class DeprecatedEndpointHandler(CorsSupportMixin, tornado.web.RequestHandler):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ that redirects",
            "    to another ``url`` and logs a deprecation warning.",
            "",
            "    Arguments:",
            "       url (str): URL to which to redirect",
            "    \"\"\"",
            "",
            "    def initialize(self, url):",
            "        self._url = url",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "    def _handle_method(self, *args, **kwargs):",
            "        to_url = self._url.format(*args)",
            "        self._logger.info(",
            "            f\"Redirecting deprecated endpoint {self.request.path} to {to_url}\"",
            "        )",
            "        self.redirect(to_url, permanent=True)",
            "",
            "    # make all http methods trigger _handle_method",
            "    get = _handle_method",
            "    post = _handle_method",
            "    put = _handle_method",
            "    patch = _handle_method",
            "    delete = _handle_method",
            "    head = _handle_method",
            "    options = _handle_method",
            "",
            "",
            "class StaticZipBundleHandler(CorsSupportMixin, tornado.web.RequestHandler):",
            "    def initialize(",
            "        self,",
            "        files=None,",
            "        as_attachment=True,",
            "        attachment_name=None,",
            "        access_validation=None,",
            "        compress=False,",
            "    ):",
            "        if files is None:",
            "            files = []",
            "        if as_attachment and not attachment_name:",
            "            raise ValueError(\"attachment name must be set if as_attachment is True\")",
            "",
            "        self._files = files",
            "        self._as_attachment = as_attachment",
            "        self._attachment_name = attachment_name",
            "        self._access_validator = access_validation",
            "        self._compress = compress",
            "",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "        return self.stream_zip(self._files)",
            "",
            "    def get_attachment_name(self):",
            "        return self._attachment_name",
            "",
            "    def normalize_files(self, files):",
            "        result = []",
            "        for f in files:",
            "            if isinstance(f, str):",
            "                result.append({\"path\": f})",
            "            elif isinstance(f, dict) and (\"path\" in f or \"iter\" in f or \"content\" in f):",
            "                result.append(f)",
            "        return result",
            "",
            "    @tornado.gen.coroutine",
            "    def stream_zip(self, files):",
            "        self.set_header(\"Content-Type\", \"application/zip\")",
            "        if self._as_attachment:",
            "            self.set_header(",
            "                \"Content-Disposition\",",
            "                f'attachment; filename=\"{self.get_attachment_name()}\"',",
            "            )",
            "",
            "        z = ZipStream(sized=True)",
            "        if self._compress:",
            "            try:",
            "                z = ZipStream(compress_type=ZIP_DEFLATED)",
            "            except RuntimeError:",
            "                # no zlib support",
            "                pass",
            "",
            "        for f in self.normalize_files(files):",
            "            name = f.get(\"name\")",
            "            path = f.get(\"path\")",
            "            data = f.get(\"iter\") or f.get(\"content\")",
            "",
            "            if path:",
            "                z.add_path(path, arcname=name)",
            "            elif data and name:",
            "                z.add(data, arcname=name)",
            "",
            "        if z.sized:",
            "            self.set_header(\"Content-Length\", len(z))",
            "        self.set_header(\"Last-Modified\", z.last_modified)",
            "",
            "        for chunk in z:",
            "            try:",
            "                self.write(chunk)",
            "                yield self.flush()",
            "            except tornado.iostream.StreamClosedError:",
            "                return",
            "",
            "",
            "class DynamicZipBundleHandler(StaticZipBundleHandler):",
            "    # noinspection PyMethodOverriding",
            "    def initialize(",
            "        self,",
            "        path_validation=None,",
            "        path_processor=None,",
            "        as_attachment=True,",
            "        attachment_name=None,",
            "        access_validation=None,",
            "        compress=False,",
            "    ):",
            "        if as_attachment and not attachment_name:",
            "            raise ValueError(\"attachment name must be set if as_attachment is True\")",
            "",
            "        self._path_validator = path_validation",
            "        self._path_processor = path_processor",
            "        self._as_attachment = as_attachment",
            "        self._attachment_name = attachment_name",
            "        self._access_validator = access_validation",
            "        self._compress = compress",
            "",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "",
            "        files = list(",
            "            map(octoprint.util.to_unicode, self.request.query_arguments.get(\"files\", []))",
            "        )",
            "        return self._get_files_zip(files)",
            "",
            "    def post(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "",
            "        import json",
            "",
            "        content_type = self.request.headers.get(\"Content-Type\", \"\")",
            "        try:",
            "            if \"application/json\" in content_type:",
            "                data = json.loads(self.request.body)",
            "            else:",
            "                data = self.request.body_arguments",
            "        except Exception:",
            "            raise tornado.web.HTTPError(400)",
            "",
            "        return self._get_files_zip(",
            "            list(map(octoprint.util.to_unicode, data.get(\"files\", [])))",
            "        )",
            "",
            "    def _get_files_zip(self, files):",
            "        files = self.normalize_files(files)",
            "        if not files:",
            "            raise tornado.web.HTTPError(400)",
            "",
            "        for f in files:",
            "            if \"path\" in f:",
            "                if callable(self._path_processor):",
            "                    path = self._path_processor(f[\"path\"])",
            "                    if isinstance(path, tuple):",
            "                        f[\"name\"], f[\"path\"] = path",
            "                    else:",
            "                        f[\"path\"] = path",
            "                self._path_validator(f[\"path\"])",
            "",
            "        return self.stream_zip(files)",
            "",
            "",
            "class SystemInfoBundleHandler(CorsSupportMixin, tornado.web.RequestHandler):",
            "    # noinspection PyMethodOverriding",
            "    def initialize(self, access_validation=None):",
            "        self._access_validator = access_validation",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "",
            "        from octoprint.cli.systeminfo import (",
            "            get_systeminfo,",
            "            get_systeminfo_bundle,",
            "            get_systeminfo_bundle_name,",
            "        )",
            "        from octoprint.server import (",
            "            connectivityChecker,",
            "            environmentDetector,",
            "            pluginManager,",
            "            printer,",
            "            safe_mode,",
            "        )",
            "        from octoprint.settings import settings",
            "",
            "        systeminfo = get_systeminfo(",
            "            environmentDetector,",
            "            connectivityChecker,",
            "            settings(),",
            "            {",
            "                \"browser.user_agent\": self.request.headers.get(\"User-Agent\"),",
            "                \"octoprint.safe_mode\": safe_mode is not None,",
            "                \"systeminfo.generator\": \"zipapi\",",
            "            },",
            "        )",
            "",
            "        z = get_systeminfo_bundle(",
            "            systeminfo,",
            "            settings().getBaseFolder(\"logs\"),",
            "            printer=printer,",
            "            plugin_manager=pluginManager,",
            "        )",
            "",
            "        self.set_header(\"Content-Type\", \"application/zip\")",
            "        self.set_header(",
            "            \"Content-Disposition\",",
            "            f'attachment; filename=\"{get_systeminfo_bundle_name()}\"',",
            "        )",
            "        if z.sized:",
            "            self.set_header(\"Content-Length\", len(z))",
            "        self.set_header(\"Last-Modified\", z.last_modified)",
            "",
            "        for chunk in z:",
            "            try:",
            "                self.write(chunk)",
            "                yield self.flush()",
            "            except tornado.iostream.StreamClosedError:",
            "                return",
            "",
            "    def get_attachment_name(self):",
            "        import time",
            "",
            "        return \"octoprint-systeminfo-{}.zip\".format(time.strftime(\"%Y%m%d%H%M%S\"))",
            "",
            "",
            "class GlobalHeaderTransform(tornado.web.OutputTransform):",
            "    HEADERS = {}",
            "    FORCED_HEADERS = {}",
            "    REMOVED_HEADERS = []",
            "",
            "    @classmethod",
            "    def for_headers(cls, name, headers=None, forced_headers=None, removed_headers=None):",
            "        if headers is None:",
            "            headers = {}",
            "        if forced_headers is None:",
            "            forced_headers = {}",
            "        if removed_headers is None:",
            "            removed_headers = []",
            "",
            "        return type(",
            "            name,",
            "            (GlobalHeaderTransform,),",
            "            {",
            "                \"HEADERS\": headers,",
            "                \"FORCED_HEADERS\": forced_headers,",
            "                \"REMOVED_HEADERS\": removed_headers,",
            "            },",
            "        )",
            "",
            "    def __init__(self, request):",
            "        tornado.web.OutputTransform.__init__(self, request)",
            "",
            "    def transform_first_chunk(self, status_code, headers, chunk, finishing):",
            "        for header, value in self.HEADERS.items():",
            "            if header not in headers:",
            "                headers[header] = value",
            "        for header, value in self.FORCED_HEADERS.items():",
            "            headers[header] = value",
            "        for header in self.REMOVED_HEADERS:",
            "            del headers[header]",
            "        return status_code, headers, chunk",
            "",
            "",
            "# ~~ Factory method for creating Flask access validation wrappers from the Tornado request context",
            "",
            "",
            "def access_validation_factory(app, validator, *args):",
            "    \"\"\"",
            "    Creates an access validation wrapper using the supplied validator.",
            "",
            "    :param validator: the access validator to use inside the validation wrapper",
            "    :return: an access validator taking a request as parameter and performing the request validation",
            "    \"\"\"",
            "",
            "    # noinspection PyProtectedMember",
            "    def f(request):",
            "        \"\"\"",
            "        Creates a custom wsgi and Flask request context in order to be able to process user information",
            "        stored in the current session.",
            "",
            "        :param request: The Tornado request for which to create the environment and context",
            "        \"\"\"",
            "        import flask",
            "        from werkzeug.exceptions import HTTPException",
            "",
            "        wsgi_environ = WsgiInputContainer.environ(request)",
            "        with app.request_context(wsgi_environ):",
            "            session = app.session_interface.open_session(app, flask.request)",
            "            user_id = session.get(\"_user_id\")",
            "            user = None",
            "",
            "            # Yes, using protected methods is ugly. But these used to be publicly available in former versions",
            "            # of flask-login, there are no replacements, and seeing them renamed & hidden in a minor version release",
            "            # without any mention in the changelog means the public API ain't strictly stable either, so we might",
            "            # as well make our life easier here and just use them...",
            "            if user_id is not None and app.login_manager._user_callback is not None:",
            "                user = app.login_manager._user_callback(user_id)",
            "            app.login_manager._update_request_context_with_user(user)",
            "",
            "            try:",
            "                validator(flask.request, *args)",
            "            except HTTPException as e:",
            "                raise tornado.web.HTTPError(e.code)",
            "",
            "    return f",
            "",
            "",
            "def path_validation_factory(path_filter, status_code=404):",
            "    \"\"\"",
            "    Creates a request path validation wrapper returning the defined status code if the supplied path_filter returns False.",
            "",
            "    :param path_filter: the path filter to use on the requested path, should return False for requests that should",
            "       be responded with the provided error code.",
            "    :return: a request path validator taking a request path as parameter and performing the request validation",
            "    \"\"\"",
            "",
            "    def f(path):",
            "        if not path_filter(path):",
            "            raise tornado.web.HTTPError(status_code)",
            "",
            "    return f",
            "",
            "",
            "def validation_chain(*validators):",
            "    def f(request):",
            "        for validator in validators:",
            "            validator(request)",
            "",
            "    return f"
        ],
        "afterPatchFile": [
            "__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"",
            "__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"",
            "__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"",
            "",
            "import asyncio",
            "import logging",
            "import mimetypes",
            "import os",
            "import re",
            "import sys",
            "from urllib.parse import urlparse",
            "",
            "import tornado",
            "import tornado.escape",
            "import tornado.gen",
            "import tornado.http1connection",
            "import tornado.httpclient",
            "import tornado.httpserver",
            "import tornado.httputil",
            "import tornado.iostream",
            "import tornado.netutil",
            "import tornado.tcpserver",
            "import tornado.util",
            "import tornado.web",
            "from tornado.concurrent import dummy_executor",
            "from tornado.ioloop import IOLoop",
            "from zipstream.ng import ZIP_DEFLATED, ZipStream",
            "",
            "import octoprint.util",
            "import octoprint.util.net",
            "",
            "",
            "def fix_json_encode():",
            "    \"\"\"",
            "    This makes tornado.escape.json_encode use octoprint.util.JsonEncoding.encode as fallback in order to allow",
            "    serialization of globally registered types like frozendict and others.",
            "    \"\"\"",
            "",
            "    import json",
            "",
            "    from octoprint.util.json import JsonEncoding",
            "",
            "    def fixed_json_encode(value):",
            "        return json.dumps(value, default=JsonEncoding.encode, allow_nan=False).replace(",
            "            \"</\", \"<\\\\/\"",
            "        )",
            "",
            "    import tornado.escape",
            "",
            "    tornado.escape.json_encode = fixed_json_encode",
            "",
            "",
            "def enable_per_message_deflate_extension():",
            "    \"\"\"",
            "    This configures tornado.websocket.WebSocketHandler.get_compression_options to support the permessage-deflate extension",
            "    to the websocket protocol, minimizing data bandwidth if clients support the extension as well",
            "    \"\"\"",
            "",
            "    def get_compression_options(self):",
            "        return {\"compression_level\": 1, \"mem_level\": 1}",
            "",
            "    tornado.websocket.WebSocketHandler.get_compression_options = get_compression_options",
            "",
            "",
            "def fix_websocket_check_origin():",
            "    \"\"\"",
            "    This fixes tornado.websocket.WebSocketHandler.check_origin to do the same origin check against the Host",
            "    header case-insensitively, as defined in RFC6454, Section 4, item 5.",
            "    \"\"\"",
            "",
            "    scheme_translation = {\"wss\": \"https\", \"ws\": \"http\"}",
            "",
            "    def patched_check_origin(self, origin):",
            "        def get_check_tuple(urlstring):",
            "            parsed = urlparse(urlstring)",
            "            scheme = scheme_translation.get(parsed.scheme, parsed.scheme)",
            "            return (",
            "                scheme,",
            "                parsed.hostname,",
            "                (",
            "                    parsed.port",
            "                    if parsed.port",
            "                    else 80",
            "                    if scheme == \"http\"",
            "                    else 443",
            "                    if scheme == \"https\"",
            "                    else None",
            "                ),",
            "            )",
            "",
            "        return get_check_tuple(origin) == get_check_tuple(self.request.full_url())",
            "",
            "    import tornado.websocket",
            "",
            "    tornado.websocket.WebSocketHandler.check_origin = patched_check_origin",
            "",
            "",
            "def fix_tornado_xheader_handling():",
            "    \"\"\"",
            "    This fixes tornado.httpserver._HTTPRequestContext._apply_xheaders to only use \"X-Forwarded-For\" header",
            "    for rewriting the ``remote_ip`` field, utilizing the set of trusted downstreams, instead of blindly",
            "    trusting ``X-Real-Ip``, and to also fetch the scheme from \"X-Forwarded-Proto\" if available.",
            "    \"\"\"",
            "",
            "    def patched_apply_xheaders(self, headers: \"tornado.httputil.HTTPHeaders\") -> None:",
            "        \"\"\"Rewrite the ``remote_ip`` and ``protocol`` fields.\"\"\"",
            "",
            "        # other than the default implementation, we only use \"X-Forwarded-For\" here, not \"X-Real-Ip\"",
            "        ip = octoprint.util.net.get_http_client_ip(",
            "            self.remote_ip, headers.get(\"X-Forwarded-For\"), self.trusted_downstream",
            "        )",
            "        if tornado.netutil.is_valid_ip(ip):",
            "            self.remote_ip = ip",
            "",
            "        # also fetch scheme from \"X-Forwarded-Proto\" if available",
            "        proto_header = headers.get(\"X-Scheme\", headers.get(\"X-Forwarded-Proto\"))",
            "        if proto_header:",
            "            # use only the last proto entry if there is more than one",
            "            proto_header = proto_header.split(\",\")[-1].strip()",
            "        if proto_header in (\"http\", \"https\"):",
            "            self.protocol = proto_header",
            "",
            "    import tornado.httpserver",
            "",
            "    tornado.httpserver._HTTPRequestContext._apply_xheaders = patched_apply_xheaders",
            "",
            "",
            "# ~~ More sensible logging",
            "",
            "",
            "class RequestlessExceptionLoggingMixin(tornado.web.RequestHandler):",
            "    LOG_REQUEST = False",
            "",
            "    def log_exception(self, typ, value, tb, *args, **kwargs):",
            "        if isinstance(value, tornado.web.HTTPError):",
            "            if value.log_message:",
            "                format = \"%d %s: \" + value.log_message",
            "                args = [value.status_code, self._request_summary()] + list(value.args)",
            "                tornado.web.gen_log.warning(format, *args)",
            "        else:",
            "            if self.LOG_REQUEST:",
            "                tornado.web.app_log.error(",
            "                    \"Uncaught exception %s\\n%r\",",
            "                    self._request_summary(),",
            "                    self.request,",
            "                    exc_info=(typ, value, tb),",
            "                )",
            "            else:",
            "                tornado.web.app_log.error(",
            "                    \"Uncaught exception %s\",",
            "                    self._request_summary(),",
            "                    exc_info=(typ, value, tb),",
            "                )",
            "",
            "",
            "# ~~ CORS support",
            "",
            "",
            "class CorsSupportMixin(tornado.web.RequestHandler):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ mixin that",
            "    makes sure to set CORS headers similarly to the Flask backed API endpoints.",
            "    \"\"\"",
            "",
            "    ENABLE_CORS = False",
            "",
            "    def set_default_headers(self):",
            "        origin = self.request.headers.get(\"Origin\")",
            "        if self.request.method != \"OPTIONS\" and origin and self.ENABLE_CORS:",
            "            self.set_header(\"Access-Control-Allow-Origin\", origin)",
            "",
            "    @tornado.gen.coroutine",
            "    def options(self, *args, **kwargs):",
            "        if self.ENABLE_CORS:",
            "            origin = self.request.headers.get(\"Origin\")",
            "            method = self.request.headers.get(\"Access-Control-Request-Method\")",
            "",
            "            # Allow the origin which made the XHR",
            "            self.set_header(\"Access-Control-Allow-Origin\", origin)",
            "            # Allow the actual method",
            "            self.set_header(\"Access-Control-Allow-Methods\", method)",
            "            # Allow for 10 seconds",
            "            self.set_header(\"Access-Control-Max-Age\", \"10\")",
            "",
            "            # 'preflight' request contains the non-standard headers the real request will have (like X-Api-Key)",
            "            custom_headers = self.request.headers.get(\"Access-Control-Request-Headers\")",
            "            if custom_headers is not None:",
            "                self.set_header(\"Access-Control-Allow-Headers\", custom_headers)",
            "",
            "        self.set_status(204)",
            "        self.finish()",
            "",
            "",
            "# ~~ WSGI middleware",
            "",
            "",
            "@tornado.web.stream_request_body",
            "class UploadStorageFallbackHandler(RequestlessExceptionLoggingMixin, CorsSupportMixin):",
            "    \"\"\"",
            "    A ``RequestHandler`` similar to ``tornado.web.FallbackHandler`` which fetches any files contained in the request bodies",
            "    of content type ``multipart``, stores them in temporary files and supplies the ``fallback`` with the file's ``name``,",
            "    ``content_type``, ``path`` and ``size`` instead via a rewritten body.",
            "",
            "    Basically similar to what the nginx upload module does.",
            "",
            "    Basic request body example:",
            "",
            "    .. code-block:: none",
            "",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file\"; filename=\"test.gcode\"",
            "        Content-Type: application/octet-stream",
            "",
            "        ...",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"apikey\"",
            "",
            "        my_funny_apikey",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"select\"",
            "",
            "        true",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C--",
            "",
            "    That would get turned into:",
            "",
            "    .. code-block:: none",
            "",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"apikey\"",
            "",
            "        my_funny_apikey",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"select\"",
            "",
            "        true",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.path\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        /tmp/tmpzupkro",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.name\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        test.gcode",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.content_type\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        application/octet-stream",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C",
            "        Content-Disposition: form-data; name=\"file.size\"",
            "        Content-Type: text/plain; charset=utf-8",
            "",
            "        349182",
            "        ------WebKitFormBoundarypYiSUx63abAmhT5C--",
            "",
            "    The underlying application can then access the contained files via their respective paths and just move them",
            "    where necessary.",
            "    \"\"\"",
            "",
            "    BODY_METHODS = (\"POST\", \"PATCH\", \"PUT\")",
            "    \"\"\" The request methods that may contain a request body. \"\"\"",
            "",
            "    def initialize(",
            "        self, fallback, file_prefix=\"tmp\", file_suffix=\"\", path=None, suffixes=None",
            "    ):",
            "        if not suffixes:",
            "            suffixes = {}",
            "",
            "        self._fallback = fallback",
            "        self._file_prefix = file_prefix",
            "        self._file_suffix = file_suffix",
            "        self._path = path",
            "",
            "        self._suffixes = {key: key for key in (\"name\", \"path\", \"content_type\", \"size\")}",
            "        for suffix_type, suffix in suffixes.items():",
            "            if suffix_type in self._suffixes and suffix is not None:",
            "                self._suffixes[suffix_type] = suffix",
            "",
            "        # multipart boundary",
            "        self._multipart_boundary = None",
            "",
            "        # Parts, files and values will be stored here",
            "        self._parts = {}",
            "        self._files = []",
            "",
            "        # Part currently being processed",
            "        self._current_part = None",
            "",
            "        # content type of request body",
            "        self._content_type = None",
            "",
            "        # bytes left to read according to content_length of request body",
            "        self._bytes_left = 0",
            "",
            "        # buffer needed for identifying form data parts",
            "        self._buffer = b\"\"",
            "",
            "        # buffer for new body",
            "        self._new_body = b\"\"",
            "",
            "        # logger",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "    def prepare(self):",
            "        \"\"\"",
            "        Prepares the processing of the request. If it's a request that may contain a request body (as defined in",
            "        :attr:`UploadStorageFallbackHandler.BODY_METHODS`) prepares the multipart parsing if content type fits. If it's a",
            "        body-less request, just calls the ``fallback`` with an empty body and finishes the request.",
            "        \"\"\"",
            "        if self.request.method in UploadStorageFallbackHandler.BODY_METHODS:",
            "            self._bytes_left = self.request.headers.get(\"Content-Length\", 0)",
            "            self._content_type = self.request.headers.get(\"Content-Type\", None)",
            "",
            "            # request might contain a body",
            "            if self.is_multipart():",
            "                if not self._bytes_left:",
            "                    # we don't support requests without a content-length",
            "                    raise tornado.web.HTTPError(",
            "                        411, log_message=\"No Content-Length supplied\"",
            "                    )",
            "",
            "                # extract the multipart boundary",
            "                fields = self._content_type.split(\";\")",
            "                for field in fields:",
            "                    k, sep, v = field.strip().partition(\"=\")",
            "                    if k == \"boundary\" and v:",
            "                        if v.startswith('\"') and v.endswith('\"'):",
            "                            self._multipart_boundary = tornado.escape.utf8(v[1:-1])",
            "                        else:",
            "                            self._multipart_boundary = tornado.escape.utf8(v)",
            "                        break",
            "                else:",
            "                    # RFC2046 section 5.1 (as referred to from RFC 7578) defines the boundary",
            "                    # parameter as mandatory for multipart requests:",
            "                    #",
            "                    #     The only mandatory global parameter for the \"multipart\" media type is",
            "                    #     the boundary parameter, which consists of 1 to 70 characters [...]",
            "                    #",
            "                    # So no boundary? 400 Bad Request",
            "                    raise tornado.web.HTTPError(",
            "                        400, log_message=\"No multipart boundary supplied\"",
            "                    )",
            "        else:",
            "            self._fallback(self.request, b\"\")",
            "            self._finished = True",
            "            self.on_finish()",
            "",
            "    def data_received(self, chunk):",
            "        \"\"\"",
            "        Called by Tornado on receiving a chunk of the request body. If request is a multipart request, takes care of",
            "        processing the multipart data structure via :func:`_process_multipart_data`. If not, just adds the chunk to",
            "        internal in-memory buffer.",
            "",
            "        :param chunk: chunk of data received from Tornado",
            "        \"\"\"",
            "",
            "        data = self._buffer + chunk",
            "        if self.is_multipart():",
            "            self._process_multipart_data(data)",
            "        else:",
            "            self._buffer = data",
            "",
            "    def is_multipart(self):",
            "        \"\"\"Checks whether this request is a ``multipart`` request\"\"\"",
            "        return self._content_type is not None and self._content_type.startswith(",
            "            \"multipart\"",
            "        )",
            "",
            "    def _process_multipart_data(self, data):",
            "        \"\"\"",
            "        Processes the given data, parsing it for multipart definitions and calling the appropriate methods.",
            "",
            "        :param data: the data to process as a string",
            "        \"\"\"",
            "",
            "        # check for boundary",
            "        delimiter = b\"--%s\" % self._multipart_boundary",
            "        delimiter_loc = data.find(delimiter)",
            "        delimiter_len = len(delimiter)",
            "        end_of_header = -1",
            "        if delimiter_loc != -1:",
            "            # found the delimiter in the currently available data",
            "            delimiter_data_end = 0 if delimiter_loc == 0 else delimiter_loc - 2",
            "            data, self._buffer = data[0:delimiter_data_end], data[delimiter_loc:]",
            "            end_of_header = self._buffer.find(b\"\\r\\n\\r\\n\")",
            "        else:",
            "            # make sure any boundary (with single or double ==) contained at the end of chunk does not get",
            "            # truncated by this processing round => save it to the buffer for next round",
            "            endlen = len(self._multipart_boundary) + 4",
            "            data, self._buffer = data[0:-endlen], data[-endlen:]",
            "",
            "        # stream data to part handler",
            "        if data and self._current_part:",
            "            self._on_part_data(self._current_part, data)",
            "",
            "        if end_of_header >= 0:",
            "            self._on_part_header(self._buffer[delimiter_len + 2 : end_of_header])",
            "            self._buffer = self._buffer[end_of_header + 4 :]",
            "",
            "        if delimiter_loc != -1 and self._buffer.strip() == delimiter + b\"--\":",
            "            # we saw the last boundary and are at the end of our request",
            "            if self._current_part:",
            "                self._on_part_finish(self._current_part)",
            "                self._current_part = None",
            "            self._buffer = b\"\"",
            "            self._on_request_body_finish()",
            "",
            "    def _on_part_header(self, header):",
            "        \"\"\"",
            "        Called for a new multipart header, takes care of parsing the header and calling :func:`_on_part` with the",
            "        relevant data, setting the current part in the process.",
            "",
            "        :param header: header to parse",
            "        \"\"\"",
            "",
            "        # close any open parts",
            "        if self._current_part:",
            "            self._on_part_finish(self._current_part)",
            "            self._current_part = None",
            "",
            "        header_check = header.find(self._multipart_boundary)",
            "        if header_check != -1:",
            "            self._logger.warning(",
            "                \"Header still contained multipart boundary, stripping it...\"",
            "            )",
            "            header = header[header_check:]",
            "",
            "        # convert to dict",
            "        try:",
            "            header = tornado.httputil.HTTPHeaders.parse(header.decode(\"utf-8\"))",
            "        except UnicodeDecodeError:",
            "            try:",
            "                header = tornado.httputil.HTTPHeaders.parse(header.decode(\"iso-8859-1\"))",
            "            except Exception:",
            "                # looks like we couldn't decode something here neither as UTF-8 nor ISO-8859-1",
            "                self._logger.warning(",
            "                    \"Could not decode multipart headers in request, should be either UTF-8 or ISO-8859-1\"",
            "                )",
            "                self.send_error(400)",
            "                return",
            "",
            "        disp_header = header.get(\"Content-Disposition\", \"\")",
            "        disposition, disp_params = _parse_header(disp_header, strip_quotes=False)",
            "",
            "        if disposition != \"form-data\":",
            "            self._logger.warning(",
            "                \"Got a multipart header without form-data content disposition, ignoring that one\"",
            "            )",
            "            return",
            "        if not disp_params.get(\"name\"):",
            "            self._logger.warning(\"Got a multipart header without name, ignoring that one\")",
            "            return",
            "",
            "        filename = disp_params.get(\"filename*\", None)  # RFC 5987 header present?",
            "        if filename is not None:",
            "            try:",
            "                filename = _extended_header_value(filename)",
            "            except Exception:",
            "                # parse error, this is not RFC 5987 compliant after all",
            "                self._logger.warning(",
            "                    \"extended filename* value {!r} is not RFC 5987 compliant\".format(",
            "                        filename",
            "                    )",
            "                )",
            "                self.send_error(400)",
            "                return",
            "        else:",
            "            # no filename* header, just strip quotes from filename header then and be done",
            "            filename = _strip_value_quotes(disp_params.get(\"filename\", None))",
            "",
            "        self._current_part = self._on_part_start(",
            "            _strip_value_quotes(disp_params[\"name\"]),",
            "            header.get(\"Content-Type\", None),",
            "            filename=filename,",
            "        )",
            "",
            "    def _on_part_start(self, name, content_type, filename=None):",
            "        \"\"\"",
            "        Called for new parts in the multipart stream. If ``filename`` is given creates new ``file`` part (which leads",
            "        to storage of the data as temporary file on disk), if not creates a new ``data`` part (which stores",
            "        incoming data in memory).",
            "",
            "        Structure of ``file`` parts:",
            "",
            "        * ``name``: name of the part",
            "        * ``filename``: filename associated with the part",
            "        * ``path``: path to the temporary file storing the file's data",
            "        * ``content_type``: content type of the part",
            "        * ``file``: file handle for the temporary file (mode \"wb\", not deleted on close, will be deleted however after",
            "          handling of the request has finished in :func:`_handle_method`)",
            "",
            "        Structure of ``data`` parts:",
            "",
            "        * ``name``: name of the part",
            "        * ``content_type``: content type of the part",
            "        * ``data``: bytes of the part (initialized to an empty string)",
            "",
            "        :param name: name of the part",
            "        :param content_type: content type of the part",
            "        :param filename: filename associated with the part.",
            "        :return: dict describing the new part",
            "        \"\"\"",
            "        if filename is not None:",
            "            # this is a file",
            "            import tempfile",
            "",
            "            handle = tempfile.NamedTemporaryFile(",
            "                mode=\"wb\",",
            "                prefix=self._file_prefix,",
            "                suffix=self._file_suffix,",
            "                dir=self._path,",
            "                delete=False,",
            "            )",
            "            return {",
            "                \"name\": tornado.escape.utf8(name),",
            "                \"filename\": tornado.escape.utf8(filename),",
            "                \"path\": tornado.escape.utf8(handle.name),",
            "                \"content_type\": tornado.escape.utf8(content_type),",
            "                \"file\": handle,",
            "            }",
            "",
            "        else:",
            "            return {",
            "                \"name\": tornado.escape.utf8(name),",
            "                \"content_type\": tornado.escape.utf8(content_type),",
            "                \"data\": b\"\",",
            "            }",
            "",
            "    def _on_part_data(self, part, data):",
            "        \"\"\"",
            "        Called when new bytes are received for the given ``part``, takes care of writing them to their storage.",
            "",
            "        :param part: part for which data was received",
            "        :param data: data chunk which was received",
            "        \"\"\"",
            "        if \"file\" in part:",
            "            part[\"file\"].write(data)",
            "        else:",
            "            part[\"data\"] += data",
            "",
            "    def _on_part_finish(self, part):",
            "        \"\"\"",
            "        Called when a part gets closed, takes care of storing the finished part in the internal parts storage and for",
            "        ``file`` parts closing the temporary file and storing the part in the internal files storage.",
            "",
            "        :param part: part which was closed",
            "        \"\"\"",
            "        name = part[\"name\"]",
            "        self._parts[name] = part",
            "        if \"file\" in part:",
            "            self._files.append(part[\"path\"])",
            "            part[\"file\"].close()",
            "            del part[\"file\"]",
            "",
            "    def _on_request_body_finish(self):",
            "        \"\"\"",
            "        Called when the request body has been read completely. Takes care of creating the replacement body out of the",
            "        logged parts, turning ``file`` parts into new ``data`` parts.",
            "        \"\"\"",
            "",
            "        self._new_body = b\"\"",
            "        for name, part in self._parts.items():",
            "            if \"filename\" in part:",
            "                # add form fields for filename, path, size and content_type for all files contained in the request",
            "                if \"path\" not in part:",
            "                    continue",
            "",
            "                parameters = {",
            "                    \"name\": part[\"filename\"],",
            "                    \"path\": part[\"path\"],",
            "                    \"size\": str(os.stat(part[\"path\"]).st_size),",
            "                }",
            "                if \"content_type\" in part:",
            "                    parameters[\"content_type\"] = part[\"content_type\"]",
            "",
            "                fields = {",
            "                    self._suffixes[key]: value for (key, value) in parameters.items()",
            "                }",
            "                for n, p in fields.items():",
            "                    if n is None or p is None:",
            "                        continue",
            "                    key = name + b\".\" + octoprint.util.to_bytes(n)",
            "                    self._new_body += b\"--%s\\r\\n\" % self._multipart_boundary",
            "                    self._new_body += (",
            "                        b'Content-Disposition: form-data; name=\"%s\"\\r\\n' % key",
            "                    )",
            "                    self._new_body += b\"Content-Type: text/plain; charset=utf-8\\r\\n\"",
            "                    self._new_body += b\"\\r\\n\"",
            "                    self._new_body += octoprint.util.to_bytes(p) + b\"\\r\\n\"",
            "            elif \"data\" in part:",
            "                self._new_body += b\"--%s\\r\\n\" % self._multipart_boundary",
            "                value = part[\"data\"]",
            "                self._new_body += b'Content-Disposition: form-data; name=\"%s\"\\r\\n' % name",
            "                if \"content_type\" in part and part[\"content_type\"] is not None:",
            "                    self._new_body += b\"Content-Type: %s\\r\\n\" % part[\"content_type\"]",
            "                self._new_body += b\"\\r\\n\"",
            "                self._new_body += value + b\"\\r\\n\"",
            "        self._new_body += b\"--%s--\\r\\n\" % self._multipart_boundary",
            "",
            "    async def _handle_method(self, *args, **kwargs):",
            "        \"\"\"",
            "        Takes care of defining the new request body if necessary and forwarding",
            "        the current request and changed body to the ``fallback``.",
            "        \"\"\"",
            "",
            "        # determine which body to supply",
            "        body = b\"\"",
            "        if self.is_multipart():",
            "            # make sure we really processed all data in the buffer",
            "            while len(self._buffer):",
            "                self._process_multipart_data(self._buffer)",
            "",
            "            # use rewritten body",
            "            body = self._new_body",
            "",
            "        elif self.request.method in UploadStorageFallbackHandler.BODY_METHODS:",
            "            # directly use data from buffer",
            "            body = self._buffer",
            "",
            "        self.request.headers[\"Content-Length\"] = len(body)",
            "",
            "        try:",
            "            # call the configured fallback with request and body to use",
            "            result = self._fallback(self.request, body)",
            "            if result is not None:",
            "                await result",
            "        finally:",
            "            self._finished = True",
            "            self.on_finish()",
            "",
            "    def on_finish(self):",
            "        self._cleanup_files()",
            "",
            "    def _cleanup_files(self):",
            "        \"\"\"",
            "        Removes all temporary files created by this handler.",
            "        \"\"\"",
            "        for f in self._files:",
            "            octoprint.util.silent_remove(f)",
            "",
            "    # make all http methods trigger _handle_method",
            "    get = _handle_method",
            "    post = _handle_method",
            "    put = _handle_method",
            "    patch = _handle_method",
            "    delete = _handle_method",
            "    head = _handle_method",
            "    options = _handle_method",
            "",
            "",
            "def _parse_header(line, strip_quotes=True):",
            "    parts = tornado.httputil._parseparam(\";\" + line)",
            "    key = next(parts)",
            "    pdict = {}",
            "    for p in parts:",
            "        i = p.find(\"=\")",
            "        if i >= 0:",
            "            name = p[:i].strip().lower()",
            "            value = p[i + 1 :].strip()",
            "            if strip_quotes:",
            "                value = _strip_value_quotes(value)",
            "            pdict[name] = value",
            "    return key, pdict",
            "",
            "",
            "def _strip_value_quotes(value):",
            "    if not value:",
            "        return value",
            "",
            "    if len(value) >= 2 and value[0] == value[-1] == '\"':",
            "        value = value[1:-1]",
            "        value = value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')",
            "",
            "    return value",
            "",
            "",
            "def _extended_header_value(value):",
            "    if not value:",
            "        return value",
            "",
            "    if value.lower().startswith(\"iso-8859-1'\") or value.lower().startswith(\"utf-8'\"):",
            "        # RFC 5987 section 3.2",
            "        from urllib.parse import unquote",
            "",
            "        encoding, _, value = value.split(\"'\", 2)",
            "        return unquote(value, encoding=encoding)",
            "    else:",
            "        # no encoding provided, strip potentially present quotes and call it a day",
            "        return octoprint.util.to_unicode(_strip_value_quotes(value), encoding=\"utf-8\")",
            "",
            "",
            "class WsgiInputContainer:",
            "    \"\"\"",
            "    A WSGI container for use with Tornado that allows supplying the request body to be used for ``wsgi.input`` in the",
            "    generated WSGI environment upon call.",
            "",
            "    A ``RequestHandler`` can thus provide the WSGI application with a stream for the request body, or a modified body.",
            "",
            "    Example usage:",
            "",
            "    .. code-block:: python",
            "",
            "       wsgi_app = octoprint.server.util.WsgiInputContainer(octoprint_app)",
            "       application = tornado.web.Application([",
            "           (r\".*\", UploadStorageFallbackHandler, dict(fallback=wsgi_app),",
            "       ])",
            "",
            "    The implementation logic is basically the same as ``tornado.wsgi.WSGIContainer`` but the ``__call__`` and ``environ``",
            "    methods have been adjusted to allow for an optionally supplied ``body`` argument which is then used for ``wsgi.input``.",
            "",
            "    Additionally, some headers can be added or removed from the response by supplying ``forced_headers`` and",
            "    ``removed_headers`` arguments. ``forced_headers`` will be added to the response, ``removed_headers`` will be removed.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        wsgi_application,",
            "        executor=None,",
            "        headers=None,",
            "        forced_headers=None,",
            "        removed_headers=None,",
            "    ):",
            "        self.wsgi_application = wsgi_application",
            "        self.executor = dummy_executor if executor is None else executor",
            "",
            "        if headers is None:",
            "            headers = {}",
            "        if forced_headers is None:",
            "            forced_headers = {}",
            "        if removed_headers is None:",
            "            removed_headers = []",
            "",
            "        self.headers = headers",
            "        self.forced_headers = forced_headers",
            "        self.removed_headers = removed_headers",
            "",
            "    def __call__(self, request, body=None):",
            "        future = tornado.concurrent.Future()",
            "        IOLoop.current().spawn_callback(",
            "            self.handle_request, request, body=body, future=future",
            "        )",
            "        return future",
            "",
            "    async def handle_request(self, request, body=None, future=None):",
            "        \"\"\"",
            "        Wraps the call against the WSGI app, deriving the WSGI environment from the supplied Tornado ``HTTPServerRequest``.",
            "",
            "        :param request: the ``tornado.httpserver.HTTPServerRequest`` to derive the WSGI environment from",
            "        :param body: an optional body  to use as ``wsgi.input`` instead of ``request.body``, can be a string or a stream",
            "        :param future: a future to complete after the request has been handled",
            "        \"\"\"",
            "",
            "        data = {}",
            "        response = []",
            "",
            "        def start_response(status, response_headers, exc_info=None):",
            "            data[\"status\"] = status",
            "            data[\"headers\"] = response_headers",
            "            return response.append",
            "",
            "        try:",
            "            loop = IOLoop.current()",
            "            app_response = await loop.run_in_executor(",
            "                self.executor,",
            "                self.wsgi_application,",
            "                self.environ(request, body),",
            "                start_response,",
            "            )",
            "            try:",
            "                app_response_iter = iter(app_response)",
            "",
            "                def next_chunk():",
            "                    try:",
            "                        return next(app_response_iter)",
            "                    except StopIteration:",
            "                        return None",
            "",
            "                while True:",
            "                    chunk = await loop.run_in_executor(self.executor, next_chunk)",
            "                    if chunk is None:",
            "                        break",
            "                    response.append(chunk)",
            "            finally:",
            "                if hasattr(app_response, \"close\"):",
            "                    app_response.close()",
            "            body = b\"\".join(response)",
            "            if not data:",
            "                raise Exception(\"WSGI app did not call start_response\")",
            "",
            "            status_code_str, reason = data[\"status\"].split(\" \", 1)",
            "            status_code = int(status_code_str)",
            "            headers = data[\"headers\"]",
            "            header_set = {k.lower() for (k, v) in headers}",
            "            body = tornado.escape.utf8(body)",
            "            if status_code != 304:",
            "                if \"content-length\" not in header_set:",
            "                    headers.append((\"Content-Length\", str(len(body))))",
            "                if \"content-type\" not in header_set:",
            "                    headers.append((\"Content-Type\", \"text/html; charset=UTF-8\"))",
            "",
            "            header_set = {k.lower() for (k, v) in headers}",
            "            for header, value in self.headers.items():",
            "                if header.lower() not in header_set:",
            "                    headers.append((header, value))",
            "            for header, value in self.forced_headers.items():",
            "                headers.append((header, value))",
            "            headers = [",
            "                (header, value)",
            "                for header, value in headers",
            "                if header.lower() not in self.removed_headers",
            "            ]",
            "",
            "            start_line = tornado.httputil.ResponseStartLine(",
            "                \"HTTP/1.1\", status_code, reason",
            "            )",
            "            header_obj = tornado.httputil.HTTPHeaders()",
            "            for key, value in headers:",
            "                header_obj.add(key, value)",
            "            assert request.connection is not None",
            "            request.connection.write_headers(start_line, header_obj, chunk=body)",
            "            request.connection.finish()",
            "            self._log(status_code, request)",
            "",
            "        finally:",
            "            if future is not None:",
            "                future.set_result(None)",
            "",
            "    @staticmethod",
            "    def environ(request, body=None):",
            "        \"\"\"",
            "        Converts a ``tornado.httputil.HTTPServerRequest`` to a WSGI environment.",
            "",
            "        An optional ``body`` to be used for populating ``wsgi.input`` can be supplied (either a string or a stream). If not",
            "        supplied, ``request.body`` will be wrapped into a ``io.BytesIO`` stream and used instead.",
            "",
            "        :param request: the ``tornado.httpserver.HTTPServerRequest`` to derive the WSGI environment from",
            "        :param body: an optional body  to use as ``wsgi.input`` instead of ``request.body``, can be a string or a stream",
            "        \"\"\"",
            "        import io",
            "",
            "        from tornado.wsgi import to_wsgi_str",
            "",
            "        # determine the request_body to supply as wsgi.input",
            "        if body is not None:",
            "            if isinstance(body, (bytes, str)):",
            "                request_body = io.BytesIO(tornado.escape.utf8(body))",
            "            else:",
            "                request_body = body",
            "        else:",
            "            request_body = io.BytesIO(tornado.escape.utf8(request.body))",
            "",
            "        hostport = request.host.split(\":\")",
            "        if len(hostport) == 2:",
            "            host = hostport[0]",
            "            port = int(hostport[1])",
            "        else:",
            "            host = request.host",
            "            port = 443 if request.protocol == \"https\" else 80",
            "        environ = {",
            "            \"REQUEST_METHOD\": request.method,",
            "            \"SCRIPT_NAME\": \"\",",
            "            \"PATH_INFO\": to_wsgi_str(",
            "                tornado.escape.url_unescape(request.path, encoding=None, plus=False)",
            "            ),",
            "            \"QUERY_STRING\": request.query,",
            "            \"REMOTE_ADDR\": request.remote_ip,",
            "            \"SERVER_NAME\": host,",
            "            \"SERVER_PORT\": str(port),",
            "            \"SERVER_PROTOCOL\": request.version,",
            "            \"wsgi.version\": (1, 0),",
            "            \"wsgi.url_scheme\": request.protocol,",
            "            \"wsgi.input\": request_body,",
            "            \"wsgi.errors\": sys.stderr,",
            "            \"wsgi.multithread\": False,",
            "            \"wsgi.multiprocess\": True,",
            "            \"wsgi.run_once\": False,",
            "        }",
            "        if \"Content-Type\" in request.headers:",
            "            environ[\"CONTENT_TYPE\"] = request.headers.pop(\"Content-Type\")",
            "        if \"Content-Length\" in request.headers:",
            "            environ[\"CONTENT_LENGTH\"] = request.headers.pop(\"Content-Length\")",
            "",
            "        # remove transfer encoding header if chunked, otherwise flask wsgi entrypoint makes input empty",
            "        if (",
            "            \"Transfer-Encoding\" in request.headers",
            "            and request.headers.get(\"Transfer-Encoding\") == \"chunked\"",
            "        ):",
            "            request.headers.pop(\"Transfer-Encoding\")",
            "",
            "        for key, value in request.headers.items():",
            "            environ[\"HTTP_\" + key.replace(\"-\", \"_\").upper()] = value",
            "        return environ",
            "",
            "    def _log(self, status_code, request):",
            "        access_log = logging.getLogger(\"tornado.access\")",
            "",
            "        if status_code < 400:",
            "            log_method = access_log.info",
            "        elif status_code < 500:",
            "            log_method = access_log.warning",
            "        else:",
            "            log_method = access_log.error",
            "        request_time = 1000 * request.request_time()",
            "        summary = request.method + \" \" + request.uri + \" (\" + request.remote_ip + \")\"",
            "        log_method(\"%d %s %.2fms\", status_code, summary, request_time)",
            "",
            "",
            "# ~~ customized HTTP1Connection implementation",
            "",
            "",
            "class CustomHTTPServer(tornado.httpserver.HTTPServer):",
            "    \"\"\"",
            "    Custom implementation of ``tornado.httpserver.HTTPServer`` that allows defining max body sizes depending on path and",
            "    method.",
            "",
            "    The implementation is mostly taken from ``tornado.httpserver.HTTPServer``, the only difference is the creation",
            "    of a ``CustomHTTP1ConnectionParameters`` instance instead of ``tornado.http1connection.HTTP1ConnectionParameters``",
            "    which is supplied with the two new constructor arguments ``max_body_sizes`` and ``max_default_body_size`` and the",
            "    creation of a ``CustomHTTP1ServerConnection`` instead of a ``tornado.http1connection.HTTP1ServerConnection`` upon",
            "    connection by a client.",
            "",
            "    ``max_body_sizes`` is expected to be an iterable containing tuples of the form (method, path regex, maximum body size),",
            "    with method and path regex having to match in order for maximum body size to take affect.",
            "",
            "    ``default_max_body_size`` is the default maximum body size to apply if no specific one from ``max_body_sizes`` matches.",
            "    \"\"\"",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        pass",
            "",
            "    def initialize(self, *args, **kwargs):",
            "        default_max_body_size = kwargs.pop(\"default_max_body_size\", None)",
            "        max_body_sizes = kwargs.pop(\"max_body_sizes\", None)",
            "",
            "        tornado.httpserver.HTTPServer.initialize(self, *args, **kwargs)",
            "",
            "        additional = {",
            "            \"default_max_body_size\": default_max_body_size,",
            "            \"max_body_sizes\": max_body_sizes,",
            "        }",
            "        self.conn_params = CustomHTTP1ConnectionParameters.from_stock_params(",
            "            self.conn_params, **additional",
            "        )",
            "",
            "    def handle_stream(self, stream, address):",
            "        context = tornado.httpserver._HTTPRequestContext(",
            "            stream, address, self.protocol, self.trusted_downstream",
            "        )",
            "        conn = CustomHTTP1ServerConnection(stream, self.conn_params, context)",
            "        self._connections.add(conn)",
            "        conn.start_serving(self)",
            "",
            "",
            "class CustomHTTP1ServerConnection(tornado.http1connection.HTTP1ServerConnection):",
            "    \"\"\"",
            "    A custom implementation of ``tornado.http1connection.HTTP1ServerConnection`` which utilizes a ``CustomHTTP1Connection``",
            "    instead of a ``tornado.http1connection.HTTP1Connection`` in ``_server_request_loop``. The implementation logic is",
            "    otherwise the same as ``tornado.http1connection.HTTP1ServerConnection``.",
            "    \"\"\"",
            "",
            "    async def _server_request_loop(self, delegate):",
            "        try:",
            "            while True:",
            "                conn = CustomHTTP1Connection(",
            "                    self.stream, False, self.params, self.context",
            "                )",
            "                request_delegate = delegate.start_request(self, conn)",
            "                try:",
            "                    ret = await conn.read_response(request_delegate)",
            "                except (",
            "                    tornado.iostream.StreamClosedError,",
            "                    tornado.iostream.UnsatisfiableReadError,",
            "                    asyncio.CancelledError,",
            "                ):",
            "                    return",
            "                except tornado.http1connection._QuietException:",
            "                    # This exception was already logged.",
            "                    conn.close()",
            "                    return",
            "                except Exception:",
            "                    tornado.http1connection.gen_log.error(",
            "                        \"Uncaught exception\", exc_info=True",
            "                    )",
            "                    conn.close()",
            "                    return",
            "                if not ret:",
            "                    return",
            "                await asyncio.sleep(0)",
            "        finally:",
            "            delegate.on_close(self)",
            "",
            "",
            "class CustomHTTP1Connection(tornado.http1connection.HTTP1Connection):",
            "    \"\"\"",
            "    A custom implementation of ``tornado.http1connection.HTTP1Connection`` which upon checking the ``Content-Length`` of",
            "    the request against the configured maximum utilizes ``max_body_sizes`` and ``default_max_body_size`` as a fallback.",
            "    \"\"\"",
            "",
            "    def __init__(self, stream, is_client, params=None, context=None):",
            "        if params is None:",
            "            params = CustomHTTP1ConnectionParameters()",
            "",
            "        tornado.http1connection.HTTP1Connection.__init__(",
            "            self, stream, is_client, params=params, context=context",
            "        )",
            "",
            "        import re",
            "",
            "        self._max_body_sizes = list(",
            "            map(",
            "                lambda x: (x[0], re.compile(x[1]), x[2]),",
            "                self.params.max_body_sizes or [],",
            "            )",
            "        )",
            "        self._default_max_body_size = (",
            "            self.params.default_max_body_size or self.stream.max_buffer_size",
            "        )",
            "",
            "    def _read_body(self, code, headers, delegate):",
            "        \"\"\"",
            "        Basically the same as ``tornado.http1connection.HTTP1Connection._read_body``, but determines the maximum",
            "        content length individually for the request (utilizing ``._get_max_content_length``).",
            "",
            "        If the individual max content length is 0 or smaller no content length is checked. If the content length of the",
            "        current request exceeds the individual max content length, the request processing is aborted and an",
            "        ``HTTPInputError`` is raised.",
            "        \"\"\"",
            "        if \"Content-Length\" in headers:",
            "            if \"Transfer-Encoding\" in headers:",
            "                # Response cannot contain both Content-Length and",
            "                # Transfer-Encoding headers.",
            "                # http://tools.ietf.org/html/rfc7230#section-3.3.3",
            "                raise tornado.httputil.HTTPInputError(",
            "                    \"Response with both Transfer-Encoding and Content-Length\"",
            "                )",
            "            if \",\" in headers[\"Content-Length\"]:",
            "                # Proxies sometimes cause Content-Length headers to get",
            "                # duplicated.  If all the values are identical then we can",
            "                # use them but if they differ it's an error.",
            "                pieces = re.split(r\",\\s*\", headers[\"Content-Length\"])",
            "                if any(i != pieces[0] for i in pieces):",
            "                    raise tornado.httputil.HTTPInputError(",
            "                        \"Multiple unequal Content-Lengths: %r\" % headers[\"Content-Length\"]",
            "                    )",
            "                headers[\"Content-Length\"] = pieces[0]",
            "",
            "            try:",
            "                content_length = int(headers[\"Content-Length\"])",
            "            except ValueError:",
            "                # Handles non-integer Content-Length value.",
            "                raise tornado.httputil.HTTPInputError(",
            "                    \"Only integer Content-Length is allowed: %s\"",
            "                    % headers[\"Content-Length\"]",
            "                )",
            "",
            "            max_content_length = self._get_max_content_length(",
            "                self._request_start_line.method, self._request_start_line.path",
            "            )",
            "            if (",
            "                max_content_length is not None",
            "                and 0 <= max_content_length < content_length",
            "            ):",
            "                raise tornado.httputil.HTTPInputError(\"Content-Length too long\")",
            "        else:",
            "            content_length = None",
            "",
            "        if code == 204:",
            "            # This response code is not allowed to have a non-empty body,",
            "            # and has an implicit length of zero instead of read-until-close.",
            "            # http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.3",
            "            if \"Transfer-Encoding\" in headers or content_length not in (None, 0):",
            "                raise tornado.httputil.HTTPInputError(",
            "                    \"Response with code %d should not have body\" % code",
            "                )",
            "            content_length = 0",
            "",
            "        if content_length is not None:",
            "            return self._read_fixed_body(content_length, delegate)",
            "        if headers.get(\"Transfer-Encoding\") == \"chunked\":",
            "            return self._read_chunked_body(delegate)",
            "        if self.is_client:",
            "            return self._read_body_until_close(delegate)",
            "        return None",
            "",
            "    def _get_max_content_length(self, method, path):",
            "        \"\"\"",
            "        Gets the max content length for the given method and path. Checks whether method and path match against any",
            "        of the specific maximum content lengths supplied in ``max_body_sizes`` and returns that as the maximum content",
            "        length if available, otherwise returns ``default_max_body_size``.",
            "",
            "        :param method: method of the request to match against",
            "        :param path: path of the request to match against",
            "        :return: determine maximum content length to apply to this request, max return 0 for unlimited allowed content",
            "                 length",
            "        \"\"\"",
            "",
            "        for m, p, s in self._max_body_sizes:",
            "            if method == m and p.match(path):",
            "                return s",
            "        return self._default_max_body_size",
            "",
            "",
            "class CustomHTTP1ConnectionParameters(tornado.http1connection.HTTP1ConnectionParameters):",
            "    \"\"\"",
            "    An implementation of ``tornado.http1connection.HTTP1ConnectionParameters`` that adds two new parameters",
            "    ``max_body_sizes`` and ``default_max_body_size``.",
            "",
            "    For a description of these please see the documentation of ``CustomHTTPServer`` above.",
            "    \"\"\"",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        max_body_sizes = kwargs.pop(\"max_body_sizes\", list())",
            "        default_max_body_size = kwargs.pop(\"default_max_body_size\", None)",
            "",
            "        tornado.http1connection.HTTP1ConnectionParameters.__init__(self, *args, **kwargs)",
            "",
            "        self.max_body_sizes = max_body_sizes",
            "        self.default_max_body_size = default_max_body_size",
            "",
            "    @classmethod",
            "    def from_stock_params(cls, other, **additional):",
            "        kwargs = dict(other.__dict__)",
            "        for key, value in additional.items():",
            "            kwargs[key] = value",
            "        return cls(**kwargs)",
            "",
            "",
            "# ~~ customized large response handler",
            "",
            "",
            "class LargeResponseHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.StaticFileHandler",
            "):",
            "    \"\"\"",
            "    Customized `tornado.web.StaticFileHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#tornado.web.StaticFileHandler>`_",
            "    that allows delivery of the requested resource as attachment and access and request path validation through",
            "    optional callbacks. Note that access validation takes place before path validation.",
            "",
            "    Arguments:",
            "       path (str): The system path from which to serve files (this will be forwarded to the ``initialize`` method of",
            "           :class:``~tornado.web.StaticFileHandler``)",
            "       default_filename (str): The default filename to serve if none is explicitly specified and the request references",
            "           a subdirectory of the served path (this will be forwarded to the ``initialize`` method of",
            "           :class:``~tornado.web.StaticFileHandler`` as the ``default_filename`` keyword parameter). Defaults to ``None``.",
            "       as_attachment (bool): Whether to serve requested files with ``Content-Disposition: attachment`` header (``True``)",
            "           or not. Defaults to ``False``.",
            "       allow_client_caching (bool): Whether to allow the client to cache (by not setting any ``Cache-Control`` or",
            "           ``Expires`` headers on the response) or not.",
            "       access_validation (function): Callback to call in the ``get`` method to validate access to the resource. Will",
            "           be called with ``self.request`` as parameter which contains the full tornado request object. Should raise",
            "           a ``tornado.web.HTTPError`` if access is not allowed in which case the request will not be further processed.",
            "           Defaults to ``None`` and hence no access validation being performed.",
            "       path_validation (function): Callback to call in the ``get`` method to validate the requested path. Will be called",
            "           with the requested path as parameter. Should raise a ``tornado.web.HTTPError`` (e.g. an 404) if the requested",
            "           path does not pass validation in which case the request will not be further processed.",
            "           Defaults to ``None`` and hence no path validation being performed.",
            "       etag_generator (function): Callback to call for generating the value of the ETag response header. Will be",
            "           called with the response handler as parameter. May return ``None`` to prevent the ETag response header",
            "           from being set. If not provided the last modified time of the file in question will be used as returned",
            "           by ``get_content_version``.",
            "       name_generator (function): Callback to call for generating the value of the attachment file name header. Will be",
            "           called with the requested path as parameter.",
            "       mime_type_guesser (function): Callback to guess the mime type to use for the content type encoding of the",
            "           response. Will be called with the requested path on disk as parameter.",
            "       is_pre_compressed (bool): if the file is expected to be pre-compressed, i.e, if there is a file in the same",
            "           directory with the same name, but with '.gz' appended and gzip-encoded",
            "    \"\"\"",
            "",
            "    def initialize(",
            "        self,",
            "        path,",
            "        default_filename=None,",
            "        as_attachment=False,",
            "        allow_client_caching=True,",
            "        access_validation=None,",
            "        path_validation=None,",
            "        etag_generator=None,",
            "        name_generator=None,",
            "        mime_type_guesser=None,",
            "        is_pre_compressed=False,",
            "        stream_body=False,",
            "    ):",
            "        tornado.web.StaticFileHandler.initialize(",
            "            self, os.path.abspath(path), default_filename",
            "        )",
            "        self._as_attachment = as_attachment",
            "        self._allow_client_caching = allow_client_caching",
            "        self._access_validation = access_validation",
            "        self._path_validation = path_validation",
            "        self._etag_generator = etag_generator",
            "        self._name_generator = name_generator",
            "        self._mime_type_guesser = mime_type_guesser",
            "        self._is_pre_compressed = is_pre_compressed",
            "        self._stream_body = stream_body",
            "",
            "    def should_use_precompressed(self):",
            "        return self._is_pre_compressed and \"gzip\" in self.request.headers.get(",
            "            \"Accept-Encoding\", \"\"",
            "        )",
            "",
            "    def get(self, path, include_body=True):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "        if self._path_validation is not None:",
            "            self._path_validation(path)",
            "",
            "        if \"cookie\" in self.request.arguments:",
            "            self.set_cookie(self.request.arguments[\"cookie\"][0], \"true\", path=\"/\")",
            "",
            "        if self.should_use_precompressed():",
            "            if os.path.exists(os.path.join(self.root, path + \".gz\")):",
            "                self.set_header(\"Content-Encoding\", \"gzip\")",
            "                path = path + \".gz\"",
            "            else:",
            "                logging.getLogger(__name__).warning(",
            "                    \"Precompressed assets expected but {}.gz does not exist \"",
            "                    \"in {}, using plain file instead.\".format(path, self.root)",
            "                )",
            "",
            "        if self._stream_body:",
            "            return self.streamed_get(path, include_body=include_body)",
            "        else:",
            "            return tornado.web.StaticFileHandler.get(",
            "                self, path, include_body=include_body",
            "            )",
            "",
            "    @tornado.gen.coroutine",
            "    def streamed_get(self, path, include_body=True):",
            "        \"\"\"",
            "        Version of StaticFileHandler.get that doesn't support ranges or ETag but streams the content. Helpful for files",
            "        that might still change while being transmitted (e.g. log files)",
            "        \"\"\"",
            "",
            "        # Set up our path instance variables.",
            "        self.path = self.parse_url_path(path)",
            "        del path  # make sure we don't refer to path instead of self.path again",
            "        absolute_path = self.get_absolute_path(self.root, self.path)",
            "        self.absolute_path = self.validate_absolute_path(self.root, absolute_path)",
            "        if self.absolute_path is None:",
            "            return",
            "",
            "        content_type = self.get_content_type()",
            "        if content_type:",
            "            self.set_header(\"Content-Type\", content_type)",
            "        self.set_extra_headers(self.path)",
            "",
            "        if include_body:",
            "            content = self.get_content(self.absolute_path)",
            "            if isinstance(content, bytes):",
            "                content = [content]",
            "            for chunk in content:",
            "                try:",
            "                    self.write(chunk)",
            "                    yield self.flush()",
            "                except tornado.iostream.StreamClosedError:",
            "                    return",
            "        else:",
            "            assert self.request.method == \"HEAD\"",
            "",
            "    def set_extra_headers(self, path):",
            "        if self._as_attachment:",
            "            filename = None",
            "            if callable(self._name_generator):",
            "                filename = self._name_generator(path)",
            "            if filename is None:",
            "                filename = os.path.basename(path)",
            "",
            "            filename = tornado.escape.url_escape(filename, plus=False)",
            "            self.set_header(",
            "                \"Content-Disposition\",",
            "                \"attachment; filename=\\\"{}\\\"; filename*=UTF-8''{}\".format(",
            "                    filename, filename",
            "                ),",
            "            )",
            "",
            "        if not self._allow_client_caching:",
            "            self.set_header(\"Cache-Control\", \"max-age=0, must-revalidate, private\")",
            "            self.set_header(\"Expires\", \"-1\")",
            "",
            "        self.set_header(\"X-Original-Content-Length\", str(self.get_content_size()))",
            "",
            "    @property",
            "    def original_absolute_path(self):",
            "        \"\"\"The path of the uncompressed file corresponding to the compressed file\"\"\"",
            "        if self._is_pre_compressed:",
            "            return self.absolute_path.rstrip(\".gz\")",
            "        return self.absolute_path",
            "",
            "    def compute_etag(self):",
            "        if self._etag_generator is not None:",
            "            etag = self._etag_generator(self)",
            "        else:",
            "            etag = str(self.get_content_version(self.absolute_path))",
            "",
            "        if not etag.endswith('\"'):",
            "            etag = f'\"{etag}\"'",
            "        return etag",
            "",
            "    # noinspection PyAttributeOutsideInit",
            "    def get_content_type(self):",
            "        if self._mime_type_guesser is not None:",
            "            type = self._mime_type_guesser(self.original_absolute_path)",
            "            if type is not None:",
            "                return type",
            "",
            "        correct_absolute_path = None",
            "        try:",
            "            # reset self.absolute_path temporarily",
            "            if self.should_use_precompressed():",
            "                correct_absolute_path = self.absolute_path",
            "                self.absolute_path = self.original_absolute_path",
            "            return tornado.web.StaticFileHandler.get_content_type(self)",
            "        finally:",
            "            # restore self.absolute_path",
            "            if self.should_use_precompressed() and correct_absolute_path is not None:",
            "                self.absolute_path = correct_absolute_path",
            "",
            "    @classmethod",
            "    def get_content_version(cls, abspath):",
            "        import os",
            "        import stat",
            "",
            "        return os.stat(abspath)[stat.ST_MTIME]",
            "",
            "",
            "##~~ URL Forward Handler for forwarding requests to a preconfigured static URL",
            "",
            "",
            "class UrlProxyHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.RequestHandler",
            "):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ that proxies",
            "    requests to a preconfigured url and returns the response. Allows delivery of the requested content as attachment",
            "    and access validation through an optional callback.",
            "",
            "    This will use `tornado.httpclient.AsyncHTTPClient <http://tornado.readthedocs.org/en/branch4.0/httpclient.html#tornado.httpclient.AsyncHTTPClient>`_",
            "    for making the request to the configured endpoint and return the body of the client response with the status code",
            "    from the client response and the following headers:",
            "",
            "      * ``Date``, ``Cache-Control``, ``Expires``, ``ETag``, ``Server``, ``Content-Type`` and ``Location`` will be copied over.",
            "      * If ``as_attachment`` is set to True, ``Content-Disposition`` will be set to ``attachment``. If ``basename`` is",
            "        set including the attachment's ``filename`` attribute will be set to the base name followed by the extension",
            "        guessed based on the MIME type from the ``Content-Type`` header of the response. If no extension can be guessed",
            "        no ``filename`` attribute will be set.",
            "",
            "    Arguments:",
            "       url (str): URL to forward any requests to. A 404 response will be returned if this is not set. Defaults to ``None``.",
            "       as_attachment (bool): Whether to serve files with ``Content-Disposition: attachment`` header (``True``)",
            "           or not. Defaults to ``False``.",
            "       basename (str): base name of file names to return as part of the attachment header, see above. Defaults to ``None``.",
            "       access_validation (function): Callback to call in the ``get`` method to validate access to the resource. Will",
            "           be called with ``self.request`` as parameter which contains the full tornado request object. Should raise",
            "           a ``tornado.web.HTTPError`` if access is not allowed in which case the request will not be further processed.",
            "           Defaults to ``None`` and hence no access validation being performed.",
            "    \"\"\"",
            "",
            "    def initialize(",
            "        self, url=None, as_attachment=False, basename=None, access_validation=None",
            "    ):",
            "        tornado.web.RequestHandler.initialize(self)",
            "        self._url = url",
            "        self._as_attachment = as_attachment",
            "        self._basename = basename",
            "        self._access_validation = access_validation",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "",
            "        if self._url is None:",
            "            raise tornado.web.HTTPError(404)",
            "",
            "        client = tornado.httpclient.AsyncHTTPClient()",
            "        r = tornado.httpclient.HTTPRequest(",
            "            url=self._url,",
            "            method=self.request.method,",
            "            body=self.request.body,",
            "            headers=self.request.headers,",
            "            follow_redirects=False,",
            "            allow_nonstandard_methods=True,",
            "        )",
            "",
            "        try:",
            "            return client.fetch(r, self.handle_response)",
            "        except tornado.web.HTTPError as e:",
            "            if hasattr(e, \"response\") and e.response:",
            "                self.handle_response(e.response)",
            "            else:",
            "                raise tornado.web.HTTPError(500)",
            "",
            "    def handle_response(self, response):",
            "        if response.error and not isinstance(response.error, tornado.web.HTTPError):",
            "            raise tornado.web.HTTPError(500)",
            "",
            "        filename = None",
            "",
            "        self.set_status(response.code)",
            "        for name in (",
            "            \"Date\",",
            "            \"Cache-Control\",",
            "            \"Server\",",
            "            \"Content-Type\",",
            "            \"Location\",",
            "            \"Expires\",",
            "            \"ETag\",",
            "        ):",
            "            value = response.headers.get(name)",
            "            if value:",
            "                self.set_header(name, value)",
            "",
            "                if name == \"Content-Type\":",
            "                    filename = self.get_filename(value)",
            "",
            "        if self._as_attachment:",
            "            if filename is not None:",
            "                self.set_header(",
            "                    \"Content-Disposition\", \"attachment; filename=%s\" % filename",
            "                )",
            "            else:",
            "                self.set_header(\"Content-Disposition\", \"attachment\")",
            "",
            "        if response.body:",
            "            self.write(response.body)",
            "        self.finish()",
            "",
            "    def get_filename(self, content_type):",
            "        if not self._basename:",
            "            return None",
            "",
            "        typeValue = list(x.strip() for x in content_type.split(\";\"))",
            "        if len(typeValue) == 0:",
            "            return None",
            "",
            "        extension = mimetypes.guess_extension(typeValue[0])",
            "        if not extension:",
            "            return None",
            "",
            "        return f\"{self._basename}{extension}\"",
            "",
            "",
            "class StaticDataHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.RequestHandler",
            "):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ that returns",
            "    static ``data`` of a configured ``content_type``.",
            "",
            "    Arguments:",
            "       data (str): The data with which to respond",
            "       content_type (str): The content type with which to respond. Defaults to ``text/plain``",
            "    \"\"\"",
            "",
            "    def initialize(self, data=\"\", content_type=\"text/plain\"):",
            "        self.data = data",
            "        self.content_type = content_type",
            "",
            "    def get(self, *args, **kwargs):",
            "        self.set_status(200)",
            "        self.set_header(\"Content-Type\", self.content_type)",
            "        self.write(self.data)",
            "        self.flush()",
            "        self.finish()",
            "",
            "",
            "class GeneratingDataHandler(",
            "    RequestlessExceptionLoggingMixin, CorsSupportMixin, tornado.web.RequestHandler",
            "):",
            "    \"\"\"",
            "    A `RequestHandler` that generates data from a generator function and returns it to the client.",
            "",
            "    Arguments:",
            "        generator (function): A generator function that returns the data to be written to the client. The function",
            "            will be called without any parameters.",
            "        content_type (str): The content type with which to respond. Defaults to `text/plain`",
            "        as_attachment (bool | str): Whether to serve files with `Content-Disposition: attachment` header (`True`)",
            "            or not. Defaults to `False`. If a string is given it will be used as the filename of the attachment.",
            "        access_validation (function): Callback to call in the `get` method to validate access to the resource. Will",
            "            be called with `self.request` as parameter which contains the full tornado request object. Should raise",
            "            a `tornado.web.HTTPError` if access is not allowed in which case the request will not be further processed.",
            "            Defaults to `None` and hence no access validation being performed.",
            "    \"\"\"",
            "",
            "    def initialize(",
            "        self,",
            "        generator=None,",
            "        content_type=\"text/plain\",",
            "        as_attachment=False,",
            "        access_validation=None,",
            "    ):",
            "        super().initialize()",
            "        self._generator = generator",
            "        self._content_type = content_type",
            "        self._as_attachment = as_attachment",
            "        self._access_validation = access_validation",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "",
            "        self.set_status(200)",
            "        self.set_header(\"Content-Type\", self._content_type)",
            "        self.set_content_disposition()",
            "        for data in self._generator():",
            "            self.write(data)",
            "            yield self.flush()",
            "        self.finish()",
            "",
            "    def set_content_disposition(self):",
            "        if self._as_attachment:",
            "            if isinstance(self._as_attachment, str):",
            "                self.set_header(",
            "                    \"Content-Disposition\", f\"attachment; filename={self._as_attachment}\"",
            "                )",
            "            else:",
            "                self.set_header(\"Content-Disposition\", \"attachment\")",
            "",
            "",
            "class WebcamSnapshotHandler(GeneratingDataHandler):",
            "    \"\"\"",
            "    `GeneratingDataHandler` that returns a snapshot from the configured webcam.",
            "",
            "    Arguments:",
            "        as_attachment (bool | str): Whether to serve files with `Content-Disposition: attachment` header (`True`)",
            "            or not. Defaults to `False`. If a string is given it will be used as the filename of the attachment.",
            "        access_validation (function): Callback to call in the `get` method to validate access to the resource. Will",
            "            be called with `self.request` as parameter which contains the full tornado request object. Should raise",
            "            a `tornado.web.HTTPError` if access is not allowed in which case the request will not be further processed.",
            "            Defaults to `None` and hence no access validation being performed.",
            "    \"\"\"",
            "",
            "    def initialize(self, as_attachment=False, access_validation=None):",
            "        super().initialize(",
            "            content_type=\"image/jpeg\",",
            "            as_attachment=as_attachment,",
            "            access_validation=access_validation,",
            "        )",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validation is not None:",
            "            self._access_validation(self.request)",
            "",
            "        import functools",
            "",
            "        from octoprint.webcams import get_snapshot_webcam",
            "",
            "        webcam = get_snapshot_webcam()",
            "        if not webcam:",
            "            raise tornado.web.HTTPError(404)",
            "",
            "        generator = functools.partial(",
            "            webcam.providerPlugin.take_webcam_snapshot, webcam.config.name",
            "        )",
            "",
            "        self.set_status(200)",
            "        self.set_header(\"Content-Type\", self._content_type)",
            "        self.set_content_disposition()",
            "        for data in generator():",
            "            self.write(data)",
            "            yield self.flush()",
            "        self.finish()",
            "",
            "",
            "class DeprecatedEndpointHandler(CorsSupportMixin, tornado.web.RequestHandler):",
            "    \"\"\"",
            "    `tornado.web.RequestHandler <http://tornado.readthedocs.org/en/branch4.0/web.html#request-handlers>`_ that redirects",
            "    to another ``url`` and logs a deprecation warning.",
            "",
            "    Arguments:",
            "       url (str): URL to which to redirect",
            "    \"\"\"",
            "",
            "    def initialize(self, url):",
            "        self._url = url",
            "        self._logger = logging.getLogger(__name__)",
            "",
            "    def _handle_method(self, *args, **kwargs):",
            "        to_url = self._url.format(*args)",
            "        self._logger.info(",
            "            f\"Redirecting deprecated endpoint {self.request.path} to {to_url}\"",
            "        )",
            "        self.redirect(to_url, permanent=True)",
            "",
            "    # make all http methods trigger _handle_method",
            "    get = _handle_method",
            "    post = _handle_method",
            "    put = _handle_method",
            "    patch = _handle_method",
            "    delete = _handle_method",
            "    head = _handle_method",
            "    options = _handle_method",
            "",
            "",
            "class StaticZipBundleHandler(CorsSupportMixin, tornado.web.RequestHandler):",
            "    def initialize(",
            "        self,",
            "        files=None,",
            "        as_attachment=True,",
            "        attachment_name=None,",
            "        access_validation=None,",
            "        compress=False,",
            "    ):",
            "        if files is None:",
            "            files = []",
            "        if as_attachment and not attachment_name:",
            "            raise ValueError(\"attachment name must be set if as_attachment is True\")",
            "",
            "        self._files = files",
            "        self._as_attachment = as_attachment",
            "        self._attachment_name = attachment_name",
            "        self._access_validator = access_validation",
            "        self._compress = compress",
            "",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "        return self.stream_zip(self._files)",
            "",
            "    def get_attachment_name(self):",
            "        return self._attachment_name",
            "",
            "    def normalize_files(self, files):",
            "        result = []",
            "        for f in files:",
            "            if isinstance(f, str):",
            "                result.append({\"path\": f})",
            "            elif isinstance(f, dict) and (\"path\" in f or \"iter\" in f or \"content\" in f):",
            "                result.append(f)",
            "        return result",
            "",
            "    @tornado.gen.coroutine",
            "    def stream_zip(self, files):",
            "        self.set_header(\"Content-Type\", \"application/zip\")",
            "        if self._as_attachment:",
            "            self.set_header(",
            "                \"Content-Disposition\",",
            "                f'attachment; filename=\"{self.get_attachment_name()}\"',",
            "            )",
            "",
            "        z = ZipStream(sized=True)",
            "        if self._compress:",
            "            try:",
            "                z = ZipStream(compress_type=ZIP_DEFLATED)",
            "            except RuntimeError:",
            "                # no zlib support",
            "                pass",
            "",
            "        for f in self.normalize_files(files):",
            "            name = f.get(\"name\")",
            "            path = f.get(\"path\")",
            "            data = f.get(\"iter\") or f.get(\"content\")",
            "",
            "            if path:",
            "                z.add_path(path, arcname=name)",
            "            elif data and name:",
            "                z.add(data, arcname=name)",
            "",
            "        if z.sized:",
            "            self.set_header(\"Content-Length\", len(z))",
            "        self.set_header(\"Last-Modified\", z.last_modified)",
            "",
            "        for chunk in z:",
            "            try:",
            "                self.write(chunk)",
            "                yield self.flush()",
            "            except tornado.iostream.StreamClosedError:",
            "                return",
            "",
            "",
            "class DynamicZipBundleHandler(StaticZipBundleHandler):",
            "    # noinspection PyMethodOverriding",
            "    def initialize(",
            "        self,",
            "        path_validation=None,",
            "        path_processor=None,",
            "        as_attachment=True,",
            "        attachment_name=None,",
            "        access_validation=None,",
            "        compress=False,",
            "    ):",
            "        if as_attachment and not attachment_name:",
            "            raise ValueError(\"attachment name must be set if as_attachment is True\")",
            "",
            "        self._path_validator = path_validation",
            "        self._path_processor = path_processor",
            "        self._as_attachment = as_attachment",
            "        self._attachment_name = attachment_name",
            "        self._access_validator = access_validation",
            "        self._compress = compress",
            "",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "",
            "        files = list(",
            "            map(octoprint.util.to_unicode, self.request.query_arguments.get(\"files\", []))",
            "        )",
            "        return self._get_files_zip(files)",
            "",
            "    def post(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "",
            "        import json",
            "",
            "        content_type = self.request.headers.get(\"Content-Type\", \"\")",
            "        try:",
            "            if \"application/json\" in content_type:",
            "                data = json.loads(self.request.body)",
            "            else:",
            "                data = self.request.body_arguments",
            "        except Exception:",
            "            raise tornado.web.HTTPError(400)",
            "",
            "        return self._get_files_zip(",
            "            list(map(octoprint.util.to_unicode, data.get(\"files\", [])))",
            "        )",
            "",
            "    def _get_files_zip(self, files):",
            "        files = self.normalize_files(files)",
            "        if not files:",
            "            raise tornado.web.HTTPError(400)",
            "",
            "        for f in files:",
            "            if \"path\" in f:",
            "                if callable(self._path_processor):",
            "                    path = self._path_processor(f[\"path\"])",
            "                    if isinstance(path, tuple):",
            "                        f[\"name\"], f[\"path\"] = path",
            "                    else:",
            "                        f[\"path\"] = path",
            "                self._path_validator(f[\"path\"])",
            "",
            "        return self.stream_zip(files)",
            "",
            "",
            "class SystemInfoBundleHandler(CorsSupportMixin, tornado.web.RequestHandler):",
            "    # noinspection PyMethodOverriding",
            "    def initialize(self, access_validation=None):",
            "        self._access_validator = access_validation",
            "",
            "    @tornado.gen.coroutine",
            "    def get(self, *args, **kwargs):",
            "        if self._access_validator is not None:",
            "            self._access_validator(self.request)",
            "",
            "        from octoprint.cli.systeminfo import (",
            "            get_systeminfo,",
            "            get_systeminfo_bundle,",
            "            get_systeminfo_bundle_name,",
            "        )",
            "        from octoprint.server import (",
            "            connectivityChecker,",
            "            environmentDetector,",
            "            pluginManager,",
            "            printer,",
            "            safe_mode,",
            "        )",
            "        from octoprint.settings import settings",
            "",
            "        systeminfo = get_systeminfo(",
            "            environmentDetector,",
            "            connectivityChecker,",
            "            settings(),",
            "            {",
            "                \"browser.user_agent\": self.request.headers.get(\"User-Agent\"),",
            "                \"octoprint.safe_mode\": safe_mode is not None,",
            "                \"systeminfo.generator\": \"zipapi\",",
            "            },",
            "        )",
            "",
            "        z = get_systeminfo_bundle(",
            "            systeminfo,",
            "            settings().getBaseFolder(\"logs\"),",
            "            printer=printer,",
            "            plugin_manager=pluginManager,",
            "        )",
            "",
            "        self.set_header(\"Content-Type\", \"application/zip\")",
            "        self.set_header(",
            "            \"Content-Disposition\",",
            "            f'attachment; filename=\"{get_systeminfo_bundle_name()}\"',",
            "        )",
            "        if z.sized:",
            "            self.set_header(\"Content-Length\", len(z))",
            "        self.set_header(\"Last-Modified\", z.last_modified)",
            "",
            "        for chunk in z:",
            "            try:",
            "                self.write(chunk)",
            "                yield self.flush()",
            "            except tornado.iostream.StreamClosedError:",
            "                return",
            "",
            "    def get_attachment_name(self):",
            "        import time",
            "",
            "        return \"octoprint-systeminfo-{}.zip\".format(time.strftime(\"%Y%m%d%H%M%S\"))",
            "",
            "",
            "class GlobalHeaderTransform(tornado.web.OutputTransform):",
            "    HEADERS = {}",
            "    FORCED_HEADERS = {}",
            "    REMOVED_HEADERS = []",
            "",
            "    @classmethod",
            "    def for_headers(cls, name, headers=None, forced_headers=None, removed_headers=None):",
            "        if headers is None:",
            "            headers = {}",
            "        if forced_headers is None:",
            "            forced_headers = {}",
            "        if removed_headers is None:",
            "            removed_headers = []",
            "",
            "        return type(",
            "            name,",
            "            (GlobalHeaderTransform,),",
            "            {",
            "                \"HEADERS\": headers,",
            "                \"FORCED_HEADERS\": forced_headers,",
            "                \"REMOVED_HEADERS\": removed_headers,",
            "            },",
            "        )",
            "",
            "    def __init__(self, request):",
            "        tornado.web.OutputTransform.__init__(self, request)",
            "",
            "    def transform_first_chunk(self, status_code, headers, chunk, finishing):",
            "        for header, value in self.HEADERS.items():",
            "            if header not in headers:",
            "                headers[header] = value",
            "        for header, value in self.FORCED_HEADERS.items():",
            "            headers[header] = value",
            "        for header in self.REMOVED_HEADERS:",
            "            del headers[header]",
            "        return status_code, headers, chunk",
            "",
            "",
            "# ~~ Factory method for creating Flask access validation wrappers from the Tornado request context",
            "",
            "",
            "def access_validation_factory(app, validator, *args):",
            "    \"\"\"",
            "    Creates an access validation wrapper using the supplied validator.",
            "",
            "    :param validator: the access validator to use inside the validation wrapper",
            "    :return: an access validator taking a request as parameter and performing the request validation",
            "    \"\"\"",
            "",
            "    # noinspection PyProtectedMember",
            "    def f(request):",
            "        \"\"\"",
            "        Creates a custom wsgi and Flask request context in order to be able to process user information",
            "        stored in the current session.",
            "",
            "        :param request: The Tornado request for which to create the environment and context",
            "        \"\"\"",
            "        import flask",
            "        from werkzeug.exceptions import HTTPException",
            "",
            "        wsgi_environ = WsgiInputContainer.environ(request)",
            "        with app.request_context(wsgi_environ):",
            "            session = app.session_interface.open_session(app, flask.request)",
            "            user_id = session.get(\"_user_id\")",
            "            user = None",
            "",
            "            # Yes, using protected methods is ugly. But these used to be publicly available in former versions",
            "            # of flask-login, there are no replacements, and seeing them renamed & hidden in a minor version release",
            "            # without any mention in the changelog means the public API ain't strictly stable either, so we might",
            "            # as well make our life easier here and just use them...",
            "            if user_id is not None and app.login_manager._user_callback is not None:",
            "                user = app.login_manager._user_callback(user_id)",
            "            app.login_manager._update_request_context_with_user(user)",
            "",
            "            try:",
            "                validator(flask.request, *args)",
            "            except HTTPException as e:",
            "                raise tornado.web.HTTPError(e.code)",
            "",
            "    return f",
            "",
            "",
            "def path_validation_factory(path_filter, status_code=404):",
            "    \"\"\"",
            "    Creates a request path validation wrapper returning the defined status code if the supplied path_filter returns False.",
            "",
            "    :param path_filter: the path filter to use on the requested path, should return False for requests that should",
            "       be responded with the provided error code.",
            "    :return: a request path validator taking a request path as parameter and performing the request validation",
            "    \"\"\"",
            "",
            "    def f(path):",
            "        if not path_filter(path):",
            "            raise tornado.web.HTTPError(status_code)",
            "",
            "    return f",
            "",
            "",
            "def validation_chain(*validators):",
            "    def f(request):",
            "        for validator in validators:",
            "            validator(request)",
            "",
            "    return f"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "cbor2._decoder"
        ]
    }
}