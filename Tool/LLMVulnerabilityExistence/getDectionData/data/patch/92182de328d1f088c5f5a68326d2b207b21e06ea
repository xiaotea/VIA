{
    "aodh/api/controllers/v2/alarms.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": 269,
                "PatchRowcode": "             self.time_constraints = [AlarmTimeConstraint(**tc)"
            },
            "1": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": 270,
                "PatchRowcode": "                                      for tc in time_constraints]"
            },
            "2": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": 271,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+    @classmethod"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 273,
                "PatchRowcode": "+    def from_db_model_scrubbed(cls, m):"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 274,
                "PatchRowcode": "+        # Return an Alarm from a DB model with trust IDs scrubbed from actions"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 275,
                "PatchRowcode": "+        data = m.as_dict()"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 276,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 277,
                "PatchRowcode": "+        for field in ('ok_actions', 'alarm_actions',"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 278,
                "PatchRowcode": "+                      'insufficient_data_actions'):"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 279,
                "PatchRowcode": "+            if data.get(field) is not None:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 280,
                "PatchRowcode": "+                data[field] = [cls._scrub_action_url(action)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 281,
                "PatchRowcode": "+                               for action in data[field]]"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 282,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 283,
                "PatchRowcode": "+        return cls(**data)"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 284,
                "PatchRowcode": "+"
            },
            "16": {
                "beforePatchRowNumber": 272,
                "afterPatchRowNumber": 285,
                "PatchRowcode": "     @staticmethod"
            },
            "17": {
                "beforePatchRowNumber": 273,
                "afterPatchRowNumber": 286,
                "PatchRowcode": "     def validate(alarm):"
            },
            "18": {
                "beforePatchRowNumber": 274,
                "afterPatchRowNumber": 287,
                "PatchRowcode": "         Alarm.check_rule(alarm)"
            },
            "19": {
                "beforePatchRowNumber": 380,
                "afterPatchRowNumber": 393,
                "PatchRowcode": "     def _is_trust_url(url):"
            },
            "20": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 394,
                "PatchRowcode": "         return url.scheme.startswith('trust+')"
            },
            "21": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": 395,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+    @staticmethod"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+    def _scrub_action_url(action):"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 398,
                "PatchRowcode": "+        \"\"\"Remove trust ID from a URL.\"\"\""
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 399,
                "PatchRowcode": "+        url = netutils.urlsplit(action)"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 400,
                "PatchRowcode": "+        if Alarm._is_trust_url(url):"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 401,
                "PatchRowcode": "+            netloc = url.netloc.rsplit('@', 1)[-1]"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 402,
                "PatchRowcode": "+            url = urlparse.SplitResult(url.scheme, netloc,"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 403,
                "PatchRowcode": "+                                       url.path, url.query,"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 404,
                "PatchRowcode": "+                                       url.fragment)"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 405,
                "PatchRowcode": "+        return url.geturl()"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 406,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": 407,
                "PatchRowcode": "     def _get_existing_trust_ids(self):"
            },
            "34": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 408,
                "PatchRowcode": "         for action in itertools.chain(self.ok_actions or [],"
            },
            "35": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 409,
                "PatchRowcode": "                                       self.alarm_actions or [],"
            },
            "36": {
                "beforePatchRowNumber": 590,
                "afterPatchRowNumber": 614,
                "PatchRowcode": "     @wsme_pecan.wsexpose(Alarm)"
            },
            "37": {
                "beforePatchRowNumber": 591,
                "afterPatchRowNumber": 615,
                "PatchRowcode": "     def get(self):"
            },
            "38": {
                "beforePatchRowNumber": 592,
                "afterPatchRowNumber": 616,
                "PatchRowcode": "         \"\"\"Return this alarm.\"\"\""
            },
            "39": {
                "beforePatchRowNumber": 593,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return Alarm.from_db_model(self._enforce_rbac('get_alarm'))"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 617,
                "PatchRowcode": "+        return Alarm.from_db_model_scrubbed(self._enforce_rbac('get_alarm'))"
            },
            "41": {
                "beforePatchRowNumber": 594,
                "afterPatchRowNumber": 618,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": 595,
                "afterPatchRowNumber": 619,
                "PatchRowcode": "     @wsme_pecan.wsexpose(Alarm, body=Alarm)"
            },
            "43": {
                "beforePatchRowNumber": 596,
                "afterPatchRowNumber": 620,
                "PatchRowcode": "     def put(self, data):"
            },
            "44": {
                "beforePatchRowNumber": 642,
                "afterPatchRowNumber": 666,
                "PatchRowcode": "                       if v != old_alarm[k] and k not in"
            },
            "45": {
                "beforePatchRowNumber": 643,
                "afterPatchRowNumber": 667,
                "PatchRowcode": "                       ['timestamp', 'state_timestamp'])"
            },
            "46": {
                "beforePatchRowNumber": 644,
                "afterPatchRowNumber": 668,
                "PatchRowcode": "         self._record_change(change, now, on_behalf_of=alarm.project_id)"
            },
            "47": {
                "beforePatchRowNumber": 645,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return Alarm.from_db_model(alarm)"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 669,
                "PatchRowcode": "+        return Alarm.from_db_model_scrubbed(alarm)"
            },
            "49": {
                "beforePatchRowNumber": 646,
                "afterPatchRowNumber": 670,
                "PatchRowcode": " "
            },
            "50": {
                "beforePatchRowNumber": 647,
                "afterPatchRowNumber": 671,
                "PatchRowcode": "     @wsme_pecan.wsexpose(None, status_code=204)"
            },
            "51": {
                "beforePatchRowNumber": 648,
                "afterPatchRowNumber": 672,
                "PatchRowcode": "     def delete(self):"
            },
            "52": {
                "beforePatchRowNumber": 805,
                "afterPatchRowNumber": 829,
                "PatchRowcode": "         alarm = conn.create_alarm(alarm_in)"
            },
            "53": {
                "beforePatchRowNumber": 806,
                "afterPatchRowNumber": 830,
                "PatchRowcode": "         self._record_creation(conn, change, alarm.alarm_id, now)"
            },
            "54": {
                "beforePatchRowNumber": 807,
                "afterPatchRowNumber": 831,
                "PatchRowcode": "         v2_utils.set_resp_location_hdr(\"/alarms/\" + alarm.alarm_id)"
            },
            "55": {
                "beforePatchRowNumber": 808,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return Alarm.from_db_model(alarm)"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 832,
                "PatchRowcode": "+        return Alarm.from_db_model_scrubbed(alarm)"
            },
            "57": {
                "beforePatchRowNumber": 809,
                "afterPatchRowNumber": 833,
                "PatchRowcode": " "
            },
            "58": {
                "beforePatchRowNumber": 810,
                "afterPatchRowNumber": 834,
                "PatchRowcode": "     @wsme_pecan.wsexpose([Alarm], [base.Query], [str], int, str)"
            },
            "59": {
                "beforePatchRowNumber": 811,
                "afterPatchRowNumber": 835,
                "PatchRowcode": "     def get_all(self, q=None, sort=None, limit=None, marker=None):"
            },
            "60": {
                "beforePatchRowNumber": 829,
                "afterPatchRowNumber": 853,
                "PatchRowcode": "         if sort or limit or marker:"
            },
            "61": {
                "beforePatchRowNumber": 830,
                "afterPatchRowNumber": 854,
                "PatchRowcode": "             kwargs['pagination'] = v2_utils.get_pagination_options("
            },
            "62": {
                "beforePatchRowNumber": 831,
                "afterPatchRowNumber": 855,
                "PatchRowcode": "                 sort, limit, marker, models.Alarm)"
            },
            "63": {
                "beforePatchRowNumber": 832,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return [Alarm.from_db_model(m)"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 856,
                "PatchRowcode": "+        return [Alarm.from_db_model_scrubbed(m)"
            },
            "65": {
                "beforePatchRowNumber": 833,
                "afterPatchRowNumber": 857,
                "PatchRowcode": "                 for m in pecan.request.storage.get_alarms(**kwargs)]"
            }
        },
        "frontPatchFile": [
            "#",
            "# Copyright 2012 New Dream Network, LLC (DreamHost)",
            "# Copyright 2013 IBM Corp.",
            "# Copyright 2013 eNovance <licensing@enovance.com>",
            "# Copyright Ericsson AB 2013. All rights reserved",
            "# Copyright 2014 Hewlett-Packard Company",
            "# Copyright 2015 Huawei Technologies Co., Ltd.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "",
            "import datetime",
            "import itertools",
            "import json",
            "",
            "import croniter",
            "from oslo_config import cfg",
            "from oslo_log import log",
            "from oslo_utils import netutils",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import pecan",
            "from pecan import rest",
            "import pytz",
            "import six",
            "from six.moves.urllib import parse as urlparse",
            "from stevedore import extension",
            "import wsme",
            "from wsme import types as wtypes",
            "import wsmeext.pecan as wsme_pecan",
            "",
            "import aodh",
            "from aodh.api.controllers.v2 import base",
            "from aodh.api.controllers.v2 import utils as v2_utils",
            "from aodh.api import rbac",
            "from aodh.i18n import _",
            "from aodh import keystone_client",
            "from aodh import messaging",
            "from aodh import notifier",
            "from aodh.storage import models",
            "",
            "LOG = log.getLogger(__name__)",
            "",
            "",
            "ALARM_API_OPTS = [",
            "    cfg.IntOpt('user_alarm_quota',",
            "               deprecated_group='DEFAULT',",
            "               help='Maximum number of alarms defined for a user.'",
            "               ),",
            "    cfg.IntOpt('project_alarm_quota',",
            "               deprecated_group='DEFAULT',",
            "               help='Maximum number of alarms defined for a project.'",
            "               ),",
            "    cfg.IntOpt('alarm_max_actions',",
            "               default=-1,",
            "               deprecated_group='DEFAULT',",
            "               help='Maximum count of actions for each state of an alarm, '",
            "                    'non-positive number means no limit.'),",
            "]",
            "",
            "state_kind = [\"ok\", \"alarm\", \"insufficient data\"]",
            "state_kind_enum = wtypes.Enum(str, *state_kind)",
            "severity_kind = [\"low\", \"moderate\", \"critical\"]",
            "severity_kind_enum = wtypes.Enum(str, *severity_kind)",
            "",
            "ALARM_REASON_DEFAULT = \"Not evaluated yet\"",
            "ALARM_REASON_MANUAL = \"Manually set via API\"",
            "",
            "",
            "class OverQuota(base.ClientSideError):",
            "    def __init__(self, data):",
            "        d = {",
            "            'u': data.user_id,",
            "            'p': data.project_id",
            "        }",
            "        super(OverQuota, self).__init__(",
            "            _(\"Alarm quota exceeded for user %(u)s on project %(p)s\") % d,",
            "            status_code=403)",
            "",
            "",
            "def is_over_quota(conn, project_id, user_id):",
            "    \"\"\"Returns False if an alarm is within the set quotas, True otherwise.",
            "",
            "    :param conn: a backend connection object",
            "    :param project_id: the ID of the project setting the alarm",
            "    :param user_id: the ID of the user setting the alarm",
            "    \"\"\"",
            "",
            "    over_quota = False",
            "",
            "    # Start by checking for user quota",
            "    user_alarm_quota = pecan.request.cfg.api.user_alarm_quota",
            "    if user_alarm_quota is not None:",
            "        user_alarms = list(conn.get_alarms(user=user_id))",
            "        over_quota = len(user_alarms) >= user_alarm_quota",
            "",
            "    # If the user quota isn't reached, we check for the project quota",
            "    if not over_quota:",
            "        project_alarm_quota = pecan.request.cfg.api.project_alarm_quota",
            "        if project_alarm_quota is not None:",
            "            project_alarms = list(conn.get_alarms(project=project_id))",
            "            over_quota = len(project_alarms) >= project_alarm_quota",
            "",
            "    return over_quota",
            "",
            "",
            "class CronType(wtypes.UserType):",
            "    \"\"\"A user type that represents a cron format.\"\"\"",
            "    basetype = six.string_types",
            "    name = 'cron'",
            "",
            "    @staticmethod",
            "    def validate(value):",
            "        # raises ValueError if invalid",
            "        croniter.croniter(value)",
            "        return value",
            "",
            "",
            "class AlarmTimeConstraint(base.Base):",
            "    \"\"\"Representation of a time constraint on an alarm.\"\"\"",
            "",
            "    name = wsme.wsattr(wtypes.text, mandatory=True)",
            "    \"The name of the constraint\"",
            "",
            "    _description = None  # provide a default",
            "",
            "    def get_description(self):",
            "        if not self._description:",
            "            return ('Time constraint at %s lasting for %s seconds'",
            "                    % (self.start, self.duration))",
            "        return self._description",
            "",
            "    def set_description(self, value):",
            "        self._description = value",
            "",
            "    description = wsme.wsproperty(wtypes.text, get_description,",
            "                                  set_description)",
            "    \"The description of the constraint\"",
            "",
            "    start = wsme.wsattr(CronType(), mandatory=True)",
            "    \"Start point of the time constraint, in cron format\"",
            "",
            "    duration = wsme.wsattr(wtypes.IntegerType(minimum=0), mandatory=True)",
            "    \"How long the constraint should last, in seconds\"",
            "",
            "    timezone = wsme.wsattr(wtypes.text, default=\"\")",
            "    \"Timezone of the constraint\"",
            "",
            "    def as_dict(self):",
            "        return self.as_dict_from_keys(['name', 'description', 'start',",
            "                                       'duration', 'timezone'])",
            "",
            "    @staticmethod",
            "    def validate(tc):",
            "        if tc.timezone:",
            "            try:",
            "                pytz.timezone(tc.timezone)",
            "            except Exception:",
            "                raise base.ClientSideError(_(\"Timezone %s is not valid\")",
            "                                           % tc.timezone)",
            "        return tc",
            "",
            "    @classmethod",
            "    def sample(cls):",
            "        return cls(name='SampleConstraint',",
            "                   description='nightly build every night at 23h for 3 hours',",
            "                   start='0 23 * * *',",
            "                   duration=10800,",
            "                   timezone='Europe/Ljubljana')",
            "",
            "",
            "ALARMS_RULES = extension.ExtensionManager(\"aodh.alarm.rule\")",
            "LOG.debug(\"alarm rules plugin loaded: %s\" % \",\".join(ALARMS_RULES.names()))",
            "",
            "ACTIONS_SCHEMA = extension.ExtensionManager(",
            "    notifier.AlarmNotifierService.NOTIFIER_EXTENSIONS_NAMESPACE).names()",
            "",
            "",
            "class Alarm(base.Base):",
            "    \"\"\"Representation of an alarm.\"\"\"",
            "",
            "    alarm_id = wtypes.text",
            "    \"The UUID of the alarm\"",
            "",
            "    name = wsme.wsattr(wtypes.text, mandatory=True)",
            "    \"The name for the alarm\"",
            "",
            "    _description = None  # provide a default",
            "",
            "    def get_description(self):",
            "        rule = getattr(self, '%s_rule' % self.type, None)",
            "        if not self._description:",
            "            if hasattr(rule, 'default_description'):",
            "                return six.text_type(rule.default_description)",
            "            return \"%s alarm rule\" % self.type",
            "        return self._description",
            "",
            "    def set_description(self, value):",
            "        self._description = value",
            "",
            "    description = wsme.wsproperty(wtypes.text, get_description,",
            "                                  set_description)",
            "    \"The description of the alarm\"",
            "",
            "    enabled = wsme.wsattr(bool, default=True)",
            "    \"This alarm is enabled?\"",
            "",
            "    ok_actions = wsme.wsattr([wtypes.text], default=[])",
            "    \"The actions to do when alarm state change to ok\"",
            "",
            "    alarm_actions = wsme.wsattr([wtypes.text], default=[])",
            "    \"The actions to do when alarm state change to alarm\"",
            "",
            "    insufficient_data_actions = wsme.wsattr([wtypes.text], default=[])",
            "    \"The actions to do when alarm state change to insufficient data\"",
            "",
            "    repeat_actions = wsme.wsattr(bool, default=False)",
            "    \"The actions should be re-triggered on each evaluation cycle\"",
            "",
            "    type = base.AdvEnum('type', str, *ALARMS_RULES.names(),",
            "                        mandatory=True)",
            "    \"Explicit type specifier to select which rule to follow below.\"",
            "",
            "    time_constraints = wtypes.wsattr([AlarmTimeConstraint], default=[])",
            "    \"\"\"Describe time constraints for the alarm\"\"\"",
            "",
            "    # These settings are ignored in the PUT or POST operations, but are",
            "    # filled in for GET",
            "    project_id = wtypes.text",
            "    \"The ID of the project or tenant that owns the alarm\"",
            "",
            "    user_id = wtypes.text",
            "    \"The ID of the user who created the alarm\"",
            "",
            "    timestamp = datetime.datetime",
            "    \"The date of the last alarm definition update\"",
            "",
            "    state = base.AdvEnum('state', str, *state_kind,",
            "                         default='insufficient data')",
            "    \"The state offset the alarm\"",
            "",
            "    state_timestamp = datetime.datetime",
            "    \"The date of the last alarm state changed\"",
            "",
            "    state_reason = wsme.wsattr(wtypes.text, default=ALARM_REASON_DEFAULT)",
            "    \"The reason of the current state\"",
            "",
            "    severity = base.AdvEnum('severity', str, *severity_kind,",
            "                            default='low')",
            "    \"The severity of the alarm\"",
            "",
            "    def __init__(self, rule=None, time_constraints=None, **kwargs):",
            "        super(Alarm, self).__init__(**kwargs)",
            "",
            "        if rule:",
            "            setattr(self, '%s_rule' % self.type,",
            "                    ALARMS_RULES[self.type].plugin(**rule))",
            "",
            "        if time_constraints:",
            "            self.time_constraints = [AlarmTimeConstraint(**tc)",
            "                                     for tc in time_constraints]",
            "",
            "    @staticmethod",
            "    def validate(alarm):",
            "        Alarm.check_rule(alarm)",
            "        Alarm.check_alarm_actions(alarm)",
            "",
            "        ALARMS_RULES[alarm.type].plugin.validate_alarm(alarm)",
            "",
            "        if alarm.time_constraints:",
            "            tc_names = [tc.name for tc in alarm.time_constraints]",
            "            if len(tc_names) > len(set(tc_names)):",
            "                error = _(\"Time constraint names must be \"",
            "                          \"unique for a given alarm.\")",
            "                raise base.ClientSideError(error)",
            "",
            "        return alarm",
            "",
            "    @staticmethod",
            "    def check_rule(alarm):",
            "        rule = '%s_rule' % alarm.type",
            "        if getattr(alarm, rule) in (wtypes.Unset, None):",
            "            error = _(\"%(rule)s must be set for %(type)s\"",
            "                      \" type alarm\") % {\"rule\": rule, \"type\": alarm.type}",
            "            raise base.ClientSideError(error)",
            "",
            "        rule_set = None",
            "        for ext in ALARMS_RULES:",
            "            name = \"%s_rule\" % ext.name",
            "            if getattr(alarm, name):",
            "                if rule_set is None:",
            "                    rule_set = name",
            "                else:",
            "                    error = _(\"%(rule1)s and %(rule2)s cannot be set at the \"",
            "                              \"same time\") % {'rule1': rule_set, 'rule2': name}",
            "                    raise base.ClientSideError(error)",
            "",
            "    @staticmethod",
            "    def check_alarm_actions(alarm):",
            "        max_actions = pecan.request.cfg.api.alarm_max_actions",
            "        for state in state_kind:",
            "            actions_name = state.replace(\" \", \"_\") + '_actions'",
            "            actions = getattr(alarm, actions_name)",
            "            if not actions:",
            "                continue",
            "",
            "            action_set = set(actions)",
            "            if len(actions) != len(action_set):",
            "                LOG.info('duplicate actions are found: %s, '",
            "                         'remove duplicate ones', actions)",
            "                actions = list(action_set)",
            "                setattr(alarm, actions_name, actions)",
            "",
            "            if 0 < max_actions < len(actions):",
            "                error = _('%(name)s count exceeds maximum value '",
            "                          '%(maximum)d') % {\"name\": actions_name,",
            "                                            \"maximum\": max_actions}",
            "                raise base.ClientSideError(error)",
            "",
            "            limited = rbac.get_limited_to_project(pecan.request.headers,",
            "                                                  pecan.request.enforcer)",
            "",
            "            for action in actions:",
            "                try:",
            "                    url = netutils.urlsplit(action)",
            "                except Exception:",
            "                    error = _(\"Unable to parse action %s\") % action",
            "                    raise base.ClientSideError(error)",
            "                if url.scheme not in ACTIONS_SCHEMA:",
            "                    error = _(\"Unsupported action %s\") % action",
            "                    raise base.ClientSideError(error)",
            "                if limited and url.scheme in ('log', 'test'):",
            "                    error = _('You are not authorized to create '",
            "                              'action: %s') % action",
            "                    raise base.ClientSideError(error, status_code=401)",
            "",
            "    @classmethod",
            "    def sample(cls):",
            "        return cls(alarm_id=None,",
            "                   name=\"SwiftObjectAlarm\",",
            "                   description=\"An alarm\",",
            "                   type='gnocchi_aggregation_by_metrics_threshold',",
            "                   time_constraints=[AlarmTimeConstraint.sample().as_dict()],",
            "                   user_id=\"c96c887c216949acbdfbd8b494863567\",",
            "                   project_id=\"c96c887c216949acbdfbd8b494863567\",",
            "                   enabled=True,",
            "                   timestamp=datetime.datetime(2015, 1, 1, 12, 0, 0, 0),",
            "                   state=\"ok\",",
            "                   severity=\"moderate\",",
            "                   state_reason=\"threshold over 90%\",",
            "                   state_timestamp=datetime.datetime(2015, 1, 1, 12, 0, 0, 0),",
            "                   ok_actions=[\"http://site:8000/ok\"],",
            "                   alarm_actions=[\"http://site:8000/alarm\"],",
            "                   insufficient_data_actions=[\"http://site:8000/nodata\"],",
            "                   repeat_actions=False,",
            "                   )",
            "",
            "    def as_dict(self, db_model):",
            "        d = super(Alarm, self).as_dict(db_model)",
            "        for k in d:",
            "            if k.endswith('_rule'):",
            "                del d[k]",
            "        rule = getattr(self, \"%s_rule\" % self.type)",
            "        d['rule'] = rule if isinstance(rule, dict) else rule.as_dict()",
            "        if self.time_constraints:",
            "            d['time_constraints'] = [tc.as_dict()",
            "                                     for tc in self.time_constraints]",
            "        return d",
            "",
            "    @staticmethod",
            "    def _is_trust_url(url):",
            "        return url.scheme.startswith('trust+')",
            "",
            "    def _get_existing_trust_ids(self):",
            "        for action in itertools.chain(self.ok_actions or [],",
            "                                      self.alarm_actions or [],",
            "                                      self.insufficient_data_actions or []):",
            "            url = netutils.urlsplit(action)",
            "            if self._is_trust_url(url):",
            "                trust_id = url.username",
            "                if trust_id and url.password == 'delete':",
            "                    yield trust_id",
            "",
            "    def update_actions(self, old_alarm=None):",
            "        trustor_user_id = pecan.request.headers.get('X-User-Id')",
            "        trustor_project_id = pecan.request.headers.get('X-Project-Id')",
            "        roles = pecan.request.headers.get('X-Roles', '')",
            "        if roles:",
            "            roles = roles.split(',')",
            "        else:",
            "            roles = []",
            "        auth_plugin = pecan.request.environ.get('keystone.token_auth')",
            "",
            "        if old_alarm:",
            "            prev_trust_ids = set(old_alarm._get_existing_trust_ids())",
            "        else:",
            "            prev_trust_ids = set()",
            "        trust_id = prev_trust_ids.pop() if prev_trust_ids else None",
            "        trust_id_used = False",
            "",
            "        for actions in (self.ok_actions, self.alarm_actions,",
            "                        self.insufficient_data_actions):",
            "            if actions is not None:",
            "                for index, action in enumerate(actions[:]):",
            "                    url = netutils.urlsplit(action)",
            "                    if self._is_trust_url(url):",
            "                        if '@' in url.netloc:",
            "                            errmsg = _(\"trust URL cannot contain a trust ID.\")",
            "                            raise base.ClientSideError(errmsg)",
            "                        if trust_id is None:",
            "                            # We have a trust action without a trust ID,",
            "                            # create it",
            "                            trust_id = keystone_client.create_trust_id(",
            "                                pecan.request.cfg,",
            "                                trustor_user_id, trustor_project_id, roles,",
            "                                auth_plugin)",
            "                        if trust_id_used:",
            "                            pw = ''",
            "                        else:",
            "                            pw = ':delete'",
            "                            trust_id_used = True",
            "                        netloc = '%s%s@%s' % (trust_id, pw, url.netloc)",
            "                        url = urlparse.SplitResult(url.scheme, netloc,",
            "                                                   url.path, url.query,",
            "                                                   url.fragment)",
            "                        actions[index] = url.geturl()",
            "        if trust_id is not None and not trust_id_used:",
            "            prev_trust_ids.add(trust_id)",
            "        for old_trust_id in prev_trust_ids:",
            "            keystone_client.delete_trust_id(old_trust_id, auth_plugin)",
            "",
            "    def delete_actions(self):",
            "        auth_plugin = pecan.request.environ.get('keystone.token_auth')",
            "        for trust_id in self._get_existing_trust_ids():",
            "            keystone_client.delete_trust_id(trust_id, auth_plugin)",
            "",
            "",
            "Alarm.add_attributes(**{\"%s_rule\" % ext.name: ext.plugin",
            "                        for ext in ALARMS_RULES})",
            "",
            "",
            "class AlarmChange(base.Base):",
            "    \"\"\"Representation of an event in an alarm's history.\"\"\"",
            "",
            "    event_id = wtypes.text",
            "    \"The UUID of the change event\"",
            "",
            "    alarm_id = wtypes.text",
            "    \"The UUID of the alarm\"",
            "",
            "    type = wtypes.Enum(str,",
            "                       'creation',",
            "                       'rule change',",
            "                       'state transition',",
            "                       'deletion')",
            "    \"The type of change\"",
            "",
            "    detail = wtypes.text",
            "    \"JSON fragment describing change\"",
            "",
            "    project_id = wtypes.text",
            "    \"The project ID of the initiating identity\"",
            "",
            "    user_id = wtypes.text",
            "    \"The user ID of the initiating identity\"",
            "",
            "    on_behalf_of = wtypes.text",
            "    \"The tenant on behalf of which the change is being made\"",
            "",
            "    timestamp = datetime.datetime",
            "    \"The time/date of the alarm change\"",
            "",
            "    @classmethod",
            "    def sample(cls):",
            "        return cls(alarm_id='e8ff32f772a44a478182c3fe1f7cad6a',",
            "                   type='rule change',",
            "                   detail='{\"threshold\": 42.0, \"evaluation_periods\": 4}',",
            "                   user_id=\"3e5d11fda79448ac99ccefb20be187ca\",",
            "                   project_id=\"b6f16144010811e387e4de429e99ee8c\",",
            "                   on_behalf_of=\"92159030020611e3b26dde429e99ee8c\",",
            "                   timestamp=datetime.datetime(2015, 1, 1, 12, 0, 0, 0),",
            "                   )",
            "",
            "",
            "def _send_notification(event, payload):",
            "    notification = event.replace(\" \", \"_\")",
            "    notification = \"alarm.%s\" % notification",
            "    transport = messaging.get_transport(pecan.request.cfg)",
            "    notifier = messaging.get_notifier(transport, publisher_id=\"aodh.api\")",
            "    # FIXME(sileht): perhaps we need to copy some infos from the",
            "    # pecan request headers like nova does",
            "    notifier.info({}, notification, payload)",
            "",
            "",
            "def stringify_timestamps(data):",
            "    \"\"\"Stringify any datetimes in given dict.\"\"\"",
            "    return dict((k, v.isoformat()",
            "                 if isinstance(v, datetime.datetime) else v)",
            "                for (k, v) in six.iteritems(data))",
            "",
            "",
            "class AlarmController(rest.RestController):",
            "    \"\"\"Manages operations on a single alarm.\"\"\"",
            "",
            "    _custom_actions = {",
            "        'history': ['GET'],",
            "        'state': ['PUT', 'GET'],",
            "    }",
            "",
            "    def __init__(self, alarm_id):",
            "        pecan.request.context['alarm_id'] = alarm_id",
            "        self._id = alarm_id",
            "",
            "    def _enforce_rbac(self, rbac_directive):",
            "        # TODO(sileht): We should be able to relax this since we",
            "        # pass the alarm object to the enforcer.",
            "        auth_project = rbac.get_limited_to_project(pecan.request.headers,",
            "                                                   pecan.request.enforcer)",
            "        alarms = list(pecan.request.storage.get_alarms(alarm_id=self._id,",
            "                                                       project=auth_project))",
            "        if not alarms:",
            "            raise base.AlarmNotFound(alarm=self._id, auth_project=auth_project)",
            "        alarm = alarms[0]",
            "        target = {'user_id': alarm.user_id,",
            "                  'project_id': alarm.project_id}",
            "        rbac.enforce(rbac_directive, pecan.request.headers,",
            "                     pecan.request.enforcer, target)",
            "        return alarm",
            "",
            "    def _record_change(self, data, now, on_behalf_of=None, type=None):",
            "        if not pecan.request.cfg.record_history:",
            "            return",
            "        if not data:",
            "            return",
            "        type = type or models.AlarmChange.RULE_CHANGE",
            "        scrubbed_data = stringify_timestamps(data)",
            "        detail = json.dumps(scrubbed_data)",
            "        user_id = pecan.request.headers.get('X-User-Id')",
            "        project_id = pecan.request.headers.get('X-Project-Id')",
            "        on_behalf_of = on_behalf_of or project_id",
            "        severity = scrubbed_data.get('severity')",
            "        payload = dict(event_id=uuidutils.generate_uuid(),",
            "                       alarm_id=self._id,",
            "                       type=type,",
            "                       detail=detail,",
            "                       user_id=user_id,",
            "                       project_id=project_id,",
            "                       on_behalf_of=on_behalf_of,",
            "                       timestamp=now,",
            "                       severity=severity)",
            "",
            "        try:",
            "            pecan.request.storage.record_alarm_change(payload)",
            "        except aodh.NotImplementedError:",
            "            pass",
            "",
            "        # Revert to the pre-json'ed details ...",
            "        payload['detail'] = scrubbed_data",
            "        _send_notification(type, payload)",
            "",
            "    def _record_delete(self, alarm):",
            "        if not alarm:",
            "            return",
            "        type = models.AlarmChange.DELETION",
            "        detail = {'state': alarm.state}",
            "        user_id = pecan.request.headers.get('X-User-Id')",
            "        project_id = pecan.request.headers.get('X-Project-Id')",
            "        payload = dict(event_id=uuidutils.generate_uuid(),",
            "                       alarm_id=self._id,",
            "                       type=type,",
            "                       detail=detail,",
            "                       user_id=user_id,",
            "                       project_id=project_id,",
            "                       on_behalf_of=project_id,",
            "                       timestamp=timeutils.utcnow(),",
            "                       severity=alarm.severity)",
            "",
            "        pecan.request.storage.delete_alarm(alarm.alarm_id)",
            "        _send_notification(type, payload)",
            "",
            "    @wsme_pecan.wsexpose(Alarm)",
            "    def get(self):",
            "        \"\"\"Return this alarm.\"\"\"",
            "        return Alarm.from_db_model(self._enforce_rbac('get_alarm'))",
            "",
            "    @wsme_pecan.wsexpose(Alarm, body=Alarm)",
            "    def put(self, data):",
            "        \"\"\"Modify this alarm.",
            "",
            "        :param data: an alarm within the request body.",
            "        \"\"\"",
            "",
            "        # Ensure alarm exists",
            "        alarm_in = self._enforce_rbac('change_alarm')",
            "",
            "        now = timeutils.utcnow()",
            "",
            "        data.alarm_id = self._id",
            "",
            "        user, project = rbac.get_limited_to(pecan.request.headers,",
            "                                            pecan.request.enforcer)",
            "        if user:",
            "            data.user_id = user",
            "        elif data.user_id == wtypes.Unset:",
            "            data.user_id = alarm_in.user_id",
            "        if project:",
            "            data.project_id = project",
            "        elif data.project_id == wtypes.Unset:",
            "            data.project_id = alarm_in.project_id",
            "        data.timestamp = now",
            "        if alarm_in.state != data.state:",
            "            data.state_timestamp = now",
            "            data.state_reason = ALARM_REASON_MANUAL",
            "        else:",
            "            data.state_timestamp = alarm_in.state_timestamp",
            "            data.state_reason = alarm_in.state_reason",
            "",
            "        ALARMS_RULES[data.type].plugin.update_hook(data)",
            "",
            "        old_data = Alarm.from_db_model(alarm_in)",
            "        old_alarm = old_data.as_dict(models.Alarm)",
            "        data.update_actions(old_data)",
            "        updated_alarm = data.as_dict(models.Alarm)",
            "        try:",
            "            alarm_in = models.Alarm(**updated_alarm)",
            "        except Exception:",
            "            LOG.exception(\"Error while putting alarm: %s\", updated_alarm)",
            "            raise base.ClientSideError(_(\"Alarm incorrect\"))",
            "",
            "        alarm = pecan.request.storage.update_alarm(alarm_in)",
            "",
            "        change = dict((k, v) for k, v in updated_alarm.items()",
            "                      if v != old_alarm[k] and k not in",
            "                      ['timestamp', 'state_timestamp'])",
            "        self._record_change(change, now, on_behalf_of=alarm.project_id)",
            "        return Alarm.from_db_model(alarm)",
            "",
            "    @wsme_pecan.wsexpose(None, status_code=204)",
            "    def delete(self):",
            "        \"\"\"Delete this alarm.\"\"\"",
            "",
            "        # ensure alarm exists before deleting",
            "        alarm = self._enforce_rbac('delete_alarm')",
            "        self._record_delete(alarm)",
            "        alarm_object = Alarm.from_db_model(alarm)",
            "        alarm_object.delete_actions()",
            "",
            "    @wsme_pecan.wsexpose([AlarmChange], [base.Query], [str], int, str)",
            "    def history(self, q=None, sort=None, limit=None, marker=None):",
            "        \"\"\"Assembles the alarm history requested.",
            "",
            "        :param q: Filter rules for the changes to be described.",
            "        :param sort: A list of pairs of sort key and sort dir.",
            "        :param limit: The maximum number of items to be return.",
            "        :param marker: The pagination query marker.",
            "        \"\"\"",
            "",
            "        # Ensure alarm exists",
            "        self._enforce_rbac('alarm_history')",
            "",
            "        q = q or []",
            "        # allow history to be returned for deleted alarms, but scope changes",
            "        # returned to those carried out on behalf of the auth'd tenant, to",
            "        # avoid inappropriate cross-tenant visibility of alarm history",
            "        auth_project = rbac.get_limited_to_project(pecan.request.headers,",
            "                                                   pecan.request.enforcer)",
            "        conn = pecan.request.storage",
            "        kwargs = v2_utils.query_to_kwargs(",
            "            q, conn.get_alarm_changes, ['on_behalf_of', 'alarm_id'])",
            "        if sort or limit or marker:",
            "            kwargs['pagination'] = v2_utils.get_pagination_options(",
            "                sort, limit, marker, models.AlarmChange)",
            "        return [AlarmChange.from_db_model(ac)",
            "                for ac in conn.get_alarm_changes(self._id, auth_project,",
            "                                                 **kwargs)]",
            "",
            "    @wsme.validate(state_kind_enum)",
            "    @wsme_pecan.wsexpose(state_kind_enum, body=state_kind_enum)",
            "    def put_state(self, state):",
            "        \"\"\"Set the state of this alarm.",
            "",
            "        :param state: an alarm state within the request body.",
            "        \"\"\"",
            "",
            "        alarm = self._enforce_rbac('change_alarm_state')",
            "",
            "        # note(sileht): body are not validated by wsme",
            "        # Workaround for https://bugs.launchpad.net/wsme/+bug/1227229",
            "        if state not in state_kind:",
            "            raise base.ClientSideError(_(\"state invalid\"))",
            "        now = timeutils.utcnow()",
            "        alarm.state = state",
            "        alarm.state_timestamp = now",
            "        alarm.state_reason = ALARM_REASON_MANUAL",
            "        alarm = pecan.request.storage.update_alarm(alarm)",
            "        change = {'state': alarm.state,",
            "                  'state_reason': alarm.state_reason}",
            "        self._record_change(change, now, on_behalf_of=alarm.project_id,",
            "                            type=models.AlarmChange.STATE_TRANSITION)",
            "        return alarm.state",
            "",
            "    @wsme_pecan.wsexpose(state_kind_enum)",
            "    def get_state(self):",
            "        \"\"\"Get the state of this alarm.\"\"\"",
            "        return self._enforce_rbac('get_alarm_state').state",
            "",
            "",
            "class AlarmsController(rest.RestController):",
            "    \"\"\"Manages operations on the alarms collection.\"\"\"",
            "",
            "    @pecan.expose()",
            "    def _lookup(self, alarm_id, *remainder):",
            "        return AlarmController(alarm_id), remainder",
            "",
            "    @staticmethod",
            "    def _record_creation(conn, data, alarm_id, now):",
            "        if not pecan.request.cfg.record_history:",
            "            return",
            "        type = models.AlarmChange.CREATION",
            "        scrubbed_data = stringify_timestamps(data)",
            "        detail = json.dumps(scrubbed_data)",
            "        user_id = pecan.request.headers.get('X-User-Id')",
            "        project_id = pecan.request.headers.get('X-Project-Id')",
            "        severity = scrubbed_data.get('severity')",
            "        payload = dict(event_id=uuidutils.generate_uuid(),",
            "                       alarm_id=alarm_id,",
            "                       type=type,",
            "                       detail=detail,",
            "                       user_id=user_id,",
            "                       project_id=project_id,",
            "                       on_behalf_of=project_id,",
            "                       timestamp=now,",
            "                       severity=severity)",
            "",
            "        try:",
            "            conn.record_alarm_change(payload)",
            "        except aodh.NotImplementedError:",
            "            pass",
            "",
            "        # Revert to the pre-json'ed details ...",
            "        payload['detail'] = scrubbed_data",
            "        _send_notification(type, payload)",
            "",
            "    @wsme_pecan.wsexpose(Alarm, body=Alarm, status_code=201)",
            "    def post(self, data):",
            "        \"\"\"Create a new alarm.",
            "",
            "        :param data: an alarm within the request body.",
            "        \"\"\"",
            "        rbac.enforce('create_alarm', pecan.request.headers,",
            "                     pecan.request.enforcer, {})",
            "",
            "        conn = pecan.request.storage",
            "        now = timeutils.utcnow()",
            "",
            "        data.alarm_id = uuidutils.generate_uuid()",
            "        user_limit, project_limit = rbac.get_limited_to(pecan.request.headers,",
            "                                                        pecan.request.enforcer)",
            "",
            "        def _set_ownership(aspect, owner_limitation, header):",
            "            attr = '%s_id' % aspect",
            "            requested_owner = getattr(data, attr)",
            "            explicit_owner = requested_owner != wtypes.Unset",
            "            caller = pecan.request.headers.get(header)",
            "            if (owner_limitation and explicit_owner",
            "                    and requested_owner != caller):",
            "                raise base.ProjectNotAuthorized(requested_owner, aspect)",
            "",
            "            actual_owner = (owner_limitation or",
            "                            requested_owner if explicit_owner else caller)",
            "            setattr(data, attr, actual_owner)",
            "",
            "        _set_ownership('user', user_limit, 'X-User-Id')",
            "        _set_ownership('project', project_limit, 'X-Project-Id')",
            "",
            "        # Check if there's room for one more alarm",
            "        if is_over_quota(conn, data.project_id, data.user_id):",
            "            raise OverQuota(data)",
            "",
            "        data.timestamp = now",
            "        data.state_timestamp = now",
            "        data.state_reason = ALARM_REASON_DEFAULT",
            "",
            "        ALARMS_RULES[data.type].plugin.create_hook(data)",
            "",
            "        change = data.as_dict(models.Alarm)",
            "",
            "        data.update_actions()",
            "",
            "        try:",
            "            alarm_in = models.Alarm(**change)",
            "        except Exception:",
            "            LOG.exception(\"Error while posting alarm: %s\", change)",
            "            raise base.ClientSideError(_(\"Alarm incorrect\"))",
            "",
            "        alarm = conn.create_alarm(alarm_in)",
            "        self._record_creation(conn, change, alarm.alarm_id, now)",
            "        v2_utils.set_resp_location_hdr(\"/alarms/\" + alarm.alarm_id)",
            "        return Alarm.from_db_model(alarm)",
            "",
            "    @wsme_pecan.wsexpose([Alarm], [base.Query], [str], int, str)",
            "    def get_all(self, q=None, sort=None, limit=None, marker=None):",
            "        \"\"\"Return all alarms, based on the query provided.",
            "",
            "        :param q: Filter rules for the alarms to be returned.",
            "        :param sort: A list of pairs of sort key and sort dir.",
            "        :param limit: The maximum number of items to be return.",
            "        :param marker: The pagination query marker.",
            "        \"\"\"",
            "        target = rbac.target_from_segregation_rule(",
            "            pecan.request.headers, pecan.request.enforcer)",
            "        rbac.enforce('get_alarms', pecan.request.headers,",
            "                     pecan.request.enforcer, target)",
            "",
            "        q = q or []",
            "        # Timestamp is not supported field for Simple Alarm queries",
            "        kwargs = v2_utils.query_to_kwargs(",
            "            q, pecan.request.storage.get_alarms,",
            "            allow_timestamps=False)",
            "        if sort or limit or marker:",
            "            kwargs['pagination'] = v2_utils.get_pagination_options(",
            "                sort, limit, marker, models.Alarm)",
            "        return [Alarm.from_db_model(m)",
            "                for m in pecan.request.storage.get_alarms(**kwargs)]"
        ],
        "afterPatchFile": [
            "#",
            "# Copyright 2012 New Dream Network, LLC (DreamHost)",
            "# Copyright 2013 IBM Corp.",
            "# Copyright 2013 eNovance <licensing@enovance.com>",
            "# Copyright Ericsson AB 2013. All rights reserved",
            "# Copyright 2014 Hewlett-Packard Company",
            "# Copyright 2015 Huawei Technologies Co., Ltd.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "",
            "import datetime",
            "import itertools",
            "import json",
            "",
            "import croniter",
            "from oslo_config import cfg",
            "from oslo_log import log",
            "from oslo_utils import netutils",
            "from oslo_utils import timeutils",
            "from oslo_utils import uuidutils",
            "import pecan",
            "from pecan import rest",
            "import pytz",
            "import six",
            "from six.moves.urllib import parse as urlparse",
            "from stevedore import extension",
            "import wsme",
            "from wsme import types as wtypes",
            "import wsmeext.pecan as wsme_pecan",
            "",
            "import aodh",
            "from aodh.api.controllers.v2 import base",
            "from aodh.api.controllers.v2 import utils as v2_utils",
            "from aodh.api import rbac",
            "from aodh.i18n import _",
            "from aodh import keystone_client",
            "from aodh import messaging",
            "from aodh import notifier",
            "from aodh.storage import models",
            "",
            "LOG = log.getLogger(__name__)",
            "",
            "",
            "ALARM_API_OPTS = [",
            "    cfg.IntOpt('user_alarm_quota',",
            "               deprecated_group='DEFAULT',",
            "               help='Maximum number of alarms defined for a user.'",
            "               ),",
            "    cfg.IntOpt('project_alarm_quota',",
            "               deprecated_group='DEFAULT',",
            "               help='Maximum number of alarms defined for a project.'",
            "               ),",
            "    cfg.IntOpt('alarm_max_actions',",
            "               default=-1,",
            "               deprecated_group='DEFAULT',",
            "               help='Maximum count of actions for each state of an alarm, '",
            "                    'non-positive number means no limit.'),",
            "]",
            "",
            "state_kind = [\"ok\", \"alarm\", \"insufficient data\"]",
            "state_kind_enum = wtypes.Enum(str, *state_kind)",
            "severity_kind = [\"low\", \"moderate\", \"critical\"]",
            "severity_kind_enum = wtypes.Enum(str, *severity_kind)",
            "",
            "ALARM_REASON_DEFAULT = \"Not evaluated yet\"",
            "ALARM_REASON_MANUAL = \"Manually set via API\"",
            "",
            "",
            "class OverQuota(base.ClientSideError):",
            "    def __init__(self, data):",
            "        d = {",
            "            'u': data.user_id,",
            "            'p': data.project_id",
            "        }",
            "        super(OverQuota, self).__init__(",
            "            _(\"Alarm quota exceeded for user %(u)s on project %(p)s\") % d,",
            "            status_code=403)",
            "",
            "",
            "def is_over_quota(conn, project_id, user_id):",
            "    \"\"\"Returns False if an alarm is within the set quotas, True otherwise.",
            "",
            "    :param conn: a backend connection object",
            "    :param project_id: the ID of the project setting the alarm",
            "    :param user_id: the ID of the user setting the alarm",
            "    \"\"\"",
            "",
            "    over_quota = False",
            "",
            "    # Start by checking for user quota",
            "    user_alarm_quota = pecan.request.cfg.api.user_alarm_quota",
            "    if user_alarm_quota is not None:",
            "        user_alarms = list(conn.get_alarms(user=user_id))",
            "        over_quota = len(user_alarms) >= user_alarm_quota",
            "",
            "    # If the user quota isn't reached, we check for the project quota",
            "    if not over_quota:",
            "        project_alarm_quota = pecan.request.cfg.api.project_alarm_quota",
            "        if project_alarm_quota is not None:",
            "            project_alarms = list(conn.get_alarms(project=project_id))",
            "            over_quota = len(project_alarms) >= project_alarm_quota",
            "",
            "    return over_quota",
            "",
            "",
            "class CronType(wtypes.UserType):",
            "    \"\"\"A user type that represents a cron format.\"\"\"",
            "    basetype = six.string_types",
            "    name = 'cron'",
            "",
            "    @staticmethod",
            "    def validate(value):",
            "        # raises ValueError if invalid",
            "        croniter.croniter(value)",
            "        return value",
            "",
            "",
            "class AlarmTimeConstraint(base.Base):",
            "    \"\"\"Representation of a time constraint on an alarm.\"\"\"",
            "",
            "    name = wsme.wsattr(wtypes.text, mandatory=True)",
            "    \"The name of the constraint\"",
            "",
            "    _description = None  # provide a default",
            "",
            "    def get_description(self):",
            "        if not self._description:",
            "            return ('Time constraint at %s lasting for %s seconds'",
            "                    % (self.start, self.duration))",
            "        return self._description",
            "",
            "    def set_description(self, value):",
            "        self._description = value",
            "",
            "    description = wsme.wsproperty(wtypes.text, get_description,",
            "                                  set_description)",
            "    \"The description of the constraint\"",
            "",
            "    start = wsme.wsattr(CronType(), mandatory=True)",
            "    \"Start point of the time constraint, in cron format\"",
            "",
            "    duration = wsme.wsattr(wtypes.IntegerType(minimum=0), mandatory=True)",
            "    \"How long the constraint should last, in seconds\"",
            "",
            "    timezone = wsme.wsattr(wtypes.text, default=\"\")",
            "    \"Timezone of the constraint\"",
            "",
            "    def as_dict(self):",
            "        return self.as_dict_from_keys(['name', 'description', 'start',",
            "                                       'duration', 'timezone'])",
            "",
            "    @staticmethod",
            "    def validate(tc):",
            "        if tc.timezone:",
            "            try:",
            "                pytz.timezone(tc.timezone)",
            "            except Exception:",
            "                raise base.ClientSideError(_(\"Timezone %s is not valid\")",
            "                                           % tc.timezone)",
            "        return tc",
            "",
            "    @classmethod",
            "    def sample(cls):",
            "        return cls(name='SampleConstraint',",
            "                   description='nightly build every night at 23h for 3 hours',",
            "                   start='0 23 * * *',",
            "                   duration=10800,",
            "                   timezone='Europe/Ljubljana')",
            "",
            "",
            "ALARMS_RULES = extension.ExtensionManager(\"aodh.alarm.rule\")",
            "LOG.debug(\"alarm rules plugin loaded: %s\" % \",\".join(ALARMS_RULES.names()))",
            "",
            "ACTIONS_SCHEMA = extension.ExtensionManager(",
            "    notifier.AlarmNotifierService.NOTIFIER_EXTENSIONS_NAMESPACE).names()",
            "",
            "",
            "class Alarm(base.Base):",
            "    \"\"\"Representation of an alarm.\"\"\"",
            "",
            "    alarm_id = wtypes.text",
            "    \"The UUID of the alarm\"",
            "",
            "    name = wsme.wsattr(wtypes.text, mandatory=True)",
            "    \"The name for the alarm\"",
            "",
            "    _description = None  # provide a default",
            "",
            "    def get_description(self):",
            "        rule = getattr(self, '%s_rule' % self.type, None)",
            "        if not self._description:",
            "            if hasattr(rule, 'default_description'):",
            "                return six.text_type(rule.default_description)",
            "            return \"%s alarm rule\" % self.type",
            "        return self._description",
            "",
            "    def set_description(self, value):",
            "        self._description = value",
            "",
            "    description = wsme.wsproperty(wtypes.text, get_description,",
            "                                  set_description)",
            "    \"The description of the alarm\"",
            "",
            "    enabled = wsme.wsattr(bool, default=True)",
            "    \"This alarm is enabled?\"",
            "",
            "    ok_actions = wsme.wsattr([wtypes.text], default=[])",
            "    \"The actions to do when alarm state change to ok\"",
            "",
            "    alarm_actions = wsme.wsattr([wtypes.text], default=[])",
            "    \"The actions to do when alarm state change to alarm\"",
            "",
            "    insufficient_data_actions = wsme.wsattr([wtypes.text], default=[])",
            "    \"The actions to do when alarm state change to insufficient data\"",
            "",
            "    repeat_actions = wsme.wsattr(bool, default=False)",
            "    \"The actions should be re-triggered on each evaluation cycle\"",
            "",
            "    type = base.AdvEnum('type', str, *ALARMS_RULES.names(),",
            "                        mandatory=True)",
            "    \"Explicit type specifier to select which rule to follow below.\"",
            "",
            "    time_constraints = wtypes.wsattr([AlarmTimeConstraint], default=[])",
            "    \"\"\"Describe time constraints for the alarm\"\"\"",
            "",
            "    # These settings are ignored in the PUT or POST operations, but are",
            "    # filled in for GET",
            "    project_id = wtypes.text",
            "    \"The ID of the project or tenant that owns the alarm\"",
            "",
            "    user_id = wtypes.text",
            "    \"The ID of the user who created the alarm\"",
            "",
            "    timestamp = datetime.datetime",
            "    \"The date of the last alarm definition update\"",
            "",
            "    state = base.AdvEnum('state', str, *state_kind,",
            "                         default='insufficient data')",
            "    \"The state offset the alarm\"",
            "",
            "    state_timestamp = datetime.datetime",
            "    \"The date of the last alarm state changed\"",
            "",
            "    state_reason = wsme.wsattr(wtypes.text, default=ALARM_REASON_DEFAULT)",
            "    \"The reason of the current state\"",
            "",
            "    severity = base.AdvEnum('severity', str, *severity_kind,",
            "                            default='low')",
            "    \"The severity of the alarm\"",
            "",
            "    def __init__(self, rule=None, time_constraints=None, **kwargs):",
            "        super(Alarm, self).__init__(**kwargs)",
            "",
            "        if rule:",
            "            setattr(self, '%s_rule' % self.type,",
            "                    ALARMS_RULES[self.type].plugin(**rule))",
            "",
            "        if time_constraints:",
            "            self.time_constraints = [AlarmTimeConstraint(**tc)",
            "                                     for tc in time_constraints]",
            "",
            "    @classmethod",
            "    def from_db_model_scrubbed(cls, m):",
            "        # Return an Alarm from a DB model with trust IDs scrubbed from actions",
            "        data = m.as_dict()",
            "",
            "        for field in ('ok_actions', 'alarm_actions',",
            "                      'insufficient_data_actions'):",
            "            if data.get(field) is not None:",
            "                data[field] = [cls._scrub_action_url(action)",
            "                               for action in data[field]]",
            "",
            "        return cls(**data)",
            "",
            "    @staticmethod",
            "    def validate(alarm):",
            "        Alarm.check_rule(alarm)",
            "        Alarm.check_alarm_actions(alarm)",
            "",
            "        ALARMS_RULES[alarm.type].plugin.validate_alarm(alarm)",
            "",
            "        if alarm.time_constraints:",
            "            tc_names = [tc.name for tc in alarm.time_constraints]",
            "            if len(tc_names) > len(set(tc_names)):",
            "                error = _(\"Time constraint names must be \"",
            "                          \"unique for a given alarm.\")",
            "                raise base.ClientSideError(error)",
            "",
            "        return alarm",
            "",
            "    @staticmethod",
            "    def check_rule(alarm):",
            "        rule = '%s_rule' % alarm.type",
            "        if getattr(alarm, rule) in (wtypes.Unset, None):",
            "            error = _(\"%(rule)s must be set for %(type)s\"",
            "                      \" type alarm\") % {\"rule\": rule, \"type\": alarm.type}",
            "            raise base.ClientSideError(error)",
            "",
            "        rule_set = None",
            "        for ext in ALARMS_RULES:",
            "            name = \"%s_rule\" % ext.name",
            "            if getattr(alarm, name):",
            "                if rule_set is None:",
            "                    rule_set = name",
            "                else:",
            "                    error = _(\"%(rule1)s and %(rule2)s cannot be set at the \"",
            "                              \"same time\") % {'rule1': rule_set, 'rule2': name}",
            "                    raise base.ClientSideError(error)",
            "",
            "    @staticmethod",
            "    def check_alarm_actions(alarm):",
            "        max_actions = pecan.request.cfg.api.alarm_max_actions",
            "        for state in state_kind:",
            "            actions_name = state.replace(\" \", \"_\") + '_actions'",
            "            actions = getattr(alarm, actions_name)",
            "            if not actions:",
            "                continue",
            "",
            "            action_set = set(actions)",
            "            if len(actions) != len(action_set):",
            "                LOG.info('duplicate actions are found: %s, '",
            "                         'remove duplicate ones', actions)",
            "                actions = list(action_set)",
            "                setattr(alarm, actions_name, actions)",
            "",
            "            if 0 < max_actions < len(actions):",
            "                error = _('%(name)s count exceeds maximum value '",
            "                          '%(maximum)d') % {\"name\": actions_name,",
            "                                            \"maximum\": max_actions}",
            "                raise base.ClientSideError(error)",
            "",
            "            limited = rbac.get_limited_to_project(pecan.request.headers,",
            "                                                  pecan.request.enforcer)",
            "",
            "            for action in actions:",
            "                try:",
            "                    url = netutils.urlsplit(action)",
            "                except Exception:",
            "                    error = _(\"Unable to parse action %s\") % action",
            "                    raise base.ClientSideError(error)",
            "                if url.scheme not in ACTIONS_SCHEMA:",
            "                    error = _(\"Unsupported action %s\") % action",
            "                    raise base.ClientSideError(error)",
            "                if limited and url.scheme in ('log', 'test'):",
            "                    error = _('You are not authorized to create '",
            "                              'action: %s') % action",
            "                    raise base.ClientSideError(error, status_code=401)",
            "",
            "    @classmethod",
            "    def sample(cls):",
            "        return cls(alarm_id=None,",
            "                   name=\"SwiftObjectAlarm\",",
            "                   description=\"An alarm\",",
            "                   type='gnocchi_aggregation_by_metrics_threshold',",
            "                   time_constraints=[AlarmTimeConstraint.sample().as_dict()],",
            "                   user_id=\"c96c887c216949acbdfbd8b494863567\",",
            "                   project_id=\"c96c887c216949acbdfbd8b494863567\",",
            "                   enabled=True,",
            "                   timestamp=datetime.datetime(2015, 1, 1, 12, 0, 0, 0),",
            "                   state=\"ok\",",
            "                   severity=\"moderate\",",
            "                   state_reason=\"threshold over 90%\",",
            "                   state_timestamp=datetime.datetime(2015, 1, 1, 12, 0, 0, 0),",
            "                   ok_actions=[\"http://site:8000/ok\"],",
            "                   alarm_actions=[\"http://site:8000/alarm\"],",
            "                   insufficient_data_actions=[\"http://site:8000/nodata\"],",
            "                   repeat_actions=False,",
            "                   )",
            "",
            "    def as_dict(self, db_model):",
            "        d = super(Alarm, self).as_dict(db_model)",
            "        for k in d:",
            "            if k.endswith('_rule'):",
            "                del d[k]",
            "        rule = getattr(self, \"%s_rule\" % self.type)",
            "        d['rule'] = rule if isinstance(rule, dict) else rule.as_dict()",
            "        if self.time_constraints:",
            "            d['time_constraints'] = [tc.as_dict()",
            "                                     for tc in self.time_constraints]",
            "        return d",
            "",
            "    @staticmethod",
            "    def _is_trust_url(url):",
            "        return url.scheme.startswith('trust+')",
            "",
            "    @staticmethod",
            "    def _scrub_action_url(action):",
            "        \"\"\"Remove trust ID from a URL.\"\"\"",
            "        url = netutils.urlsplit(action)",
            "        if Alarm._is_trust_url(url):",
            "            netloc = url.netloc.rsplit('@', 1)[-1]",
            "            url = urlparse.SplitResult(url.scheme, netloc,",
            "                                       url.path, url.query,",
            "                                       url.fragment)",
            "        return url.geturl()",
            "",
            "    def _get_existing_trust_ids(self):",
            "        for action in itertools.chain(self.ok_actions or [],",
            "                                      self.alarm_actions or [],",
            "                                      self.insufficient_data_actions or []):",
            "            url = netutils.urlsplit(action)",
            "            if self._is_trust_url(url):",
            "                trust_id = url.username",
            "                if trust_id and url.password == 'delete':",
            "                    yield trust_id",
            "",
            "    def update_actions(self, old_alarm=None):",
            "        trustor_user_id = pecan.request.headers.get('X-User-Id')",
            "        trustor_project_id = pecan.request.headers.get('X-Project-Id')",
            "        roles = pecan.request.headers.get('X-Roles', '')",
            "        if roles:",
            "            roles = roles.split(',')",
            "        else:",
            "            roles = []",
            "        auth_plugin = pecan.request.environ.get('keystone.token_auth')",
            "",
            "        if old_alarm:",
            "            prev_trust_ids = set(old_alarm._get_existing_trust_ids())",
            "        else:",
            "            prev_trust_ids = set()",
            "        trust_id = prev_trust_ids.pop() if prev_trust_ids else None",
            "        trust_id_used = False",
            "",
            "        for actions in (self.ok_actions, self.alarm_actions,",
            "                        self.insufficient_data_actions):",
            "            if actions is not None:",
            "                for index, action in enumerate(actions[:]):",
            "                    url = netutils.urlsplit(action)",
            "                    if self._is_trust_url(url):",
            "                        if '@' in url.netloc:",
            "                            errmsg = _(\"trust URL cannot contain a trust ID.\")",
            "                            raise base.ClientSideError(errmsg)",
            "                        if trust_id is None:",
            "                            # We have a trust action without a trust ID,",
            "                            # create it",
            "                            trust_id = keystone_client.create_trust_id(",
            "                                pecan.request.cfg,",
            "                                trustor_user_id, trustor_project_id, roles,",
            "                                auth_plugin)",
            "                        if trust_id_used:",
            "                            pw = ''",
            "                        else:",
            "                            pw = ':delete'",
            "                            trust_id_used = True",
            "                        netloc = '%s%s@%s' % (trust_id, pw, url.netloc)",
            "                        url = urlparse.SplitResult(url.scheme, netloc,",
            "                                                   url.path, url.query,",
            "                                                   url.fragment)",
            "                        actions[index] = url.geturl()",
            "        if trust_id is not None and not trust_id_used:",
            "            prev_trust_ids.add(trust_id)",
            "        for old_trust_id in prev_trust_ids:",
            "            keystone_client.delete_trust_id(old_trust_id, auth_plugin)",
            "",
            "    def delete_actions(self):",
            "        auth_plugin = pecan.request.environ.get('keystone.token_auth')",
            "        for trust_id in self._get_existing_trust_ids():",
            "            keystone_client.delete_trust_id(trust_id, auth_plugin)",
            "",
            "",
            "Alarm.add_attributes(**{\"%s_rule\" % ext.name: ext.plugin",
            "                        for ext in ALARMS_RULES})",
            "",
            "",
            "class AlarmChange(base.Base):",
            "    \"\"\"Representation of an event in an alarm's history.\"\"\"",
            "",
            "    event_id = wtypes.text",
            "    \"The UUID of the change event\"",
            "",
            "    alarm_id = wtypes.text",
            "    \"The UUID of the alarm\"",
            "",
            "    type = wtypes.Enum(str,",
            "                       'creation',",
            "                       'rule change',",
            "                       'state transition',",
            "                       'deletion')",
            "    \"The type of change\"",
            "",
            "    detail = wtypes.text",
            "    \"JSON fragment describing change\"",
            "",
            "    project_id = wtypes.text",
            "    \"The project ID of the initiating identity\"",
            "",
            "    user_id = wtypes.text",
            "    \"The user ID of the initiating identity\"",
            "",
            "    on_behalf_of = wtypes.text",
            "    \"The tenant on behalf of which the change is being made\"",
            "",
            "    timestamp = datetime.datetime",
            "    \"The time/date of the alarm change\"",
            "",
            "    @classmethod",
            "    def sample(cls):",
            "        return cls(alarm_id='e8ff32f772a44a478182c3fe1f7cad6a',",
            "                   type='rule change',",
            "                   detail='{\"threshold\": 42.0, \"evaluation_periods\": 4}',",
            "                   user_id=\"3e5d11fda79448ac99ccefb20be187ca\",",
            "                   project_id=\"b6f16144010811e387e4de429e99ee8c\",",
            "                   on_behalf_of=\"92159030020611e3b26dde429e99ee8c\",",
            "                   timestamp=datetime.datetime(2015, 1, 1, 12, 0, 0, 0),",
            "                   )",
            "",
            "",
            "def _send_notification(event, payload):",
            "    notification = event.replace(\" \", \"_\")",
            "    notification = \"alarm.%s\" % notification",
            "    transport = messaging.get_transport(pecan.request.cfg)",
            "    notifier = messaging.get_notifier(transport, publisher_id=\"aodh.api\")",
            "    # FIXME(sileht): perhaps we need to copy some infos from the",
            "    # pecan request headers like nova does",
            "    notifier.info({}, notification, payload)",
            "",
            "",
            "def stringify_timestamps(data):",
            "    \"\"\"Stringify any datetimes in given dict.\"\"\"",
            "    return dict((k, v.isoformat()",
            "                 if isinstance(v, datetime.datetime) else v)",
            "                for (k, v) in six.iteritems(data))",
            "",
            "",
            "class AlarmController(rest.RestController):",
            "    \"\"\"Manages operations on a single alarm.\"\"\"",
            "",
            "    _custom_actions = {",
            "        'history': ['GET'],",
            "        'state': ['PUT', 'GET'],",
            "    }",
            "",
            "    def __init__(self, alarm_id):",
            "        pecan.request.context['alarm_id'] = alarm_id",
            "        self._id = alarm_id",
            "",
            "    def _enforce_rbac(self, rbac_directive):",
            "        # TODO(sileht): We should be able to relax this since we",
            "        # pass the alarm object to the enforcer.",
            "        auth_project = rbac.get_limited_to_project(pecan.request.headers,",
            "                                                   pecan.request.enforcer)",
            "        alarms = list(pecan.request.storage.get_alarms(alarm_id=self._id,",
            "                                                       project=auth_project))",
            "        if not alarms:",
            "            raise base.AlarmNotFound(alarm=self._id, auth_project=auth_project)",
            "        alarm = alarms[0]",
            "        target = {'user_id': alarm.user_id,",
            "                  'project_id': alarm.project_id}",
            "        rbac.enforce(rbac_directive, pecan.request.headers,",
            "                     pecan.request.enforcer, target)",
            "        return alarm",
            "",
            "    def _record_change(self, data, now, on_behalf_of=None, type=None):",
            "        if not pecan.request.cfg.record_history:",
            "            return",
            "        if not data:",
            "            return",
            "        type = type or models.AlarmChange.RULE_CHANGE",
            "        scrubbed_data = stringify_timestamps(data)",
            "        detail = json.dumps(scrubbed_data)",
            "        user_id = pecan.request.headers.get('X-User-Id')",
            "        project_id = pecan.request.headers.get('X-Project-Id')",
            "        on_behalf_of = on_behalf_of or project_id",
            "        severity = scrubbed_data.get('severity')",
            "        payload = dict(event_id=uuidutils.generate_uuid(),",
            "                       alarm_id=self._id,",
            "                       type=type,",
            "                       detail=detail,",
            "                       user_id=user_id,",
            "                       project_id=project_id,",
            "                       on_behalf_of=on_behalf_of,",
            "                       timestamp=now,",
            "                       severity=severity)",
            "",
            "        try:",
            "            pecan.request.storage.record_alarm_change(payload)",
            "        except aodh.NotImplementedError:",
            "            pass",
            "",
            "        # Revert to the pre-json'ed details ...",
            "        payload['detail'] = scrubbed_data",
            "        _send_notification(type, payload)",
            "",
            "    def _record_delete(self, alarm):",
            "        if not alarm:",
            "            return",
            "        type = models.AlarmChange.DELETION",
            "        detail = {'state': alarm.state}",
            "        user_id = pecan.request.headers.get('X-User-Id')",
            "        project_id = pecan.request.headers.get('X-Project-Id')",
            "        payload = dict(event_id=uuidutils.generate_uuid(),",
            "                       alarm_id=self._id,",
            "                       type=type,",
            "                       detail=detail,",
            "                       user_id=user_id,",
            "                       project_id=project_id,",
            "                       on_behalf_of=project_id,",
            "                       timestamp=timeutils.utcnow(),",
            "                       severity=alarm.severity)",
            "",
            "        pecan.request.storage.delete_alarm(alarm.alarm_id)",
            "        _send_notification(type, payload)",
            "",
            "    @wsme_pecan.wsexpose(Alarm)",
            "    def get(self):",
            "        \"\"\"Return this alarm.\"\"\"",
            "        return Alarm.from_db_model_scrubbed(self._enforce_rbac('get_alarm'))",
            "",
            "    @wsme_pecan.wsexpose(Alarm, body=Alarm)",
            "    def put(self, data):",
            "        \"\"\"Modify this alarm.",
            "",
            "        :param data: an alarm within the request body.",
            "        \"\"\"",
            "",
            "        # Ensure alarm exists",
            "        alarm_in = self._enforce_rbac('change_alarm')",
            "",
            "        now = timeutils.utcnow()",
            "",
            "        data.alarm_id = self._id",
            "",
            "        user, project = rbac.get_limited_to(pecan.request.headers,",
            "                                            pecan.request.enforcer)",
            "        if user:",
            "            data.user_id = user",
            "        elif data.user_id == wtypes.Unset:",
            "            data.user_id = alarm_in.user_id",
            "        if project:",
            "            data.project_id = project",
            "        elif data.project_id == wtypes.Unset:",
            "            data.project_id = alarm_in.project_id",
            "        data.timestamp = now",
            "        if alarm_in.state != data.state:",
            "            data.state_timestamp = now",
            "            data.state_reason = ALARM_REASON_MANUAL",
            "        else:",
            "            data.state_timestamp = alarm_in.state_timestamp",
            "            data.state_reason = alarm_in.state_reason",
            "",
            "        ALARMS_RULES[data.type].plugin.update_hook(data)",
            "",
            "        old_data = Alarm.from_db_model(alarm_in)",
            "        old_alarm = old_data.as_dict(models.Alarm)",
            "        data.update_actions(old_data)",
            "        updated_alarm = data.as_dict(models.Alarm)",
            "        try:",
            "            alarm_in = models.Alarm(**updated_alarm)",
            "        except Exception:",
            "            LOG.exception(\"Error while putting alarm: %s\", updated_alarm)",
            "            raise base.ClientSideError(_(\"Alarm incorrect\"))",
            "",
            "        alarm = pecan.request.storage.update_alarm(alarm_in)",
            "",
            "        change = dict((k, v) for k, v in updated_alarm.items()",
            "                      if v != old_alarm[k] and k not in",
            "                      ['timestamp', 'state_timestamp'])",
            "        self._record_change(change, now, on_behalf_of=alarm.project_id)",
            "        return Alarm.from_db_model_scrubbed(alarm)",
            "",
            "    @wsme_pecan.wsexpose(None, status_code=204)",
            "    def delete(self):",
            "        \"\"\"Delete this alarm.\"\"\"",
            "",
            "        # ensure alarm exists before deleting",
            "        alarm = self._enforce_rbac('delete_alarm')",
            "        self._record_delete(alarm)",
            "        alarm_object = Alarm.from_db_model(alarm)",
            "        alarm_object.delete_actions()",
            "",
            "    @wsme_pecan.wsexpose([AlarmChange], [base.Query], [str], int, str)",
            "    def history(self, q=None, sort=None, limit=None, marker=None):",
            "        \"\"\"Assembles the alarm history requested.",
            "",
            "        :param q: Filter rules for the changes to be described.",
            "        :param sort: A list of pairs of sort key and sort dir.",
            "        :param limit: The maximum number of items to be return.",
            "        :param marker: The pagination query marker.",
            "        \"\"\"",
            "",
            "        # Ensure alarm exists",
            "        self._enforce_rbac('alarm_history')",
            "",
            "        q = q or []",
            "        # allow history to be returned for deleted alarms, but scope changes",
            "        # returned to those carried out on behalf of the auth'd tenant, to",
            "        # avoid inappropriate cross-tenant visibility of alarm history",
            "        auth_project = rbac.get_limited_to_project(pecan.request.headers,",
            "                                                   pecan.request.enforcer)",
            "        conn = pecan.request.storage",
            "        kwargs = v2_utils.query_to_kwargs(",
            "            q, conn.get_alarm_changes, ['on_behalf_of', 'alarm_id'])",
            "        if sort or limit or marker:",
            "            kwargs['pagination'] = v2_utils.get_pagination_options(",
            "                sort, limit, marker, models.AlarmChange)",
            "        return [AlarmChange.from_db_model(ac)",
            "                for ac in conn.get_alarm_changes(self._id, auth_project,",
            "                                                 **kwargs)]",
            "",
            "    @wsme.validate(state_kind_enum)",
            "    @wsme_pecan.wsexpose(state_kind_enum, body=state_kind_enum)",
            "    def put_state(self, state):",
            "        \"\"\"Set the state of this alarm.",
            "",
            "        :param state: an alarm state within the request body.",
            "        \"\"\"",
            "",
            "        alarm = self._enforce_rbac('change_alarm_state')",
            "",
            "        # note(sileht): body are not validated by wsme",
            "        # Workaround for https://bugs.launchpad.net/wsme/+bug/1227229",
            "        if state not in state_kind:",
            "            raise base.ClientSideError(_(\"state invalid\"))",
            "        now = timeutils.utcnow()",
            "        alarm.state = state",
            "        alarm.state_timestamp = now",
            "        alarm.state_reason = ALARM_REASON_MANUAL",
            "        alarm = pecan.request.storage.update_alarm(alarm)",
            "        change = {'state': alarm.state,",
            "                  'state_reason': alarm.state_reason}",
            "        self._record_change(change, now, on_behalf_of=alarm.project_id,",
            "                            type=models.AlarmChange.STATE_TRANSITION)",
            "        return alarm.state",
            "",
            "    @wsme_pecan.wsexpose(state_kind_enum)",
            "    def get_state(self):",
            "        \"\"\"Get the state of this alarm.\"\"\"",
            "        return self._enforce_rbac('get_alarm_state').state",
            "",
            "",
            "class AlarmsController(rest.RestController):",
            "    \"\"\"Manages operations on the alarms collection.\"\"\"",
            "",
            "    @pecan.expose()",
            "    def _lookup(self, alarm_id, *remainder):",
            "        return AlarmController(alarm_id), remainder",
            "",
            "    @staticmethod",
            "    def _record_creation(conn, data, alarm_id, now):",
            "        if not pecan.request.cfg.record_history:",
            "            return",
            "        type = models.AlarmChange.CREATION",
            "        scrubbed_data = stringify_timestamps(data)",
            "        detail = json.dumps(scrubbed_data)",
            "        user_id = pecan.request.headers.get('X-User-Id')",
            "        project_id = pecan.request.headers.get('X-Project-Id')",
            "        severity = scrubbed_data.get('severity')",
            "        payload = dict(event_id=uuidutils.generate_uuid(),",
            "                       alarm_id=alarm_id,",
            "                       type=type,",
            "                       detail=detail,",
            "                       user_id=user_id,",
            "                       project_id=project_id,",
            "                       on_behalf_of=project_id,",
            "                       timestamp=now,",
            "                       severity=severity)",
            "",
            "        try:",
            "            conn.record_alarm_change(payload)",
            "        except aodh.NotImplementedError:",
            "            pass",
            "",
            "        # Revert to the pre-json'ed details ...",
            "        payload['detail'] = scrubbed_data",
            "        _send_notification(type, payload)",
            "",
            "    @wsme_pecan.wsexpose(Alarm, body=Alarm, status_code=201)",
            "    def post(self, data):",
            "        \"\"\"Create a new alarm.",
            "",
            "        :param data: an alarm within the request body.",
            "        \"\"\"",
            "        rbac.enforce('create_alarm', pecan.request.headers,",
            "                     pecan.request.enforcer, {})",
            "",
            "        conn = pecan.request.storage",
            "        now = timeutils.utcnow()",
            "",
            "        data.alarm_id = uuidutils.generate_uuid()",
            "        user_limit, project_limit = rbac.get_limited_to(pecan.request.headers,",
            "                                                        pecan.request.enforcer)",
            "",
            "        def _set_ownership(aspect, owner_limitation, header):",
            "            attr = '%s_id' % aspect",
            "            requested_owner = getattr(data, attr)",
            "            explicit_owner = requested_owner != wtypes.Unset",
            "            caller = pecan.request.headers.get(header)",
            "            if (owner_limitation and explicit_owner",
            "                    and requested_owner != caller):",
            "                raise base.ProjectNotAuthorized(requested_owner, aspect)",
            "",
            "            actual_owner = (owner_limitation or",
            "                            requested_owner if explicit_owner else caller)",
            "            setattr(data, attr, actual_owner)",
            "",
            "        _set_ownership('user', user_limit, 'X-User-Id')",
            "        _set_ownership('project', project_limit, 'X-Project-Id')",
            "",
            "        # Check if there's room for one more alarm",
            "        if is_over_quota(conn, data.project_id, data.user_id):",
            "            raise OverQuota(data)",
            "",
            "        data.timestamp = now",
            "        data.state_timestamp = now",
            "        data.state_reason = ALARM_REASON_DEFAULT",
            "",
            "        ALARMS_RULES[data.type].plugin.create_hook(data)",
            "",
            "        change = data.as_dict(models.Alarm)",
            "",
            "        data.update_actions()",
            "",
            "        try:",
            "            alarm_in = models.Alarm(**change)",
            "        except Exception:",
            "            LOG.exception(\"Error while posting alarm: %s\", change)",
            "            raise base.ClientSideError(_(\"Alarm incorrect\"))",
            "",
            "        alarm = conn.create_alarm(alarm_in)",
            "        self._record_creation(conn, change, alarm.alarm_id, now)",
            "        v2_utils.set_resp_location_hdr(\"/alarms/\" + alarm.alarm_id)",
            "        return Alarm.from_db_model_scrubbed(alarm)",
            "",
            "    @wsme_pecan.wsexpose([Alarm], [base.Query], [str], int, str)",
            "    def get_all(self, q=None, sort=None, limit=None, marker=None):",
            "        \"\"\"Return all alarms, based on the query provided.",
            "",
            "        :param q: Filter rules for the alarms to be returned.",
            "        :param sort: A list of pairs of sort key and sort dir.",
            "        :param limit: The maximum number of items to be return.",
            "        :param marker: The pagination query marker.",
            "        \"\"\"",
            "        target = rbac.target_from_segregation_rule(",
            "            pecan.request.headers, pecan.request.enforcer)",
            "        rbac.enforce('get_alarms', pecan.request.headers,",
            "                     pecan.request.enforcer, target)",
            "",
            "        q = q or []",
            "        # Timestamp is not supported field for Simple Alarm queries",
            "        kwargs = v2_utils.query_to_kwargs(",
            "            q, pecan.request.storage.get_alarms,",
            "            allow_timestamps=False)",
            "        if sort or limit or marker:",
            "            kwargs['pagination'] = v2_utils.get_pagination_options(",
            "                sort, limit, marker, models.Alarm)",
            "        return [Alarm.from_db_model_scrubbed(m)",
            "                for m in pecan.request.storage.get_alarms(**kwargs)]"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0"
        ],
        "dele_reviseLocation": {
            "593": [
                "AlarmController",
                "get"
            ],
            "645": [
                "AlarmController",
                "put"
            ],
            "808": [
                "AlarmsController",
                "post"
            ],
            "832": [
                "AlarmsController",
                "get_all"
            ]
        },
        "addLocation": [
            "aodh.api.controllers.v2.alarms.Alarm.self",
            "aodh.api.controllers.v2.alarms.AlarmController.put",
            "airflow.www.views.LogModelView",
            "aodh.api.controllers.v2.alarms.AlarmController.get",
            "aodh.api.controllers.v2.alarms.Alarm.sample",
            "aodh.api.controllers.v2.alarms.AlarmsController.post",
            "aodh.api.controllers.v2.alarms.AlarmsController.get_all"
        ]
    },
    "aodh/tests/functional/api/v2/test_alarm_scenarios.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1207,
                "afterPatchRowNumber": 1207,
                "PatchRowcode": "         else:"
            },
            "1": {
                "beforePatchRowNumber": 1208,
                "afterPatchRowNumber": 1208,
                "PatchRowcode": "             self.fail(\"Alarm not found\")"
            },
            "2": {
                "beforePatchRowNumber": 1209,
                "afterPatchRowNumber": 1209,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1210,
                "PatchRowcode": "+        data = self._get_alarm(alarm.alarm_id)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1211,
                "PatchRowcode": "+        self.assertEqual("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1212,
                "PatchRowcode": "+            ['trust+http://my.server:1234/foo'], data['ok_actions'])"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1213,
                "PatchRowcode": "+"
            },
            "7": {
                "beforePatchRowNumber": 1210,
                "afterPatchRowNumber": 1214,
                "PatchRowcode": "         with mock.patch('aodh.keystone_client.get_client') as client:"
            },
            "8": {
                "beforePatchRowNumber": 1211,
                "afterPatchRowNumber": 1215,
                "PatchRowcode": "             client.return_value = mock.Mock("
            },
            "9": {
                "beforePatchRowNumber": 1212,
                "afterPatchRowNumber": 1216,
                "PatchRowcode": "                 auth_ref=mock.Mock(user_id='my_user'))"
            },
            "10": {
                "beforePatchRowNumber": 1419,
                "afterPatchRowNumber": 1423,
                "PatchRowcode": "                 self.put_json('/alarms/%s' % data['alarm_id'],"
            },
            "11": {
                "beforePatchRowNumber": 1420,
                "afterPatchRowNumber": 1424,
                "PatchRowcode": "                               params=data,"
            },
            "12": {
                "beforePatchRowNumber": 1421,
                "afterPatchRowNumber": 1425,
                "PatchRowcode": "                               headers=self.auth_headers)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1426,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1427,
                "PatchRowcode": "+        for alarm in list(self.alarm_conn.get_alarms()):"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1428,
                "PatchRowcode": "+            if alarm.alarm_id == data['alarm_id']:"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1429,
                "PatchRowcode": "+                self.assertEqual("
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1430,
                "PatchRowcode": "+                    ['trust+http://5678:delete@something/ok'],"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1431,
                "PatchRowcode": "+                    alarm.ok_actions)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1432,
                "PatchRowcode": "+                break"
            },
            "20": {
                "beforePatchRowNumber": 1422,
                "afterPatchRowNumber": 1433,
                "PatchRowcode": "         data = self._get_alarm('a')"
            },
            "21": {
                "beforePatchRowNumber": 1423,
                "afterPatchRowNumber": 1434,
                "PatchRowcode": "         self.assertEqual("
            },
            "22": {
                "beforePatchRowNumber": 1424,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            ['trust+http://5678:delete@something/ok'], data['ok_actions'])"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1435,
                "PatchRowcode": "+            ['trust+http://something/ok'], data['ok_actions'])"
            },
            "24": {
                "beforePatchRowNumber": 1425,
                "afterPatchRowNumber": 1436,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 1426,
                "afterPatchRowNumber": 1437,
                "PatchRowcode": "         data.update({'ok_actions': ['http://no-trust-something/ok']})"
            },
            "26": {
                "beforePatchRowNumber": 1427,
                "afterPatchRowNumber": 1438,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#",
            "# Copyright 2013 eNovance <licensing@enovance.com>",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"Tests alarm operation.\"\"\"",
            "",
            "import datetime",
            "import json as jsonlib",
            "import operator",
            "import os",
            "",
            "import fixtures",
            "import mock",
            "from oslo_utils import uuidutils",
            "import six",
            "from six import moves",
            "import webtest",
            "",
            "from aodh.api import app",
            "from aodh import messaging",
            "from aodh.storage import models",
            "from aodh.tests import constants",
            "from aodh.tests.functional.api import v2",
            "",
            "",
            "RULE_KEY = 'gnocchi_aggregation_by_metrics_threshold_rule'",
            "",
            "",
            "def default_alarms(auth_headers):",
            "    return [models.Alarm(name='name1',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='a',",
            "                         description='a',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=auth_headers['X-User-Id'],",
            "                         project_id=auth_headers['X-Project-Id'],",
            "                         time_constraints=[dict(name='testcons',",
            "                                                start='0 11 * * *',",
            "                                                duration=300)],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=60,",
            "                                   granularity=1,",
            "                                   metrics=[",
            "                                       '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                       'a1fb80f4-c242-4f57-87c6-68f47521059e'",
            "                                   ])",
            "                         ),",
            "            models.Alarm(name='name2',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='b',",
            "                         description='b',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=False,",
            "                         user_id=auth_headers['X-User-Id'],",
            "                         project_id=auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=4.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=60,",
            "                                   granularity=1,",
            "                                   metrics=[",
            "                                       '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                       'a1fb80f4-c242-4f57-87c6-68f47521059e'",
            "                                   ])",
            "                         ),",
            "            models.Alarm(name='name3',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='c',",
            "                         description='c',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='moderate',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=False,",
            "                         user_id=auth_headers['X-User-Id'],",
            "                         project_id=auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=3.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=60,",
            "                                   granularity=1,",
            "                                   metrics=[",
            "                                       '95f3c171-5605-4021-87ed-eede77101268',",
            "                                       'bf588a78-56c7-4ba4-be46-d71e5002e030',",
            "                                   ])",
            "                         )]",
            "",
            "",
            "class TestAlarmsBase(v2.FunctionalTest):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsBase, self).setUp()",
            "        self.auth_headers = {'X-User-Id': uuidutils.generate_uuid(),",
            "                             'X-Project-Id': uuidutils.generate_uuid()}",
            "",
            "        c = mock.Mock()",
            "        c.capabilities.list.return_value = {'aggregation_methods': [",
            "            'count', 'mean', 'max', 'min', 'first', 'last', 'std']}",
            "        self.useFixture(fixtures.MockPatch(",
            "            'aodh.api.controllers.v2.alarm_rules.gnocchi.client.Client',",
            "            return_value=c",
            "        ))",
            "",
            "    def _verify_alarm(self, json, alarm, expected_name=None):",
            "        if expected_name and alarm.name != expected_name:",
            "            self.fail(\"Alarm not found\")",
            "        for key in json:",
            "            if key.endswith('_rule'):",
            "                storage_key = 'rule'",
            "            else:",
            "                storage_key = key",
            "            self.assertEqual(json[key], getattr(alarm, storage_key))",
            "",
            "    def _get_alarm(self, id, auth_headers=None):",
            "        data = self.get_json('/alarms',",
            "                             headers=auth_headers or self.auth_headers)",
            "        match = [a for a in data if a['alarm_id'] == id]",
            "        self.assertEqual(1, len(match), 'alarm %s not found' % id)",
            "        return match[0]",
            "",
            "    def _update_alarm(self, id, updated_data, auth_headers=None):",
            "        data = self._get_alarm(id, auth_headers)",
            "        data.update(updated_data)",
            "        self.put_json('/alarms/%s' % id,",
            "                      params=data,",
            "                      headers=auth_headers or self.auth_headers)",
            "",
            "    def _delete_alarm(self, id, auth_headers=None):",
            "        self.delete('/alarms/%s' % id,",
            "                    headers=auth_headers or self.auth_headers,",
            "                    status=204)",
            "",
            "",
            "class TestListEmptyAlarms(TestAlarmsBase):",
            "",
            "    def test_empty(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual([], data)",
            "",
            "",
            "class TestAlarms(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarms, self).setUp()",
            "        for alarm in default_alarms(self.auth_headers):",
            "            self.alarm_conn.create_alarm(alarm)",
            "",
            "    def test_list_alarms(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "        self.assertEqual(set(['name1', 'name2', 'name3']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual([['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                           'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                          ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                           'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                          ['95f3c171-5605-4021-87ed-eede77101268',",
            "                           'bf588a78-56c7-4ba4-be46-d71e5002e030']],",
            "                         [r[RULE_KEY]['metrics']",
            "                          for r in sorted(data,",
            "                                          key=operator.itemgetter('name'))])",
            "",
            "    def test_alarms_query_with_timestamp(self):",
            "        date_time = datetime.datetime(2012, 7, 2, 10, 41)",
            "        isotime = date_time.isoformat()",
            "        resp = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'timestamp',",
            "                                 'op': 'gt',",
            "                                 'value': isotime}],",
            "                             expect_errors=True)",
            "        self.assertEqual(resp.status_code, 400)",
            "        self.assertEqual(resp.json['error_message']['faultstring'],",
            "                         'Unknown argument: \"timestamp\": '",
            "                         'not valid for this resource')",
            "",
            "    def test_alarms_query_with_state(self):",
            "        alarm = models.Alarm(name='disabled',",
            "                             type='gnocchi_aggregation_by_metrics_threshold',",
            "                             enabled=False,",
            "                             alarm_id='c',",
            "                             description='c',",
            "                             state='ok',",
            "                             state_reason='Not evaluated',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=dict(",
            "                                 comparison_operator='gt',",
            "                                 threshold=3.0,",
            "                                 aggregation_method='mean',",
            "                                 evaluation_periods=60,",
            "                                 granularity=1,",
            "                                 metrics=[",
            "                                     '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                     'a1fb80f4-c242-4f57-87c6-68f47521059e',",
            "                                 ]),",
            "                             severity='critical')",
            "        self.alarm_conn.update_alarm(alarm)",
            "        resp = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'state',",
            "                                 'op': 'eq',",
            "                                 'value': 'ok'}],",
            "                             )",
            "        self.assertEqual(1, len(resp))",
            "        self.assertEqual('ok', resp[0]['state'])",
            "",
            "    def test_list_alarms_by_type(self):",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'type',",
            "                                   'op': 'eq',",
            "                                   'value':",
            "                                   'gnocchi_aggregation_by_metrics_threshold'",
            "                                   }])",
            "        self.assertEqual(3, len(alarms))",
            "        self.assertEqual(set(['gnocchi_aggregation_by_metrics_threshold']),",
            "                         set(alarm['type'] for alarm in alarms))",
            "",
            "    def test_get_not_existing_alarm(self):",
            "        resp = self.get_json('/alarms/alarm-id-3',",
            "                             headers=self.auth_headers,",
            "                             expect_errors=True)",
            "        self.assertEqual(404, resp.status_code)",
            "        self.assertEqual('Alarm alarm-id-3 not found in project %s' %",
            "                         self.auth_headers[\"X-Project-Id\"],",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_get_alarm(self):",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'name',",
            "                                   'value': 'name1',",
            "                                   }])",
            "        self.assertEqual('name1', alarms[0]['name'])",
            "        self.assertEqual(['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                          'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                         alarms[0][RULE_KEY]['metrics'])",
            "",
            "        one = self.get_json('/alarms/%s' % alarms[0]['alarm_id'],",
            "                            headers=self.auth_headers)",
            "        self.assertEqual('name1', one['name'])",
            "        self.assertEqual(['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                          'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                         one[RULE_KEY]['metrics'])",
            "        self.assertEqual(alarms[0]['alarm_id'], one['alarm_id'])",
            "        self.assertEqual(alarms[0]['repeat_actions'], one['repeat_actions'])",
            "        self.assertEqual(alarms[0]['time_constraints'],",
            "                         one['time_constraints'])",
            "",
            "    def test_get_alarm_disabled(self):",
            "        alarm = models.Alarm(name='disabled',",
            "                             type='gnocchi_aggregation_by_metrics_threshold',",
            "                             enabled=False,",
            "                             alarm_id='c',",
            "                             description='c',",
            "                             state='insufficient data',",
            "                             state_reason='Not evaluated',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=dict(",
            "                                 comparison_operator='gt',",
            "                                 threshold=3.0,",
            "                                 aggregation_method='mean',",
            "                                 evaluation_periods=60,",
            "                                 granularity=1,",
            "                                 metrics=[",
            "                                     '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                     'a1fb80f4-c242-4f57-87c6-68f47521059e',",
            "                                 ]",
            "                             ),",
            "                             severity='critical')",
            "        self.alarm_conn.update_alarm(alarm)",
            "",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'enabled',",
            "                                   'value': 'False'}])",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual('disabled', alarms[0]['name'])",
            "",
            "        one = self.get_json('/alarms/%s' % alarms[0]['alarm_id'],",
            "                            headers=self.auth_headers)",
            "        self.assertEqual('disabled', one['name'])",
            "",
            "    def test_get_alarm_project_filter_wrong_op_normal_user(self):",
            "        project = self.auth_headers['X-Project-Id']",
            "",
            "        def _test(field, op):",
            "            response = self.get_json('/alarms',",
            "                                     q=[{'field': field,",
            "                                         'op': op,",
            "                                         'value': project}],",
            "                                     expect_errors=True,",
            "                                     status=400,",
            "                                     headers=self.auth_headers)",
            "            faultstring = ('Invalid input for field/attribute op. '",
            "                           'Value: \\'%(op)s\\'. unimplemented operator '",
            "                           'for %(field)s' % {'field': field, 'op': op})",
            "            self.assertEqual(faultstring,",
            "                             response.json['error_message']['faultstring'])",
            "",
            "        _test('project', 'ne')",
            "        _test('project_id', 'ne')",
            "",
            "    def test_get_alarm_project_filter_normal_user(self):",
            "        project = self.auth_headers['X-Project-Id']",
            "",
            "        def _test(field):",
            "            alarms = self.get_json('/alarms',",
            "                                   headers=self.auth_headers,",
            "                                   q=[{'field': field,",
            "                                       'op': 'eq',",
            "                                       'value': project}])",
            "            self.assertEqual(3, len(alarms))",
            "",
            "        _test('project')",
            "        _test('project_id')",
            "",
            "    def test_get_alarm_other_project_normal_user(self):",
            "        def _test(field):",
            "            response = self.get_json('/alarms',",
            "                                     q=[{'field': field,",
            "                                         'op': 'eq',",
            "                                         'value': 'other-project'}],",
            "                                     expect_errors=True,",
            "                                     status=401,",
            "                                     headers=self.auth_headers)",
            "            faultstring = 'Not Authorized to access project other-project'",
            "            self.assertEqual(faultstring,",
            "                             response.json['error_message']['faultstring'])",
            "",
            "        _test('project')",
            "        _test('project_id')",
            "",
            "    def test_get_alarm_forbiden(self):",
            "        pf = os.path.abspath('aodh/tests/functional/api/v2/policy.json-test')",
            "        self.CONF.set_override('policy_file', pf, group='oslo_policy')",
            "        self.CONF.set_override('auth_mode', None, group='api')",
            "        self.app = webtest.TestApp(app.load_app(self.CONF))",
            "",
            "        response = self.get_json('/alarms',",
            "                                 expect_errors=True,",
            "                                 status=403,",
            "                                 headers=self.auth_headers)",
            "        faultstring = 'RBAC Authorization Failed'",
            "        self.assertEqual(403, response.status_code)",
            "        self.assertEqual(faultstring,",
            "                         response.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_wsme_workaround(self):",
            "        jsons = {",
            "            'type': {",
            "                'name': 'missing type',",
            "                RULE_KEY: {",
            "                    'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                    'aggregation_method': 'mean',",
            "                    'threshold': 2.0,",
            "                }",
            "            },",
            "            'name': {",
            "                'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "                RULE_KEY: {",
            "                    'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                    'aggregation_method': 'mean',",
            "                    'threshold': 2.0,",
            "                }",
            "            },",
            "            'threshold_rule/metrics': {",
            "                'name': 'missing metrics',",
            "                'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "                RULE_KEY: {",
            "                    'aggregation_method': 'mean',",
            "                    'threshold': 2.0,",
            "                }",
            "            },",
            "            'threshold_rule/threshold': {",
            "                'name': 'missing threshold',",
            "                'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "                RULE_KEY: {",
            "                    'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                    'aggregation_method': 'mean',",
            "                }",
            "            },",
            "        }",
            "        for field, json in six.iteritems(jsons):",
            "            resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                                  status=400, headers=self.auth_headers)",
            "            self.assertEqual(\"Invalid input for field/attribute %s.\"",
            "                             \" Value: \\'None\\'. Mandatory field missing.\"",
            "                             % field.split('/', 1)[-1],",
            "                             resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_time_constraint_start(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_duration',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '11:00am',",
            "                    'duration': 10",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                \"aggregation_method\": \"mean\",",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_duplicate_time_constraint_name(self):",
            "        json = {",
            "            'name': 'added_alarm_duplicate_constraint_name',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* 11 * * *',",
            "                    'duration': 10",
            "                },",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* * * * *',",
            "                    'duration': 20",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                \"aggregation_method\": \"mean\",",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        self.assertEqual(",
            "            \"Time constraint names must be unique for a given alarm.\",",
            "            resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_alarm_null_time_constraint(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_duration',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': None,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "",
            "    def test_post_invalid_alarm_time_constraint_duration(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_duration',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* 11 * * *',",
            "                    'duration': -1,",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_time_constraint_timezone(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_timezone',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* 11 * * *',",
            "                    'duration': 10,",
            "                    'timezone': 'aaaa'",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_granularity(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_granularity',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 2.0,",
            "                'aggregation_method': 'mean',",
            "                'granularity': -1,",
            "            }",
            "",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_null_rule(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_threshold_rule',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: None,",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        self.assertEqual(",
            "            \"gnocchi_aggregation_by_metrics_threshold_rule \"",
            "            \"must be set for gnocchi_aggregation_by_metrics_threshold \"",
            "            \"type alarm\",",
            "            resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_invalid_alarm_input_state(self):",
            "        json = {",
            "            'name': 'alarm1',",
            "            'state': 'bad_state',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute state.\"",
            "                            \" Value: 'bad_state'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_severity(self):",
            "        json = {",
            "            'name': 'alarm1',",
            "            'state': 'ok',",
            "            'severity': 'bad_value',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute severity.\"",
            "                            \" Value: 'bad_value'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_type(self):",
            "        json = {",
            "            'name': 'alarm3',",
            "            'state': 'ok',",
            "            'type': 'bad_type',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute\"",
            "                            \" type.\"",
            "                            \" Value: 'bad_type'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_enabled_str(self):",
            "        json = {",
            "            'name': 'alarm5',",
            "            'enabled': 'bad_enabled',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = \"Value not an unambiguous boolean: bad_enabled\"",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_enabled_int(self):",
            "        json = {",
            "            'name': 'alarm6',",
            "            'enabled': 0,",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'aggregation_method': 'mean',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json,",
            "                              headers=self.auth_headers)",
            "        self.assertFalse(resp.json['enabled'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(4, len(alarms))",
            "",
            "    def _do_post_alarm_invalid_action(self, ok_actions=None,",
            "                                      alarm_actions=None,",
            "                                      insufficient_data_actions=None,",
            "                                      error_message=None):",
            "",
            "        ok_actions = ok_actions or []",
            "        alarm_actions = alarm_actions or []",
            "        insufficient_data_actions = insufficient_data_actions or []",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'added_alarm',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ok_actions,",
            "            'alarm_actions': alarm_actions,",
            "            'insufficient_data_actions': insufficient_data_actions,",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, status=400,",
            "                              headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "        self.assertEqual(error_message,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_invalid_alarm_ok_actions(self):",
            "        self._do_post_alarm_invalid_action(",
            "            ok_actions=['spam://something/ok'],",
            "            error_message='Unsupported action spam://something/ok')",
            "",
            "    def test_post_invalid_alarm_alarm_actions(self):",
            "        self._do_post_alarm_invalid_action(",
            "            alarm_actions=['spam://something/alarm'],",
            "            error_message='Unsupported action spam://something/alarm')",
            "",
            "    def test_post_invalid_alarm_insufficient_data_actions(self):",
            "        self._do_post_alarm_invalid_action(",
            "            insufficient_data_actions=['spam://something/insufficient'],",
            "            error_message='Unsupported action spam://something/insufficient')",
            "",
            "    @staticmethod",
            "    def _fake_urlsplit(*args, **kwargs):",
            "        raise Exception(\"Evil urlsplit!\")",
            "",
            "    def test_post_invalid_alarm_actions_format(self):",
            "        with mock.patch('oslo_utils.netutils.urlsplit',",
            "                        self._fake_urlsplit):",
            "            self._do_post_alarm_invalid_action(",
            "                alarm_actions=['http://[::1'],",
            "                error_message='Unable to parse action http://[::1')",
            "",
            "    def test_post_alarm_defaults(self):",
            "        to_check = {",
            "            'enabled': True,",
            "            'name': 'added_alarm_defaults',",
            "            'ok_actions': [],",
            "            'alarm_actions': [],",
            "            'insufficient_data_actions': [],",
            "            'repeat_actions': False,",
            "        }",
            "",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(4, len(alarms))",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                for key in to_check:",
            "                    self.assertEqual(to_check[key],",
            "                                     getattr(alarm, key))",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "    def test_post_alarm_with_same_name(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'dup_alarm_name',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "",
            "        resp1 = self.post_json('/alarms', params=json, status=201,",
            "                               headers=self.auth_headers)",
            "        resp2 = self.post_json('/alarms', params=json, status=201,",
            "                               headers=self.auth_headers)",
            "        self.assertEqual(resp1.json['name'], resp2.json['name'])",
            "        self.assertNotEqual(resp1.json['alarm_id'], resp2.json['alarm_id'])",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'name',",
            "                                   'value': 'dup_alarm_name'}])",
            "        self.assertEqual(2, len(alarms))",
            "",
            "    def test_post_alarm_noauth(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'added_alarm',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'low',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201)",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        # to check to BoundedInt type conversion",
            "        json[RULE_KEY]['evaluation_periods'] = 3",
            "        json[RULE_KEY]['granularity'] = 180",
            "        if alarms[0].name == 'added_alarm':",
            "            for key in json:",
            "                if key.endswith('_rule'):",
            "                    storage_key = 'rule'",
            "                else:",
            "                    storage_key = key",
            "                self.assertEqual(getattr(alarms[0], storage_key),",
            "                                 json[key])",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "    @staticmethod",
            "    def _alarm_representation_owned_by(identifiers):",
            "        json = {",
            "            'name': 'added_alarm',",
            "            'enabled': False,",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ['http://something/ok'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        for aspect, id in six.iteritems(identifiers):",
            "            json['%s_id' % aspect] = id",
            "        return json",
            "",
            "    def _do_test_post_alarm_as_nonadmin_on_behalf_of_another(self,",
            "                                                             identifiers):",
            "        \"\"\"Test posting an alarm.",
            "",
            "        Test that posting an alarm as non-admin on behalf of another",
            "        user/project fails with an explicit 401 instead of reverting",
            "        to the requestor's identity.",
            "        \"\"\"",
            "        json = self._alarm_representation_owned_by(identifiers)",
            "        headers = {}",
            "        headers.update(self.auth_headers)",
            "        headers['X-Roles'] = 'demo'",
            "        resp = self.post_json('/alarms', params=json, status=401,",
            "                              headers=headers)",
            "        aspect = 'user' if 'user' in identifiers else 'project'",
            "        params = dict(aspect=aspect, id=identifiers[aspect])",
            "        self.assertEqual(\"Not Authorized to access %(aspect)s %(id)s\" % params,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_another_user(self):",
            "        identifiers = dict(user='auseridthatisnotmine')",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_another(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_another_project(self):",
            "        identifiers = dict(project='aprojectidthatisnotmine')",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_another(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_another_creds(self):",
            "        identifiers = dict(user='auseridthatisnotmine',",
            "                           project='aprojectidthatisnotmine')",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_another(identifiers)",
            "",
            "    def _do_test_post_alarm_as_nonadmin_on_behalf_of_self(self, identifiers):",
            "        \"\"\"Test posting an alarm.",
            "",
            "        Test posting an alarm as non-admin on behalf of own user/project",
            "        creates alarm associated with the requestor's identity.",
            "        \"\"\"",
            "        json = self._alarm_representation_owned_by(identifiers)",
            "        headers = {}",
            "        headers.update(self.auth_headers)",
            "        headers['X-Roles'] = 'demo'",
            "        self.post_json('/alarms', params=json, status=201, headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(alarms[0].user_id,",
            "                         self.auth_headers['X-User-Id'])",
            "        self.assertEqual(alarms[0].project_id,",
            "                         self.auth_headers['X-Project-Id'])",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_own_user(self):",
            "        identifiers = dict(user=self.auth_headers['X-User-Id'])",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_self(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_own_project(self):",
            "        identifiers = dict(project=self.auth_headers['X-Project-Id'])",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_self(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_own_creds(self):",
            "        identifiers = dict(user=self.auth_headers['X-User-Id'],",
            "                           project=self.auth_headers['X-Project-Id'])",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_self(identifiers)",
            "",
            "    def test_post_alarm_with_mismatch_between_type_and_rule(self):",
            "        \"\"\"Test the creation of an combination alarm with threshold rule.\"\"\"",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'added_alarm',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_resources_threshold',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json,",
            "                              expect_errors=True, status=400,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(",
            "            \"gnocchi_resources_threshold_rule must \"",
            "            \"be set for gnocchi_resources_threshold type alarm\",",
            "            resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_with_duplicate_actions(self):",
            "        body = {",
            "            'name': 'dup-alarm-actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['http://no.where', 'http://no.where']",
            "        }",
            "        resp = self.post_json('/alarms', params=body,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(201, resp.status_code)",
            "        alarms = list(self.alarm_conn.get_alarms(name='dup-alarm-actions'))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(['http://no.where'], alarms[0].alarm_actions)",
            "",
            "    def test_post_alarm_with_too_many_actions(self):",
            "        self.CONF.set_override('alarm_max_actions', 1, group='api')",
            "        body = {",
            "            'name': 'alarm-with-many-actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['http://no.where', 'http://no.where2']",
            "        }",
            "        resp = self.post_json('/alarms', params=body, expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(400, resp.status_code)",
            "        self.assertEqual(\"alarm_actions count exceeds maximum value 1\",",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_normal_user_set_log_actions(self):",
            "        body = {",
            "            'name': 'log_alarm_actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['log://']",
            "        }",
            "        resp = self.post_json('/alarms', params=body, expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(401, resp.status_code)",
            "        expected_msg = (\"You are not authorized to create action: log://\")",
            "        self.assertEqual(expected_msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_normal_user_set_test_actions(self):",
            "        body = {",
            "            'name': 'test_alarm_actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['test://']",
            "        }",
            "        resp = self.post_json('/alarms', params=body, expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(401, resp.status_code)",
            "        expected_msg = (\"You are not authorized to create action: test://\")",
            "        self.assertEqual(expected_msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_admin_user_set_log_test_actions(self):",
            "        body = {",
            "            'name': 'admin_alarm_actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['test://', 'log://']",
            "        }",
            "        headers = self.auth_headers",
            "        headers['X-Roles'] = 'admin'",
            "        self.post_json('/alarms', params=body, status=201,",
            "                       headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(name='admin_alarm_actions'))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(['test://', 'log://'],",
            "                         alarms[0].alarm_actions)",
            "",
            "    def test_exercise_state_reason(self):",
            "        body = {",
            "            'name': 'nostate',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "        }",
            "        headers = self.auth_headers",
            "        headers['X-Roles'] = 'admin'",
            "",
            "        self.post_json('/alarms', params=body, status=201,",
            "                       headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(name='nostate'))",
            "        self.assertEqual(1, len(alarms))",
            "        alarm_id = alarms[0].alarm_id",
            "",
            "        alarm = self._get_alarm(alarm_id)",
            "        self.assertEqual(\"insufficient data\", alarm['state'])",
            "        self.assertEqual(\"Not evaluated yet\", alarm['state_reason'])",
            "",
            "        # Ensure state reason is updated",
            "        alarm = self._get_alarm('a')",
            "        alarm['state'] = 'ok'",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=alarm,",
            "                      headers=self.auth_headers)",
            "        alarm = self._get_alarm(alarm_id)",
            "        self.assertEqual(\"ok\", alarm['state'])",
            "        self.assertEqual(\"Manually set via API\", alarm['state_reason'])",
            "",
            "        # Ensure state reason read only",
            "        alarm = self._get_alarm('a')",
            "        alarm['state'] = 'alarm'",
            "        alarm['state_reason'] = 'oh no!'",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=alarm,",
            "                      headers=self.auth_headers)",
            "",
            "        alarm = self._get_alarm(alarm_id)",
            "        self.assertEqual(\"alarm\", alarm['state'])",
            "        self.assertEqual(\"Manually set via API\", alarm['state_reason'])",
            "",
            "    def test_post_alarm_without_actions(self):",
            "        body = {",
            "            'name': 'alarm_actions_none',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': None",
            "        }",
            "        headers = self.auth_headers",
            "        headers['X-Roles'] = 'admin'",
            "        self.post_json('/alarms', params=body, status=201,",
            "                       headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(name='alarm_actions_none'))",
            "        self.assertEqual(1, len(alarms))",
            "",
            "        # FIXME(sileht): This should really returns [] not None",
            "        # but SQL just stores the json dict as is...",
            "        # migration script for sql will be a mess because we have",
            "        # to parse all JSON :(",
            "        # I guess we assume that wsme convert the None input to []",
            "        # because of the array type, but it won't...",
            "        self.assertIsNone(alarms[0].alarm_actions)",
            "",
            "    def test_post_alarm_trust(self):",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ['trust+http://my.server:1234/foo'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        auth = mock.Mock()",
            "        trust_client = mock.Mock()",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            mock_session = mock.Mock()",
            "            mock_session.get_user_id.return_value = 'my_user'",
            "            client.return_value = mock.Mock(session=mock_session)",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                trust_client.trusts.create.return_value = mock.Mock(id='5678')",
            "                self.post_json('/alarms', params=json, status=201,",
            "                               headers=self.auth_headers,",
            "                               extra_environ={'keystone.token_auth': auth})",
            "                trust_client.trusts.create.assert_called_once_with(",
            "                    trustor_user=self.auth_headers['X-User-Id'],",
            "                    trustee_user='my_user',",
            "                    project=self.auth_headers['X-Project-Id'],",
            "                    impersonation=True,",
            "                    role_names=[])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                self.assertEqual(",
            "                    ['trust+http://5678:delete@my.server:1234/foo'],",
            "                    alarm.ok_actions)",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            client.return_value = mock.Mock(",
            "                auth_ref=mock.Mock(user_id='my_user'))",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                self.delete('/alarms/%s' % alarm.alarm_id,",
            "                            headers=self.auth_headers,",
            "                            status=204,",
            "                            extra_environ={'keystone.token_auth': auth})",
            "                trust_client.trusts.delete.assert_called_once_with('5678')",
            "",
            "    def test_put_alarm(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_put',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name1',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=json,",
            "                      headers=self.auth_headers)",
            "        alarm = list(self.alarm_conn.get_alarms(alarm_id=alarm_id,",
            "                                                enabled=False))[0]",
            "        self._verify_alarm(json, alarm)",
            "",
            "    def test_put_alarm_as_admin(self):",
            "        json = {",
            "            'user_id': 'myuserid',",
            "            'project_id': 'myprojectid',",
            "            'enabled': False,",
            "            'name': 'name_put',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        headers = {}",
            "        headers.update(self.auth_headers)",
            "        headers['X-Roles'] = 'admin'",
            "",
            "        data = self.get_json('/alarms',",
            "                             headers=headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name1',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=json,",
            "                      headers=headers)",
            "        alarm = list(self.alarm_conn.get_alarms(alarm_id=alarm_id,",
            "                                                enabled=False))[0]",
            "        self.assertEqual('myuserid', alarm.user_id)",
            "        self.assertEqual('myprojectid', alarm.project_id)",
            "        self._verify_alarm(json, alarm)",
            "",
            "    def test_put_alarm_wrong_field(self):",
            "        json = {",
            "            'this_can_not_be_correct': 'ha',",
            "            'enabled': False,",
            "            'name': 'name1',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name1',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        resp = self.put_json('/alarms/%s' % alarm_id,",
            "                             expect_errors=True,",
            "                             params=json,",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(400, resp.status_code)",
            "",
            "    def test_put_alarm_with_existing_name(self):",
            "        \"\"\"Test that update a threshold alarm with an existing name.\"\"\"",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name1',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name2',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        resp = self.put_json('/alarms/%s' % alarm_id,",
            "                             params=json,",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(200, resp.status_code)",
            "",
            "    def test_put_invalid_alarm_actions(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name1',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['spam://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name2',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        resp = self.put_json('/alarms/%s' % alarm_id,",
            "                             expect_errors=True, status=400,",
            "                             params=json,",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(",
            "            'Unsupported action spam://something/ok',",
            "            resp.json['error_message']['faultstring'])",
            "",
            "    def test_put_alarm_trust(self):",
            "        data = self._get_alarm('a')",
            "        data.update({'ok_actions': ['trust+http://something/ok']})",
            "        trust_client = mock.Mock()",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            client.return_value = mock.Mock(",
            "                auth_ref=mock.Mock(user_id='my_user'))",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                trust_client.trusts.create.return_value = mock.Mock(id='5678')",
            "                self.put_json('/alarms/%s' % data['alarm_id'],",
            "                              params=data,",
            "                              headers=self.auth_headers)",
            "        data = self._get_alarm('a')",
            "        self.assertEqual(",
            "            ['trust+http://5678:delete@something/ok'], data['ok_actions'])",
            "",
            "        data.update({'ok_actions': ['http://no-trust-something/ok']})",
            "",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            client.return_value = mock.Mock(",
            "                auth_ref=mock.Mock(user_id='my_user'))",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                self.put_json('/alarms/%s' % data['alarm_id'],",
            "                              params=data,",
            "                              headers=self.auth_headers)",
            "                trust_client.trusts.delete.assert_called_once_with('5678')",
            "",
            "        data = self._get_alarm('a')",
            "        self.assertEqual(",
            "            ['http://no-trust-something/ok'], data['ok_actions'])",
            "",
            "    def test_delete_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        resp = self.delete('/alarms/%s' % data[0]['alarm_id'],",
            "                           headers=self.auth_headers,",
            "                           status=204)",
            "        self.assertEqual(b'', resp.body)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(2, len(alarms))",
            "",
            "    def test_get_state_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        resp = self.get_json('/alarms/%s/state' % data[0]['alarm_id'],",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(resp, data[0]['state'])",
            "",
            "    def test_set_state_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        resp = self.put_json('/alarms/%s/state' % data[0]['alarm_id'],",
            "                             headers=self.auth_headers,",
            "                             params='alarm')",
            "        alarms = list(self.alarm_conn.get_alarms(alarm_id=data[0]['alarm_id']))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual('alarm', alarms[0].state)",
            "        self.assertEqual('Manually set via API',",
            "                         alarms[0].state_reason)",
            "        self.assertEqual('alarm', resp.json)",
            "",
            "    def test_set_invalid_state_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        self.put_json('/alarms/%s/state' % data[0]['alarm_id'],",
            "                      headers=self.auth_headers,",
            "                      params='not valid',",
            "                      status=400)",
            "",
            "    def test_alarms_sends_notification(self):",
            "        # Hit the AlarmsController ...",
            "        json = {",
            "            'name': 'sent_notification',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'low',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 2.0,",
            "                'aggregation_method': 'mean',",
            "            }",
            "",
            "        }",
            "        with mock.patch.object(messaging, 'get_notifier') as get_notifier:",
            "            notifier = get_notifier.return_value",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "            get_notifier.assert_called_once_with(mock.ANY,",
            "                                                 publisher_id='aodh.api')",
            "        calls = notifier.info.call_args_list",
            "        self.assertEqual(1, len(calls))",
            "        args, _ = calls[0]",
            "        context, event_type, payload = args",
            "        self.assertEqual('alarm.creation', event_type)",
            "        self.assertEqual('sent_notification', payload['detail']['name'])",
            "        self.assertEqual(['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                          'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                         payload['detail']['rule']['metrics'])",
            "        self.assertTrue(set(['alarm_id', 'detail', 'event_id', 'on_behalf_of',",
            "                             'project_id', 'timestamp', 'type',",
            "                             'user_id']).issubset(payload.keys()))",
            "",
            "    def test_alarm_sends_notification(self):",
            "        with mock.patch.object(messaging, 'get_notifier') as get_notifier:",
            "            notifier = get_notifier.return_value",
            "            self._update_alarm('a', dict(name='new_name'))",
            "            get_notifier.assert_called_once_with(mock.ANY,",
            "                                                 publisher_id='aodh.api')",
            "        calls = notifier.info.call_args_list",
            "        self.assertEqual(1, len(calls))",
            "        args, _ = calls[0]",
            "        context, event_type, payload = args",
            "        self.assertEqual('alarm.rule_change', event_type)",
            "        self.assertEqual('new_name', payload['detail']['name'])",
            "        self.assertTrue(set(['alarm_id', 'detail', 'event_id', 'on_behalf_of',",
            "                             'project_id', 'timestamp', 'type',",
            "                             'user_id']).issubset(payload.keys()))",
            "",
            "    def test_delete_alarm_sends_notification(self):",
            "        with mock.patch.object(messaging, 'get_notifier') as get_notifier:",
            "            notifier = get_notifier.return_value",
            "            self._delete_alarm(default_alarms(self.auth_headers)[1].alarm_id)",
            "            get_notifier.assert_called_once_with(mock.ANY,",
            "                                                 publisher_id='aodh.api')",
            "        calls = notifier.info.call_args_list",
            "        self.assertEqual(1, len(calls))",
            "        args, _ = calls[0]",
            "        context, event_type, payload = args",
            "        self.assertEqual('alarm.deletion', event_type)",
            "        self.assertEqual('insufficient data', payload['detail']['state'])",
            "        self.assertTrue(set(['alarm_id', 'detail', 'event_id', 'on_behalf_of',",
            "                             'project_id', 'timestamp', 'type', 'severity',",
            "                             'user_id']).issubset(payload.keys()))",
            "",
            "",
            "class TestAlarmsHistory(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsHistory, self).setUp()",
            "        alarm = models.Alarm(",
            "            name='name1',",
            "            type='gnocchi_aggregation_by_metrics_threshold',",
            "            enabled=True,",
            "            alarm_id='a',",
            "            description='a',",
            "            state='insufficient data',",
            "            state_reason='insufficient data',",
            "            severity='critical',",
            "            state_timestamp=constants.MIN_DATETIME,",
            "            timestamp=constants.MIN_DATETIME,",
            "            ok_actions=[],",
            "            insufficient_data_actions=[],",
            "            alarm_actions=[],",
            "            repeat_actions=True,",
            "            user_id=self.auth_headers['X-User-Id'],",
            "            project_id=self.auth_headers['X-Project-Id'],",
            "            time_constraints=[dict(name='testcons',",
            "                                   start='0 11 * * *',",
            "                                   duration=300)],",
            "            rule=dict(comparison_operator='gt',",
            "                      threshold=2.0,",
            "                      aggregation_method='mean',",
            "                      evaluation_periods=60,",
            "                      granularity=1,",
            "                      metrics=['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                               'a1fb80f4-c242-4f57-87c6-68f47521059e']))",
            "        self.alarm_conn.create_alarm(alarm)",
            "",
            "    def _get_alarm_history(self, alarm_id, auth_headers=None, query=None,",
            "                           expect_errors=False, status=200):",
            "        url = '/alarms/%s/history' % alarm_id",
            "        if query:",
            "            url += '?q.op=%(op)s&q.value=%(value)s&q.field=%(field)s' % query",
            "        resp = self.get_json(url,",
            "                             headers=auth_headers or self.auth_headers,",
            "                             expect_errors=expect_errors)",
            "        if expect_errors:",
            "            self.assertEqual(status, resp.status_code)",
            "        return resp",
            "",
            "    def _assert_is_subset(self, expected, actual):",
            "        for k, v in six.iteritems(expected):",
            "            current = actual.get(k)",
            "            if k == 'detail' and isinstance(v, dict):",
            "                current = jsonlib.loads(current)",
            "            self.assertEqual(v, current, 'mismatched field: %s' % k)",
            "        self.assertIsNotNone(actual['event_id'])",
            "",
            "    def _assert_in_json(self, expected, actual):",
            "        actual = jsonlib.dumps(jsonlib.loads(actual), sort_keys=True)",
            "        for k, v in six.iteritems(expected):",
            "            fragment = jsonlib.dumps({k: v}, sort_keys=True)[1:-1]",
            "            self.assertIn(fragment, actual,",
            "                          '%s not in %s' % (fragment, actual))",
            "",
            "    def test_record_alarm_history_config(self):",
            "        self.CONF.set_override('record_history', False)",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self._update_alarm('a', dict(name='renamed'))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.CONF.set_override('record_history', True)",
            "        self._update_alarm('a', dict(name='foobar'))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "",
            "    def test_record_alarm_history_severity(self):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.assertEqual('critical', alarm['severity'])",
            "",
            "        self._update_alarm('a', dict(severity='low'))",
            "        new_alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         history[0]['detail'])",
            "        self.assertEqual('low', new_alarm['severity'])",
            "",
            "    def test_record_alarm_history_statistic(self):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.assertEqual('mean', alarm[RULE_KEY]['aggregation_method'])",
            "",
            "        rule = alarm[RULE_KEY].copy()",
            "        rule['aggregation_method'] = 'min'",
            "        data = dict(gnocchi_aggregation_by_metrics_threshold_rule=rule)",
            "        self._update_alarm('a', data)",
            "        new_alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(\"min\", jsonlib.loads(history[0]['detail'])",
            "                         ['rule'][\"aggregation_method\"])",
            "        self.assertEqual('min', new_alarm[RULE_KEY]['aggregation_method'])",
            "",
            "    def test_redundant_update_alarm_property_no_history_change(self):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.assertEqual('critical', alarm['severity'])",
            "",
            "        self._update_alarm('a', dict(severity='low'))",
            "        new_alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         history[0]['detail'])",
            "        self.assertEqual('low', new_alarm['severity'])",
            "",
            "        self._update_alarm('a', dict(severity='low'))",
            "        updated_history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(updated_history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         updated_history[0]['detail'])",
            "        self.assertEqual(history, updated_history)",
            "",
            "    def test_get_recorded_alarm_history_on_create(self):",
            "        new_alarm = {",
            "            'name': 'new_alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'granularity': 60,",
            "                'evaluation_periods': 1,",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=new_alarm, status=201,",
            "                       headers=self.auth_headers)",
            "",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'name',",
            "                                   'value': 'new_alarm',",
            "                                   }])",
            "        self.assertEqual(1, len(alarms))",
            "        alarm = alarms[0]",
            "",
            "        history = self._get_alarm_history(alarm['alarm_id'])",
            "        self.assertEqual(1, len(history))",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=alarm['project_id'],",
            "                                    type='creation',",
            "                                    user_id=alarm['user_id']),",
            "                               history[0])",
            "        new_alarm['rule'] = new_alarm[RULE_KEY]",
            "        del new_alarm[RULE_KEY]",
            "        self._assert_in_json(new_alarm, history[0]['detail'])",
            "",
            "    def _do_test_get_recorded_alarm_history_on_update(self,",
            "                                                      data,",
            "                                                      type,",
            "                                                      detail,",
            "                                                      auth=None):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self._update_alarm('a', data, auth)",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        project_id = auth['X-Project-Id'] if auth else alarm['project_id']",
            "        user_id = auth['X-User-Id'] if auth else alarm['user_id']",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    detail=detail,",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=project_id,",
            "                                    type=type,",
            "                                    user_id=user_id),",
            "                               history[0])",
            "",
            "    def test_get_recorded_alarm_history_rule_change(self):",
            "        data = dict(name='renamed')",
            "        detail = '{\"name\": \"renamed\"}'",
            "        self._do_test_get_recorded_alarm_history_on_update(data,",
            "                                                           'rule change',",
            "                                                           detail)",
            "",
            "    def test_get_recorded_alarm_history_state_transition_on_behalf_of(self):",
            "        # credentials for new non-admin user, on who's behalf the alarm",
            "        # is created",
            "        member_user = uuidutils.generate_uuid()",
            "        member_project = uuidutils.generate_uuid()",
            "        member_auth = {'X-Roles': 'member',",
            "                       'X-User-Id': member_user,",
            "                       'X-Project-Id': member_project}",
            "        new_alarm = {",
            "            'name': 'new_alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'state': 'ok',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'evaluation_periods': 1,",
            "                'granularity': 60",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=new_alarm, status=201,",
            "                       headers=member_auth)",
            "        alarm = self.get_json('/alarms', headers=member_auth)[0]",
            "",
            "        # effect a state transition as a new administrative user",
            "        admin_user = uuidutils.generate_uuid()",
            "        admin_project = uuidutils.generate_uuid()",
            "        admin_auth = {'X-Roles': 'admin',",
            "                      'X-User-Id': admin_user,",
            "                      'X-Project-Id': admin_project}",
            "        data = dict(state='alarm')",
            "        self._update_alarm(alarm['alarm_id'], data, auth_headers=admin_auth)",
            "",
            "        new_alarm['rule'] = new_alarm[RULE_KEY]",
            "        del new_alarm[RULE_KEY]",
            "",
            "        # ensure that both the creation event and state transition",
            "        # are visible to the non-admin alarm owner and admin user alike",
            "        for auth in [member_auth, admin_auth]:",
            "            history = self._get_alarm_history(alarm['alarm_id'],",
            "                                              auth_headers=auth)",
            "            self.assertEqual(2, len(history), 'hist: %s' % history)",
            "            self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                        detail={\"state\": \"alarm\",",
            "                                                \"state_reason\":",
            "                                                \"Manually set via API\"},",
            "                                        on_behalf_of=alarm['project_id'],",
            "                                        project_id=admin_project,",
            "                                        type='rule change',",
            "                                        user_id=admin_user),",
            "                                   history[0])",
            "            self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                        on_behalf_of=alarm['project_id'],",
            "                                        project_id=member_project,",
            "                                        type='creation',",
            "                                        user_id=member_user),",
            "                                   history[1])",
            "            self._assert_in_json(new_alarm, history[1]['detail'])",
            "",
            "            # ensure on_behalf_of cannot be constrained in an API call",
            "            query = dict(field='on_behalf_of',",
            "                         op='eq',",
            "                         value=alarm['project_id'])",
            "            self._get_alarm_history(alarm['alarm_id'], auth_headers=auth,",
            "                                    query=query, expect_errors=True,",
            "                                    status=400)",
            "",
            "    def test_get_recorded_alarm_history_segregation(self):",
            "        data = dict(name='renamed')",
            "        detail = '{\"name\": \"renamed\"}'",
            "        self._do_test_get_recorded_alarm_history_on_update(data,",
            "                                                           'rule change',",
            "                                                           detail)",
            "        auth = {'X-Roles': 'member',",
            "                'X-User-Id': uuidutils.generate_uuid(),",
            "                'X-Project-Id': uuidutils.generate_uuid()}",
            "        self._get_alarm_history('a', auth_headers=auth,",
            "                                expect_errors=True, status=404)",
            "",
            "    def test_delete_alarm_history_after_deletion(self):",
            "        self._update_alarm('a', dict(name='renamed'))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.delete('/alarms/%s' % 'a',",
            "                    headers=self.auth_headers,",
            "                    status=204)",
            "        self._get_alarm_history('a', expect_errors=True, status=404)",
            "",
            "    def test_get_alarm_history_ordered_by_recentness(self):",
            "        for i in moves.xrange(10):",
            "            self._update_alarm('a', dict(name='%s' % i))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(10, len(history), 'hist: %s' % history)",
            "        self._assert_is_subset(dict(alarm_id='a',",
            "                                    type='rule change'),",
            "                               history[0])",
            "        for i in moves.xrange(1, 11):",
            "            detail = '{\"name\": \"%s\"}' % (10 - i)",
            "            self._assert_is_subset(dict(alarm_id='a',",
            "                                        detail=detail,",
            "                                        type='rule change'),",
            "                                   history[i - 1])",
            "",
            "    def test_get_alarm_history_constrained_by_timestamp(self):",
            "        alarm = self._get_alarm('a')",
            "        self._update_alarm('a', dict(name='renamed'))",
            "        after = datetime.datetime.utcnow().isoformat()",
            "        query = dict(field='timestamp', op='gt', value=after)",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(0, len(history))",
            "        query['op'] = 'le'",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(1, len(history))",
            "        detail = '{\"name\": \"renamed\"}'",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    detail=detail,",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=alarm['project_id'],",
            "                                    type='rule change',",
            "                                    user_id=alarm['user_id']),",
            "                               history[0])",
            "",
            "    def test_get_alarm_history_constrained_by_type(self):",
            "        alarm = self._get_alarm('a')",
            "        self._update_alarm('a', dict(name='renamed2'))",
            "        query = dict(field='type', op='eq', value='rule change')",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(1, len(history))",
            "        detail = '{\"name\": \"renamed2\"}'",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    detail=detail,",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=alarm['project_id'],",
            "                                    type='rule change',",
            "                                    user_id=alarm['user_id']),",
            "                               history[0])",
            "",
            "    def test_get_alarm_history_constrained_by_alarm_id_failed(self):",
            "        query = dict(field='alarm_id', op='eq', value='a')",
            "        resp = self._get_alarm_history('a', query=query,",
            "                                       expect_errors=True, status=400)",
            "        msg = ('Unknown argument: \"alarm_id\": unrecognized'",
            "               \" field in query: [<Query {key!r} eq\"",
            "               \" {value!r} Unset>], valid keys: ['project', \"",
            "               \"'search_offset', 'severity', 'timestamp',\"",
            "               \" 'type', 'user']\")",
            "        msg = msg.format(key=u'alarm_id', value=u'a')",
            "        self.assertEqual(msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_get_alarm_history_constrained_by_not_supported_rule(self):",
            "        query = dict(field='abcd', op='eq', value='abcd')",
            "        resp = self._get_alarm_history('a', query=query,",
            "                                       expect_errors=True, status=400)",
            "        msg = ('Unknown argument: \"abcd\": unrecognized'",
            "               \" field in query: [<Query {key!r} eq\"",
            "               \" {value!r} Unset>], valid keys: ['project', \"",
            "               \"'search_offset', 'severity', 'timestamp',\"",
            "               \" 'type', 'user']\")",
            "        msg = msg.format(key=u'abcd', value=u'abcd')",
            "        self.assertEqual(msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_get_alarm_history_constrained_by_severity(self):",
            "        self._update_alarm('a', dict(severity='low'))",
            "        query = dict(field='severity', op='eq', value='low')",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         history[0]['detail'])",
            "",
            "    def test_get_nonexistent_alarm_history(self):",
            "        self._get_alarm_history('foobar', expect_errors=True, status=404)",
            "",
            "",
            "class TestAlarmsQuotas(TestAlarmsBase):",
            "",
            "    def _test_alarm_quota(self):",
            "        alarm = {",
            "            'name': 'alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'user_id': self.auth_headers['X-User-Id'],",
            "            'project_id': self.auth_headers['X-Project-Id'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'granularity': 60,",
            "                'evaluation_periods': 1,",
            "            }",
            "        }",
            "",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(201, resp.status_code)",
            "        alarms = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(alarms))",
            "",
            "        alarm['name'] = 'another_user_alarm'",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(403, resp.status_code)",
            "        faultstring = 'Alarm quota exceeded for user'",
            "        self.assertIn(faultstring,",
            "                      resp.json['error_message']['faultstring'])",
            "",
            "        alarms = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(alarms))",
            "",
            "    def test_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 1, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_project_alarms_quotas(self):",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_user_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_larger_limit_project_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 1, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 2, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_larger_limit_user_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 2, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_larger_limit_user_alarm_quotas_multitenant_user(self):",
            "        self.CONF.set_override('user_alarm_quota', 2, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "",
            "        def _test(field, value):",
            "            query = [{",
            "                'field': field,",
            "                'op': 'eq',",
            "                'value': value",
            "            }]",
            "            alarms = self.get_json('/alarms', q=query,",
            "                                   headers=self.auth_headers)",
            "            self.assertEqual(1, len(alarms))",
            "",
            "        alarm = {",
            "            'name': 'alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'user_id': self.auth_headers['X-User-Id'],",
            "            'project_id': self.auth_headers['X-Project-Id'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'granularity': 60,",
            "                'evaluation_periods': 1,",
            "            }",
            "        }",
            "",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              headers=self.auth_headers)",
            "",
            "        self.assertEqual(201, resp.status_code)",
            "        _test('project_id', self.auth_headers['X-Project-Id'])",
            "",
            "        self.auth_headers['X-Project-Id'] = uuidutils.generate_uuid()",
            "        alarm['name'] = 'another_user_alarm'",
            "        alarm['project_id'] = self.auth_headers['X-Project-Id']",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              headers=self.auth_headers)",
            "",
            "        self.assertEqual(201, resp.status_code)",
            "        _test('project_id', self.auth_headers['X-Project-Id'])",
            "",
            "        self.auth_headers[\"X-roles\"] = \"admin\"",
            "        alarms = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(2, len(alarms))",
            "",
            "",
            "class TestAlarmsRuleThreshold(TestAlarmsBase):",
            "",
            "    def test_post_invalid_alarm_statistic(self):",
            "        json = {",
            "            'name': 'added_alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 2.0,",
            "                'aggregation_method': 'magic',",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"aggregation_method should be in ['count', \"",
            "                            \"'mean', 'max', 'min', 'first', 'last', 'std'] \"",
            "                            \"not magic\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(0, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_comparison_operator(self):",
            "        json = {",
            "            'name': 'alarm2',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'bad_co',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute\"",
            "                            \" comparison_operator.\"",
            "                            \" Value: 'bad_co'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(0, len(alarms))",
            "",
            "    def test_post_threshold_rule_defaults(self):",
            "        to_check = {",
            "            'name': 'added_alarm_defaults',",
            "            'state': 'insufficient data',",
            "            'description': ('gnocchi_aggregation_by_metrics_threshold '",
            "                            'alarm rule'),",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'threshold': 300.0,",
            "                'comparison_operator': 'eq',",
            "                'aggregation_method': 'mean',",
            "                'evaluation_periods': 1,",
            "                'granularity': 60,",
            "            }",
            "",
            "        }",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                for key in to_check:",
            "                    if key.endswith('_rule'):",
            "                        storage_key = 'rule'",
            "                    else:",
            "                        storage_key = key",
            "                    self.assertEqual(to_check[key],",
            "                                     getattr(alarm, storage_key))",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "",
            "class TestAlarmsRuleGnocchi(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsRuleGnocchi, self).setUp()",
            "        for alarm in [",
            "            models.Alarm(name='name1',",
            "                         type='gnocchi_resources_threshold',",
            "                         enabled=True,",
            "                         alarm_id='e',",
            "                         description='e',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=self.auth_headers['X-User-Id'],",
            "                         project_id=self.auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   granularity=60,",
            "                                   evaluation_periods=1,",
            "                                   metric='meter.test',",
            "                                   resource_type='instance',",
            "                                   resource_id=(",
            "                                       '6841c175-d7c4-4bc2-bc7a-1c7832271b8f'),",
            "                                   )",
            "                         ),",
            "            models.Alarm(name='name2',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='f',",
            "                         description='f',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=self.auth_headers['X-User-Id'],",
            "                         project_id=self.auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=1,",
            "                                   granularity=60,",
            "                                   metrics=[",
            "                                       '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                       'a1fb80f4-c242-4f57-87c6-68f47521059e']",
            "                                   ),",
            "                         ),",
            "            models.Alarm(name='name3',",
            "                         type='gnocchi_aggregation_by_resources_threshold',",
            "                         enabled=True,",
            "                         alarm_id='g',",
            "                         description='f',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=self.auth_headers['X-User-Id'],",
            "                         project_id=self.auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   granularity=60,",
            "                                   evaluation_periods=1,",
            "                                   metric='meter.test',",
            "                                   resource_type='instance',",
            "                                   query='{\"=\": {\"server_group\": '",
            "                                   '\"my_autoscaling_group\"}}')",
            "                         ),",
            "        ]:",
            "",
            "            self.alarm_conn.create_alarm(alarm)",
            "",
            "    def test_list_alarms(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "        self.assertEqual(set(['name1', 'name2', 'name3']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual(set(['meter.test']),",
            "                         set(r['gnocchi_resources_threshold_rule']['metric']",
            "                             for r in data",
            "                             if 'gnocchi_resources_threshold_rule' in r))",
            "",
            "    def test_post_gnocchi_metrics_alarm_cached(self):",
            "        # NOTE(gordc):  cache is a decorator and therefore, gets mocked across",
            "        # entire scenario. ideally we should test both scenario but tough.",
            "        # assume cache will return aggregation_method == ['count'] always.",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_post',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['b3d9d8ab-05e8-439f-89ad-5e978dd2a5eb',",
            "                            '009d4faf-c275-46f0-8f2d-670b15bac2b0'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "            self.assertFalse(clientlib.called)",
            "",
            "    def test_post_gnocchi_resources_alarm(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_post',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_resources_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            'gnocchi_resources_threshold_rule': {",
            "                'metric': 'ameter',",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "                'resource_type': 'instance',",
            "                'resource_id': '209ef69c-c10c-4efb-90ff-46f4b2d90d2e',",
            "            }",
            "        }",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        self._verify_alarm(json, alarms[0])",
            "",
            "    def test_post_gnocchi_metrics_alarm(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_post',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['b3d9d8ab-05e8-439f-89ad-5e978dd2a5eb',",
            "                            '009d4faf-c275-46f0-8f2d-670b15bac2b0'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        self._verify_alarm(json, alarms[0])",
            "",
            "    @mock.patch('aodh.keystone_client.get_client')",
            "    def test_post_gnocchi_aggregation_alarm_project_constraint(self,",
            "                                                               get_client):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'project_constraint',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_resources_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            'gnocchi_aggregation_by_resources_threshold_rule': {",
            "                'metric': 'ameter',",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "                'resource_type': 'instance',",
            "                'query': '{\"=\": {\"server_group\": \"my_autoscaling_group\"}}',",
            "            }",
            "        }",
            "",
            "        expected_query = {\"and\": [",
            "            {\"or\": [",
            "                {\"=\": {\"created_by_project_id\":",
            "                       self.auth_headers['X-Project-Id']}},",
            "                {\"and\": [",
            "                    {\"=\": {\"created_by_project_id\": \"<my-uuid>\"}},",
            "                    {\"=\": {\"project_id\": self.auth_headers['X-Project-Id']}}",
            "                ]},",
            "            ]},",
            "            {\"=\": {\"server_group\": \"my_autoscaling_group\"}},",
            "        ]}",
            "",
            "        ks_client = mock.Mock()",
            "        ks_client.projects.find.return_value = mock.Mock(id='<my-uuid>')",
            "        get_client.return_value = ks_client",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "            self.assertEqual([mock.call(",
            "                aggregation='count',",
            "                metrics='ameter',",
            "                needed_overlap=0,",
            "                start=\"-1 day\",",
            "                stop=\"now\",",
            "                query=expected_query,",
            "                resource_type=\"instance\")],",
            "                c.metric.aggregation.mock_calls),",
            "",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "",
            "        json['gnocchi_aggregation_by_resources_threshold_rule']['query'] = (",
            "            jsonlib.dumps(expected_query))",
            "        self._verify_alarm(json, alarms[0])",
            "",
            "",
            "class TestAlarmsEvent(TestAlarmsBase):",
            "",
            "    def test_list_alarms(self):",
            "        alarm = models.Alarm(name='event.alarm.1',",
            "                             type='event',",
            "                             enabled=True,",
            "                             alarm_id='h',",
            "                             description='h',",
            "                             state='insufficient data',",
            "                             state_reason='insufficient data',",
            "                             severity='moderate',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=dict(event_type='event.test',",
            "                                       query=[]),",
            "                             )",
            "        self.alarm_conn.create_alarm(alarm)",
            "",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(data))",
            "        self.assertEqual(set(['event.alarm.1']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual(set(['event.test']),",
            "                         set(r['event_rule']['event_type']",
            "                             for r in data if 'event_rule' in r))",
            "",
            "    def test_post_event_alarm_defaults(self):",
            "        to_check = {",
            "            'enabled': True,",
            "            'name': 'added_alarm_defaults',",
            "            'state': 'insufficient data',",
            "            'description': 'Alarm when * event occurred.',",
            "            'type': 'event',",
            "            'ok_actions': [],",
            "            'alarm_actions': [],",
            "            'insufficient_data_actions': [],",
            "            'repeat_actions': False,",
            "            'rule': {",
            "                'event_type': '*',",
            "                'query': [],",
            "            }",
            "        }",
            "",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'event',",
            "            'event_rule': {",
            "                'event_type': '*',",
            "                'query': []",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                for key in to_check:",
            "                    self.assertEqual(to_check[key], getattr(alarm, key))",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "",
            "class TestAlarmsCompositeRule(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsCompositeRule, self).setUp()",
            "        self.sub_rule1 = {",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\",",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"evaluation_periods\": 5,",
            "            \"threshold\": 0.8,",
            "            \"aggregation_method\": \"mean\",",
            "            \"granularity\": 60,",
            "            \"comparison_operator\": \"gt\"",
            "        }",
            "        self.sub_rule2 = {",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\",",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"evaluation_periods\": 4,",
            "            \"threshold\": 200,",
            "            \"aggregation_method\": \"max\",",
            "            \"granularity\": 60,",
            "            \"comparison_operator\": \"gt\"",
            "        }",
            "        self.sub_rule3 = {",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\",",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"evaluation_periods\": 3,",
            "            \"threshold\": 1000,",
            "            \"aggregation_method\": \"mean\",",
            "            \"granularity\": 60,",
            "            \"comparison_operator\": \"gt\"",
            "        }",
            "",
            "        self.rule = {",
            "            \"or\": [self.sub_rule1,",
            "                   {",
            "                       \"and\": [self.sub_rule2, self.sub_rule3]",
            "                   }]}",
            "",
            "    def test_list_alarms(self):",
            "        alarm = models.Alarm(name='composite_alarm',",
            "                             type='composite',",
            "                             enabled=True,",
            "                             alarm_id='composite',",
            "                             description='composite',",
            "                             state='insufficient data',",
            "                             state_reason='insufficient data',",
            "                             severity='moderate',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=self.rule,",
            "                             )",
            "        self.alarm_conn.create_alarm(alarm)",
            "",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(data))",
            "        self.assertEqual(set(['composite_alarm']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual(self.rule, data[0]['composite_rule'])",
            "",
            "    def test_post_with_composite_rule(self):",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": self.rule,",
            "            \"repeat_actions\": False",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(self.rule, alarms[0].rule)",
            "",
            "    def test_post_with_sub_rule_with_wrong_type(self):",
            "        self.sub_rule1['type'] = 'non-type'",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": self.rule,",
            "            \"repeat_actions\": False",
            "        }",
            "        response = self.post_json('/alarms', params=json, status=400,",
            "                                  expect_errors=True,",
            "                                  headers=self.auth_headers)",
            "",
            "        err = (\"Unsupported sub-rule type :non-type in composite \"",
            "               \"rule, should be one of: \"",
            "               \"['gnocchi_aggregation_by_metrics_threshold', \"",
            "               \"'gnocchi_aggregation_by_resources_threshold', \"",
            "               \"'gnocchi_resources_threshold']\")",
            "        faultstring = response.json['error_message']['faultstring']",
            "        self.assertEqual(err, faultstring)",
            "",
            "    def test_post_with_sub_rule_with_only_required_params(self):",
            "        sub_rulea = {",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"threshold\": 0.8,",
            "            \"aggregation_method\": \"mean\",",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\"}",
            "        sub_ruleb = {",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"threshold\": 200,",
            "            \"aggregation_method\": \"mean\",",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\"}",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": {\"and\": [sub_rulea, sub_ruleb]},",
            "            \"repeat_actions\": False",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "",
            "    def test_post_with_sub_rule_with_invalid_params(self):",
            "        self.sub_rule1['threshold'] = False",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": self.rule,",
            "            \"repeat_actions\": False",
            "        }",
            "        response = self.post_json('/alarms', params=json, status=400,",
            "                                  expect_errors=True,",
            "                                  headers=self.auth_headers)",
            "        faultstring = (\"Invalid input for field/attribute threshold. \"",
            "                       \"Value: 'False'. Wrong type. Expected '%s', got '%s'\"",
            "                       % (type(1.0), type(True)))",
            "        self.assertEqual(faultstring,",
            "                         response.json['error_message']['faultstring'])",
            "",
            "",
            "class TestPaginationQuery(TestAlarmsBase):",
            "    def setUp(self):",
            "        super(TestPaginationQuery, self).setUp()",
            "        for alarm in default_alarms(self.auth_headers):",
            "            self.alarm_conn.create_alarm(alarm)",
            "",
            "    def test_pagination_query_single_sort(self):",
            "        data = self.get_json('/alarms?sort=name:desc',",
            "                             headers=self.auth_headers)",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name3', 'name2', 'name1'], names)",
            "        data = self.get_json('/alarms?sort=name:asc',",
            "                             headers=self.auth_headers)",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name1', 'name2', 'name3'], names)",
            "",
            "    def test_sort_by_severity_with_its_value(self):",
            "        if self.engine != \"mysql\":",
            "            self.skipTest(\"This is only implemented for MySQL\")",
            "        data = self.get_json('/alarms?sort=severity:asc',",
            "                             headers=self.auth_headers)",
            "        severities = [a['severity'] for a in data]",
            "        self.assertEqual(['moderate', 'critical', 'critical'],",
            "                         severities)",
            "        data = self.get_json('/alarms?sort=severity:desc',",
            "                             headers=self.auth_headers)",
            "        severities = [a['severity'] for a in data]",
            "        self.assertEqual(['critical', 'critical', 'moderate'],",
            "                         severities)",
            "",
            "    def test_pagination_query_limit(self):",
            "        data = self.get_json('/alarms?limit=2', headers=self.auth_headers)",
            "        self.assertEqual(2, len(data))",
            "",
            "    def test_pagination_query_limit_sort(self):",
            "        data = self.get_json('/alarms?sort=name:asc&limit=2',",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(2, len(data))",
            "",
            "    def test_pagination_query_marker(self):",
            "        data = self.get_json('/alarms?sort=name:desc',",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "        alarm_ids = [a['alarm_id'] for a in data]",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name3', 'name2', 'name1'], names)",
            "        marker_url = ('/alarms?sort=name:desc&marker=%s' % alarm_ids[1])",
            "        data = self.get_json(marker_url, headers=self.auth_headers)",
            "        self.assertEqual(1, len(data))",
            "        new_alarm_ids = [a['alarm_id'] for a in data]",
            "        self.assertEqual(alarm_ids[2:], new_alarm_ids)",
            "        new_names = [a['name'] for a in data]",
            "        self.assertEqual(['name1'], new_names)",
            "",
            "    def test_pagination_query_multiple_sorts(self):",
            "        new_alarms = default_alarms(self.auth_headers)",
            "        for a_id in zip(new_alarms, ['e', 'f', 'g', 'h']):",
            "            a_id[0].alarm_id = a_id[1]",
            "            self.alarm_conn.create_alarm(a_id[0])",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(6, len(data))",
            "        sort_url = '/alarms?sort=name:desc&sort=alarm_id:asc'",
            "        data = self.get_json(sort_url, headers=self.auth_headers)",
            "        name_ids = [(a['name'], a['alarm_id']) for a in data]",
            "        expected = [('name3', 'c'),",
            "                    ('name3', 'g'), ('name2', 'b'), ('name2', 'f'),",
            "                    ('name1', 'a'), ('name1', 'e')]",
            "        self.assertEqual(expected, name_ids)",
            "",
            "    def test_pagination_query_invalid_sort_key(self):",
            "        resp = self.get_json('/alarms?sort=invalid_key:desc',",
            "                             headers=self.auth_headers,",
            "                             expect_errors=True)",
            "        self.assertEqual(resp.status_code, 400)",
            "        self.assertEqual(\"Invalid input for field/attribute sort. Value: \"",
            "                         \"'invalid_key:desc'. the sort parameter should be\"",
            "                         \" a pair of sort key and sort dir combined with \"",
            "                         \"':', or only sort key specified and sort dir will \"",
            "                         \"be default 'asc', the supported sort keys are: \"",
            "                         \"('alarm_id', 'enabled', 'name', 'type', 'severity',\"",
            "                         \" 'timestamp', 'user_id', 'project_id', 'state', \"",
            "                         \"'repeat_actions', 'state_timestamp')\",",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_pagination_query_only_sort_key_specified(self):",
            "        data = self.get_json('/alarms?sort=name',",
            "                             headers=self.auth_headers)",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name1', 'name2', 'name3'], names)",
            "",
            "    def test_pagination_query_history_data(self):",
            "        for i in moves.xrange(10):",
            "            self._update_alarm('a', dict(name='%s' % i))",
            "        url = '/alarms/a/history?sort=event_id:desc&sort=timestamp:desc'",
            "        data = self.get_json(url, headers=self.auth_headers)",
            "        sorted_data = sorted(data,",
            "                             key=lambda d: (d['event_id'], d['timestamp']),",
            "                             reverse=True)",
            "        self.assertEqual(sorted_data, data)"
        ],
        "afterPatchFile": [
            "#",
            "# Copyright 2013 eNovance <licensing@enovance.com>",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "# not use this file except in compliance with the License. You may obtain",
            "# a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "# License for the specific language governing permissions and limitations",
            "# under the License.",
            "\"\"\"Tests alarm operation.\"\"\"",
            "",
            "import datetime",
            "import json as jsonlib",
            "import operator",
            "import os",
            "",
            "import fixtures",
            "import mock",
            "from oslo_utils import uuidutils",
            "import six",
            "from six import moves",
            "import webtest",
            "",
            "from aodh.api import app",
            "from aodh import messaging",
            "from aodh.storage import models",
            "from aodh.tests import constants",
            "from aodh.tests.functional.api import v2",
            "",
            "",
            "RULE_KEY = 'gnocchi_aggregation_by_metrics_threshold_rule'",
            "",
            "",
            "def default_alarms(auth_headers):",
            "    return [models.Alarm(name='name1',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='a',",
            "                         description='a',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=auth_headers['X-User-Id'],",
            "                         project_id=auth_headers['X-Project-Id'],",
            "                         time_constraints=[dict(name='testcons',",
            "                                                start='0 11 * * *',",
            "                                                duration=300)],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=60,",
            "                                   granularity=1,",
            "                                   metrics=[",
            "                                       '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                       'a1fb80f4-c242-4f57-87c6-68f47521059e'",
            "                                   ])",
            "                         ),",
            "            models.Alarm(name='name2',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='b',",
            "                         description='b',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=False,",
            "                         user_id=auth_headers['X-User-Id'],",
            "                         project_id=auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=4.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=60,",
            "                                   granularity=1,",
            "                                   metrics=[",
            "                                       '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                       'a1fb80f4-c242-4f57-87c6-68f47521059e'",
            "                                   ])",
            "                         ),",
            "            models.Alarm(name='name3',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='c',",
            "                         description='c',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='moderate',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=False,",
            "                         user_id=auth_headers['X-User-Id'],",
            "                         project_id=auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=3.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=60,",
            "                                   granularity=1,",
            "                                   metrics=[",
            "                                       '95f3c171-5605-4021-87ed-eede77101268',",
            "                                       'bf588a78-56c7-4ba4-be46-d71e5002e030',",
            "                                   ])",
            "                         )]",
            "",
            "",
            "class TestAlarmsBase(v2.FunctionalTest):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsBase, self).setUp()",
            "        self.auth_headers = {'X-User-Id': uuidutils.generate_uuid(),",
            "                             'X-Project-Id': uuidutils.generate_uuid()}",
            "",
            "        c = mock.Mock()",
            "        c.capabilities.list.return_value = {'aggregation_methods': [",
            "            'count', 'mean', 'max', 'min', 'first', 'last', 'std']}",
            "        self.useFixture(fixtures.MockPatch(",
            "            'aodh.api.controllers.v2.alarm_rules.gnocchi.client.Client',",
            "            return_value=c",
            "        ))",
            "",
            "    def _verify_alarm(self, json, alarm, expected_name=None):",
            "        if expected_name and alarm.name != expected_name:",
            "            self.fail(\"Alarm not found\")",
            "        for key in json:",
            "            if key.endswith('_rule'):",
            "                storage_key = 'rule'",
            "            else:",
            "                storage_key = key",
            "            self.assertEqual(json[key], getattr(alarm, storage_key))",
            "",
            "    def _get_alarm(self, id, auth_headers=None):",
            "        data = self.get_json('/alarms',",
            "                             headers=auth_headers or self.auth_headers)",
            "        match = [a for a in data if a['alarm_id'] == id]",
            "        self.assertEqual(1, len(match), 'alarm %s not found' % id)",
            "        return match[0]",
            "",
            "    def _update_alarm(self, id, updated_data, auth_headers=None):",
            "        data = self._get_alarm(id, auth_headers)",
            "        data.update(updated_data)",
            "        self.put_json('/alarms/%s' % id,",
            "                      params=data,",
            "                      headers=auth_headers or self.auth_headers)",
            "",
            "    def _delete_alarm(self, id, auth_headers=None):",
            "        self.delete('/alarms/%s' % id,",
            "                    headers=auth_headers or self.auth_headers,",
            "                    status=204)",
            "",
            "",
            "class TestListEmptyAlarms(TestAlarmsBase):",
            "",
            "    def test_empty(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual([], data)",
            "",
            "",
            "class TestAlarms(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarms, self).setUp()",
            "        for alarm in default_alarms(self.auth_headers):",
            "            self.alarm_conn.create_alarm(alarm)",
            "",
            "    def test_list_alarms(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "        self.assertEqual(set(['name1', 'name2', 'name3']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual([['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                           'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                          ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                           'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                          ['95f3c171-5605-4021-87ed-eede77101268',",
            "                           'bf588a78-56c7-4ba4-be46-d71e5002e030']],",
            "                         [r[RULE_KEY]['metrics']",
            "                          for r in sorted(data,",
            "                                          key=operator.itemgetter('name'))])",
            "",
            "    def test_alarms_query_with_timestamp(self):",
            "        date_time = datetime.datetime(2012, 7, 2, 10, 41)",
            "        isotime = date_time.isoformat()",
            "        resp = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'timestamp',",
            "                                 'op': 'gt',",
            "                                 'value': isotime}],",
            "                             expect_errors=True)",
            "        self.assertEqual(resp.status_code, 400)",
            "        self.assertEqual(resp.json['error_message']['faultstring'],",
            "                         'Unknown argument: \"timestamp\": '",
            "                         'not valid for this resource')",
            "",
            "    def test_alarms_query_with_state(self):",
            "        alarm = models.Alarm(name='disabled',",
            "                             type='gnocchi_aggregation_by_metrics_threshold',",
            "                             enabled=False,",
            "                             alarm_id='c',",
            "                             description='c',",
            "                             state='ok',",
            "                             state_reason='Not evaluated',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=dict(",
            "                                 comparison_operator='gt',",
            "                                 threshold=3.0,",
            "                                 aggregation_method='mean',",
            "                                 evaluation_periods=60,",
            "                                 granularity=1,",
            "                                 metrics=[",
            "                                     '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                     'a1fb80f4-c242-4f57-87c6-68f47521059e',",
            "                                 ]),",
            "                             severity='critical')",
            "        self.alarm_conn.update_alarm(alarm)",
            "        resp = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'state',",
            "                                 'op': 'eq',",
            "                                 'value': 'ok'}],",
            "                             )",
            "        self.assertEqual(1, len(resp))",
            "        self.assertEqual('ok', resp[0]['state'])",
            "",
            "    def test_list_alarms_by_type(self):",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'type',",
            "                                   'op': 'eq',",
            "                                   'value':",
            "                                   'gnocchi_aggregation_by_metrics_threshold'",
            "                                   }])",
            "        self.assertEqual(3, len(alarms))",
            "        self.assertEqual(set(['gnocchi_aggregation_by_metrics_threshold']),",
            "                         set(alarm['type'] for alarm in alarms))",
            "",
            "    def test_get_not_existing_alarm(self):",
            "        resp = self.get_json('/alarms/alarm-id-3',",
            "                             headers=self.auth_headers,",
            "                             expect_errors=True)",
            "        self.assertEqual(404, resp.status_code)",
            "        self.assertEqual('Alarm alarm-id-3 not found in project %s' %",
            "                         self.auth_headers[\"X-Project-Id\"],",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_get_alarm(self):",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'name',",
            "                                   'value': 'name1',",
            "                                   }])",
            "        self.assertEqual('name1', alarms[0]['name'])",
            "        self.assertEqual(['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                          'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                         alarms[0][RULE_KEY]['metrics'])",
            "",
            "        one = self.get_json('/alarms/%s' % alarms[0]['alarm_id'],",
            "                            headers=self.auth_headers)",
            "        self.assertEqual('name1', one['name'])",
            "        self.assertEqual(['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                          'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                         one[RULE_KEY]['metrics'])",
            "        self.assertEqual(alarms[0]['alarm_id'], one['alarm_id'])",
            "        self.assertEqual(alarms[0]['repeat_actions'], one['repeat_actions'])",
            "        self.assertEqual(alarms[0]['time_constraints'],",
            "                         one['time_constraints'])",
            "",
            "    def test_get_alarm_disabled(self):",
            "        alarm = models.Alarm(name='disabled',",
            "                             type='gnocchi_aggregation_by_metrics_threshold',",
            "                             enabled=False,",
            "                             alarm_id='c',",
            "                             description='c',",
            "                             state='insufficient data',",
            "                             state_reason='Not evaluated',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=dict(",
            "                                 comparison_operator='gt',",
            "                                 threshold=3.0,",
            "                                 aggregation_method='mean',",
            "                                 evaluation_periods=60,",
            "                                 granularity=1,",
            "                                 metrics=[",
            "                                     '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                     'a1fb80f4-c242-4f57-87c6-68f47521059e',",
            "                                 ]",
            "                             ),",
            "                             severity='critical')",
            "        self.alarm_conn.update_alarm(alarm)",
            "",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'enabled',",
            "                                   'value': 'False'}])",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual('disabled', alarms[0]['name'])",
            "",
            "        one = self.get_json('/alarms/%s' % alarms[0]['alarm_id'],",
            "                            headers=self.auth_headers)",
            "        self.assertEqual('disabled', one['name'])",
            "",
            "    def test_get_alarm_project_filter_wrong_op_normal_user(self):",
            "        project = self.auth_headers['X-Project-Id']",
            "",
            "        def _test(field, op):",
            "            response = self.get_json('/alarms',",
            "                                     q=[{'field': field,",
            "                                         'op': op,",
            "                                         'value': project}],",
            "                                     expect_errors=True,",
            "                                     status=400,",
            "                                     headers=self.auth_headers)",
            "            faultstring = ('Invalid input for field/attribute op. '",
            "                           'Value: \\'%(op)s\\'. unimplemented operator '",
            "                           'for %(field)s' % {'field': field, 'op': op})",
            "            self.assertEqual(faultstring,",
            "                             response.json['error_message']['faultstring'])",
            "",
            "        _test('project', 'ne')",
            "        _test('project_id', 'ne')",
            "",
            "    def test_get_alarm_project_filter_normal_user(self):",
            "        project = self.auth_headers['X-Project-Id']",
            "",
            "        def _test(field):",
            "            alarms = self.get_json('/alarms',",
            "                                   headers=self.auth_headers,",
            "                                   q=[{'field': field,",
            "                                       'op': 'eq',",
            "                                       'value': project}])",
            "            self.assertEqual(3, len(alarms))",
            "",
            "        _test('project')",
            "        _test('project_id')",
            "",
            "    def test_get_alarm_other_project_normal_user(self):",
            "        def _test(field):",
            "            response = self.get_json('/alarms',",
            "                                     q=[{'field': field,",
            "                                         'op': 'eq',",
            "                                         'value': 'other-project'}],",
            "                                     expect_errors=True,",
            "                                     status=401,",
            "                                     headers=self.auth_headers)",
            "            faultstring = 'Not Authorized to access project other-project'",
            "            self.assertEqual(faultstring,",
            "                             response.json['error_message']['faultstring'])",
            "",
            "        _test('project')",
            "        _test('project_id')",
            "",
            "    def test_get_alarm_forbiden(self):",
            "        pf = os.path.abspath('aodh/tests/functional/api/v2/policy.json-test')",
            "        self.CONF.set_override('policy_file', pf, group='oslo_policy')",
            "        self.CONF.set_override('auth_mode', None, group='api')",
            "        self.app = webtest.TestApp(app.load_app(self.CONF))",
            "",
            "        response = self.get_json('/alarms',",
            "                                 expect_errors=True,",
            "                                 status=403,",
            "                                 headers=self.auth_headers)",
            "        faultstring = 'RBAC Authorization Failed'",
            "        self.assertEqual(403, response.status_code)",
            "        self.assertEqual(faultstring,",
            "                         response.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_wsme_workaround(self):",
            "        jsons = {",
            "            'type': {",
            "                'name': 'missing type',",
            "                RULE_KEY: {",
            "                    'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                    'aggregation_method': 'mean',",
            "                    'threshold': 2.0,",
            "                }",
            "            },",
            "            'name': {",
            "                'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "                RULE_KEY: {",
            "                    'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                    'aggregation_method': 'mean',",
            "                    'threshold': 2.0,",
            "                }",
            "            },",
            "            'threshold_rule/metrics': {",
            "                'name': 'missing metrics',",
            "                'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "                RULE_KEY: {",
            "                    'aggregation_method': 'mean',",
            "                    'threshold': 2.0,",
            "                }",
            "            },",
            "            'threshold_rule/threshold': {",
            "                'name': 'missing threshold',",
            "                'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "                RULE_KEY: {",
            "                    'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                    'aggregation_method': 'mean',",
            "                }",
            "            },",
            "        }",
            "        for field, json in six.iteritems(jsons):",
            "            resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                                  status=400, headers=self.auth_headers)",
            "            self.assertEqual(\"Invalid input for field/attribute %s.\"",
            "                             \" Value: \\'None\\'. Mandatory field missing.\"",
            "                             % field.split('/', 1)[-1],",
            "                             resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_time_constraint_start(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_duration',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '11:00am',",
            "                    'duration': 10",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                \"aggregation_method\": \"mean\",",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_duplicate_time_constraint_name(self):",
            "        json = {",
            "            'name': 'added_alarm_duplicate_constraint_name',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* 11 * * *',",
            "                    'duration': 10",
            "                },",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* * * * *',",
            "                    'duration': 20",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                \"aggregation_method\": \"mean\",",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        self.assertEqual(",
            "            \"Time constraint names must be unique for a given alarm.\",",
            "            resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_alarm_null_time_constraint(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_duration',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': None,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "",
            "    def test_post_invalid_alarm_time_constraint_duration(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_duration',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* 11 * * *',",
            "                    'duration': -1,",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_time_constraint_timezone(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_constraint_timezone',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'time_constraints': [",
            "                {",
            "                    'name': 'testcons',",
            "                    'start': '* 11 * * *',",
            "                    'duration': 10,",
            "                    'timezone': 'aaaa'",
            "                }",
            "            ],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_granularity(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_granularity',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 2.0,",
            "                'aggregation_method': 'mean',",
            "                'granularity': -1,",
            "            }",
            "",
            "        }",
            "        self.post_json('/alarms', params=json, expect_errors=True, status=400,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_null_rule(self):",
            "        json = {",
            "            'name': 'added_alarm_invalid_threshold_rule',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: None,",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        self.assertEqual(",
            "            \"gnocchi_aggregation_by_metrics_threshold_rule \"",
            "            \"must be set for gnocchi_aggregation_by_metrics_threshold \"",
            "            \"type alarm\",",
            "            resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_invalid_alarm_input_state(self):",
            "        json = {",
            "            'name': 'alarm1',",
            "            'state': 'bad_state',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute state.\"",
            "                            \" Value: 'bad_state'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_severity(self):",
            "        json = {",
            "            'name': 'alarm1',",
            "            'state': 'ok',",
            "            'severity': 'bad_value',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute severity.\"",
            "                            \" Value: 'bad_value'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_type(self):",
            "        json = {",
            "            'name': 'alarm3',",
            "            'state': 'ok',",
            "            'type': 'bad_type',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute\"",
            "                            \" type.\"",
            "                            \" Value: 'bad_type'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_enabled_str(self):",
            "        json = {",
            "            'name': 'alarm5',",
            "            'enabled': 'bad_enabled',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = \"Value not an unambiguous boolean: bad_enabled\"",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_enabled_int(self):",
            "        json = {",
            "            'name': 'alarm6',",
            "            'enabled': 0,",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'aggregation_method': 'mean',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json,",
            "                              headers=self.auth_headers)",
            "        self.assertFalse(resp.json['enabled'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(4, len(alarms))",
            "",
            "    def _do_post_alarm_invalid_action(self, ok_actions=None,",
            "                                      alarm_actions=None,",
            "                                      insufficient_data_actions=None,",
            "                                      error_message=None):",
            "",
            "        ok_actions = ok_actions or []",
            "        alarm_actions = alarm_actions or []",
            "        insufficient_data_actions = insufficient_data_actions or []",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'added_alarm',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ok_actions,",
            "            'alarm_actions': alarm_actions,",
            "            'insufficient_data_actions': insufficient_data_actions,",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, status=400,",
            "                              headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(3, len(alarms))",
            "        self.assertEqual(error_message,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_invalid_alarm_ok_actions(self):",
            "        self._do_post_alarm_invalid_action(",
            "            ok_actions=['spam://something/ok'],",
            "            error_message='Unsupported action spam://something/ok')",
            "",
            "    def test_post_invalid_alarm_alarm_actions(self):",
            "        self._do_post_alarm_invalid_action(",
            "            alarm_actions=['spam://something/alarm'],",
            "            error_message='Unsupported action spam://something/alarm')",
            "",
            "    def test_post_invalid_alarm_insufficient_data_actions(self):",
            "        self._do_post_alarm_invalid_action(",
            "            insufficient_data_actions=['spam://something/insufficient'],",
            "            error_message='Unsupported action spam://something/insufficient')",
            "",
            "    @staticmethod",
            "    def _fake_urlsplit(*args, **kwargs):",
            "        raise Exception(\"Evil urlsplit!\")",
            "",
            "    def test_post_invalid_alarm_actions_format(self):",
            "        with mock.patch('oslo_utils.netutils.urlsplit',",
            "                        self._fake_urlsplit):",
            "            self._do_post_alarm_invalid_action(",
            "                alarm_actions=['http://[::1'],",
            "                error_message='Unable to parse action http://[::1')",
            "",
            "    def test_post_alarm_defaults(self):",
            "        to_check = {",
            "            'enabled': True,",
            "            'name': 'added_alarm_defaults',",
            "            'ok_actions': [],",
            "            'alarm_actions': [],",
            "            'insufficient_data_actions': [],",
            "            'repeat_actions': False,",
            "        }",
            "",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(4, len(alarms))",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                for key in to_check:",
            "                    self.assertEqual(to_check[key],",
            "                                     getattr(alarm, key))",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "    def test_post_alarm_with_same_name(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'dup_alarm_name',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "",
            "        resp1 = self.post_json('/alarms', params=json, status=201,",
            "                               headers=self.auth_headers)",
            "        resp2 = self.post_json('/alarms', params=json, status=201,",
            "                               headers=self.auth_headers)",
            "        self.assertEqual(resp1.json['name'], resp2.json['name'])",
            "        self.assertNotEqual(resp1.json['alarm_id'], resp2.json['alarm_id'])",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'name',",
            "                                   'value': 'dup_alarm_name'}])",
            "        self.assertEqual(2, len(alarms))",
            "",
            "    def test_post_alarm_noauth(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'added_alarm',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'low',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201)",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        # to check to BoundedInt type conversion",
            "        json[RULE_KEY]['evaluation_periods'] = 3",
            "        json[RULE_KEY]['granularity'] = 180",
            "        if alarms[0].name == 'added_alarm':",
            "            for key in json:",
            "                if key.endswith('_rule'):",
            "                    storage_key = 'rule'",
            "                else:",
            "                    storage_key = key",
            "                self.assertEqual(getattr(alarms[0], storage_key),",
            "                                 json[key])",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "    @staticmethod",
            "    def _alarm_representation_owned_by(identifiers):",
            "        json = {",
            "            'name': 'added_alarm',",
            "            'enabled': False,",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ['http://something/ok'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        for aspect, id in six.iteritems(identifiers):",
            "            json['%s_id' % aspect] = id",
            "        return json",
            "",
            "    def _do_test_post_alarm_as_nonadmin_on_behalf_of_another(self,",
            "                                                             identifiers):",
            "        \"\"\"Test posting an alarm.",
            "",
            "        Test that posting an alarm as non-admin on behalf of another",
            "        user/project fails with an explicit 401 instead of reverting",
            "        to the requestor's identity.",
            "        \"\"\"",
            "        json = self._alarm_representation_owned_by(identifiers)",
            "        headers = {}",
            "        headers.update(self.auth_headers)",
            "        headers['X-Roles'] = 'demo'",
            "        resp = self.post_json('/alarms', params=json, status=401,",
            "                              headers=headers)",
            "        aspect = 'user' if 'user' in identifiers else 'project'",
            "        params = dict(aspect=aspect, id=identifiers[aspect])",
            "        self.assertEqual(\"Not Authorized to access %(aspect)s %(id)s\" % params,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_another_user(self):",
            "        identifiers = dict(user='auseridthatisnotmine')",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_another(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_another_project(self):",
            "        identifiers = dict(project='aprojectidthatisnotmine')",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_another(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_another_creds(self):",
            "        identifiers = dict(user='auseridthatisnotmine',",
            "                           project='aprojectidthatisnotmine')",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_another(identifiers)",
            "",
            "    def _do_test_post_alarm_as_nonadmin_on_behalf_of_self(self, identifiers):",
            "        \"\"\"Test posting an alarm.",
            "",
            "        Test posting an alarm as non-admin on behalf of own user/project",
            "        creates alarm associated with the requestor's identity.",
            "        \"\"\"",
            "        json = self._alarm_representation_owned_by(identifiers)",
            "        headers = {}",
            "        headers.update(self.auth_headers)",
            "        headers['X-Roles'] = 'demo'",
            "        self.post_json('/alarms', params=json, status=201, headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(alarms[0].user_id,",
            "                         self.auth_headers['X-User-Id'])",
            "        self.assertEqual(alarms[0].project_id,",
            "                         self.auth_headers['X-Project-Id'])",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_own_user(self):",
            "        identifiers = dict(user=self.auth_headers['X-User-Id'])",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_self(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_own_project(self):",
            "        identifiers = dict(project=self.auth_headers['X-Project-Id'])",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_self(identifiers)",
            "",
            "    def test_post_alarm_as_nonadmin_on_behalf_of_own_creds(self):",
            "        identifiers = dict(user=self.auth_headers['X-User-Id'],",
            "                           project=self.auth_headers['X-Project-Id'])",
            "        self._do_test_post_alarm_as_nonadmin_on_behalf_of_self(identifiers)",
            "",
            "    def test_post_alarm_with_mismatch_between_type_and_rule(self):",
            "        \"\"\"Test the creation of an combination alarm with threshold rule.\"\"\"",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'added_alarm',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_resources_threshold',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json,",
            "                              expect_errors=True, status=400,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(",
            "            \"gnocchi_resources_threshold_rule must \"",
            "            \"be set for gnocchi_resources_threshold type alarm\",",
            "            resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_with_duplicate_actions(self):",
            "        body = {",
            "            'name': 'dup-alarm-actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['http://no.where', 'http://no.where']",
            "        }",
            "        resp = self.post_json('/alarms', params=body,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(201, resp.status_code)",
            "        alarms = list(self.alarm_conn.get_alarms(name='dup-alarm-actions'))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(['http://no.where'], alarms[0].alarm_actions)",
            "",
            "    def test_post_alarm_with_too_many_actions(self):",
            "        self.CONF.set_override('alarm_max_actions', 1, group='api')",
            "        body = {",
            "            'name': 'alarm-with-many-actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['http://no.where', 'http://no.where2']",
            "        }",
            "        resp = self.post_json('/alarms', params=body, expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(400, resp.status_code)",
            "        self.assertEqual(\"alarm_actions count exceeds maximum value 1\",",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_normal_user_set_log_actions(self):",
            "        body = {",
            "            'name': 'log_alarm_actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['log://']",
            "        }",
            "        resp = self.post_json('/alarms', params=body, expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(401, resp.status_code)",
            "        expected_msg = (\"You are not authorized to create action: log://\")",
            "        self.assertEqual(expected_msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_normal_user_set_test_actions(self):",
            "        body = {",
            "            'name': 'test_alarm_actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['test://']",
            "        }",
            "        resp = self.post_json('/alarms', params=body, expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(401, resp.status_code)",
            "        expected_msg = (\"You are not authorized to create action: test://\")",
            "        self.assertEqual(expected_msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_post_alarm_admin_user_set_log_test_actions(self):",
            "        body = {",
            "            'name': 'admin_alarm_actions',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': ['test://', 'log://']",
            "        }",
            "        headers = self.auth_headers",
            "        headers['X-Roles'] = 'admin'",
            "        self.post_json('/alarms', params=body, status=201,",
            "                       headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(name='admin_alarm_actions'))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(['test://', 'log://'],",
            "                         alarms[0].alarm_actions)",
            "",
            "    def test_exercise_state_reason(self):",
            "        body = {",
            "            'name': 'nostate',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "        }",
            "        headers = self.auth_headers",
            "        headers['X-Roles'] = 'admin'",
            "",
            "        self.post_json('/alarms', params=body, status=201,",
            "                       headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(name='nostate'))",
            "        self.assertEqual(1, len(alarms))",
            "        alarm_id = alarms[0].alarm_id",
            "",
            "        alarm = self._get_alarm(alarm_id)",
            "        self.assertEqual(\"insufficient data\", alarm['state'])",
            "        self.assertEqual(\"Not evaluated yet\", alarm['state_reason'])",
            "",
            "        # Ensure state reason is updated",
            "        alarm = self._get_alarm('a')",
            "        alarm['state'] = 'ok'",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=alarm,",
            "                      headers=self.auth_headers)",
            "        alarm = self._get_alarm(alarm_id)",
            "        self.assertEqual(\"ok\", alarm['state'])",
            "        self.assertEqual(\"Manually set via API\", alarm['state_reason'])",
            "",
            "        # Ensure state reason read only",
            "        alarm = self._get_alarm('a')",
            "        alarm['state'] = 'alarm'",
            "        alarm['state_reason'] = 'oh no!'",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=alarm,",
            "                      headers=self.auth_headers)",
            "",
            "        alarm = self._get_alarm(alarm_id)",
            "        self.assertEqual(\"alarm\", alarm['state'])",
            "        self.assertEqual(\"Manually set via API\", alarm['state_reason'])",
            "",
            "    def test_post_alarm_without_actions(self):",
            "        body = {",
            "            'name': 'alarm_actions_none',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': '3',",
            "                'granularity': '180',",
            "            },",
            "            'alarm_actions': None",
            "        }",
            "        headers = self.auth_headers",
            "        headers['X-Roles'] = 'admin'",
            "        self.post_json('/alarms', params=body, status=201,",
            "                       headers=headers)",
            "        alarms = list(self.alarm_conn.get_alarms(name='alarm_actions_none'))",
            "        self.assertEqual(1, len(alarms))",
            "",
            "        # FIXME(sileht): This should really returns [] not None",
            "        # but SQL just stores the json dict as is...",
            "        # migration script for sql will be a mess because we have",
            "        # to parse all JSON :(",
            "        # I guess we assume that wsme convert the None input to []",
            "        # because of the array type, but it won't...",
            "        self.assertIsNone(alarms[0].alarm_actions)",
            "",
            "    def test_post_alarm_trust(self):",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'ok_actions': ['trust+http://my.server:1234/foo'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        auth = mock.Mock()",
            "        trust_client = mock.Mock()",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            mock_session = mock.Mock()",
            "            mock_session.get_user_id.return_value = 'my_user'",
            "            client.return_value = mock.Mock(session=mock_session)",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                trust_client.trusts.create.return_value = mock.Mock(id='5678')",
            "                self.post_json('/alarms', params=json, status=201,",
            "                               headers=self.auth_headers,",
            "                               extra_environ={'keystone.token_auth': auth})",
            "                trust_client.trusts.create.assert_called_once_with(",
            "                    trustor_user=self.auth_headers['X-User-Id'],",
            "                    trustee_user='my_user',",
            "                    project=self.auth_headers['X-Project-Id'],",
            "                    impersonation=True,",
            "                    role_names=[])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                self.assertEqual(",
            "                    ['trust+http://5678:delete@my.server:1234/foo'],",
            "                    alarm.ok_actions)",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "        data = self._get_alarm(alarm.alarm_id)",
            "        self.assertEqual(",
            "            ['trust+http://my.server:1234/foo'], data['ok_actions'])",
            "",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            client.return_value = mock.Mock(",
            "                auth_ref=mock.Mock(user_id='my_user'))",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                self.delete('/alarms/%s' % alarm.alarm_id,",
            "                            headers=self.auth_headers,",
            "                            status=204,",
            "                            extra_environ={'keystone.token_auth': auth})",
            "                trust_client.trusts.delete.assert_called_once_with('5678')",
            "",
            "    def test_put_alarm(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_put',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name1',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=json,",
            "                      headers=self.auth_headers)",
            "        alarm = list(self.alarm_conn.get_alarms(alarm_id=alarm_id,",
            "                                                enabled=False))[0]",
            "        self._verify_alarm(json, alarm)",
            "",
            "    def test_put_alarm_as_admin(self):",
            "        json = {",
            "            'user_id': 'myuserid',",
            "            'project_id': 'myprojectid',",
            "            'enabled': False,",
            "            'name': 'name_put',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        headers = {}",
            "        headers.update(self.auth_headers)",
            "        headers['X-Roles'] = 'admin'",
            "",
            "        data = self.get_json('/alarms',",
            "                             headers=headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name1',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        self.put_json('/alarms/%s' % alarm_id,",
            "                      params=json,",
            "                      headers=headers)",
            "        alarm = list(self.alarm_conn.get_alarms(alarm_id=alarm_id,",
            "                                                enabled=False))[0]",
            "        self.assertEqual('myuserid', alarm.user_id)",
            "        self.assertEqual('myprojectid', alarm.project_id)",
            "        self._verify_alarm(json, alarm)",
            "",
            "    def test_put_alarm_wrong_field(self):",
            "        json = {",
            "            'this_can_not_be_correct': 'ha',",
            "            'enabled': False,",
            "            'name': 'name1',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name1',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        resp = self.put_json('/alarms/%s' % alarm_id,",
            "                             expect_errors=True,",
            "                             params=json,",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(400, resp.status_code)",
            "",
            "    def test_put_alarm_with_existing_name(self):",
            "        \"\"\"Test that update a threshold alarm with an existing name.\"\"\"",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name1',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name2',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        resp = self.put_json('/alarms/%s' % alarm_id,",
            "                             params=json,",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(200, resp.status_code)",
            "",
            "    def test_put_invalid_alarm_actions(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name1',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['spam://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "        data = self.get_json('/alarms',",
            "                             headers=self.auth_headers,",
            "                             q=[{'field': 'name',",
            "                                 'value': 'name2',",
            "                                 }])",
            "        self.assertEqual(1, len(data))",
            "        alarm_id = data[0]['alarm_id']",
            "",
            "        resp = self.put_json('/alarms/%s' % alarm_id,",
            "                             expect_errors=True, status=400,",
            "                             params=json,",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(",
            "            'Unsupported action spam://something/ok',",
            "            resp.json['error_message']['faultstring'])",
            "",
            "    def test_put_alarm_trust(self):",
            "        data = self._get_alarm('a')",
            "        data.update({'ok_actions': ['trust+http://something/ok']})",
            "        trust_client = mock.Mock()",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            client.return_value = mock.Mock(",
            "                auth_ref=mock.Mock(user_id='my_user'))",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                trust_client.trusts.create.return_value = mock.Mock(id='5678')",
            "                self.put_json('/alarms/%s' % data['alarm_id'],",
            "                              params=data,",
            "                              headers=self.auth_headers)",
            "",
            "        for alarm in list(self.alarm_conn.get_alarms()):",
            "            if alarm.alarm_id == data['alarm_id']:",
            "                self.assertEqual(",
            "                    ['trust+http://5678:delete@something/ok'],",
            "                    alarm.ok_actions)",
            "                break",
            "        data = self._get_alarm('a')",
            "        self.assertEqual(",
            "            ['trust+http://something/ok'], data['ok_actions'])",
            "",
            "        data.update({'ok_actions': ['http://no-trust-something/ok']})",
            "",
            "        with mock.patch('aodh.keystone_client.get_client') as client:",
            "            client.return_value = mock.Mock(",
            "                auth_ref=mock.Mock(user_id='my_user'))",
            "            with mock.patch('keystoneclient.v3.client.Client') as sub_client:",
            "                sub_client.return_value = trust_client",
            "                self.put_json('/alarms/%s' % data['alarm_id'],",
            "                              params=data,",
            "                              headers=self.auth_headers)",
            "                trust_client.trusts.delete.assert_called_once_with('5678')",
            "",
            "        data = self._get_alarm('a')",
            "        self.assertEqual(",
            "            ['http://no-trust-something/ok'], data['ok_actions'])",
            "",
            "    def test_delete_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        resp = self.delete('/alarms/%s' % data[0]['alarm_id'],",
            "                           headers=self.auth_headers,",
            "                           status=204)",
            "        self.assertEqual(b'', resp.body)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(2, len(alarms))",
            "",
            "    def test_get_state_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        resp = self.get_json('/alarms/%s/state' % data[0]['alarm_id'],",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(resp, data[0]['state'])",
            "",
            "    def test_set_state_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        resp = self.put_json('/alarms/%s/state' % data[0]['alarm_id'],",
            "                             headers=self.auth_headers,",
            "                             params='alarm')",
            "        alarms = list(self.alarm_conn.get_alarms(alarm_id=data[0]['alarm_id']))",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual('alarm', alarms[0].state)",
            "        self.assertEqual('Manually set via API',",
            "                         alarms[0].state_reason)",
            "        self.assertEqual('alarm', resp.json)",
            "",
            "    def test_set_invalid_state_alarm(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "",
            "        self.put_json('/alarms/%s/state' % data[0]['alarm_id'],",
            "                      headers=self.auth_headers,",
            "                      params='not valid',",
            "                      status=400)",
            "",
            "    def test_alarms_sends_notification(self):",
            "        # Hit the AlarmsController ...",
            "        json = {",
            "            'name': 'sent_notification',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'low',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 2.0,",
            "                'aggregation_method': 'mean',",
            "            }",
            "",
            "        }",
            "        with mock.patch.object(messaging, 'get_notifier') as get_notifier:",
            "            notifier = get_notifier.return_value",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "            get_notifier.assert_called_once_with(mock.ANY,",
            "                                                 publisher_id='aodh.api')",
            "        calls = notifier.info.call_args_list",
            "        self.assertEqual(1, len(calls))",
            "        args, _ = calls[0]",
            "        context, event_type, payload = args",
            "        self.assertEqual('alarm.creation', event_type)",
            "        self.assertEqual('sent_notification', payload['detail']['name'])",
            "        self.assertEqual(['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                          'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                         payload['detail']['rule']['metrics'])",
            "        self.assertTrue(set(['alarm_id', 'detail', 'event_id', 'on_behalf_of',",
            "                             'project_id', 'timestamp', 'type',",
            "                             'user_id']).issubset(payload.keys()))",
            "",
            "    def test_alarm_sends_notification(self):",
            "        with mock.patch.object(messaging, 'get_notifier') as get_notifier:",
            "            notifier = get_notifier.return_value",
            "            self._update_alarm('a', dict(name='new_name'))",
            "            get_notifier.assert_called_once_with(mock.ANY,",
            "                                                 publisher_id='aodh.api')",
            "        calls = notifier.info.call_args_list",
            "        self.assertEqual(1, len(calls))",
            "        args, _ = calls[0]",
            "        context, event_type, payload = args",
            "        self.assertEqual('alarm.rule_change', event_type)",
            "        self.assertEqual('new_name', payload['detail']['name'])",
            "        self.assertTrue(set(['alarm_id', 'detail', 'event_id', 'on_behalf_of',",
            "                             'project_id', 'timestamp', 'type',",
            "                             'user_id']).issubset(payload.keys()))",
            "",
            "    def test_delete_alarm_sends_notification(self):",
            "        with mock.patch.object(messaging, 'get_notifier') as get_notifier:",
            "            notifier = get_notifier.return_value",
            "            self._delete_alarm(default_alarms(self.auth_headers)[1].alarm_id)",
            "            get_notifier.assert_called_once_with(mock.ANY,",
            "                                                 publisher_id='aodh.api')",
            "        calls = notifier.info.call_args_list",
            "        self.assertEqual(1, len(calls))",
            "        args, _ = calls[0]",
            "        context, event_type, payload = args",
            "        self.assertEqual('alarm.deletion', event_type)",
            "        self.assertEqual('insufficient data', payload['detail']['state'])",
            "        self.assertTrue(set(['alarm_id', 'detail', 'event_id', 'on_behalf_of',",
            "                             'project_id', 'timestamp', 'type', 'severity',",
            "                             'user_id']).issubset(payload.keys()))",
            "",
            "",
            "class TestAlarmsHistory(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsHistory, self).setUp()",
            "        alarm = models.Alarm(",
            "            name='name1',",
            "            type='gnocchi_aggregation_by_metrics_threshold',",
            "            enabled=True,",
            "            alarm_id='a',",
            "            description='a',",
            "            state='insufficient data',",
            "            state_reason='insufficient data',",
            "            severity='critical',",
            "            state_timestamp=constants.MIN_DATETIME,",
            "            timestamp=constants.MIN_DATETIME,",
            "            ok_actions=[],",
            "            insufficient_data_actions=[],",
            "            alarm_actions=[],",
            "            repeat_actions=True,",
            "            user_id=self.auth_headers['X-User-Id'],",
            "            project_id=self.auth_headers['X-Project-Id'],",
            "            time_constraints=[dict(name='testcons',",
            "                                   start='0 11 * * *',",
            "                                   duration=300)],",
            "            rule=dict(comparison_operator='gt',",
            "                      threshold=2.0,",
            "                      aggregation_method='mean',",
            "                      evaluation_periods=60,",
            "                      granularity=1,",
            "                      metrics=['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                               'a1fb80f4-c242-4f57-87c6-68f47521059e']))",
            "        self.alarm_conn.create_alarm(alarm)",
            "",
            "    def _get_alarm_history(self, alarm_id, auth_headers=None, query=None,",
            "                           expect_errors=False, status=200):",
            "        url = '/alarms/%s/history' % alarm_id",
            "        if query:",
            "            url += '?q.op=%(op)s&q.value=%(value)s&q.field=%(field)s' % query",
            "        resp = self.get_json(url,",
            "                             headers=auth_headers or self.auth_headers,",
            "                             expect_errors=expect_errors)",
            "        if expect_errors:",
            "            self.assertEqual(status, resp.status_code)",
            "        return resp",
            "",
            "    def _assert_is_subset(self, expected, actual):",
            "        for k, v in six.iteritems(expected):",
            "            current = actual.get(k)",
            "            if k == 'detail' and isinstance(v, dict):",
            "                current = jsonlib.loads(current)",
            "            self.assertEqual(v, current, 'mismatched field: %s' % k)",
            "        self.assertIsNotNone(actual['event_id'])",
            "",
            "    def _assert_in_json(self, expected, actual):",
            "        actual = jsonlib.dumps(jsonlib.loads(actual), sort_keys=True)",
            "        for k, v in six.iteritems(expected):",
            "            fragment = jsonlib.dumps({k: v}, sort_keys=True)[1:-1]",
            "            self.assertIn(fragment, actual,",
            "                          '%s not in %s' % (fragment, actual))",
            "",
            "    def test_record_alarm_history_config(self):",
            "        self.CONF.set_override('record_history', False)",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self._update_alarm('a', dict(name='renamed'))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.CONF.set_override('record_history', True)",
            "        self._update_alarm('a', dict(name='foobar'))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "",
            "    def test_record_alarm_history_severity(self):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.assertEqual('critical', alarm['severity'])",
            "",
            "        self._update_alarm('a', dict(severity='low'))",
            "        new_alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         history[0]['detail'])",
            "        self.assertEqual('low', new_alarm['severity'])",
            "",
            "    def test_record_alarm_history_statistic(self):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.assertEqual('mean', alarm[RULE_KEY]['aggregation_method'])",
            "",
            "        rule = alarm[RULE_KEY].copy()",
            "        rule['aggregation_method'] = 'min'",
            "        data = dict(gnocchi_aggregation_by_metrics_threshold_rule=rule)",
            "        self._update_alarm('a', data)",
            "        new_alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(\"min\", jsonlib.loads(history[0]['detail'])",
            "                         ['rule'][\"aggregation_method\"])",
            "        self.assertEqual('min', new_alarm[RULE_KEY]['aggregation_method'])",
            "",
            "    def test_redundant_update_alarm_property_no_history_change(self):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self.assertEqual('critical', alarm['severity'])",
            "",
            "        self._update_alarm('a', dict(severity='low'))",
            "        new_alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         history[0]['detail'])",
            "        self.assertEqual('low', new_alarm['severity'])",
            "",
            "        self._update_alarm('a', dict(severity='low'))",
            "        updated_history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(updated_history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         updated_history[0]['detail'])",
            "        self.assertEqual(history, updated_history)",
            "",
            "    def test_get_recorded_alarm_history_on_create(self):",
            "        new_alarm = {",
            "            'name': 'new_alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'granularity': 60,",
            "                'evaluation_periods': 1,",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=new_alarm, status=201,",
            "                       headers=self.auth_headers)",
            "",
            "        alarms = self.get_json('/alarms',",
            "                               headers=self.auth_headers,",
            "                               q=[{'field': 'name',",
            "                                   'value': 'new_alarm',",
            "                                   }])",
            "        self.assertEqual(1, len(alarms))",
            "        alarm = alarms[0]",
            "",
            "        history = self._get_alarm_history(alarm['alarm_id'])",
            "        self.assertEqual(1, len(history))",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=alarm['project_id'],",
            "                                    type='creation',",
            "                                    user_id=alarm['user_id']),",
            "                               history[0])",
            "        new_alarm['rule'] = new_alarm[RULE_KEY]",
            "        del new_alarm[RULE_KEY]",
            "        self._assert_in_json(new_alarm, history[0]['detail'])",
            "",
            "    def _do_test_get_recorded_alarm_history_on_update(self,",
            "                                                      data,",
            "                                                      type,",
            "                                                      detail,",
            "                                                      auth=None):",
            "        alarm = self._get_alarm('a')",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual([], history)",
            "        self._update_alarm('a', data, auth)",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        project_id = auth['X-Project-Id'] if auth else alarm['project_id']",
            "        user_id = auth['X-User-Id'] if auth else alarm['user_id']",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    detail=detail,",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=project_id,",
            "                                    type=type,",
            "                                    user_id=user_id),",
            "                               history[0])",
            "",
            "    def test_get_recorded_alarm_history_rule_change(self):",
            "        data = dict(name='renamed')",
            "        detail = '{\"name\": \"renamed\"}'",
            "        self._do_test_get_recorded_alarm_history_on_update(data,",
            "                                                           'rule change',",
            "                                                           detail)",
            "",
            "    def test_get_recorded_alarm_history_state_transition_on_behalf_of(self):",
            "        # credentials for new non-admin user, on who's behalf the alarm",
            "        # is created",
            "        member_user = uuidutils.generate_uuid()",
            "        member_project = uuidutils.generate_uuid()",
            "        member_auth = {'X-Roles': 'member',",
            "                       'X-User-Id': member_user,",
            "                       'X-Project-Id': member_project}",
            "        new_alarm = {",
            "            'name': 'new_alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'state': 'ok',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'evaluation_periods': 1,",
            "                'granularity': 60",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=new_alarm, status=201,",
            "                       headers=member_auth)",
            "        alarm = self.get_json('/alarms', headers=member_auth)[0]",
            "",
            "        # effect a state transition as a new administrative user",
            "        admin_user = uuidutils.generate_uuid()",
            "        admin_project = uuidutils.generate_uuid()",
            "        admin_auth = {'X-Roles': 'admin',",
            "                      'X-User-Id': admin_user,",
            "                      'X-Project-Id': admin_project}",
            "        data = dict(state='alarm')",
            "        self._update_alarm(alarm['alarm_id'], data, auth_headers=admin_auth)",
            "",
            "        new_alarm['rule'] = new_alarm[RULE_KEY]",
            "        del new_alarm[RULE_KEY]",
            "",
            "        # ensure that both the creation event and state transition",
            "        # are visible to the non-admin alarm owner and admin user alike",
            "        for auth in [member_auth, admin_auth]:",
            "            history = self._get_alarm_history(alarm['alarm_id'],",
            "                                              auth_headers=auth)",
            "            self.assertEqual(2, len(history), 'hist: %s' % history)",
            "            self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                        detail={\"state\": \"alarm\",",
            "                                                \"state_reason\":",
            "                                                \"Manually set via API\"},",
            "                                        on_behalf_of=alarm['project_id'],",
            "                                        project_id=admin_project,",
            "                                        type='rule change',",
            "                                        user_id=admin_user),",
            "                                   history[0])",
            "            self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                        on_behalf_of=alarm['project_id'],",
            "                                        project_id=member_project,",
            "                                        type='creation',",
            "                                        user_id=member_user),",
            "                                   history[1])",
            "            self._assert_in_json(new_alarm, history[1]['detail'])",
            "",
            "            # ensure on_behalf_of cannot be constrained in an API call",
            "            query = dict(field='on_behalf_of',",
            "                         op='eq',",
            "                         value=alarm['project_id'])",
            "            self._get_alarm_history(alarm['alarm_id'], auth_headers=auth,",
            "                                    query=query, expect_errors=True,",
            "                                    status=400)",
            "",
            "    def test_get_recorded_alarm_history_segregation(self):",
            "        data = dict(name='renamed')",
            "        detail = '{\"name\": \"renamed\"}'",
            "        self._do_test_get_recorded_alarm_history_on_update(data,",
            "                                                           'rule change',",
            "                                                           detail)",
            "        auth = {'X-Roles': 'member',",
            "                'X-User-Id': uuidutils.generate_uuid(),",
            "                'X-Project-Id': uuidutils.generate_uuid()}",
            "        self._get_alarm_history('a', auth_headers=auth,",
            "                                expect_errors=True, status=404)",
            "",
            "    def test_delete_alarm_history_after_deletion(self):",
            "        self._update_alarm('a', dict(name='renamed'))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(1, len(history))",
            "        self.delete('/alarms/%s' % 'a',",
            "                    headers=self.auth_headers,",
            "                    status=204)",
            "        self._get_alarm_history('a', expect_errors=True, status=404)",
            "",
            "    def test_get_alarm_history_ordered_by_recentness(self):",
            "        for i in moves.xrange(10):",
            "            self._update_alarm('a', dict(name='%s' % i))",
            "        history = self._get_alarm_history('a')",
            "        self.assertEqual(10, len(history), 'hist: %s' % history)",
            "        self._assert_is_subset(dict(alarm_id='a',",
            "                                    type='rule change'),",
            "                               history[0])",
            "        for i in moves.xrange(1, 11):",
            "            detail = '{\"name\": \"%s\"}' % (10 - i)",
            "            self._assert_is_subset(dict(alarm_id='a',",
            "                                        detail=detail,",
            "                                        type='rule change'),",
            "                                   history[i - 1])",
            "",
            "    def test_get_alarm_history_constrained_by_timestamp(self):",
            "        alarm = self._get_alarm('a')",
            "        self._update_alarm('a', dict(name='renamed'))",
            "        after = datetime.datetime.utcnow().isoformat()",
            "        query = dict(field='timestamp', op='gt', value=after)",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(0, len(history))",
            "        query['op'] = 'le'",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(1, len(history))",
            "        detail = '{\"name\": \"renamed\"}'",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    detail=detail,",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=alarm['project_id'],",
            "                                    type='rule change',",
            "                                    user_id=alarm['user_id']),",
            "                               history[0])",
            "",
            "    def test_get_alarm_history_constrained_by_type(self):",
            "        alarm = self._get_alarm('a')",
            "        self._update_alarm('a', dict(name='renamed2'))",
            "        query = dict(field='type', op='eq', value='rule change')",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(1, len(history))",
            "        detail = '{\"name\": \"renamed2\"}'",
            "        self._assert_is_subset(dict(alarm_id=alarm['alarm_id'],",
            "                                    detail=detail,",
            "                                    on_behalf_of=alarm['project_id'],",
            "                                    project_id=alarm['project_id'],",
            "                                    type='rule change',",
            "                                    user_id=alarm['user_id']),",
            "                               history[0])",
            "",
            "    def test_get_alarm_history_constrained_by_alarm_id_failed(self):",
            "        query = dict(field='alarm_id', op='eq', value='a')",
            "        resp = self._get_alarm_history('a', query=query,",
            "                                       expect_errors=True, status=400)",
            "        msg = ('Unknown argument: \"alarm_id\": unrecognized'",
            "               \" field in query: [<Query {key!r} eq\"",
            "               \" {value!r} Unset>], valid keys: ['project', \"",
            "               \"'search_offset', 'severity', 'timestamp',\"",
            "               \" 'type', 'user']\")",
            "        msg = msg.format(key=u'alarm_id', value=u'a')",
            "        self.assertEqual(msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_get_alarm_history_constrained_by_not_supported_rule(self):",
            "        query = dict(field='abcd', op='eq', value='abcd')",
            "        resp = self._get_alarm_history('a', query=query,",
            "                                       expect_errors=True, status=400)",
            "        msg = ('Unknown argument: \"abcd\": unrecognized'",
            "               \" field in query: [<Query {key!r} eq\"",
            "               \" {value!r} Unset>], valid keys: ['project', \"",
            "               \"'search_offset', 'severity', 'timestamp',\"",
            "               \" 'type', 'user']\")",
            "        msg = msg.format(key=u'abcd', value=u'abcd')",
            "        self.assertEqual(msg,",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_get_alarm_history_constrained_by_severity(self):",
            "        self._update_alarm('a', dict(severity='low'))",
            "        query = dict(field='severity', op='eq', value='low')",
            "        history = self._get_alarm_history('a', query=query)",
            "        self.assertEqual(1, len(history))",
            "        self.assertEqual(jsonlib.dumps({'severity': 'low'}),",
            "                         history[0]['detail'])",
            "",
            "    def test_get_nonexistent_alarm_history(self):",
            "        self._get_alarm_history('foobar', expect_errors=True, status=404)",
            "",
            "",
            "class TestAlarmsQuotas(TestAlarmsBase):",
            "",
            "    def _test_alarm_quota(self):",
            "        alarm = {",
            "            'name': 'alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'user_id': self.auth_headers['X-User-Id'],",
            "            'project_id': self.auth_headers['X-Project-Id'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'granularity': 60,",
            "                'evaluation_periods': 1,",
            "            }",
            "        }",
            "",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(201, resp.status_code)",
            "        alarms = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(alarms))",
            "",
            "        alarm['name'] = 'another_user_alarm'",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              expect_errors=True,",
            "                              headers=self.auth_headers)",
            "        self.assertEqual(403, resp.status_code)",
            "        faultstring = 'Alarm quota exceeded for user'",
            "        self.assertIn(faultstring,",
            "                      resp.json['error_message']['faultstring'])",
            "",
            "        alarms = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(alarms))",
            "",
            "    def test_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 1, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_project_alarms_quotas(self):",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_user_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_larger_limit_project_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 1, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 2, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_larger_limit_user_alarms_quotas(self):",
            "        self.CONF.set_override('user_alarm_quota', 2, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "        self._test_alarm_quota()",
            "",
            "    def test_larger_limit_user_alarm_quotas_multitenant_user(self):",
            "        self.CONF.set_override('user_alarm_quota', 2, 'api')",
            "        self.CONF.set_override('project_alarm_quota', 1, 'api')",
            "",
            "        def _test(field, value):",
            "            query = [{",
            "                'field': field,",
            "                'op': 'eq',",
            "                'value': value",
            "            }]",
            "            alarms = self.get_json('/alarms', q=query,",
            "                                   headers=self.auth_headers)",
            "            self.assertEqual(1, len(alarms))",
            "",
            "        alarm = {",
            "            'name': 'alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'user_id': self.auth_headers['X-User-Id'],",
            "            'project_id': self.auth_headers['X-Project-Id'],",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'max',",
            "                'threshold': 42.0,",
            "                'granularity': 60,",
            "                'evaluation_periods': 1,",
            "            }",
            "        }",
            "",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              headers=self.auth_headers)",
            "",
            "        self.assertEqual(201, resp.status_code)",
            "        _test('project_id', self.auth_headers['X-Project-Id'])",
            "",
            "        self.auth_headers['X-Project-Id'] = uuidutils.generate_uuid()",
            "        alarm['name'] = 'another_user_alarm'",
            "        alarm['project_id'] = self.auth_headers['X-Project-Id']",
            "        resp = self.post_json('/alarms', params=alarm,",
            "                              headers=self.auth_headers)",
            "",
            "        self.assertEqual(201, resp.status_code)",
            "        _test('project_id', self.auth_headers['X-Project-Id'])",
            "",
            "        self.auth_headers[\"X-roles\"] = \"admin\"",
            "        alarms = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(2, len(alarms))",
            "",
            "",
            "class TestAlarmsRuleThreshold(TestAlarmsBase):",
            "",
            "    def test_post_invalid_alarm_statistic(self):",
            "        json = {",
            "            'name': 'added_alarm',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'gt',",
            "                'threshold': 2.0,",
            "                'aggregation_method': 'magic',",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"aggregation_method should be in ['count', \"",
            "                            \"'mean', 'max', 'min', 'first', 'last', 'std'] \"",
            "                            \"not magic\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(0, len(alarms))",
            "",
            "    def test_post_invalid_alarm_input_comparison_operator(self):",
            "        json = {",
            "            'name': 'alarm2',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'comparison_operator': 'bad_co',",
            "                'threshold': 50.0",
            "            }",
            "        }",
            "        resp = self.post_json('/alarms', params=json, expect_errors=True,",
            "                              status=400, headers=self.auth_headers)",
            "        expected_err_msg = (\"Invalid input for field/attribute\"",
            "                            \" comparison_operator.\"",
            "                            \" Value: 'bad_co'.\")",
            "        self.assertIn(expected_err_msg,",
            "                      resp.json['error_message']['faultstring'])",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(0, len(alarms))",
            "",
            "    def test_post_threshold_rule_defaults(self):",
            "        to_check = {",
            "            'name': 'added_alarm_defaults',",
            "            'state': 'insufficient data',",
            "            'description': ('gnocchi_aggregation_by_metrics_threshold '",
            "                            'alarm rule'),",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'threshold': 300.0,",
            "                'comparison_operator': 'eq',",
            "                'aggregation_method': 'mean',",
            "                'evaluation_periods': 1,",
            "                'granularity': 60,",
            "            }",
            "",
            "        }",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            RULE_KEY: {",
            "                'metrics': ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                            'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "                'aggregation_method': 'mean',",
            "                'threshold': 300.0",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                for key in to_check:",
            "                    if key.endswith('_rule'):",
            "                        storage_key = 'rule'",
            "                    else:",
            "                        storage_key = key",
            "                    self.assertEqual(to_check[key],",
            "                                     getattr(alarm, storage_key))",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "",
            "class TestAlarmsRuleGnocchi(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsRuleGnocchi, self).setUp()",
            "        for alarm in [",
            "            models.Alarm(name='name1',",
            "                         type='gnocchi_resources_threshold',",
            "                         enabled=True,",
            "                         alarm_id='e',",
            "                         description='e',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=self.auth_headers['X-User-Id'],",
            "                         project_id=self.auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   granularity=60,",
            "                                   evaluation_periods=1,",
            "                                   metric='meter.test',",
            "                                   resource_type='instance',",
            "                                   resource_id=(",
            "                                       '6841c175-d7c4-4bc2-bc7a-1c7832271b8f'),",
            "                                   )",
            "                         ),",
            "            models.Alarm(name='name2',",
            "                         type='gnocchi_aggregation_by_metrics_threshold',",
            "                         enabled=True,",
            "                         alarm_id='f',",
            "                         description='f',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=self.auth_headers['X-User-Id'],",
            "                         project_id=self.auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   evaluation_periods=1,",
            "                                   granularity=60,",
            "                                   metrics=[",
            "                                       '41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                                       'a1fb80f4-c242-4f57-87c6-68f47521059e']",
            "                                   ),",
            "                         ),",
            "            models.Alarm(name='name3',",
            "                         type='gnocchi_aggregation_by_resources_threshold',",
            "                         enabled=True,",
            "                         alarm_id='g',",
            "                         description='f',",
            "                         state='insufficient data',",
            "                         state_reason='Not evaluated',",
            "                         severity='critical',",
            "                         state_timestamp=constants.MIN_DATETIME,",
            "                         timestamp=constants.MIN_DATETIME,",
            "                         ok_actions=[],",
            "                         insufficient_data_actions=[],",
            "                         alarm_actions=[],",
            "                         repeat_actions=True,",
            "                         user_id=self.auth_headers['X-User-Id'],",
            "                         project_id=self.auth_headers['X-Project-Id'],",
            "                         time_constraints=[],",
            "                         rule=dict(comparison_operator='gt',",
            "                                   threshold=2.0,",
            "                                   aggregation_method='mean',",
            "                                   granularity=60,",
            "                                   evaluation_periods=1,",
            "                                   metric='meter.test',",
            "                                   resource_type='instance',",
            "                                   query='{\"=\": {\"server_group\": '",
            "                                   '\"my_autoscaling_group\"}}')",
            "                         ),",
            "        ]:",
            "",
            "            self.alarm_conn.create_alarm(alarm)",
            "",
            "    def test_list_alarms(self):",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "        self.assertEqual(set(['name1', 'name2', 'name3']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual(set(['meter.test']),",
            "                         set(r['gnocchi_resources_threshold_rule']['metric']",
            "                             for r in data",
            "                             if 'gnocchi_resources_threshold_rule' in r))",
            "",
            "    def test_post_gnocchi_metrics_alarm_cached(self):",
            "        # NOTE(gordc):  cache is a decorator and therefore, gets mocked across",
            "        # entire scenario. ideally we should test both scenario but tough.",
            "        # assume cache will return aggregation_method == ['count'] always.",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_post',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['b3d9d8ab-05e8-439f-89ad-5e978dd2a5eb',",
            "                            '009d4faf-c275-46f0-8f2d-670b15bac2b0'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "            self.assertFalse(clientlib.called)",
            "",
            "    def test_post_gnocchi_resources_alarm(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_post',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_resources_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            'gnocchi_resources_threshold_rule': {",
            "                'metric': 'ameter',",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "                'resource_type': 'instance',",
            "                'resource_id': '209ef69c-c10c-4efb-90ff-46f4b2d90d2e',",
            "            }",
            "        }",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        self._verify_alarm(json, alarms[0])",
            "",
            "    def test_post_gnocchi_metrics_alarm(self):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'name_post',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_metrics_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            RULE_KEY: {",
            "                'metrics': ['b3d9d8ab-05e8-439f-89ad-5e978dd2a5eb',",
            "                            '009d4faf-c275-46f0-8f2d-670b15bac2b0'],",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "            }",
            "        }",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "        self._verify_alarm(json, alarms[0])",
            "",
            "    @mock.patch('aodh.keystone_client.get_client')",
            "    def test_post_gnocchi_aggregation_alarm_project_constraint(self,",
            "                                                               get_client):",
            "        json = {",
            "            'enabled': False,",
            "            'name': 'project_constraint',",
            "            'state': 'ok',",
            "            'type': 'gnocchi_aggregation_by_resources_threshold',",
            "            'severity': 'critical',",
            "            'ok_actions': ['http://something/ok'],",
            "            'alarm_actions': ['http://something/alarm'],",
            "            'insufficient_data_actions': ['http://something/no'],",
            "            'repeat_actions': True,",
            "            'gnocchi_aggregation_by_resources_threshold_rule': {",
            "                'metric': 'ameter',",
            "                'comparison_operator': 'le',",
            "                'aggregation_method': 'count',",
            "                'threshold': 50,",
            "                'evaluation_periods': 3,",
            "                'granularity': 180,",
            "                'resource_type': 'instance',",
            "                'query': '{\"=\": {\"server_group\": \"my_autoscaling_group\"}}',",
            "            }",
            "        }",
            "",
            "        expected_query = {\"and\": [",
            "            {\"or\": [",
            "                {\"=\": {\"created_by_project_id\":",
            "                       self.auth_headers['X-Project-Id']}},",
            "                {\"and\": [",
            "                    {\"=\": {\"created_by_project_id\": \"<my-uuid>\"}},",
            "                    {\"=\": {\"project_id\": self.auth_headers['X-Project-Id']}}",
            "                ]},",
            "            ]},",
            "            {\"=\": {\"server_group\": \"my_autoscaling_group\"}},",
            "        ]}",
            "",
            "        ks_client = mock.Mock()",
            "        ks_client.projects.find.return_value = mock.Mock(id='<my-uuid>')",
            "        get_client.return_value = ks_client",
            "",
            "        with mock.patch('aodh.api.controllers.v2.alarm_rules.'",
            "                        'gnocchi.client') as clientlib:",
            "            c = clientlib.Client.return_value",
            "            c.capabilities.list.return_value = {",
            "                'aggregation_methods': ['count']}",
            "            self.post_json('/alarms', params=json, headers=self.auth_headers)",
            "",
            "            self.assertEqual([mock.call(",
            "                aggregation='count',",
            "                metrics='ameter',",
            "                needed_overlap=0,",
            "                start=\"-1 day\",",
            "                stop=\"now\",",
            "                query=expected_query,",
            "                resource_type=\"instance\")],",
            "                c.metric.aggregation.mock_calls),",
            "",
            "        alarms = list(self.alarm_conn.get_alarms(enabled=False))",
            "        self.assertEqual(1, len(alarms))",
            "",
            "        json['gnocchi_aggregation_by_resources_threshold_rule']['query'] = (",
            "            jsonlib.dumps(expected_query))",
            "        self._verify_alarm(json, alarms[0])",
            "",
            "",
            "class TestAlarmsEvent(TestAlarmsBase):",
            "",
            "    def test_list_alarms(self):",
            "        alarm = models.Alarm(name='event.alarm.1',",
            "                             type='event',",
            "                             enabled=True,",
            "                             alarm_id='h',",
            "                             description='h',",
            "                             state='insufficient data',",
            "                             state_reason='insufficient data',",
            "                             severity='moderate',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=dict(event_type='event.test',",
            "                                       query=[]),",
            "                             )",
            "        self.alarm_conn.create_alarm(alarm)",
            "",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(data))",
            "        self.assertEqual(set(['event.alarm.1']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual(set(['event.test']),",
            "                         set(r['event_rule']['event_type']",
            "                             for r in data if 'event_rule' in r))",
            "",
            "    def test_post_event_alarm_defaults(self):",
            "        to_check = {",
            "            'enabled': True,",
            "            'name': 'added_alarm_defaults',",
            "            'state': 'insufficient data',",
            "            'description': 'Alarm when * event occurred.',",
            "            'type': 'event',",
            "            'ok_actions': [],",
            "            'alarm_actions': [],",
            "            'insufficient_data_actions': [],",
            "            'repeat_actions': False,",
            "            'rule': {",
            "                'event_type': '*',",
            "                'query': [],",
            "            }",
            "        }",
            "",
            "        json = {",
            "            'name': 'added_alarm_defaults',",
            "            'type': 'event',",
            "            'event_rule': {",
            "                'event_type': '*',",
            "                'query': []",
            "            }",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "        for alarm in alarms:",
            "            if alarm.name == 'added_alarm_defaults':",
            "                for key in to_check:",
            "                    self.assertEqual(to_check[key], getattr(alarm, key))",
            "                break",
            "        else:",
            "            self.fail(\"Alarm not found\")",
            "",
            "",
            "class TestAlarmsCompositeRule(TestAlarmsBase):",
            "",
            "    def setUp(self):",
            "        super(TestAlarmsCompositeRule, self).setUp()",
            "        self.sub_rule1 = {",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\",",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"evaluation_periods\": 5,",
            "            \"threshold\": 0.8,",
            "            \"aggregation_method\": \"mean\",",
            "            \"granularity\": 60,",
            "            \"comparison_operator\": \"gt\"",
            "        }",
            "        self.sub_rule2 = {",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\",",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"evaluation_periods\": 4,",
            "            \"threshold\": 200,",
            "            \"aggregation_method\": \"max\",",
            "            \"granularity\": 60,",
            "            \"comparison_operator\": \"gt\"",
            "        }",
            "        self.sub_rule3 = {",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\",",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"evaluation_periods\": 3,",
            "            \"threshold\": 1000,",
            "            \"aggregation_method\": \"mean\",",
            "            \"granularity\": 60,",
            "            \"comparison_operator\": \"gt\"",
            "        }",
            "",
            "        self.rule = {",
            "            \"or\": [self.sub_rule1,",
            "                   {",
            "                       \"and\": [self.sub_rule2, self.sub_rule3]",
            "                   }]}",
            "",
            "    def test_list_alarms(self):",
            "        alarm = models.Alarm(name='composite_alarm',",
            "                             type='composite',",
            "                             enabled=True,",
            "                             alarm_id='composite',",
            "                             description='composite',",
            "                             state='insufficient data',",
            "                             state_reason='insufficient data',",
            "                             severity='moderate',",
            "                             state_timestamp=constants.MIN_DATETIME,",
            "                             timestamp=constants.MIN_DATETIME,",
            "                             ok_actions=[],",
            "                             insufficient_data_actions=[],",
            "                             alarm_actions=[],",
            "                             repeat_actions=False,",
            "                             user_id=self.auth_headers['X-User-Id'],",
            "                             project_id=self.auth_headers['X-Project-Id'],",
            "                             time_constraints=[],",
            "                             rule=self.rule,",
            "                             )",
            "        self.alarm_conn.create_alarm(alarm)",
            "",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(1, len(data))",
            "        self.assertEqual(set(['composite_alarm']),",
            "                         set(r['name'] for r in data))",
            "        self.assertEqual(self.rule, data[0]['composite_rule'])",
            "",
            "    def test_post_with_composite_rule(self):",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": self.rule,",
            "            \"repeat_actions\": False",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "        self.assertEqual(self.rule, alarms[0].rule)",
            "",
            "    def test_post_with_sub_rule_with_wrong_type(self):",
            "        self.sub_rule1['type'] = 'non-type'",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": self.rule,",
            "            \"repeat_actions\": False",
            "        }",
            "        response = self.post_json('/alarms', params=json, status=400,",
            "                                  expect_errors=True,",
            "                                  headers=self.auth_headers)",
            "",
            "        err = (\"Unsupported sub-rule type :non-type in composite \"",
            "               \"rule, should be one of: \"",
            "               \"['gnocchi_aggregation_by_metrics_threshold', \"",
            "               \"'gnocchi_aggregation_by_resources_threshold', \"",
            "               \"'gnocchi_resources_threshold']\")",
            "        faultstring = response.json['error_message']['faultstring']",
            "        self.assertEqual(err, faultstring)",
            "",
            "    def test_post_with_sub_rule_with_only_required_params(self):",
            "        sub_rulea = {",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"threshold\": 0.8,",
            "            \"aggregation_method\": \"mean\",",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\"}",
            "        sub_ruleb = {",
            "            \"metrics\": ['41869681-5776-46d6-91ed-cccc43b6e4e3',",
            "                        'a1fb80f4-c242-4f57-87c6-68f47521059e'],",
            "            \"threshold\": 200,",
            "            \"aggregation_method\": \"mean\",",
            "            \"type\": \"gnocchi_aggregation_by_metrics_threshold\"}",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": {\"and\": [sub_rulea, sub_ruleb]},",
            "            \"repeat_actions\": False",
            "        }",
            "        self.post_json('/alarms', params=json, status=201,",
            "                       headers=self.auth_headers)",
            "        alarms = list(self.alarm_conn.get_alarms())",
            "        self.assertEqual(1, len(alarms))",
            "",
            "    def test_post_with_sub_rule_with_invalid_params(self):",
            "        self.sub_rule1['threshold'] = False",
            "        json = {",
            "            \"type\": \"composite\",",
            "            \"name\": \"composite_alarm\",",
            "            \"composite_rule\": self.rule,",
            "            \"repeat_actions\": False",
            "        }",
            "        response = self.post_json('/alarms', params=json, status=400,",
            "                                  expect_errors=True,",
            "                                  headers=self.auth_headers)",
            "        faultstring = (\"Invalid input for field/attribute threshold. \"",
            "                       \"Value: 'False'. Wrong type. Expected '%s', got '%s'\"",
            "                       % (type(1.0), type(True)))",
            "        self.assertEqual(faultstring,",
            "                         response.json['error_message']['faultstring'])",
            "",
            "",
            "class TestPaginationQuery(TestAlarmsBase):",
            "    def setUp(self):",
            "        super(TestPaginationQuery, self).setUp()",
            "        for alarm in default_alarms(self.auth_headers):",
            "            self.alarm_conn.create_alarm(alarm)",
            "",
            "    def test_pagination_query_single_sort(self):",
            "        data = self.get_json('/alarms?sort=name:desc',",
            "                             headers=self.auth_headers)",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name3', 'name2', 'name1'], names)",
            "        data = self.get_json('/alarms?sort=name:asc',",
            "                             headers=self.auth_headers)",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name1', 'name2', 'name3'], names)",
            "",
            "    def test_sort_by_severity_with_its_value(self):",
            "        if self.engine != \"mysql\":",
            "            self.skipTest(\"This is only implemented for MySQL\")",
            "        data = self.get_json('/alarms?sort=severity:asc',",
            "                             headers=self.auth_headers)",
            "        severities = [a['severity'] for a in data]",
            "        self.assertEqual(['moderate', 'critical', 'critical'],",
            "                         severities)",
            "        data = self.get_json('/alarms?sort=severity:desc',",
            "                             headers=self.auth_headers)",
            "        severities = [a['severity'] for a in data]",
            "        self.assertEqual(['critical', 'critical', 'moderate'],",
            "                         severities)",
            "",
            "    def test_pagination_query_limit(self):",
            "        data = self.get_json('/alarms?limit=2', headers=self.auth_headers)",
            "        self.assertEqual(2, len(data))",
            "",
            "    def test_pagination_query_limit_sort(self):",
            "        data = self.get_json('/alarms?sort=name:asc&limit=2',",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(2, len(data))",
            "",
            "    def test_pagination_query_marker(self):",
            "        data = self.get_json('/alarms?sort=name:desc',",
            "                             headers=self.auth_headers)",
            "        self.assertEqual(3, len(data))",
            "        alarm_ids = [a['alarm_id'] for a in data]",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name3', 'name2', 'name1'], names)",
            "        marker_url = ('/alarms?sort=name:desc&marker=%s' % alarm_ids[1])",
            "        data = self.get_json(marker_url, headers=self.auth_headers)",
            "        self.assertEqual(1, len(data))",
            "        new_alarm_ids = [a['alarm_id'] for a in data]",
            "        self.assertEqual(alarm_ids[2:], new_alarm_ids)",
            "        new_names = [a['name'] for a in data]",
            "        self.assertEqual(['name1'], new_names)",
            "",
            "    def test_pagination_query_multiple_sorts(self):",
            "        new_alarms = default_alarms(self.auth_headers)",
            "        for a_id in zip(new_alarms, ['e', 'f', 'g', 'h']):",
            "            a_id[0].alarm_id = a_id[1]",
            "            self.alarm_conn.create_alarm(a_id[0])",
            "        data = self.get_json('/alarms', headers=self.auth_headers)",
            "        self.assertEqual(6, len(data))",
            "        sort_url = '/alarms?sort=name:desc&sort=alarm_id:asc'",
            "        data = self.get_json(sort_url, headers=self.auth_headers)",
            "        name_ids = [(a['name'], a['alarm_id']) for a in data]",
            "        expected = [('name3', 'c'),",
            "                    ('name3', 'g'), ('name2', 'b'), ('name2', 'f'),",
            "                    ('name1', 'a'), ('name1', 'e')]",
            "        self.assertEqual(expected, name_ids)",
            "",
            "    def test_pagination_query_invalid_sort_key(self):",
            "        resp = self.get_json('/alarms?sort=invalid_key:desc',",
            "                             headers=self.auth_headers,",
            "                             expect_errors=True)",
            "        self.assertEqual(resp.status_code, 400)",
            "        self.assertEqual(\"Invalid input for field/attribute sort. Value: \"",
            "                         \"'invalid_key:desc'. the sort parameter should be\"",
            "                         \" a pair of sort key and sort dir combined with \"",
            "                         \"':', or only sort key specified and sort dir will \"",
            "                         \"be default 'asc', the supported sort keys are: \"",
            "                         \"('alarm_id', 'enabled', 'name', 'type', 'severity',\"",
            "                         \" 'timestamp', 'user_id', 'project_id', 'state', \"",
            "                         \"'repeat_actions', 'state_timestamp')\",",
            "                         resp.json['error_message']['faultstring'])",
            "",
            "    def test_pagination_query_only_sort_key_specified(self):",
            "        data = self.get_json('/alarms?sort=name',",
            "                             headers=self.auth_headers)",
            "        names = [a['name'] for a in data]",
            "        self.assertEqual(['name1', 'name2', 'name3'], names)",
            "",
            "    def test_pagination_query_history_data(self):",
            "        for i in moves.xrange(10):",
            "            self._update_alarm('a', dict(name='%s' % i))",
            "        url = '/alarms/a/history?sort=event_id:desc&sort=timestamp:desc'",
            "        data = self.get_json(url, headers=self.auth_headers)",
            "        sorted_data = sorted(data,",
            "                             key=lambda d: (d['event_id'], d['timestamp']),",
            "                             reverse=True)",
            "        self.assertEqual(sorted_data, data)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1424": [
                "TestAlarms",
                "test_put_alarm_trust"
            ]
        },
        "addLocation": [
            "aodh.tests.functional.api.v2.test_alarm_scenarios.TestAlarms.test_post_alarm_trust.json",
            "airflow.www.views.LogModelView"
        ]
    }
}