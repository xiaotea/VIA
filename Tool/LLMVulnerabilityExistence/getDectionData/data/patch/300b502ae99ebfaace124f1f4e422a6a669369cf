{
    "sigstore/models.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 525,
                "afterPatchRowNumber": 525,
                "PatchRowcode": "         # * For 0.2+, an inclusion proof is required; the client MUST"
            },
            "1": {
                "beforePatchRowNumber": 526,
                "afterPatchRowNumber": 526,
                "PatchRowcode": "         #   verify the inclusion proof. The inclusion prof MUST contain"
            },
            "2": {
                "beforePatchRowNumber": 527,
                "afterPatchRowNumber": 527,
                "PatchRowcode": "         #   a checkpoint."
            },
            "3": {
                "beforePatchRowNumber": 528,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #   The inclusion promise is NOT required; if present, the client"
            },
            "4": {
                "beforePatchRowNumber": 529,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        #   SHOULD verify it."
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 528,
                "PatchRowcode": "+        #"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 529,
                "PatchRowcode": "+        #   The inclusion promise is NOT required if another source of signed"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 530,
                "PatchRowcode": "+        #   time (such as a signed timestamp) is present. If no other source"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 531,
                "PatchRowcode": "+        #   of signed time is present, then the inclusion promise MUST be"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 532,
                "PatchRowcode": "+        #   present."
            },
            "10": {
                "beforePatchRowNumber": 530,
                "afterPatchRowNumber": 533,
                "PatchRowcode": "         #"
            },
            "11": {
                "beforePatchRowNumber": 531,
                "afterPatchRowNumber": 534,
                "PatchRowcode": "         # Before all of this, we require that the inclusion proof be present"
            },
            "12": {
                "beforePatchRowNumber": 532,
                "afterPatchRowNumber": 535,
                "PatchRowcode": "         # (when constructing the LogEntry)."
            },
            "13": {
                "beforePatchRowNumber": 543,
                "afterPatchRowNumber": 546,
                "PatchRowcode": "             if not log_entry.inclusion_proof.checkpoint:"
            },
            "14": {
                "beforePatchRowNumber": 544,
                "afterPatchRowNumber": 547,
                "PatchRowcode": "                 raise InvalidBundle(\"expected checkpoint in inclusion proof\")"
            },
            "15": {
                "beforePatchRowNumber": 545,
                "afterPatchRowNumber": 548,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 549,
                "PatchRowcode": "+            if ("
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 550,
                "PatchRowcode": "+                not log_entry.inclusion_promise"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 551,
                "PatchRowcode": "+                and not self._inner.verification_material.timestamp_verification_data.rfc3161_timestamps"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 552,
                "PatchRowcode": "+            ):"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 553,
                "PatchRowcode": "+                raise InvalidBundle("
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 554,
                "PatchRowcode": "+                    \"bundle must contain an inclusion promise or signed timestamp(s)\""
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 555,
                "PatchRowcode": "+                )"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 556,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": 546,
                "afterPatchRowNumber": 557,
                "PatchRowcode": "         self._log_entry = log_entry"
            },
            "25": {
                "beforePatchRowNumber": 547,
                "afterPatchRowNumber": 558,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 548,
                "afterPatchRowNumber": 559,
                "PatchRowcode": "     @property"
            }
        },
        "frontPatchFile": [
            "# Copyright 2022 The Sigstore Authors",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"",
            "Common models shared between signing and verification.",
            "\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import base64",
            "import logging",
            "import typing",
            "from enum import Enum",
            "from textwrap import dedent",
            "from typing import Any, List, Optional",
            "",
            "import rfc8785",
            "from cryptography.hazmat.primitives.serialization import Encoding",
            "from cryptography.x509 import (",
            "    Certificate,",
            "    load_der_x509_certificate,",
            ")",
            "from pydantic import (",
            "    BaseModel,",
            "    ConfigDict,",
            "    Field,",
            "    StrictInt,",
            "    StrictStr,",
            "    TypeAdapter,",
            "    ValidationInfo,",
            "    field_validator,",
            ")",
            "from pydantic.dataclasses import dataclass",
            "from rekor_types import Dsse, Hashedrekord, ProposedEntry",
            "from rfc3161_client import TimeStampResponse, decode_timestamp_response",
            "from sigstore_protobuf_specs.dev.sigstore.bundle import v1 as bundle_v1",
            "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (",
            "    Bundle as _Bundle,",
            ")",
            "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (",
            "    TimestampVerificationData as _TimestampVerificationData,",
            ")",
            "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (",
            "    VerificationMaterial as _VerificationMaterial,",
            ")",
            "from sigstore_protobuf_specs.dev.sigstore.common import v1 as common_v1",
            "from sigstore_protobuf_specs.dev.sigstore.common.v1 import Rfc3161SignedTimestamp",
            "from sigstore_protobuf_specs.dev.sigstore.rekor import v1 as rekor_v1",
            "from sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (",
            "    InclusionProof,",
            ")",
            "",
            "from sigstore import dsse",
            "from sigstore._internal.merkle import verify_merkle_inclusion",
            "from sigstore._internal.rekor.checkpoint import verify_checkpoint",
            "from sigstore._utils import (",
            "    B64Str,",
            "    KeyID,",
            "    cert_is_leaf,",
            "    cert_is_root_ca,",
            ")",
            "from sigstore.errors import Error, VerificationError",
            "",
            "if typing.TYPE_CHECKING:",
            "    from sigstore._internal.trust import RekorKeyring",
            "",
            "",
            "_logger = logging.getLogger(__name__)",
            "",
            "",
            "class LogInclusionProof(BaseModel):",
            "    \"\"\"",
            "    Represents an inclusion proof for a transparency log entry.",
            "    \"\"\"",
            "",
            "    model_config = ConfigDict(populate_by_name=True)",
            "",
            "    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")",
            "    hashes: List[StrictStr] = Field(..., alias=\"hashes\")",
            "    log_index: StrictInt = Field(..., alias=\"logIndex\")",
            "    root_hash: StrictStr = Field(..., alias=\"rootHash\")",
            "    tree_size: StrictInt = Field(..., alias=\"treeSize\")",
            "",
            "    @field_validator(\"log_index\")",
            "    def _log_index_positive(cls, v: int) -> int:",
            "        if v < 0:",
            "            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")",
            "        return v",
            "",
            "    @field_validator(\"tree_size\")",
            "    def _tree_size_positive(cls, v: int) -> int:",
            "        if v < 0:",
            "            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")",
            "        return v",
            "",
            "    @field_validator(\"tree_size\")",
            "    def _log_index_within_tree_size(",
            "        cls, v: int, info: ValidationInfo, **kwargs: Any",
            "    ) -> int:",
            "        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:",
            "            raise ValueError(",
            "                \"Inclusion proof has log index greater than or equal to tree size: \"",
            "                f\"{v} <= {info.data['log_index']}\"",
            "            )",
            "        return v",
            "",
            "",
            "@dataclass(frozen=True)",
            "class LogEntry:",
            "    \"\"\"",
            "    Represents a transparency log entry.",
            "",
            "    Log entries are retrieved from the transparency log after signing or verification events,",
            "    or loaded from \"Sigstore\" bundles provided by the user.",
            "",
            "    This representation allows for either a missing inclusion promise or a missing",
            "    inclusion proof, but not both: attempting to construct a `LogEntry` without",
            "    at least one will fail.",
            "    \"\"\"",
            "",
            "    uuid: Optional[str]",
            "    \"\"\"",
            "    This entry's unique ID in the log instance it was retrieved from.",
            "",
            "    For sharded log deployments, IDs are unique per-shard.",
            "",
            "    Not present for `LogEntry` instances loaded from Sigstore bundles.",
            "    \"\"\"",
            "",
            "    body: B64Str",
            "    \"\"\"",
            "    The base64-encoded body of the transparency log entry.",
            "    \"\"\"",
            "",
            "    integrated_time: int",
            "    \"\"\"",
            "    The UNIX time at which this entry was integrated into the transparency log.",
            "    \"\"\"",
            "",
            "    log_id: str",
            "    \"\"\"",
            "    The log's ID (as the SHA256 hash of the DER-encoded public key for the log",
            "    at the time of entry inclusion).",
            "    \"\"\"",
            "",
            "    log_index: int",
            "    \"\"\"",
            "    The index of this entry within the log.",
            "    \"\"\"",
            "",
            "    inclusion_proof: LogInclusionProof",
            "    \"\"\"",
            "    An inclusion proof for this log entry.",
            "    \"\"\"",
            "",
            "    inclusion_promise: Optional[B64Str]",
            "    \"\"\"",
            "    An inclusion promise for this log entry, if present.",
            "",
            "    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this",
            "    log entry.",
            "    \"\"\"",
            "",
            "    @classmethod",
            "    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:",
            "        \"\"\"",
            "        Create a new `LogEntry` from the given API response.",
            "        \"\"\"",
            "",
            "        # Assumes we only get one entry back",
            "        entries = list(dict_.items())",
            "        if len(entries) != 1:",
            "            raise ValueError(\"Received multiple entries in response\")",
            "",
            "        uuid, entry = entries[0]",
            "        return LogEntry(",
            "            uuid=uuid,",
            "            body=entry[\"body\"],",
            "            integrated_time=entry[\"integratedTime\"],",
            "            log_id=entry[\"logID\"],",
            "            log_index=entry[\"logIndex\"],",
            "            inclusion_proof=LogInclusionProof.model_validate(",
            "                entry[\"verification\"][\"inclusionProof\"]",
            "            ),",
            "            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],",
            "        )",
            "",
            "    @classmethod",
            "    def _from_dict_rekor(cls, dict_: dict[str, Any]) -> LogEntry:",
            "        \"\"\"",
            "        Create a new `LogEntry` from the given Rekor TransparencyLogEntry.",
            "        \"\"\"",
            "        tlog_entry = rekor_v1.TransparencyLogEntry()",
            "        tlog_entry.from_dict(dict_)",
            "",
            "        inclusion_proof: InclusionProof | None = tlog_entry.inclusion_proof",
            "        # This check is required by us as the client, not the",
            "        # protobuf-specs themselves.",
            "        if not inclusion_proof or not inclusion_proof.checkpoint.envelope:",
            "            raise InvalidBundle(\"entry must contain inclusion proof, with checkpoint\")",
            "",
            "        parsed_inclusion_proof = LogInclusionProof(",
            "            checkpoint=inclusion_proof.checkpoint.envelope,",
            "            hashes=[h.hex() for h in inclusion_proof.hashes],",
            "            log_index=inclusion_proof.log_index,",
            "            root_hash=inclusion_proof.root_hash.hex(),",
            "            tree_size=inclusion_proof.tree_size,",
            "        )",
            "",
            "        return LogEntry(",
            "            uuid=None,",
            "            body=B64Str(base64.b64encode(tlog_entry.canonicalized_body).decode()),",
            "            integrated_time=tlog_entry.integrated_time,",
            "            log_id=tlog_entry.log_id.key_id.hex(),",
            "            log_index=tlog_entry.log_index,",
            "            inclusion_proof=parsed_inclusion_proof,",
            "            inclusion_promise=B64Str(",
            "                base64.b64encode(",
            "                    tlog_entry.inclusion_promise.signed_entry_timestamp",
            "                ).decode()",
            "            ),",
            "        )",
            "",
            "    def _to_rekor(self) -> rekor_v1.TransparencyLogEntry:",
            "        \"\"\"",
            "        Create a new protobuf-level `TransparencyLogEntry` from this `LogEntry`.",
            "",
            "        @private",
            "        \"\"\"",
            "        inclusion_promise: rekor_v1.InclusionPromise | None = None",
            "        if self.inclusion_promise:",
            "            inclusion_promise = rekor_v1.InclusionPromise(",
            "                signed_entry_timestamp=base64.b64decode(self.inclusion_promise)",
            "            )",
            "",
            "        inclusion_proof = rekor_v1.InclusionProof(",
            "            log_index=self.inclusion_proof.log_index,",
            "            root_hash=bytes.fromhex(self.inclusion_proof.root_hash),",
            "            tree_size=self.inclusion_proof.tree_size,",
            "            hashes=[bytes.fromhex(hash_) for hash_ in self.inclusion_proof.hashes],",
            "            checkpoint=rekor_v1.Checkpoint(envelope=self.inclusion_proof.checkpoint),",
            "        )",
            "",
            "        tlog_entry = rekor_v1.TransparencyLogEntry(",
            "            log_index=self.log_index,",
            "            log_id=common_v1.LogId(key_id=bytes.fromhex(self.log_id)),",
            "            integrated_time=self.integrated_time,",
            "            inclusion_promise=inclusion_promise,  # type: ignore[arg-type]",
            "            inclusion_proof=inclusion_proof,",
            "            canonicalized_body=base64.b64decode(self.body),",
            "        )",
            "",
            "        # Fill in the appropriate kind",
            "        body_entry: ProposedEntry = TypeAdapter(ProposedEntry).validate_json(",
            "            tlog_entry.canonicalized_body",
            "        )",
            "        if not isinstance(body_entry, (Hashedrekord, Dsse)):",
            "            raise InvalidBundle(\"log entry is not of expected type\")",
            "",
            "        tlog_entry.kind_version = rekor_v1.KindVersion(",
            "            kind=body_entry.kind, version=body_entry.api_version",
            "        )",
            "",
            "        return tlog_entry",
            "",
            "    def encode_canonical(self) -> bytes:",
            "        \"\"\"",
            "        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.",
            "",
            "        This encoded representation is suitable for verification against",
            "        the Signed Entry Timestamp.",
            "        \"\"\"",
            "        payload: dict[str, int | str] = {",
            "            \"body\": self.body,",
            "            \"integratedTime\": self.integrated_time,",
            "            \"logID\": self.log_id,",
            "            \"logIndex\": self.log_index,",
            "        }",
            "",
            "        return rfc8785.dumps(payload)",
            "",
            "    def _verify_set(self, keyring: RekorKeyring) -> None:",
            "        \"\"\"",
            "        Verify the inclusion promise (Signed Entry Timestamp) for a given transparency log",
            "        `entry` using the given `keyring`.",
            "",
            "        Fails if the given log entry does not contain an inclusion promise.",
            "        \"\"\"",
            "",
            "        if self.inclusion_promise is None:",
            "            raise VerificationError(\"SET: invalid inclusion promise: missing\")",
            "",
            "        signed_entry_ts = base64.b64decode(self.inclusion_promise)",
            "",
            "        try:",
            "            keyring.verify(",
            "                key_id=KeyID(bytes.fromhex(self.log_id)),",
            "                signature=signed_entry_ts,",
            "                data=self.encode_canonical(),",
            "            )",
            "        except VerificationError as exc:",
            "            raise VerificationError(f\"SET: invalid inclusion promise: {exc}\")",
            "",
            "    def _verify(self, keyring: RekorKeyring) -> None:",
            "        \"\"\"",
            "        Verifies this log entry.",
            "",
            "        This method performs steps (5), (6), and optionally (7) in",
            "        the top-level verify API:",
            "",
            "        * Verifies the consistency of the entry with the given bundle;",
            "        * Verifies the Merkle inclusion proof and its signed checkpoint;",
            "        * Verifies the inclusion promise, if present.",
            "        \"\"\"",
            "",
            "        verify_merkle_inclusion(self)",
            "        verify_checkpoint(keyring, self)",
            "",
            "        _logger.debug(f\"successfully verified inclusion proof: index={self.log_index}\")",
            "",
            "        if self.inclusion_promise:",
            "            self._verify_set(keyring)",
            "            _logger.debug(",
            "                f\"successfully verified inclusion promise: index={self.log_index}\"",
            "            )",
            "",
            "",
            "class TimestampVerificationData:",
            "    \"\"\"",
            "    Represents a TimestampVerificationData structure.",
            "",
            "    @private",
            "    \"\"\"",
            "",
            "    def __init__(self, inner: _TimestampVerificationData) -> None:",
            "        \"\"\"Init method.\"\"\"",
            "        self._inner = inner",
            "        self._verify()",
            "",
            "    def _verify(self) -> None:",
            "        \"\"\"",
            "        Verifies the TimestampVerificationData.",
            "",
            "        It verifies that TimeStamp Responses embedded in the bundle are correctly",
            "        formed.",
            "        \"\"\"",
            "        try:",
            "            self._signed_ts = [",
            "                decode_timestamp_response(ts.signed_timestamp)",
            "                for ts in self._inner.rfc3161_timestamps",
            "            ]",
            "        except ValueError:",
            "            raise VerificationError(\"Invalid Timestamp Response\")",
            "",
            "    @property",
            "    def rfc3161_timestamps(self) -> list[TimeStampResponse]:",
            "        \"\"\"Returns a list of signed timestamp.\"\"\"",
            "        return self._signed_ts",
            "",
            "    @classmethod",
            "    def from_json(cls, raw: str | bytes) -> TimestampVerificationData:",
            "        \"\"\"",
            "        Deserialize the given timestamp verification data.",
            "        \"\"\"",
            "        inner = _TimestampVerificationData().from_json(raw)",
            "        return cls(inner)",
            "",
            "",
            "class VerificationMaterial:",
            "    \"\"\"",
            "    Represents a VerificationMaterial structure.",
            "    \"\"\"",
            "",
            "    def __init__(self, inner: _VerificationMaterial) -> None:",
            "        \"\"\"Init method.\"\"\"",
            "        self._inner = inner",
            "",
            "    @property",
            "    def timestamp_verification_data(self) -> TimestampVerificationData:",
            "        \"\"\"",
            "        Returns the Timestamp Verification Data.",
            "        \"\"\"",
            "        return TimestampVerificationData(self._inner.timestamp_verification_data)",
            "",
            "",
            "class InvalidBundle(Error):",
            "    \"\"\"",
            "    Raised when the associated `Bundle` is invalid in some way.",
            "    \"\"\"",
            "",
            "    def diagnostics(self) -> str:",
            "        \"\"\"Returns diagnostics for the error.\"\"\"",
            "",
            "        return dedent(",
            "            f\"\"\"\\",
            "        An issue occurred while parsing the Sigstore bundle.",
            "",
            "        The provided bundle is malformed and may have been modified maliciously.",
            "",
            "        Additional context:",
            "",
            "        {self}",
            "        \"\"\"",
            "        )",
            "",
            "",
            "class Bundle:",
            "    \"\"\"",
            "    Represents a Sigstore bundle.",
            "    \"\"\"",
            "",
            "    class BundleType(str, Enum):",
            "        \"\"\"",
            "        Known Sigstore bundle media types.",
            "        \"\"\"",
            "",
            "        BUNDLE_0_1 = \"application/vnd.dev.sigstore.bundle+json;version=0.1\"",
            "        BUNDLE_0_2 = \"application/vnd.dev.sigstore.bundle+json;version=0.2\"",
            "        BUNDLE_0_3_ALT = \"application/vnd.dev.sigstore.bundle+json;version=0.3\"",
            "        BUNDLE_0_3 = \"application/vnd.dev.sigstore.bundle.v0.3+json\"",
            "",
            "        def __str__(self) -> str:",
            "            \"\"\"Returns the variant's string value.\"\"\"",
            "            return self.value",
            "",
            "    def __init__(self, inner: _Bundle) -> None:",
            "        \"\"\"",
            "        Creates a new bundle. This is not a public API; use",
            "        `from_json` instead.",
            "",
            "        @private",
            "        \"\"\"",
            "        self._inner = inner",
            "        self._verify()",
            "",
            "    def _verify(self) -> None:",
            "        \"\"\"",
            "        Performs various feats of heroism to ensure the bundle is well-formed",
            "        and upholds invariants, including:",
            "",
            "        * The \"leaf\" (signing) certificate is present;",
            "        * There is a inclusion proof present, even if the Bundle's version",
            "           predates a mandatory inclusion proof.",
            "        \"\"\"",
            "",
            "        # The bundle must have a recognized media type.",
            "        try:",
            "            media_type = Bundle.BundleType(self._inner.media_type)",
            "        except ValueError:",
            "            raise InvalidBundle(f\"unsupported bundle format: {self._inner.media_type}\")",
            "",
            "        # Extract the signing certificate.",
            "        if media_type in (",
            "            Bundle.BundleType.BUNDLE_0_3,",
            "            Bundle.BundleType.BUNDLE_0_3_ALT,",
            "        ):",
            "            # For \"v3\" bundles, the signing certificate is the only one present.",
            "            leaf_cert = load_der_x509_certificate(",
            "                self._inner.verification_material.certificate.raw_bytes",
            "            )",
            "        else:",
            "            # In older bundles, there is an entire pool (misleadingly called",
            "            # a chain) of certificates, the first of which is the signing",
            "            # certificate.",
            "            certs = (",
            "                self._inner.verification_material.x509_certificate_chain.certificates",
            "            )",
            "",
            "            if len(certs) == 0:",
            "                raise InvalidBundle(\"expected non-empty certificate chain in bundle\")",
            "",
            "            # Per client policy in protobuf-specs: the first entry in the chain",
            "            # MUST be a leaf certificate, and the rest of the chain MUST NOT",
            "            # include a root CA or any intermediate CAs that appear in an",
            "            # independent root of trust.",
            "            #",
            "            # We expect some old bundles to violate the rules around root",
            "            # and intermediate CAs, so we issue warnings and not hard errors",
            "            # in those cases.",
            "            leaf_cert, *chain_certs = [",
            "                load_der_x509_certificate(cert.raw_bytes) for cert in certs",
            "            ]",
            "            if not cert_is_leaf(leaf_cert):",
            "                raise InvalidBundle(",
            "                    \"bundle contains an invalid leaf or non-leaf certificate in the leaf position\"",
            "                )",
            "",
            "            for chain_cert in chain_certs:",
            "                # TODO: We should also retrieve the root of trust here and",
            "                # cross-check against it.",
            "                if cert_is_root_ca(chain_cert):",
            "                    _logger.warning(",
            "                        \"this bundle contains a root CA, making it subject to misuse\"",
            "                    )",
            "",
            "        self._signing_certificate = leaf_cert",
            "",
            "        # Extract the log entry. For the time being, we expect",
            "        # bundles to only contain a single log entry.",
            "        tlog_entries = self._inner.verification_material.tlog_entries",
            "        if len(tlog_entries) != 1:",
            "            raise InvalidBundle(\"expected exactly one log entry in bundle\")",
            "        tlog_entry = tlog_entries[0]",
            "",
            "        # Handling of inclusion promises and proofs varies between bundle",
            "        # format versions:",
            "        #",
            "        # * For 0.1, an inclusion promise is required; the client",
            "        #   MUST verify the inclusion promise.",
            "        #   The inclusion proof is NOT required. If provided, it might NOT",
            "        #   contain a checkpoint; in this case, we ignore it (since it's",
            "        #   useless without one).",
            "        #",
            "        # * For 0.2+, an inclusion proof is required; the client MUST",
            "        #   verify the inclusion proof. The inclusion prof MUST contain",
            "        #   a checkpoint.",
            "        #   The inclusion promise is NOT required; if present, the client",
            "        #   SHOULD verify it.",
            "        #",
            "        # Before all of this, we require that the inclusion proof be present",
            "        # (when constructing the LogEntry).",
            "        log_entry = LogEntry._from_dict_rekor(tlog_entry.to_dict())",
            "",
            "        if media_type == Bundle.BundleType.BUNDLE_0_1:",
            "            if not log_entry.inclusion_promise:",
            "                raise InvalidBundle(\"bundle must contain an inclusion promise\")",
            "            if not log_entry.inclusion_proof.checkpoint:",
            "                _logger.debug(",
            "                    \"0.1 bundle contains inclusion proof without checkpoint; ignoring\"",
            "                )",
            "        else:",
            "            if not log_entry.inclusion_proof.checkpoint:",
            "                raise InvalidBundle(\"expected checkpoint in inclusion proof\")",
            "",
            "        self._log_entry = log_entry",
            "",
            "    @property",
            "    def signing_certificate(self) -> Certificate:",
            "        \"\"\"Returns the bundle's contained signing (i.e. leaf) certificate.\"\"\"",
            "        return self._signing_certificate",
            "",
            "    @property",
            "    def log_entry(self) -> LogEntry:",
            "        \"\"\"",
            "        Returns the bundle's log entry, containing an inclusion proof",
            "        (with checkpoint) and an inclusion promise (if the latter is present).",
            "        \"\"\"",
            "        return self._log_entry",
            "",
            "    @property",
            "    def _dsse_envelope(self) -> dsse.Envelope | None:",
            "        \"\"\"",
            "        Returns the DSSE envelope within this Bundle as a `dsse.Envelope`.",
            "",
            "        @private",
            "        \"\"\"",
            "        if self._inner.dsse_envelope:",
            "            return dsse.Envelope(self._inner.dsse_envelope)",
            "        return None",
            "",
            "    @property",
            "    def signature(self) -> bytes:",
            "        \"\"\"",
            "        Returns the signature bytes of this bundle.",
            "        Either from the DSSE Envelope or from the message itself.",
            "        \"\"\"",
            "        return (",
            "            self._dsse_envelope.signature",
            "            if self._dsse_envelope",
            "            else self._inner.message_signature.signature",
            "        )",
            "",
            "    @property",
            "    def verification_material(self) -> VerificationMaterial:",
            "        \"\"\"",
            "        Returns the bundle's verification material.",
            "        \"\"\"",
            "        return VerificationMaterial(self._inner.verification_material)",
            "",
            "    @classmethod",
            "    def from_json(cls, raw: bytes | str) -> Bundle:",
            "        \"\"\"",
            "        Deserialize the given Sigstore bundle.",
            "        \"\"\"",
            "        inner = _Bundle().from_json(raw)",
            "        return cls(inner)",
            "",
            "    def to_json(self) -> str:",
            "        \"\"\"",
            "        Return a JSON encoding of this bundle.",
            "        \"\"\"",
            "        return self._inner.to_json()",
            "",
            "    def _to_parts(",
            "        self,",
            "    ) -> tuple[Certificate, common_v1.MessageSignature | dsse.Envelope, LogEntry]:",
            "        \"\"\"",
            "        Decompose the `Bundle` into its core constituent parts.",
            "",
            "        @private",
            "        \"\"\"",
            "",
            "        content: common_v1.MessageSignature | dsse.Envelope",
            "        if self._dsse_envelope:",
            "            content = self._dsse_envelope",
            "        else:",
            "            content = self._inner.message_signature",
            "",
            "        return (self.signing_certificate, content, self.log_entry)",
            "",
            "    @classmethod",
            "    def from_parts(cls, cert: Certificate, sig: bytes, log_entry: LogEntry) -> Bundle:",
            "        \"\"\"",
            "        Construct a Sigstore bundle (of `hashedrekord` type) from its",
            "        constituent parts.",
            "        \"\"\"",
            "",
            "        return cls._from_parts(",
            "            cert, common_v1.MessageSignature(signature=sig), log_entry",
            "        )",
            "",
            "    @classmethod",
            "    def _from_parts(",
            "        cls,",
            "        cert: Certificate,",
            "        content: common_v1.MessageSignature | dsse.Envelope,",
            "        log_entry: LogEntry,",
            "        signed_timestamp: Optional[List[TimeStampResponse]] = None,",
            "    ) -> Bundle:",
            "        \"\"\"",
            "        @private",
            "        \"\"\"",
            "",
            "        inner = _Bundle(",
            "            media_type=Bundle.BundleType.BUNDLE_0_3.value,",
            "            verification_material=bundle_v1.VerificationMaterial(",
            "                certificate=common_v1.X509Certificate(cert.public_bytes(Encoding.DER)),",
            "            ),",
            "        )",
            "",
            "        # Fill in the appropriate variants.",
            "        if isinstance(content, common_v1.MessageSignature):",
            "            inner.message_signature = content",
            "        else:",
            "            inner.dsse_envelope = content._inner",
            "",
            "        tlog_entry = log_entry._to_rekor()",
            "        inner.verification_material.tlog_entries = [tlog_entry]",
            "",
            "        if signed_timestamp is not None:",
            "            inner.verification_material.timestamp_verification_data = (",
            "                bundle_v1.TimestampVerificationData(",
            "                    rfc3161_timestamps=[",
            "                        Rfc3161SignedTimestamp(signed_timestamp=response.as_bytes())",
            "                        for response in signed_timestamp",
            "                    ]",
            "                )",
            "            )",
            "",
            "        return cls(inner)"
        ],
        "afterPatchFile": [
            "# Copyright 2022 The Sigstore Authors",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"",
            "Common models shared between signing and verification.",
            "\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import base64",
            "import logging",
            "import typing",
            "from enum import Enum",
            "from textwrap import dedent",
            "from typing import Any, List, Optional",
            "",
            "import rfc8785",
            "from cryptography.hazmat.primitives.serialization import Encoding",
            "from cryptography.x509 import (",
            "    Certificate,",
            "    load_der_x509_certificate,",
            ")",
            "from pydantic import (",
            "    BaseModel,",
            "    ConfigDict,",
            "    Field,",
            "    StrictInt,",
            "    StrictStr,",
            "    TypeAdapter,",
            "    ValidationInfo,",
            "    field_validator,",
            ")",
            "from pydantic.dataclasses import dataclass",
            "from rekor_types import Dsse, Hashedrekord, ProposedEntry",
            "from rfc3161_client import TimeStampResponse, decode_timestamp_response",
            "from sigstore_protobuf_specs.dev.sigstore.bundle import v1 as bundle_v1",
            "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (",
            "    Bundle as _Bundle,",
            ")",
            "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (",
            "    TimestampVerificationData as _TimestampVerificationData,",
            ")",
            "from sigstore_protobuf_specs.dev.sigstore.bundle.v1 import (",
            "    VerificationMaterial as _VerificationMaterial,",
            ")",
            "from sigstore_protobuf_specs.dev.sigstore.common import v1 as common_v1",
            "from sigstore_protobuf_specs.dev.sigstore.common.v1 import Rfc3161SignedTimestamp",
            "from sigstore_protobuf_specs.dev.sigstore.rekor import v1 as rekor_v1",
            "from sigstore_protobuf_specs.dev.sigstore.rekor.v1 import (",
            "    InclusionProof,",
            ")",
            "",
            "from sigstore import dsse",
            "from sigstore._internal.merkle import verify_merkle_inclusion",
            "from sigstore._internal.rekor.checkpoint import verify_checkpoint",
            "from sigstore._utils import (",
            "    B64Str,",
            "    KeyID,",
            "    cert_is_leaf,",
            "    cert_is_root_ca,",
            ")",
            "from sigstore.errors import Error, VerificationError",
            "",
            "if typing.TYPE_CHECKING:",
            "    from sigstore._internal.trust import RekorKeyring",
            "",
            "",
            "_logger = logging.getLogger(__name__)",
            "",
            "",
            "class LogInclusionProof(BaseModel):",
            "    \"\"\"",
            "    Represents an inclusion proof for a transparency log entry.",
            "    \"\"\"",
            "",
            "    model_config = ConfigDict(populate_by_name=True)",
            "",
            "    checkpoint: StrictStr = Field(..., alias=\"checkpoint\")",
            "    hashes: List[StrictStr] = Field(..., alias=\"hashes\")",
            "    log_index: StrictInt = Field(..., alias=\"logIndex\")",
            "    root_hash: StrictStr = Field(..., alias=\"rootHash\")",
            "    tree_size: StrictInt = Field(..., alias=\"treeSize\")",
            "",
            "    @field_validator(\"log_index\")",
            "    def _log_index_positive(cls, v: int) -> int:",
            "        if v < 0:",
            "            raise ValueError(f\"Inclusion proof has invalid log index: {v} < 0\")",
            "        return v",
            "",
            "    @field_validator(\"tree_size\")",
            "    def _tree_size_positive(cls, v: int) -> int:",
            "        if v < 0:",
            "            raise ValueError(f\"Inclusion proof has invalid tree size: {v} < 0\")",
            "        return v",
            "",
            "    @field_validator(\"tree_size\")",
            "    def _log_index_within_tree_size(",
            "        cls, v: int, info: ValidationInfo, **kwargs: Any",
            "    ) -> int:",
            "        if \"log_index\" in info.data and v <= info.data[\"log_index\"]:",
            "            raise ValueError(",
            "                \"Inclusion proof has log index greater than or equal to tree size: \"",
            "                f\"{v} <= {info.data['log_index']}\"",
            "            )",
            "        return v",
            "",
            "",
            "@dataclass(frozen=True)",
            "class LogEntry:",
            "    \"\"\"",
            "    Represents a transparency log entry.",
            "",
            "    Log entries are retrieved from the transparency log after signing or verification events,",
            "    or loaded from \"Sigstore\" bundles provided by the user.",
            "",
            "    This representation allows for either a missing inclusion promise or a missing",
            "    inclusion proof, but not both: attempting to construct a `LogEntry` without",
            "    at least one will fail.",
            "    \"\"\"",
            "",
            "    uuid: Optional[str]",
            "    \"\"\"",
            "    This entry's unique ID in the log instance it was retrieved from.",
            "",
            "    For sharded log deployments, IDs are unique per-shard.",
            "",
            "    Not present for `LogEntry` instances loaded from Sigstore bundles.",
            "    \"\"\"",
            "",
            "    body: B64Str",
            "    \"\"\"",
            "    The base64-encoded body of the transparency log entry.",
            "    \"\"\"",
            "",
            "    integrated_time: int",
            "    \"\"\"",
            "    The UNIX time at which this entry was integrated into the transparency log.",
            "    \"\"\"",
            "",
            "    log_id: str",
            "    \"\"\"",
            "    The log's ID (as the SHA256 hash of the DER-encoded public key for the log",
            "    at the time of entry inclusion).",
            "    \"\"\"",
            "",
            "    log_index: int",
            "    \"\"\"",
            "    The index of this entry within the log.",
            "    \"\"\"",
            "",
            "    inclusion_proof: LogInclusionProof",
            "    \"\"\"",
            "    An inclusion proof for this log entry.",
            "    \"\"\"",
            "",
            "    inclusion_promise: Optional[B64Str]",
            "    \"\"\"",
            "    An inclusion promise for this log entry, if present.",
            "",
            "    Internally, this is a base64-encoded Signed Entry Timestamp (SET) for this",
            "    log entry.",
            "    \"\"\"",
            "",
            "    @classmethod",
            "    def _from_response(cls, dict_: dict[str, Any]) -> LogEntry:",
            "        \"\"\"",
            "        Create a new `LogEntry` from the given API response.",
            "        \"\"\"",
            "",
            "        # Assumes we only get one entry back",
            "        entries = list(dict_.items())",
            "        if len(entries) != 1:",
            "            raise ValueError(\"Received multiple entries in response\")",
            "",
            "        uuid, entry = entries[0]",
            "        return LogEntry(",
            "            uuid=uuid,",
            "            body=entry[\"body\"],",
            "            integrated_time=entry[\"integratedTime\"],",
            "            log_id=entry[\"logID\"],",
            "            log_index=entry[\"logIndex\"],",
            "            inclusion_proof=LogInclusionProof.model_validate(",
            "                entry[\"verification\"][\"inclusionProof\"]",
            "            ),",
            "            inclusion_promise=entry[\"verification\"][\"signedEntryTimestamp\"],",
            "        )",
            "",
            "    @classmethod",
            "    def _from_dict_rekor(cls, dict_: dict[str, Any]) -> LogEntry:",
            "        \"\"\"",
            "        Create a new `LogEntry` from the given Rekor TransparencyLogEntry.",
            "        \"\"\"",
            "        tlog_entry = rekor_v1.TransparencyLogEntry()",
            "        tlog_entry.from_dict(dict_)",
            "",
            "        inclusion_proof: InclusionProof | None = tlog_entry.inclusion_proof",
            "        # This check is required by us as the client, not the",
            "        # protobuf-specs themselves.",
            "        if not inclusion_proof or not inclusion_proof.checkpoint.envelope:",
            "            raise InvalidBundle(\"entry must contain inclusion proof, with checkpoint\")",
            "",
            "        parsed_inclusion_proof = LogInclusionProof(",
            "            checkpoint=inclusion_proof.checkpoint.envelope,",
            "            hashes=[h.hex() for h in inclusion_proof.hashes],",
            "            log_index=inclusion_proof.log_index,",
            "            root_hash=inclusion_proof.root_hash.hex(),",
            "            tree_size=inclusion_proof.tree_size,",
            "        )",
            "",
            "        return LogEntry(",
            "            uuid=None,",
            "            body=B64Str(base64.b64encode(tlog_entry.canonicalized_body).decode()),",
            "            integrated_time=tlog_entry.integrated_time,",
            "            log_id=tlog_entry.log_id.key_id.hex(),",
            "            log_index=tlog_entry.log_index,",
            "            inclusion_proof=parsed_inclusion_proof,",
            "            inclusion_promise=B64Str(",
            "                base64.b64encode(",
            "                    tlog_entry.inclusion_promise.signed_entry_timestamp",
            "                ).decode()",
            "            ),",
            "        )",
            "",
            "    def _to_rekor(self) -> rekor_v1.TransparencyLogEntry:",
            "        \"\"\"",
            "        Create a new protobuf-level `TransparencyLogEntry` from this `LogEntry`.",
            "",
            "        @private",
            "        \"\"\"",
            "        inclusion_promise: rekor_v1.InclusionPromise | None = None",
            "        if self.inclusion_promise:",
            "            inclusion_promise = rekor_v1.InclusionPromise(",
            "                signed_entry_timestamp=base64.b64decode(self.inclusion_promise)",
            "            )",
            "",
            "        inclusion_proof = rekor_v1.InclusionProof(",
            "            log_index=self.inclusion_proof.log_index,",
            "            root_hash=bytes.fromhex(self.inclusion_proof.root_hash),",
            "            tree_size=self.inclusion_proof.tree_size,",
            "            hashes=[bytes.fromhex(hash_) for hash_ in self.inclusion_proof.hashes],",
            "            checkpoint=rekor_v1.Checkpoint(envelope=self.inclusion_proof.checkpoint),",
            "        )",
            "",
            "        tlog_entry = rekor_v1.TransparencyLogEntry(",
            "            log_index=self.log_index,",
            "            log_id=common_v1.LogId(key_id=bytes.fromhex(self.log_id)),",
            "            integrated_time=self.integrated_time,",
            "            inclusion_promise=inclusion_promise,  # type: ignore[arg-type]",
            "            inclusion_proof=inclusion_proof,",
            "            canonicalized_body=base64.b64decode(self.body),",
            "        )",
            "",
            "        # Fill in the appropriate kind",
            "        body_entry: ProposedEntry = TypeAdapter(ProposedEntry).validate_json(",
            "            tlog_entry.canonicalized_body",
            "        )",
            "        if not isinstance(body_entry, (Hashedrekord, Dsse)):",
            "            raise InvalidBundle(\"log entry is not of expected type\")",
            "",
            "        tlog_entry.kind_version = rekor_v1.KindVersion(",
            "            kind=body_entry.kind, version=body_entry.api_version",
            "        )",
            "",
            "        return tlog_entry",
            "",
            "    def encode_canonical(self) -> bytes:",
            "        \"\"\"",
            "        Returns a canonicalized JSON (RFC 8785) representation of the transparency log entry.",
            "",
            "        This encoded representation is suitable for verification against",
            "        the Signed Entry Timestamp.",
            "        \"\"\"",
            "        payload: dict[str, int | str] = {",
            "            \"body\": self.body,",
            "            \"integratedTime\": self.integrated_time,",
            "            \"logID\": self.log_id,",
            "            \"logIndex\": self.log_index,",
            "        }",
            "",
            "        return rfc8785.dumps(payload)",
            "",
            "    def _verify_set(self, keyring: RekorKeyring) -> None:",
            "        \"\"\"",
            "        Verify the inclusion promise (Signed Entry Timestamp) for a given transparency log",
            "        `entry` using the given `keyring`.",
            "",
            "        Fails if the given log entry does not contain an inclusion promise.",
            "        \"\"\"",
            "",
            "        if self.inclusion_promise is None:",
            "            raise VerificationError(\"SET: invalid inclusion promise: missing\")",
            "",
            "        signed_entry_ts = base64.b64decode(self.inclusion_promise)",
            "",
            "        try:",
            "            keyring.verify(",
            "                key_id=KeyID(bytes.fromhex(self.log_id)),",
            "                signature=signed_entry_ts,",
            "                data=self.encode_canonical(),",
            "            )",
            "        except VerificationError as exc:",
            "            raise VerificationError(f\"SET: invalid inclusion promise: {exc}\")",
            "",
            "    def _verify(self, keyring: RekorKeyring) -> None:",
            "        \"\"\"",
            "        Verifies this log entry.",
            "",
            "        This method performs steps (5), (6), and optionally (7) in",
            "        the top-level verify API:",
            "",
            "        * Verifies the consistency of the entry with the given bundle;",
            "        * Verifies the Merkle inclusion proof and its signed checkpoint;",
            "        * Verifies the inclusion promise, if present.",
            "        \"\"\"",
            "",
            "        verify_merkle_inclusion(self)",
            "        verify_checkpoint(keyring, self)",
            "",
            "        _logger.debug(f\"successfully verified inclusion proof: index={self.log_index}\")",
            "",
            "        if self.inclusion_promise:",
            "            self._verify_set(keyring)",
            "            _logger.debug(",
            "                f\"successfully verified inclusion promise: index={self.log_index}\"",
            "            )",
            "",
            "",
            "class TimestampVerificationData:",
            "    \"\"\"",
            "    Represents a TimestampVerificationData structure.",
            "",
            "    @private",
            "    \"\"\"",
            "",
            "    def __init__(self, inner: _TimestampVerificationData) -> None:",
            "        \"\"\"Init method.\"\"\"",
            "        self._inner = inner",
            "        self._verify()",
            "",
            "    def _verify(self) -> None:",
            "        \"\"\"",
            "        Verifies the TimestampVerificationData.",
            "",
            "        It verifies that TimeStamp Responses embedded in the bundle are correctly",
            "        formed.",
            "        \"\"\"",
            "        try:",
            "            self._signed_ts = [",
            "                decode_timestamp_response(ts.signed_timestamp)",
            "                for ts in self._inner.rfc3161_timestamps",
            "            ]",
            "        except ValueError:",
            "            raise VerificationError(\"Invalid Timestamp Response\")",
            "",
            "    @property",
            "    def rfc3161_timestamps(self) -> list[TimeStampResponse]:",
            "        \"\"\"Returns a list of signed timestamp.\"\"\"",
            "        return self._signed_ts",
            "",
            "    @classmethod",
            "    def from_json(cls, raw: str | bytes) -> TimestampVerificationData:",
            "        \"\"\"",
            "        Deserialize the given timestamp verification data.",
            "        \"\"\"",
            "        inner = _TimestampVerificationData().from_json(raw)",
            "        return cls(inner)",
            "",
            "",
            "class VerificationMaterial:",
            "    \"\"\"",
            "    Represents a VerificationMaterial structure.",
            "    \"\"\"",
            "",
            "    def __init__(self, inner: _VerificationMaterial) -> None:",
            "        \"\"\"Init method.\"\"\"",
            "        self._inner = inner",
            "",
            "    @property",
            "    def timestamp_verification_data(self) -> TimestampVerificationData:",
            "        \"\"\"",
            "        Returns the Timestamp Verification Data.",
            "        \"\"\"",
            "        return TimestampVerificationData(self._inner.timestamp_verification_data)",
            "",
            "",
            "class InvalidBundle(Error):",
            "    \"\"\"",
            "    Raised when the associated `Bundle` is invalid in some way.",
            "    \"\"\"",
            "",
            "    def diagnostics(self) -> str:",
            "        \"\"\"Returns diagnostics for the error.\"\"\"",
            "",
            "        return dedent(",
            "            f\"\"\"\\",
            "        An issue occurred while parsing the Sigstore bundle.",
            "",
            "        The provided bundle is malformed and may have been modified maliciously.",
            "",
            "        Additional context:",
            "",
            "        {self}",
            "        \"\"\"",
            "        )",
            "",
            "",
            "class Bundle:",
            "    \"\"\"",
            "    Represents a Sigstore bundle.",
            "    \"\"\"",
            "",
            "    class BundleType(str, Enum):",
            "        \"\"\"",
            "        Known Sigstore bundle media types.",
            "        \"\"\"",
            "",
            "        BUNDLE_0_1 = \"application/vnd.dev.sigstore.bundle+json;version=0.1\"",
            "        BUNDLE_0_2 = \"application/vnd.dev.sigstore.bundle+json;version=0.2\"",
            "        BUNDLE_0_3_ALT = \"application/vnd.dev.sigstore.bundle+json;version=0.3\"",
            "        BUNDLE_0_3 = \"application/vnd.dev.sigstore.bundle.v0.3+json\"",
            "",
            "        def __str__(self) -> str:",
            "            \"\"\"Returns the variant's string value.\"\"\"",
            "            return self.value",
            "",
            "    def __init__(self, inner: _Bundle) -> None:",
            "        \"\"\"",
            "        Creates a new bundle. This is not a public API; use",
            "        `from_json` instead.",
            "",
            "        @private",
            "        \"\"\"",
            "        self._inner = inner",
            "        self._verify()",
            "",
            "    def _verify(self) -> None:",
            "        \"\"\"",
            "        Performs various feats of heroism to ensure the bundle is well-formed",
            "        and upholds invariants, including:",
            "",
            "        * The \"leaf\" (signing) certificate is present;",
            "        * There is a inclusion proof present, even if the Bundle's version",
            "           predates a mandatory inclusion proof.",
            "        \"\"\"",
            "",
            "        # The bundle must have a recognized media type.",
            "        try:",
            "            media_type = Bundle.BundleType(self._inner.media_type)",
            "        except ValueError:",
            "            raise InvalidBundle(f\"unsupported bundle format: {self._inner.media_type}\")",
            "",
            "        # Extract the signing certificate.",
            "        if media_type in (",
            "            Bundle.BundleType.BUNDLE_0_3,",
            "            Bundle.BundleType.BUNDLE_0_3_ALT,",
            "        ):",
            "            # For \"v3\" bundles, the signing certificate is the only one present.",
            "            leaf_cert = load_der_x509_certificate(",
            "                self._inner.verification_material.certificate.raw_bytes",
            "            )",
            "        else:",
            "            # In older bundles, there is an entire pool (misleadingly called",
            "            # a chain) of certificates, the first of which is the signing",
            "            # certificate.",
            "            certs = (",
            "                self._inner.verification_material.x509_certificate_chain.certificates",
            "            )",
            "",
            "            if len(certs) == 0:",
            "                raise InvalidBundle(\"expected non-empty certificate chain in bundle\")",
            "",
            "            # Per client policy in protobuf-specs: the first entry in the chain",
            "            # MUST be a leaf certificate, and the rest of the chain MUST NOT",
            "            # include a root CA or any intermediate CAs that appear in an",
            "            # independent root of trust.",
            "            #",
            "            # We expect some old bundles to violate the rules around root",
            "            # and intermediate CAs, so we issue warnings and not hard errors",
            "            # in those cases.",
            "            leaf_cert, *chain_certs = [",
            "                load_der_x509_certificate(cert.raw_bytes) for cert in certs",
            "            ]",
            "            if not cert_is_leaf(leaf_cert):",
            "                raise InvalidBundle(",
            "                    \"bundle contains an invalid leaf or non-leaf certificate in the leaf position\"",
            "                )",
            "",
            "            for chain_cert in chain_certs:",
            "                # TODO: We should also retrieve the root of trust here and",
            "                # cross-check against it.",
            "                if cert_is_root_ca(chain_cert):",
            "                    _logger.warning(",
            "                        \"this bundle contains a root CA, making it subject to misuse\"",
            "                    )",
            "",
            "        self._signing_certificate = leaf_cert",
            "",
            "        # Extract the log entry. For the time being, we expect",
            "        # bundles to only contain a single log entry.",
            "        tlog_entries = self._inner.verification_material.tlog_entries",
            "        if len(tlog_entries) != 1:",
            "            raise InvalidBundle(\"expected exactly one log entry in bundle\")",
            "        tlog_entry = tlog_entries[0]",
            "",
            "        # Handling of inclusion promises and proofs varies between bundle",
            "        # format versions:",
            "        #",
            "        # * For 0.1, an inclusion promise is required; the client",
            "        #   MUST verify the inclusion promise.",
            "        #   The inclusion proof is NOT required. If provided, it might NOT",
            "        #   contain a checkpoint; in this case, we ignore it (since it's",
            "        #   useless without one).",
            "        #",
            "        # * For 0.2+, an inclusion proof is required; the client MUST",
            "        #   verify the inclusion proof. The inclusion prof MUST contain",
            "        #   a checkpoint.",
            "        #",
            "        #   The inclusion promise is NOT required if another source of signed",
            "        #   time (such as a signed timestamp) is present. If no other source",
            "        #   of signed time is present, then the inclusion promise MUST be",
            "        #   present.",
            "        #",
            "        # Before all of this, we require that the inclusion proof be present",
            "        # (when constructing the LogEntry).",
            "        log_entry = LogEntry._from_dict_rekor(tlog_entry.to_dict())",
            "",
            "        if media_type == Bundle.BundleType.BUNDLE_0_1:",
            "            if not log_entry.inclusion_promise:",
            "                raise InvalidBundle(\"bundle must contain an inclusion promise\")",
            "            if not log_entry.inclusion_proof.checkpoint:",
            "                _logger.debug(",
            "                    \"0.1 bundle contains inclusion proof without checkpoint; ignoring\"",
            "                )",
            "        else:",
            "            if not log_entry.inclusion_proof.checkpoint:",
            "                raise InvalidBundle(\"expected checkpoint in inclusion proof\")",
            "",
            "            if (",
            "                not log_entry.inclusion_promise",
            "                and not self._inner.verification_material.timestamp_verification_data.rfc3161_timestamps",
            "            ):",
            "                raise InvalidBundle(",
            "                    \"bundle must contain an inclusion promise or signed timestamp(s)\"",
            "                )",
            "",
            "        self._log_entry = log_entry",
            "",
            "    @property",
            "    def signing_certificate(self) -> Certificate:",
            "        \"\"\"Returns the bundle's contained signing (i.e. leaf) certificate.\"\"\"",
            "        return self._signing_certificate",
            "",
            "    @property",
            "    def log_entry(self) -> LogEntry:",
            "        \"\"\"",
            "        Returns the bundle's log entry, containing an inclusion proof",
            "        (with checkpoint) and an inclusion promise (if the latter is present).",
            "        \"\"\"",
            "        return self._log_entry",
            "",
            "    @property",
            "    def _dsse_envelope(self) -> dsse.Envelope | None:",
            "        \"\"\"",
            "        Returns the DSSE envelope within this Bundle as a `dsse.Envelope`.",
            "",
            "        @private",
            "        \"\"\"",
            "        if self._inner.dsse_envelope:",
            "            return dsse.Envelope(self._inner.dsse_envelope)",
            "        return None",
            "",
            "    @property",
            "    def signature(self) -> bytes:",
            "        \"\"\"",
            "        Returns the signature bytes of this bundle.",
            "        Either from the DSSE Envelope or from the message itself.",
            "        \"\"\"",
            "        return (",
            "            self._dsse_envelope.signature",
            "            if self._dsse_envelope",
            "            else self._inner.message_signature.signature",
            "        )",
            "",
            "    @property",
            "    def verification_material(self) -> VerificationMaterial:",
            "        \"\"\"",
            "        Returns the bundle's verification material.",
            "        \"\"\"",
            "        return VerificationMaterial(self._inner.verification_material)",
            "",
            "    @classmethod",
            "    def from_json(cls, raw: bytes | str) -> Bundle:",
            "        \"\"\"",
            "        Deserialize the given Sigstore bundle.",
            "        \"\"\"",
            "        inner = _Bundle().from_json(raw)",
            "        return cls(inner)",
            "",
            "    def to_json(self) -> str:",
            "        \"\"\"",
            "        Return a JSON encoding of this bundle.",
            "        \"\"\"",
            "        return self._inner.to_json()",
            "",
            "    def _to_parts(",
            "        self,",
            "    ) -> tuple[Certificate, common_v1.MessageSignature | dsse.Envelope, LogEntry]:",
            "        \"\"\"",
            "        Decompose the `Bundle` into its core constituent parts.",
            "",
            "        @private",
            "        \"\"\"",
            "",
            "        content: common_v1.MessageSignature | dsse.Envelope",
            "        if self._dsse_envelope:",
            "            content = self._dsse_envelope",
            "        else:",
            "            content = self._inner.message_signature",
            "",
            "        return (self.signing_certificate, content, self.log_entry)",
            "",
            "    @classmethod",
            "    def from_parts(cls, cert: Certificate, sig: bytes, log_entry: LogEntry) -> Bundle:",
            "        \"\"\"",
            "        Construct a Sigstore bundle (of `hashedrekord` type) from its",
            "        constituent parts.",
            "        \"\"\"",
            "",
            "        return cls._from_parts(",
            "            cert, common_v1.MessageSignature(signature=sig), log_entry",
            "        )",
            "",
            "    @classmethod",
            "    def _from_parts(",
            "        cls,",
            "        cert: Certificate,",
            "        content: common_v1.MessageSignature | dsse.Envelope,",
            "        log_entry: LogEntry,",
            "        signed_timestamp: Optional[List[TimeStampResponse]] = None,",
            "    ) -> Bundle:",
            "        \"\"\"",
            "        @private",
            "        \"\"\"",
            "",
            "        inner = _Bundle(",
            "            media_type=Bundle.BundleType.BUNDLE_0_3.value,",
            "            verification_material=bundle_v1.VerificationMaterial(",
            "                certificate=common_v1.X509Certificate(cert.public_bytes(Encoding.DER)),",
            "            ),",
            "        )",
            "",
            "        # Fill in the appropriate variants.",
            "        if isinstance(content, common_v1.MessageSignature):",
            "            inner.message_signature = content",
            "        else:",
            "            inner.dsse_envelope = content._inner",
            "",
            "        tlog_entry = log_entry._to_rekor()",
            "        inner.verification_material.tlog_entries = [tlog_entry]",
            "",
            "        if signed_timestamp is not None:",
            "            inner.verification_material.timestamp_verification_data = (",
            "                bundle_v1.TimestampVerificationData(",
            "                    rfc3161_timestamps=[",
            "                        Rfc3161SignedTimestamp(signed_timestamp=response.as_bytes())",
            "                        for response in signed_timestamp",
            "                    ]",
            "                )",
            "            )",
            "",
            "        return cls(inner)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "528": [
                "Bundle",
                "_verify"
            ],
            "529": [
                "Bundle",
                "_verify"
            ]
        },
        "addLocation": []
    },
    "sigstore/verify/verifier.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 227,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": 228,
                "PatchRowcode": "         # If a timestamp from the Transparency Service is available, the Verifier MUST"
            },
            "2": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": 229,
                "PatchRowcode": "         # perform path validation using the timestamp from the Transparency Service."
            },
            "3": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if timestamp := bundle.log_entry.integrated_time:"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 230,
                "PatchRowcode": "+        # NOTE: We only include this timestamp if it's accompanied by an inclusion"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 231,
                "PatchRowcode": "+        # promise that cryptographically binds it. We verify the inclusion promise"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 232,
                "PatchRowcode": "+        # itself later, as part of log entry verification."
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 233,
                "PatchRowcode": "+        if ("
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 234,
                "PatchRowcode": "+            timestamp := bundle.log_entry.integrated_time"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+        ) and bundle.log_entry.inclusion_promise:"
            },
            "10": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "             verified_timestamps.append("
            },
            "11": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "                 TimestampVerificationResult("
            },
            "12": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "                     source=TimestampSource.TRANSPARENCY_SERVICE,"
            }
        },
        "frontPatchFile": [
            "# Copyright 2022 The Sigstore Authors",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"",
            "Verification API machinery.",
            "\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import base64",
            "import logging",
            "from datetime import datetime, timezone",
            "from typing import List, cast",
            "",
            "import rekor_types",
            "from cryptography.exceptions import InvalidSignature",
            "from cryptography.hazmat.primitives.asymmetric import ec",
            "from cryptography.x509 import ExtendedKeyUsage, KeyUsage",
            "from cryptography.x509.oid import ExtendedKeyUsageOID",
            "from OpenSSL.crypto import (",
            "    X509,",
            "    X509Store,",
            "    X509StoreContext,",
            "    X509StoreContextError,",
            "    X509StoreFlags,",
            ")",
            "from pydantic import ValidationError",
            "from rfc3161_client import TimeStampResponse, VerifierBuilder",
            "from rfc3161_client import VerificationError as Rfc3161VerificationError",
            "",
            "from sigstore import dsse",
            "from sigstore._internal.rekor import _hashedrekord_from_parts",
            "from sigstore._internal.rekor.client import RekorClient",
            "from sigstore._internal.sct import (",
            "    _get_precertificate_signed_certificate_timestamps,",
            "    verify_sct,",
            ")",
            "from sigstore._internal.timestamp import TimestampSource, TimestampVerificationResult",
            "from sigstore._internal.trust import ClientTrustConfig, KeyringPurpose, TrustedRoot",
            "from sigstore._utils import base64_encode_pem_cert, sha256_digest",
            "from sigstore.errors import VerificationError",
            "from sigstore.hashes import Hashed",
            "from sigstore.models import Bundle",
            "from sigstore.verify.policy import VerificationPolicy",
            "",
            "_logger = logging.getLogger(__name__)",
            "",
            "# Limit the number of timestamps to prevent DoS",
            "# From https://github.com/sigstore/sigstore-go/blob/e92142f0734064ebf6001f188b7330a1212245fe/pkg/verify/tsa.go#L29",
            "MAX_ALLOWED_TIMESTAMP: int = 32",
            "",
            "# When verifying a timestamp, this threshold represents the minimum number of required",
            "# timestamps to consider a signature valid.",
            "VERIFY_TIMESTAMP_THRESHOLD: int = 1",
            "",
            "",
            "class Verifier:",
            "    \"\"\"",
            "    The primary API for verification operations.",
            "    \"\"\"",
            "",
            "    def __init__(self, *, rekor: RekorClient, trusted_root: TrustedRoot):",
            "        \"\"\"",
            "        Create a new `Verifier`.",
            "",
            "        `rekor` is a `RekorClient` capable of connecting to a Rekor instance",
            "        containing logs for the file(s) being verified.",
            "",
            "        `fulcio_certificate_chain` is a list of PEM-encoded X.509 certificates,",
            "        establishing the trust chain for the signing certificate and signature.",
            "        \"\"\"",
            "        self._rekor = rekor",
            "        self._fulcio_certificate_chain: List[X509] = [",
            "            X509.from_cryptography(parent_cert)",
            "            for parent_cert in trusted_root.get_fulcio_certs()",
            "        ]",
            "        self._trusted_root = trusted_root",
            "",
            "    @classmethod",
            "    def production(cls, *, offline: bool = False) -> Verifier:",
            "        \"\"\"",
            "        Return a `Verifier` instance configured against Sigstore's production-level services.",
            "        \"\"\"",
            "        return cls(",
            "            rekor=RekorClient.production(),",
            "            trusted_root=TrustedRoot.production(offline=offline),",
            "        )",
            "",
            "    @classmethod",
            "    def staging(cls, *, offline: bool = False) -> Verifier:",
            "        \"\"\"",
            "        Return a `Verifier` instance configured against Sigstore's staging-level services.",
            "        \"\"\"",
            "        return cls(",
            "            rekor=RekorClient.staging(),",
            "            trusted_root=TrustedRoot.staging(offline=offline),",
            "        )",
            "",
            "    @classmethod",
            "    def _from_trust_config(cls, trust_config: ClientTrustConfig) -> Verifier:",
            "        \"\"\"",
            "        Create a `Verifier` from the given `ClientTrustConfig`.",
            "",
            "        @api private",
            "        \"\"\"",
            "        return cls(",
            "            rekor=RekorClient(trust_config._inner.signing_config.tlog_urls[0]),",
            "            trusted_root=trust_config.trusted_root,",
            "        )",
            "",
            "    def _verify_signed_timestamp(",
            "        self, timestamp_response: TimeStampResponse, signature: bytes",
            "    ) -> TimestampVerificationResult | None:",
            "        \"\"\"",
            "        Verify a Signed Timestamp using the TSA provided by the Trusted Root.",
            "        \"\"\"",
            "        cert_authorities = self._trusted_root.get_timestamp_authorities()",
            "        for certificate_authority in cert_authorities:",
            "            certificates = certificate_authority.certificates(allow_expired=True)",
            "",
            "            builder = VerifierBuilder()",
            "            for certificate in certificates:",
            "                builder.add_root_certificate(certificate)",
            "",
            "            verifier = builder.build()",
            "            try:",
            "                verifier.verify(timestamp_response, signature)",
            "            except Rfc3161VerificationError as e:",
            "                _logger.debug(\"Unable to verify Timestamp with CA.\")",
            "                _logger.exception(e)",
            "                continue",
            "",
            "            if (",
            "                certificate_authority.validity_period_start",
            "                and certificate_authority.validity_period_end",
            "            ):",
            "                if (",
            "                    certificate_authority.validity_period_start",
            "                    <= timestamp_response.tst_info.gen_time",
            "                    < certificate_authority.validity_period_end",
            "                ):",
            "                    return TimestampVerificationResult(",
            "                        source=TimestampSource.TIMESTAMP_AUTHORITY,",
            "                        time=timestamp_response.tst_info.gen_time,",
            "                    )",
            "",
            "                _logger.debug(",
            "                    \"Unable to verify Timestamp because not in CA time range.\"",
            "                )",
            "            else:",
            "                _logger.debug(",
            "                    \"Unable to verify Timestamp because no validity provided.\"",
            "                )",
            "",
            "        return None",
            "",
            "    def _verify_timestamp_authority(",
            "        self, bundle: Bundle",
            "    ) -> List[TimestampVerificationResult]:",
            "        \"\"\"",
            "        Verify that the given bundle has been timestamped by a trusted timestamp authority",
            "        and that the timestamp is valid.",
            "",
            "        Returns the number of valid signed timestamp in the bundle.",
            "        \"\"\"",
            "        timestamp_responses = (",
            "            bundle.verification_material.timestamp_verification_data.rfc3161_timestamps",
            "        )",
            "        if len(timestamp_responses) > MAX_ALLOWED_TIMESTAMP:",
            "            msg = f\"too many signed timestamp: {len(timestamp_responses)} > {MAX_ALLOWED_TIMESTAMP}\"",
            "            raise VerificationError(msg)",
            "",
            "        if len(set(timestamp_responses)) != len(timestamp_responses):",
            "            msg = \"duplicate timestamp found\"",
            "            raise VerificationError(msg)",
            "",
            "        # The Signer sends a hash of the signature as the messageImprint in a TimeStampReq",
            "        # to the Timestamping Service",
            "        signature_hash = sha256_digest(bundle.signature).digest",
            "        verified_timestamps = []",
            "        for tsr in timestamp_responses:",
            "            if verified_timestamp := self._verify_signed_timestamp(tsr, signature_hash):",
            "                verified_timestamps.append(verified_timestamp)",
            "",
            "        return verified_timestamps",
            "",
            "    def _establish_time(self, bundle: Bundle) -> List[TimestampVerificationResult]:",
            "        \"\"\"",
            "        Establish the time for bundle verification.",
            "",
            "        This method uses timestamps from two possible sources:",
            "        1. RFC3161 signed timestamps from a Timestamping Authority (TSA)",
            "        2. Transparency Log timestamps",
            "        \"\"\"",
            "        verified_timestamps = []",
            "",
            "        # If a timestamp from the timestamping service is available, the Verifier MUST",
            "        # perform path validation using the timestamp from the Timestamping Service.",
            "        if bundle.verification_material.timestamp_verification_data.rfc3161_timestamps:",
            "            if not self._trusted_root.get_timestamp_authorities():",
            "                msg = (",
            "                    \"no Timestamp Authorities have been provided to validate this \"",
            "                    \"bundle but it contains a signed timestamp\"",
            "                )",
            "                raise VerificationError(msg)",
            "",
            "            timestamp_from_tsa = self._verify_timestamp_authority(bundle)",
            "            if len(timestamp_from_tsa) < VERIFY_TIMESTAMP_THRESHOLD:",
            "                msg = (",
            "                    f\"not enough timestamps validated to meet the validation \"",
            "                    f\"threshold ({len(timestamp_from_tsa)}/{VERIFY_TIMESTAMP_THRESHOLD})\"",
            "                )",
            "                raise VerificationError(msg)",
            "",
            "            verified_timestamps.extend(timestamp_from_tsa)",
            "",
            "        # If a timestamp from the Transparency Service is available, the Verifier MUST",
            "        # perform path validation using the timestamp from the Transparency Service.",
            "        if timestamp := bundle.log_entry.integrated_time:",
            "            verified_timestamps.append(",
            "                TimestampVerificationResult(",
            "                    source=TimestampSource.TRANSPARENCY_SERVICE,",
            "                    time=datetime.fromtimestamp(timestamp, tz=timezone.utc),",
            "                )",
            "            )",
            "        return verified_timestamps",
            "",
            "    def _verify_chain_at_time(",
            "        self, certificate: X509, timestamp_result: TimestampVerificationResult",
            "    ) -> List[X509]:",
            "        \"\"\"",
            "        Verify the validity of the certificate chain at the given time.",
            "",
            "        Raises a VerificationError if the chain can't be built or be verified.",
            "        \"\"\"",
            "        # NOTE: The `X509Store` object cannot have its time reset once the `set_time`",
            "        # method been called on it. To get around this, we construct a new one in each",
            "        # call.",
            "        store = X509Store()",
            "        # NOTE: By explicitly setting the flags here, we ensure that OpenSSL's",
            "        # PARTIAL_CHAIN default does not change on us. Enabling PARTIAL_CHAIN",
            "        # would be strictly more conformant of OpenSSL, but we currently",
            "        # *want* the \"long\" chain behavior of performing path validation",
            "        # down to a self-signed root.",
            "        store.set_flags(X509StoreFlags.X509_STRICT)",
            "        for parent_cert_ossl in self._fulcio_certificate_chain:",
            "            store.add_cert(parent_cert_ossl)",
            "",
            "        store.set_time(timestamp_result.time)",
            "",
            "        store_ctx = X509StoreContext(store, certificate)",
            "",
            "        try:",
            "            # get_verified_chain returns the full chain including the end-entity certificate",
            "            # and chain should contain only CA certificates",
            "            return store_ctx.get_verified_chain()[1:]",
            "        except X509StoreContextError as e:",
            "            raise VerificationError(f\"failed to build chain: {e}\")",
            "",
            "    def _verify_common_signing_cert(",
            "        self, bundle: Bundle, policy: VerificationPolicy",
            "    ) -> None:",
            "        \"\"\"",
            "        Performs the signing certificate verification steps that are shared between",
            "        `verify_dsse` and `verify_artifact`.",
            "",
            "        Raises `VerificationError` on all failures.",
            "        \"\"\"",
            "",
            "        # In order to verify an artifact, we need to achieve the following:",
            "        #",
            "        # 0. Establish a time for the signature.",
            "        # 1. Verify that the signing certificate chains to the root of trust",
            "        #    and is valid at the time of signing.",
            "        # 2. Verify the signing certificate's SCT.",
            "        # 3. Verify that the signing certificate conforms to the Sigstore",
            "        #    X.509 profile as well as the passed-in `VerificationPolicy`.",
            "        # 4. Verify the inclusion proof and signed checkpoint for the log",
            "        #    entry.",
            "        # 5. Verify the inclusion promise for the log entry, if present.",
            "        # 6. Verify the timely insertion of the log entry against the validity",
            "        #    period for the signing certificate.",
            "        # 7. Verify the signature and input against the signing certificate's",
            "        #    public key.",
            "        # 8. Verify the transparency log entry's consistency against the other",
            "        #    materials, to prevent variants of CVE-2022-36056.",
            "        #",
            "        # This method performs steps (0) through (6) above. Its caller",
            "        # MUST perform steps (7) and (8) separately, since they vary based on",
            "        # the kind of verification being performed (i.e. hashedrekord, DSSE, etc.)",
            "",
            "        cert = bundle.signing_certificate",
            "",
            "        # NOTE: The `X509Store` object currently cannot have its time reset once the `set_time`",
            "        # method been called on it. To get around this, we construct a new one for every `verify`",
            "        # call.",
            "        store = X509Store()",
            "        # NOTE: By explicitly setting the flags here, we ensure that OpenSSL's",
            "        # PARTIAL_CHAIN default does not change on us. Enabling PARTIAL_CHAIN",
            "        # would be strictly more conformant of OpenSSL, but we currently",
            "        # *want* the \"long\" chain behavior of performing path validation",
            "        # down to a self-signed root.",
            "        store.set_flags(X509StoreFlags.X509_STRICT)",
            "        for parent_cert_ossl in self._fulcio_certificate_chain:",
            "            store.add_cert(parent_cert_ossl)",
            "",
            "        # (0): Establishing a Time for the Signature",
            "        # First, establish a time for the signature. This timestamp is required to",
            "        # validate the certificate chain, so this step comes first.",
            "        # While this step is optional and only performed if timestamp data has been",
            "        # provided within the bundle, providing a signed timestamp without a TSA to",
            "        # verify it result in a VerificationError.",
            "        verified_timestamps = self._establish_time(bundle)",
            "        if not verified_timestamps:",
            "            raise VerificationError(\"not enough sources of verified time\")",
            "",
            "        # (1): verify that the signing certificate is signed by the root",
            "        #      certificate and that the signing certificate was valid at the",
            "        #      time of signing.",
            "        cert_ossl = X509.from_cryptography(cert)",
            "        chain: list[X509] = []",
            "        for vts in verified_timestamps:",
            "            chain = self._verify_chain_at_time(cert_ossl, vts)",
            "",
            "        # (2): verify the signing certificate's SCT.",
            "        sct = _get_precertificate_signed_certificate_timestamps(cert)[0]",
            "        try:",
            "            verify_sct(",
            "                sct,",
            "                cert,",
            "                [parent_cert.to_cryptography() for parent_cert in chain],",
            "                self._trusted_root.ct_keyring(KeyringPurpose.VERIFY),",
            "            )",
            "        except VerificationError as e:",
            "            raise VerificationError(f\"failed to verify SCT on signing certificate: {e}\")",
            "",
            "        # (3): verify the signing certificate against the Sigstore",
            "        #      X.509 profile and verify against the given `VerificationPolicy`.",
            "        usage_ext = cert.extensions.get_extension_for_class(KeyUsage)",
            "        if not usage_ext.value.digital_signature:",
            "            raise VerificationError(\"Key usage is not of type `digital signature`\")",
            "",
            "        extended_usage_ext = cert.extensions.get_extension_for_class(ExtendedKeyUsage)",
            "        if ExtendedKeyUsageOID.CODE_SIGNING not in extended_usage_ext.value:",
            "            raise VerificationError(\"Extended usage does not contain `code signing`\")",
            "",
            "        policy.verify(cert)",
            "",
            "        _logger.debug(\"Successfully verified signing certificate validity...\")",
            "",
            "        # (4): verify the inclusion proof and signed checkpoint for the",
            "        #      log entry.",
            "        # (5): verify the inclusion promise for the log entry, if present.",
            "        entry = bundle.log_entry",
            "        try:",
            "            entry._verify(self._trusted_root.rekor_keyring(KeyringPurpose.VERIFY))",
            "        except VerificationError as exc:",
            "            raise VerificationError(f\"invalid log entry: {exc}\")",
            "",
            "        # (6): verify that log entry was integrated circa the signing certificate's",
            "        #      validity period.",
            "        integrated_time = datetime.fromtimestamp(entry.integrated_time, tz=timezone.utc)",
            "        if not (",
            "            bundle.signing_certificate.not_valid_before_utc",
            "            <= integrated_time",
            "            <= bundle.signing_certificate.not_valid_after_utc",
            "        ):",
            "            raise VerificationError(",
            "                \"invalid signing cert: expired at time of Rekor entry\"",
            "            )",
            "",
            "    def verify_dsse(",
            "        self, bundle: Bundle, policy: VerificationPolicy",
            "    ) -> tuple[str, bytes]:",
            "        \"\"\"",
            "        Verifies an bundle's DSSE envelope, returning the encapsulated payload",
            "        and its content type.",
            "",
            "        This method is only for DSSE-enveloped payloads. To verify",
            "        an arbitrary input against a bundle, use the `verify_artifact`",
            "        method.",
            "",
            "        `bundle` is the Sigstore `Bundle` to both verify and verify against.",
            "",
            "        `policy` is the `VerificationPolicy` to verify against.",
            "",
            "        Returns a tuple of `(type, payload)`, where `type` is the payload's",
            "        type as encoded in the DSSE envelope and `payload` is the raw `bytes`",
            "        of the payload. No validation of either `type` or `payload` is",
            "        performed; users of this API **must** assert that `type` is known",
            "        to them before proceeding to handle `payload` in an application-dependent",
            "        manner.",
            "        \"\"\"",
            "",
            "        # (1) through (6) are performed by `_verify_common_signing_cert`.",
            "        self._verify_common_signing_cert(bundle, policy)",
            "",
            "        # (7): verify the bundle's signature and DSSE envelope against the",
            "        #      signing certificate's public key.",
            "        envelope = bundle._dsse_envelope",
            "        if envelope is None:",
            "            raise VerificationError(",
            "                \"cannot perform DSSE verification on a bundle without a DSSE envelope\"",
            "            )",
            "",
            "        signing_key = bundle.signing_certificate.public_key()",
            "        signing_key = cast(ec.EllipticCurvePublicKey, signing_key)",
            "        dsse._verify(signing_key, envelope)",
            "",
            "        # (8): verify the consistency of the log entry's body against",
            "        #      the other bundle materials.",
            "        # NOTE: This is very slightly weaker than the consistency check",
            "        # for hashedrekord entries, due to how inclusion is recorded for DSSE:",
            "        # the included entry for DSSE includes an envelope hash that we",
            "        # *cannot* verify, since the envelope is uncanonicalized JSON.",
            "        # Instead, we manually pick apart the entry body below and verify",
            "        # the parts we can (namely the payload hash and signature list).",
            "        entry = bundle.log_entry",
            "        try:",
            "            entry_body = rekor_types.Dsse.model_validate_json(",
            "                base64.b64decode(entry.body)",
            "            )",
            "        except ValidationError as exc:",
            "            raise VerificationError(f\"invalid DSSE log entry: {exc}\")",
            "",
            "        payload_hash = sha256_digest(envelope._inner.payload).digest.hex()",
            "        if (",
            "            entry_body.spec.root.payload_hash.algorithm  # type: ignore[union-attr]",
            "            != rekor_types.dsse.Algorithm.SHA256",
            "        ):",
            "            raise VerificationError(\"expected SHA256 payload hash in DSSE log entry\")",
            "        if payload_hash != entry_body.spec.root.payload_hash.value:  # type: ignore[union-attr]",
            "            raise VerificationError(\"log entry payload hash does not match bundle\")",
            "",
            "        # NOTE: Like `dsse._verify`: multiple signatures would be frivolous here,",
            "        # but we handle them just in case the signer has somehow produced multiple",
            "        # signatures for their envelope with the same signing key.",
            "        signatures = [",
            "            rekor_types.dsse.Signature(",
            "                signature=base64.b64encode(signature.sig).decode(),",
            "                verifier=base64_encode_pem_cert(bundle.signing_certificate),",
            "            )",
            "            for signature in envelope._inner.signatures",
            "        ]",
            "        if signatures != entry_body.spec.root.signatures:",
            "            raise VerificationError(\"log entry signatures do not match bundle\")",
            "",
            "        return (envelope._inner.payload_type, envelope._inner.payload)",
            "",
            "    def verify_artifact(",
            "        self,",
            "        input_: bytes | Hashed,",
            "        bundle: Bundle,",
            "        policy: VerificationPolicy,",
            "    ) -> None:",
            "        \"\"\"",
            "        Public API for verifying.",
            "",
            "        `input_` is the input to verify, either as a buffer of contents or as",
            "        a prehashed `Hashed` object.",
            "",
            "        `bundle` is the Sigstore `Bundle` to verify against.",
            "",
            "        `policy` is the `VerificationPolicy` to verify against.",
            "",
            "        On failure, this method raises `VerificationError`.",
            "        \"\"\"",
            "",
            "        # (1) through (6) are performed by `_verify_common_signing_cert`.",
            "        self._verify_common_signing_cert(bundle, policy)",
            "",
            "        hashed_input = sha256_digest(input_)",
            "",
            "        # (7): verify that the signature was signed by the public key in the signing certificate.",
            "        try:",
            "            signing_key = bundle.signing_certificate.public_key()",
            "            signing_key = cast(ec.EllipticCurvePublicKey, signing_key)",
            "            signing_key.verify(",
            "                bundle._inner.message_signature.signature,",
            "                hashed_input.digest,",
            "                ec.ECDSA(hashed_input._as_prehashed()),",
            "            )",
            "        except InvalidSignature:",
            "            raise VerificationError(\"Signature is invalid for input\")",
            "",
            "        _logger.debug(\"Successfully verified signature...\")",
            "",
            "        # (8): verify the consistency of the log entry's body against",
            "        #      the other bundle materials (and input being verified).",
            "        entry = bundle.log_entry",
            "",
            "        expected_body = _hashedrekord_from_parts(",
            "            bundle.signing_certificate,",
            "            bundle._inner.message_signature.signature,",
            "            hashed_input,",
            "        )",
            "        actual_body = rekor_types.Hashedrekord.model_validate_json(",
            "            base64.b64decode(entry.body)",
            "        )",
            "        if expected_body != actual_body:",
            "            raise VerificationError(",
            "                \"transparency log entry is inconsistent with other materials\"",
            "            )"
        ],
        "afterPatchFile": [
            "# Copyright 2022 The Sigstore Authors",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#      http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"",
            "Verification API machinery.",
            "\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import base64",
            "import logging",
            "from datetime import datetime, timezone",
            "from typing import List, cast",
            "",
            "import rekor_types",
            "from cryptography.exceptions import InvalidSignature",
            "from cryptography.hazmat.primitives.asymmetric import ec",
            "from cryptography.x509 import ExtendedKeyUsage, KeyUsage",
            "from cryptography.x509.oid import ExtendedKeyUsageOID",
            "from OpenSSL.crypto import (",
            "    X509,",
            "    X509Store,",
            "    X509StoreContext,",
            "    X509StoreContextError,",
            "    X509StoreFlags,",
            ")",
            "from pydantic import ValidationError",
            "from rfc3161_client import TimeStampResponse, VerifierBuilder",
            "from rfc3161_client import VerificationError as Rfc3161VerificationError",
            "",
            "from sigstore import dsse",
            "from sigstore._internal.rekor import _hashedrekord_from_parts",
            "from sigstore._internal.rekor.client import RekorClient",
            "from sigstore._internal.sct import (",
            "    _get_precertificate_signed_certificate_timestamps,",
            "    verify_sct,",
            ")",
            "from sigstore._internal.timestamp import TimestampSource, TimestampVerificationResult",
            "from sigstore._internal.trust import ClientTrustConfig, KeyringPurpose, TrustedRoot",
            "from sigstore._utils import base64_encode_pem_cert, sha256_digest",
            "from sigstore.errors import VerificationError",
            "from sigstore.hashes import Hashed",
            "from sigstore.models import Bundle",
            "from sigstore.verify.policy import VerificationPolicy",
            "",
            "_logger = logging.getLogger(__name__)",
            "",
            "# Limit the number of timestamps to prevent DoS",
            "# From https://github.com/sigstore/sigstore-go/blob/e92142f0734064ebf6001f188b7330a1212245fe/pkg/verify/tsa.go#L29",
            "MAX_ALLOWED_TIMESTAMP: int = 32",
            "",
            "# When verifying a timestamp, this threshold represents the minimum number of required",
            "# timestamps to consider a signature valid.",
            "VERIFY_TIMESTAMP_THRESHOLD: int = 1",
            "",
            "",
            "class Verifier:",
            "    \"\"\"",
            "    The primary API for verification operations.",
            "    \"\"\"",
            "",
            "    def __init__(self, *, rekor: RekorClient, trusted_root: TrustedRoot):",
            "        \"\"\"",
            "        Create a new `Verifier`.",
            "",
            "        `rekor` is a `RekorClient` capable of connecting to a Rekor instance",
            "        containing logs for the file(s) being verified.",
            "",
            "        `fulcio_certificate_chain` is a list of PEM-encoded X.509 certificates,",
            "        establishing the trust chain for the signing certificate and signature.",
            "        \"\"\"",
            "        self._rekor = rekor",
            "        self._fulcio_certificate_chain: List[X509] = [",
            "            X509.from_cryptography(parent_cert)",
            "            for parent_cert in trusted_root.get_fulcio_certs()",
            "        ]",
            "        self._trusted_root = trusted_root",
            "",
            "    @classmethod",
            "    def production(cls, *, offline: bool = False) -> Verifier:",
            "        \"\"\"",
            "        Return a `Verifier` instance configured against Sigstore's production-level services.",
            "        \"\"\"",
            "        return cls(",
            "            rekor=RekorClient.production(),",
            "            trusted_root=TrustedRoot.production(offline=offline),",
            "        )",
            "",
            "    @classmethod",
            "    def staging(cls, *, offline: bool = False) -> Verifier:",
            "        \"\"\"",
            "        Return a `Verifier` instance configured against Sigstore's staging-level services.",
            "        \"\"\"",
            "        return cls(",
            "            rekor=RekorClient.staging(),",
            "            trusted_root=TrustedRoot.staging(offline=offline),",
            "        )",
            "",
            "    @classmethod",
            "    def _from_trust_config(cls, trust_config: ClientTrustConfig) -> Verifier:",
            "        \"\"\"",
            "        Create a `Verifier` from the given `ClientTrustConfig`.",
            "",
            "        @api private",
            "        \"\"\"",
            "        return cls(",
            "            rekor=RekorClient(trust_config._inner.signing_config.tlog_urls[0]),",
            "            trusted_root=trust_config.trusted_root,",
            "        )",
            "",
            "    def _verify_signed_timestamp(",
            "        self, timestamp_response: TimeStampResponse, signature: bytes",
            "    ) -> TimestampVerificationResult | None:",
            "        \"\"\"",
            "        Verify a Signed Timestamp using the TSA provided by the Trusted Root.",
            "        \"\"\"",
            "        cert_authorities = self._trusted_root.get_timestamp_authorities()",
            "        for certificate_authority in cert_authorities:",
            "            certificates = certificate_authority.certificates(allow_expired=True)",
            "",
            "            builder = VerifierBuilder()",
            "            for certificate in certificates:",
            "                builder.add_root_certificate(certificate)",
            "",
            "            verifier = builder.build()",
            "            try:",
            "                verifier.verify(timestamp_response, signature)",
            "            except Rfc3161VerificationError as e:",
            "                _logger.debug(\"Unable to verify Timestamp with CA.\")",
            "                _logger.exception(e)",
            "                continue",
            "",
            "            if (",
            "                certificate_authority.validity_period_start",
            "                and certificate_authority.validity_period_end",
            "            ):",
            "                if (",
            "                    certificate_authority.validity_period_start",
            "                    <= timestamp_response.tst_info.gen_time",
            "                    < certificate_authority.validity_period_end",
            "                ):",
            "                    return TimestampVerificationResult(",
            "                        source=TimestampSource.TIMESTAMP_AUTHORITY,",
            "                        time=timestamp_response.tst_info.gen_time,",
            "                    )",
            "",
            "                _logger.debug(",
            "                    \"Unable to verify Timestamp because not in CA time range.\"",
            "                )",
            "            else:",
            "                _logger.debug(",
            "                    \"Unable to verify Timestamp because no validity provided.\"",
            "                )",
            "",
            "        return None",
            "",
            "    def _verify_timestamp_authority(",
            "        self, bundle: Bundle",
            "    ) -> List[TimestampVerificationResult]:",
            "        \"\"\"",
            "        Verify that the given bundle has been timestamped by a trusted timestamp authority",
            "        and that the timestamp is valid.",
            "",
            "        Returns the number of valid signed timestamp in the bundle.",
            "        \"\"\"",
            "        timestamp_responses = (",
            "            bundle.verification_material.timestamp_verification_data.rfc3161_timestamps",
            "        )",
            "        if len(timestamp_responses) > MAX_ALLOWED_TIMESTAMP:",
            "            msg = f\"too many signed timestamp: {len(timestamp_responses)} > {MAX_ALLOWED_TIMESTAMP}\"",
            "            raise VerificationError(msg)",
            "",
            "        if len(set(timestamp_responses)) != len(timestamp_responses):",
            "            msg = \"duplicate timestamp found\"",
            "            raise VerificationError(msg)",
            "",
            "        # The Signer sends a hash of the signature as the messageImprint in a TimeStampReq",
            "        # to the Timestamping Service",
            "        signature_hash = sha256_digest(bundle.signature).digest",
            "        verified_timestamps = []",
            "        for tsr in timestamp_responses:",
            "            if verified_timestamp := self._verify_signed_timestamp(tsr, signature_hash):",
            "                verified_timestamps.append(verified_timestamp)",
            "",
            "        return verified_timestamps",
            "",
            "    def _establish_time(self, bundle: Bundle) -> List[TimestampVerificationResult]:",
            "        \"\"\"",
            "        Establish the time for bundle verification.",
            "",
            "        This method uses timestamps from two possible sources:",
            "        1. RFC3161 signed timestamps from a Timestamping Authority (TSA)",
            "        2. Transparency Log timestamps",
            "        \"\"\"",
            "        verified_timestamps = []",
            "",
            "        # If a timestamp from the timestamping service is available, the Verifier MUST",
            "        # perform path validation using the timestamp from the Timestamping Service.",
            "        if bundle.verification_material.timestamp_verification_data.rfc3161_timestamps:",
            "            if not self._trusted_root.get_timestamp_authorities():",
            "                msg = (",
            "                    \"no Timestamp Authorities have been provided to validate this \"",
            "                    \"bundle but it contains a signed timestamp\"",
            "                )",
            "                raise VerificationError(msg)",
            "",
            "            timestamp_from_tsa = self._verify_timestamp_authority(bundle)",
            "            if len(timestamp_from_tsa) < VERIFY_TIMESTAMP_THRESHOLD:",
            "                msg = (",
            "                    f\"not enough timestamps validated to meet the validation \"",
            "                    f\"threshold ({len(timestamp_from_tsa)}/{VERIFY_TIMESTAMP_THRESHOLD})\"",
            "                )",
            "                raise VerificationError(msg)",
            "",
            "            verified_timestamps.extend(timestamp_from_tsa)",
            "",
            "        # If a timestamp from the Transparency Service is available, the Verifier MUST",
            "        # perform path validation using the timestamp from the Transparency Service.",
            "        # NOTE: We only include this timestamp if it's accompanied by an inclusion",
            "        # promise that cryptographically binds it. We verify the inclusion promise",
            "        # itself later, as part of log entry verification.",
            "        if (",
            "            timestamp := bundle.log_entry.integrated_time",
            "        ) and bundle.log_entry.inclusion_promise:",
            "            verified_timestamps.append(",
            "                TimestampVerificationResult(",
            "                    source=TimestampSource.TRANSPARENCY_SERVICE,",
            "                    time=datetime.fromtimestamp(timestamp, tz=timezone.utc),",
            "                )",
            "            )",
            "        return verified_timestamps",
            "",
            "    def _verify_chain_at_time(",
            "        self, certificate: X509, timestamp_result: TimestampVerificationResult",
            "    ) -> List[X509]:",
            "        \"\"\"",
            "        Verify the validity of the certificate chain at the given time.",
            "",
            "        Raises a VerificationError if the chain can't be built or be verified.",
            "        \"\"\"",
            "        # NOTE: The `X509Store` object cannot have its time reset once the `set_time`",
            "        # method been called on it. To get around this, we construct a new one in each",
            "        # call.",
            "        store = X509Store()",
            "        # NOTE: By explicitly setting the flags here, we ensure that OpenSSL's",
            "        # PARTIAL_CHAIN default does not change on us. Enabling PARTIAL_CHAIN",
            "        # would be strictly more conformant of OpenSSL, but we currently",
            "        # *want* the \"long\" chain behavior of performing path validation",
            "        # down to a self-signed root.",
            "        store.set_flags(X509StoreFlags.X509_STRICT)",
            "        for parent_cert_ossl in self._fulcio_certificate_chain:",
            "            store.add_cert(parent_cert_ossl)",
            "",
            "        store.set_time(timestamp_result.time)",
            "",
            "        store_ctx = X509StoreContext(store, certificate)",
            "",
            "        try:",
            "            # get_verified_chain returns the full chain including the end-entity certificate",
            "            # and chain should contain only CA certificates",
            "            return store_ctx.get_verified_chain()[1:]",
            "        except X509StoreContextError as e:",
            "            raise VerificationError(f\"failed to build chain: {e}\")",
            "",
            "    def _verify_common_signing_cert(",
            "        self, bundle: Bundle, policy: VerificationPolicy",
            "    ) -> None:",
            "        \"\"\"",
            "        Performs the signing certificate verification steps that are shared between",
            "        `verify_dsse` and `verify_artifact`.",
            "",
            "        Raises `VerificationError` on all failures.",
            "        \"\"\"",
            "",
            "        # In order to verify an artifact, we need to achieve the following:",
            "        #",
            "        # 0. Establish a time for the signature.",
            "        # 1. Verify that the signing certificate chains to the root of trust",
            "        #    and is valid at the time of signing.",
            "        # 2. Verify the signing certificate's SCT.",
            "        # 3. Verify that the signing certificate conforms to the Sigstore",
            "        #    X.509 profile as well as the passed-in `VerificationPolicy`.",
            "        # 4. Verify the inclusion proof and signed checkpoint for the log",
            "        #    entry.",
            "        # 5. Verify the inclusion promise for the log entry, if present.",
            "        # 6. Verify the timely insertion of the log entry against the validity",
            "        #    period for the signing certificate.",
            "        # 7. Verify the signature and input against the signing certificate's",
            "        #    public key.",
            "        # 8. Verify the transparency log entry's consistency against the other",
            "        #    materials, to prevent variants of CVE-2022-36056.",
            "        #",
            "        # This method performs steps (0) through (6) above. Its caller",
            "        # MUST perform steps (7) and (8) separately, since they vary based on",
            "        # the kind of verification being performed (i.e. hashedrekord, DSSE, etc.)",
            "",
            "        cert = bundle.signing_certificate",
            "",
            "        # NOTE: The `X509Store` object currently cannot have its time reset once the `set_time`",
            "        # method been called on it. To get around this, we construct a new one for every `verify`",
            "        # call.",
            "        store = X509Store()",
            "        # NOTE: By explicitly setting the flags here, we ensure that OpenSSL's",
            "        # PARTIAL_CHAIN default does not change on us. Enabling PARTIAL_CHAIN",
            "        # would be strictly more conformant of OpenSSL, but we currently",
            "        # *want* the \"long\" chain behavior of performing path validation",
            "        # down to a self-signed root.",
            "        store.set_flags(X509StoreFlags.X509_STRICT)",
            "        for parent_cert_ossl in self._fulcio_certificate_chain:",
            "            store.add_cert(parent_cert_ossl)",
            "",
            "        # (0): Establishing a Time for the Signature",
            "        # First, establish a time for the signature. This timestamp is required to",
            "        # validate the certificate chain, so this step comes first.",
            "        # While this step is optional and only performed if timestamp data has been",
            "        # provided within the bundle, providing a signed timestamp without a TSA to",
            "        # verify it result in a VerificationError.",
            "        verified_timestamps = self._establish_time(bundle)",
            "        if not verified_timestamps:",
            "            raise VerificationError(\"not enough sources of verified time\")",
            "",
            "        # (1): verify that the signing certificate is signed by the root",
            "        #      certificate and that the signing certificate was valid at the",
            "        #      time of signing.",
            "        cert_ossl = X509.from_cryptography(cert)",
            "        chain: list[X509] = []",
            "        for vts in verified_timestamps:",
            "            chain = self._verify_chain_at_time(cert_ossl, vts)",
            "",
            "        # (2): verify the signing certificate's SCT.",
            "        sct = _get_precertificate_signed_certificate_timestamps(cert)[0]",
            "        try:",
            "            verify_sct(",
            "                sct,",
            "                cert,",
            "                [parent_cert.to_cryptography() for parent_cert in chain],",
            "                self._trusted_root.ct_keyring(KeyringPurpose.VERIFY),",
            "            )",
            "        except VerificationError as e:",
            "            raise VerificationError(f\"failed to verify SCT on signing certificate: {e}\")",
            "",
            "        # (3): verify the signing certificate against the Sigstore",
            "        #      X.509 profile and verify against the given `VerificationPolicy`.",
            "        usage_ext = cert.extensions.get_extension_for_class(KeyUsage)",
            "        if not usage_ext.value.digital_signature:",
            "            raise VerificationError(\"Key usage is not of type `digital signature`\")",
            "",
            "        extended_usage_ext = cert.extensions.get_extension_for_class(ExtendedKeyUsage)",
            "        if ExtendedKeyUsageOID.CODE_SIGNING not in extended_usage_ext.value:",
            "            raise VerificationError(\"Extended usage does not contain `code signing`\")",
            "",
            "        policy.verify(cert)",
            "",
            "        _logger.debug(\"Successfully verified signing certificate validity...\")",
            "",
            "        # (4): verify the inclusion proof and signed checkpoint for the",
            "        #      log entry.",
            "        # (5): verify the inclusion promise for the log entry, if present.",
            "        entry = bundle.log_entry",
            "        try:",
            "            entry._verify(self._trusted_root.rekor_keyring(KeyringPurpose.VERIFY))",
            "        except VerificationError as exc:",
            "            raise VerificationError(f\"invalid log entry: {exc}\")",
            "",
            "        # (6): verify that log entry was integrated circa the signing certificate's",
            "        #      validity period.",
            "        integrated_time = datetime.fromtimestamp(entry.integrated_time, tz=timezone.utc)",
            "        if not (",
            "            bundle.signing_certificate.not_valid_before_utc",
            "            <= integrated_time",
            "            <= bundle.signing_certificate.not_valid_after_utc",
            "        ):",
            "            raise VerificationError(",
            "                \"invalid signing cert: expired at time of Rekor entry\"",
            "            )",
            "",
            "    def verify_dsse(",
            "        self, bundle: Bundle, policy: VerificationPolicy",
            "    ) -> tuple[str, bytes]:",
            "        \"\"\"",
            "        Verifies an bundle's DSSE envelope, returning the encapsulated payload",
            "        and its content type.",
            "",
            "        This method is only for DSSE-enveloped payloads. To verify",
            "        an arbitrary input against a bundle, use the `verify_artifact`",
            "        method.",
            "",
            "        `bundle` is the Sigstore `Bundle` to both verify and verify against.",
            "",
            "        `policy` is the `VerificationPolicy` to verify against.",
            "",
            "        Returns a tuple of `(type, payload)`, where `type` is the payload's",
            "        type as encoded in the DSSE envelope and `payload` is the raw `bytes`",
            "        of the payload. No validation of either `type` or `payload` is",
            "        performed; users of this API **must** assert that `type` is known",
            "        to them before proceeding to handle `payload` in an application-dependent",
            "        manner.",
            "        \"\"\"",
            "",
            "        # (1) through (6) are performed by `_verify_common_signing_cert`.",
            "        self._verify_common_signing_cert(bundle, policy)",
            "",
            "        # (7): verify the bundle's signature and DSSE envelope against the",
            "        #      signing certificate's public key.",
            "        envelope = bundle._dsse_envelope",
            "        if envelope is None:",
            "            raise VerificationError(",
            "                \"cannot perform DSSE verification on a bundle without a DSSE envelope\"",
            "            )",
            "",
            "        signing_key = bundle.signing_certificate.public_key()",
            "        signing_key = cast(ec.EllipticCurvePublicKey, signing_key)",
            "        dsse._verify(signing_key, envelope)",
            "",
            "        # (8): verify the consistency of the log entry's body against",
            "        #      the other bundle materials.",
            "        # NOTE: This is very slightly weaker than the consistency check",
            "        # for hashedrekord entries, due to how inclusion is recorded for DSSE:",
            "        # the included entry for DSSE includes an envelope hash that we",
            "        # *cannot* verify, since the envelope is uncanonicalized JSON.",
            "        # Instead, we manually pick apart the entry body below and verify",
            "        # the parts we can (namely the payload hash and signature list).",
            "        entry = bundle.log_entry",
            "        try:",
            "            entry_body = rekor_types.Dsse.model_validate_json(",
            "                base64.b64decode(entry.body)",
            "            )",
            "        except ValidationError as exc:",
            "            raise VerificationError(f\"invalid DSSE log entry: {exc}\")",
            "",
            "        payload_hash = sha256_digest(envelope._inner.payload).digest.hex()",
            "        if (",
            "            entry_body.spec.root.payload_hash.algorithm  # type: ignore[union-attr]",
            "            != rekor_types.dsse.Algorithm.SHA256",
            "        ):",
            "            raise VerificationError(\"expected SHA256 payload hash in DSSE log entry\")",
            "        if payload_hash != entry_body.spec.root.payload_hash.value:  # type: ignore[union-attr]",
            "            raise VerificationError(\"log entry payload hash does not match bundle\")",
            "",
            "        # NOTE: Like `dsse._verify`: multiple signatures would be frivolous here,",
            "        # but we handle them just in case the signer has somehow produced multiple",
            "        # signatures for their envelope with the same signing key.",
            "        signatures = [",
            "            rekor_types.dsse.Signature(",
            "                signature=base64.b64encode(signature.sig).decode(),",
            "                verifier=base64_encode_pem_cert(bundle.signing_certificate),",
            "            )",
            "            for signature in envelope._inner.signatures",
            "        ]",
            "        if signatures != entry_body.spec.root.signatures:",
            "            raise VerificationError(\"log entry signatures do not match bundle\")",
            "",
            "        return (envelope._inner.payload_type, envelope._inner.payload)",
            "",
            "    def verify_artifact(",
            "        self,",
            "        input_: bytes | Hashed,",
            "        bundle: Bundle,",
            "        policy: VerificationPolicy,",
            "    ) -> None:",
            "        \"\"\"",
            "        Public API for verifying.",
            "",
            "        `input_` is the input to verify, either as a buffer of contents or as",
            "        a prehashed `Hashed` object.",
            "",
            "        `bundle` is the Sigstore `Bundle` to verify against.",
            "",
            "        `policy` is the `VerificationPolicy` to verify against.",
            "",
            "        On failure, this method raises `VerificationError`.",
            "        \"\"\"",
            "",
            "        # (1) through (6) are performed by `_verify_common_signing_cert`.",
            "        self._verify_common_signing_cert(bundle, policy)",
            "",
            "        hashed_input = sha256_digest(input_)",
            "",
            "        # (7): verify that the signature was signed by the public key in the signing certificate.",
            "        try:",
            "            signing_key = bundle.signing_certificate.public_key()",
            "            signing_key = cast(ec.EllipticCurvePublicKey, signing_key)",
            "            signing_key.verify(",
            "                bundle._inner.message_signature.signature,",
            "                hashed_input.digest,",
            "                ec.ECDSA(hashed_input._as_prehashed()),",
            "            )",
            "        except InvalidSignature:",
            "            raise VerificationError(\"Signature is invalid for input\")",
            "",
            "        _logger.debug(\"Successfully verified signature...\")",
            "",
            "        # (8): verify the consistency of the log entry's body against",
            "        #      the other bundle materials (and input being verified).",
            "        entry = bundle.log_entry",
            "",
            "        expected_body = _hashedrekord_from_parts(",
            "            bundle.signing_certificate,",
            "            bundle._inner.message_signature.signature,",
            "            hashed_input,",
            "        )",
            "        actual_body = rekor_types.Hashedrekord.model_validate_json(",
            "            base64.b64decode(entry.body)",
            "        )",
            "        if expected_body != actual_body:",
            "            raise VerificationError(",
            "                \"transparency log entry is inconsistent with other materials\"",
            "            )"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "230": [
                "Verifier",
                "_establish_time"
            ]
        },
        "addLocation": []
    }
}