{
    "puncia/__main__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " import re"
            },
            "1": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " API_URLS = {"
            },
            "3": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"subdomain\": \"http://api.subdomain.center/?domain=\","
            },
            "4": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"exploit\": \"http://api.exploit.observer/?keyword=\","
            },
            "5": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"enrich\": \"http://api.exploit.observer/?enrich=True&keyword=\","
            },
            "6": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"auth_subdomain\": \"http://api.subdomain.center/beta/?auth={0}&domain=\","
            },
            "7": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"auth_exploit\": \"http://api.exploit.observer/beta/?auth={0}&keyword=\","
            },
            "8": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"auth_enrich\": \"http://api.exploit.observer/beta/?auth={0}&enrich=True&keyword=\","
            },
            "9": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"russia\": \"http://api.exploit.observer/russia/\","
            },
            "10": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"china\": \"http://api.exploit.observer/china/\","
            },
            "11": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"watchlist\": \"http://api.exploit.observer/watchlist/\","
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+    \"subdomain\": \"https://api.subdomain.center/?domain=\","
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 10,
                "PatchRowcode": "+    \"exploit\": \"https://api.exploit.observer/?keyword=\","
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 11,
                "PatchRowcode": "+    \"enrich\": \"https://api.exploit.observer/?enrich=True&keyword=\","
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+    \"auth_subdomain\": \"https://api.subdomain.center/beta/?auth={0}&domain=\","
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 13,
                "PatchRowcode": "+    \"auth_exploit\": \"https://api.exploit.observer/beta/?auth={0}&keyword=\","
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 14,
                "PatchRowcode": "+    \"auth_enrich\": \"https://api.exploit.observer/beta/?auth={0}&enrich=True&keyword=\","
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 15,
                "PatchRowcode": "+    \"russia\": \"https://api.exploit.observer/russia/\","
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+    \"china\": \"https://api.exploit.observer/china/\","
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 17,
                "PatchRowcode": "+    \"watchlist\": \"https://api.exploit.observer/watchlist/\","
            },
            "21": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " }"
            },
            "22": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " "
            },
            "24": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 137,
                "PatchRowcode": " def main():"
            },
            "25": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 138,
                "PatchRowcode": "     try:"
            },
            "26": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 139,
                "PatchRowcode": "         print(\"---------\")"
            },
            "27": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        print(\"Panthera(P.)uncia [v0.20]\")"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 140,
                "PatchRowcode": "+        print(\"Panthera(P.)uncia [v0.21]\")"
            },
            "29": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "         print(\"A.R.P. Syndicate [https://arpsyndicate.io]\")"
            },
            "30": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 142,
                "PatchRowcode": "         print(\"---------\")"
            },
            "31": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 143,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "import os",
            "import requests",
            "import sys",
            "import json",
            "import time",
            "import re",
            "",
            "API_URLS = {",
            "    \"subdomain\": \"http://api.subdomain.center/?domain=\",",
            "    \"exploit\": \"http://api.exploit.observer/?keyword=\",",
            "    \"enrich\": \"http://api.exploit.observer/?enrich=True&keyword=\",",
            "    \"auth_subdomain\": \"http://api.subdomain.center/beta/?auth={0}&domain=\",",
            "    \"auth_exploit\": \"http://api.exploit.observer/beta/?auth={0}&keyword=\",",
            "    \"auth_enrich\": \"http://api.exploit.observer/beta/?auth={0}&enrich=True&keyword=\",",
            "    \"russia\": \"http://api.exploit.observer/russia/\",",
            "    \"china\": \"http://api.exploit.observer/china/\",",
            "    \"watchlist\": \"http://api.exploit.observer/watchlist/\",",
            "}",
            "",
            "",
            "def store_key(key=\"\"):",
            "    home = os.path.expanduser(\"~\")",
            "    with open(home + \"/.puncia\", \"w\") as f:",
            "        f.write(key)",
            "",
            "",
            "def read_key():",
            "    try:",
            "        home = os.path.expanduser(\"~\")",
            "        with open(home + \"/.puncia\", \"r\") as f:",
            "            key = f.read()",
            "        return key",
            "    except:",
            "        pass",
            "    return \"\"",
            "",
            "",
            "def query_api(mode, query, output_file=None, cid=None, akey=\"\"):",
            "    if len(akey) > 0 and mode in [\"exploit\", \"subdomain\", \"enrich\"]:",
            "        url = API_URLS.get(\"auth_\" + mode).format(akey)",
            "    else:",
            "        time.sleep(60)",
            "        url = API_URLS.get(mode)",
            "    if \"^\" in query and \"exploit\" in mode:",
            "        if query == \"^RU_NON_CVE\":",
            "            url = API_URLS.get(\"russia\")",
            "            query = \"noncve\"",
            "            mode = \"spec_exploit\"",
            "            cid = \"Russian VIDs with no associated CVEs\"",
            "        if query == \"^CN_NON_CVE\":",
            "            url = API_URLS.get(\"china\")",
            "            query = \"noncve\"",
            "            mode = \"spec_exploit\"",
            "            cid = \"Chinese VIDs with no associated CVEs\"",
            "        if query == \"^WATCHLIST\":",
            "            url = API_URLS.get(\"watchlist\")",
            "            query = \"\"",
            "            mode = \"spec_exploit\"",
            "            cid = \"Daily Vulnerability & Exploit Watchlist\"",
            "    if not url:",
            "        sys.exit(\"Invalid Mode\")",
            "    response = requests.get(url + query).json()",
            "    if not response:",
            "        print(\"Null response from the API\")",
            "        return",
            "    result = json.dumps(response, indent=4, sort_keys=True)",
            "    print(result)",
            "    if mode in [\"spec_exploit\"]:",
            "        for reurl in response:",
            "            query_api(",
            "                \"exploit\",",
            "                reurl,",
            "                output_file,",
            "                cid,",
            "                akey,",
            "            )",
            "        return",
            "    if output_file:",
            "        existing_data = {}",
            "        if os.path.isfile(output_file):",
            "            with open(output_file, \"r\") as f:",
            "                existing_data = json.load(f)",
            "        if mode == \"subdomain\":",
            "            if len(existing_data) == 0:",
            "                existing_data = []",
            "            existing_data.extend(response)",
            "            existing_data = list(set(existing_data))",
            "        elif mode == \"enrich\":",
            "            existing_data = response",
            "        elif mode == \"exploit\":",
            "            if \"entries\" in existing_data and len(existing_data[\"entries\"]) > 0:",
            "                for lang in existing_data[\"entries\"]:",
            "                    response_entries = response.get(\"entries\", {}).get(lang, [])",
            "                    existing_data_entries = existing_data[\"entries\"].get(lang, [])",
            "                    existing_data[\"entries\"][lang] = list(",
            "                        set(existing_data_entries + response_entries)",
            "                    )",
            "                    existing_data[\"entries\"][lang].sort()",
            "            else:",
            "                existing_data = response",
            "            if \"clusters\" in existing_data:",
            "                existing_data_clusters = existing_data.get(\"clusters\", [])",
            "                existing_data_clusters.extend(response.get(\"clusters\", []))",
            "                existing_data[\"clusters\"] = list(set(existing_data_clusters))",
            "                existing_data[\"clusters\"].sort()",
            "            total_entries = 0",
            "            for lang in existing_data[\"entries\"]:",
            "                total_entries = len(existing_data[\"entries\"][lang]) + total_entries",
            "            if \"priority\" in existing_data:",
            "                existing_data[\"priority\"] = (",
            "                    response.get(\"priority\", 1) + existing_data[\"priority\"]",
            "                ) / 2",
            "            if len(existing_data[\"description\"]) > 0:",
            "                if \"description\" in response and len(response[\"description\"]) > 0:",
            "                    existing_data[\"description\"] = response[\"description\"]",
            "                existing_data[\"description\"] = re.sub(",
            "                    r\"\\b(\\d+)\\s+(?:entries in)\\b\",",
            "                    str(total_entries) + \" entries in\",",
            "                    existing_data[\"description\"],",
            "                )",
            "                existing_data[\"description\"] = re.sub(",
            "                    r\"\\b(\\d+)\\s+(?:file formats)\\b\",",
            "                    str(len(existing_data[\"entries\"])) + \" file formats\",",
            "                    existing_data[\"description\"],",
            "                )",
            "                if cid:",
            "                    existing_data[\"description\"] = re.sub(",
            "                        r\"(?<=related to\\s)[^.]+(?=\\.)\",",
            "                        cid,",
            "                        existing_data[\"description\"],",
            "                    )",
            "",
            "        with open(output_file, \"w\") as f:",
            "            json.dump(existing_data, f, indent=4, sort_keys=True)",
            "",
            "",
            "def main():",
            "    try:",
            "        print(\"---------\")",
            "        print(\"Panthera(P.)uncia [v0.20]\")",
            "        print(\"A.R.P. Syndicate [https://arpsyndicate.io]\")",
            "        print(\"---------\")",
            "",
            "        if len(sys.argv) < 3:",
            "            sys.exit(",
            "                \"usage: puncia <mode:subdomain/exploit/enrich/bulk/storekey> <query:domain/eoidentifier/jsonfile/apikey> [output_file/output_directory]\\nrefer: https://github.com/ARPSyndicate/puncia#usage\"",
            "            )",
            "",
            "        mode = sys.argv[1]",
            "        query = sys.argv[2]",
            "        output_file = sys.argv[3] if len(sys.argv) == 4 else None",
            "        akey = read_key()",
            "",
            "        if mode not in API_URLS and mode != \"bulk\" and mode != \"storekey\":",
            "            sys.exit(\"Invalid Mode\")",
            "",
            "        if mode == \"bulk\":",
            "            if not os.path.isfile(query):",
            "                sys.exit(\"jsonfile as query input required for bulk mode\")",
            "            if output_file:",
            "                os.makedirs(output_file + \"/subdomain/\", exist_ok=True)",
            "                os.makedirs(output_file + \"/exploit/\", exist_ok=True)",
            "                os.makedirs(output_file + \"/enrich/\", exist_ok=True)",
            "            else:",
            "                sys.exit(\"Bulk Mode requires an Output Directory\")",
            "            with open(query, \"r\") as f:",
            "                input_file = json.load(f)",
            "            if \"subdomain\" in input_file:",
            "                for bulk_query in input_file[\"subdomain\"]:",
            "                    try:",
            "                        query_api(",
            "                            \"subdomain\",",
            "                            bulk_query,",
            "                            output_file + \"/subdomain/\" + bulk_query + \".json\",",
            "                            akey=akey,",
            "                        )",
            "                    except Exception as ne:",
            "                        sys.exit(f\"Error: {str(ne)}\")",
            "                        continue",
            "            if \"exploit\" in input_file:",
            "                for bulk_query in input_file[\"exploit\"]:",
            "                    try:",
            "                        query_api(",
            "                            \"exploit\",",
            "                            bulk_query,",
            "                            output_file + \"/exploit/\" + bulk_query + \".json\",",
            "                            akey=akey,",
            "                        )",
            "                    except Exception as ne:",
            "                        sys.exit(f\"Error: {str(ne)}\")",
            "            if \"enrich\" in input_file:",
            "                for bulk_query in input_file[\"enrich\"]:",
            "                    try:",
            "                        query_api(",
            "                            \"enrich\",",
            "                            bulk_query,",
            "                            output_file + \"/enrich/\" + bulk_query + \".json\",",
            "                            akey=akey,",
            "                        )",
            "                    except Exception as ne:",
            "                        sys.exit(f\"Error: {str(ne)}\")",
            "",
            "        elif mode == \"storekey\":",
            "            store_key(query)",
            "            print(\"Successful!\")",
            "",
            "        else:",
            "            query_api(mode, query, output_file, akey=akey)",
            "    except Exception as e:",
            "        sys.exit(f\"Error: {str(e)}\")",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    main()"
        ],
        "afterPatchFile": [
            "import os",
            "import requests",
            "import sys",
            "import json",
            "import time",
            "import re",
            "",
            "API_URLS = {",
            "    \"subdomain\": \"https://api.subdomain.center/?domain=\",",
            "    \"exploit\": \"https://api.exploit.observer/?keyword=\",",
            "    \"enrich\": \"https://api.exploit.observer/?enrich=True&keyword=\",",
            "    \"auth_subdomain\": \"https://api.subdomain.center/beta/?auth={0}&domain=\",",
            "    \"auth_exploit\": \"https://api.exploit.observer/beta/?auth={0}&keyword=\",",
            "    \"auth_enrich\": \"https://api.exploit.observer/beta/?auth={0}&enrich=True&keyword=\",",
            "    \"russia\": \"https://api.exploit.observer/russia/\",",
            "    \"china\": \"https://api.exploit.observer/china/\",",
            "    \"watchlist\": \"https://api.exploit.observer/watchlist/\",",
            "}",
            "",
            "",
            "def store_key(key=\"\"):",
            "    home = os.path.expanduser(\"~\")",
            "    with open(home + \"/.puncia\", \"w\") as f:",
            "        f.write(key)",
            "",
            "",
            "def read_key():",
            "    try:",
            "        home = os.path.expanduser(\"~\")",
            "        with open(home + \"/.puncia\", \"r\") as f:",
            "            key = f.read()",
            "        return key",
            "    except:",
            "        pass",
            "    return \"\"",
            "",
            "",
            "def query_api(mode, query, output_file=None, cid=None, akey=\"\"):",
            "    if len(akey) > 0 and mode in [\"exploit\", \"subdomain\", \"enrich\"]:",
            "        url = API_URLS.get(\"auth_\" + mode).format(akey)",
            "    else:",
            "        time.sleep(60)",
            "        url = API_URLS.get(mode)",
            "    if \"^\" in query and \"exploit\" in mode:",
            "        if query == \"^RU_NON_CVE\":",
            "            url = API_URLS.get(\"russia\")",
            "            query = \"noncve\"",
            "            mode = \"spec_exploit\"",
            "            cid = \"Russian VIDs with no associated CVEs\"",
            "        if query == \"^CN_NON_CVE\":",
            "            url = API_URLS.get(\"china\")",
            "            query = \"noncve\"",
            "            mode = \"spec_exploit\"",
            "            cid = \"Chinese VIDs with no associated CVEs\"",
            "        if query == \"^WATCHLIST\":",
            "            url = API_URLS.get(\"watchlist\")",
            "            query = \"\"",
            "            mode = \"spec_exploit\"",
            "            cid = \"Daily Vulnerability & Exploit Watchlist\"",
            "    if not url:",
            "        sys.exit(\"Invalid Mode\")",
            "    response = requests.get(url + query).json()",
            "    if not response:",
            "        print(\"Null response from the API\")",
            "        return",
            "    result = json.dumps(response, indent=4, sort_keys=True)",
            "    print(result)",
            "    if mode in [\"spec_exploit\"]:",
            "        for reurl in response:",
            "            query_api(",
            "                \"exploit\",",
            "                reurl,",
            "                output_file,",
            "                cid,",
            "                akey,",
            "            )",
            "        return",
            "    if output_file:",
            "        existing_data = {}",
            "        if os.path.isfile(output_file):",
            "            with open(output_file, \"r\") as f:",
            "                existing_data = json.load(f)",
            "        if mode == \"subdomain\":",
            "            if len(existing_data) == 0:",
            "                existing_data = []",
            "            existing_data.extend(response)",
            "            existing_data = list(set(existing_data))",
            "        elif mode == \"enrich\":",
            "            existing_data = response",
            "        elif mode == \"exploit\":",
            "            if \"entries\" in existing_data and len(existing_data[\"entries\"]) > 0:",
            "                for lang in existing_data[\"entries\"]:",
            "                    response_entries = response.get(\"entries\", {}).get(lang, [])",
            "                    existing_data_entries = existing_data[\"entries\"].get(lang, [])",
            "                    existing_data[\"entries\"][lang] = list(",
            "                        set(existing_data_entries + response_entries)",
            "                    )",
            "                    existing_data[\"entries\"][lang].sort()",
            "            else:",
            "                existing_data = response",
            "            if \"clusters\" in existing_data:",
            "                existing_data_clusters = existing_data.get(\"clusters\", [])",
            "                existing_data_clusters.extend(response.get(\"clusters\", []))",
            "                existing_data[\"clusters\"] = list(set(existing_data_clusters))",
            "                existing_data[\"clusters\"].sort()",
            "            total_entries = 0",
            "            for lang in existing_data[\"entries\"]:",
            "                total_entries = len(existing_data[\"entries\"][lang]) + total_entries",
            "            if \"priority\" in existing_data:",
            "                existing_data[\"priority\"] = (",
            "                    response.get(\"priority\", 1) + existing_data[\"priority\"]",
            "                ) / 2",
            "            if len(existing_data[\"description\"]) > 0:",
            "                if \"description\" in response and len(response[\"description\"]) > 0:",
            "                    existing_data[\"description\"] = response[\"description\"]",
            "                existing_data[\"description\"] = re.sub(",
            "                    r\"\\b(\\d+)\\s+(?:entries in)\\b\",",
            "                    str(total_entries) + \" entries in\",",
            "                    existing_data[\"description\"],",
            "                )",
            "                existing_data[\"description\"] = re.sub(",
            "                    r\"\\b(\\d+)\\s+(?:file formats)\\b\",",
            "                    str(len(existing_data[\"entries\"])) + \" file formats\",",
            "                    existing_data[\"description\"],",
            "                )",
            "                if cid:",
            "                    existing_data[\"description\"] = re.sub(",
            "                        r\"(?<=related to\\s)[^.]+(?=\\.)\",",
            "                        cid,",
            "                        existing_data[\"description\"],",
            "                    )",
            "",
            "        with open(output_file, \"w\") as f:",
            "            json.dump(existing_data, f, indent=4, sort_keys=True)",
            "",
            "",
            "def main():",
            "    try:",
            "        print(\"---------\")",
            "        print(\"Panthera(P.)uncia [v0.21]\")",
            "        print(\"A.R.P. Syndicate [https://arpsyndicate.io]\")",
            "        print(\"---------\")",
            "",
            "        if len(sys.argv) < 3:",
            "            sys.exit(",
            "                \"usage: puncia <mode:subdomain/exploit/enrich/bulk/storekey> <query:domain/eoidentifier/jsonfile/apikey> [output_file/output_directory]\\nrefer: https://github.com/ARPSyndicate/puncia#usage\"",
            "            )",
            "",
            "        mode = sys.argv[1]",
            "        query = sys.argv[2]",
            "        output_file = sys.argv[3] if len(sys.argv) == 4 else None",
            "        akey = read_key()",
            "",
            "        if mode not in API_URLS and mode != \"bulk\" and mode != \"storekey\":",
            "            sys.exit(\"Invalid Mode\")",
            "",
            "        if mode == \"bulk\":",
            "            if not os.path.isfile(query):",
            "                sys.exit(\"jsonfile as query input required for bulk mode\")",
            "            if output_file:",
            "                os.makedirs(output_file + \"/subdomain/\", exist_ok=True)",
            "                os.makedirs(output_file + \"/exploit/\", exist_ok=True)",
            "                os.makedirs(output_file + \"/enrich/\", exist_ok=True)",
            "            else:",
            "                sys.exit(\"Bulk Mode requires an Output Directory\")",
            "            with open(query, \"r\") as f:",
            "                input_file = json.load(f)",
            "            if \"subdomain\" in input_file:",
            "                for bulk_query in input_file[\"subdomain\"]:",
            "                    try:",
            "                        query_api(",
            "                            \"subdomain\",",
            "                            bulk_query,",
            "                            output_file + \"/subdomain/\" + bulk_query + \".json\",",
            "                            akey=akey,",
            "                        )",
            "                    except Exception as ne:",
            "                        sys.exit(f\"Error: {str(ne)}\")",
            "                        continue",
            "            if \"exploit\" in input_file:",
            "                for bulk_query in input_file[\"exploit\"]:",
            "                    try:",
            "                        query_api(",
            "                            \"exploit\",",
            "                            bulk_query,",
            "                            output_file + \"/exploit/\" + bulk_query + \".json\",",
            "                            akey=akey,",
            "                        )",
            "                    except Exception as ne:",
            "                        sys.exit(f\"Error: {str(ne)}\")",
            "            if \"enrich\" in input_file:",
            "                for bulk_query in input_file[\"enrich\"]:",
            "                    try:",
            "                        query_api(",
            "                            \"enrich\",",
            "                            bulk_query,",
            "                            output_file + \"/enrich/\" + bulk_query + \".json\",",
            "                            akey=akey,",
            "                        )",
            "                    except Exception as ne:",
            "                        sys.exit(f\"Error: {str(ne)}\")",
            "",
            "        elif mode == \"storekey\":",
            "            store_key(query)",
            "            print(\"Successful!\")",
            "",
            "        else:",
            "            query_api(mode, query, output_file, akey=akey)",
            "    except Exception as e:",
            "        sys.exit(f\"Error: {str(e)}\")",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "9": [],
            "10": [],
            "11": [],
            "12": [],
            "13": [],
            "14": [],
            "15": [],
            "16": [],
            "17": [],
            "140": [
                "main"
            ]
        },
        "addLocation": []
    },
    "setup.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " setup("
            },
            "2": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": "     name=\"puncia\","
            },
            "3": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    version=\"0.20\","
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 5,
                "PatchRowcode": "+    version=\"0.21\","
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": "     author=\"A.R.P. Syndicate\","
            },
            "6": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": "     author_email=\"ayush@arpsyndicate.io\","
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": "     keywords=\"subdomains subdomain exploits exploit arpsyndicate panthera uncia puncia snow leopard\","
            }
        },
        "frontPatchFile": [
            "from setuptools import setup, find_packages",
            "",
            "setup(",
            "    name=\"puncia\",",
            "    version=\"0.20\",",
            "    author=\"A.R.P. Syndicate\",",
            "    author_email=\"ayush@arpsyndicate.io\",",
            "    keywords=\"subdomains subdomain exploits exploit arpsyndicate panthera uncia puncia snow leopard\",",
            "    url=\"https://github.com/ARPSyndicate/puncia\",",
            "    project_urls={",
            "        \"A.R.P. Syndicate\": \"https://www.arpsyndicate.io\",",
            "        \"Subdomain Center\": \"https://subdomain.center\",",
            "        \"Exploit Observer\": \"https://exploit.observer\",",
            "    },",
            "    license=\"MIT\",",
            "    long_description=open(\"README.md\").read(),",
            "    long_description_content_type=\"text/markdown\",",
            "    description=\"The Panthera(P.)uncia of Cybersecurity - Official CLI utility for Subdomain Center & Exploit Observer\",",
            "    packages=find_packages(),",
            "    install_requires=[",
            "        \"requests\",",
            "    ],",
            "    entry_points={\"console_scripts\": [\"puncia=puncia.__main__:main\"]},",
            ")"
        ],
        "afterPatchFile": [
            "from setuptools import setup, find_packages",
            "",
            "setup(",
            "    name=\"puncia\",",
            "    version=\"0.21\",",
            "    author=\"A.R.P. Syndicate\",",
            "    author_email=\"ayush@arpsyndicate.io\",",
            "    keywords=\"subdomains subdomain exploits exploit arpsyndicate panthera uncia puncia snow leopard\",",
            "    url=\"https://github.com/ARPSyndicate/puncia\",",
            "    project_urls={",
            "        \"A.R.P. Syndicate\": \"https://www.arpsyndicate.io\",",
            "        \"Subdomain Center\": \"https://subdomain.center\",",
            "        \"Exploit Observer\": \"https://exploit.observer\",",
            "    },",
            "    license=\"MIT\",",
            "    long_description=open(\"README.md\").read(),",
            "    long_description_content_type=\"text/markdown\",",
            "    description=\"The Panthera(P.)uncia of Cybersecurity - Official CLI utility for Subdomain Center & Exploit Observer\",",
            "    packages=find_packages(),",
            "    install_requires=[",
            "        \"requests\",",
            "    ],",
            "    entry_points={\"console_scripts\": [\"puncia=puncia.__main__:main\"]},",
            ")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "5": []
        },
        "addLocation": []
    }
}