{
    "mlflow/store/model_registry/file_store.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " from mlflow.utils.validation import ("
            },
            "1": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "     _validate_registered_model_tag,"
            },
            "2": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "     _validate_model_version_tag,"
            },
            "3": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    _validate_model_name,"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+    _validate_model_name as _original_validate_model_name,"
            },
            "5": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "     _validate_model_version,"
            },
            "6": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "     _validate_tag_name,"
            },
            "7": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": 43,
                "PatchRowcode": " )"
            },
            "8": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "     make_containing_dirs,"
            },
            "9": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "     list_all,"
            },
            "10": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "     local_file_uri_to_path,"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+    contains_path_separator,"
            },
            "12": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 60,
                "PatchRowcode": " )"
            },
            "13": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 61,
                "PatchRowcode": " from mlflow.utils.time_utils import get_current_time_millis"
            },
            "14": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 62,
                "PatchRowcode": " "
            },
            "15": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 68,
                "PatchRowcode": "     return get_env(_REGISTRY_DIR_ENV_VAR) or os.path.abspath(DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH)"
            },
            "16": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 69,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": 70,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+def _validate_model_name(name):"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+    _original_validate_model_name(name)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+    if contains_path_separator(name):"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+        raise MlflowException("
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+            f\"Invalid name: '{name}'. Registered model name cannot contain path separator\","
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+            INVALID_PARAMETER_VALUE,"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+        )"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+"
            },
            "27": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": 80,
                "PatchRowcode": " class FileStore(AbstractStore):"
            },
            "28": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": 81,
                "PatchRowcode": "     MODELS_FOLDER_NAME = \"models\""
            },
            "29": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": 82,
                "PatchRowcode": "     META_DATA_FILE_NAME = \"meta.yaml\""
            }
        },
        "frontPatchFile": [
            "import logging",
            "import os",
            "from os.path import join",
            "import shutil",
            "import sys",
            "import time",
            "",
            "from mlflow.entities.model_registry import (",
            "    RegisteredModel,",
            "    ModelVersion,",
            "    RegisteredModelTag,",
            "    ModelVersionTag,",
            ")",
            "from mlflow.entities.model_registry.model_version_stages import (",
            "    get_canonical_stage,",
            "    ALL_STAGES,",
            "    DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS,",
            "    STAGE_ARCHIVED,",
            "    STAGE_NONE,",
            "    STAGE_DELETED_INTERNAL,",
            ")",
            "from mlflow.exceptions import MlflowException",
            "from mlflow.protos.databricks_pb2 import (",
            "    INVALID_PARAMETER_VALUE,",
            "    RESOURCE_ALREADY_EXISTS,",
            "    RESOURCE_DOES_NOT_EXIST,",
            ")",
            "from mlflow.store.entities.paged_list import PagedList",
            "from mlflow.store.model_registry.abstract_store import AbstractStore",
            "from mlflow.store.model_registry import (",
            "    DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH,",
            "    SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD,",
            "    SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,",
            ")",
            "from mlflow.utils.search_utils import SearchUtils, SearchModelUtils, SearchModelVersionUtils",
            "from mlflow.utils.string_utils import is_string_type",
            "from mlflow.utils.validation import (",
            "    _validate_registered_model_tag,",
            "    _validate_model_version_tag,",
            "    _validate_model_name,",
            "    _validate_model_version,",
            "    _validate_tag_name,",
            ")",
            "from mlflow.utils.env import get_env",
            "from mlflow.utils.file_utils import (",
            "    is_directory,",
            "    list_subdirs,",
            "    mkdir,",
            "    exists,",
            "    write_yaml,",
            "    overwrite_yaml,",
            "    read_yaml,",
            "    find,",
            "    read_file,",
            "    write_to,",
            "    make_containing_dirs,",
            "    list_all,",
            "    local_file_uri_to_path,",
            ")",
            "from mlflow.utils.time_utils import get_current_time_millis",
            "",
            "",
            "_REGISTRY_DIR_ENV_VAR = \"MLFLOW_REGISTRY_DIR\"",
            "",
            "",
            "def _default_root_dir():",
            "    return get_env(_REGISTRY_DIR_ENV_VAR) or os.path.abspath(DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH)",
            "",
            "",
            "class FileStore(AbstractStore):",
            "    MODELS_FOLDER_NAME = \"models\"",
            "    META_DATA_FILE_NAME = \"meta.yaml\"",
            "    TAGS_FOLDER_NAME = \"tags\"",
            "    MODEL_VERSION_TAGS_FOLDER_NAME = \"tags\"",
            "    CREATE_MODEL_VERSION_RETRIES = 3",
            "",
            "    def __init__(self, root_directory=None):",
            "        \"\"\"",
            "        Create a new FileStore with the given root directory.",
            "        \"\"\"",
            "",
            "        super().__init__()",
            "        self.root_directory = local_file_uri_to_path(root_directory or _default_root_dir())",
            "        # Create models directory if needed",
            "        if not exists(self.models_directory):",
            "            mkdir(self.models_directory)",
            "",
            "    @property",
            "    def models_directory(self):",
            "        return os.path.join(self.root_directory, FileStore.MODELS_FOLDER_NAME)",
            "",
            "    def _check_root_dir(self):",
            "        \"\"\"",
            "        Run checks before running directory operations.",
            "        \"\"\"",
            "        if not exists(self.root_directory):",
            "            raise Exception(\"'%s' does not exist.\" % self.root_directory)",
            "        if not is_directory(self.root_directory):",
            "            raise Exception(\"'%s' is not a directory.\" % self.root_directory)",
            "",
            "    def _validate_registered_model_does_not_exist(self, name):",
            "        model_path = self._get_registered_model_path(name)",
            "        if exists(model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model (name={name}) already exists.\",",
            "                RESOURCE_ALREADY_EXISTS,",
            "            )",
            "",
            "    def _save_registered_model_as_meta_file(self, registered_model, meta_dir=None, overwrite=True):",
            "        registered_model_dict = dict(registered_model)",
            "        # tags are stored under TAGS_FOLDER_NAME so remove them in meta file.",
            "        del registered_model_dict[\"tags\"]",
            "        del registered_model_dict[\"latest_versions\"]",
            "        meta_dir = meta_dir or self._get_registered_model_path(registered_model.name)",
            "        if overwrite:",
            "            overwrite_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                registered_model_dict,",
            "            )",
            "        else:",
            "            write_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                registered_model_dict,",
            "            )",
            "",
            "    def _update_registered_model_last_updated_time(self, name, updated_time):",
            "        registered_model = self.get_registered_model(name)",
            "        registered_model.last_updated_timestamp = updated_time",
            "        self._save_registered_model_as_meta_file(registered_model)",
            "",
            "    def create_registered_model(self, name, tags=None, description=None):",
            "        \"\"\"",
            "        Create a new registered model in backend store.",
            "",
            "        :param name: Name of the new model. This is expected to be unique in the backend store.",
            "        :param tags: A list of :py:class:`mlflow.entities.model_registry.RegisteredModelTag`",
            "                     instances associated with this registered model.",
            "        :param description: Description of the model.",
            "        :return: A single object of :py:class:`mlflow.entities.model_registry.RegisteredModel`",
            "                 created in the backend.",
            "        \"\"\"",
            "",
            "        self._check_root_dir()",
            "        _validate_model_name(name)",
            "        self._validate_registered_model_does_not_exist(name)",
            "        for tag in tags or []:",
            "            _validate_registered_model_tag(tag.key, tag.value)",
            "        meta_dir = self._get_registered_model_path(name)",
            "        mkdir(meta_dir)",
            "        creation_time = get_current_time_millis()",
            "        latest_versions = []",
            "        registered_model = RegisteredModel(",
            "            name=name,",
            "            creation_timestamp=creation_time,",
            "            last_updated_timestamp=creation_time,",
            "            description=description,",
            "            latest_versions=latest_versions,",
            "            tags=tags,",
            "        )",
            "        self._save_registered_model_as_meta_file(",
            "            registered_model, meta_dir=meta_dir, overwrite=False",
            "        )",
            "        if tags is not None:",
            "            for tag in tags:",
            "                self.set_registered_model_tag(name, tag)",
            "        return registered_model",
            "",
            "    def _get_registered_model_path(self, name):",
            "        self._check_root_dir()",
            "        _validate_model_name(name)",
            "        return join(self.root_directory, FileStore.MODELS_FOLDER_NAME, name)",
            "",
            "    def _get_registered_model_from_path(self, model_path):",
            "        meta = FileStore._read_yaml(model_path, FileStore.META_DATA_FILE_NAME)",
            "        meta[\"tags\"] = self.get_all_registered_model_tags_from_path(model_path)",
            "        registered_model = RegisteredModel.from_dictionary(meta)",
            "        registered_model.latest_versions = self.get_latest_versions(os.path.basename(model_path))",
            "        return registered_model",
            "",
            "    def update_registered_model(self, name, description):",
            "        \"\"\"",
            "        Update description of the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param description: New description.",
            "        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.",
            "        \"\"\"",
            "        registered_model = self.get_registered_model(name)",
            "        updated_time = get_current_time_millis()",
            "        registered_model.description = description",
            "        registered_model.last_updated_timestamp = updated_time",
            "        self._save_registered_model_as_meta_file(registered_model)",
            "        return registered_model",
            "",
            "    def rename_registered_model(self, name, new_name):",
            "        \"\"\"",
            "        Rename the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param new_name: New proposed name.",
            "        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.",
            "        \"\"\"",
            "        model_path = self._get_registered_model_path(name)",
            "        if not exists(model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        registered_model = self._get_registered_model_from_path(model_path)",
            "",
            "        new_meta_dir = self._get_registered_model_path(new_name)",
            "        if not exists(new_meta_dir):",
            "            mkdir(new_meta_dir)",
            "            updated_time = get_current_time_millis()",
            "            registered_model.name = new_name",
            "            registered_model.last_updated_timestamp = updated_time",
            "            self._save_registered_model_as_meta_file(",
            "                registered_model, meta_dir=new_meta_dir, overwrite=False",
            "            )",
            "            model_versions = self._list_model_versions_under_path(model_path)",
            "            for mv in model_versions:",
            "                mv.name = new_name",
            "                mv.last_updated_timestamp = updated_time",
            "                new_model_version_dir = join(new_meta_dir, f\"version-{mv.version}\")",
            "                mkdir(new_model_version_dir)",
            "                self._save_model_version_as_meta_file(",
            "                    mv, meta_dir=new_model_version_dir, overwrite=False",
            "                )",
            "                if mv.tags is not None:",
            "                    for tag in mv.tags:",
            "                        self.set_model_version_tag(new_name, mv.version, tag)",
            "            shutil.rmtree(model_path)",
            "        else:",
            "            raise MlflowException(",
            "                f\"Registered Model (name={new_name}) already exists.\",",
            "                RESOURCE_ALREADY_EXISTS,",
            "            )",
            "",
            "        return registered_model",
            "",
            "    def delete_registered_model(self, name):",
            "        \"\"\"",
            "        Delete the registered model.",
            "        Backend raises exception if a registered model with given name does not exist.",
            "",
            "        :param name: Registered model name.",
            "        :return: None",
            "        \"\"\"",
            "        meta_dir = self._get_registered_model_path(name)",
            "        if not exists(meta_dir):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        shutil.rmtree(meta_dir)",
            "",
            "    def list_registered_models(self, max_results, page_token):",
            "        \"\"\"",
            "        List of all registered models.",
            "",
            "        :param max_results: Maximum number of registered models desired.",
            "        :param page_token: Token specifying the next page of results. It should be obtained from",
            "                            a ``list_registered_models`` call.",
            "        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects",
            "                that satisfy the search expressions. The pagination token for the next page can be",
            "                obtained via the ``token`` attribute of the object.",
            "        \"\"\"",
            "        return self.search_registered_models(max_results=max_results, page_token=page_token)",
            "",
            "    def _list_all_registered_models(self):",
            "        registered_model_paths = self._get_all_registered_model_paths()",
            "        registered_models = []",
            "        for path in registered_model_paths:",
            "            registered_models.append(self._get_registered_model_from_path(path))",
            "        return registered_models",
            "",
            "    def search_registered_models(",
            "        self, filter_string=None, max_results=None, order_by=None, page_token=None",
            "    ):",
            "        \"\"\"",
            "        Search for registered models in backend that satisfy the filter criteria.",
            "",
            "        :param filter_string: Filter query string, defaults to searching all registered models.",
            "        :param max_results: Maximum number of registered models desired.",
            "        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering",
            "                         matching search results.",
            "        :param page_token: Token specifying the next page of results. It should be obtained from",
            "                            a ``search_registered_models`` call.",
            "        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects",
            "                that satisfy the search expressions. The pagination token for the next page can be",
            "                obtained via the ``token`` attribute of the object.",
            "        \"\"\"",
            "        if not isinstance(max_results, int) or max_results < 1:",
            "            raise MlflowException(",
            "                \"Invalid value for max_results. It must be a positive integer,\"",
            "                f\" but got {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        if max_results > SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD:",
            "            raise MlflowException(",
            "                \"Invalid value for request parameter max_results. It must be at most \"",
            "                f\"{SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        registered_models = self._list_all_registered_models()",
            "        filtered_rms = SearchModelUtils.filter(registered_models, filter_string)",
            "        sorted_rms = SearchModelUtils.sort(filtered_rms, order_by)",
            "        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)",
            "        final_offset = start_offset + max_results",
            "",
            "        paginated_rms = sorted_rms[start_offset:final_offset]",
            "        next_page_token = None",
            "        if final_offset < len(sorted_rms):",
            "            next_page_token = SearchUtils.create_page_token(final_offset)",
            "        return PagedList(paginated_rms, next_page_token)",
            "",
            "    def get_registered_model(self, name):",
            "        \"\"\"",
            "        Get registered model instance by name.",
            "",
            "        :param name: Registered model name.",
            "        :return: A single :py:class:`mlflow.entities.model_registry.RegisteredModel` object.",
            "        \"\"\"",
            "        model_path = self._get_registered_model_path(name)",
            "        if not exists(model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return self._get_registered_model_from_path(model_path)",
            "",
            "    def get_latest_versions(self, name, stages=None):",
            "        \"\"\"",
            "        Latest version models for each requested stage. If no ``stages`` argument is provided,",
            "        returns the latest version for each stage.",
            "",
            "        :param name: Registered model name.",
            "        :param stages: List of desired stages. If input list is None, return latest versions for",
            "                       each stage.",
            "        :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.",
            "        \"\"\"",
            "        registered_model_path = self._get_registered_model_path(name)",
            "        if not exists(registered_model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        model_versions = self._list_model_versions_under_path(registered_model_path)",
            "        if stages is None or len(stages) == 0:",
            "            expected_stages = {get_canonical_stage(stage) for stage in ALL_STAGES}",
            "        else:",
            "            expected_stages = {get_canonical_stage(stage) for stage in stages}",
            "        latest_versions = {}",
            "        for mv in model_versions:",
            "            if mv.current_stage in expected_stages:",
            "                if (",
            "                    mv.current_stage not in latest_versions",
            "                    or latest_versions[mv.current_stage].version < mv.version",
            "                ):",
            "                    latest_versions[mv.current_stage] = mv",
            "",
            "        return [latest_versions[stage] for stage in expected_stages if stage in latest_versions]",
            "",
            "    def _get_registered_model_tag_path(self, name, tag_name):",
            "        _validate_model_name(name)",
            "        _validate_tag_name(tag_name)",
            "        registered_model_path = self._get_registered_model_path(name)",
            "        if not exists(registered_model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return os.path.join(registered_model_path, FileStore.TAGS_FOLDER_NAME, tag_name)",
            "",
            "    def _get_registered_model_tag_from_file(self, parent_path, tag_name):",
            "        _validate_tag_name(tag_name)",
            "        tag_data = read_file(parent_path, tag_name)",
            "        return RegisteredModelTag(tag_name, tag_data)",
            "",
            "    def _get_resource_files(self, root_dir, subfolder_name):",
            "        source_dirs = find(root_dir, subfolder_name, full_path=True)",
            "        if len(source_dirs) == 0:",
            "            return root_dir, []",
            "        file_names = []",
            "        for root, _, files in os.walk(source_dirs[0]):",
            "            for name in files:",
            "                abspath = join(root, name)",
            "                file_names.append(os.path.relpath(abspath, source_dirs[0]))",
            "        if sys.platform == \"win32\":",
            "            # Turn registered models / model versions relative path into metric name.",
            "            # Registered models and model versions can have '/' in the name.",
            "            # On windows, '/' is interpreted as a separator.",
            "            # When the model / model version is read back the path will use '\\' for separator.",
            "            # We need to translate the path into posix path.",
            "            from mlflow.utils.file_utils import relative_path_to_artifact_path",
            "",
            "            file_names = [relative_path_to_artifact_path(x) for x in file_names]",
            "        return source_dirs[0], file_names",
            "",
            "    def get_all_registered_model_tags_from_path(self, model_path):",
            "        parent_path, tag_files = self._get_resource_files(model_path, FileStore.TAGS_FOLDER_NAME)",
            "        tags = []",
            "        for tag_file in tag_files:",
            "            tags.append(self._get_registered_model_tag_from_file(parent_path, tag_file))",
            "        return tags",
            "",
            "    def _writeable_value(self, tag_value):",
            "        if tag_value is None:",
            "            return \"\"",
            "        elif is_string_type(tag_value):",
            "            return tag_value",
            "        else:",
            "            return \"%s\" % tag_value",
            "",
            "    def set_registered_model_tag(self, name, tag):",
            "        \"\"\"",
            "        Set a tag for the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param tag: :py:class:`mlflow.entities.model_registry.RegisteredModelTag` instance to log.",
            "        :return: None",
            "        \"\"\"",
            "        _validate_registered_model_tag(tag.key, tag.value)",
            "        tag_path = self._get_registered_model_tag_path(name, tag.key)",
            "        make_containing_dirs(tag_path)",
            "        write_to(tag_path, self._writeable_value(tag.value))",
            "        updated_time = get_current_time_millis()",
            "        self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    def delete_registered_model_tag(self, name, key):",
            "        \"\"\"",
            "        Delete a tag associated with the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param key: Registered model tag key.",
            "        :return: None",
            "        \"\"\"",
            "        tag_path = self._get_registered_model_tag_path(name, key)",
            "        if exists(tag_path):",
            "            os.remove(tag_path)",
            "            updated_time = get_current_time_millis()",
            "            self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    # CRUD API for ModelVersion objects",
            "",
            "    def _get_registered_model_version_tag_from_file(self, parent_path, tag_name):",
            "        _validate_tag_name(tag_name)",
            "        tag_data = read_file(parent_path, tag_name)",
            "        return ModelVersionTag(tag_name, tag_data)",
            "",
            "    def _get_model_version_tags_from_dir(self, directory):",
            "        parent_path, tag_files = self._get_resource_files(directory, FileStore.TAGS_FOLDER_NAME)",
            "        tags = []",
            "        for tag_file in tag_files:",
            "            tags.append(self._get_registered_model_version_tag_from_file(parent_path, tag_file))",
            "        return tags",
            "",
            "    def _get_model_version_dir(self, name, version):",
            "        registered_model_path = self._get_registered_model_path(name)",
            "        if not exists(registered_model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return join(registered_model_path, f\"version-{version}\")",
            "",
            "    def _get_model_version_from_dir(self, directory):",
            "        meta = FileStore._read_yaml(directory, FileStore.META_DATA_FILE_NAME)",
            "        meta[\"tags\"] = self._get_model_version_tags_from_dir(directory)",
            "        model_version = ModelVersion.from_dictionary(meta)",
            "        return model_version",
            "",
            "    def _save_model_version_as_meta_file(self, model_version, meta_dir=None, overwrite=True):",
            "        model_version_dict = dict(model_version)",
            "        del model_version_dict[\"tags\"]",
            "        meta_dir = meta_dir or self._get_model_version_dir(",
            "            model_version.name, model_version.version",
            "        )",
            "        if overwrite:",
            "            overwrite_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                model_version_dict,",
            "            )",
            "        else:",
            "            write_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                model_version_dict,",
            "            )",
            "",
            "    def create_model_version(",
            "        self, name, source, run_id=None, tags=None, run_link=None, description=None",
            "    ):",
            "        \"\"\"",
            "        Create a new model version from given source and run ID.",
            "",
            "        :param name: Registered model name.",
            "        :param source: Source path where the MLflow model is stored.",
            "        :param run_id: Run ID from MLflow tracking server that generated the model.",
            "        :param tags: A list of :py:class:`mlflow.entities.model_registry.ModelVersionTag`",
            "                     instances associated with this model version.",
            "        :param run_link: Link to the run from an MLflow tracking server that generated this model.",
            "        :param description: Description of the version.",
            "        :return: A single object of :py:class:`mlflow.entities.model_registry.ModelVersion`",
            "                 created in the backend.",
            "        \"\"\"",
            "",
            "        def next_version(registered_model_name):",
            "            path = self._get_registered_model_path(registered_model_name)",
            "            model_versions = self._list_model_versions_under_path(path)",
            "            if model_versions:",
            "                return max(mv.version for mv in model_versions) + 1",
            "            else:",
            "                return 1",
            "",
            "        _validate_model_name(name)",
            "        for tag in tags or []:",
            "            _validate_model_version_tag(tag.key, tag.value)",
            "        for attempt in range(self.CREATE_MODEL_VERSION_RETRIES):",
            "            try:",
            "                creation_time = get_current_time_millis()",
            "                registered_model = self.get_registered_model(name)",
            "                registered_model.last_updated_timestamp = creation_time",
            "                self._save_registered_model_as_meta_file(registered_model)",
            "                version = next_version(name)",
            "                model_version = ModelVersion(",
            "                    name=name,",
            "                    version=version,",
            "                    creation_timestamp=creation_time,",
            "                    last_updated_timestamp=creation_time,",
            "                    description=description,",
            "                    current_stage=STAGE_NONE,",
            "                    source=source,",
            "                    run_id=run_id,",
            "                    run_link=run_link,",
            "                    tags=tags,",
            "                )",
            "                model_version_dir = self._get_model_version_dir(name, version)",
            "                mkdir(model_version_dir)",
            "                self._save_model_version_as_meta_file(",
            "                    model_version, meta_dir=model_version_dir, overwrite=False",
            "                )",
            "                self._save_registered_model_as_meta_file(registered_model)",
            "                if tags is not None:",
            "                    for tag in tags:",
            "                        self.set_model_version_tag(name, version, tag)",
            "                return model_version",
            "            except Exception as e:",
            "                more_retries = self.CREATE_MODEL_VERSION_RETRIES - attempt - 1",
            "                logging.warning(",
            "                    \"Model Version creation error (name=%s) Retrying %s more time%s.\",",
            "                    name,",
            "                    str(more_retries),",
            "                    \"s\" if more_retries > 1 else \"\",",
            "                )",
            "                if more_retries == 0:",
            "                    raise MlflowException(",
            "                        \"Model Version creation error (name={}). Error: {}. Giving up after \"",
            "                        \"{} attempts.\".format(name, e, self.CREATE_MODEL_VERSION_RETRIES)",
            "                    )",
            "",
            "    def update_model_version(self, name, version, description):",
            "        \"\"\"",
            "        Update metadata associated with a model version in backend.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param description: New model description.",
            "        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.",
            "        \"\"\"",
            "        updated_time = get_current_time_millis()",
            "        model_version = self.get_model_version(name=name, version=version)",
            "        model_version.description = description",
            "        model_version.last_updated_timestamp = updated_time",
            "        self._save_model_version_as_meta_file(model_version)",
            "        return model_version",
            "",
            "    def transition_model_version_stage(self, name, version, stage, archive_existing_versions):",
            "        \"\"\"",
            "        Update model version stage.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param stage: New desired stage for this model version.",
            "        :param archive_existing_versions: If this flag is set to ``True``, all existing model",
            "            versions in the stage will be automatically moved to the \"archived\" stage. Only valid",
            "            when ``stage`` is ``\"staging\"`` or ``\"production\"`` otherwise an error will be raised.",
            "",
            "        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.",
            "        \"\"\"",
            "        is_active_stage = get_canonical_stage(stage) in DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS",
            "        if archive_existing_versions and not is_active_stage:",
            "            msg_tpl = (",
            "                \"Model version transition cannot archive existing model versions \"",
            "                \"because '{}' is not an Active stage. Valid stages are {}\"",
            "            )",
            "            raise MlflowException(msg_tpl.format(stage, DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS))",
            "",
            "        last_updated_time = get_current_time_millis()",
            "        model_versions = []",
            "        if archive_existing_versions:",
            "            registered_model_path = self._get_registered_model_path(name)",
            "            model_versions = self._list_model_versions_under_path(registered_model_path)",
            "            for mv in model_versions:",
            "                if mv.version != version and mv.current_stage == get_canonical_stage(stage):",
            "                    mv.current_stage = STAGE_ARCHIVED",
            "                    mv.last_updated_timestamp = last_updated_time",
            "                    self._save_model_version_as_meta_file(mv)",
            "",
            "        model_version = self.get_model_version(name, version)",
            "        model_version.current_stage = get_canonical_stage(stage)",
            "        model_version.last_updated_timestamp = last_updated_time",
            "        self._save_model_version_as_meta_file(model_version)",
            "        self._update_registered_model_last_updated_time(name, last_updated_time)",
            "        return model_version",
            "",
            "    def delete_model_version(self, name, version):",
            "        \"\"\"",
            "        Delete model version in backend.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :return: None",
            "        \"\"\"",
            "        model_version = self.get_model_version(name=name, version=version)",
            "        model_version.current_stage = STAGE_DELETED_INTERNAL",
            "        updated_time = get_current_time_millis()",
            "        model_version.last_updated_timestamp = updated_time",
            "        self._save_model_version_as_meta_file(model_version)",
            "        self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    def get_model_version(self, name, version):",
            "        \"\"\"",
            "        Get the model version instance by name and version.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.",
            "        \"\"\"",
            "        _validate_model_name(name)",
            "        _validate_model_version(version)",
            "        registered_model_version_dir = self._get_model_version_dir(name, version)",
            "        if not exists(registered_model_version_dir):",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        model_version = self._get_model_version_from_dir(registered_model_version_dir)",
            "        if model_version.current_stage == STAGE_DELETED_INTERNAL:",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return model_version",
            "",
            "    def get_model_version_download_uri(self, name, version):",
            "        \"\"\"",
            "        Get the download location in Model Registry for this model version.",
            "        NOTE: For first version of Model Registry, since the models are not copied over to another",
            "              location, download URI points to input source path.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :return: A single URI location that allows reads for downloading.",
            "        \"\"\"",
            "        model_version = self.get_model_version(name, version)",
            "        return model_version.source",
            "",
            "    def _get_all_registered_model_paths(self):",
            "        self._check_root_dir()",
            "        model_dirs = list_subdirs(",
            "            join(self.root_directory, FileStore.MODELS_FOLDER_NAME), full_path=True",
            "        )",
            "        return model_dirs",
            "",
            "    def _list_model_versions_under_path(self, path):",
            "        model_versions = []",
            "        model_version_dirs = list_all(",
            "            path,",
            "            filter_func=lambda x: os.path.isdir(x)",
            "            and os.path.basename(os.path.normpath(x)).startswith(\"version-\"),",
            "            full_path=True,",
            "        )",
            "        for directory in model_version_dirs:",
            "            model_versions.append(self._get_model_version_from_dir(directory))",
            "        return model_versions",
            "",
            "    def search_model_versions(",
            "        self, filter_string=None, max_results=None, order_by=None, page_token=None",
            "    ):",
            "        \"\"\"",
            "        Search for model versions in backend that satisfy the filter criteria.",
            "",
            "        :param filter_string: A filter string expression. Currently supports a single filter",
            "                              condition either name of model like ``name = 'model_name'`` or",
            "                              ``run_id = '...'``.",
            "        :param max_results: Maximum number of model versions desired.",
            "        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering",
            "                         matching search results.",
            "        :param page_token: Token specifying the next page of results. It should be obtained from",
            "                            a ``search_model_versions`` call.",
            "        :return: A PagedList of :py:class:`mlflow.entities.model_registry.ModelVersion`",
            "                 objects that satisfy the search expressions. The pagination token for the next",
            "                 page can be obtained via the ``token`` attribute of the object.",
            "        \"\"\"",
            "        if not isinstance(max_results, int) or max_results < 1:",
            "            raise MlflowException(",
            "                \"Invalid value for max_results. It must be a positive integer,\"",
            "                f\" but got {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        if max_results > SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD:",
            "            raise MlflowException(",
            "                \"Invalid value for request parameter max_results. It must be at most \"",
            "                f\"{SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        registered_model_paths = self._get_all_registered_model_paths()",
            "        model_versions = []",
            "        for path in registered_model_paths:",
            "            model_versions.extend(self._list_model_versions_under_path(path))",
            "        filtered_mvs = SearchModelVersionUtils.filter(model_versions, filter_string)",
            "",
            "        sorted_mvs = SearchModelVersionUtils.sort(",
            "            filtered_mvs,",
            "            order_by or [\"last_updated_timestamp DESC\", \"name ASC\", \"version_number DESC\"],",
            "        )",
            "        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)",
            "        final_offset = start_offset + max_results",
            "",
            "        paginated_mvs = sorted_mvs[start_offset:final_offset]",
            "        next_page_token = None",
            "        if final_offset < len(sorted_mvs):",
            "            next_page_token = SearchUtils.create_page_token(final_offset)",
            "        return PagedList(paginated_mvs, next_page_token)",
            "",
            "    def _get_registered_model_version_tag_path(self, name, version, tag_name):",
            "        _validate_model_name(name)",
            "        _validate_model_version(version)",
            "        _validate_tag_name(tag_name)",
            "        registered_model_version_path = self._get_model_version_dir(name, version)",
            "        if not exists(registered_model_version_path):",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        model_version = self._get_model_version_from_dir(registered_model_version_path)",
            "        if model_version.current_stage == STAGE_DELETED_INTERNAL:",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return os.path.join(registered_model_version_path, FileStore.TAGS_FOLDER_NAME, tag_name)",
            "",
            "    def set_model_version_tag(self, name, version, tag):",
            "        \"\"\"",
            "        Set a tag for the model version.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param tag: :py:class:`mlflow.entities.model_registry.ModelVersionTag` instance to log.",
            "        :return: None",
            "        \"\"\"",
            "        _validate_model_version_tag(tag.key, tag.value)",
            "        tag_path = self._get_registered_model_version_tag_path(name, version, tag.key)",
            "        make_containing_dirs(tag_path)",
            "        write_to(tag_path, self._writeable_value(tag.value))",
            "        updated_time = get_current_time_millis()",
            "        self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    def delete_model_version_tag(self, name, version, key):",
            "        \"\"\"",
            "        Delete a tag associated with the model version.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param key: Tag key.",
            "        :return: None",
            "        \"\"\"",
            "        tag_path = self._get_registered_model_version_tag_path(name, version, key)",
            "        if exists(tag_path):",
            "            os.remove(tag_path)",
            "            updated_time = get_current_time_millis()",
            "            self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    @staticmethod",
            "    def _read_yaml(root, file_name, retries=2):",
            "        \"\"\"",
            "        Read data from yaml file and return as dictionary, retrying up to",
            "        a specified number of times if the file contents are unexpectedly",
            "        empty due to a concurrent write.",
            "",
            "        :param root: Directory name.",
            "        :param file_name: File name. Expects to have '.yaml' extension.",
            "        :param retries: The number of times to retry for unexpected empty content.",
            "        :return: Data in yaml file as dictionary",
            "        \"\"\"",
            "",
            "        def _read_helper(root, file_name, attempts_remaining=2):",
            "            result = read_yaml(root, file_name)",
            "            if result is not None or attempts_remaining == 0:",
            "                return result",
            "            else:",
            "                time.sleep(0.1 * (3 - attempts_remaining))",
            "                return _read_helper(root, file_name, attempts_remaining - 1)",
            "",
            "        return _read_helper(root, file_name, attempts_remaining=retries)"
        ],
        "afterPatchFile": [
            "import logging",
            "import os",
            "from os.path import join",
            "import shutil",
            "import sys",
            "import time",
            "",
            "from mlflow.entities.model_registry import (",
            "    RegisteredModel,",
            "    ModelVersion,",
            "    RegisteredModelTag,",
            "    ModelVersionTag,",
            ")",
            "from mlflow.entities.model_registry.model_version_stages import (",
            "    get_canonical_stage,",
            "    ALL_STAGES,",
            "    DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS,",
            "    STAGE_ARCHIVED,",
            "    STAGE_NONE,",
            "    STAGE_DELETED_INTERNAL,",
            ")",
            "from mlflow.exceptions import MlflowException",
            "from mlflow.protos.databricks_pb2 import (",
            "    INVALID_PARAMETER_VALUE,",
            "    RESOURCE_ALREADY_EXISTS,",
            "    RESOURCE_DOES_NOT_EXIST,",
            ")",
            "from mlflow.store.entities.paged_list import PagedList",
            "from mlflow.store.model_registry.abstract_store import AbstractStore",
            "from mlflow.store.model_registry import (",
            "    DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH,",
            "    SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD,",
            "    SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,",
            ")",
            "from mlflow.utils.search_utils import SearchUtils, SearchModelUtils, SearchModelVersionUtils",
            "from mlflow.utils.string_utils import is_string_type",
            "from mlflow.utils.validation import (",
            "    _validate_registered_model_tag,",
            "    _validate_model_version_tag,",
            "    _validate_model_name as _original_validate_model_name,",
            "    _validate_model_version,",
            "    _validate_tag_name,",
            ")",
            "from mlflow.utils.env import get_env",
            "from mlflow.utils.file_utils import (",
            "    is_directory,",
            "    list_subdirs,",
            "    mkdir,",
            "    exists,",
            "    write_yaml,",
            "    overwrite_yaml,",
            "    read_yaml,",
            "    find,",
            "    read_file,",
            "    write_to,",
            "    make_containing_dirs,",
            "    list_all,",
            "    local_file_uri_to_path,",
            "    contains_path_separator,",
            ")",
            "from mlflow.utils.time_utils import get_current_time_millis",
            "",
            "",
            "_REGISTRY_DIR_ENV_VAR = \"MLFLOW_REGISTRY_DIR\"",
            "",
            "",
            "def _default_root_dir():",
            "    return get_env(_REGISTRY_DIR_ENV_VAR) or os.path.abspath(DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH)",
            "",
            "",
            "def _validate_model_name(name):",
            "    _original_validate_model_name(name)",
            "    if contains_path_separator(name):",
            "        raise MlflowException(",
            "            f\"Invalid name: '{name}'. Registered model name cannot contain path separator\",",
            "            INVALID_PARAMETER_VALUE,",
            "        )",
            "",
            "",
            "class FileStore(AbstractStore):",
            "    MODELS_FOLDER_NAME = \"models\"",
            "    META_DATA_FILE_NAME = \"meta.yaml\"",
            "    TAGS_FOLDER_NAME = \"tags\"",
            "    MODEL_VERSION_TAGS_FOLDER_NAME = \"tags\"",
            "    CREATE_MODEL_VERSION_RETRIES = 3",
            "",
            "    def __init__(self, root_directory=None):",
            "        \"\"\"",
            "        Create a new FileStore with the given root directory.",
            "        \"\"\"",
            "",
            "        super().__init__()",
            "        self.root_directory = local_file_uri_to_path(root_directory or _default_root_dir())",
            "        # Create models directory if needed",
            "        if not exists(self.models_directory):",
            "            mkdir(self.models_directory)",
            "",
            "    @property",
            "    def models_directory(self):",
            "        return os.path.join(self.root_directory, FileStore.MODELS_FOLDER_NAME)",
            "",
            "    def _check_root_dir(self):",
            "        \"\"\"",
            "        Run checks before running directory operations.",
            "        \"\"\"",
            "        if not exists(self.root_directory):",
            "            raise Exception(\"'%s' does not exist.\" % self.root_directory)",
            "        if not is_directory(self.root_directory):",
            "            raise Exception(\"'%s' is not a directory.\" % self.root_directory)",
            "",
            "    def _validate_registered_model_does_not_exist(self, name):",
            "        model_path = self._get_registered_model_path(name)",
            "        if exists(model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model (name={name}) already exists.\",",
            "                RESOURCE_ALREADY_EXISTS,",
            "            )",
            "",
            "    def _save_registered_model_as_meta_file(self, registered_model, meta_dir=None, overwrite=True):",
            "        registered_model_dict = dict(registered_model)",
            "        # tags are stored under TAGS_FOLDER_NAME so remove them in meta file.",
            "        del registered_model_dict[\"tags\"]",
            "        del registered_model_dict[\"latest_versions\"]",
            "        meta_dir = meta_dir or self._get_registered_model_path(registered_model.name)",
            "        if overwrite:",
            "            overwrite_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                registered_model_dict,",
            "            )",
            "        else:",
            "            write_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                registered_model_dict,",
            "            )",
            "",
            "    def _update_registered_model_last_updated_time(self, name, updated_time):",
            "        registered_model = self.get_registered_model(name)",
            "        registered_model.last_updated_timestamp = updated_time",
            "        self._save_registered_model_as_meta_file(registered_model)",
            "",
            "    def create_registered_model(self, name, tags=None, description=None):",
            "        \"\"\"",
            "        Create a new registered model in backend store.",
            "",
            "        :param name: Name of the new model. This is expected to be unique in the backend store.",
            "        :param tags: A list of :py:class:`mlflow.entities.model_registry.RegisteredModelTag`",
            "                     instances associated with this registered model.",
            "        :param description: Description of the model.",
            "        :return: A single object of :py:class:`mlflow.entities.model_registry.RegisteredModel`",
            "                 created in the backend.",
            "        \"\"\"",
            "",
            "        self._check_root_dir()",
            "        _validate_model_name(name)",
            "        self._validate_registered_model_does_not_exist(name)",
            "        for tag in tags or []:",
            "            _validate_registered_model_tag(tag.key, tag.value)",
            "        meta_dir = self._get_registered_model_path(name)",
            "        mkdir(meta_dir)",
            "        creation_time = get_current_time_millis()",
            "        latest_versions = []",
            "        registered_model = RegisteredModel(",
            "            name=name,",
            "            creation_timestamp=creation_time,",
            "            last_updated_timestamp=creation_time,",
            "            description=description,",
            "            latest_versions=latest_versions,",
            "            tags=tags,",
            "        )",
            "        self._save_registered_model_as_meta_file(",
            "            registered_model, meta_dir=meta_dir, overwrite=False",
            "        )",
            "        if tags is not None:",
            "            for tag in tags:",
            "                self.set_registered_model_tag(name, tag)",
            "        return registered_model",
            "",
            "    def _get_registered_model_path(self, name):",
            "        self._check_root_dir()",
            "        _validate_model_name(name)",
            "        return join(self.root_directory, FileStore.MODELS_FOLDER_NAME, name)",
            "",
            "    def _get_registered_model_from_path(self, model_path):",
            "        meta = FileStore._read_yaml(model_path, FileStore.META_DATA_FILE_NAME)",
            "        meta[\"tags\"] = self.get_all_registered_model_tags_from_path(model_path)",
            "        registered_model = RegisteredModel.from_dictionary(meta)",
            "        registered_model.latest_versions = self.get_latest_versions(os.path.basename(model_path))",
            "        return registered_model",
            "",
            "    def update_registered_model(self, name, description):",
            "        \"\"\"",
            "        Update description of the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param description: New description.",
            "        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.",
            "        \"\"\"",
            "        registered_model = self.get_registered_model(name)",
            "        updated_time = get_current_time_millis()",
            "        registered_model.description = description",
            "        registered_model.last_updated_timestamp = updated_time",
            "        self._save_registered_model_as_meta_file(registered_model)",
            "        return registered_model",
            "",
            "    def rename_registered_model(self, name, new_name):",
            "        \"\"\"",
            "        Rename the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param new_name: New proposed name.",
            "        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.",
            "        \"\"\"",
            "        model_path = self._get_registered_model_path(name)",
            "        if not exists(model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        registered_model = self._get_registered_model_from_path(model_path)",
            "",
            "        new_meta_dir = self._get_registered_model_path(new_name)",
            "        if not exists(new_meta_dir):",
            "            mkdir(new_meta_dir)",
            "            updated_time = get_current_time_millis()",
            "            registered_model.name = new_name",
            "            registered_model.last_updated_timestamp = updated_time",
            "            self._save_registered_model_as_meta_file(",
            "                registered_model, meta_dir=new_meta_dir, overwrite=False",
            "            )",
            "            model_versions = self._list_model_versions_under_path(model_path)",
            "            for mv in model_versions:",
            "                mv.name = new_name",
            "                mv.last_updated_timestamp = updated_time",
            "                new_model_version_dir = join(new_meta_dir, f\"version-{mv.version}\")",
            "                mkdir(new_model_version_dir)",
            "                self._save_model_version_as_meta_file(",
            "                    mv, meta_dir=new_model_version_dir, overwrite=False",
            "                )",
            "                if mv.tags is not None:",
            "                    for tag in mv.tags:",
            "                        self.set_model_version_tag(new_name, mv.version, tag)",
            "            shutil.rmtree(model_path)",
            "        else:",
            "            raise MlflowException(",
            "                f\"Registered Model (name={new_name}) already exists.\",",
            "                RESOURCE_ALREADY_EXISTS,",
            "            )",
            "",
            "        return registered_model",
            "",
            "    def delete_registered_model(self, name):",
            "        \"\"\"",
            "        Delete the registered model.",
            "        Backend raises exception if a registered model with given name does not exist.",
            "",
            "        :param name: Registered model name.",
            "        :return: None",
            "        \"\"\"",
            "        meta_dir = self._get_registered_model_path(name)",
            "        if not exists(meta_dir):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        shutil.rmtree(meta_dir)",
            "",
            "    def list_registered_models(self, max_results, page_token):",
            "        \"\"\"",
            "        List of all registered models.",
            "",
            "        :param max_results: Maximum number of registered models desired.",
            "        :param page_token: Token specifying the next page of results. It should be obtained from",
            "                            a ``list_registered_models`` call.",
            "        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects",
            "                that satisfy the search expressions. The pagination token for the next page can be",
            "                obtained via the ``token`` attribute of the object.",
            "        \"\"\"",
            "        return self.search_registered_models(max_results=max_results, page_token=page_token)",
            "",
            "    def _list_all_registered_models(self):",
            "        registered_model_paths = self._get_all_registered_model_paths()",
            "        registered_models = []",
            "        for path in registered_model_paths:",
            "            registered_models.append(self._get_registered_model_from_path(path))",
            "        return registered_models",
            "",
            "    def search_registered_models(",
            "        self, filter_string=None, max_results=None, order_by=None, page_token=None",
            "    ):",
            "        \"\"\"",
            "        Search for registered models in backend that satisfy the filter criteria.",
            "",
            "        :param filter_string: Filter query string, defaults to searching all registered models.",
            "        :param max_results: Maximum number of registered models desired.",
            "        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering",
            "                         matching search results.",
            "        :param page_token: Token specifying the next page of results. It should be obtained from",
            "                            a ``search_registered_models`` call.",
            "        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects",
            "                that satisfy the search expressions. The pagination token for the next page can be",
            "                obtained via the ``token`` attribute of the object.",
            "        \"\"\"",
            "        if not isinstance(max_results, int) or max_results < 1:",
            "            raise MlflowException(",
            "                \"Invalid value for max_results. It must be a positive integer,\"",
            "                f\" but got {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        if max_results > SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD:",
            "            raise MlflowException(",
            "                \"Invalid value for request parameter max_results. It must be at most \"",
            "                f\"{SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        registered_models = self._list_all_registered_models()",
            "        filtered_rms = SearchModelUtils.filter(registered_models, filter_string)",
            "        sorted_rms = SearchModelUtils.sort(filtered_rms, order_by)",
            "        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)",
            "        final_offset = start_offset + max_results",
            "",
            "        paginated_rms = sorted_rms[start_offset:final_offset]",
            "        next_page_token = None",
            "        if final_offset < len(sorted_rms):",
            "            next_page_token = SearchUtils.create_page_token(final_offset)",
            "        return PagedList(paginated_rms, next_page_token)",
            "",
            "    def get_registered_model(self, name):",
            "        \"\"\"",
            "        Get registered model instance by name.",
            "",
            "        :param name: Registered model name.",
            "        :return: A single :py:class:`mlflow.entities.model_registry.RegisteredModel` object.",
            "        \"\"\"",
            "        model_path = self._get_registered_model_path(name)",
            "        if not exists(model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return self._get_registered_model_from_path(model_path)",
            "",
            "    def get_latest_versions(self, name, stages=None):",
            "        \"\"\"",
            "        Latest version models for each requested stage. If no ``stages`` argument is provided,",
            "        returns the latest version for each stage.",
            "",
            "        :param name: Registered model name.",
            "        :param stages: List of desired stages. If input list is None, return latest versions for",
            "                       each stage.",
            "        :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.",
            "        \"\"\"",
            "        registered_model_path = self._get_registered_model_path(name)",
            "        if not exists(registered_model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        model_versions = self._list_model_versions_under_path(registered_model_path)",
            "        if stages is None or len(stages) == 0:",
            "            expected_stages = {get_canonical_stage(stage) for stage in ALL_STAGES}",
            "        else:",
            "            expected_stages = {get_canonical_stage(stage) for stage in stages}",
            "        latest_versions = {}",
            "        for mv in model_versions:",
            "            if mv.current_stage in expected_stages:",
            "                if (",
            "                    mv.current_stage not in latest_versions",
            "                    or latest_versions[mv.current_stage].version < mv.version",
            "                ):",
            "                    latest_versions[mv.current_stage] = mv",
            "",
            "        return [latest_versions[stage] for stage in expected_stages if stage in latest_versions]",
            "",
            "    def _get_registered_model_tag_path(self, name, tag_name):",
            "        _validate_model_name(name)",
            "        _validate_tag_name(tag_name)",
            "        registered_model_path = self._get_registered_model_path(name)",
            "        if not exists(registered_model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return os.path.join(registered_model_path, FileStore.TAGS_FOLDER_NAME, tag_name)",
            "",
            "    def _get_registered_model_tag_from_file(self, parent_path, tag_name):",
            "        _validate_tag_name(tag_name)",
            "        tag_data = read_file(parent_path, tag_name)",
            "        return RegisteredModelTag(tag_name, tag_data)",
            "",
            "    def _get_resource_files(self, root_dir, subfolder_name):",
            "        source_dirs = find(root_dir, subfolder_name, full_path=True)",
            "        if len(source_dirs) == 0:",
            "            return root_dir, []",
            "        file_names = []",
            "        for root, _, files in os.walk(source_dirs[0]):",
            "            for name in files:",
            "                abspath = join(root, name)",
            "                file_names.append(os.path.relpath(abspath, source_dirs[0]))",
            "        if sys.platform == \"win32\":",
            "            # Turn registered models / model versions relative path into metric name.",
            "            # Registered models and model versions can have '/' in the name.",
            "            # On windows, '/' is interpreted as a separator.",
            "            # When the model / model version is read back the path will use '\\' for separator.",
            "            # We need to translate the path into posix path.",
            "            from mlflow.utils.file_utils import relative_path_to_artifact_path",
            "",
            "            file_names = [relative_path_to_artifact_path(x) for x in file_names]",
            "        return source_dirs[0], file_names",
            "",
            "    def get_all_registered_model_tags_from_path(self, model_path):",
            "        parent_path, tag_files = self._get_resource_files(model_path, FileStore.TAGS_FOLDER_NAME)",
            "        tags = []",
            "        for tag_file in tag_files:",
            "            tags.append(self._get_registered_model_tag_from_file(parent_path, tag_file))",
            "        return tags",
            "",
            "    def _writeable_value(self, tag_value):",
            "        if tag_value is None:",
            "            return \"\"",
            "        elif is_string_type(tag_value):",
            "            return tag_value",
            "        else:",
            "            return \"%s\" % tag_value",
            "",
            "    def set_registered_model_tag(self, name, tag):",
            "        \"\"\"",
            "        Set a tag for the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param tag: :py:class:`mlflow.entities.model_registry.RegisteredModelTag` instance to log.",
            "        :return: None",
            "        \"\"\"",
            "        _validate_registered_model_tag(tag.key, tag.value)",
            "        tag_path = self._get_registered_model_tag_path(name, tag.key)",
            "        make_containing_dirs(tag_path)",
            "        write_to(tag_path, self._writeable_value(tag.value))",
            "        updated_time = get_current_time_millis()",
            "        self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    def delete_registered_model_tag(self, name, key):",
            "        \"\"\"",
            "        Delete a tag associated with the registered model.",
            "",
            "        :param name: Registered model name.",
            "        :param key: Registered model tag key.",
            "        :return: None",
            "        \"\"\"",
            "        tag_path = self._get_registered_model_tag_path(name, key)",
            "        if exists(tag_path):",
            "            os.remove(tag_path)",
            "            updated_time = get_current_time_millis()",
            "            self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    # CRUD API for ModelVersion objects",
            "",
            "    def _get_registered_model_version_tag_from_file(self, parent_path, tag_name):",
            "        _validate_tag_name(tag_name)",
            "        tag_data = read_file(parent_path, tag_name)",
            "        return ModelVersionTag(tag_name, tag_data)",
            "",
            "    def _get_model_version_tags_from_dir(self, directory):",
            "        parent_path, tag_files = self._get_resource_files(directory, FileStore.TAGS_FOLDER_NAME)",
            "        tags = []",
            "        for tag_file in tag_files:",
            "            tags.append(self._get_registered_model_version_tag_from_file(parent_path, tag_file))",
            "        return tags",
            "",
            "    def _get_model_version_dir(self, name, version):",
            "        registered_model_path = self._get_registered_model_path(name)",
            "        if not exists(registered_model_path):",
            "            raise MlflowException(",
            "                f\"Registered Model with name={name} not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return join(registered_model_path, f\"version-{version}\")",
            "",
            "    def _get_model_version_from_dir(self, directory):",
            "        meta = FileStore._read_yaml(directory, FileStore.META_DATA_FILE_NAME)",
            "        meta[\"tags\"] = self._get_model_version_tags_from_dir(directory)",
            "        model_version = ModelVersion.from_dictionary(meta)",
            "        return model_version",
            "",
            "    def _save_model_version_as_meta_file(self, model_version, meta_dir=None, overwrite=True):",
            "        model_version_dict = dict(model_version)",
            "        del model_version_dict[\"tags\"]",
            "        meta_dir = meta_dir or self._get_model_version_dir(",
            "            model_version.name, model_version.version",
            "        )",
            "        if overwrite:",
            "            overwrite_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                model_version_dict,",
            "            )",
            "        else:",
            "            write_yaml(",
            "                meta_dir,",
            "                FileStore.META_DATA_FILE_NAME,",
            "                model_version_dict,",
            "            )",
            "",
            "    def create_model_version(",
            "        self, name, source, run_id=None, tags=None, run_link=None, description=None",
            "    ):",
            "        \"\"\"",
            "        Create a new model version from given source and run ID.",
            "",
            "        :param name: Registered model name.",
            "        :param source: Source path where the MLflow model is stored.",
            "        :param run_id: Run ID from MLflow tracking server that generated the model.",
            "        :param tags: A list of :py:class:`mlflow.entities.model_registry.ModelVersionTag`",
            "                     instances associated with this model version.",
            "        :param run_link: Link to the run from an MLflow tracking server that generated this model.",
            "        :param description: Description of the version.",
            "        :return: A single object of :py:class:`mlflow.entities.model_registry.ModelVersion`",
            "                 created in the backend.",
            "        \"\"\"",
            "",
            "        def next_version(registered_model_name):",
            "            path = self._get_registered_model_path(registered_model_name)",
            "            model_versions = self._list_model_versions_under_path(path)",
            "            if model_versions:",
            "                return max(mv.version for mv in model_versions) + 1",
            "            else:",
            "                return 1",
            "",
            "        _validate_model_name(name)",
            "        for tag in tags or []:",
            "            _validate_model_version_tag(tag.key, tag.value)",
            "        for attempt in range(self.CREATE_MODEL_VERSION_RETRIES):",
            "            try:",
            "                creation_time = get_current_time_millis()",
            "                registered_model = self.get_registered_model(name)",
            "                registered_model.last_updated_timestamp = creation_time",
            "                self._save_registered_model_as_meta_file(registered_model)",
            "                version = next_version(name)",
            "                model_version = ModelVersion(",
            "                    name=name,",
            "                    version=version,",
            "                    creation_timestamp=creation_time,",
            "                    last_updated_timestamp=creation_time,",
            "                    description=description,",
            "                    current_stage=STAGE_NONE,",
            "                    source=source,",
            "                    run_id=run_id,",
            "                    run_link=run_link,",
            "                    tags=tags,",
            "                )",
            "                model_version_dir = self._get_model_version_dir(name, version)",
            "                mkdir(model_version_dir)",
            "                self._save_model_version_as_meta_file(",
            "                    model_version, meta_dir=model_version_dir, overwrite=False",
            "                )",
            "                self._save_registered_model_as_meta_file(registered_model)",
            "                if tags is not None:",
            "                    for tag in tags:",
            "                        self.set_model_version_tag(name, version, tag)",
            "                return model_version",
            "            except Exception as e:",
            "                more_retries = self.CREATE_MODEL_VERSION_RETRIES - attempt - 1",
            "                logging.warning(",
            "                    \"Model Version creation error (name=%s) Retrying %s more time%s.\",",
            "                    name,",
            "                    str(more_retries),",
            "                    \"s\" if more_retries > 1 else \"\",",
            "                )",
            "                if more_retries == 0:",
            "                    raise MlflowException(",
            "                        \"Model Version creation error (name={}). Error: {}. Giving up after \"",
            "                        \"{} attempts.\".format(name, e, self.CREATE_MODEL_VERSION_RETRIES)",
            "                    )",
            "",
            "    def update_model_version(self, name, version, description):",
            "        \"\"\"",
            "        Update metadata associated with a model version in backend.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param description: New model description.",
            "        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.",
            "        \"\"\"",
            "        updated_time = get_current_time_millis()",
            "        model_version = self.get_model_version(name=name, version=version)",
            "        model_version.description = description",
            "        model_version.last_updated_timestamp = updated_time",
            "        self._save_model_version_as_meta_file(model_version)",
            "        return model_version",
            "",
            "    def transition_model_version_stage(self, name, version, stage, archive_existing_versions):",
            "        \"\"\"",
            "        Update model version stage.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param stage: New desired stage for this model version.",
            "        :param archive_existing_versions: If this flag is set to ``True``, all existing model",
            "            versions in the stage will be automatically moved to the \"archived\" stage. Only valid",
            "            when ``stage`` is ``\"staging\"`` or ``\"production\"`` otherwise an error will be raised.",
            "",
            "        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.",
            "        \"\"\"",
            "        is_active_stage = get_canonical_stage(stage) in DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS",
            "        if archive_existing_versions and not is_active_stage:",
            "            msg_tpl = (",
            "                \"Model version transition cannot archive existing model versions \"",
            "                \"because '{}' is not an Active stage. Valid stages are {}\"",
            "            )",
            "            raise MlflowException(msg_tpl.format(stage, DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS))",
            "",
            "        last_updated_time = get_current_time_millis()",
            "        model_versions = []",
            "        if archive_existing_versions:",
            "            registered_model_path = self._get_registered_model_path(name)",
            "            model_versions = self._list_model_versions_under_path(registered_model_path)",
            "            for mv in model_versions:",
            "                if mv.version != version and mv.current_stage == get_canonical_stage(stage):",
            "                    mv.current_stage = STAGE_ARCHIVED",
            "                    mv.last_updated_timestamp = last_updated_time",
            "                    self._save_model_version_as_meta_file(mv)",
            "",
            "        model_version = self.get_model_version(name, version)",
            "        model_version.current_stage = get_canonical_stage(stage)",
            "        model_version.last_updated_timestamp = last_updated_time",
            "        self._save_model_version_as_meta_file(model_version)",
            "        self._update_registered_model_last_updated_time(name, last_updated_time)",
            "        return model_version",
            "",
            "    def delete_model_version(self, name, version):",
            "        \"\"\"",
            "        Delete model version in backend.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :return: None",
            "        \"\"\"",
            "        model_version = self.get_model_version(name=name, version=version)",
            "        model_version.current_stage = STAGE_DELETED_INTERNAL",
            "        updated_time = get_current_time_millis()",
            "        model_version.last_updated_timestamp = updated_time",
            "        self._save_model_version_as_meta_file(model_version)",
            "        self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    def get_model_version(self, name, version):",
            "        \"\"\"",
            "        Get the model version instance by name and version.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.",
            "        \"\"\"",
            "        _validate_model_name(name)",
            "        _validate_model_version(version)",
            "        registered_model_version_dir = self._get_model_version_dir(name, version)",
            "        if not exists(registered_model_version_dir):",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        model_version = self._get_model_version_from_dir(registered_model_version_dir)",
            "        if model_version.current_stage == STAGE_DELETED_INTERNAL:",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return model_version",
            "",
            "    def get_model_version_download_uri(self, name, version):",
            "        \"\"\"",
            "        Get the download location in Model Registry for this model version.",
            "        NOTE: For first version of Model Registry, since the models are not copied over to another",
            "              location, download URI points to input source path.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :return: A single URI location that allows reads for downloading.",
            "        \"\"\"",
            "        model_version = self.get_model_version(name, version)",
            "        return model_version.source",
            "",
            "    def _get_all_registered_model_paths(self):",
            "        self._check_root_dir()",
            "        model_dirs = list_subdirs(",
            "            join(self.root_directory, FileStore.MODELS_FOLDER_NAME), full_path=True",
            "        )",
            "        return model_dirs",
            "",
            "    def _list_model_versions_under_path(self, path):",
            "        model_versions = []",
            "        model_version_dirs = list_all(",
            "            path,",
            "            filter_func=lambda x: os.path.isdir(x)",
            "            and os.path.basename(os.path.normpath(x)).startswith(\"version-\"),",
            "            full_path=True,",
            "        )",
            "        for directory in model_version_dirs:",
            "            model_versions.append(self._get_model_version_from_dir(directory))",
            "        return model_versions",
            "",
            "    def search_model_versions(",
            "        self, filter_string=None, max_results=None, order_by=None, page_token=None",
            "    ):",
            "        \"\"\"",
            "        Search for model versions in backend that satisfy the filter criteria.",
            "",
            "        :param filter_string: A filter string expression. Currently supports a single filter",
            "                              condition either name of model like ``name = 'model_name'`` or",
            "                              ``run_id = '...'``.",
            "        :param max_results: Maximum number of model versions desired.",
            "        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering",
            "                         matching search results.",
            "        :param page_token: Token specifying the next page of results. It should be obtained from",
            "                            a ``search_model_versions`` call.",
            "        :return: A PagedList of :py:class:`mlflow.entities.model_registry.ModelVersion`",
            "                 objects that satisfy the search expressions. The pagination token for the next",
            "                 page can be obtained via the ``token`` attribute of the object.",
            "        \"\"\"",
            "        if not isinstance(max_results, int) or max_results < 1:",
            "            raise MlflowException(",
            "                \"Invalid value for max_results. It must be a positive integer,\"",
            "                f\" but got {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        if max_results > SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD:",
            "            raise MlflowException(",
            "                \"Invalid value for request parameter max_results. It must be at most \"",
            "                f\"{SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",",
            "                INVALID_PARAMETER_VALUE,",
            "            )",
            "",
            "        registered_model_paths = self._get_all_registered_model_paths()",
            "        model_versions = []",
            "        for path in registered_model_paths:",
            "            model_versions.extend(self._list_model_versions_under_path(path))",
            "        filtered_mvs = SearchModelVersionUtils.filter(model_versions, filter_string)",
            "",
            "        sorted_mvs = SearchModelVersionUtils.sort(",
            "            filtered_mvs,",
            "            order_by or [\"last_updated_timestamp DESC\", \"name ASC\", \"version_number DESC\"],",
            "        )",
            "        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)",
            "        final_offset = start_offset + max_results",
            "",
            "        paginated_mvs = sorted_mvs[start_offset:final_offset]",
            "        next_page_token = None",
            "        if final_offset < len(sorted_mvs):",
            "            next_page_token = SearchUtils.create_page_token(final_offset)",
            "        return PagedList(paginated_mvs, next_page_token)",
            "",
            "    def _get_registered_model_version_tag_path(self, name, version, tag_name):",
            "        _validate_model_name(name)",
            "        _validate_model_version(version)",
            "        _validate_tag_name(tag_name)",
            "        registered_model_version_path = self._get_model_version_dir(name, version)",
            "        if not exists(registered_model_version_path):",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        model_version = self._get_model_version_from_dir(registered_model_version_path)",
            "        if model_version.current_stage == STAGE_DELETED_INTERNAL:",
            "            raise MlflowException(",
            "                f\"Model Version (name={name}, version={version}) not found\",",
            "                RESOURCE_DOES_NOT_EXIST,",
            "            )",
            "        return os.path.join(registered_model_version_path, FileStore.TAGS_FOLDER_NAME, tag_name)",
            "",
            "    def set_model_version_tag(self, name, version, tag):",
            "        \"\"\"",
            "        Set a tag for the model version.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param tag: :py:class:`mlflow.entities.model_registry.ModelVersionTag` instance to log.",
            "        :return: None",
            "        \"\"\"",
            "        _validate_model_version_tag(tag.key, tag.value)",
            "        tag_path = self._get_registered_model_version_tag_path(name, version, tag.key)",
            "        make_containing_dirs(tag_path)",
            "        write_to(tag_path, self._writeable_value(tag.value))",
            "        updated_time = get_current_time_millis()",
            "        self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    def delete_model_version_tag(self, name, version, key):",
            "        \"\"\"",
            "        Delete a tag associated with the model version.",
            "",
            "        :param name: Registered model name.",
            "        :param version: Registered model version.",
            "        :param key: Tag key.",
            "        :return: None",
            "        \"\"\"",
            "        tag_path = self._get_registered_model_version_tag_path(name, version, key)",
            "        if exists(tag_path):",
            "            os.remove(tag_path)",
            "            updated_time = get_current_time_millis()",
            "            self._update_registered_model_last_updated_time(name, updated_time)",
            "",
            "    @staticmethod",
            "    def _read_yaml(root, file_name, retries=2):",
            "        \"\"\"",
            "        Read data from yaml file and return as dictionary, retrying up to",
            "        a specified number of times if the file contents are unexpectedly",
            "        empty due to a concurrent write.",
            "",
            "        :param root: Directory name.",
            "        :param file_name: File name. Expects to have '.yaml' extension.",
            "        :param retries: The number of times to retry for unexpected empty content.",
            "        :return: Data in yaml file as dictionary",
            "        \"\"\"",
            "",
            "        def _read_helper(root, file_name, attempts_remaining=2):",
            "            result = read_yaml(root, file_name)",
            "            if result is not None or attempts_remaining == 0:",
            "                return result",
            "            else:",
            "                time.sleep(0.1 * (3 - attempts_remaining))",
            "                return _read_helper(root, file_name, attempts_remaining - 1)",
            "",
            "        return _read_helper(root, file_name, attempts_remaining=retries)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "40": []
        },
        "addLocation": []
    },
    "mlflow/utils/file_utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 711,
                "afterPatchRowNumber": 711,
                "PatchRowcode": "             relative_file_path = os.path.relpath(file_path, src_dir)"
            },
            "1": {
                "beforePatchRowNumber": 712,
                "afterPatchRowNumber": 712,
                "PatchRowcode": "             abs_file_path = os.path.join(dst_dir, relative_file_path)"
            },
            "2": {
                "beforePatchRowNumber": 713,
                "afterPatchRowNumber": 713,
                "PatchRowcode": "             shutil.copyfile(file_path, abs_file_path)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 714,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 715,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 716,
                "PatchRowcode": "+def contains_path_separator(path):"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 717,
                "PatchRowcode": "+    \"\"\""
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 718,
                "PatchRowcode": "+    Returns True if a path contains a path separator, False otherwise."
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 719,
                "PatchRowcode": "+    \"\"\""
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 720,
                "PatchRowcode": "+    return any((sep in path) for sep in (os.path.sep, os.path.altsep) if sep is not None)"
            }
        },
        "frontPatchFile": [
            "import codecs",
            "import errno",
            "import gzip",
            "import os",
            "import posixpath",
            "import shutil",
            "import sys",
            "import tarfile",
            "import tempfile",
            "import stat",
            "import pathlib",
            "",
            "import urllib.parse",
            "import urllib.request",
            "from urllib.parse import unquote",
            "from urllib.request import pathname2url",
            "",
            "import atexit",
            "",
            "import yaml",
            "",
            "try:",
            "    from yaml import CSafeLoader as YamlSafeLoader, CSafeDumper as YamlSafeDumper",
            "except ImportError:",
            "    from yaml import SafeLoader as YamlSafeLoader, SafeDumper as YamlSafeDumper",
            "",
            "from mlflow.entities import FileInfo",
            "from mlflow.exceptions import MissingConfigException",
            "from mlflow.utils.rest_utils import cloud_storage_http_request, augmented_raise_for_status",
            "from mlflow.utils.process import cache_return_value_per_process",
            "from mlflow.utils import merge_dicts",
            "from mlflow.utils.databricks_utils import _get_dbutils",
            "from mlflow.utils.os import is_windows",
            "",
            "ENCODING = \"utf-8\"",
            "",
            "",
            "def is_directory(name):",
            "    return os.path.isdir(name)",
            "",
            "",
            "def is_file(name):",
            "    return os.path.isfile(name)",
            "",
            "",
            "def exists(name):",
            "    return os.path.exists(name)",
            "",
            "",
            "def list_all(root, filter_func=lambda x: True, full_path=False):",
            "    \"\"\"",
            "    List all entities directly under 'dir_name' that satisfy 'filter_func'",
            "",
            "    :param root: Name of directory to start search",
            "    :param filter_func: function or lambda that takes path",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of all files or directories that satisfy the criteria.",
            "    \"\"\"",
            "    if not is_directory(root):",
            "        raise Exception(\"Invalid parent directory '%s'\" % root)",
            "    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]",
            "    return [os.path.join(root, m) for m in matches] if full_path else matches",
            "",
            "",
            "def list_subdirs(dir_name, full_path=False):",
            "    \"\"\"",
            "    Equivalent to UNIX command:",
            "      ``find $dir_name -depth 1 -type d``",
            "",
            "    :param dir_name: Name of directory to start search",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of all directories directly under 'dir_name'",
            "    \"\"\"",
            "    return list_all(dir_name, os.path.isdir, full_path)",
            "",
            "",
            "def list_files(dir_name, full_path=False):",
            "    \"\"\"",
            "    Equivalent to UNIX command:",
            "      ``find $dir_name -depth 1 -type f``",
            "",
            "    :param dir_name: Name of directory to start search",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of all files directly under 'dir_name'",
            "    \"\"\"",
            "    return list_all(dir_name, os.path.isfile, full_path)",
            "",
            "",
            "def find(root, name, full_path=False):",
            "    \"\"\"",
            "    Search for a file in a root directory. Equivalent to:",
            "      ``find $root -name \"$name\" -depth 1``",
            "",
            "    :param root: Name of root directory for find",
            "    :param name: Name of file or directory to find directly under root directory",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of matching files or directories",
            "    \"\"\"",
            "    path_name = os.path.join(root, name)",
            "    return list_all(root, lambda x: x == path_name, full_path)",
            "",
            "",
            "def mkdir(root, name=None):",
            "    \"\"\"",
            "    Make directory with name \"root/name\", or just \"root\" if name is None.",
            "",
            "    :param root: Name of parent directory",
            "    :param name: Optional name of leaf directory",
            "",
            "    :return: Path to created directory",
            "    \"\"\"",
            "    target = os.path.join(root, name) if name is not None else root",
            "    try:",
            "        os.makedirs(target)",
            "    except OSError as e:",
            "        if e.errno != errno.EEXIST or not os.path.isdir(target):",
            "            raise e",
            "    return target",
            "",
            "",
            "def make_containing_dirs(path):",
            "    \"\"\"",
            "    Create the base directory for a given file path if it does not exist; also creates parent",
            "    directories.",
            "    \"\"\"",
            "    dir_name = os.path.dirname(path)",
            "    if not os.path.exists(dir_name):",
            "        os.makedirs(dir_name)",
            "",
            "",
            "def write_yaml(root, file_name, data, overwrite=False, sort_keys=True):",
            "    \"\"\"",
            "    Write dictionary data in yaml format.",
            "",
            "    :param root: Directory name.",
            "    :param file_name: Desired file name. Will automatically add .yaml extension if not given",
            "    :param data: data to be dumped as yaml format",
            "    :param overwrite: If True, will overwrite existing files",
            "    \"\"\"",
            "    if not exists(root):",
            "        raise MissingConfigException(\"Parent directory '%s' does not exist.\" % root)",
            "",
            "    file_path = os.path.join(root, file_name)",
            "    yaml_file_name = file_path if file_path.endswith(\".yaml\") else file_path + \".yaml\"",
            "",
            "    if exists(yaml_file_name) and not overwrite:",
            "        raise Exception(f\"Yaml file '{file_path}' exists as '{yaml_file_name}\")",
            "",
            "    try:",
            "        with codecs.open(yaml_file_name, mode=\"w\", encoding=ENCODING) as yaml_file:",
            "            yaml.dump(",
            "                data,",
            "                yaml_file,",
            "                default_flow_style=False,",
            "                allow_unicode=True,",
            "                sort_keys=sort_keys,",
            "                Dumper=YamlSafeDumper,",
            "            )",
            "    except Exception as e:",
            "        raise e",
            "",
            "",
            "def overwrite_yaml(root, file_name, data):",
            "    \"\"\"",
            "    Safely overwrites a preexisting yaml file, ensuring that file contents are not deleted or",
            "    corrupted if the write fails. This is achieved by writing contents to a temporary file",
            "    and moving the temporary file to replace the preexisting file, rather than opening the",
            "    preexisting file for a direct write.",
            "",
            "    :param root: Directory name.",
            "    :param file_name: File name. Expects to have '.yaml' extension.",
            "    :param data: The data to write, represented as a dictionary.",
            "    \"\"\"",
            "    tmp_file_path = None",
            "    try:",
            "        tmp_file_fd, tmp_file_path = tempfile.mkstemp(suffix=\"file.yaml\")",
            "        os.close(tmp_file_fd)",
            "        write_yaml(",
            "            root=get_parent_dir(tmp_file_path),",
            "            file_name=os.path.basename(tmp_file_path),",
            "            data=data,",
            "            overwrite=True,",
            "            sort_keys=True,",
            "        )",
            "        shutil.move(",
            "            tmp_file_path,",
            "            os.path.join(root, file_name),",
            "        )",
            "    finally:",
            "        if tmp_file_path is not None and os.path.exists(tmp_file_path):",
            "            os.remove(tmp_file_path)",
            "",
            "",
            "def read_yaml(root, file_name):",
            "    \"\"\"",
            "    Read data from yaml file and return as dictionary",
            "",
            "    :param root: Directory name",
            "    :param file_name: File name. Expects to have '.yaml' extension",
            "",
            "    :return: Data in yaml file as dictionary",
            "    \"\"\"",
            "    if not exists(root):",
            "        raise MissingConfigException(",
            "            f\"Cannot read '{file_name}'. Parent dir '{root}' does not exist.\"",
            "        )",
            "",
            "    file_path = os.path.join(root, file_name)",
            "    if not exists(file_path):",
            "        raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)",
            "    try:",
            "        with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as yaml_file:",
            "            return yaml.load(yaml_file, Loader=YamlSafeLoader)",
            "    except Exception as e:",
            "        raise e",
            "",
            "",
            "class UniqueKeyLoader(YamlSafeLoader):",
            "    def construct_mapping(self, node, deep=False):",
            "        mapping = set()",
            "        for key_node, _ in node.value:",
            "            key = self.construct_object(key_node, deep=deep)",
            "            if key in mapping:",
            "                raise ValueError(f\"Duplicate '{key}' key found in YAML.\")",
            "            mapping.add(key)",
            "        return super().construct_mapping(node, deep)",
            "",
            "",
            "def render_and_merge_yaml(root, template_name, context_name):",
            "    \"\"\"",
            "    Renders a Jinja2-templated YAML file based on a YAML context file, merge them, and return",
            "    result as a dictionary.",
            "",
            "    :param root: Root directory of the YAML files",
            "    :param template_name: Name of the template file",
            "    :param context_name: Name of the context file",
            "    :return: Data in yaml file as dictionary",
            "    \"\"\"",
            "    import jinja2",
            "",
            "    template_path = os.path.join(root, template_name)",
            "    context_path = os.path.join(root, context_name)",
            "",
            "    for path in (template_path, context_path):",
            "        if not pathlib.Path(path).is_file():",
            "            raise MissingConfigException(\"Yaml file '%s' does not exist.\" % path)",
            "",
            "    j2_env = jinja2.Environment(",
            "        loader=jinja2.FileSystemLoader(root, encoding=ENCODING),",
            "        undefined=jinja2.StrictUndefined,",
            "        line_comment_prefix=\"#\",",
            "    )",
            "",
            "    def from_json(input_var):",
            "        import json",
            "",
            "        with open(input_var, encoding=\"utf-8\") as f:",
            "            return json.load(f)",
            "",
            "    j2_env.filters[\"from_json\"] = from_json",
            "    # Compute final source of context file (e.g. my-profile.yml), applying Jinja filters",
            "    # like from_json as needed to load context information from files, then load into a dict",
            "    context_source = j2_env.get_template(context_name).render({})",
            "    context_dict = yaml.load(context_source, Loader=UniqueKeyLoader) or {}",
            "",
            "    # Substitute parameters from context dict into template",
            "    source = j2_env.get_template(template_name).render(context_dict)",
            "    rendered_template_dict = yaml.load(source, Loader=UniqueKeyLoader)",
            "    return merge_dicts(rendered_template_dict, context_dict)",
            "",
            "",
            "def read_parquet_as_pandas_df(data_parquet_path: str):",
            "    \"\"\"",
            "    Deserialize and load the specified parquet file as a Pandas DataFrame.",
            "",
            "    :param data_parquet_path: String, path object (implementing os.PathLike[str]),",
            "    or file-like object implementing a binary read() function. The string",
            "    could be a URL. Valid URL schemes include http, ftp, s3, gs, and file.",
            "    For file URLs, a host is expected. A local file could",
            "    be: file://localhost/path/to/table.parquet. A file URL can also be a path to a",
            "    directory that contains multiple partitioned parquet files. Pyarrow",
            "    support paths to directories as well as file URLs. A directory",
            "    path could be: file://localhost/path/to/tables or s3://bucket/partition_dir.",
            "    :return: pandas dataframe",
            "    \"\"\"",
            "    import pandas as pd",
            "",
            "    return pd.read_parquet(data_parquet_path, engine=\"pyarrow\")",
            "",
            "",
            "def write_pandas_df_as_parquet(df, data_parquet_path: str):",
            "    \"\"\"",
            "    Write a DataFrame to the binary parquet format.",
            "",
            "    :param df: pandas data frame.",
            "    :param data_parquet_path: String, path object (implementing os.PathLike[str]),",
            "    or file-like object implementing a binary write() function.",
            "    \"\"\"",
            "    df.to_parquet(data_parquet_path, engine=\"pyarrow\")",
            "",
            "",
            "class TempDir:",
            "    def __init__(self, chdr=False, remove_on_exit=True):",
            "        self._dir = None",
            "        self._path = None",
            "        self._chdr = chdr",
            "        self._remove = remove_on_exit",
            "",
            "    def __enter__(self):",
            "        self._path = os.path.abspath(tempfile.mkdtemp())",
            "        assert os.path.exists(self._path)",
            "        if self._chdr:",
            "            self._dir = os.path.abspath(os.getcwd())",
            "            os.chdir(self._path)",
            "        return self",
            "",
            "    def __exit__(self, tp, val, traceback):",
            "        if self._chdr and self._dir:",
            "            os.chdir(self._dir)",
            "            self._dir = None",
            "        if self._remove and os.path.exists(self._path):",
            "            shutil.rmtree(self._path)",
            "",
            "        assert not self._remove or not os.path.exists(self._path)",
            "        assert os.path.exists(os.getcwd())",
            "",
            "    def path(self, *path):",
            "        return os.path.join(\"./\", *path) if self._chdr else os.path.join(self._path, *path)",
            "",
            "",
            "def read_file_lines(parent_path, file_name):",
            "    \"\"\"",
            "    Return the contents of the file as an array where each element is a separate line.",
            "",
            "    :param parent_path: Full path to the directory that contains the file.",
            "    :param file_name: Leaf file name.",
            "",
            "    :return: All lines in the file as an array.",
            "    \"\"\"",
            "    file_path = os.path.join(parent_path, file_name)",
            "    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:",
            "        return f.readlines()",
            "",
            "",
            "def read_file(parent_path, file_name):",
            "    \"\"\"",
            "    Return the contents of the file.",
            "",
            "    :param parent_path: Full path to the directory that contains the file.",
            "    :param file_name: Leaf file name.",
            "",
            "    :return: The contents of the file.",
            "    \"\"\"",
            "    file_path = os.path.join(parent_path, file_name)",
            "    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:",
            "        return f.read()",
            "",
            "",
            "def get_file_info(path, rel_path):",
            "    \"\"\"",
            "    Returns file meta data : location, size, ... etc",
            "",
            "    :param path: Path to artifact",
            "",
            "    :return: `FileInfo` object",
            "    \"\"\"",
            "    if is_directory(path):",
            "        return FileInfo(rel_path, True, None)",
            "    else:",
            "        return FileInfo(rel_path, False, os.path.getsize(path))",
            "",
            "",
            "def get_relative_path(root_path, target_path):",
            "    \"\"\"",
            "    Remove root path common prefix and return part of `path` relative to `root_path`.",
            "",
            "    :param root_path: Root path",
            "    :param target_path: Desired path for common prefix removal",
            "",
            "    :return: Path relative to root_path",
            "    \"\"\"",
            "    if len(root_path) > len(target_path):",
            "        raise Exception(f\"Root path '{root_path}' longer than target path '{target_path}'\")",
            "    common_prefix = os.path.commonprefix([root_path, target_path])",
            "    return os.path.relpath(target_path, common_prefix)",
            "",
            "",
            "def mv(target, new_parent):",
            "    shutil.move(target, new_parent)",
            "",
            "",
            "def write_to(filename, data):",
            "    with codecs.open(filename, mode=\"w\", encoding=ENCODING) as handle:",
            "        handle.write(data)",
            "",
            "",
            "def append_to(filename, data):",
            "    with open(filename, \"a\") as handle:",
            "        handle.write(data)",
            "",
            "",
            "def make_tarfile(output_filename, source_dir, archive_name, custom_filter=None):",
            "    # Helper for filtering out modification timestamps",
            "    def _filter_timestamps(tar_info):",
            "        tar_info.mtime = 0",
            "        return tar_info if custom_filter is None else custom_filter(tar_info)",
            "",
            "    unzipped_file_handle, unzipped_filename = tempfile.mkstemp()",
            "    try:",
            "        with tarfile.open(unzipped_filename, \"w\") as tar:",
            "            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)",
            "        # When gzipping the tar, don't include the tar's filename or modification time in the",
            "        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)",
            "        with gzip.GzipFile(",
            "            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0",
            "        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar:",
            "            gzipped_tar.write(tar.read())",
            "    finally:",
            "        os.close(unzipped_file_handle)",
            "",
            "",
            "def _copy_project(src_path, dst_path=\"\"):",
            "    \"\"\"",
            "    Internal function used to copy MLflow project during development.",
            "",
            "    Copies the content of the whole directory tree except patterns defined in .dockerignore.",
            "    The MLflow is assumed to be accessible as a local directory in this case.",
            "",
            "",
            "    :param dst_path: MLflow will be copied here",
            "    :return: name of the MLflow project directory",
            "    \"\"\"",
            "",
            "    def _docker_ignore(mlflow_root):",
            "        docker_ignore = os.path.join(mlflow_root, \".dockerignore\")",
            "        patterns = []",
            "        if os.path.exists(docker_ignore):",
            "            with open(docker_ignore) as f:",
            "                patterns = [x.strip() for x in f.readlines()]",
            "",
            "        def ignore(_, names):",
            "            import fnmatch",
            "",
            "            res = set()",
            "            for p in patterns:",
            "                res.update(set(fnmatch.filter(names, p)))",
            "            return list(res)",
            "",
            "        return ignore if patterns else None",
            "",
            "    mlflow_dir = \"mlflow-project\"",
            "    # check if we have project root",
            "    assert os.path.isfile(os.path.join(src_path, \"setup.py\")), \"file not found \" + str(",
            "        os.path.abspath(os.path.join(src_path, \"setup.py\"))",
            "    )",
            "    shutil.copytree(src_path, os.path.join(dst_path, mlflow_dir), ignore=_docker_ignore(src_path))",
            "    return mlflow_dir",
            "",
            "",
            "def _copy_file_or_tree(src, dst, dst_dir=None):",
            "    \"\"\"",
            "    :return: The path to the copied artifacts, relative to `dst`",
            "    \"\"\"",
            "    dst_subpath = os.path.basename(os.path.abspath(src))",
            "    if dst_dir is not None:",
            "        dst_subpath = os.path.join(dst_dir, dst_subpath)",
            "    dst_path = os.path.join(dst, dst_subpath)",
            "    if os.path.isfile(src):",
            "        dst_dirpath = os.path.dirname(dst_path)",
            "        if not os.path.exists(dst_dirpath):",
            "            os.makedirs(dst_dirpath)",
            "        shutil.copy(src=src, dst=dst_path)",
            "    else:",
            "        shutil.copytree(src=src, dst=dst_path, ignore=shutil.ignore_patterns(\"__pycache__\"))",
            "    return dst_subpath",
            "",
            "",
            "def _get_local_project_dir_size(project_path):",
            "    \"\"\"",
            "    Internal function for reporting the size of a local project directory before copying to",
            "    destination for cli logging reporting to stdout.",
            "    :param project_path: local path of the project directory",
            "    :return: directory file sizes in KB, rounded to single decimal point for legibility",
            "    \"\"\"",
            "",
            "    total_size = 0",
            "    for root, _, files in os.walk(project_path):",
            "        for f in files:",
            "            path = os.path.join(root, f)",
            "            total_size += os.path.getsize(path)",
            "    return round(total_size / 1024.0, 1)",
            "",
            "",
            "def _get_local_file_size(file):",
            "    \"\"\"",
            "    Get the size of a local file in KB",
            "    \"\"\"",
            "    return round(os.path.getsize(file) / 1024.0, 1)",
            "",
            "",
            "def get_parent_dir(path):",
            "    return os.path.abspath(os.path.join(path, os.pardir))",
            "",
            "",
            "def relative_path_to_artifact_path(path):",
            "    if os.path == posixpath:",
            "        return path",
            "    if os.path.abspath(path) == path:",
            "        raise Exception(\"This method only works with relative paths.\")",
            "    return unquote(pathname2url(path))",
            "",
            "",
            "def path_to_local_file_uri(path):",
            "    \"\"\"",
            "    Convert local filesystem path to local file uri.",
            "    \"\"\"",
            "    return pathlib.Path(os.path.abspath(path)).as_uri()",
            "",
            "",
            "def path_to_local_sqlite_uri(path):",
            "    \"\"\"",
            "    Convert local filesystem path to sqlite uri.",
            "    \"\"\"",
            "    path = posixpath.abspath(pathname2url(os.path.abspath(path)))",
            "    prefix = \"sqlite://\" if sys.platform == \"win32\" else \"sqlite:///\"",
            "    return prefix + path",
            "",
            "",
            "def local_file_uri_to_path(uri):",
            "    \"\"\"",
            "    Convert URI to local filesystem path.",
            "    No-op if the uri does not have the expected scheme.",
            "    \"\"\"",
            "    path = uri",
            "    if uri.startswith(\"file:\"):",
            "        parsed_path = urllib.parse.urlparse(uri)",
            "        path = parsed_path.path",
            "        # Fix for retaining server name in UNC path.",
            "        if is_windows() and parsed_path.netloc:",
            "            return urllib.request.url2pathname(rf\"\\\\{parsed_path.netloc}{path}\")",
            "    return urllib.request.url2pathname(path)",
            "",
            "",
            "def get_local_path_or_none(path_or_uri):",
            "    \"\"\"Check if the argument is a local path (no scheme or file:///) and return local path if true,",
            "    None otherwise.",
            "    \"\"\"",
            "    parsed_uri = urllib.parse.urlparse(path_or_uri)",
            "    if len(parsed_uri.scheme) == 0 or parsed_uri.scheme == \"file\" and len(parsed_uri.netloc) == 0:",
            "        return local_file_uri_to_path(path_or_uri)",
            "    else:",
            "        return None",
            "",
            "",
            "def yield_file_in_chunks(file, chunk_size=100000000):",
            "    \"\"\"",
            "    Generator to chunk-ify the inputted file based on the chunk-size.",
            "    \"\"\"",
            "    with open(file, \"rb\") as f:",
            "        while True:",
            "            chunk = f.read(chunk_size)",
            "            if chunk:",
            "                yield chunk",
            "            else:",
            "                break",
            "",
            "",
            "def download_file_using_http_uri(http_uri, download_path, chunk_size=100000000, headers=None):",
            "    \"\"\"",
            "    Downloads a file specified using the `http_uri` to a local `download_path`. This function",
            "    uses a `chunk_size` to ensure an OOM error is not raised a large file is downloaded.",
            "",
            "    Note : This function is meant to download files using presigned urls from various cloud",
            "            providers.",
            "    \"\"\"",
            "    if headers is None:",
            "        headers = {}",
            "    with cloud_storage_http_request(\"get\", http_uri, stream=True, headers=headers) as response:",
            "        augmented_raise_for_status(response)",
            "        with open(download_path, \"wb\") as output_file:",
            "            for chunk in response.iter_content(chunk_size=chunk_size):",
            "                if not chunk:",
            "                    break",
            "                output_file.write(chunk)",
            "",
            "",
            "def _handle_readonly_on_windows(func, path, exc_info):",
            "    \"\"\"",
            "    This function should not be called directly but should be passed to `onerror` of",
            "    `shutil.rmtree` in order to reattempt the removal of a read-only file after making",
            "    it writable on Windows.",
            "",
            "    References:",
            "    - https://bugs.python.org/issue19643",
            "    - https://bugs.python.org/issue43657",
            "    \"\"\"",
            "    exc_type, exc_value = exc_info[:2]",
            "    should_reattempt = (",
            "        os.name == \"nt\"",
            "        and func in (os.unlink, os.rmdir)",
            "        and issubclass(exc_type, PermissionError)",
            "        and exc_value.winerror == 5",
            "    )",
            "    if not should_reattempt:",
            "        raise exc_value",
            "    os.chmod(path, stat.S_IWRITE)",
            "    func(path)",
            "",
            "",
            "@cache_return_value_per_process",
            "def get_or_create_tmp_dir():",
            "    \"\"\"",
            "    Get or create a temporary directory which will be removed once python process exit.",
            "    \"\"\"",
            "    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id",
            "",
            "    if is_in_databricks_runtime() and get_repl_id() is not None:",
            "        # Note: For python process attached to databricks notebook, atexit does not work.",
            "        # The directory returned by `dbutils.entry_point.getReplLocalTempDir()`",
            "        # will be removed once databricks notebook detaches.",
            "        # The temp directory is designed to be used by all kinds of applications,",
            "        # so create a child directory \"mlflow\" for storing mlflow temp data.",
            "        try:",
            "            repl_local_tmp_dir = _get_dbutils().entry_point.getReplLocalTempDir()",
            "        except Exception:",
            "            repl_local_tmp_dir = os.path.join(\"/tmp\", \"repl_tmp_data\", get_repl_id())",
            "",
            "        tmp_dir = os.path.join(repl_local_tmp_dir, \"mlflow\")",
            "        os.makedirs(tmp_dir, exist_ok=True)",
            "    else:",
            "        tmp_dir = tempfile.mkdtemp()",
            "        # mkdtemp creates a directory with permission 0o700",
            "        # change it to be 0o777 to ensure it can be seen in spark UDF",
            "        os.chmod(tmp_dir, 0o777)",
            "        atexit.register(shutil.rmtree, tmp_dir, ignore_errors=True)",
            "",
            "    return tmp_dir",
            "",
            "",
            "@cache_return_value_per_process",
            "def get_or_create_nfs_tmp_dir():",
            "    \"\"\"",
            "    Get or create a temporary NFS directory which will be removed once python process exit.",
            "    \"\"\"",
            "    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id",
            "    from mlflow.utils.nfs_on_spark import get_nfs_cache_root_dir",
            "",
            "    nfs_root_dir = get_nfs_cache_root_dir()",
            "",
            "    if is_in_databricks_runtime() and get_repl_id() is not None:",
            "        # Note: In databricks, atexit hook does not work.",
            "        # The directory returned by `dbutils.entry_point.getReplNFSTempDir()`",
            "        # will be removed once databricks notebook detaches.",
            "        # The temp directory is designed to be used by all kinds of applications,",
            "        # so create a child directory \"mlflow\" for storing mlflow temp data.",
            "        try:",
            "            repl_nfs_tmp_dir = _get_dbutils().entry_point.getReplNFSTempDir()",
            "        except Exception:",
            "            repl_nfs_tmp_dir = os.path.join(nfs_root_dir, \"repl_tmp_data\", get_repl_id())",
            "",
            "        tmp_nfs_dir = os.path.join(repl_nfs_tmp_dir, \"mlflow\")",
            "        os.makedirs(tmp_nfs_dir, exist_ok=True)",
            "    else:",
            "        tmp_nfs_dir = tempfile.mkdtemp(dir=nfs_root_dir)",
            "        # mkdtemp creates a directory with permission 0o700",
            "        # change it to be 0o777 to ensure it can be seen in spark UDF",
            "        os.chmod(tmp_nfs_dir, 0o777)",
            "        atexit.register(shutil.rmtree, tmp_nfs_dir, ignore_errors=True)",
            "",
            "    return tmp_nfs_dir",
            "",
            "",
            "def write_spark_dataframe_to_parquet_on_local_disk(spark_df, output_path):",
            "    \"\"\"",
            "    Write spark dataframe in parquet format to local disk.",
            "",
            "    :param spark_df: Spark dataframe",
            "    :param output_path: path to write the data to",
            "    \"\"\"",
            "    from mlflow.utils.databricks_utils import is_in_databricks_runtime",
            "    import uuid",
            "",
            "    if is_in_databricks_runtime():",
            "        dbfs_path = os.path.join(\".mlflow\", \"cache\", str(uuid.uuid4()))",
            "        spark_df.coalesce(1).write.format(\"parquet\").save(dbfs_path)",
            "        shutil.copytree(\"/dbfs/\" + dbfs_path, output_path)",
            "        shutil.rmtree(\"/dbfs/\" + dbfs_path)",
            "    else:",
            "        spark_df.coalesce(1).write.format(\"parquet\").save(output_path)",
            "",
            "",
            "def shutil_copytree_without_file_permissions(src_dir, dst_dir):",
            "    \"\"\"",
            "    Copies the directory src_dir into dst_dir, without preserving filesystem permissions",
            "    \"\"\"",
            "    for dirpath, dirnames, filenames in os.walk(src_dir):",
            "        for dirname in dirnames:",
            "            relative_dir_path = os.path.relpath(os.path.join(dirpath, dirname), src_dir)",
            "            # For each directory <dirname> immediately under <dirpath>, create an equivalently-named",
            "            # directory under the destination directory",
            "            abs_dir_path = os.path.join(dst_dir, relative_dir_path)",
            "            os.mkdir(abs_dir_path)",
            "        for filename in filenames:",
            "            # For each file with name <filename> immediately under <dirpath>, copy that file to",
            "            # the appropriate location in the destination directory",
            "            file_path = os.path.join(dirpath, filename)",
            "            relative_file_path = os.path.relpath(file_path, src_dir)",
            "            abs_file_path = os.path.join(dst_dir, relative_file_path)",
            "            shutil.copyfile(file_path, abs_file_path)"
        ],
        "afterPatchFile": [
            "import codecs",
            "import errno",
            "import gzip",
            "import os",
            "import posixpath",
            "import shutil",
            "import sys",
            "import tarfile",
            "import tempfile",
            "import stat",
            "import pathlib",
            "",
            "import urllib.parse",
            "import urllib.request",
            "from urllib.parse import unquote",
            "from urllib.request import pathname2url",
            "",
            "import atexit",
            "",
            "import yaml",
            "",
            "try:",
            "    from yaml import CSafeLoader as YamlSafeLoader, CSafeDumper as YamlSafeDumper",
            "except ImportError:",
            "    from yaml import SafeLoader as YamlSafeLoader, SafeDumper as YamlSafeDumper",
            "",
            "from mlflow.entities import FileInfo",
            "from mlflow.exceptions import MissingConfigException",
            "from mlflow.utils.rest_utils import cloud_storage_http_request, augmented_raise_for_status",
            "from mlflow.utils.process import cache_return_value_per_process",
            "from mlflow.utils import merge_dicts",
            "from mlflow.utils.databricks_utils import _get_dbutils",
            "from mlflow.utils.os import is_windows",
            "",
            "ENCODING = \"utf-8\"",
            "",
            "",
            "def is_directory(name):",
            "    return os.path.isdir(name)",
            "",
            "",
            "def is_file(name):",
            "    return os.path.isfile(name)",
            "",
            "",
            "def exists(name):",
            "    return os.path.exists(name)",
            "",
            "",
            "def list_all(root, filter_func=lambda x: True, full_path=False):",
            "    \"\"\"",
            "    List all entities directly under 'dir_name' that satisfy 'filter_func'",
            "",
            "    :param root: Name of directory to start search",
            "    :param filter_func: function or lambda that takes path",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of all files or directories that satisfy the criteria.",
            "    \"\"\"",
            "    if not is_directory(root):",
            "        raise Exception(\"Invalid parent directory '%s'\" % root)",
            "    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]",
            "    return [os.path.join(root, m) for m in matches] if full_path else matches",
            "",
            "",
            "def list_subdirs(dir_name, full_path=False):",
            "    \"\"\"",
            "    Equivalent to UNIX command:",
            "      ``find $dir_name -depth 1 -type d``",
            "",
            "    :param dir_name: Name of directory to start search",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of all directories directly under 'dir_name'",
            "    \"\"\"",
            "    return list_all(dir_name, os.path.isdir, full_path)",
            "",
            "",
            "def list_files(dir_name, full_path=False):",
            "    \"\"\"",
            "    Equivalent to UNIX command:",
            "      ``find $dir_name -depth 1 -type f``",
            "",
            "    :param dir_name: Name of directory to start search",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of all files directly under 'dir_name'",
            "    \"\"\"",
            "    return list_all(dir_name, os.path.isfile, full_path)",
            "",
            "",
            "def find(root, name, full_path=False):",
            "    \"\"\"",
            "    Search for a file in a root directory. Equivalent to:",
            "      ``find $root -name \"$name\" -depth 1``",
            "",
            "    :param root: Name of root directory for find",
            "    :param name: Name of file or directory to find directly under root directory",
            "    :param full_path: If True will return results as full path including `root`",
            "",
            "    :return: list of matching files or directories",
            "    \"\"\"",
            "    path_name = os.path.join(root, name)",
            "    return list_all(root, lambda x: x == path_name, full_path)",
            "",
            "",
            "def mkdir(root, name=None):",
            "    \"\"\"",
            "    Make directory with name \"root/name\", or just \"root\" if name is None.",
            "",
            "    :param root: Name of parent directory",
            "    :param name: Optional name of leaf directory",
            "",
            "    :return: Path to created directory",
            "    \"\"\"",
            "    target = os.path.join(root, name) if name is not None else root",
            "    try:",
            "        os.makedirs(target)",
            "    except OSError as e:",
            "        if e.errno != errno.EEXIST or not os.path.isdir(target):",
            "            raise e",
            "    return target",
            "",
            "",
            "def make_containing_dirs(path):",
            "    \"\"\"",
            "    Create the base directory for a given file path if it does not exist; also creates parent",
            "    directories.",
            "    \"\"\"",
            "    dir_name = os.path.dirname(path)",
            "    if not os.path.exists(dir_name):",
            "        os.makedirs(dir_name)",
            "",
            "",
            "def write_yaml(root, file_name, data, overwrite=False, sort_keys=True):",
            "    \"\"\"",
            "    Write dictionary data in yaml format.",
            "",
            "    :param root: Directory name.",
            "    :param file_name: Desired file name. Will automatically add .yaml extension if not given",
            "    :param data: data to be dumped as yaml format",
            "    :param overwrite: If True, will overwrite existing files",
            "    \"\"\"",
            "    if not exists(root):",
            "        raise MissingConfigException(\"Parent directory '%s' does not exist.\" % root)",
            "",
            "    file_path = os.path.join(root, file_name)",
            "    yaml_file_name = file_path if file_path.endswith(\".yaml\") else file_path + \".yaml\"",
            "",
            "    if exists(yaml_file_name) and not overwrite:",
            "        raise Exception(f\"Yaml file '{file_path}' exists as '{yaml_file_name}\")",
            "",
            "    try:",
            "        with codecs.open(yaml_file_name, mode=\"w\", encoding=ENCODING) as yaml_file:",
            "            yaml.dump(",
            "                data,",
            "                yaml_file,",
            "                default_flow_style=False,",
            "                allow_unicode=True,",
            "                sort_keys=sort_keys,",
            "                Dumper=YamlSafeDumper,",
            "            )",
            "    except Exception as e:",
            "        raise e",
            "",
            "",
            "def overwrite_yaml(root, file_name, data):",
            "    \"\"\"",
            "    Safely overwrites a preexisting yaml file, ensuring that file contents are not deleted or",
            "    corrupted if the write fails. This is achieved by writing contents to a temporary file",
            "    and moving the temporary file to replace the preexisting file, rather than opening the",
            "    preexisting file for a direct write.",
            "",
            "    :param root: Directory name.",
            "    :param file_name: File name. Expects to have '.yaml' extension.",
            "    :param data: The data to write, represented as a dictionary.",
            "    \"\"\"",
            "    tmp_file_path = None",
            "    try:",
            "        tmp_file_fd, tmp_file_path = tempfile.mkstemp(suffix=\"file.yaml\")",
            "        os.close(tmp_file_fd)",
            "        write_yaml(",
            "            root=get_parent_dir(tmp_file_path),",
            "            file_name=os.path.basename(tmp_file_path),",
            "            data=data,",
            "            overwrite=True,",
            "            sort_keys=True,",
            "        )",
            "        shutil.move(",
            "            tmp_file_path,",
            "            os.path.join(root, file_name),",
            "        )",
            "    finally:",
            "        if tmp_file_path is not None and os.path.exists(tmp_file_path):",
            "            os.remove(tmp_file_path)",
            "",
            "",
            "def read_yaml(root, file_name):",
            "    \"\"\"",
            "    Read data from yaml file and return as dictionary",
            "",
            "    :param root: Directory name",
            "    :param file_name: File name. Expects to have '.yaml' extension",
            "",
            "    :return: Data in yaml file as dictionary",
            "    \"\"\"",
            "    if not exists(root):",
            "        raise MissingConfigException(",
            "            f\"Cannot read '{file_name}'. Parent dir '{root}' does not exist.\"",
            "        )",
            "",
            "    file_path = os.path.join(root, file_name)",
            "    if not exists(file_path):",
            "        raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)",
            "    try:",
            "        with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as yaml_file:",
            "            return yaml.load(yaml_file, Loader=YamlSafeLoader)",
            "    except Exception as e:",
            "        raise e",
            "",
            "",
            "class UniqueKeyLoader(YamlSafeLoader):",
            "    def construct_mapping(self, node, deep=False):",
            "        mapping = set()",
            "        for key_node, _ in node.value:",
            "            key = self.construct_object(key_node, deep=deep)",
            "            if key in mapping:",
            "                raise ValueError(f\"Duplicate '{key}' key found in YAML.\")",
            "            mapping.add(key)",
            "        return super().construct_mapping(node, deep)",
            "",
            "",
            "def render_and_merge_yaml(root, template_name, context_name):",
            "    \"\"\"",
            "    Renders a Jinja2-templated YAML file based on a YAML context file, merge them, and return",
            "    result as a dictionary.",
            "",
            "    :param root: Root directory of the YAML files",
            "    :param template_name: Name of the template file",
            "    :param context_name: Name of the context file",
            "    :return: Data in yaml file as dictionary",
            "    \"\"\"",
            "    import jinja2",
            "",
            "    template_path = os.path.join(root, template_name)",
            "    context_path = os.path.join(root, context_name)",
            "",
            "    for path in (template_path, context_path):",
            "        if not pathlib.Path(path).is_file():",
            "            raise MissingConfigException(\"Yaml file '%s' does not exist.\" % path)",
            "",
            "    j2_env = jinja2.Environment(",
            "        loader=jinja2.FileSystemLoader(root, encoding=ENCODING),",
            "        undefined=jinja2.StrictUndefined,",
            "        line_comment_prefix=\"#\",",
            "    )",
            "",
            "    def from_json(input_var):",
            "        import json",
            "",
            "        with open(input_var, encoding=\"utf-8\") as f:",
            "            return json.load(f)",
            "",
            "    j2_env.filters[\"from_json\"] = from_json",
            "    # Compute final source of context file (e.g. my-profile.yml), applying Jinja filters",
            "    # like from_json as needed to load context information from files, then load into a dict",
            "    context_source = j2_env.get_template(context_name).render({})",
            "    context_dict = yaml.load(context_source, Loader=UniqueKeyLoader) or {}",
            "",
            "    # Substitute parameters from context dict into template",
            "    source = j2_env.get_template(template_name).render(context_dict)",
            "    rendered_template_dict = yaml.load(source, Loader=UniqueKeyLoader)",
            "    return merge_dicts(rendered_template_dict, context_dict)",
            "",
            "",
            "def read_parquet_as_pandas_df(data_parquet_path: str):",
            "    \"\"\"",
            "    Deserialize and load the specified parquet file as a Pandas DataFrame.",
            "",
            "    :param data_parquet_path: String, path object (implementing os.PathLike[str]),",
            "    or file-like object implementing a binary read() function. The string",
            "    could be a URL. Valid URL schemes include http, ftp, s3, gs, and file.",
            "    For file URLs, a host is expected. A local file could",
            "    be: file://localhost/path/to/table.parquet. A file URL can also be a path to a",
            "    directory that contains multiple partitioned parquet files. Pyarrow",
            "    support paths to directories as well as file URLs. A directory",
            "    path could be: file://localhost/path/to/tables or s3://bucket/partition_dir.",
            "    :return: pandas dataframe",
            "    \"\"\"",
            "    import pandas as pd",
            "",
            "    return pd.read_parquet(data_parquet_path, engine=\"pyarrow\")",
            "",
            "",
            "def write_pandas_df_as_parquet(df, data_parquet_path: str):",
            "    \"\"\"",
            "    Write a DataFrame to the binary parquet format.",
            "",
            "    :param df: pandas data frame.",
            "    :param data_parquet_path: String, path object (implementing os.PathLike[str]),",
            "    or file-like object implementing a binary write() function.",
            "    \"\"\"",
            "    df.to_parquet(data_parquet_path, engine=\"pyarrow\")",
            "",
            "",
            "class TempDir:",
            "    def __init__(self, chdr=False, remove_on_exit=True):",
            "        self._dir = None",
            "        self._path = None",
            "        self._chdr = chdr",
            "        self._remove = remove_on_exit",
            "",
            "    def __enter__(self):",
            "        self._path = os.path.abspath(tempfile.mkdtemp())",
            "        assert os.path.exists(self._path)",
            "        if self._chdr:",
            "            self._dir = os.path.abspath(os.getcwd())",
            "            os.chdir(self._path)",
            "        return self",
            "",
            "    def __exit__(self, tp, val, traceback):",
            "        if self._chdr and self._dir:",
            "            os.chdir(self._dir)",
            "            self._dir = None",
            "        if self._remove and os.path.exists(self._path):",
            "            shutil.rmtree(self._path)",
            "",
            "        assert not self._remove or not os.path.exists(self._path)",
            "        assert os.path.exists(os.getcwd())",
            "",
            "    def path(self, *path):",
            "        return os.path.join(\"./\", *path) if self._chdr else os.path.join(self._path, *path)",
            "",
            "",
            "def read_file_lines(parent_path, file_name):",
            "    \"\"\"",
            "    Return the contents of the file as an array where each element is a separate line.",
            "",
            "    :param parent_path: Full path to the directory that contains the file.",
            "    :param file_name: Leaf file name.",
            "",
            "    :return: All lines in the file as an array.",
            "    \"\"\"",
            "    file_path = os.path.join(parent_path, file_name)",
            "    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:",
            "        return f.readlines()",
            "",
            "",
            "def read_file(parent_path, file_name):",
            "    \"\"\"",
            "    Return the contents of the file.",
            "",
            "    :param parent_path: Full path to the directory that contains the file.",
            "    :param file_name: Leaf file name.",
            "",
            "    :return: The contents of the file.",
            "    \"\"\"",
            "    file_path = os.path.join(parent_path, file_name)",
            "    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:",
            "        return f.read()",
            "",
            "",
            "def get_file_info(path, rel_path):",
            "    \"\"\"",
            "    Returns file meta data : location, size, ... etc",
            "",
            "    :param path: Path to artifact",
            "",
            "    :return: `FileInfo` object",
            "    \"\"\"",
            "    if is_directory(path):",
            "        return FileInfo(rel_path, True, None)",
            "    else:",
            "        return FileInfo(rel_path, False, os.path.getsize(path))",
            "",
            "",
            "def get_relative_path(root_path, target_path):",
            "    \"\"\"",
            "    Remove root path common prefix and return part of `path` relative to `root_path`.",
            "",
            "    :param root_path: Root path",
            "    :param target_path: Desired path for common prefix removal",
            "",
            "    :return: Path relative to root_path",
            "    \"\"\"",
            "    if len(root_path) > len(target_path):",
            "        raise Exception(f\"Root path '{root_path}' longer than target path '{target_path}'\")",
            "    common_prefix = os.path.commonprefix([root_path, target_path])",
            "    return os.path.relpath(target_path, common_prefix)",
            "",
            "",
            "def mv(target, new_parent):",
            "    shutil.move(target, new_parent)",
            "",
            "",
            "def write_to(filename, data):",
            "    with codecs.open(filename, mode=\"w\", encoding=ENCODING) as handle:",
            "        handle.write(data)",
            "",
            "",
            "def append_to(filename, data):",
            "    with open(filename, \"a\") as handle:",
            "        handle.write(data)",
            "",
            "",
            "def make_tarfile(output_filename, source_dir, archive_name, custom_filter=None):",
            "    # Helper for filtering out modification timestamps",
            "    def _filter_timestamps(tar_info):",
            "        tar_info.mtime = 0",
            "        return tar_info if custom_filter is None else custom_filter(tar_info)",
            "",
            "    unzipped_file_handle, unzipped_filename = tempfile.mkstemp()",
            "    try:",
            "        with tarfile.open(unzipped_filename, \"w\") as tar:",
            "            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)",
            "        # When gzipping the tar, don't include the tar's filename or modification time in the",
            "        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)",
            "        with gzip.GzipFile(",
            "            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0",
            "        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar:",
            "            gzipped_tar.write(tar.read())",
            "    finally:",
            "        os.close(unzipped_file_handle)",
            "",
            "",
            "def _copy_project(src_path, dst_path=\"\"):",
            "    \"\"\"",
            "    Internal function used to copy MLflow project during development.",
            "",
            "    Copies the content of the whole directory tree except patterns defined in .dockerignore.",
            "    The MLflow is assumed to be accessible as a local directory in this case.",
            "",
            "",
            "    :param dst_path: MLflow will be copied here",
            "    :return: name of the MLflow project directory",
            "    \"\"\"",
            "",
            "    def _docker_ignore(mlflow_root):",
            "        docker_ignore = os.path.join(mlflow_root, \".dockerignore\")",
            "        patterns = []",
            "        if os.path.exists(docker_ignore):",
            "            with open(docker_ignore) as f:",
            "                patterns = [x.strip() for x in f.readlines()]",
            "",
            "        def ignore(_, names):",
            "            import fnmatch",
            "",
            "            res = set()",
            "            for p in patterns:",
            "                res.update(set(fnmatch.filter(names, p)))",
            "            return list(res)",
            "",
            "        return ignore if patterns else None",
            "",
            "    mlflow_dir = \"mlflow-project\"",
            "    # check if we have project root",
            "    assert os.path.isfile(os.path.join(src_path, \"setup.py\")), \"file not found \" + str(",
            "        os.path.abspath(os.path.join(src_path, \"setup.py\"))",
            "    )",
            "    shutil.copytree(src_path, os.path.join(dst_path, mlflow_dir), ignore=_docker_ignore(src_path))",
            "    return mlflow_dir",
            "",
            "",
            "def _copy_file_or_tree(src, dst, dst_dir=None):",
            "    \"\"\"",
            "    :return: The path to the copied artifacts, relative to `dst`",
            "    \"\"\"",
            "    dst_subpath = os.path.basename(os.path.abspath(src))",
            "    if dst_dir is not None:",
            "        dst_subpath = os.path.join(dst_dir, dst_subpath)",
            "    dst_path = os.path.join(dst, dst_subpath)",
            "    if os.path.isfile(src):",
            "        dst_dirpath = os.path.dirname(dst_path)",
            "        if not os.path.exists(dst_dirpath):",
            "            os.makedirs(dst_dirpath)",
            "        shutil.copy(src=src, dst=dst_path)",
            "    else:",
            "        shutil.copytree(src=src, dst=dst_path, ignore=shutil.ignore_patterns(\"__pycache__\"))",
            "    return dst_subpath",
            "",
            "",
            "def _get_local_project_dir_size(project_path):",
            "    \"\"\"",
            "    Internal function for reporting the size of a local project directory before copying to",
            "    destination for cli logging reporting to stdout.",
            "    :param project_path: local path of the project directory",
            "    :return: directory file sizes in KB, rounded to single decimal point for legibility",
            "    \"\"\"",
            "",
            "    total_size = 0",
            "    for root, _, files in os.walk(project_path):",
            "        for f in files:",
            "            path = os.path.join(root, f)",
            "            total_size += os.path.getsize(path)",
            "    return round(total_size / 1024.0, 1)",
            "",
            "",
            "def _get_local_file_size(file):",
            "    \"\"\"",
            "    Get the size of a local file in KB",
            "    \"\"\"",
            "    return round(os.path.getsize(file) / 1024.0, 1)",
            "",
            "",
            "def get_parent_dir(path):",
            "    return os.path.abspath(os.path.join(path, os.pardir))",
            "",
            "",
            "def relative_path_to_artifact_path(path):",
            "    if os.path == posixpath:",
            "        return path",
            "    if os.path.abspath(path) == path:",
            "        raise Exception(\"This method only works with relative paths.\")",
            "    return unquote(pathname2url(path))",
            "",
            "",
            "def path_to_local_file_uri(path):",
            "    \"\"\"",
            "    Convert local filesystem path to local file uri.",
            "    \"\"\"",
            "    return pathlib.Path(os.path.abspath(path)).as_uri()",
            "",
            "",
            "def path_to_local_sqlite_uri(path):",
            "    \"\"\"",
            "    Convert local filesystem path to sqlite uri.",
            "    \"\"\"",
            "    path = posixpath.abspath(pathname2url(os.path.abspath(path)))",
            "    prefix = \"sqlite://\" if sys.platform == \"win32\" else \"sqlite:///\"",
            "    return prefix + path",
            "",
            "",
            "def local_file_uri_to_path(uri):",
            "    \"\"\"",
            "    Convert URI to local filesystem path.",
            "    No-op if the uri does not have the expected scheme.",
            "    \"\"\"",
            "    path = uri",
            "    if uri.startswith(\"file:\"):",
            "        parsed_path = urllib.parse.urlparse(uri)",
            "        path = parsed_path.path",
            "        # Fix for retaining server name in UNC path.",
            "        if is_windows() and parsed_path.netloc:",
            "            return urllib.request.url2pathname(rf\"\\\\{parsed_path.netloc}{path}\")",
            "    return urllib.request.url2pathname(path)",
            "",
            "",
            "def get_local_path_or_none(path_or_uri):",
            "    \"\"\"Check if the argument is a local path (no scheme or file:///) and return local path if true,",
            "    None otherwise.",
            "    \"\"\"",
            "    parsed_uri = urllib.parse.urlparse(path_or_uri)",
            "    if len(parsed_uri.scheme) == 0 or parsed_uri.scheme == \"file\" and len(parsed_uri.netloc) == 0:",
            "        return local_file_uri_to_path(path_or_uri)",
            "    else:",
            "        return None",
            "",
            "",
            "def yield_file_in_chunks(file, chunk_size=100000000):",
            "    \"\"\"",
            "    Generator to chunk-ify the inputted file based on the chunk-size.",
            "    \"\"\"",
            "    with open(file, \"rb\") as f:",
            "        while True:",
            "            chunk = f.read(chunk_size)",
            "            if chunk:",
            "                yield chunk",
            "            else:",
            "                break",
            "",
            "",
            "def download_file_using_http_uri(http_uri, download_path, chunk_size=100000000, headers=None):",
            "    \"\"\"",
            "    Downloads a file specified using the `http_uri` to a local `download_path`. This function",
            "    uses a `chunk_size` to ensure an OOM error is not raised a large file is downloaded.",
            "",
            "    Note : This function is meant to download files using presigned urls from various cloud",
            "            providers.",
            "    \"\"\"",
            "    if headers is None:",
            "        headers = {}",
            "    with cloud_storage_http_request(\"get\", http_uri, stream=True, headers=headers) as response:",
            "        augmented_raise_for_status(response)",
            "        with open(download_path, \"wb\") as output_file:",
            "            for chunk in response.iter_content(chunk_size=chunk_size):",
            "                if not chunk:",
            "                    break",
            "                output_file.write(chunk)",
            "",
            "",
            "def _handle_readonly_on_windows(func, path, exc_info):",
            "    \"\"\"",
            "    This function should not be called directly but should be passed to `onerror` of",
            "    `shutil.rmtree` in order to reattempt the removal of a read-only file after making",
            "    it writable on Windows.",
            "",
            "    References:",
            "    - https://bugs.python.org/issue19643",
            "    - https://bugs.python.org/issue43657",
            "    \"\"\"",
            "    exc_type, exc_value = exc_info[:2]",
            "    should_reattempt = (",
            "        os.name == \"nt\"",
            "        and func in (os.unlink, os.rmdir)",
            "        and issubclass(exc_type, PermissionError)",
            "        and exc_value.winerror == 5",
            "    )",
            "    if not should_reattempt:",
            "        raise exc_value",
            "    os.chmod(path, stat.S_IWRITE)",
            "    func(path)",
            "",
            "",
            "@cache_return_value_per_process",
            "def get_or_create_tmp_dir():",
            "    \"\"\"",
            "    Get or create a temporary directory which will be removed once python process exit.",
            "    \"\"\"",
            "    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id",
            "",
            "    if is_in_databricks_runtime() and get_repl_id() is not None:",
            "        # Note: For python process attached to databricks notebook, atexit does not work.",
            "        # The directory returned by `dbutils.entry_point.getReplLocalTempDir()`",
            "        # will be removed once databricks notebook detaches.",
            "        # The temp directory is designed to be used by all kinds of applications,",
            "        # so create a child directory \"mlflow\" for storing mlflow temp data.",
            "        try:",
            "            repl_local_tmp_dir = _get_dbutils().entry_point.getReplLocalTempDir()",
            "        except Exception:",
            "            repl_local_tmp_dir = os.path.join(\"/tmp\", \"repl_tmp_data\", get_repl_id())",
            "",
            "        tmp_dir = os.path.join(repl_local_tmp_dir, \"mlflow\")",
            "        os.makedirs(tmp_dir, exist_ok=True)",
            "    else:",
            "        tmp_dir = tempfile.mkdtemp()",
            "        # mkdtemp creates a directory with permission 0o700",
            "        # change it to be 0o777 to ensure it can be seen in spark UDF",
            "        os.chmod(tmp_dir, 0o777)",
            "        atexit.register(shutil.rmtree, tmp_dir, ignore_errors=True)",
            "",
            "    return tmp_dir",
            "",
            "",
            "@cache_return_value_per_process",
            "def get_or_create_nfs_tmp_dir():",
            "    \"\"\"",
            "    Get or create a temporary NFS directory which will be removed once python process exit.",
            "    \"\"\"",
            "    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id",
            "    from mlflow.utils.nfs_on_spark import get_nfs_cache_root_dir",
            "",
            "    nfs_root_dir = get_nfs_cache_root_dir()",
            "",
            "    if is_in_databricks_runtime() and get_repl_id() is not None:",
            "        # Note: In databricks, atexit hook does not work.",
            "        # The directory returned by `dbutils.entry_point.getReplNFSTempDir()`",
            "        # will be removed once databricks notebook detaches.",
            "        # The temp directory is designed to be used by all kinds of applications,",
            "        # so create a child directory \"mlflow\" for storing mlflow temp data.",
            "        try:",
            "            repl_nfs_tmp_dir = _get_dbutils().entry_point.getReplNFSTempDir()",
            "        except Exception:",
            "            repl_nfs_tmp_dir = os.path.join(nfs_root_dir, \"repl_tmp_data\", get_repl_id())",
            "",
            "        tmp_nfs_dir = os.path.join(repl_nfs_tmp_dir, \"mlflow\")",
            "        os.makedirs(tmp_nfs_dir, exist_ok=True)",
            "    else:",
            "        tmp_nfs_dir = tempfile.mkdtemp(dir=nfs_root_dir)",
            "        # mkdtemp creates a directory with permission 0o700",
            "        # change it to be 0o777 to ensure it can be seen in spark UDF",
            "        os.chmod(tmp_nfs_dir, 0o777)",
            "        atexit.register(shutil.rmtree, tmp_nfs_dir, ignore_errors=True)",
            "",
            "    return tmp_nfs_dir",
            "",
            "",
            "def write_spark_dataframe_to_parquet_on_local_disk(spark_df, output_path):",
            "    \"\"\"",
            "    Write spark dataframe in parquet format to local disk.",
            "",
            "    :param spark_df: Spark dataframe",
            "    :param output_path: path to write the data to",
            "    \"\"\"",
            "    from mlflow.utils.databricks_utils import is_in_databricks_runtime",
            "    import uuid",
            "",
            "    if is_in_databricks_runtime():",
            "        dbfs_path = os.path.join(\".mlflow\", \"cache\", str(uuid.uuid4()))",
            "        spark_df.coalesce(1).write.format(\"parquet\").save(dbfs_path)",
            "        shutil.copytree(\"/dbfs/\" + dbfs_path, output_path)",
            "        shutil.rmtree(\"/dbfs/\" + dbfs_path)",
            "    else:",
            "        spark_df.coalesce(1).write.format(\"parquet\").save(output_path)",
            "",
            "",
            "def shutil_copytree_without_file_permissions(src_dir, dst_dir):",
            "    \"\"\"",
            "    Copies the directory src_dir into dst_dir, without preserving filesystem permissions",
            "    \"\"\"",
            "    for dirpath, dirnames, filenames in os.walk(src_dir):",
            "        for dirname in dirnames:",
            "            relative_dir_path = os.path.relpath(os.path.join(dirpath, dirname), src_dir)",
            "            # For each directory <dirname> immediately under <dirpath>, create an equivalently-named",
            "            # directory under the destination directory",
            "            abs_dir_path = os.path.join(dst_dir, relative_dir_path)",
            "            os.mkdir(abs_dir_path)",
            "        for filename in filenames:",
            "            # For each file with name <filename> immediately under <dirpath>, copy that file to",
            "            # the appropriate location in the destination directory",
            "            file_path = os.path.join(dirpath, filename)",
            "            relative_file_path = os.path.relpath(file_path, src_dir)",
            "            abs_file_path = os.path.join(dst_dir, relative_file_path)",
            "            shutil.copyfile(file_path, abs_file_path)",
            "",
            "",
            "def contains_path_separator(path):",
            "    \"\"\"",
            "    Returns True if a path contains a path separator, False otherwise.",
            "    \"\"\"",
            "    return any((sep in path) for sep in (os.path.sep, os.path.altsep) if sep is not None)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "pypdf.generic._data_structures"
        ]
    }
}