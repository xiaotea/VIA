{
    "numpy/core/_type_aliases.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 115,
                "PatchRowcode": "         # add forward, reverse, and string mapping to numarray"
            },
            "1": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 116,
                "PatchRowcode": "         sctypeDict[char] = info.type"
            },
            "2": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 117,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # Add deprecated numeric-style type aliases manually, at some point"
            },
            "4": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # we may want to deprecate the lower case \"bytes0\" version as well."
            },
            "5": {
                "beforePatchRowNumber": 120,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    for name in [\"Bytes0\", \"Datetime64\", \"Str0\", \"Uint32\", \"Uint64\"]:"
            },
            "6": {
                "beforePatchRowNumber": 121,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if english_lower(name) not in allTypes:"
            },
            "7": {
                "beforePatchRowNumber": 122,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # Only one of Uint32 or Uint64, aliases of `np.uintp`, was (and is) defined, note that this"
            },
            "8": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # is not UInt32/UInt64 (capital i), which is removed."
            },
            "9": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            continue"
            },
            "10": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        allTypes[name] = allTypes[english_lower(name)]"
            },
            "11": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        sctypeDict[name] = sctypeDict[english_lower(name)]"
            },
            "12": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 118,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 119,
                "PatchRowcode": " _add_aliases()"
            },
            "14": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 120,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Due to compatibility, numpy has a very large number of different naming",
            "conventions for the scalar types (those subclassing from `numpy.generic`).",
            "This file produces a convoluted set of dictionaries mapping names to types,",
            "and sometimes other mappings too.",
            "",
            ".. data:: allTypes",
            "    A dictionary of names to types that will be exposed as attributes through",
            "    ``np.core.numerictypes.*``",
            "",
            ".. data:: sctypeDict",
            "    Similar to `allTypes`, but maps a broader set of aliases to their types.",
            "",
            ".. data:: sctypes",
            "    A dictionary keyed by a \"type group\" string, providing a list of types",
            "    under that group.",
            "",
            "\"\"\"",
            "",
            "from numpy.compat import unicode",
            "from numpy.core._string_helpers import english_lower",
            "from numpy.core.multiarray import typeinfo, dtype",
            "from numpy.core._dtype import _kind_name",
            "",
            "",
            "sctypeDict = {}      # Contains all leaf-node scalar types with aliases",
            "allTypes = {}            # Collect the types we will add to the module",
            "",
            "",
            "# separate the actual type info from the abstract base classes",
            "_abstract_types = {}",
            "_concrete_typeinfo = {}",
            "for k, v in typeinfo.items():",
            "    # make all the keys lowercase too",
            "    k = english_lower(k)",
            "    if isinstance(v, type):",
            "        _abstract_types[k] = v",
            "    else:",
            "        _concrete_typeinfo[k] = v",
            "",
            "_concrete_types = {v.type for k, v in _concrete_typeinfo.items()}",
            "",
            "",
            "def _bits_of(obj):",
            "    try:",
            "        info = next(v for v in _concrete_typeinfo.values() if v.type is obj)",
            "    except StopIteration:",
            "        if obj in _abstract_types.values():",
            "            msg = \"Cannot count the bits of an abstract type\"",
            "            raise ValueError(msg) from None",
            "",
            "        # some third-party type - make a best-guess",
            "        return dtype(obj).itemsize * 8",
            "    else:",
            "        return info.bits",
            "",
            "",
            "def bitname(obj):",
            "    \"\"\"Return a bit-width name for a given type object\"\"\"",
            "    bits = _bits_of(obj)",
            "    dt = dtype(obj)",
            "    char = dt.kind",
            "    base = _kind_name(dt)",
            "",
            "    if base == 'object':",
            "        bits = 0",
            "",
            "    if bits != 0:",
            "        char = \"%s%d\" % (char, bits // 8)",
            "",
            "    return base, bits, char",
            "",
            "",
            "def _add_types():",
            "    for name, info in _concrete_typeinfo.items():",
            "        # define C-name and insert typenum and typechar references also",
            "        allTypes[name] = info.type",
            "        sctypeDict[name] = info.type",
            "        sctypeDict[info.char] = info.type",
            "        sctypeDict[info.num] = info.type",
            "",
            "    for name, cls in _abstract_types.items():",
            "        allTypes[name] = cls",
            "_add_types()",
            "",
            "# This is the priority order used to assign the bit-sized NPY_INTxx names, which",
            "# must match the order in npy_common.h in order for NPY_INTxx and np.intxx to be",
            "# consistent.",
            "# If two C types have the same size, then the earliest one in this list is used",
            "# as the sized name.",
            "_int_ctypes = ['long', 'longlong', 'int', 'short', 'byte']",
            "_uint_ctypes = list('u' + t for t in _int_ctypes)",
            "",
            "def _add_aliases():",
            "    for name, info in _concrete_typeinfo.items():",
            "        # these are handled by _add_integer_aliases",
            "        if name in _int_ctypes or name in _uint_ctypes:",
            "            continue",
            "",
            "        # insert bit-width version for this class (if relevant)",
            "        base, bit, char = bitname(info.type)",
            "",
            "        myname = \"%s%d\" % (base, bit)",
            "",
            "        # ensure that (c)longdouble does not overwrite the aliases assigned to",
            "        # (c)double",
            "        if name in ('longdouble', 'clongdouble') and myname in allTypes:",
            "            continue",
            "",
            "        allTypes[myname] = info.type",
            "",
            "        # add mapping for both the bit name and the numarray name",
            "        sctypeDict[myname] = info.type",
            "",
            "        # add forward, reverse, and string mapping to numarray",
            "        sctypeDict[char] = info.type",
            "",
            "    # Add deprecated numeric-style type aliases manually, at some point",
            "    # we may want to deprecate the lower case \"bytes0\" version as well.",
            "    for name in [\"Bytes0\", \"Datetime64\", \"Str0\", \"Uint32\", \"Uint64\"]:",
            "        if english_lower(name) not in allTypes:",
            "            # Only one of Uint32 or Uint64, aliases of `np.uintp`, was (and is) defined, note that this",
            "            # is not UInt32/UInt64 (capital i), which is removed.",
            "            continue",
            "        allTypes[name] = allTypes[english_lower(name)]",
            "        sctypeDict[name] = sctypeDict[english_lower(name)]",
            "",
            "_add_aliases()",
            "",
            "def _add_integer_aliases():",
            "    seen_bits = set()",
            "    for i_ctype, u_ctype in zip(_int_ctypes, _uint_ctypes):",
            "        i_info = _concrete_typeinfo[i_ctype]",
            "        u_info = _concrete_typeinfo[u_ctype]",
            "        bits = i_info.bits  # same for both",
            "",
            "        for info, charname, intname in [",
            "                (i_info,'i%d' % (bits//8,), 'int%d' % bits),",
            "                (u_info,'u%d' % (bits//8,), 'uint%d' % bits)]:",
            "            if bits not in seen_bits:",
            "                # sometimes two different types have the same number of bits",
            "                # if so, the one iterated over first takes precedence",
            "                allTypes[intname] = info.type",
            "                sctypeDict[intname] = info.type",
            "                sctypeDict[charname] = info.type",
            "",
            "        seen_bits.add(bits)",
            "",
            "_add_integer_aliases()",
            "",
            "# We use these later",
            "void = allTypes['void']",
            "",
            "#",
            "# Rework the Python names (so that float and complex and int are consistent",
            "#                            with Python usage)",
            "#",
            "def _set_up_aliases():",
            "    type_pairs = [('complex_', 'cdouble'),",
            "                  ('int0', 'intp'),",
            "                  ('uint0', 'uintp'),",
            "                  ('single', 'float'),",
            "                  ('csingle', 'cfloat'),",
            "                  ('singlecomplex', 'cfloat'),",
            "                  ('float_', 'double'),",
            "                  ('intc', 'int'),",
            "                  ('uintc', 'uint'),",
            "                  ('int_', 'long'),",
            "                  ('uint', 'ulong'),",
            "                  ('cfloat', 'cdouble'),",
            "                  ('longfloat', 'longdouble'),",
            "                  ('clongfloat', 'clongdouble'),",
            "                  ('longcomplex', 'clongdouble'),",
            "                  ('bool_', 'bool'),",
            "                  ('bytes_', 'string'),",
            "                  ('string_', 'string'),",
            "                  ('str_', 'unicode'),",
            "                  ('unicode_', 'unicode'),",
            "                  ('object_', 'object')]",
            "    for alias, t in type_pairs:",
            "        allTypes[alias] = allTypes[t]",
            "        sctypeDict[alias] = sctypeDict[t]",
            "    # Remove aliases overriding python types and modules",
            "    to_remove = ['ulong', 'object', 'int', 'float',",
            "                 'complex', 'bool', 'string', 'datetime', 'timedelta',",
            "                 'bytes', 'str']",
            "",
            "    for t in to_remove:",
            "        try:",
            "            del allTypes[t]",
            "            del sctypeDict[t]",
            "        except KeyError:",
            "            pass",
            "_set_up_aliases()",
            "",
            "",
            "sctypes = {'int': [],",
            "           'uint':[],",
            "           'float':[],",
            "           'complex':[],",
            "           'others':[bool, object, bytes, unicode, void]}",
            "",
            "def _add_array_type(typename, bits):",
            "    try:",
            "        t = allTypes['%s%d' % (typename, bits)]",
            "    except KeyError:",
            "        pass",
            "    else:",
            "        sctypes[typename].append(t)",
            "",
            "def _set_array_types():",
            "    ibytes = [1, 2, 4, 8, 16, 32, 64]",
            "    fbytes = [2, 4, 8, 10, 12, 16, 32, 64]",
            "    for bytes in ibytes:",
            "        bits = 8*bytes",
            "        _add_array_type('int', bits)",
            "        _add_array_type('uint', bits)",
            "    for bytes in fbytes:",
            "        bits = 8*bytes",
            "        _add_array_type('float', bits)",
            "        _add_array_type('complex', 2*bits)",
            "    _gi = dtype('p')",
            "    if _gi.type not in sctypes['int']:",
            "        indx = 0",
            "        sz = _gi.itemsize",
            "        _lst = sctypes['int']",
            "        while (indx < len(_lst) and sz >= _lst[indx](0).itemsize):",
            "            indx += 1",
            "        sctypes['int'].insert(indx, _gi.type)",
            "        sctypes['uint'].insert(indx, dtype('P').type)",
            "_set_array_types()",
            "",
            "",
            "# Add additional strings to the sctypeDict",
            "_toadd = ['int', 'float', 'complex', 'bool', 'object',",
            "          'str', 'bytes', ('a', 'bytes_')]",
            "",
            "for name in _toadd:",
            "    if isinstance(name, tuple):",
            "        sctypeDict[name[0]] = allTypes[name[1]]",
            "    else:",
            "        sctypeDict[name] = allTypes['%s_' % name]",
            "",
            "del _toadd, name"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Due to compatibility, numpy has a very large number of different naming",
            "conventions for the scalar types (those subclassing from `numpy.generic`).",
            "This file produces a convoluted set of dictionaries mapping names to types,",
            "and sometimes other mappings too.",
            "",
            ".. data:: allTypes",
            "    A dictionary of names to types that will be exposed as attributes through",
            "    ``np.core.numerictypes.*``",
            "",
            ".. data:: sctypeDict",
            "    Similar to `allTypes`, but maps a broader set of aliases to their types.",
            "",
            ".. data:: sctypes",
            "    A dictionary keyed by a \"type group\" string, providing a list of types",
            "    under that group.",
            "",
            "\"\"\"",
            "",
            "from numpy.compat import unicode",
            "from numpy.core._string_helpers import english_lower",
            "from numpy.core.multiarray import typeinfo, dtype",
            "from numpy.core._dtype import _kind_name",
            "",
            "",
            "sctypeDict = {}      # Contains all leaf-node scalar types with aliases",
            "allTypes = {}            # Collect the types we will add to the module",
            "",
            "",
            "# separate the actual type info from the abstract base classes",
            "_abstract_types = {}",
            "_concrete_typeinfo = {}",
            "for k, v in typeinfo.items():",
            "    # make all the keys lowercase too",
            "    k = english_lower(k)",
            "    if isinstance(v, type):",
            "        _abstract_types[k] = v",
            "    else:",
            "        _concrete_typeinfo[k] = v",
            "",
            "_concrete_types = {v.type for k, v in _concrete_typeinfo.items()}",
            "",
            "",
            "def _bits_of(obj):",
            "    try:",
            "        info = next(v for v in _concrete_typeinfo.values() if v.type is obj)",
            "    except StopIteration:",
            "        if obj in _abstract_types.values():",
            "            msg = \"Cannot count the bits of an abstract type\"",
            "            raise ValueError(msg) from None",
            "",
            "        # some third-party type - make a best-guess",
            "        return dtype(obj).itemsize * 8",
            "    else:",
            "        return info.bits",
            "",
            "",
            "def bitname(obj):",
            "    \"\"\"Return a bit-width name for a given type object\"\"\"",
            "    bits = _bits_of(obj)",
            "    dt = dtype(obj)",
            "    char = dt.kind",
            "    base = _kind_name(dt)",
            "",
            "    if base == 'object':",
            "        bits = 0",
            "",
            "    if bits != 0:",
            "        char = \"%s%d\" % (char, bits // 8)",
            "",
            "    return base, bits, char",
            "",
            "",
            "def _add_types():",
            "    for name, info in _concrete_typeinfo.items():",
            "        # define C-name and insert typenum and typechar references also",
            "        allTypes[name] = info.type",
            "        sctypeDict[name] = info.type",
            "        sctypeDict[info.char] = info.type",
            "        sctypeDict[info.num] = info.type",
            "",
            "    for name, cls in _abstract_types.items():",
            "        allTypes[name] = cls",
            "_add_types()",
            "",
            "# This is the priority order used to assign the bit-sized NPY_INTxx names, which",
            "# must match the order in npy_common.h in order for NPY_INTxx and np.intxx to be",
            "# consistent.",
            "# If two C types have the same size, then the earliest one in this list is used",
            "# as the sized name.",
            "_int_ctypes = ['long', 'longlong', 'int', 'short', 'byte']",
            "_uint_ctypes = list('u' + t for t in _int_ctypes)",
            "",
            "def _add_aliases():",
            "    for name, info in _concrete_typeinfo.items():",
            "        # these are handled by _add_integer_aliases",
            "        if name in _int_ctypes or name in _uint_ctypes:",
            "            continue",
            "",
            "        # insert bit-width version for this class (if relevant)",
            "        base, bit, char = bitname(info.type)",
            "",
            "        myname = \"%s%d\" % (base, bit)",
            "",
            "        # ensure that (c)longdouble does not overwrite the aliases assigned to",
            "        # (c)double",
            "        if name in ('longdouble', 'clongdouble') and myname in allTypes:",
            "            continue",
            "",
            "        allTypes[myname] = info.type",
            "",
            "        # add mapping for both the bit name and the numarray name",
            "        sctypeDict[myname] = info.type",
            "",
            "        # add forward, reverse, and string mapping to numarray",
            "        sctypeDict[char] = info.type",
            "",
            "",
            "_add_aliases()",
            "",
            "def _add_integer_aliases():",
            "    seen_bits = set()",
            "    for i_ctype, u_ctype in zip(_int_ctypes, _uint_ctypes):",
            "        i_info = _concrete_typeinfo[i_ctype]",
            "        u_info = _concrete_typeinfo[u_ctype]",
            "        bits = i_info.bits  # same for both",
            "",
            "        for info, charname, intname in [",
            "                (i_info,'i%d' % (bits//8,), 'int%d' % bits),",
            "                (u_info,'u%d' % (bits//8,), 'uint%d' % bits)]:",
            "            if bits not in seen_bits:",
            "                # sometimes two different types have the same number of bits",
            "                # if so, the one iterated over first takes precedence",
            "                allTypes[intname] = info.type",
            "                sctypeDict[intname] = info.type",
            "                sctypeDict[charname] = info.type",
            "",
            "        seen_bits.add(bits)",
            "",
            "_add_integer_aliases()",
            "",
            "# We use these later",
            "void = allTypes['void']",
            "",
            "#",
            "# Rework the Python names (so that float and complex and int are consistent",
            "#                            with Python usage)",
            "#",
            "def _set_up_aliases():",
            "    type_pairs = [('complex_', 'cdouble'),",
            "                  ('int0', 'intp'),",
            "                  ('uint0', 'uintp'),",
            "                  ('single', 'float'),",
            "                  ('csingle', 'cfloat'),",
            "                  ('singlecomplex', 'cfloat'),",
            "                  ('float_', 'double'),",
            "                  ('intc', 'int'),",
            "                  ('uintc', 'uint'),",
            "                  ('int_', 'long'),",
            "                  ('uint', 'ulong'),",
            "                  ('cfloat', 'cdouble'),",
            "                  ('longfloat', 'longdouble'),",
            "                  ('clongfloat', 'clongdouble'),",
            "                  ('longcomplex', 'clongdouble'),",
            "                  ('bool_', 'bool'),",
            "                  ('bytes_', 'string'),",
            "                  ('string_', 'string'),",
            "                  ('str_', 'unicode'),",
            "                  ('unicode_', 'unicode'),",
            "                  ('object_', 'object')]",
            "    for alias, t in type_pairs:",
            "        allTypes[alias] = allTypes[t]",
            "        sctypeDict[alias] = sctypeDict[t]",
            "    # Remove aliases overriding python types and modules",
            "    to_remove = ['ulong', 'object', 'int', 'float',",
            "                 'complex', 'bool', 'string', 'datetime', 'timedelta',",
            "                 'bytes', 'str']",
            "",
            "    for t in to_remove:",
            "        try:",
            "            del allTypes[t]",
            "            del sctypeDict[t]",
            "        except KeyError:",
            "            pass",
            "_set_up_aliases()",
            "",
            "",
            "sctypes = {'int': [],",
            "           'uint':[],",
            "           'float':[],",
            "           'complex':[],",
            "           'others':[bool, object, bytes, unicode, void]}",
            "",
            "def _add_array_type(typename, bits):",
            "    try:",
            "        t = allTypes['%s%d' % (typename, bits)]",
            "    except KeyError:",
            "        pass",
            "    else:",
            "        sctypes[typename].append(t)",
            "",
            "def _set_array_types():",
            "    ibytes = [1, 2, 4, 8, 16, 32, 64]",
            "    fbytes = [2, 4, 8, 10, 12, 16, 32, 64]",
            "    for bytes in ibytes:",
            "        bits = 8*bytes",
            "        _add_array_type('int', bits)",
            "        _add_array_type('uint', bits)",
            "    for bytes in fbytes:",
            "        bits = 8*bytes",
            "        _add_array_type('float', bits)",
            "        _add_array_type('complex', 2*bits)",
            "    _gi = dtype('p')",
            "    if _gi.type not in sctypes['int']:",
            "        indx = 0",
            "        sz = _gi.itemsize",
            "        _lst = sctypes['int']",
            "        while (indx < len(_lst) and sz >= _lst[indx](0).itemsize):",
            "            indx += 1",
            "        sctypes['int'].insert(indx, _gi.type)",
            "        sctypes['uint'].insert(indx, dtype('P').type)",
            "_set_array_types()",
            "",
            "",
            "# Add additional strings to the sctypeDict",
            "_toadd = ['int', 'float', 'complex', 'bool', 'object',",
            "          'str', 'bytes', ('a', 'bytes_')]",
            "",
            "for name in _toadd:",
            "    if isinstance(name, tuple):",
            "        sctypeDict[name[0]] = allTypes[name[1]]",
            "    else:",
            "        sctypeDict[name] = allTypes['%s_' % name]",
            "",
            "del _toadd, name"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "118": [
                "_add_aliases"
            ],
            "119": [
                "_add_aliases"
            ],
            "120": [
                "_add_aliases"
            ],
            "121": [
                "_add_aliases"
            ],
            "122": [
                "_add_aliases"
            ],
            "123": [
                "_add_aliases"
            ],
            "124": [
                "_add_aliases"
            ],
            "125": [
                "_add_aliases"
            ],
            "126": [
                "_add_aliases"
            ]
        },
        "addLocation": []
    },
    "numpy/core/tests/test_deprecations.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": 314,
                "PatchRowcode": "         self.assert_deprecated(np.binary_repr, args=args, kwargs=kwargs)"
            },
            "1": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": 315,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": 316,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-class TestNumericStyleTypecodes(_DeprecationTestCase):"
            },
            "4": {
                "beforePatchRowNumber": 318,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "5": {
                "beforePatchRowNumber": 319,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    Most numeric style typecodes were previously deprecated (and removed)"
            },
            "6": {
                "beforePatchRowNumber": 320,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    in 1.20. This also deprecates the remaining ones."
            },
            "7": {
                "beforePatchRowNumber": 321,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\""
            },
            "8": {
                "beforePatchRowNumber": 322,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # 2020-06-09, NumPy 1.20"
            },
            "9": {
                "beforePatchRowNumber": 323,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def test_all_dtypes(self):"
            },
            "10": {
                "beforePatchRowNumber": 324,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        deprecated_types = ['Bytes0', 'Datetime64', 'Str0']"
            },
            "11": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Depending on intp size, either Uint32 or Uint64 is defined:"
            },
            "12": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        deprecated_types.append(f\"U{np.dtype(np.intp).name}\")"
            },
            "13": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for dt in deprecated_types:"
            },
            "14": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.assert_deprecated(np.dtype, exceptions=(TypeError,),"
            },
            "15": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                   args=(dt,))"
            },
            "16": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "17": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "18": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 317,
                "PatchRowcode": " class TestDTypeAttributeIsDTypeDeprecation(_DeprecationTestCase):"
            },
            "19": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 318,
                "PatchRowcode": "     # Deprecated 2021-01-05, NumPy 1.21"
            },
            "20": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 319,
                "PatchRowcode": "     message = r\".*`.dtype` attribute\""
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Tests related to deprecation warnings. Also a convenient place",
            "to document how deprecations should eventually be turned into errors.",
            "",
            "\"\"\"",
            "import datetime",
            "import operator",
            "import warnings",
            "import pytest",
            "import tempfile",
            "import re",
            "import sys",
            "",
            "import numpy as np",
            "from numpy.testing import (",
            "    assert_raises, assert_warns, assert_, assert_array_equal, SkipTest, KnownFailureException",
            "    )",
            "",
            "from numpy.core._multiarray_tests import fromstring_null_term_c_api",
            "",
            "try:",
            "    import pytz",
            "    _has_pytz = True",
            "except ImportError:",
            "    _has_pytz = False",
            "",
            "",
            "class _DeprecationTestCase:",
            "    # Just as warning: warnings uses re.match, so the start of this message",
            "    # must match.",
            "    message = ''",
            "    warning_cls = DeprecationWarning",
            "",
            "    def setup(self):",
            "        self.warn_ctx = warnings.catch_warnings(record=True)",
            "        self.log = self.warn_ctx.__enter__()",
            "",
            "        # Do *not* ignore other DeprecationWarnings. Ignoring warnings",
            "        # can give very confusing results because of",
            "        # https://bugs.python.org/issue4180 and it is probably simplest to",
            "        # try to keep the tests cleanly giving only the right warning type.",
            "        # (While checking them set to \"error\" those are ignored anyway)",
            "        # We still have them show up, because otherwise they would be raised",
            "        warnings.filterwarnings(\"always\", category=self.warning_cls)",
            "        warnings.filterwarnings(\"always\", message=self.message,",
            "                                category=self.warning_cls)",
            "",
            "    def teardown(self):",
            "        self.warn_ctx.__exit__()",
            "",
            "    def assert_deprecated(self, function, num=1, ignore_others=False,",
            "                          function_fails=False,",
            "                          exceptions=np._NoValue,",
            "                          args=(), kwargs={}):",
            "        \"\"\"Test if DeprecationWarnings are given and raised.",
            "",
            "        This first checks if the function when called gives `num`",
            "        DeprecationWarnings, after that it tries to raise these",
            "        DeprecationWarnings and compares them with `exceptions`.",
            "        The exceptions can be different for cases where this code path",
            "        is simply not anticipated and the exception is replaced.",
            "",
            "        Parameters",
            "        ----------",
            "        function : callable",
            "            The function to test",
            "        num : int",
            "            Number of DeprecationWarnings to expect. This should normally be 1.",
            "        ignore_others : bool",
            "            Whether warnings of the wrong type should be ignored (note that",
            "            the message is not checked)",
            "        function_fails : bool",
            "            If the function would normally fail, setting this will check for",
            "            warnings inside a try/except block.",
            "        exceptions : Exception or tuple of Exceptions",
            "            Exception to expect when turning the warnings into an error.",
            "            The default checks for DeprecationWarnings. If exceptions is",
            "            empty the function is expected to run successfully.",
            "        args : tuple",
            "            Arguments for `function`",
            "        kwargs : dict",
            "            Keyword arguments for `function`",
            "        \"\"\"",
            "        __tracebackhide__ = True  # Hide traceback for py.test",
            "",
            "        # reset the log",
            "        self.log[:] = []",
            "",
            "        if exceptions is np._NoValue:",
            "            exceptions = (self.warning_cls,)",
            "",
            "        try:",
            "            function(*args, **kwargs)",
            "        except (Exception if function_fails else tuple()):",
            "            pass",
            "",
            "        # just in case, clear the registry",
            "        num_found = 0",
            "        for warning in self.log:",
            "            if warning.category is self.warning_cls:",
            "                num_found += 1",
            "            elif not ignore_others:",
            "                raise AssertionError(",
            "                        \"expected %s but got: %s\" %",
            "                        (self.warning_cls.__name__, warning.category))",
            "        if num is not None and num_found != num:",
            "            msg = \"%i warnings found but %i expected.\" % (len(self.log), num)",
            "            lst = [str(w) for w in self.log]",
            "            raise AssertionError(\"\\n\".join([msg] + lst))",
            "",
            "        with warnings.catch_warnings():",
            "            warnings.filterwarnings(\"error\", message=self.message,",
            "                                    category=self.warning_cls)",
            "            try:",
            "                function(*args, **kwargs)",
            "                if exceptions != tuple():",
            "                    raise AssertionError(",
            "                            \"No error raised during function call\")",
            "            except exceptions:",
            "                if exceptions == tuple():",
            "                    raise AssertionError(",
            "                            \"Error raised during function call\")",
            "",
            "    def assert_not_deprecated(self, function, args=(), kwargs={}):",
            "        \"\"\"Test that warnings are not raised.",
            "",
            "        This is just a shorthand for:",
            "",
            "        self.assert_deprecated(function, num=0, ignore_others=True,",
            "                        exceptions=tuple(), args=args, kwargs=kwargs)",
            "        \"\"\"",
            "        self.assert_deprecated(function, num=0, ignore_others=True,",
            "                        exceptions=tuple(), args=args, kwargs=kwargs)",
            "",
            "",
            "class _VisibleDeprecationTestCase(_DeprecationTestCase):",
            "    warning_cls = np.VisibleDeprecationWarning",
            "",
            "",
            "class TestNonTupleNDIndexDeprecation:",
            "    def test_basic(self):",
            "        a = np.zeros((5, 5))",
            "        with warnings.catch_warnings():",
            "            warnings.filterwarnings('always')",
            "            assert_warns(FutureWarning, a.__getitem__, [[0, 1], [0, 1]])",
            "            assert_warns(FutureWarning, a.__getitem__, [slice(None)])",
            "",
            "            warnings.filterwarnings('error')",
            "            assert_raises(FutureWarning, a.__getitem__, [[0, 1], [0, 1]])",
            "            assert_raises(FutureWarning, a.__getitem__, [slice(None)])",
            "",
            "            # a a[[0, 1]] always was advanced indexing, so no error/warning",
            "            a[[0, 1]]",
            "",
            "",
            "class TestComparisonDeprecations(_DeprecationTestCase):",
            "    \"\"\"This tests the deprecation, for non-element-wise comparison logic.",
            "    This used to mean that when an error occurred during element-wise comparison",
            "    (i.e. broadcasting) NotImplemented was returned, but also in the comparison",
            "    itself, False was given instead of the error.",
            "",
            "    Also test FutureWarning for the None comparison.",
            "    \"\"\"",
            "",
            "    message = \"elementwise.* comparison failed; .*\"",
            "",
            "    def test_normal_types(self):",
            "        for op in (operator.eq, operator.ne):",
            "            # Broadcasting errors:",
            "            self.assert_deprecated(op, args=(np.zeros(3), []))",
            "            a = np.zeros(3, dtype='i,i')",
            "            # (warning is issued a couple of times here)",
            "            self.assert_deprecated(op, args=(a, a[:-1]), num=None)",
            "",
            "            # ragged array comparison returns True/False",
            "            a = np.array([1, np.array([1,2,3])], dtype=object)",
            "            b = np.array([1, np.array([1,2,3])], dtype=object)",
            "            self.assert_deprecated(op, args=(a, b), num=None)",
            "",
            "    def test_string(self):",
            "        # For two string arrays, strings always raised the broadcasting error:",
            "        a = np.array(['a', 'b'])",
            "        b = np.array(['a', 'b', 'c'])",
            "        assert_raises(ValueError, lambda x, y: x == y, a, b)",
            "",
            "        # The empty list is not cast to string, and this used to pass due",
            "        # to dtype mismatch; now (2018-06-21) it correctly leads to a",
            "        # FutureWarning.",
            "        assert_warns(FutureWarning, lambda: a == [])",
            "",
            "    def test_void_dtype_equality_failures(self):",
            "        class NotArray:",
            "            def __array__(self):",
            "                raise TypeError",
            "",
            "            # Needed so Python 3 does not raise DeprecationWarning twice.",
            "            def __ne__(self, other):",
            "                return NotImplemented",
            "",
            "        self.assert_deprecated(lambda: np.arange(2) == NotArray())",
            "        self.assert_deprecated(lambda: np.arange(2) != NotArray())",
            "",
            "        struct1 = np.zeros(2, dtype=\"i4,i4\")",
            "        struct2 = np.zeros(2, dtype=\"i4,i4,i4\")",
            "",
            "        assert_warns(FutureWarning, lambda: struct1 == 1)",
            "        assert_warns(FutureWarning, lambda: struct1 == struct2)",
            "        assert_warns(FutureWarning, lambda: struct1 != 1)",
            "        assert_warns(FutureWarning, lambda: struct1 != struct2)",
            "",
            "    def test_array_richcompare_legacy_weirdness(self):",
            "        # It doesn't really work to use assert_deprecated here, b/c part of",
            "        # the point of assert_deprecated is to check that when warnings are",
            "        # set to \"error\" mode then the error is propagated -- which is good!",
            "        # But here we are testing a bunch of code that is deprecated *because*",
            "        # it has the habit of swallowing up errors and converting them into",
            "        # different warnings. So assert_warns will have to be sufficient.",
            "        assert_warns(FutureWarning, lambda: np.arange(2) == \"a\")",
            "        assert_warns(FutureWarning, lambda: np.arange(2) != \"a\")",
            "        # No warning for scalar comparisons",
            "        with warnings.catch_warnings():",
            "            warnings.filterwarnings(\"error\")",
            "            assert_(not (np.array(0) == \"a\"))",
            "            assert_(np.array(0) != \"a\")",
            "            assert_(not (np.int16(0) == \"a\"))",
            "            assert_(np.int16(0) != \"a\")",
            "",
            "        for arg1 in [np.asarray(0), np.int16(0)]:",
            "            struct = np.zeros(2, dtype=\"i4,i4\")",
            "            for arg2 in [struct, \"a\"]:",
            "                for f in [operator.lt, operator.le, operator.gt, operator.ge]:",
            "                    with warnings.catch_warnings() as l:",
            "                        warnings.filterwarnings(\"always\")",
            "                        assert_raises(TypeError, f, arg1, arg2)",
            "                        assert_(not l)",
            "",
            "",
            "class TestDatetime64Timezone(_DeprecationTestCase):",
            "    \"\"\"Parsing of datetime64 with timezones deprecated in 1.11.0, because",
            "    datetime64 is now timezone naive rather than UTC only.",
            "",
            "    It will be quite a while before we can remove this, because, at the very",
            "    least, a lot of existing code uses the 'Z' modifier to avoid conversion",
            "    from local time to UTC, even if otherwise it handles time in a timezone",
            "    naive fashion.",
            "    \"\"\"",
            "    def test_string(self):",
            "        self.assert_deprecated(np.datetime64, args=('2000-01-01T00+01',))",
            "        self.assert_deprecated(np.datetime64, args=('2000-01-01T00Z',))",
            "",
            "    @pytest.mark.skipif(not _has_pytz,",
            "                        reason=\"The pytz module is not available.\")",
            "    def test_datetime(self):",
            "        tz = pytz.timezone('US/Eastern')",
            "        dt = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=tz)",
            "        self.assert_deprecated(np.datetime64, args=(dt,))",
            "",
            "",
            "class TestNonCContiguousViewDeprecation(_DeprecationTestCase):",
            "    \"\"\"View of non-C-contiguous arrays deprecated in 1.11.0.",
            "",
            "    The deprecation will not be raised for arrays that are both C and F",
            "    contiguous, as C contiguous is dominant. There are more such arrays",
            "    with relaxed stride checking than without so the deprecation is not",
            "    as visible with relaxed stride checking in force.",
            "    \"\"\"",
            "",
            "    def test_fortran_contiguous(self):",
            "        self.assert_deprecated(np.ones((2,2)).T.view, args=(complex,))",
            "        self.assert_deprecated(np.ones((2,2)).T.view, args=(np.int8,))",
            "",
            "",
            "class TestArrayDataAttributeAssignmentDeprecation(_DeprecationTestCase):",
            "    \"\"\"Assigning the 'data' attribute of an ndarray is unsafe as pointed",
            "     out in gh-7093. Eventually, such assignment should NOT be allowed, but",
            "     in the interests of maintaining backwards compatibility, only a Deprecation-",
            "     Warning will be raised instead for the time being to give developers time to",
            "     refactor relevant code.",
            "    \"\"\"",
            "",
            "    def test_data_attr_assignment(self):",
            "        a = np.arange(10)",
            "        b = np.linspace(0, 1, 10)",
            "",
            "        self.message = (\"Assigning the 'data' attribute is an \"",
            "                        \"inherently unsafe operation and will \"",
            "                        \"be removed in the future.\")",
            "        self.assert_deprecated(a.__setattr__, args=('data', b.data))",
            "",
            "",
            "class TestBinaryReprInsufficientWidthParameterForRepresentation(_DeprecationTestCase):",
            "    \"\"\"",
            "    If a 'width' parameter is passed into ``binary_repr`` that is insufficient to",
            "    represent the number in base 2 (positive) or 2's complement (negative) form,",
            "    the function used to silently ignore the parameter and return a representation",
            "    using the minimal number of bits needed for the form in question. Such behavior",
            "    is now considered unsafe from a user perspective and will raise an error in the future.",
            "    \"\"\"",
            "",
            "    def test_insufficient_width_positive(self):",
            "        args = (10,)",
            "        kwargs = {'width': 2}",
            "",
            "        self.message = (\"Insufficient bit width provided. This behavior \"",
            "                        \"will raise an error in the future.\")",
            "        self.assert_deprecated(np.binary_repr, args=args, kwargs=kwargs)",
            "",
            "    def test_insufficient_width_negative(self):",
            "        args = (-5,)",
            "        kwargs = {'width': 2}",
            "",
            "        self.message = (\"Insufficient bit width provided. This behavior \"",
            "                        \"will raise an error in the future.\")",
            "        self.assert_deprecated(np.binary_repr, args=args, kwargs=kwargs)",
            "",
            "",
            "class TestNumericStyleTypecodes(_DeprecationTestCase):",
            "    \"\"\"",
            "    Most numeric style typecodes were previously deprecated (and removed)",
            "    in 1.20. This also deprecates the remaining ones.",
            "    \"\"\"",
            "    # 2020-06-09, NumPy 1.20",
            "    def test_all_dtypes(self):",
            "        deprecated_types = ['Bytes0', 'Datetime64', 'Str0']",
            "        # Depending on intp size, either Uint32 or Uint64 is defined:",
            "        deprecated_types.append(f\"U{np.dtype(np.intp).name}\")",
            "        for dt in deprecated_types:",
            "            self.assert_deprecated(np.dtype, exceptions=(TypeError,),",
            "                                   args=(dt,))",
            "",
            "",
            "class TestDTypeAttributeIsDTypeDeprecation(_DeprecationTestCase):",
            "    # Deprecated 2021-01-05, NumPy 1.21",
            "    message = r\".*`.dtype` attribute\"",
            "",
            "    def test_deprecation_dtype_attribute_is_dtype(self):",
            "        class dt:",
            "            dtype = \"f8\"",
            "",
            "        class vdt(np.void):",
            "            dtype = \"f,f\"",
            "",
            "        self.assert_deprecated(lambda: np.dtype(dt))",
            "        self.assert_deprecated(lambda: np.dtype(dt()))",
            "        self.assert_deprecated(lambda: np.dtype(vdt))",
            "        self.assert_deprecated(lambda: np.dtype(vdt(1)))",
            "",
            "",
            "class TestTestDeprecated:",
            "    def test_assert_deprecated(self):",
            "        test_case_instance = _DeprecationTestCase()",
            "        test_case_instance.setup()",
            "        assert_raises(AssertionError,",
            "                      test_case_instance.assert_deprecated,",
            "                      lambda: None)",
            "",
            "        def foo():",
            "            warnings.warn(\"foo\", category=DeprecationWarning, stacklevel=2)",
            "",
            "        test_case_instance.assert_deprecated(foo)",
            "        test_case_instance.teardown()",
            "",
            "",
            "class TestNonNumericConjugate(_DeprecationTestCase):",
            "    \"\"\"",
            "    Deprecate no-op behavior of ndarray.conjugate on non-numeric dtypes,",
            "    which conflicts with the error behavior of np.conjugate.",
            "    \"\"\"",
            "    def test_conjugate(self):",
            "        for a in np.array(5), np.array(5j):",
            "            self.assert_not_deprecated(a.conjugate)",
            "        for a in (np.array('s'), np.array('2016', 'M'),",
            "                np.array((1, 2), [('a', int), ('b', int)])):",
            "            self.assert_deprecated(a.conjugate)",
            "",
            "",
            "class TestNPY_CHAR(_DeprecationTestCase):",
            "    # 2017-05-03, 1.13.0",
            "    def test_npy_char_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_char_deprecation",
            "        self.assert_deprecated(npy_char_deprecation)",
            "        assert_(npy_char_deprecation() == 'S1')",
            "",
            "",
            "class TestPyArray_AS1D(_DeprecationTestCase):",
            "    def test_npy_pyarrayas1d_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_pyarrayas1d_deprecation",
            "        assert_raises(NotImplementedError, npy_pyarrayas1d_deprecation)",
            "",
            "",
            "class TestPyArray_AS2D(_DeprecationTestCase):",
            "    def test_npy_pyarrayas2d_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_pyarrayas2d_deprecation",
            "        assert_raises(NotImplementedError, npy_pyarrayas2d_deprecation)",
            "",
            "",
            "class Test_UPDATEIFCOPY(_DeprecationTestCase):",
            "    \"\"\"",
            "    v1.14 deprecates creating an array with the UPDATEIFCOPY flag, use",
            "    WRITEBACKIFCOPY instead",
            "    \"\"\"",
            "    def test_npy_updateifcopy_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_updateifcopy_deprecation",
            "        arr = np.arange(9).reshape(3, 3)",
            "        v = arr.T",
            "        self.assert_deprecated(npy_updateifcopy_deprecation, args=(v,))",
            "",
            "",
            "class TestDatetimeEvent(_DeprecationTestCase):",
            "    # 2017-08-11, 1.14.0",
            "    def test_3_tuple(self):",
            "        for cls in (np.datetime64, np.timedelta64):",
            "            # two valid uses - (unit, num) and (unit, num, den, None)",
            "            self.assert_not_deprecated(cls, args=(1, ('ms', 2)))",
            "            self.assert_not_deprecated(cls, args=(1, ('ms', 2, 1, None)))",
            "",
            "            # trying to use the event argument, removed in 1.7.0, is deprecated",
            "            # it used to be a uint8",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 'event')))",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 63)))",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 1, 'event')))",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 1, 63)))",
            "",
            "",
            "class TestTruthTestingEmptyArrays(_DeprecationTestCase):",
            "    # 2017-09-25, 1.14.0",
            "    message = '.*truth value of an empty array is ambiguous.*'",
            "",
            "    def test_1d(self):",
            "        self.assert_deprecated(bool, args=(np.array([]),))",
            "",
            "    def test_2d(self):",
            "        self.assert_deprecated(bool, args=(np.zeros((1, 0)),))",
            "        self.assert_deprecated(bool, args=(np.zeros((0, 1)),))",
            "        self.assert_deprecated(bool, args=(np.zeros((0, 0)),))",
            "",
            "",
            "class TestBincount(_DeprecationTestCase):",
            "    # 2017-06-01, 1.14.0",
            "    def test_bincount_minlength(self):",
            "        self.assert_deprecated(lambda: np.bincount([1, 2, 3], minlength=None))",
            "",
            "",
            "class TestAlen(_DeprecationTestCase):",
            "    # 2019-08-02, 1.18.0",
            "    def test_alen(self):",
            "        self.assert_deprecated(lambda: np.alen(np.array([1, 2, 3])))",
            "",
            "",
            "class TestGeneratorSum(_DeprecationTestCase):",
            "    # 2018-02-25, 1.15.0",
            "    def test_generator_sum(self):",
            "        self.assert_deprecated(np.sum, args=((i for i in range(5)),))",
            "",
            "",
            "class TestPositiveOnNonNumerical(_DeprecationTestCase):",
            "    # 2018-06-28, 1.16.0",
            "    def test_positive_on_non_number(self):",
            "        self.assert_deprecated(operator.pos, args=(np.array('foo'),))",
            "",
            "",
            "class TestFromstring(_DeprecationTestCase):",
            "    # 2017-10-19, 1.14",
            "    def test_fromstring(self):",
            "        self.assert_deprecated(np.fromstring, args=('\\x00'*80,))",
            "",
            "",
            "class TestFromStringAndFileInvalidData(_DeprecationTestCase):",
            "    # 2019-06-08, 1.17.0",
            "    # Tests should be moved to real tests when deprecation is done.",
            "    message = \"string or file could not be read to its end\"",
            "",
            "    @pytest.mark.parametrize(\"invalid_str\", [\",invalid_data\", \"invalid_sep\"])",
            "    def test_deprecate_unparsable_data_file(self, invalid_str):",
            "        x = np.array([1.51, 2, 3.51, 4], dtype=float)",
            "",
            "        with tempfile.TemporaryFile(mode=\"w\") as f:",
            "            x.tofile(f, sep=',', format='%.2f')",
            "            f.write(invalid_str)",
            "",
            "            f.seek(0)",
            "            self.assert_deprecated(lambda: np.fromfile(f, sep=\",\"))",
            "            f.seek(0)",
            "            self.assert_deprecated(lambda: np.fromfile(f, sep=\",\", count=5))",
            "            # Should not raise:",
            "            with warnings.catch_warnings():",
            "                warnings.simplefilter(\"error\", DeprecationWarning)",
            "                f.seek(0)",
            "                res = np.fromfile(f, sep=\",\", count=4)",
            "                assert_array_equal(res, x)",
            "",
            "    @pytest.mark.parametrize(\"invalid_str\", [\",invalid_data\", \"invalid_sep\"])",
            "    def test_deprecate_unparsable_string(self, invalid_str):",
            "        x = np.array([1.51, 2, 3.51, 4], dtype=float)",
            "        x_str = \"1.51,2,3.51,4{}\".format(invalid_str)",
            "",
            "        self.assert_deprecated(lambda: np.fromstring(x_str, sep=\",\"))",
            "        self.assert_deprecated(lambda: np.fromstring(x_str, sep=\",\", count=5))",
            "",
            "        # The C-level API can use not fixed size, but 0 terminated strings,",
            "        # so test that as well:",
            "        bytestr = x_str.encode(\"ascii\")",
            "        self.assert_deprecated(lambda: fromstring_null_term_c_api(bytestr))",
            "",
            "        with assert_warns(DeprecationWarning):",
            "            # this is slightly strange, in that fromstring leaves data",
            "            # potentially uninitialized (would be good to error when all is",
            "            # read, but count is larger then actual data maybe).",
            "            res = np.fromstring(x_str, sep=\",\", count=5)",
            "            assert_array_equal(res[:-1], x)",
            "",
            "        with warnings.catch_warnings():",
            "            warnings.simplefilter(\"error\", DeprecationWarning)",
            "",
            "            # Should not raise:",
            "            res = np.fromstring(x_str, sep=\",\", count=4)",
            "            assert_array_equal(res, x)",
            "",
            "",
            "class Test_GetSet_NumericOps(_DeprecationTestCase):",
            "    # 2018-09-20, 1.16.0",
            "    def test_get_numeric_ops(self):",
            "        from numpy.core._multiarray_tests import getset_numericops",
            "        self.assert_deprecated(getset_numericops, num=2)",
            "",
            "        # empty kwargs prevents any state actually changing which would break",
            "        # other tests.",
            "        self.assert_deprecated(np.set_numeric_ops, kwargs={})",
            "        assert_raises(ValueError, np.set_numeric_ops, add='abc')",
            "",
            "",
            "class TestShape1Fields(_DeprecationTestCase):",
            "    warning_cls = FutureWarning",
            "",
            "    # 2019-05-20, 1.17.0",
            "    def test_shape_1_fields(self):",
            "        self.assert_deprecated(np.dtype, args=([('a', int, 1)],))",
            "",
            "",
            "class TestNonZero(_DeprecationTestCase):",
            "    # 2019-05-26, 1.17.0",
            "    def test_zerod(self):",
            "        self.assert_deprecated(lambda: np.nonzero(np.array(0)))",
            "        self.assert_deprecated(lambda: np.nonzero(np.array(1)))",
            "",
            "",
            "def test_deprecate_ragged_arrays():",
            "    # 2019-11-29 1.19.0",
            "    #",
            "    # NEP 34 deprecated automatic object dtype when creating ragged",
            "    # arrays. Also see the \"ragged\" tests in `test_multiarray`",
            "    #",
            "    # emits a VisibleDeprecationWarning",
            "    arg = [1, [2, 3]]",
            "    with assert_warns(np.VisibleDeprecationWarning):",
            "        np.array(arg)",
            "",
            "",
            "class TestTooDeepDeprecation(_VisibleDeprecationTestCase):",
            "    # NumPy 1.20, 2020-05-08",
            "    # This is a bit similar to the above ragged array deprecation case.",
            "    message = re.escape(\"Creating an ndarray from nested sequences exceeding\")",
            "",
            "    def test_deprecation(self):",
            "        nested = [1]",
            "        for i in range(np.MAXDIMS - 1):",
            "            nested = [nested]",
            "        self.assert_not_deprecated(np.array, args=(nested,))",
            "        self.assert_not_deprecated(np.array,",
            "                args=(nested,), kwargs=dict(dtype=object))",
            "",
            "        self.assert_deprecated(np.array, args=([nested],))",
            "",
            "",
            "class TestToString(_DeprecationTestCase):",
            "    # 2020-03-06 1.19.0",
            "    message = re.escape(\"tostring() is deprecated. Use tobytes() instead.\")",
            "",
            "    def test_tostring(self):",
            "        arr = np.array(list(b\"test\\xFF\"), dtype=np.uint8)",
            "        self.assert_deprecated(arr.tostring)",
            "",
            "    def test_tostring_matches_tobytes(self):",
            "        arr = np.array(list(b\"test\\xFF\"), dtype=np.uint8)",
            "        b = arr.tobytes()",
            "        with assert_warns(DeprecationWarning):",
            "            s = arr.tostring()",
            "        assert s == b",
            "",
            "",
            "class TestDTypeCoercion(_DeprecationTestCase):",
            "    # 2020-02-06 1.19.0",
            "    message = \"Converting .* to a dtype .*is deprecated\"",
            "    deprecated_types = [",
            "        # The builtin scalar super types:",
            "        np.generic, np.flexible, np.number,",
            "        np.inexact, np.floating, np.complexfloating,",
            "        np.integer, np.unsignedinteger, np.signedinteger,",
            "        # character is a deprecated S1 special case:",
            "        np.character,",
            "    ]",
            "",
            "    def test_dtype_coercion(self):",
            "        for scalar_type in self.deprecated_types:",
            "            self.assert_deprecated(np.dtype, args=(scalar_type,))",
            "",
            "    def test_array_construction(self):",
            "        for scalar_type in self.deprecated_types:",
            "            self.assert_deprecated(np.array, args=([], scalar_type,))",
            "",
            "    def test_not_deprecated(self):",
            "        # All specific types are not deprecated:",
            "        for group in np.sctypes.values():",
            "            for scalar_type in group:",
            "                self.assert_not_deprecated(np.dtype, args=(scalar_type,))",
            "",
            "        for scalar_type in [type, dict, list, tuple]:",
            "            # Typical python types are coerced to object currently:",
            "            self.assert_not_deprecated(np.dtype, args=(scalar_type,))",
            "",
            "",
            "class BuiltInRoundComplexDType(_DeprecationTestCase):",
            "    # 2020-03-31 1.19.0",
            "    deprecated_types = [np.csingle, np.cdouble, np.clongdouble]",
            "    not_deprecated_types = [",
            "        np.int8, np.int16, np.int32, np.int64,",
            "        np.uint8, np.uint16, np.uint32, np.uint64,",
            "        np.float16, np.float32, np.float64,",
            "    ]",
            "",
            "    def test_deprecated(self):",
            "        for scalar_type in self.deprecated_types:",
            "            scalar = scalar_type(0)",
            "            self.assert_deprecated(round, args=(scalar,))",
            "            self.assert_deprecated(round, args=(scalar, 0))",
            "            self.assert_deprecated(round, args=(scalar,), kwargs={'ndigits': 0})",
            "",
            "    def test_not_deprecated(self):",
            "        for scalar_type in self.not_deprecated_types:",
            "            scalar = scalar_type(0)",
            "            self.assert_not_deprecated(round, args=(scalar,))",
            "            self.assert_not_deprecated(round, args=(scalar, 0))",
            "            self.assert_not_deprecated(round, args=(scalar,), kwargs={'ndigits': 0})",
            "",
            "",
            "class TestIncorrectAdvancedIndexWithEmptyResult(_DeprecationTestCase):",
            "    # 2020-05-27, NumPy 1.20.0",
            "    message = \"Out of bound index found. This was previously ignored.*\"",
            "",
            "    @pytest.mark.parametrize(\"index\", [([3, 0],), ([0, 0], [3, 0])])",
            "    def test_empty_subspace(self, index):",
            "        # Test for both a single and two/multiple advanced indices. These",
            "        # This will raise an IndexError in the future.",
            "        arr = np.ones((2, 2, 0))",
            "        self.assert_deprecated(arr.__getitem__, args=(index,))",
            "        self.assert_deprecated(arr.__setitem__, args=(index, 0.))",
            "",
            "        # for this array, the subspace is only empty after applying the slice",
            "        arr2 = np.ones((2, 2, 1))",
            "        index2 = (slice(0, 0),) + index",
            "        self.assert_deprecated(arr2.__getitem__, args=(index2,))",
            "        self.assert_deprecated(arr2.__setitem__, args=(index2, 0.))",
            "",
            "    def test_empty_index_broadcast_not_deprecated(self):",
            "        arr = np.ones((2, 2, 2))",
            "",
            "        index = ([[3], [2]], [])  # broadcast to an empty result.",
            "        self.assert_not_deprecated(arr.__getitem__, args=(index,))",
            "        self.assert_not_deprecated(arr.__setitem__,",
            "                                   args=(index, np.empty((2, 0, 2))))",
            "",
            "",
            "class TestNonExactMatchDeprecation(_DeprecationTestCase):",
            "    # 2020-04-22",
            "    def test_non_exact_match(self):",
            "        arr = np.array([[3, 6, 6], [4, 5, 1]])",
            "        # misspelt mode check",
            "        self.assert_deprecated(lambda: np.ravel_multi_index(arr, (7, 6), mode='Cilp'))",
            "        # using completely different word with first character as R",
            "        self.assert_deprecated(lambda: np.searchsorted(arr[0], 4, side='Random'))",
            "",
            "",
            "class TestDeprecatedGlobals(_DeprecationTestCase):",
            "    # 2020-06-06",
            "    @pytest.mark.skipif(",
            "        sys.version_info < (3, 7),",
            "        reason='module-level __getattr__ not supported')",
            "    def test_type_aliases(self):",
            "        # from builtins",
            "        self.assert_deprecated(lambda: np.bool(True))",
            "        self.assert_deprecated(lambda: np.int(1))",
            "        self.assert_deprecated(lambda: np.float(1))",
            "        self.assert_deprecated(lambda: np.complex(1))",
            "        self.assert_deprecated(lambda: np.object())",
            "        self.assert_deprecated(lambda: np.str('abc'))",
            "",
            "        # from np.compat",
            "        self.assert_deprecated(lambda: np.long(1))",
            "        self.assert_deprecated(lambda: np.unicode('abc'))",
            "",
            "        # from np.core.numerictypes",
            "        self.assert_deprecated(lambda: np.typeDict)",
            "",
            "",
            "class TestMatrixInOuter(_DeprecationTestCase):",
            "    # 2020-05-13 NumPy 1.20.0",
            "    message = (r\"add.outer\\(\\) was passed a numpy matrix as \"",
            "               r\"(first|second) argument.\")",
            "",
            "    def test_deprecated(self):",
            "        arr = np.array([1, 2, 3])",
            "        m = np.array([1, 2, 3]).view(np.matrix)",
            "        self.assert_deprecated(np.add.outer, args=(m, m), num=2)",
            "        self.assert_deprecated(np.add.outer, args=(arr, m))",
            "        self.assert_deprecated(np.add.outer, args=(m, arr))",
            "        self.assert_not_deprecated(np.add.outer, args=(arr, arr))",
            "",
            "",
            "class TestRaggedArray(_DeprecationTestCase):",
            "    # 2020-07-24, NumPy 1.20.0",
            "    message = \"setting an array element with a sequence\"",
            "",
            "    def test_deprecated(self):",
            "        arr = np.ones((1, 1))",
            "        # Deprecated if the array is a leave node:",
            "        self.assert_deprecated(lambda: np.array([arr, 0], dtype=np.float64))",
            "        self.assert_deprecated(lambda: np.array([0, arr], dtype=np.float64))",
            "        # And when it is an assignment into a lower dimensional subarray:",
            "        self.assert_deprecated(lambda: np.array([arr, [0]], dtype=np.float64))",
            "        self.assert_deprecated(lambda: np.array([[0], arr], dtype=np.float64))",
            "",
            "",
            "class FlatteningConcatenateUnsafeCast(_DeprecationTestCase):",
            "    # NumPy 1.20, 2020-09-03",
            "    message = \"concatenate with `axis=None` will use same-kind casting\"",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(np.concatenate,",
            "                args=(([0.], [1.]),),",
            "                kwargs=dict(axis=None, out=np.empty(2, dtype=np.int64)))",
            "",
            "    def test_not_deprecated(self):",
            "        self.assert_not_deprecated(np.concatenate,",
            "                args=(([0.], [1.]),),",
            "                kwargs={'axis': None, 'out': np.empty(2, dtype=np.int64),",
            "                        'casting': \"unsafe\"})",
            "",
            "        with assert_raises(TypeError):",
            "            # Tests should notice if the deprecation warning is given first...",
            "            np.concatenate(([0.], [1.]), out=np.empty(2, dtype=np.int64),",
            "                           casting=\"same_kind\")",
            "",
            "",
            "class TestDeprecateSubarrayDTypeDuringArrayCoercion(_DeprecationTestCase):",
            "    warning_cls = FutureWarning",
            "    message = \"(creating|casting) an array (with|to) a subarray dtype\"",
            "",
            "    def test_deprecated_array(self):",
            "        # Arrays are more complex, since they \"broadcast\" on success:",
            "        arr = np.array([1, 2])",
            "",
            "        self.assert_deprecated(lambda: arr.astype(\"(2)i,\"))",
            "        with pytest.warns(FutureWarning):",
            "            res = arr.astype(\"(2)i,\")",
            "",
            "        assert_array_equal(res, [[1, 2], [1, 2]])",
            "",
            "        self.assert_deprecated(lambda: np.array(arr, dtype=\"(2)i,\"))",
            "        with pytest.warns(FutureWarning):",
            "            res = np.array(arr, dtype=\"(2)i,\")",
            "",
            "        assert_array_equal(res, [[1, 2], [1, 2]])",
            "",
            "        with pytest.warns(FutureWarning):",
            "            res = np.array([[(1,), (2,)], arr], dtype=\"(2)i,\")",
            "",
            "        assert_array_equal(res, [[[1, 1], [2, 2]], [[1, 2], [1, 2]]])",
            "",
            "    def test_deprecated_and_error(self):",
            "        # These error paths do not give a warning, but will succeed in the",
            "        # future.",
            "        arr = np.arange(5 * 2).reshape(5, 2)",
            "        def check():",
            "            with pytest.raises(ValueError):",
            "                arr.astype(\"(2,2)f\")",
            "",
            "        self.assert_deprecated(check)",
            "",
            "        def check():",
            "            with pytest.raises(ValueError):",
            "                np.array(arr, dtype=\"(2,2)f\")",
            "",
            "        self.assert_deprecated(check)",
            "",
            "",
            "class TestFutureWarningArrayLikeNotIterable(_DeprecationTestCase):",
            "    # Deprecated 2020-12-09, NumPy 1.20",
            "    warning_cls = FutureWarning",
            "    message = \"The input object of type.*but not a sequence\"",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "            [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_deprecated(self, protocol):",
            "        \"\"\"Test that these objects give a warning since they are not 0-D,",
            "        not coerced at the top level `np.array(obj)`, but nested, and do",
            "        *not* define the sequence protocol.",
            "",
            "        NOTE: Tests for the versions including __len__ and __getitem__ exist",
            "              in `test_array_coercion.py` and they can be modified or ammended",
            "              when this deprecation expired.",
            "        \"\"\"",
            "        blueprint = np.arange(10)",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol)})",
            "        self.assert_deprecated(lambda: np.array([MyArr()], dtype=object))",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_0d_not_deprecated(self, protocol):",
            "        # 0-D always worked (albeit it would use __float__ or similar for the",
            "        # conversion, which may not happen anymore)",
            "        blueprint = np.array(1.)",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol)})",
            "        myarr = MyArr()",
            "",
            "        self.assert_not_deprecated(lambda: np.array([myarr], dtype=object))",
            "        res = np.array([myarr], dtype=object)",
            "        expected = np.empty(1, dtype=object)",
            "        expected[0] = myarr",
            "        assert_array_equal(res, expected)",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_unnested_not_deprecated(self, protocol):",
            "        blueprint = np.arange(10)",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol)})",
            "        myarr = MyArr()",
            "",
            "        self.assert_not_deprecated(lambda: np.array(myarr))",
            "        res = np.array(myarr)",
            "        assert_array_equal(res, blueprint)",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_strange_dtype_handling(self, protocol):",
            "        \"\"\"The old code would actually use the dtype from the array, but",
            "        then end up not using the array (for dimension discovery)",
            "        \"\"\"",
            "        blueprint = np.arange(10).astype(\"f4\")",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol),",
            "                                   \"__float__\": lambda _: 0.5})",
            "        myarr = MyArr()",
            "",
            "        # Make sure we warn (and capture the FutureWarning)",
            "        with pytest.warns(FutureWarning, match=self.message):",
            "            res = np.array([[myarr]])",
            "",
            "        assert res.shape == (1, 1)",
            "        assert res.dtype == \"f4\"",
            "        assert res[0, 0] == 0.5",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_assignment_not_deprecated(self, protocol):",
            "        # If the result is dtype=object we do not unpack a nested array or",
            "        # array-like, if it is nested at exactly the right depth.",
            "        # NOTE: We actually do still call __array__, etc. but ignore the result",
            "        #       in the end. For `dtype=object` we could optimize that away.",
            "        blueprint = np.arange(10).astype(\"f4\")",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol),",
            "                                   \"__float__\": lambda _: 0.5})",
            "        myarr = MyArr()",
            "",
            "        res = np.empty(3, dtype=object)",
            "        def set():",
            "            res[:] = [myarr, myarr, myarr]",
            "        self.assert_not_deprecated(set)",
            "        assert res[0] is myarr",
            "        assert res[1] is myarr",
            "        assert res[2] is myarr",
            "",
            "",
            "class TestDeprecatedUnpickleObjectScalar(_DeprecationTestCase):",
            "    # Deprecated 2020-11-24, NumPy 1.20",
            "    \"\"\"",
            "    Technically, it should be impossible to create numpy object scalars,",
            "    but there was an unpickle path that would in theory allow it. That",
            "    path is invalid and must lead to the warning.",
            "    \"\"\"",
            "    message = \"Unpickling a scalar with object dtype is deprecated.\"",
            "",
            "    def test_deprecated(self):",
            "        ctor = np.core.multiarray.scalar",
            "        self.assert_deprecated(lambda: ctor(np.dtype(\"O\"), 1))",
            "",
            "try:",
            "    with warnings.catch_warnings():",
            "        warnings.simplefilter(\"always\")",
            "        import nose  # noqa: F401",
            "except ImportError:",
            "    HAVE_NOSE = False",
            "else:",
            "    HAVE_NOSE = True",
            "",
            "",
            "@pytest.mark.skipif(not HAVE_NOSE, reason=\"Needs nose\")",
            "class TestNoseDecoratorsDeprecated(_DeprecationTestCase):",
            "    class DidntSkipException(Exception):",
            "        pass",
            "",
            "    def test_slow(self):",
            "        def _test_slow():",
            "            @np.testing.dec.slow",
            "            def slow_func(x, y, z):",
            "                pass",
            "",
            "            assert_(slow_func.slow)",
            "        self.assert_deprecated(_test_slow)",
            "",
            "    def test_setastest(self):",
            "        def _test_setastest():",
            "            @np.testing.dec.setastest()",
            "            def f_default(a):",
            "                pass",
            "",
            "            @np.testing.dec.setastest(True)",
            "            def f_istest(a):",
            "                pass",
            "",
            "            @np.testing.dec.setastest(False)",
            "            def f_isnottest(a):",
            "                pass",
            "",
            "            assert_(f_default.__test__)",
            "            assert_(f_istest.__test__)",
            "            assert_(not f_isnottest.__test__)",
            "        self.assert_deprecated(_test_setastest, num=3)",
            "",
            "    def test_skip_functions_hardcoded(self):",
            "        def _test_skip_functions_hardcoded():",
            "            @np.testing.dec.skipif(True)",
            "            def f1(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                f1('a')",
            "            except self.DidntSkipException:",
            "                raise Exception('Failed to skip')",
            "            except SkipTest().__class__:",
            "                pass",
            "",
            "            @np.testing.dec.skipif(False)",
            "            def f2(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                f2('a')",
            "            except self.DidntSkipException:",
            "                pass",
            "            except SkipTest().__class__:",
            "                raise Exception('Skipped when not expected to')",
            "        self.assert_deprecated(_test_skip_functions_hardcoded, num=2)",
            "",
            "    def test_skip_functions_callable(self):",
            "        def _test_skip_functions_callable():",
            "            def skip_tester():",
            "                return skip_flag == 'skip me!'",
            "",
            "            @np.testing.dec.skipif(skip_tester)",
            "            def f1(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                skip_flag = 'skip me!'",
            "                f1('a')",
            "            except self.DidntSkipException:",
            "                raise Exception('Failed to skip')",
            "            except SkipTest().__class__:",
            "                pass",
            "",
            "            @np.testing.dec.skipif(skip_tester)",
            "            def f2(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                skip_flag = 'five is right out!'",
            "                f2('a')",
            "            except self.DidntSkipException:",
            "                pass",
            "            except SkipTest().__class__:",
            "                raise Exception('Skipped when not expected to')",
            "        self.assert_deprecated(_test_skip_functions_callable, num=2)",
            "",
            "    def test_skip_generators_hardcoded(self):",
            "        def _test_skip_generators_hardcoded():",
            "            @np.testing.dec.knownfailureif(True, \"This test is known to fail\")",
            "            def g1(x):",
            "                yield from range(x)",
            "",
            "            try:",
            "                for j in g1(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                pass",
            "            else:",
            "                raise Exception('Failed to mark as known failure')",
            "",
            "            @np.testing.dec.knownfailureif(False, \"This test is NOT known to fail\")",
            "            def g2(x):",
            "                yield from range(x)",
            "                raise self.DidntSkipException('FAIL')",
            "",
            "            try:",
            "                for j in g2(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                raise Exception('Marked incorrectly as known failure')",
            "            except self.DidntSkipException:",
            "                pass",
            "        self.assert_deprecated(_test_skip_generators_hardcoded, num=2)",
            "",
            "    def test_skip_generators_callable(self):",
            "        def _test_skip_generators_callable():",
            "            def skip_tester():",
            "                return skip_flag == 'skip me!'",
            "",
            "            @np.testing.dec.knownfailureif(skip_tester, \"This test is known to fail\")",
            "            def g1(x):",
            "                yield from range(x)",
            "",
            "            try:",
            "                skip_flag = 'skip me!'",
            "                for j in g1(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                pass",
            "            else:",
            "                raise Exception('Failed to mark as known failure')",
            "",
            "            @np.testing.dec.knownfailureif(skip_tester, \"This test is NOT known to fail\")",
            "            def g2(x):",
            "                yield from range(x)",
            "                raise self.DidntSkipException('FAIL')",
            "",
            "            try:",
            "                skip_flag = 'do not skip'",
            "                for j in g2(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                raise Exception('Marked incorrectly as known failure')",
            "            except self.DidntSkipException:",
            "                pass",
            "        self.assert_deprecated(_test_skip_generators_callable, num=2)",
            "",
            "    def test_deprecated(self):",
            "        def _test_deprecated():",
            "            @np.testing.dec.deprecated(True)",
            "            def non_deprecated_func():",
            "                pass",
            "",
            "            @np.testing.dec.deprecated()",
            "            def deprecated_func():",
            "                import warnings",
            "                warnings.warn(\"TEST: deprecated func\", DeprecationWarning, stacklevel=1)",
            "",
            "            @np.testing.dec.deprecated()",
            "            def deprecated_func2():",
            "                import warnings",
            "                warnings.warn(\"AHHHH\", stacklevel=1)",
            "                raise ValueError",
            "",
            "            @np.testing.dec.deprecated()",
            "            def deprecated_func3():",
            "                import warnings",
            "                warnings.warn(\"AHHHH\", stacklevel=1)",
            "",
            "            # marked as deprecated, but does not raise DeprecationWarning",
            "            assert_raises(AssertionError, non_deprecated_func)",
            "            # should be silent",
            "            deprecated_func()",
            "            with warnings.catch_warnings(record=True):",
            "                warnings.simplefilter(\"always\")  # do not propagate unrelated warnings",
            "                # fails if deprecated decorator just disables test. See #1453.",
            "                assert_raises(ValueError, deprecated_func2)",
            "                # warning is not a DeprecationWarning",
            "                assert_raises(AssertionError, deprecated_func3)",
            "        self.assert_deprecated(_test_deprecated, num=4)",
            "",
            "    def test_parametrize(self):",
            "        def _test_parametrize():",
            "            # dec.parametrize assumes that it is being run by nose. Because",
            "            # we are running under pytest, we need to explicitly check the",
            "            # results.",
            "            @np.testing.dec.parametrize('base, power, expected',",
            "                    [(1, 1, 1),",
            "                    (2, 1, 2),",
            "                    (2, 2, 4)])",
            "            def check_parametrize(base, power, expected):",
            "                assert_(base**power == expected)",
            "",
            "            count = 0",
            "            for test in check_parametrize():",
            "                test[0](*test[1:])",
            "                count += 1",
            "            assert_(count == 3)",
            "        self.assert_deprecated(_test_parametrize)",
            "",
            "",
            "class TestSingleElementSignature(_DeprecationTestCase):",
            "    # Deprecated 2021-04-01, NumPy 1.21",
            "    message = r\"The use of a length 1\"",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.add(1, 2, signature=\"d\"))",
            "        self.assert_deprecated(lambda: np.add(1, 2, sig=(np.dtype(\"l\"),)))",
            "",
            "",
            "class TestComparisonBadDType(_DeprecationTestCase):",
            "    # Deprecated 2021-04-01, NumPy 1.21",
            "    message = r\"using `dtype=` in comparisons is only useful for\"",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.equal(1, 1, dtype=np.int64))",
            "        # Not an error only for the transition",
            "        self.assert_deprecated(lambda: np.equal(1, 1, sig=(None, None, \"l\")))",
            "",
            "    def test_not_deprecated(self):",
            "        np.equal(True, False, dtype=bool)",
            "        np.equal(3, 5, dtype=bool, casting=\"unsafe\")",
            "        np.equal([None], [4], dtype=object)",
            "",
            "class TestComparisonBadObjectDType(_DeprecationTestCase):",
            "    # Deprecated 2021-04-01, NumPy 1.21  (different branch of the above one)",
            "    message = r\"using `dtype=object` \\(or equivalent signature\\) will\"",
            "    warning_cls = FutureWarning",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.equal(1, 1, dtype=object))",
            "        self.assert_deprecated(",
            "                lambda: np.equal(1, 1, sig=(None, None, object)))",
            "",
            "",
            "class TestSpecialAttributeLookupFailure(_DeprecationTestCase):",
            "    message = r\"An exception was ignored while fetching the attribute\"",
            "",
            "    class WeirdArrayLike:",
            "        @property",
            "        def __array__(self):",
            "            raise RuntimeError(\"oops!\")",
            "",
            "    class WeirdArrayInterface:",
            "        @property",
            "        def __array_interface__(self):",
            "            raise RuntimeError(\"oops!\")",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.array(self.WeirdArrayLike()))",
            "        self.assert_deprecated(lambda: np.array(self.WeirdArrayInterface()))",
            "",
            "",
            "class TestCtypesGetter(_DeprecationTestCase):",
            "    # Deprecated 2021-05-18, Numpy 1.21.0",
            "    warning_cls = DeprecationWarning",
            "    ctypes = np.array([1]).ctypes",
            "",
            "    @pytest.mark.parametrize(",
            "        \"name\", [\"get_data\", \"get_shape\", \"get_strides\", \"get_as_parameter\"]",
            "    )",
            "    def test_deprecated(self, name: str) -> None:",
            "        func = getattr(self.ctypes, name)",
            "        self.assert_deprecated(lambda: func())",
            "",
            "    @pytest.mark.parametrize(",
            "        \"name\", [\"data\", \"shape\", \"strides\", \"_as_parameter_\"]",
            "    )",
            "    def test_not_deprecated(self, name: str) -> None:",
            "        self.assert_not_deprecated(lambda: getattr(self.ctypes, name))"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Tests related to deprecation warnings. Also a convenient place",
            "to document how deprecations should eventually be turned into errors.",
            "",
            "\"\"\"",
            "import datetime",
            "import operator",
            "import warnings",
            "import pytest",
            "import tempfile",
            "import re",
            "import sys",
            "",
            "import numpy as np",
            "from numpy.testing import (",
            "    assert_raises, assert_warns, assert_, assert_array_equal, SkipTest, KnownFailureException",
            "    )",
            "",
            "from numpy.core._multiarray_tests import fromstring_null_term_c_api",
            "",
            "try:",
            "    import pytz",
            "    _has_pytz = True",
            "except ImportError:",
            "    _has_pytz = False",
            "",
            "",
            "class _DeprecationTestCase:",
            "    # Just as warning: warnings uses re.match, so the start of this message",
            "    # must match.",
            "    message = ''",
            "    warning_cls = DeprecationWarning",
            "",
            "    def setup(self):",
            "        self.warn_ctx = warnings.catch_warnings(record=True)",
            "        self.log = self.warn_ctx.__enter__()",
            "",
            "        # Do *not* ignore other DeprecationWarnings. Ignoring warnings",
            "        # can give very confusing results because of",
            "        # https://bugs.python.org/issue4180 and it is probably simplest to",
            "        # try to keep the tests cleanly giving only the right warning type.",
            "        # (While checking them set to \"error\" those are ignored anyway)",
            "        # We still have them show up, because otherwise they would be raised",
            "        warnings.filterwarnings(\"always\", category=self.warning_cls)",
            "        warnings.filterwarnings(\"always\", message=self.message,",
            "                                category=self.warning_cls)",
            "",
            "    def teardown(self):",
            "        self.warn_ctx.__exit__()",
            "",
            "    def assert_deprecated(self, function, num=1, ignore_others=False,",
            "                          function_fails=False,",
            "                          exceptions=np._NoValue,",
            "                          args=(), kwargs={}):",
            "        \"\"\"Test if DeprecationWarnings are given and raised.",
            "",
            "        This first checks if the function when called gives `num`",
            "        DeprecationWarnings, after that it tries to raise these",
            "        DeprecationWarnings and compares them with `exceptions`.",
            "        The exceptions can be different for cases where this code path",
            "        is simply not anticipated and the exception is replaced.",
            "",
            "        Parameters",
            "        ----------",
            "        function : callable",
            "            The function to test",
            "        num : int",
            "            Number of DeprecationWarnings to expect. This should normally be 1.",
            "        ignore_others : bool",
            "            Whether warnings of the wrong type should be ignored (note that",
            "            the message is not checked)",
            "        function_fails : bool",
            "            If the function would normally fail, setting this will check for",
            "            warnings inside a try/except block.",
            "        exceptions : Exception or tuple of Exceptions",
            "            Exception to expect when turning the warnings into an error.",
            "            The default checks for DeprecationWarnings. If exceptions is",
            "            empty the function is expected to run successfully.",
            "        args : tuple",
            "            Arguments for `function`",
            "        kwargs : dict",
            "            Keyword arguments for `function`",
            "        \"\"\"",
            "        __tracebackhide__ = True  # Hide traceback for py.test",
            "",
            "        # reset the log",
            "        self.log[:] = []",
            "",
            "        if exceptions is np._NoValue:",
            "            exceptions = (self.warning_cls,)",
            "",
            "        try:",
            "            function(*args, **kwargs)",
            "        except (Exception if function_fails else tuple()):",
            "            pass",
            "",
            "        # just in case, clear the registry",
            "        num_found = 0",
            "        for warning in self.log:",
            "            if warning.category is self.warning_cls:",
            "                num_found += 1",
            "            elif not ignore_others:",
            "                raise AssertionError(",
            "                        \"expected %s but got: %s\" %",
            "                        (self.warning_cls.__name__, warning.category))",
            "        if num is not None and num_found != num:",
            "            msg = \"%i warnings found but %i expected.\" % (len(self.log), num)",
            "            lst = [str(w) for w in self.log]",
            "            raise AssertionError(\"\\n\".join([msg] + lst))",
            "",
            "        with warnings.catch_warnings():",
            "            warnings.filterwarnings(\"error\", message=self.message,",
            "                                    category=self.warning_cls)",
            "            try:",
            "                function(*args, **kwargs)",
            "                if exceptions != tuple():",
            "                    raise AssertionError(",
            "                            \"No error raised during function call\")",
            "            except exceptions:",
            "                if exceptions == tuple():",
            "                    raise AssertionError(",
            "                            \"Error raised during function call\")",
            "",
            "    def assert_not_deprecated(self, function, args=(), kwargs={}):",
            "        \"\"\"Test that warnings are not raised.",
            "",
            "        This is just a shorthand for:",
            "",
            "        self.assert_deprecated(function, num=0, ignore_others=True,",
            "                        exceptions=tuple(), args=args, kwargs=kwargs)",
            "        \"\"\"",
            "        self.assert_deprecated(function, num=0, ignore_others=True,",
            "                        exceptions=tuple(), args=args, kwargs=kwargs)",
            "",
            "",
            "class _VisibleDeprecationTestCase(_DeprecationTestCase):",
            "    warning_cls = np.VisibleDeprecationWarning",
            "",
            "",
            "class TestNonTupleNDIndexDeprecation:",
            "    def test_basic(self):",
            "        a = np.zeros((5, 5))",
            "        with warnings.catch_warnings():",
            "            warnings.filterwarnings('always')",
            "            assert_warns(FutureWarning, a.__getitem__, [[0, 1], [0, 1]])",
            "            assert_warns(FutureWarning, a.__getitem__, [slice(None)])",
            "",
            "            warnings.filterwarnings('error')",
            "            assert_raises(FutureWarning, a.__getitem__, [[0, 1], [0, 1]])",
            "            assert_raises(FutureWarning, a.__getitem__, [slice(None)])",
            "",
            "            # a a[[0, 1]] always was advanced indexing, so no error/warning",
            "            a[[0, 1]]",
            "",
            "",
            "class TestComparisonDeprecations(_DeprecationTestCase):",
            "    \"\"\"This tests the deprecation, for non-element-wise comparison logic.",
            "    This used to mean that when an error occurred during element-wise comparison",
            "    (i.e. broadcasting) NotImplemented was returned, but also in the comparison",
            "    itself, False was given instead of the error.",
            "",
            "    Also test FutureWarning for the None comparison.",
            "    \"\"\"",
            "",
            "    message = \"elementwise.* comparison failed; .*\"",
            "",
            "    def test_normal_types(self):",
            "        for op in (operator.eq, operator.ne):",
            "            # Broadcasting errors:",
            "            self.assert_deprecated(op, args=(np.zeros(3), []))",
            "            a = np.zeros(3, dtype='i,i')",
            "            # (warning is issued a couple of times here)",
            "            self.assert_deprecated(op, args=(a, a[:-1]), num=None)",
            "",
            "            # ragged array comparison returns True/False",
            "            a = np.array([1, np.array([1,2,3])], dtype=object)",
            "            b = np.array([1, np.array([1,2,3])], dtype=object)",
            "            self.assert_deprecated(op, args=(a, b), num=None)",
            "",
            "    def test_string(self):",
            "        # For two string arrays, strings always raised the broadcasting error:",
            "        a = np.array(['a', 'b'])",
            "        b = np.array(['a', 'b', 'c'])",
            "        assert_raises(ValueError, lambda x, y: x == y, a, b)",
            "",
            "        # The empty list is not cast to string, and this used to pass due",
            "        # to dtype mismatch; now (2018-06-21) it correctly leads to a",
            "        # FutureWarning.",
            "        assert_warns(FutureWarning, lambda: a == [])",
            "",
            "    def test_void_dtype_equality_failures(self):",
            "        class NotArray:",
            "            def __array__(self):",
            "                raise TypeError",
            "",
            "            # Needed so Python 3 does not raise DeprecationWarning twice.",
            "            def __ne__(self, other):",
            "                return NotImplemented",
            "",
            "        self.assert_deprecated(lambda: np.arange(2) == NotArray())",
            "        self.assert_deprecated(lambda: np.arange(2) != NotArray())",
            "",
            "        struct1 = np.zeros(2, dtype=\"i4,i4\")",
            "        struct2 = np.zeros(2, dtype=\"i4,i4,i4\")",
            "",
            "        assert_warns(FutureWarning, lambda: struct1 == 1)",
            "        assert_warns(FutureWarning, lambda: struct1 == struct2)",
            "        assert_warns(FutureWarning, lambda: struct1 != 1)",
            "        assert_warns(FutureWarning, lambda: struct1 != struct2)",
            "",
            "    def test_array_richcompare_legacy_weirdness(self):",
            "        # It doesn't really work to use assert_deprecated here, b/c part of",
            "        # the point of assert_deprecated is to check that when warnings are",
            "        # set to \"error\" mode then the error is propagated -- which is good!",
            "        # But here we are testing a bunch of code that is deprecated *because*",
            "        # it has the habit of swallowing up errors and converting them into",
            "        # different warnings. So assert_warns will have to be sufficient.",
            "        assert_warns(FutureWarning, lambda: np.arange(2) == \"a\")",
            "        assert_warns(FutureWarning, lambda: np.arange(2) != \"a\")",
            "        # No warning for scalar comparisons",
            "        with warnings.catch_warnings():",
            "            warnings.filterwarnings(\"error\")",
            "            assert_(not (np.array(0) == \"a\"))",
            "            assert_(np.array(0) != \"a\")",
            "            assert_(not (np.int16(0) == \"a\"))",
            "            assert_(np.int16(0) != \"a\")",
            "",
            "        for arg1 in [np.asarray(0), np.int16(0)]:",
            "            struct = np.zeros(2, dtype=\"i4,i4\")",
            "            for arg2 in [struct, \"a\"]:",
            "                for f in [operator.lt, operator.le, operator.gt, operator.ge]:",
            "                    with warnings.catch_warnings() as l:",
            "                        warnings.filterwarnings(\"always\")",
            "                        assert_raises(TypeError, f, arg1, arg2)",
            "                        assert_(not l)",
            "",
            "",
            "class TestDatetime64Timezone(_DeprecationTestCase):",
            "    \"\"\"Parsing of datetime64 with timezones deprecated in 1.11.0, because",
            "    datetime64 is now timezone naive rather than UTC only.",
            "",
            "    It will be quite a while before we can remove this, because, at the very",
            "    least, a lot of existing code uses the 'Z' modifier to avoid conversion",
            "    from local time to UTC, even if otherwise it handles time in a timezone",
            "    naive fashion.",
            "    \"\"\"",
            "    def test_string(self):",
            "        self.assert_deprecated(np.datetime64, args=('2000-01-01T00+01',))",
            "        self.assert_deprecated(np.datetime64, args=('2000-01-01T00Z',))",
            "",
            "    @pytest.mark.skipif(not _has_pytz,",
            "                        reason=\"The pytz module is not available.\")",
            "    def test_datetime(self):",
            "        tz = pytz.timezone('US/Eastern')",
            "        dt = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=tz)",
            "        self.assert_deprecated(np.datetime64, args=(dt,))",
            "",
            "",
            "class TestNonCContiguousViewDeprecation(_DeprecationTestCase):",
            "    \"\"\"View of non-C-contiguous arrays deprecated in 1.11.0.",
            "",
            "    The deprecation will not be raised for arrays that are both C and F",
            "    contiguous, as C contiguous is dominant. There are more such arrays",
            "    with relaxed stride checking than without so the deprecation is not",
            "    as visible with relaxed stride checking in force.",
            "    \"\"\"",
            "",
            "    def test_fortran_contiguous(self):",
            "        self.assert_deprecated(np.ones((2,2)).T.view, args=(complex,))",
            "        self.assert_deprecated(np.ones((2,2)).T.view, args=(np.int8,))",
            "",
            "",
            "class TestArrayDataAttributeAssignmentDeprecation(_DeprecationTestCase):",
            "    \"\"\"Assigning the 'data' attribute of an ndarray is unsafe as pointed",
            "     out in gh-7093. Eventually, such assignment should NOT be allowed, but",
            "     in the interests of maintaining backwards compatibility, only a Deprecation-",
            "     Warning will be raised instead for the time being to give developers time to",
            "     refactor relevant code.",
            "    \"\"\"",
            "",
            "    def test_data_attr_assignment(self):",
            "        a = np.arange(10)",
            "        b = np.linspace(0, 1, 10)",
            "",
            "        self.message = (\"Assigning the 'data' attribute is an \"",
            "                        \"inherently unsafe operation and will \"",
            "                        \"be removed in the future.\")",
            "        self.assert_deprecated(a.__setattr__, args=('data', b.data))",
            "",
            "",
            "class TestBinaryReprInsufficientWidthParameterForRepresentation(_DeprecationTestCase):",
            "    \"\"\"",
            "    If a 'width' parameter is passed into ``binary_repr`` that is insufficient to",
            "    represent the number in base 2 (positive) or 2's complement (negative) form,",
            "    the function used to silently ignore the parameter and return a representation",
            "    using the minimal number of bits needed for the form in question. Such behavior",
            "    is now considered unsafe from a user perspective and will raise an error in the future.",
            "    \"\"\"",
            "",
            "    def test_insufficient_width_positive(self):",
            "        args = (10,)",
            "        kwargs = {'width': 2}",
            "",
            "        self.message = (\"Insufficient bit width provided. This behavior \"",
            "                        \"will raise an error in the future.\")",
            "        self.assert_deprecated(np.binary_repr, args=args, kwargs=kwargs)",
            "",
            "    def test_insufficient_width_negative(self):",
            "        args = (-5,)",
            "        kwargs = {'width': 2}",
            "",
            "        self.message = (\"Insufficient bit width provided. This behavior \"",
            "                        \"will raise an error in the future.\")",
            "        self.assert_deprecated(np.binary_repr, args=args, kwargs=kwargs)",
            "",
            "",
            "class TestDTypeAttributeIsDTypeDeprecation(_DeprecationTestCase):",
            "    # Deprecated 2021-01-05, NumPy 1.21",
            "    message = r\".*`.dtype` attribute\"",
            "",
            "    def test_deprecation_dtype_attribute_is_dtype(self):",
            "        class dt:",
            "            dtype = \"f8\"",
            "",
            "        class vdt(np.void):",
            "            dtype = \"f,f\"",
            "",
            "        self.assert_deprecated(lambda: np.dtype(dt))",
            "        self.assert_deprecated(lambda: np.dtype(dt()))",
            "        self.assert_deprecated(lambda: np.dtype(vdt))",
            "        self.assert_deprecated(lambda: np.dtype(vdt(1)))",
            "",
            "",
            "class TestTestDeprecated:",
            "    def test_assert_deprecated(self):",
            "        test_case_instance = _DeprecationTestCase()",
            "        test_case_instance.setup()",
            "        assert_raises(AssertionError,",
            "                      test_case_instance.assert_deprecated,",
            "                      lambda: None)",
            "",
            "        def foo():",
            "            warnings.warn(\"foo\", category=DeprecationWarning, stacklevel=2)",
            "",
            "        test_case_instance.assert_deprecated(foo)",
            "        test_case_instance.teardown()",
            "",
            "",
            "class TestNonNumericConjugate(_DeprecationTestCase):",
            "    \"\"\"",
            "    Deprecate no-op behavior of ndarray.conjugate on non-numeric dtypes,",
            "    which conflicts with the error behavior of np.conjugate.",
            "    \"\"\"",
            "    def test_conjugate(self):",
            "        for a in np.array(5), np.array(5j):",
            "            self.assert_not_deprecated(a.conjugate)",
            "        for a in (np.array('s'), np.array('2016', 'M'),",
            "                np.array((1, 2), [('a', int), ('b', int)])):",
            "            self.assert_deprecated(a.conjugate)",
            "",
            "",
            "class TestNPY_CHAR(_DeprecationTestCase):",
            "    # 2017-05-03, 1.13.0",
            "    def test_npy_char_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_char_deprecation",
            "        self.assert_deprecated(npy_char_deprecation)",
            "        assert_(npy_char_deprecation() == 'S1')",
            "",
            "",
            "class TestPyArray_AS1D(_DeprecationTestCase):",
            "    def test_npy_pyarrayas1d_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_pyarrayas1d_deprecation",
            "        assert_raises(NotImplementedError, npy_pyarrayas1d_deprecation)",
            "",
            "",
            "class TestPyArray_AS2D(_DeprecationTestCase):",
            "    def test_npy_pyarrayas2d_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_pyarrayas2d_deprecation",
            "        assert_raises(NotImplementedError, npy_pyarrayas2d_deprecation)",
            "",
            "",
            "class Test_UPDATEIFCOPY(_DeprecationTestCase):",
            "    \"\"\"",
            "    v1.14 deprecates creating an array with the UPDATEIFCOPY flag, use",
            "    WRITEBACKIFCOPY instead",
            "    \"\"\"",
            "    def test_npy_updateifcopy_deprecation(self):",
            "        from numpy.core._multiarray_tests import npy_updateifcopy_deprecation",
            "        arr = np.arange(9).reshape(3, 3)",
            "        v = arr.T",
            "        self.assert_deprecated(npy_updateifcopy_deprecation, args=(v,))",
            "",
            "",
            "class TestDatetimeEvent(_DeprecationTestCase):",
            "    # 2017-08-11, 1.14.0",
            "    def test_3_tuple(self):",
            "        for cls in (np.datetime64, np.timedelta64):",
            "            # two valid uses - (unit, num) and (unit, num, den, None)",
            "            self.assert_not_deprecated(cls, args=(1, ('ms', 2)))",
            "            self.assert_not_deprecated(cls, args=(1, ('ms', 2, 1, None)))",
            "",
            "            # trying to use the event argument, removed in 1.7.0, is deprecated",
            "            # it used to be a uint8",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 'event')))",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 63)))",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 1, 'event')))",
            "            self.assert_deprecated(cls, args=(1, ('ms', 2, 1, 63)))",
            "",
            "",
            "class TestTruthTestingEmptyArrays(_DeprecationTestCase):",
            "    # 2017-09-25, 1.14.0",
            "    message = '.*truth value of an empty array is ambiguous.*'",
            "",
            "    def test_1d(self):",
            "        self.assert_deprecated(bool, args=(np.array([]),))",
            "",
            "    def test_2d(self):",
            "        self.assert_deprecated(bool, args=(np.zeros((1, 0)),))",
            "        self.assert_deprecated(bool, args=(np.zeros((0, 1)),))",
            "        self.assert_deprecated(bool, args=(np.zeros((0, 0)),))",
            "",
            "",
            "class TestBincount(_DeprecationTestCase):",
            "    # 2017-06-01, 1.14.0",
            "    def test_bincount_minlength(self):",
            "        self.assert_deprecated(lambda: np.bincount([1, 2, 3], minlength=None))",
            "",
            "",
            "class TestAlen(_DeprecationTestCase):",
            "    # 2019-08-02, 1.18.0",
            "    def test_alen(self):",
            "        self.assert_deprecated(lambda: np.alen(np.array([1, 2, 3])))",
            "",
            "",
            "class TestGeneratorSum(_DeprecationTestCase):",
            "    # 2018-02-25, 1.15.0",
            "    def test_generator_sum(self):",
            "        self.assert_deprecated(np.sum, args=((i for i in range(5)),))",
            "",
            "",
            "class TestPositiveOnNonNumerical(_DeprecationTestCase):",
            "    # 2018-06-28, 1.16.0",
            "    def test_positive_on_non_number(self):",
            "        self.assert_deprecated(operator.pos, args=(np.array('foo'),))",
            "",
            "",
            "class TestFromstring(_DeprecationTestCase):",
            "    # 2017-10-19, 1.14",
            "    def test_fromstring(self):",
            "        self.assert_deprecated(np.fromstring, args=('\\x00'*80,))",
            "",
            "",
            "class TestFromStringAndFileInvalidData(_DeprecationTestCase):",
            "    # 2019-06-08, 1.17.0",
            "    # Tests should be moved to real tests when deprecation is done.",
            "    message = \"string or file could not be read to its end\"",
            "",
            "    @pytest.mark.parametrize(\"invalid_str\", [\",invalid_data\", \"invalid_sep\"])",
            "    def test_deprecate_unparsable_data_file(self, invalid_str):",
            "        x = np.array([1.51, 2, 3.51, 4], dtype=float)",
            "",
            "        with tempfile.TemporaryFile(mode=\"w\") as f:",
            "            x.tofile(f, sep=',', format='%.2f')",
            "            f.write(invalid_str)",
            "",
            "            f.seek(0)",
            "            self.assert_deprecated(lambda: np.fromfile(f, sep=\",\"))",
            "            f.seek(0)",
            "            self.assert_deprecated(lambda: np.fromfile(f, sep=\",\", count=5))",
            "            # Should not raise:",
            "            with warnings.catch_warnings():",
            "                warnings.simplefilter(\"error\", DeprecationWarning)",
            "                f.seek(0)",
            "                res = np.fromfile(f, sep=\",\", count=4)",
            "                assert_array_equal(res, x)",
            "",
            "    @pytest.mark.parametrize(\"invalid_str\", [\",invalid_data\", \"invalid_sep\"])",
            "    def test_deprecate_unparsable_string(self, invalid_str):",
            "        x = np.array([1.51, 2, 3.51, 4], dtype=float)",
            "        x_str = \"1.51,2,3.51,4{}\".format(invalid_str)",
            "",
            "        self.assert_deprecated(lambda: np.fromstring(x_str, sep=\",\"))",
            "        self.assert_deprecated(lambda: np.fromstring(x_str, sep=\",\", count=5))",
            "",
            "        # The C-level API can use not fixed size, but 0 terminated strings,",
            "        # so test that as well:",
            "        bytestr = x_str.encode(\"ascii\")",
            "        self.assert_deprecated(lambda: fromstring_null_term_c_api(bytestr))",
            "",
            "        with assert_warns(DeprecationWarning):",
            "            # this is slightly strange, in that fromstring leaves data",
            "            # potentially uninitialized (would be good to error when all is",
            "            # read, but count is larger then actual data maybe).",
            "            res = np.fromstring(x_str, sep=\",\", count=5)",
            "            assert_array_equal(res[:-1], x)",
            "",
            "        with warnings.catch_warnings():",
            "            warnings.simplefilter(\"error\", DeprecationWarning)",
            "",
            "            # Should not raise:",
            "            res = np.fromstring(x_str, sep=\",\", count=4)",
            "            assert_array_equal(res, x)",
            "",
            "",
            "class Test_GetSet_NumericOps(_DeprecationTestCase):",
            "    # 2018-09-20, 1.16.0",
            "    def test_get_numeric_ops(self):",
            "        from numpy.core._multiarray_tests import getset_numericops",
            "        self.assert_deprecated(getset_numericops, num=2)",
            "",
            "        # empty kwargs prevents any state actually changing which would break",
            "        # other tests.",
            "        self.assert_deprecated(np.set_numeric_ops, kwargs={})",
            "        assert_raises(ValueError, np.set_numeric_ops, add='abc')",
            "",
            "",
            "class TestShape1Fields(_DeprecationTestCase):",
            "    warning_cls = FutureWarning",
            "",
            "    # 2019-05-20, 1.17.0",
            "    def test_shape_1_fields(self):",
            "        self.assert_deprecated(np.dtype, args=([('a', int, 1)],))",
            "",
            "",
            "class TestNonZero(_DeprecationTestCase):",
            "    # 2019-05-26, 1.17.0",
            "    def test_zerod(self):",
            "        self.assert_deprecated(lambda: np.nonzero(np.array(0)))",
            "        self.assert_deprecated(lambda: np.nonzero(np.array(1)))",
            "",
            "",
            "def test_deprecate_ragged_arrays():",
            "    # 2019-11-29 1.19.0",
            "    #",
            "    # NEP 34 deprecated automatic object dtype when creating ragged",
            "    # arrays. Also see the \"ragged\" tests in `test_multiarray`",
            "    #",
            "    # emits a VisibleDeprecationWarning",
            "    arg = [1, [2, 3]]",
            "    with assert_warns(np.VisibleDeprecationWarning):",
            "        np.array(arg)",
            "",
            "",
            "class TestTooDeepDeprecation(_VisibleDeprecationTestCase):",
            "    # NumPy 1.20, 2020-05-08",
            "    # This is a bit similar to the above ragged array deprecation case.",
            "    message = re.escape(\"Creating an ndarray from nested sequences exceeding\")",
            "",
            "    def test_deprecation(self):",
            "        nested = [1]",
            "        for i in range(np.MAXDIMS - 1):",
            "            nested = [nested]",
            "        self.assert_not_deprecated(np.array, args=(nested,))",
            "        self.assert_not_deprecated(np.array,",
            "                args=(nested,), kwargs=dict(dtype=object))",
            "",
            "        self.assert_deprecated(np.array, args=([nested],))",
            "",
            "",
            "class TestToString(_DeprecationTestCase):",
            "    # 2020-03-06 1.19.0",
            "    message = re.escape(\"tostring() is deprecated. Use tobytes() instead.\")",
            "",
            "    def test_tostring(self):",
            "        arr = np.array(list(b\"test\\xFF\"), dtype=np.uint8)",
            "        self.assert_deprecated(arr.tostring)",
            "",
            "    def test_tostring_matches_tobytes(self):",
            "        arr = np.array(list(b\"test\\xFF\"), dtype=np.uint8)",
            "        b = arr.tobytes()",
            "        with assert_warns(DeprecationWarning):",
            "            s = arr.tostring()",
            "        assert s == b",
            "",
            "",
            "class TestDTypeCoercion(_DeprecationTestCase):",
            "    # 2020-02-06 1.19.0",
            "    message = \"Converting .* to a dtype .*is deprecated\"",
            "    deprecated_types = [",
            "        # The builtin scalar super types:",
            "        np.generic, np.flexible, np.number,",
            "        np.inexact, np.floating, np.complexfloating,",
            "        np.integer, np.unsignedinteger, np.signedinteger,",
            "        # character is a deprecated S1 special case:",
            "        np.character,",
            "    ]",
            "",
            "    def test_dtype_coercion(self):",
            "        for scalar_type in self.deprecated_types:",
            "            self.assert_deprecated(np.dtype, args=(scalar_type,))",
            "",
            "    def test_array_construction(self):",
            "        for scalar_type in self.deprecated_types:",
            "            self.assert_deprecated(np.array, args=([], scalar_type,))",
            "",
            "    def test_not_deprecated(self):",
            "        # All specific types are not deprecated:",
            "        for group in np.sctypes.values():",
            "            for scalar_type in group:",
            "                self.assert_not_deprecated(np.dtype, args=(scalar_type,))",
            "",
            "        for scalar_type in [type, dict, list, tuple]:",
            "            # Typical python types are coerced to object currently:",
            "            self.assert_not_deprecated(np.dtype, args=(scalar_type,))",
            "",
            "",
            "class BuiltInRoundComplexDType(_DeprecationTestCase):",
            "    # 2020-03-31 1.19.0",
            "    deprecated_types = [np.csingle, np.cdouble, np.clongdouble]",
            "    not_deprecated_types = [",
            "        np.int8, np.int16, np.int32, np.int64,",
            "        np.uint8, np.uint16, np.uint32, np.uint64,",
            "        np.float16, np.float32, np.float64,",
            "    ]",
            "",
            "    def test_deprecated(self):",
            "        for scalar_type in self.deprecated_types:",
            "            scalar = scalar_type(0)",
            "            self.assert_deprecated(round, args=(scalar,))",
            "            self.assert_deprecated(round, args=(scalar, 0))",
            "            self.assert_deprecated(round, args=(scalar,), kwargs={'ndigits': 0})",
            "",
            "    def test_not_deprecated(self):",
            "        for scalar_type in self.not_deprecated_types:",
            "            scalar = scalar_type(0)",
            "            self.assert_not_deprecated(round, args=(scalar,))",
            "            self.assert_not_deprecated(round, args=(scalar, 0))",
            "            self.assert_not_deprecated(round, args=(scalar,), kwargs={'ndigits': 0})",
            "",
            "",
            "class TestIncorrectAdvancedIndexWithEmptyResult(_DeprecationTestCase):",
            "    # 2020-05-27, NumPy 1.20.0",
            "    message = \"Out of bound index found. This was previously ignored.*\"",
            "",
            "    @pytest.mark.parametrize(\"index\", [([3, 0],), ([0, 0], [3, 0])])",
            "    def test_empty_subspace(self, index):",
            "        # Test for both a single and two/multiple advanced indices. These",
            "        # This will raise an IndexError in the future.",
            "        arr = np.ones((2, 2, 0))",
            "        self.assert_deprecated(arr.__getitem__, args=(index,))",
            "        self.assert_deprecated(arr.__setitem__, args=(index, 0.))",
            "",
            "        # for this array, the subspace is only empty after applying the slice",
            "        arr2 = np.ones((2, 2, 1))",
            "        index2 = (slice(0, 0),) + index",
            "        self.assert_deprecated(arr2.__getitem__, args=(index2,))",
            "        self.assert_deprecated(arr2.__setitem__, args=(index2, 0.))",
            "",
            "    def test_empty_index_broadcast_not_deprecated(self):",
            "        arr = np.ones((2, 2, 2))",
            "",
            "        index = ([[3], [2]], [])  # broadcast to an empty result.",
            "        self.assert_not_deprecated(arr.__getitem__, args=(index,))",
            "        self.assert_not_deprecated(arr.__setitem__,",
            "                                   args=(index, np.empty((2, 0, 2))))",
            "",
            "",
            "class TestNonExactMatchDeprecation(_DeprecationTestCase):",
            "    # 2020-04-22",
            "    def test_non_exact_match(self):",
            "        arr = np.array([[3, 6, 6], [4, 5, 1]])",
            "        # misspelt mode check",
            "        self.assert_deprecated(lambda: np.ravel_multi_index(arr, (7, 6), mode='Cilp'))",
            "        # using completely different word with first character as R",
            "        self.assert_deprecated(lambda: np.searchsorted(arr[0], 4, side='Random'))",
            "",
            "",
            "class TestDeprecatedGlobals(_DeprecationTestCase):",
            "    # 2020-06-06",
            "    @pytest.mark.skipif(",
            "        sys.version_info < (3, 7),",
            "        reason='module-level __getattr__ not supported')",
            "    def test_type_aliases(self):",
            "        # from builtins",
            "        self.assert_deprecated(lambda: np.bool(True))",
            "        self.assert_deprecated(lambda: np.int(1))",
            "        self.assert_deprecated(lambda: np.float(1))",
            "        self.assert_deprecated(lambda: np.complex(1))",
            "        self.assert_deprecated(lambda: np.object())",
            "        self.assert_deprecated(lambda: np.str('abc'))",
            "",
            "        # from np.compat",
            "        self.assert_deprecated(lambda: np.long(1))",
            "        self.assert_deprecated(lambda: np.unicode('abc'))",
            "",
            "        # from np.core.numerictypes",
            "        self.assert_deprecated(lambda: np.typeDict)",
            "",
            "",
            "class TestMatrixInOuter(_DeprecationTestCase):",
            "    # 2020-05-13 NumPy 1.20.0",
            "    message = (r\"add.outer\\(\\) was passed a numpy matrix as \"",
            "               r\"(first|second) argument.\")",
            "",
            "    def test_deprecated(self):",
            "        arr = np.array([1, 2, 3])",
            "        m = np.array([1, 2, 3]).view(np.matrix)",
            "        self.assert_deprecated(np.add.outer, args=(m, m), num=2)",
            "        self.assert_deprecated(np.add.outer, args=(arr, m))",
            "        self.assert_deprecated(np.add.outer, args=(m, arr))",
            "        self.assert_not_deprecated(np.add.outer, args=(arr, arr))",
            "",
            "",
            "class TestRaggedArray(_DeprecationTestCase):",
            "    # 2020-07-24, NumPy 1.20.0",
            "    message = \"setting an array element with a sequence\"",
            "",
            "    def test_deprecated(self):",
            "        arr = np.ones((1, 1))",
            "        # Deprecated if the array is a leave node:",
            "        self.assert_deprecated(lambda: np.array([arr, 0], dtype=np.float64))",
            "        self.assert_deprecated(lambda: np.array([0, arr], dtype=np.float64))",
            "        # And when it is an assignment into a lower dimensional subarray:",
            "        self.assert_deprecated(lambda: np.array([arr, [0]], dtype=np.float64))",
            "        self.assert_deprecated(lambda: np.array([[0], arr], dtype=np.float64))",
            "",
            "",
            "class FlatteningConcatenateUnsafeCast(_DeprecationTestCase):",
            "    # NumPy 1.20, 2020-09-03",
            "    message = \"concatenate with `axis=None` will use same-kind casting\"",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(np.concatenate,",
            "                args=(([0.], [1.]),),",
            "                kwargs=dict(axis=None, out=np.empty(2, dtype=np.int64)))",
            "",
            "    def test_not_deprecated(self):",
            "        self.assert_not_deprecated(np.concatenate,",
            "                args=(([0.], [1.]),),",
            "                kwargs={'axis': None, 'out': np.empty(2, dtype=np.int64),",
            "                        'casting': \"unsafe\"})",
            "",
            "        with assert_raises(TypeError):",
            "            # Tests should notice if the deprecation warning is given first...",
            "            np.concatenate(([0.], [1.]), out=np.empty(2, dtype=np.int64),",
            "                           casting=\"same_kind\")",
            "",
            "",
            "class TestDeprecateSubarrayDTypeDuringArrayCoercion(_DeprecationTestCase):",
            "    warning_cls = FutureWarning",
            "    message = \"(creating|casting) an array (with|to) a subarray dtype\"",
            "",
            "    def test_deprecated_array(self):",
            "        # Arrays are more complex, since they \"broadcast\" on success:",
            "        arr = np.array([1, 2])",
            "",
            "        self.assert_deprecated(lambda: arr.astype(\"(2)i,\"))",
            "        with pytest.warns(FutureWarning):",
            "            res = arr.astype(\"(2)i,\")",
            "",
            "        assert_array_equal(res, [[1, 2], [1, 2]])",
            "",
            "        self.assert_deprecated(lambda: np.array(arr, dtype=\"(2)i,\"))",
            "        with pytest.warns(FutureWarning):",
            "            res = np.array(arr, dtype=\"(2)i,\")",
            "",
            "        assert_array_equal(res, [[1, 2], [1, 2]])",
            "",
            "        with pytest.warns(FutureWarning):",
            "            res = np.array([[(1,), (2,)], arr], dtype=\"(2)i,\")",
            "",
            "        assert_array_equal(res, [[[1, 1], [2, 2]], [[1, 2], [1, 2]]])",
            "",
            "    def test_deprecated_and_error(self):",
            "        # These error paths do not give a warning, but will succeed in the",
            "        # future.",
            "        arr = np.arange(5 * 2).reshape(5, 2)",
            "        def check():",
            "            with pytest.raises(ValueError):",
            "                arr.astype(\"(2,2)f\")",
            "",
            "        self.assert_deprecated(check)",
            "",
            "        def check():",
            "            with pytest.raises(ValueError):",
            "                np.array(arr, dtype=\"(2,2)f\")",
            "",
            "        self.assert_deprecated(check)",
            "",
            "",
            "class TestFutureWarningArrayLikeNotIterable(_DeprecationTestCase):",
            "    # Deprecated 2020-12-09, NumPy 1.20",
            "    warning_cls = FutureWarning",
            "    message = \"The input object of type.*but not a sequence\"",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "            [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_deprecated(self, protocol):",
            "        \"\"\"Test that these objects give a warning since they are not 0-D,",
            "        not coerced at the top level `np.array(obj)`, but nested, and do",
            "        *not* define the sequence protocol.",
            "",
            "        NOTE: Tests for the versions including __len__ and __getitem__ exist",
            "              in `test_array_coercion.py` and they can be modified or ammended",
            "              when this deprecation expired.",
            "        \"\"\"",
            "        blueprint = np.arange(10)",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol)})",
            "        self.assert_deprecated(lambda: np.array([MyArr()], dtype=object))",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_0d_not_deprecated(self, protocol):",
            "        # 0-D always worked (albeit it would use __float__ or similar for the",
            "        # conversion, which may not happen anymore)",
            "        blueprint = np.array(1.)",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol)})",
            "        myarr = MyArr()",
            "",
            "        self.assert_not_deprecated(lambda: np.array([myarr], dtype=object))",
            "        res = np.array([myarr], dtype=object)",
            "        expected = np.empty(1, dtype=object)",
            "        expected[0] = myarr",
            "        assert_array_equal(res, expected)",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_unnested_not_deprecated(self, protocol):",
            "        blueprint = np.arange(10)",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol)})",
            "        myarr = MyArr()",
            "",
            "        self.assert_not_deprecated(lambda: np.array(myarr))",
            "        res = np.array(myarr)",
            "        assert_array_equal(res, blueprint)",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_strange_dtype_handling(self, protocol):",
            "        \"\"\"The old code would actually use the dtype from the array, but",
            "        then end up not using the array (for dimension discovery)",
            "        \"\"\"",
            "        blueprint = np.arange(10).astype(\"f4\")",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol),",
            "                                   \"__float__\": lambda _: 0.5})",
            "        myarr = MyArr()",
            "",
            "        # Make sure we warn (and capture the FutureWarning)",
            "        with pytest.warns(FutureWarning, match=self.message):",
            "            res = np.array([[myarr]])",
            "",
            "        assert res.shape == (1, 1)",
            "        assert res.dtype == \"f4\"",
            "        assert res[0, 0] == 0.5",
            "",
            "    @pytest.mark.parametrize(\"protocol\",",
            "             [\"__array__\", \"__array_interface__\", \"__array_struct__\"])",
            "    def test_assignment_not_deprecated(self, protocol):",
            "        # If the result is dtype=object we do not unpack a nested array or",
            "        # array-like, if it is nested at exactly the right depth.",
            "        # NOTE: We actually do still call __array__, etc. but ignore the result",
            "        #       in the end. For `dtype=object` we could optimize that away.",
            "        blueprint = np.arange(10).astype(\"f4\")",
            "        MyArr = type(\"MyArr\", (), {protocol: getattr(blueprint, protocol),",
            "                                   \"__float__\": lambda _: 0.5})",
            "        myarr = MyArr()",
            "",
            "        res = np.empty(3, dtype=object)",
            "        def set():",
            "            res[:] = [myarr, myarr, myarr]",
            "        self.assert_not_deprecated(set)",
            "        assert res[0] is myarr",
            "        assert res[1] is myarr",
            "        assert res[2] is myarr",
            "",
            "",
            "class TestDeprecatedUnpickleObjectScalar(_DeprecationTestCase):",
            "    # Deprecated 2020-11-24, NumPy 1.20",
            "    \"\"\"",
            "    Technically, it should be impossible to create numpy object scalars,",
            "    but there was an unpickle path that would in theory allow it. That",
            "    path is invalid and must lead to the warning.",
            "    \"\"\"",
            "    message = \"Unpickling a scalar with object dtype is deprecated.\"",
            "",
            "    def test_deprecated(self):",
            "        ctor = np.core.multiarray.scalar",
            "        self.assert_deprecated(lambda: ctor(np.dtype(\"O\"), 1))",
            "",
            "try:",
            "    with warnings.catch_warnings():",
            "        warnings.simplefilter(\"always\")",
            "        import nose  # noqa: F401",
            "except ImportError:",
            "    HAVE_NOSE = False",
            "else:",
            "    HAVE_NOSE = True",
            "",
            "",
            "@pytest.mark.skipif(not HAVE_NOSE, reason=\"Needs nose\")",
            "class TestNoseDecoratorsDeprecated(_DeprecationTestCase):",
            "    class DidntSkipException(Exception):",
            "        pass",
            "",
            "    def test_slow(self):",
            "        def _test_slow():",
            "            @np.testing.dec.slow",
            "            def slow_func(x, y, z):",
            "                pass",
            "",
            "            assert_(slow_func.slow)",
            "        self.assert_deprecated(_test_slow)",
            "",
            "    def test_setastest(self):",
            "        def _test_setastest():",
            "            @np.testing.dec.setastest()",
            "            def f_default(a):",
            "                pass",
            "",
            "            @np.testing.dec.setastest(True)",
            "            def f_istest(a):",
            "                pass",
            "",
            "            @np.testing.dec.setastest(False)",
            "            def f_isnottest(a):",
            "                pass",
            "",
            "            assert_(f_default.__test__)",
            "            assert_(f_istest.__test__)",
            "            assert_(not f_isnottest.__test__)",
            "        self.assert_deprecated(_test_setastest, num=3)",
            "",
            "    def test_skip_functions_hardcoded(self):",
            "        def _test_skip_functions_hardcoded():",
            "            @np.testing.dec.skipif(True)",
            "            def f1(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                f1('a')",
            "            except self.DidntSkipException:",
            "                raise Exception('Failed to skip')",
            "            except SkipTest().__class__:",
            "                pass",
            "",
            "            @np.testing.dec.skipif(False)",
            "            def f2(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                f2('a')",
            "            except self.DidntSkipException:",
            "                pass",
            "            except SkipTest().__class__:",
            "                raise Exception('Skipped when not expected to')",
            "        self.assert_deprecated(_test_skip_functions_hardcoded, num=2)",
            "",
            "    def test_skip_functions_callable(self):",
            "        def _test_skip_functions_callable():",
            "            def skip_tester():",
            "                return skip_flag == 'skip me!'",
            "",
            "            @np.testing.dec.skipif(skip_tester)",
            "            def f1(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                skip_flag = 'skip me!'",
            "                f1('a')",
            "            except self.DidntSkipException:",
            "                raise Exception('Failed to skip')",
            "            except SkipTest().__class__:",
            "                pass",
            "",
            "            @np.testing.dec.skipif(skip_tester)",
            "            def f2(x):",
            "                raise self.DidntSkipException",
            "",
            "            try:",
            "                skip_flag = 'five is right out!'",
            "                f2('a')",
            "            except self.DidntSkipException:",
            "                pass",
            "            except SkipTest().__class__:",
            "                raise Exception('Skipped when not expected to')",
            "        self.assert_deprecated(_test_skip_functions_callable, num=2)",
            "",
            "    def test_skip_generators_hardcoded(self):",
            "        def _test_skip_generators_hardcoded():",
            "            @np.testing.dec.knownfailureif(True, \"This test is known to fail\")",
            "            def g1(x):",
            "                yield from range(x)",
            "",
            "            try:",
            "                for j in g1(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                pass",
            "            else:",
            "                raise Exception('Failed to mark as known failure')",
            "",
            "            @np.testing.dec.knownfailureif(False, \"This test is NOT known to fail\")",
            "            def g2(x):",
            "                yield from range(x)",
            "                raise self.DidntSkipException('FAIL')",
            "",
            "            try:",
            "                for j in g2(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                raise Exception('Marked incorrectly as known failure')",
            "            except self.DidntSkipException:",
            "                pass",
            "        self.assert_deprecated(_test_skip_generators_hardcoded, num=2)",
            "",
            "    def test_skip_generators_callable(self):",
            "        def _test_skip_generators_callable():",
            "            def skip_tester():",
            "                return skip_flag == 'skip me!'",
            "",
            "            @np.testing.dec.knownfailureif(skip_tester, \"This test is known to fail\")",
            "            def g1(x):",
            "                yield from range(x)",
            "",
            "            try:",
            "                skip_flag = 'skip me!'",
            "                for j in g1(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                pass",
            "            else:",
            "                raise Exception('Failed to mark as known failure')",
            "",
            "            @np.testing.dec.knownfailureif(skip_tester, \"This test is NOT known to fail\")",
            "            def g2(x):",
            "                yield from range(x)",
            "                raise self.DidntSkipException('FAIL')",
            "",
            "            try:",
            "                skip_flag = 'do not skip'",
            "                for j in g2(10):",
            "                    pass",
            "            except KnownFailureException().__class__:",
            "                raise Exception('Marked incorrectly as known failure')",
            "            except self.DidntSkipException:",
            "                pass",
            "        self.assert_deprecated(_test_skip_generators_callable, num=2)",
            "",
            "    def test_deprecated(self):",
            "        def _test_deprecated():",
            "            @np.testing.dec.deprecated(True)",
            "            def non_deprecated_func():",
            "                pass",
            "",
            "            @np.testing.dec.deprecated()",
            "            def deprecated_func():",
            "                import warnings",
            "                warnings.warn(\"TEST: deprecated func\", DeprecationWarning, stacklevel=1)",
            "",
            "            @np.testing.dec.deprecated()",
            "            def deprecated_func2():",
            "                import warnings",
            "                warnings.warn(\"AHHHH\", stacklevel=1)",
            "                raise ValueError",
            "",
            "            @np.testing.dec.deprecated()",
            "            def deprecated_func3():",
            "                import warnings",
            "                warnings.warn(\"AHHHH\", stacklevel=1)",
            "",
            "            # marked as deprecated, but does not raise DeprecationWarning",
            "            assert_raises(AssertionError, non_deprecated_func)",
            "            # should be silent",
            "            deprecated_func()",
            "            with warnings.catch_warnings(record=True):",
            "                warnings.simplefilter(\"always\")  # do not propagate unrelated warnings",
            "                # fails if deprecated decorator just disables test. See #1453.",
            "                assert_raises(ValueError, deprecated_func2)",
            "                # warning is not a DeprecationWarning",
            "                assert_raises(AssertionError, deprecated_func3)",
            "        self.assert_deprecated(_test_deprecated, num=4)",
            "",
            "    def test_parametrize(self):",
            "        def _test_parametrize():",
            "            # dec.parametrize assumes that it is being run by nose. Because",
            "            # we are running under pytest, we need to explicitly check the",
            "            # results.",
            "            @np.testing.dec.parametrize('base, power, expected',",
            "                    [(1, 1, 1),",
            "                    (2, 1, 2),",
            "                    (2, 2, 4)])",
            "            def check_parametrize(base, power, expected):",
            "                assert_(base**power == expected)",
            "",
            "            count = 0",
            "            for test in check_parametrize():",
            "                test[0](*test[1:])",
            "                count += 1",
            "            assert_(count == 3)",
            "        self.assert_deprecated(_test_parametrize)",
            "",
            "",
            "class TestSingleElementSignature(_DeprecationTestCase):",
            "    # Deprecated 2021-04-01, NumPy 1.21",
            "    message = r\"The use of a length 1\"",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.add(1, 2, signature=\"d\"))",
            "        self.assert_deprecated(lambda: np.add(1, 2, sig=(np.dtype(\"l\"),)))",
            "",
            "",
            "class TestComparisonBadDType(_DeprecationTestCase):",
            "    # Deprecated 2021-04-01, NumPy 1.21",
            "    message = r\"using `dtype=` in comparisons is only useful for\"",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.equal(1, 1, dtype=np.int64))",
            "        # Not an error only for the transition",
            "        self.assert_deprecated(lambda: np.equal(1, 1, sig=(None, None, \"l\")))",
            "",
            "    def test_not_deprecated(self):",
            "        np.equal(True, False, dtype=bool)",
            "        np.equal(3, 5, dtype=bool, casting=\"unsafe\")",
            "        np.equal([None], [4], dtype=object)",
            "",
            "class TestComparisonBadObjectDType(_DeprecationTestCase):",
            "    # Deprecated 2021-04-01, NumPy 1.21  (different branch of the above one)",
            "    message = r\"using `dtype=object` \\(or equivalent signature\\) will\"",
            "    warning_cls = FutureWarning",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.equal(1, 1, dtype=object))",
            "        self.assert_deprecated(",
            "                lambda: np.equal(1, 1, sig=(None, None, object)))",
            "",
            "",
            "class TestSpecialAttributeLookupFailure(_DeprecationTestCase):",
            "    message = r\"An exception was ignored while fetching the attribute\"",
            "",
            "    class WeirdArrayLike:",
            "        @property",
            "        def __array__(self):",
            "            raise RuntimeError(\"oops!\")",
            "",
            "    class WeirdArrayInterface:",
            "        @property",
            "        def __array_interface__(self):",
            "            raise RuntimeError(\"oops!\")",
            "",
            "    def test_deprecated(self):",
            "        self.assert_deprecated(lambda: np.array(self.WeirdArrayLike()))",
            "        self.assert_deprecated(lambda: np.array(self.WeirdArrayInterface()))",
            "",
            "",
            "class TestCtypesGetter(_DeprecationTestCase):",
            "    # Deprecated 2021-05-18, Numpy 1.21.0",
            "    warning_cls = DeprecationWarning",
            "    ctypes = np.array([1]).ctypes",
            "",
            "    @pytest.mark.parametrize(",
            "        \"name\", [\"get_data\", \"get_shape\", \"get_strides\", \"get_as_parameter\"]",
            "    )",
            "    def test_deprecated(self, name: str) -> None:",
            "        func = getattr(self.ctypes, name)",
            "        self.assert_deprecated(lambda: func())",
            "",
            "    @pytest.mark.parametrize(",
            "        \"name\", [\"data\", \"shape\", \"strides\", \"_as_parameter_\"]",
            "    )",
            "    def test_not_deprecated(self, name: str) -> None:",
            "        self.assert_not_deprecated(lambda: getattr(self.ctypes, name))"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "317": [
                "TestNumericStyleTypecodes"
            ],
            "318": [
                "TestNumericStyleTypecodes"
            ],
            "319": [
                "TestNumericStyleTypecodes"
            ],
            "320": [
                "TestNumericStyleTypecodes"
            ],
            "321": [
                "TestNumericStyleTypecodes"
            ],
            "322": [
                "TestNumericStyleTypecodes"
            ],
            "323": [
                "TestNumericStyleTypecodes",
                "test_all_dtypes"
            ],
            "324": [
                "TestNumericStyleTypecodes",
                "test_all_dtypes"
            ],
            "325": [
                "TestNumericStyleTypecodes",
                "test_all_dtypes"
            ],
            "326": [
                "TestNumericStyleTypecodes",
                "test_all_dtypes"
            ],
            "327": [
                "TestNumericStyleTypecodes",
                "test_all_dtypes"
            ],
            "328": [
                "TestNumericStyleTypecodes",
                "test_all_dtypes"
            ],
            "329": [
                "TestNumericStyleTypecodes",
                "test_all_dtypes"
            ],
            "330": [],
            "331": []
        },
        "addLocation": []
    },
    "numpy/core/tests/test_dtype.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 109,
                "afterPatchRowNumber": 109,
                "PatchRowcode": "             operation(np.dtype(np.int32), 7)"
            },
            "1": {
                "beforePatchRowNumber": 110,
                "afterPatchRowNumber": 110,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 111,
                "afterPatchRowNumber": 111,
                "PatchRowcode": "     @pytest.mark.parametrize(\"dtype\","
            },
            "3": {
                "beforePatchRowNumber": 112,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-             ['Bool', 'Complex32', 'Complex64', 'Float16', 'Float32', 'Float64',"
            },
            "4": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-              'Int8', 'Int16', 'Int32', 'Int64', 'Object0', 'Timedelta64',"
            },
            "5": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-              'UInt8', 'UInt16', 'UInt32', 'UInt64', 'Void0',"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 112,
                "PatchRowcode": "+             ['Bool', 'Bytes0', 'Complex32', 'Complex64',"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 113,
                "PatchRowcode": "+              'Datetime64', 'Float16', 'Float32', 'Float64',"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 114,
                "PatchRowcode": "+              'Int8', 'Int16', 'Int32', 'Int64', "
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 115,
                "PatchRowcode": "+              'Object0', 'Str0', 'Timedelta64',"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+              'UInt8', 'UInt16', 'Uint32', 'UInt32', "
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 117,
                "PatchRowcode": "+              'Uint64', 'UInt64', 'Void0',"
            },
            "12": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "               \"Float128\", \"Complex128\"])"
            },
            "13": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "     def test_numeric_style_types_are_invalid(self, dtype):"
            },
            "14": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 120,
                "PatchRowcode": "         with assert_raises(TypeError):"
            }
        },
        "frontPatchFile": [
            "import sys",
            "import operator",
            "import pytest",
            "import ctypes",
            "import gc",
            "import warnings",
            "",
            "import numpy as np",
            "from numpy.core._rational_tests import rational",
            "from numpy.core._multiarray_tests import create_custom_field_dtype",
            "from numpy.testing import (",
            "    assert_, assert_equal, assert_array_equal, assert_raises, HAS_REFCOUNT,",
            "    IS_PYSTON)",
            "from numpy.compat import pickle",
            "from itertools import permutations",
            "",
            "",
            "def assert_dtype_equal(a, b):",
            "    assert_equal(a, b)",
            "    assert_equal(hash(a), hash(b),",
            "                 \"two equivalent types do not hash to the same value !\")",
            "",
            "def assert_dtype_not_equal(a, b):",
            "    assert_(a != b)",
            "    assert_(hash(a) != hash(b),",
            "            \"two different types hash to the same value !\")",
            "",
            "class TestBuiltin:",
            "    @pytest.mark.parametrize('t', [int, float, complex, np.int32, str, object,",
            "                                   np.compat.unicode])",
            "    def test_run(self, t):",
            "        \"\"\"Only test hash runs at all.\"\"\"",
            "        dt = np.dtype(t)",
            "        hash(dt)",
            "",
            "    @pytest.mark.parametrize('t', [int, float])",
            "    def test_dtype(self, t):",
            "        # Make sure equivalent byte order char hash the same (e.g. < and = on",
            "        # little endian)",
            "        dt = np.dtype(t)",
            "        dt2 = dt.newbyteorder(\"<\")",
            "        dt3 = dt.newbyteorder(\">\")",
            "        if dt == dt2:",
            "            assert_(dt.byteorder != dt2.byteorder, \"bogus test\")",
            "            assert_dtype_equal(dt, dt2)",
            "        else:",
            "            assert_(dt.byteorder != dt3.byteorder, \"bogus test\")",
            "            assert_dtype_equal(dt, dt3)",
            "",
            "    def test_equivalent_dtype_hashing(self):",
            "        # Make sure equivalent dtypes with different type num hash equal",
            "        uintp = np.dtype(np.uintp)",
            "        if uintp.itemsize == 4:",
            "            left = uintp",
            "            right = np.dtype(np.uint32)",
            "        else:",
            "            left = uintp",
            "            right = np.dtype(np.ulonglong)",
            "        assert_(left == right)",
            "        assert_(hash(left) == hash(right))",
            "",
            "    def test_invalid_types(self):",
            "        # Make sure invalid type strings raise an error",
            "",
            "        assert_raises(TypeError, np.dtype, 'O3')",
            "        assert_raises(TypeError, np.dtype, 'O5')",
            "        assert_raises(TypeError, np.dtype, 'O7')",
            "        assert_raises(TypeError, np.dtype, 'b3')",
            "        assert_raises(TypeError, np.dtype, 'h4')",
            "        assert_raises(TypeError, np.dtype, 'I5')",
            "        assert_raises(TypeError, np.dtype, 'e3')",
            "        assert_raises(TypeError, np.dtype, 'f5')",
            "",
            "        if np.dtype('g').itemsize == 8 or np.dtype('g').itemsize == 16:",
            "            assert_raises(TypeError, np.dtype, 'g12')",
            "        elif np.dtype('g').itemsize == 12:",
            "            assert_raises(TypeError, np.dtype, 'g16')",
            "",
            "        if np.dtype('l').itemsize == 8:",
            "            assert_raises(TypeError, np.dtype, 'l4')",
            "            assert_raises(TypeError, np.dtype, 'L4')",
            "        else:",
            "            assert_raises(TypeError, np.dtype, 'l8')",
            "            assert_raises(TypeError, np.dtype, 'L8')",
            "",
            "        if np.dtype('q').itemsize == 8:",
            "            assert_raises(TypeError, np.dtype, 'q4')",
            "            assert_raises(TypeError, np.dtype, 'Q4')",
            "        else:",
            "            assert_raises(TypeError, np.dtype, 'q8')",
            "            assert_raises(TypeError, np.dtype, 'Q8')",
            "",
            "    def test_richcompare_invalid_dtype_equality(self):",
            "        # Make sure objects that cannot be converted to valid",
            "        # dtypes results in False/True when compared to valid dtypes.",
            "        # Here 7 cannot be converted to dtype. No exceptions should be raised",
            "",
            "        assert not np.dtype(np.int32) == 7, \"dtype richcompare failed for ==\"",
            "        assert np.dtype(np.int32) != 7, \"dtype richcompare failed for !=\"",
            "",
            "    @pytest.mark.parametrize(",
            "        'operation',",
            "        [operator.le, operator.lt, operator.ge, operator.gt])",
            "    def test_richcompare_invalid_dtype_comparison(self, operation):",
            "        # Make sure TypeError is raised for comparison operators",
            "        # for invalid dtypes. Here 7 is an invalid dtype.",
            "",
            "        with pytest.raises(TypeError):",
            "            operation(np.dtype(np.int32), 7)",
            "",
            "    @pytest.mark.parametrize(\"dtype\",",
            "             ['Bool', 'Complex32', 'Complex64', 'Float16', 'Float32', 'Float64',",
            "              'Int8', 'Int16', 'Int32', 'Int64', 'Object0', 'Timedelta64',",
            "              'UInt8', 'UInt16', 'UInt32', 'UInt64', 'Void0',",
            "              \"Float128\", \"Complex128\"])",
            "    def test_numeric_style_types_are_invalid(self, dtype):",
            "        with assert_raises(TypeError):",
            "            np.dtype(dtype)",
            "",
            "    @pytest.mark.parametrize(",
            "        'value',",
            "        ['m8', 'M8', 'datetime64', 'timedelta64',",
            "         'i4, (2,3)f8, f4', 'a3, 3u8, (3,4)a10',",
            "         '>f', '<f', '=f', '|f',",
            "        ])",
            "    def test_dtype_bytes_str_equivalence(self, value):",
            "        bytes_value = value.encode('ascii')",
            "        from_bytes = np.dtype(bytes_value)",
            "        from_str = np.dtype(value)",
            "        assert_dtype_equal(from_bytes, from_str)",
            "",
            "    def test_dtype_from_bytes(self):",
            "        # Empty bytes object",
            "        assert_raises(TypeError, np.dtype, b'')",
            "        # Byte order indicator, but no type",
            "        assert_raises(TypeError, np.dtype, b'|')",
            "",
            "        # Single character with ordinal < NPY_NTYPES returns",
            "        # type by index into _builtin_descrs",
            "        assert_dtype_equal(np.dtype(bytes([0])), np.dtype('bool'))",
            "        assert_dtype_equal(np.dtype(bytes([17])), np.dtype(object))",
            "",
            "        # Single character where value is a valid type code",
            "        assert_dtype_equal(np.dtype(b'f'), np.dtype('float32'))",
            "",
            "        # Bytes with non-ascii values raise errors",
            "        assert_raises(TypeError, np.dtype, b'\\xff')",
            "        assert_raises(TypeError, np.dtype, b's\\xff')",
            "",
            "    def test_bad_param(self):",
            "        # Can't give a size that's too small",
            "        assert_raises(ValueError, np.dtype,",
            "                        {'names':['f0', 'f1'],",
            "                         'formats':['i4', 'i1'],",
            "                         'offsets':[0, 4],",
            "                         'itemsize':4})",
            "        # If alignment is enabled, the alignment (4) must divide the itemsize",
            "        assert_raises(ValueError, np.dtype,",
            "                        {'names':['f0', 'f1'],",
            "                         'formats':['i4', 'i1'],",
            "                         'offsets':[0, 4],",
            "                         'itemsize':9}, align=True)",
            "        # If alignment is enabled, the individual fields must be aligned",
            "        assert_raises(ValueError, np.dtype,",
            "                        {'names':['f0', 'f1'],",
            "                         'formats':['i1', 'f4'],",
            "                         'offsets':[0, 2]}, align=True)",
            "",
            "    def test_field_order_equality(self):",
            "        x = np.dtype({'names': ['A', 'B'],",
            "                      'formats': ['i4', 'f4'],",
            "                      'offsets': [0, 4]})",
            "        y = np.dtype({'names': ['B', 'A'],",
            "                      'formats': ['f4', 'i4'],",
            "                      'offsets': [4, 0]})",
            "        assert_equal(x == y, False)",
            "        # But it is currently an equivalent cast:",
            "        assert np.can_cast(x, y, casting=\"equiv\")",
            "",
            "",
            "class TestRecord:",
            "    def test_equivalent_record(self):",
            "        \"\"\"Test whether equivalent record dtypes hash the same.\"\"\"",
            "        a = np.dtype([('yo', int)])",
            "        b = np.dtype([('yo', int)])",
            "        assert_dtype_equal(a, b)",
            "",
            "    def test_different_names(self):",
            "        # In theory, they may hash the same (collision) ?",
            "        a = np.dtype([('yo', int)])",
            "        b = np.dtype([('ye', int)])",
            "        assert_dtype_not_equal(a, b)",
            "",
            "    def test_different_titles(self):",
            "        # In theory, they may hash the same (collision) ?",
            "        a = np.dtype({'names': ['r', 'b'],",
            "                      'formats': ['u1', 'u1'],",
            "                      'titles': ['Red pixel', 'Blue pixel']})",
            "        b = np.dtype({'names': ['r', 'b'],",
            "                      'formats': ['u1', 'u1'],",
            "                      'titles': ['RRed pixel', 'Blue pixel']})",
            "        assert_dtype_not_equal(a, b)",
            "",
            "    @pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")",
            "    def test_refcount_dictionary_setting(self):",
            "        names = [\"name1\"]",
            "        formats = [\"f8\"]",
            "        titles = [\"t1\"]",
            "        offsets = [0]",
            "        d = dict(names=names, formats=formats, titles=titles, offsets=offsets)",
            "        refcounts = {k: sys.getrefcount(i) for k, i in d.items()}",
            "        np.dtype(d)",
            "        refcounts_new = {k: sys.getrefcount(i) for k, i in d.items()}",
            "        assert refcounts == refcounts_new",
            "",
            "    def test_mutate(self):",
            "        # Mutating a dtype should reset the cached hash value",
            "        a = np.dtype([('yo', int)])",
            "        b = np.dtype([('yo', int)])",
            "        c = np.dtype([('ye', int)])",
            "        assert_dtype_equal(a, b)",
            "        assert_dtype_not_equal(a, c)",
            "        a.names = ['ye']",
            "        assert_dtype_equal(a, c)",
            "        assert_dtype_not_equal(a, b)",
            "        state = b.__reduce__()[2]",
            "        a.__setstate__(state)",
            "        assert_dtype_equal(a, b)",
            "        assert_dtype_not_equal(a, c)",
            "",
            "    def test_not_lists(self):",
            "        \"\"\"Test if an appropriate exception is raised when passing bad values to",
            "        the dtype constructor.",
            "        \"\"\"",
            "        assert_raises(TypeError, np.dtype,",
            "                      dict(names={'A', 'B'}, formats=['f8', 'i4']))",
            "        assert_raises(TypeError, np.dtype,",
            "                      dict(names=['A', 'B'], formats={'f8', 'i4'}))",
            "",
            "    def test_aligned_size(self):",
            "        # Check that structured dtypes get padded to an aligned size",
            "        dt = np.dtype('i4, i1', align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        dt = np.dtype([('f0', 'i4'), ('f1', 'i1')], align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        dt = np.dtype({'names':['f0', 'f1'],",
            "                       'formats':['i4', 'u1'],",
            "                       'offsets':[0, 4]}, align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        dt = np.dtype({'f0': ('i4', 0), 'f1':('u1', 4)}, align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        # Nesting should preserve that alignment",
            "        dt1 = np.dtype([('f0', 'i4'),",
            "                       ('f1', [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')]),",
            "                       ('f2', 'i1')], align=True)",
            "        assert_equal(dt1.itemsize, 20)",
            "        dt2 = np.dtype({'names':['f0', 'f1', 'f2'],",
            "                       'formats':['i4',",
            "                                  [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')],",
            "                                  'i1'],",
            "                       'offsets':[0, 4, 16]}, align=True)",
            "        assert_equal(dt2.itemsize, 20)",
            "        dt3 = np.dtype({'f0': ('i4', 0),",
            "                       'f1': ([('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')], 4),",
            "                       'f2': ('i1', 16)}, align=True)",
            "        assert_equal(dt3.itemsize, 20)",
            "        assert_equal(dt1, dt2)",
            "        assert_equal(dt2, dt3)",
            "        # Nesting should preserve packing",
            "        dt1 = np.dtype([('f0', 'i4'),",
            "                       ('f1', [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')]),",
            "                       ('f2', 'i1')], align=False)",
            "        assert_equal(dt1.itemsize, 11)",
            "        dt2 = np.dtype({'names':['f0', 'f1', 'f2'],",
            "                       'formats':['i4',",
            "                                  [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')],",
            "                                  'i1'],",
            "                       'offsets':[0, 4, 10]}, align=False)",
            "        assert_equal(dt2.itemsize, 11)",
            "        dt3 = np.dtype({'f0': ('i4', 0),",
            "                       'f1': ([('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')], 4),",
            "                       'f2': ('i1', 10)}, align=False)",
            "        assert_equal(dt3.itemsize, 11)",
            "        assert_equal(dt1, dt2)",
            "        assert_equal(dt2, dt3)",
            "        # Array of subtype should preserve alignment",
            "        dt1 = np.dtype([('a', '|i1'),",
            "                        ('b', [('f0', '<i2'),",
            "                        ('f1', '<f4')], 2)], align=True)",
            "        assert_equal(dt1.descr, [('a', '|i1'), ('', '|V3'),",
            "                                 ('b', [('f0', '<i2'), ('', '|V2'),",
            "                                 ('f1', '<f4')], (2,))])",
            "",
            "    def test_union_struct(self):",
            "        # Should be able to create union dtypes",
            "        dt = np.dtype({'names':['f0', 'f1', 'f2'], 'formats':['<u4', '<u2', '<u2'],",
            "                        'offsets':[0, 0, 2]}, align=True)",
            "        assert_equal(dt.itemsize, 4)",
            "        a = np.array([3], dtype='<u4').view(dt)",
            "        a['f1'] = 10",
            "        a['f2'] = 36",
            "        assert_equal(a['f0'], 10 + 36*256*256)",
            "        # Should be able to specify fields out of order",
            "        dt = np.dtype({'names':['f0', 'f1', 'f2'], 'formats':['<u4', '<u2', '<u2'],",
            "                        'offsets':[4, 0, 2]}, align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        # field name should not matter: assignment is by position",
            "        dt2 = np.dtype({'names':['f2', 'f0', 'f1'],",
            "                        'formats':['<u4', '<u2', '<u2'],",
            "                        'offsets':[4, 0, 2]}, align=True)",
            "        vals = [(0, 1, 2), (3, -1, 4)]",
            "        vals2 = [(0, 1, 2), (3, -1, 4)]",
            "        a = np.array(vals, dt)",
            "        b = np.array(vals2, dt2)",
            "        assert_equal(a.astype(dt2), b)",
            "        assert_equal(b.astype(dt), a)",
            "        assert_equal(a.view(dt2), b)",
            "        assert_equal(b.view(dt), a)",
            "        # Should not be able to overlap objects with other types",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':['O', 'i1'],",
            "                 'offsets':[0, 2]})",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':['i4', 'O'],",
            "                 'offsets':[0, 3]})",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':[[('a', 'O')], 'i1'],",
            "                 'offsets':[0, 2]})",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':['i4', [('a', 'O')]],",
            "                 'offsets':[0, 3]})",
            "        # Out of order should still be ok, however",
            "        dt = np.dtype({'names':['f0', 'f1'],",
            "                       'formats':['i1', 'O'],",
            "                       'offsets':[np.dtype('intp').itemsize, 0]})",
            "",
            "    @pytest.mark.parametrize([\"obj\", \"dtype\", \"expected\"],",
            "        [([], (\"(2)f4,\"), np.empty((0, 2), dtype=\"f4\")),",
            "         (3, \"(3)f4,\", [3, 3, 3]),",
            "         (np.float64(2), \"(2)f4,\", [2, 2]),",
            "         ([((0, 1), (1, 2)), ((2,),)], '(2,2)f4', None),",
            "         ([\"1\", \"2\"], \"(2)i,\", None)])",
            "    def test_subarray_list(self, obj, dtype, expected):",
            "        dtype = np.dtype(dtype)",
            "        res = np.array(obj, dtype=dtype)",
            "",
            "        if expected is None:",
            "            # iterate the 1-d list to fill the array",
            "            expected = np.empty(len(obj), dtype=dtype)",
            "            for i in range(len(expected)):",
            "                expected[i] = obj[i]",
            "",
            "        assert_array_equal(res, expected)",
            "",
            "    def test_comma_datetime(self):",
            "        dt = np.dtype('M8[D],datetime64[Y],i8')",
            "        assert_equal(dt, np.dtype([('f0', 'M8[D]'),",
            "                                   ('f1', 'datetime64[Y]'),",
            "                                   ('f2', 'i8')]))",
            "",
            "    def test_from_dictproxy(self):",
            "        # Tests for PR #5920",
            "        dt = np.dtype({'names': ['a', 'b'], 'formats': ['i4', 'f4']})",
            "        assert_dtype_equal(dt, np.dtype(dt.fields))",
            "        dt2 = np.dtype((np.void, dt.fields))",
            "        assert_equal(dt2.fields, dt.fields)",
            "",
            "    def test_from_dict_with_zero_width_field(self):",
            "        # Regression test for #6430 / #2196",
            "        dt = np.dtype([('val1', np.float32, (0,)), ('val2', int)])",
            "        dt2 = np.dtype({'names': ['val1', 'val2'],",
            "                        'formats': [(np.float32, (0,)), int]})",
            "",
            "        assert_dtype_equal(dt, dt2)",
            "        assert_equal(dt.fields['val1'][0].itemsize, 0)",
            "        assert_equal(dt.itemsize, dt.fields['val2'][0].itemsize)",
            "",
            "    def test_bool_commastring(self):",
            "        d = np.dtype('?,?,?')  # raises?",
            "        assert_equal(len(d.names), 3)",
            "        for n in d.names:",
            "            assert_equal(d.fields[n][0], np.dtype('?'))",
            "",
            "    def test_nonint_offsets(self):",
            "        # gh-8059",
            "        def make_dtype(off):",
            "            return np.dtype({'names': ['A'], 'formats': ['i4'],",
            "                             'offsets': [off]})",
            "",
            "        assert_raises(TypeError, make_dtype, 'ASD')",
            "        assert_raises(OverflowError, make_dtype, 2**70)",
            "        assert_raises(TypeError, make_dtype, 2.3)",
            "        assert_raises(ValueError, make_dtype, -10)",
            "",
            "        # no errors here:",
            "        dt = make_dtype(np.uint32(0))",
            "        np.zeros(1, dtype=dt)[0].item()",
            "",
            "    def test_fields_by_index(self):",
            "        dt = np.dtype([('a', np.int8), ('b', np.float32, 3)])",
            "        assert_dtype_equal(dt[0], np.dtype(np.int8))",
            "        assert_dtype_equal(dt[1], np.dtype((np.float32, 3)))",
            "        assert_dtype_equal(dt[-1], dt[1])",
            "        assert_dtype_equal(dt[-2], dt[0])",
            "        assert_raises(IndexError, lambda: dt[-3])",
            "",
            "        assert_raises(TypeError, operator.getitem, dt, 3.0)",
            "",
            "        assert_equal(dt[1], dt[np.int8(1)])",
            "",
            "    @pytest.mark.parametrize('align_flag',[False, True])",
            "    def test_multifield_index(self, align_flag):",
            "        # indexing with a list produces subfields",
            "        # the align flag should be preserved",
            "        dt = np.dtype([",
            "            (('title', 'col1'), '<U20'), ('A', '<f8'), ('B', '<f8')",
            "        ], align=align_flag)",
            "",
            "        dt_sub = dt[['B', 'col1']]",
            "        assert_equal(",
            "            dt_sub,",
            "            np.dtype({",
            "                'names': ['B', 'col1'],",
            "                'formats': ['<f8', '<U20'],",
            "                'offsets': [88, 0],",
            "                'titles': [None, 'title'],",
            "                'itemsize': 96",
            "            })",
            "        )",
            "        assert_equal(dt_sub.isalignedstruct, align_flag)",
            "",
            "        dt_sub = dt[['B']]",
            "        assert_equal(",
            "            dt_sub,",
            "            np.dtype({",
            "                'names': ['B'],",
            "                'formats': ['<f8'],",
            "                'offsets': [88],",
            "                'itemsize': 96",
            "            })",
            "        )",
            "        assert_equal(dt_sub.isalignedstruct, align_flag)",
            "",
            "        dt_sub = dt[[]]",
            "        assert_equal(",
            "            dt_sub,",
            "            np.dtype({",
            "                'names': [],",
            "                'formats': [],",
            "                'offsets': [],",
            "                'itemsize': 96",
            "            })",
            "        )",
            "        assert_equal(dt_sub.isalignedstruct, align_flag)",
            "",
            "        assert_raises(TypeError, operator.getitem, dt, ())",
            "        assert_raises(TypeError, operator.getitem, dt, [1, 2, 3])",
            "        assert_raises(TypeError, operator.getitem, dt, ['col1', 2])",
            "        assert_raises(KeyError, operator.getitem, dt, ['fake'])",
            "        assert_raises(KeyError, operator.getitem, dt, ['title'])",
            "        assert_raises(ValueError, operator.getitem, dt, ['col1', 'col1'])",
            "",
            "    def test_partial_dict(self):",
            "        # 'names' is missing",
            "        assert_raises(ValueError, np.dtype,",
            "                {'formats': ['i4', 'i4'], 'f0': ('i4', 0), 'f1':('i4', 4)})",
            "",
            "    def test_fieldless_views(self):",
            "        a = np.zeros(2, dtype={'names':[], 'formats':[], 'offsets':[],",
            "                               'itemsize':8})",
            "        assert_raises(ValueError, a.view, np.dtype([]))",
            "",
            "        d = np.dtype((np.dtype([]), 10))",
            "        assert_equal(d.shape, (10,))",
            "        assert_equal(d.itemsize, 0)",
            "        assert_equal(d.base, np.dtype([]))",
            "",
            "        arr = np.fromiter((() for i in range(10)), [])",
            "        assert_equal(arr.dtype, np.dtype([]))",
            "        assert_raises(ValueError, np.frombuffer, b'', dtype=[])",
            "        assert_equal(np.frombuffer(b'', dtype=[], count=2),",
            "                     np.empty(2, dtype=[]))",
            "",
            "        assert_raises(ValueError, np.dtype, ([], 'f8'))",
            "        assert_raises(ValueError, np.zeros(1, dtype='i4').view, [])",
            "",
            "        assert_equal(np.zeros(2, dtype=[]) == np.zeros(2, dtype=[]),",
            "                     np.ones(2, dtype=bool))",
            "",
            "        assert_equal(np.zeros((1, 2), dtype=[]) == a,",
            "                     np.ones((1, 2), dtype=bool))",
            "",
            "",
            "class TestSubarray:",
            "    def test_single_subarray(self):",
            "        a = np.dtype((int, (2)))",
            "        b = np.dtype((int, (2,)))",
            "        assert_dtype_equal(a, b)",
            "",
            "        assert_equal(type(a.subdtype[1]), tuple)",
            "        assert_equal(type(b.subdtype[1]), tuple)",
            "",
            "    def test_equivalent_record(self):",
            "        \"\"\"Test whether equivalent subarray dtypes hash the same.\"\"\"",
            "        a = np.dtype((int, (2, 3)))",
            "        b = np.dtype((int, (2, 3)))",
            "        assert_dtype_equal(a, b)",
            "",
            "    def test_nonequivalent_record(self):",
            "        \"\"\"Test whether different subarray dtypes hash differently.\"\"\"",
            "        a = np.dtype((int, (2, 3)))",
            "        b = np.dtype((int, (3, 2)))",
            "        assert_dtype_not_equal(a, b)",
            "",
            "        a = np.dtype((int, (2, 3)))",
            "        b = np.dtype((int, (2, 2)))",
            "        assert_dtype_not_equal(a, b)",
            "",
            "        a = np.dtype((int, (1, 2, 3)))",
            "        b = np.dtype((int, (1, 2)))",
            "        assert_dtype_not_equal(a, b)",
            "",
            "    def test_shape_equal(self):",
            "        \"\"\"Test some data types that are equal\"\"\"",
            "        assert_dtype_equal(np.dtype('f8'), np.dtype(('f8', tuple())))",
            "        # FutureWarning during deprecation period; after it is passed this",
            "        # should instead check that \"(1)f8\" == \"1f8\" == (\"f8\", 1).",
            "        with pytest.warns(FutureWarning):",
            "            assert_dtype_equal(np.dtype('f8'), np.dtype(('f8', 1)))",
            "        assert_dtype_equal(np.dtype((int, 2)), np.dtype((int, (2,))))",
            "        assert_dtype_equal(np.dtype(('<f4', (3, 2))), np.dtype(('<f4', (3, 2))))",
            "        d = ([('a', 'f4', (1, 2)), ('b', 'f8', (3, 1))], (3, 2))",
            "        assert_dtype_equal(np.dtype(d), np.dtype(d))",
            "",
            "    def test_shape_simple(self):",
            "        \"\"\"Test some simple cases that shouldn't be equal\"\"\"",
            "        assert_dtype_not_equal(np.dtype('f8'), np.dtype(('f8', (1,))))",
            "        assert_dtype_not_equal(np.dtype(('f8', (1,))), np.dtype(('f8', (1, 1))))",
            "        assert_dtype_not_equal(np.dtype(('f4', (3, 2))), np.dtype(('f4', (2, 3))))",
            "",
            "    def test_shape_monster(self):",
            "        \"\"\"Test some more complicated cases that shouldn't be equal\"\"\"",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('a', 'f4', (1, 2)), ('b', 'f8', (1, 3))], (2, 2))))",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'i8', (1, 3))], (2, 2))))",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('e', 'f8', (1, 3)), ('d', 'f4', (2, 1))], (2, 2))))",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', [('a', 'i4', 6)], (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('a', [('a', 'u4', 6)], (2, 1)), ('b', 'f8', (1, 3))], (2, 2))))",
            "",
            "    def test_shape_sequence(self):",
            "        # Any sequence of integers should work as shape, but the result",
            "        # should be a tuple (immutable) of base type integers.",
            "        a = np.array([1, 2, 3], dtype=np.int16)",
            "        l = [1, 2, 3]",
            "        # Array gets converted",
            "        dt = np.dtype([('a', 'f4', a)])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        assert_(isinstance(dt['a'].shape[0], int))",
            "        # List gets converted",
            "        dt = np.dtype([('a', 'f4', l)])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        #",
            "",
            "        class IntLike:",
            "            def __index__(self):",
            "                return 3",
            "",
            "            def __int__(self):",
            "                # (a PyNumber_Check fails without __int__)",
            "                return 3",
            "",
            "        dt = np.dtype([('a', 'f4', IntLike())])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        assert_(isinstance(dt['a'].shape[0], int))",
            "        dt = np.dtype([('a', 'f4', (IntLike(),))])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        assert_(isinstance(dt['a'].shape[0], int))",
            "",
            "    def test_shape_matches_ndim(self):",
            "        dt = np.dtype([('a', 'f4', ())])",
            "        assert_equal(dt['a'].shape, ())",
            "        assert_equal(dt['a'].ndim, 0)",
            "",
            "        dt = np.dtype([('a', 'f4')])",
            "        assert_equal(dt['a'].shape, ())",
            "        assert_equal(dt['a'].ndim, 0)",
            "",
            "        dt = np.dtype([('a', 'f4', 4)])",
            "        assert_equal(dt['a'].shape, (4,))",
            "        assert_equal(dt['a'].ndim, 1)",
            "",
            "        dt = np.dtype([('a', 'f4', (1, 2, 3))])",
            "        assert_equal(dt['a'].shape, (1, 2, 3))",
            "        assert_equal(dt['a'].ndim, 3)",
            "",
            "    def test_shape_invalid(self):",
            "        # Check that the shape is valid.",
            "        max_int = np.iinfo(np.intc).max",
            "        max_intp = np.iinfo(np.intp).max",
            "        # Too large values (the datatype is part of this)",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', max_int // 4 + 1)])",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', max_int + 1)])",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', (max_int, 2))])",
            "        # Takes a different code path (fails earlier:",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', max_intp + 1)])",
            "        # Negative values",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', -1)])",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', (-1, -1))])",
            "",
            "    def test_alignment(self):",
            "        #Check that subarrays are aligned",
            "        t1 = np.dtype('(1,)i4', align=True)",
            "        t2 = np.dtype('2i4', align=True)",
            "        assert_equal(t1.alignment, t2.alignment)",
            "",
            "",
            "def iter_struct_object_dtypes():",
            "    \"\"\"",
            "    Iterates over a few complex dtypes and object pattern which",
            "    fill the array with a given object (defaults to a singleton).",
            "",
            "    Yields",
            "    ------",
            "    dtype : dtype",
            "    pattern : tuple",
            "        Structured tuple for use with `np.array`.",
            "    count : int",
            "        Number of objects stored in the dtype.",
            "    singleton : object",
            "        A singleton object. The returned pattern is constructed so that",
            "        all objects inside the datatype are set to the singleton.",
            "    \"\"\"",
            "    obj = object()",
            "",
            "    dt = np.dtype([('b', 'O', (2, 3))])",
            "    p = ([[obj] * 3] * 2,)",
            "    yield pytest.param(dt, p, 6, obj, id=\"<subarray>\")",
            "",
            "    dt = np.dtype([('a', 'i4'), ('b', 'O', (2, 3))])",
            "    p = (0, [[obj] * 3] * 2)",
            "    yield pytest.param(dt, p, 6, obj, id=\"<subarray in field>\")",
            "",
            "    dt = np.dtype([('a', 'i4'),",
            "                   ('b', [('ba', 'O'), ('bb', 'i1')], (2, 3))])",
            "    p = (0, [[(obj, 0)] * 3] * 2)",
            "    yield pytest.param(dt, p, 6, obj, id=\"<structured subarray 1>\")",
            "",
            "    dt = np.dtype([('a', 'i4'),",
            "                   ('b', [('ba', 'O'), ('bb', 'O')], (2, 3))])",
            "    p = (0, [[(obj, obj)] * 3] * 2)",
            "    yield pytest.param(dt, p, 12, obj, id=\"<structured subarray 2>\")",
            "",
            "",
            "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")",
            "class TestStructuredObjectRefcounting:",
            "    \"\"\"These tests cover various uses of complicated structured types which",
            "    include objects and thus require reference counting.",
            "    \"\"\"",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    @pytest.mark.parametrize([\"creation_func\", \"creation_obj\"], [",
            "        pytest.param(np.empty, None,",
            "             # None is probably used for too many things",
            "             marks=pytest.mark.skip(\"unreliable due to python's behaviour\")),",
            "        (np.ones, 1),",
            "        (np.zeros, 0)])",
            "    def test_structured_object_create_delete(self, dt, pat, count, singleton,",
            "                                             creation_func, creation_obj):",
            "        \"\"\"Structured object reference counting in creation and deletion\"\"\"",
            "        # The test assumes that 0, 1, and None are singletons.",
            "        gc.collect()",
            "        before = sys.getrefcount(creation_obj)",
            "        arr = creation_func(3, dt)",
            "",
            "        now = sys.getrefcount(creation_obj)",
            "        assert now - before == count * 3",
            "        del arr",
            "        now = sys.getrefcount(creation_obj)",
            "        assert now == before",
            "",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    def test_structured_object_item_setting(self, dt, pat, count, singleton):",
            "        \"\"\"Structured object reference counting for simple item setting\"\"\"",
            "        one = 1",
            "",
            "        gc.collect()",
            "        before = sys.getrefcount(singleton)",
            "        arr = np.array([pat] * 3, dt)",
            "        assert sys.getrefcount(singleton) - before == count * 3",
            "        # Fill with `1` and check that it was replaced correctly:",
            "        before2 = sys.getrefcount(one)",
            "        arr[...] = one",
            "        after2 = sys.getrefcount(one)",
            "        assert after2 - before2 == count * 3",
            "        del arr",
            "        gc.collect()",
            "        assert sys.getrefcount(one) == before2",
            "        assert sys.getrefcount(singleton) == before",
            "",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    @pytest.mark.parametrize(",
            "        ['shape', 'index', 'items_changed'],",
            "        [((3,), ([0, 2],), 2),",
            "         ((3, 2), ([0, 2], slice(None)), 4),",
            "         ((3, 2), ([0, 2], [1]), 2),",
            "         ((3,), ([True, False, True]), 2)])",
            "    def test_structured_object_indexing(self, shape, index, items_changed,",
            "                                        dt, pat, count, singleton):",
            "        \"\"\"Structured object reference counting for advanced indexing.\"\"\"",
            "        zero = 0",
            "        one = 1",
            "",
            "        arr = np.zeros(shape, dt)",
            "",
            "        gc.collect()",
            "        before_zero = sys.getrefcount(zero)",
            "        before_one = sys.getrefcount(one)",
            "        # Test item getting:",
            "        part = arr[index]",
            "        after_zero = sys.getrefcount(zero)",
            "        assert after_zero - before_zero == count * items_changed",
            "        del part",
            "        # Test item setting:",
            "        arr[index] = one",
            "        gc.collect()",
            "        after_zero = sys.getrefcount(zero)",
            "        after_one = sys.getrefcount(one)",
            "        assert before_zero - after_zero == count * items_changed",
            "        assert after_one - before_one == count * items_changed",
            "",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    def test_structured_object_take_and_repeat(self, dt, pat, count, singleton):",
            "        \"\"\"Structured object reference counting for specialized functions.",
            "        The older functions such as take and repeat use different code paths",
            "        then item setting (when writing this).",
            "        \"\"\"",
            "        indices = [0, 1]",
            "",
            "        arr = np.array([pat] * 3, dt)",
            "        gc.collect()",
            "        before = sys.getrefcount(singleton)",
            "        res = arr.take(indices)",
            "        after = sys.getrefcount(singleton)",
            "        assert after - before == count * 2",
            "        new = res.repeat(10)",
            "        gc.collect()",
            "        after_repeat = sys.getrefcount(singleton)",
            "        assert after_repeat - after == count * 2 * 10",
            "",
            "",
            "class TestStructuredDtypeSparseFields:",
            "    \"\"\"Tests subarray fields which contain sparse dtypes so that",
            "    not all memory is used by the dtype work. Such dtype's should",
            "    leave the underlying memory unchanged.",
            "    \"\"\"",
            "    dtype = np.dtype([('a', {'names':['aa', 'ab'], 'formats':['f', 'f'],",
            "                             'offsets':[0, 4]}, (2, 3))])",
            "    sparse_dtype = np.dtype([('a', {'names':['ab'], 'formats':['f'],",
            "                                    'offsets':[4]}, (2, 3))])",
            "",
            "    def test_sparse_field_assignment(self):",
            "        arr = np.zeros(3, self.dtype)",
            "        sparse_arr = arr.view(self.sparse_dtype)",
            "",
            "        sparse_arr[...] = np.finfo(np.float32).max",
            "        # dtype is reduced when accessing the field, so shape is (3, 2, 3):",
            "        assert_array_equal(arr[\"a\"][\"aa\"], np.zeros((3, 2, 3)))",
            "",
            "    def test_sparse_field_assignment_fancy(self):",
            "        # Fancy assignment goes to the copyswap function for complex types:",
            "        arr = np.zeros(3, self.dtype)",
            "        sparse_arr = arr.view(self.sparse_dtype)",
            "",
            "        sparse_arr[[0, 1, 2]] = np.finfo(np.float32).max",
            "        # dtype is reduced when accessing the field, so shape is (3, 2, 3):",
            "        assert_array_equal(arr[\"a\"][\"aa\"], np.zeros((3, 2, 3)))",
            "",
            "",
            "class TestMonsterType:",
            "    \"\"\"Test deeply nested subtypes.\"\"\"",
            "",
            "    def test1(self):",
            "        simple1 = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],",
            "            'titles': ['Red pixel', 'Blue pixel']})",
            "        a = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((int, (3, 2))))])",
            "        b = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((int, (3, 2))))])",
            "        assert_dtype_equal(a, b)",
            "",
            "        c = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((a, (3, 2))))])",
            "        d = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((a, (3, 2))))])",
            "        assert_dtype_equal(c, d)",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_list_recursion(self):",
            "        l = list()",
            "        l.append(('f', l))",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(l)",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_tuple_recursion(self):",
            "        d = np.int32",
            "        for i in range(100000):",
            "            d = (d, (1,))",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(d)",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_dict_recursion(self):",
            "        d = dict(names=['self'], formats=[None], offsets=[0])",
            "        d['formats'][0] = d",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(d)",
            "",
            "",
            "class TestMetadata:",
            "    def test_no_metadata(self):",
            "        d = np.dtype(int)",
            "        assert_(d.metadata is None)",
            "",
            "    def test_metadata_takes_dict(self):",
            "        d = np.dtype(int, metadata={'datum': 1})",
            "        assert_(d.metadata == {'datum': 1})",
            "",
            "    def test_metadata_rejects_nondict(self):",
            "        assert_raises(TypeError, np.dtype, int, metadata='datum')",
            "        assert_raises(TypeError, np.dtype, int, metadata=1)",
            "        assert_raises(TypeError, np.dtype, int, metadata=None)",
            "",
            "    def test_nested_metadata(self):",
            "        d = np.dtype([('a', np.dtype(int, metadata={'datum': 1}))])",
            "        assert_(d['a'].metadata == {'datum': 1})",
            "",
            "    def test_base_metadata_copied(self):",
            "        d = np.dtype((np.void, np.dtype('i4,i4', metadata={'datum': 1})))",
            "        assert_(d.metadata == {'datum': 1})",
            "",
            "class TestString:",
            "    def test_complex_dtype_str(self):",
            "        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),",
            "                                ('rtile', '>f4', (64, 36))], (3,)),",
            "                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),",
            "                                   ('bright', '>f4', (8, 36))])])",
            "        assert_equal(str(dt),",
            "                     \"[('top', [('tiles', ('>f4', (64, 64)), (1,)), \"",
            "                     \"('rtile', '>f4', (64, 36))], (3,)), \"",
            "                     \"('bottom', [('bleft', ('>f4', (8, 64)), (1,)), \"",
            "                     \"('bright', '>f4', (8, 36))])]\")",
            "",
            "        # If the sticky aligned flag is set to True, it makes the",
            "        # str() function use a dict representation with an 'aligned' flag",
            "        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),",
            "                                ('rtile', '>f4', (64, 36))],",
            "                                (3,)),",
            "                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),",
            "                                   ('bright', '>f4', (8, 36))])],",
            "                       align=True)",
            "        assert_equal(str(dt),",
            "                    \"{'names':['top','bottom'], \"",
            "                     \"'formats':[([('tiles', ('>f4', (64, 64)), (1,)), \"",
            "                                  \"('rtile', '>f4', (64, 36))], (3,)),\"",
            "                                 \"[('bleft', ('>f4', (8, 64)), (1,)), \"",
            "                                  \"('bright', '>f4', (8, 36))]], \"",
            "                     \"'offsets':[0,76800], \"",
            "                     \"'itemsize':80000, \"",
            "                     \"'aligned':True}\")",
            "        assert_equal(np.dtype(eval(str(dt))), dt)",
            "",
            "        dt = np.dtype({'names': ['r', 'g', 'b'], 'formats': ['u1', 'u1', 'u1'],",
            "                        'offsets': [0, 1, 2],",
            "                        'titles': ['Red pixel', 'Green pixel', 'Blue pixel']})",
            "        assert_equal(str(dt),",
            "                    \"[(('Red pixel', 'r'), 'u1'), \"",
            "                    \"(('Green pixel', 'g'), 'u1'), \"",
            "                    \"(('Blue pixel', 'b'), 'u1')]\")",
            "",
            "        dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
            "                       'formats': ['<u4', 'u1', 'u1', 'u1'],",
            "                       'offsets': [0, 0, 1, 2],",
            "                       'titles': ['Color', 'Red pixel',",
            "                                  'Green pixel', 'Blue pixel']})",
            "        assert_equal(str(dt),",
            "                    \"{'names':['rgba','r','g','b'],\"",
            "                    \" 'formats':['<u4','u1','u1','u1'],\"",
            "                    \" 'offsets':[0,0,1,2],\"",
            "                    \" 'titles':['Color','Red pixel',\"",
            "                              \"'Green pixel','Blue pixel'],\"",
            "                    \" 'itemsize':4}\")",
            "",
            "        dt = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],",
            "                        'offsets': [0, 2],",
            "                        'titles': ['Red pixel', 'Blue pixel']})",
            "        assert_equal(str(dt),",
            "                    \"{'names':['r','b'],\"",
            "                    \" 'formats':['u1','u1'],\"",
            "                    \" 'offsets':[0,2],\"",
            "                    \" 'titles':['Red pixel','Blue pixel'],\"",
            "                    \" 'itemsize':3}\")",
            "",
            "        dt = np.dtype([('a', '<m8[D]'), ('b', '<M8[us]')])",
            "        assert_equal(str(dt),",
            "                    \"[('a', '<m8[D]'), ('b', '<M8[us]')]\")",
            "",
            "    def test_repr_structured(self):",
            "        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),",
            "                                ('rtile', '>f4', (64, 36))], (3,)),",
            "                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),",
            "                                   ('bright', '>f4', (8, 36))])])",
            "        assert_equal(repr(dt),",
            "                     \"dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)), \"",
            "                     \"('rtile', '>f4', (64, 36))], (3,)), \"",
            "                     \"('bottom', [('bleft', ('>f4', (8, 64)), (1,)), \"",
            "                     \"('bright', '>f4', (8, 36))])])\")",
            "",
            "        dt = np.dtype({'names': ['r', 'g', 'b'], 'formats': ['u1', 'u1', 'u1'],",
            "                        'offsets': [0, 1, 2],",
            "                        'titles': ['Red pixel', 'Green pixel', 'Blue pixel']},",
            "                        align=True)",
            "        assert_equal(repr(dt),",
            "                    \"dtype([(('Red pixel', 'r'), 'u1'), \"",
            "                    \"(('Green pixel', 'g'), 'u1'), \"",
            "                    \"(('Blue pixel', 'b'), 'u1')], align=True)\")",
            "",
            "    def test_repr_structured_not_packed(self):",
            "        dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
            "                       'formats': ['<u4', 'u1', 'u1', 'u1'],",
            "                       'offsets': [0, 0, 1, 2],",
            "                       'titles': ['Color', 'Red pixel',",
            "                                  'Green pixel', 'Blue pixel']}, align=True)",
            "        assert_equal(repr(dt),",
            "                    \"dtype({'names':['rgba','r','g','b'],\"",
            "                    \" 'formats':['<u4','u1','u1','u1'],\"",
            "                    \" 'offsets':[0,0,1,2],\"",
            "                    \" 'titles':['Color','Red pixel',\"",
            "                              \"'Green pixel','Blue pixel'],\"",
            "                    \" 'itemsize':4}, align=True)\")",
            "",
            "        dt = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],",
            "                        'offsets': [0, 2],",
            "                        'titles': ['Red pixel', 'Blue pixel'],",
            "                        'itemsize': 4})",
            "        assert_equal(repr(dt),",
            "                    \"dtype({'names':['r','b'], \"",
            "                    \"'formats':['u1','u1'], \"",
            "                    \"'offsets':[0,2], \"",
            "                    \"'titles':['Red pixel','Blue pixel'], \"",
            "                    \"'itemsize':4})\")",
            "",
            "    def test_repr_structured_datetime(self):",
            "        dt = np.dtype([('a', '<M8[D]'), ('b', '<m8[us]')])",
            "        assert_equal(repr(dt),",
            "                    \"dtype([('a', '<M8[D]'), ('b', '<m8[us]')])\")",
            "",
            "    def test_repr_str_subarray(self):",
            "        dt = np.dtype(('<i2', (1,)))",
            "        assert_equal(repr(dt), \"dtype(('<i2', (1,)))\")",
            "        assert_equal(str(dt), \"('<i2', (1,))\")",
            "",
            "    def test_base_dtype_with_object_type(self):",
            "        # Issue gh-2798, should not error.",
            "        np.array(['a'], dtype=\"O\").astype((\"O\", [(\"name\", \"O\")]))",
            "",
            "    def test_empty_string_to_object(self):",
            "        # Pull request #4722",
            "        np.array([\"\", \"\"]).astype(object)",
            "",
            "    def test_void_subclass_unsized(self):",
            "        dt = np.dtype(np.record)",
            "        assert_equal(repr(dt), \"dtype('V')\")",
            "        assert_equal(str(dt), '|V0')",
            "        assert_equal(dt.name, 'record')",
            "",
            "    def test_void_subclass_sized(self):",
            "        dt = np.dtype((np.record, 2))",
            "        assert_equal(repr(dt), \"dtype('V2')\")",
            "        assert_equal(str(dt), '|V2')",
            "        assert_equal(dt.name, 'record16')",
            "",
            "    def test_void_subclass_fields(self):",
            "        dt = np.dtype((np.record, [('a', '<u2')]))",
            "        assert_equal(repr(dt), \"dtype((numpy.record, [('a', '<u2')]))\")",
            "        assert_equal(str(dt), \"(numpy.record, [('a', '<u2')])\")",
            "        assert_equal(dt.name, 'record16')",
            "",
            "",
            "class TestDtypeAttributeDeletion:",
            "",
            "    def test_dtype_non_writable_attributes_deletion(self):",
            "        dt = np.dtype(np.double)",
            "        attr = [\"subdtype\", \"descr\", \"str\", \"name\", \"base\", \"shape\",",
            "                \"isbuiltin\", \"isnative\", \"isalignedstruct\", \"fields\",",
            "                \"metadata\", \"hasobject\"]",
            "",
            "        for s in attr:",
            "            assert_raises(AttributeError, delattr, dt, s)",
            "",
            "    def test_dtype_writable_attributes_deletion(self):",
            "        dt = np.dtype(np.double)",
            "        attr = [\"names\"]",
            "        for s in attr:",
            "            assert_raises(AttributeError, delattr, dt, s)",
            "",
            "",
            "class TestDtypeAttributes:",
            "    def test_descr_has_trailing_void(self):",
            "        # see gh-6359",
            "        dtype = np.dtype({",
            "            'names': ['A', 'B'],",
            "            'formats': ['f4', 'f4'],",
            "            'offsets': [0, 8],",
            "            'itemsize': 16})",
            "        new_dtype = np.dtype(dtype.descr)",
            "        assert_equal(new_dtype.itemsize, 16)",
            "",
            "    def test_name_dtype_subclass(self):",
            "        # Ticket #4357",
            "        class user_def_subcls(np.void):",
            "            pass",
            "        assert_equal(np.dtype(user_def_subcls).name, 'user_def_subcls')",
            "",
            "",
            "class TestPickling:",
            "",
            "    def check_pickling(self, dtype):",
            "        for proto in range(pickle.HIGHEST_PROTOCOL + 1):",
            "            buf = pickle.dumps(dtype, proto)",
            "            # The dtype pickling itself pickles `np.dtype` if it is pickled",
            "            # as a singleton `dtype` should be stored in the buffer:",
            "            assert b\"_DType_reconstruct\" not in buf",
            "            assert b\"dtype\" in buf",
            "            pickled = pickle.loads(buf)",
            "            assert_equal(pickled, dtype)",
            "            assert_equal(pickled.descr, dtype.descr)",
            "            if dtype.metadata is not None:",
            "                assert_equal(pickled.metadata, dtype.metadata)",
            "            # Check the reconstructed dtype is functional",
            "            x = np.zeros(3, dtype=dtype)",
            "            y = np.zeros(3, dtype=pickled)",
            "            assert_equal(x, y)",
            "            assert_equal(x[0], y[0])",
            "",
            "    @pytest.mark.parametrize('t', [int, float, complex, np.int32, str, object,",
            "                                   np.compat.unicode, bool])",
            "    def test_builtin(self, t):",
            "        self.check_pickling(np.dtype(t))",
            "",
            "    def test_structured(self):",
            "        dt = np.dtype(([('a', '>f4', (2, 1)), ('b', '<f8', (1, 3))], (2, 2)))",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_aligned(self):",
            "        dt = np.dtype('i4, i1', align=True)",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_unaligned(self):",
            "        dt = np.dtype('i4, i1', align=False)",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_padded(self):",
            "        dt = np.dtype({",
            "            'names': ['A', 'B'],",
            "            'formats': ['f4', 'f4'],",
            "            'offsets': [0, 8],",
            "            'itemsize': 16})",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_titles(self):",
            "        dt = np.dtype({'names': ['r', 'b'],",
            "                       'formats': ['u1', 'u1'],",
            "                       'titles': ['Red pixel', 'Blue pixel']})",
            "        self.check_pickling(dt)",
            "",
            "    @pytest.mark.parametrize('base', ['m8', 'M8'])",
            "    @pytest.mark.parametrize('unit', ['', 'Y', 'M', 'W', 'D', 'h', 'm', 's',",
            "                                      'ms', 'us', 'ns', 'ps', 'fs', 'as'])",
            "    def test_datetime(self, base, unit):",
            "        dt = np.dtype('%s[%s]' % (base, unit) if unit else base)",
            "        self.check_pickling(dt)",
            "        if unit:",
            "            dt = np.dtype('%s[7%s]' % (base, unit))",
            "            self.check_pickling(dt)",
            "",
            "    def test_metadata(self):",
            "        dt = np.dtype(int, metadata={'datum': 1})",
            "        self.check_pickling(dt)",
            "",
            "    @pytest.mark.parametrize(\"DType\",",
            "        [type(np.dtype(t)) for t in np.typecodes['All']] +",
            "        [np.dtype(rational), np.dtype])",
            "    def test_pickle_types(self, DType):",
            "        # Check that DTypes (the classes/types) roundtrip when pickling",
            "        for proto in range(pickle.HIGHEST_PROTOCOL + 1):",
            "            roundtrip_DType = pickle.loads(pickle.dumps(DType, proto))",
            "            assert roundtrip_DType is DType",
            "",
            "",
            "class TestPromotion:",
            "    \"\"\"Test cases related to more complex DType promotions.  Further promotion",
            "    tests are defined in `test_numeric.py`",
            "    \"\"\"",
            "    @pytest.mark.parametrize([\"other\", \"expected\"],",
            "            [(2**16-1, np.complex64),",
            "             (2**32-1, np.complex128),",
            "             (np.float16(2), np.complex64),",
            "             (np.float32(2), np.complex64),",
            "             (np.longdouble(2), np.complex64),",
            "             # Base of the double value to sidestep any rounding issues:",
            "             (np.longdouble(np.nextafter(1.7e308, 0.)), np.complex128),",
            "             # Additionally use \"nextafter\" so the cast can't round down:",
            "             (np.longdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),",
            "             # repeat for complex scalars:",
            "             (np.complex64(2), np.complex64),",
            "             (np.clongdouble(2), np.complex64),",
            "             # Base of the double value to sidestep any rounding issues:",
            "             (np.clongdouble(np.nextafter(1.7e308, 0.) * 1j), np.complex128),",
            "             # Additionally use \"nextafter\" so the cast can't round down:",
            "             (np.clongdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),",
            "             ])",
            "    def test_complex_other_value_based(self, other, expected):",
            "        # This would change if we modify the value based promotion",
            "        min_complex = np.dtype(np.complex64)",
            "",
            "        res = np.result_type(other, min_complex)",
            "        assert res == expected",
            "        # Check the same for a simple ufunc call that uses the same logic:",
            "        res = np.minimum(other, np.ones(3, dtype=min_complex)).dtype",
            "        assert res == expected",
            "",
            "    @pytest.mark.parametrize([\"other\", \"expected\"],",
            "                 [(np.bool_, np.complex128),",
            "                  (np.int64, np.complex128),",
            "                  (np.float16, np.complex64),",
            "                  (np.float32, np.complex64),",
            "                  (np.float64, np.complex128),",
            "                  (np.longdouble, np.clongdouble),",
            "                  (np.complex64, np.complex64),",
            "                  (np.complex128, np.complex128),",
            "                  (np.clongdouble, np.clongdouble),",
            "                  ])",
            "    def test_complex_scalar_value_based(self, other, expected):",
            "        # This would change if we modify the value based promotion",
            "        complex_scalar = 1j",
            "",
            "        res = np.result_type(other, complex_scalar)",
            "        assert res == expected",
            "        # Check the same for a simple ufunc call that uses the same logic:",
            "        res = np.minimum(np.ones(3, dtype=other), complex_scalar).dtype",
            "        assert res == expected",
            "",
            "    def test_complex_pyscalar_promote_rational(self):",
            "        with pytest.raises(TypeError,",
            "                match=r\".* do not have a common DType\"):",
            "            np.result_type(1j, rational)",
            "",
            "        with pytest.raises(TypeError,",
            "                match=r\".* no common DType exists for the given inputs\"):",
            "            np.result_type(1j, rational(1, 2))",
            "",
            "    @pytest.mark.parametrize([\"other\", \"expected\"],",
            "            [(1, rational), (1., np.float64)])",
            "    def test_float_int_pyscalar_promote_rational(self, other, expected):",
            "        # Note that rationals are a bit akward as they promote with float64",
            "        # or default ints, but not float16 or uint8/int8 (which looks",
            "        # inconsistent here)",
            "        with pytest.raises(TypeError,",
            "                match=r\".* do not have a common DType\"):",
            "            np.result_type(other, rational)",
            "",
            "        assert np.result_type(other, rational(1, 2)) == expected",
            "",
            "    @pytest.mark.parametrize([\"dtypes\", \"expected\"], [",
            "             # These promotions are not associative/commutative:",
            "             ([np.uint16, np.int16, np.float16], np.float32),",
            "             ([np.uint16, np.int8, np.float16], np.float32),",
            "             ([np.uint8, np.int16, np.float16], np.float32),",
            "             # The following promotions are not ambiguous, but cover code",
            "             # paths of abstract promotion (no particular logic being tested)",
            "             ([1, 1, np.float64], np.float64),",
            "             ([1, 1., np.complex128], np.complex128),",
            "             ([1, 1j, np.float64], np.complex128),",
            "             ([1., 1., np.int64], np.float64),",
            "             ([1., 1j, np.float64], np.complex128),",
            "             ([1j, 1j, np.float64], np.complex128),",
            "             ([1, True, np.bool_], np.int_),",
            "            ])",
            "    def test_permutations_do_not_influence_result(self, dtypes, expected):",
            "        # Tests that most permutations do not influence the result.  In the",
            "        # above some uint and int combintations promote to a larger integer",
            "        # type, which would then promote to a larger than necessary float.",
            "        for perm in permutations(dtypes):",
            "            assert np.result_type(*perm) == expected",
            "",
            "",
            "def test_rational_dtype():",
            "    # test for bug gh-5719",
            "    a = np.array([1111], dtype=rational).astype",
            "    assert_raises(OverflowError, a, 'int8')",
            "",
            "    # test that dtype detection finds user-defined types",
            "    x = rational(1)",
            "    assert_equal(np.array([x,x]).dtype, np.dtype(rational))",
            "",
            "",
            "def test_dtypes_are_true():",
            "    # test for gh-6294",
            "    assert bool(np.dtype('f8'))",
            "    assert bool(np.dtype('i8'))",
            "    assert bool(np.dtype([('a', 'i8'), ('b', 'f4')]))",
            "",
            "",
            "def test_invalid_dtype_string():",
            "    # test for gh-10440",
            "    assert_raises(TypeError, np.dtype, 'f8,i8,[f8,i8]')",
            "    assert_raises(TypeError, np.dtype, u'Fl\\xfcgel')",
            "",
            "",
            "def test_keyword_argument():",
            "    # test for https://github.com/numpy/numpy/pull/16574#issuecomment-642660971",
            "    assert np.dtype(dtype=np.float64) == np.dtype(np.float64)",
            "",
            "",
            "class TestFromDTypeAttribute:",
            "    def test_simple(self):",
            "        class dt:",
            "            dtype = np.dtype(\"f8\")",
            "",
            "        assert np.dtype(dt) == np.float64",
            "        assert np.dtype(dt()) == np.float64",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_recursion(self):",
            "        class dt:",
            "            pass",
            "",
            "        dt.dtype = dt",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(dt)",
            "",
            "        dt_instance = dt()",
            "        dt_instance.dtype = dt",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(dt_instance)",
            "",
            "    def test_void_subtype(self):",
            "        class dt(np.void):",
            "            # This code path is fully untested before, so it is unclear",
            "            # what this should be useful for. Note that if np.void is used",
            "            # numpy will think we are deallocating a base type [1.17, 2019-02].",
            "            dtype = np.dtype(\"f,f\")",
            "",
            "        np.dtype(dt)",
            "        np.dtype(dt(1))",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_void_subtype_recursion(self):",
            "        class vdt(np.void):",
            "            pass",
            "",
            "        vdt.dtype = vdt",
            "",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(vdt)",
            "",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(vdt(1))",
            "",
            "",
            "class TestDTypeClasses:",
            "    @pytest.mark.parametrize(\"dtype\", list(np.typecodes['All']) + [rational])",
            "    def test_basic_dtypes_subclass_properties(self, dtype):",
            "        # Note: Except for the isinstance and type checks, these attributes",
            "        #       are considered currently private and may change.",
            "        dtype = np.dtype(dtype)",
            "        assert isinstance(dtype, np.dtype)",
            "        assert type(dtype) is not np.dtype",
            "        assert type(dtype).__name__ == f\"dtype[{dtype.type.__name__}]\"",
            "        assert type(dtype).__module__ == \"numpy\"",
            "        assert not type(dtype)._abstract",
            "",
            "        # the flexible dtypes and datetime/timedelta have additional parameters",
            "        # which are more than just storage information, these would need to be",
            "        # given when creating a dtype:",
            "        parametric = (np.void, np.str_, np.bytes_, np.datetime64, np.timedelta64)",
            "        if dtype.type not in parametric:",
            "            assert not type(dtype)._parametric",
            "            assert type(dtype)() is dtype",
            "        else:",
            "            assert type(dtype)._parametric",
            "            with assert_raises(TypeError):",
            "                type(dtype)()",
            "",
            "    def test_dtype_superclass(self):",
            "        assert type(np.dtype) is not type",
            "        assert isinstance(np.dtype, type)",
            "",
            "        assert type(np.dtype).__name__ == \"_DTypeMeta\"",
            "        assert type(np.dtype).__module__ == \"numpy\"",
            "        assert np.dtype._abstract",
            "",
            "",
            "class TestFromCTypes:",
            "",
            "    @staticmethod",
            "    def check(ctype, dtype):",
            "        dtype = np.dtype(dtype)",
            "        assert_equal(np.dtype(ctype), dtype)",
            "        assert_equal(np.dtype(ctype()), dtype)",
            "",
            "    def test_array(self):",
            "        c8 = ctypes.c_uint8",
            "        self.check(     3 * c8,  (np.uint8, (3,)))",
            "        self.check(     1 * c8,  (np.uint8, (1,)))",
            "        self.check(     0 * c8,  (np.uint8, (0,)))",
            "        self.check(1 * (3 * c8), ((np.uint8, (3,)), (1,)))",
            "        self.check(3 * (1 * c8), ((np.uint8, (1,)), (3,)))",
            "",
            "    def test_padded_structure(self):",
            "        class PaddedStruct(ctypes.Structure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', np.uint8),",
            "            ('b', np.uint16)",
            "        ], align=True)",
            "        self.check(PaddedStruct, expected)",
            "",
            "    def test_bit_fields(self):",
            "        class BitfieldStruct(ctypes.Structure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8, 7),",
            "                ('b', ctypes.c_uint8, 1)",
            "            ]",
            "        assert_raises(TypeError, np.dtype, BitfieldStruct)",
            "        assert_raises(TypeError, np.dtype, BitfieldStruct())",
            "",
            "    def test_pointer(self):",
            "        p_uint8 = ctypes.POINTER(ctypes.c_uint8)",
            "        assert_raises(TypeError, np.dtype, p_uint8)",
            "",
            "    def test_void_pointer(self):",
            "        self.check(ctypes.c_void_p, np.uintp)",
            "",
            "    def test_union(self):",
            "        class Union(ctypes.Union):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "            ]",
            "        expected = np.dtype(dict(",
            "            names=['a', 'b'],",
            "            formats=[np.uint8, np.uint16],",
            "            offsets=[0, 0],",
            "            itemsize=2",
            "        ))",
            "        self.check(Union, expected)",
            "",
            "    def test_union_with_struct_packed(self):",
            "        class Struct(ctypes.Structure):",
            "            _pack_ = 1",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "",
            "        class Union(ctypes.Union):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "                ('c', ctypes.c_uint32),",
            "                ('d', Struct),",
            "            ]",
            "        expected = np.dtype(dict(",
            "            names=['a', 'b', 'c', 'd'],",
            "            formats=['u1', np.uint16, np.uint32, [('one', 'u1'), ('two', np.uint32)]],",
            "            offsets=[0, 0, 0, 0],",
            "            itemsize=ctypes.sizeof(Union)",
            "        ))",
            "        self.check(Union, expected)",
            "",
            "    def test_union_packed(self):",
            "        class Struct(ctypes.Structure):",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "            _pack_ = 1",
            "        class Union(ctypes.Union):",
            "            _pack_ = 1",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "                ('c', ctypes.c_uint32),",
            "                ('d', Struct),",
            "            ]",
            "        expected = np.dtype(dict(",
            "            names=['a', 'b', 'c', 'd'],",
            "            formats=['u1', np.uint16, np.uint32, [('one', 'u1'), ('two', np.uint32)]],",
            "            offsets=[0, 0, 0, 0],",
            "            itemsize=ctypes.sizeof(Union)",
            "        ))",
            "        self.check(Union, expected)",
            "",
            "    def test_packed_structure(self):",
            "        class PackedStructure(ctypes.Structure):",
            "            _pack_ = 1",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', np.uint8),",
            "            ('b', np.uint16)",
            "        ])",
            "        self.check(PackedStructure, expected)",
            "",
            "    def test_large_packed_structure(self):",
            "        class PackedStructure(ctypes.Structure):",
            "            _pack_ = 2",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "                ('c', ctypes.c_uint8),",
            "                ('d', ctypes.c_uint16),",
            "                ('e', ctypes.c_uint32),",
            "                ('f', ctypes.c_uint32),",
            "                ('g', ctypes.c_uint8)",
            "                ]",
            "        expected = np.dtype(dict(",
            "            formats=[np.uint8, np.uint16, np.uint8, np.uint16, np.uint32, np.uint32, np.uint8 ],",
            "            offsets=[0, 2, 4, 6, 8, 12, 16],",
            "            names=['a', 'b', 'c', 'd', 'e', 'f', 'g'],",
            "            itemsize=18))",
            "        self.check(PackedStructure, expected)",
            "",
            "    def test_big_endian_structure_packed(self):",
            "        class BigEndStruct(ctypes.BigEndianStructure):",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "            _pack_ = 1",
            "        expected = np.dtype([('one', 'u1'), ('two', '>u4')])",
            "        self.check(BigEndStruct, expected)",
            "",
            "    def test_little_endian_structure_packed(self):",
            "        class LittleEndStruct(ctypes.LittleEndianStructure):",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "            _pack_ = 1",
            "        expected = np.dtype([('one', 'u1'), ('two', '<u4')])",
            "        self.check(LittleEndStruct, expected)",
            "",
            "    def test_little_endian_structure(self):",
            "        class PaddedStruct(ctypes.LittleEndianStructure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', '<B'),",
            "            ('b', '<H')",
            "        ], align=True)",
            "        self.check(PaddedStruct, expected)",
            "",
            "    def test_big_endian_structure(self):",
            "        class PaddedStruct(ctypes.BigEndianStructure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', '>B'),",
            "            ('b', '>H')",
            "        ], align=True)",
            "        self.check(PaddedStruct, expected)",
            "",
            "    def test_simple_endian_types(self):",
            "        self.check(ctypes.c_uint16.__ctype_le__, np.dtype('<u2'))",
            "        self.check(ctypes.c_uint16.__ctype_be__, np.dtype('>u2'))",
            "        self.check(ctypes.c_uint8.__ctype_le__, np.dtype('u1'))",
            "        self.check(ctypes.c_uint8.__ctype_be__, np.dtype('u1'))",
            "",
            "    all_types = set(np.typecodes['All'])",
            "    all_pairs = permutations(all_types, 2)",
            "",
            "    @pytest.mark.parametrize(\"pair\", all_pairs)",
            "    def test_pairs(self, pair):",
            "        \"\"\"",
            "        Check that np.dtype('x,y') matches [np.dtype('x'), np.dtype('y')]",
            "        Example: np.dtype('d,I') -> dtype([('f0', '<f8'), ('f1', '<u4')])",
            "        \"\"\"",
            "        # gh-5645: check that np.dtype('i,L') can be used",
            "        pair_type = np.dtype('{},{}'.format(*pair))",
            "        expected = np.dtype([('f0', pair[0]), ('f1', pair[1])])",
            "        assert_equal(pair_type, expected)",
            "",
            "",
            "class TestUserDType:",
            "    @pytest.mark.leaks_references(reason=\"dynamically creates custom dtype.\")",
            "    def test_custom_structured_dtype(self):",
            "        class mytype:",
            "            pass",
            "",
            "        blueprint = np.dtype([(\"field\", object)])",
            "        dt = create_custom_field_dtype(blueprint, mytype, 0)",
            "        assert dt.type == mytype",
            "        # We cannot (currently) *create* this dtype with `np.dtype` because",
            "        # mytype does not inherit from `np.generic`.  This seems like an",
            "        # unnecessary restriction, but one that has been around forever:",
            "        assert np.dtype(mytype) == np.dtype(\"O\")",
            "",
            "    def test_custom_structured_dtype_errors(self):",
            "        class mytype:",
            "            pass",
            "",
            "        blueprint = np.dtype([(\"field\", object)])",
            "",
            "        with pytest.raises(ValueError):",
            "            # Tests what happens if fields are unset during creation",
            "            # which is currently rejected due to the containing object",
            "            # (see PyArray_RegisterDataType).",
            "            create_custom_field_dtype(blueprint, mytype, 1)",
            "",
            "        with pytest.raises(RuntimeError):",
            "            # Tests that a dtype must have its type field set up to np.dtype",
            "            # or in this case a builtin instance.",
            "            create_custom_field_dtype(blueprint, mytype, 2)"
        ],
        "afterPatchFile": [
            "import sys",
            "import operator",
            "import pytest",
            "import ctypes",
            "import gc",
            "import warnings",
            "",
            "import numpy as np",
            "from numpy.core._rational_tests import rational",
            "from numpy.core._multiarray_tests import create_custom_field_dtype",
            "from numpy.testing import (",
            "    assert_, assert_equal, assert_array_equal, assert_raises, HAS_REFCOUNT,",
            "    IS_PYSTON)",
            "from numpy.compat import pickle",
            "from itertools import permutations",
            "",
            "",
            "def assert_dtype_equal(a, b):",
            "    assert_equal(a, b)",
            "    assert_equal(hash(a), hash(b),",
            "                 \"two equivalent types do not hash to the same value !\")",
            "",
            "def assert_dtype_not_equal(a, b):",
            "    assert_(a != b)",
            "    assert_(hash(a) != hash(b),",
            "            \"two different types hash to the same value !\")",
            "",
            "class TestBuiltin:",
            "    @pytest.mark.parametrize('t', [int, float, complex, np.int32, str, object,",
            "                                   np.compat.unicode])",
            "    def test_run(self, t):",
            "        \"\"\"Only test hash runs at all.\"\"\"",
            "        dt = np.dtype(t)",
            "        hash(dt)",
            "",
            "    @pytest.mark.parametrize('t', [int, float])",
            "    def test_dtype(self, t):",
            "        # Make sure equivalent byte order char hash the same (e.g. < and = on",
            "        # little endian)",
            "        dt = np.dtype(t)",
            "        dt2 = dt.newbyteorder(\"<\")",
            "        dt3 = dt.newbyteorder(\">\")",
            "        if dt == dt2:",
            "            assert_(dt.byteorder != dt2.byteorder, \"bogus test\")",
            "            assert_dtype_equal(dt, dt2)",
            "        else:",
            "            assert_(dt.byteorder != dt3.byteorder, \"bogus test\")",
            "            assert_dtype_equal(dt, dt3)",
            "",
            "    def test_equivalent_dtype_hashing(self):",
            "        # Make sure equivalent dtypes with different type num hash equal",
            "        uintp = np.dtype(np.uintp)",
            "        if uintp.itemsize == 4:",
            "            left = uintp",
            "            right = np.dtype(np.uint32)",
            "        else:",
            "            left = uintp",
            "            right = np.dtype(np.ulonglong)",
            "        assert_(left == right)",
            "        assert_(hash(left) == hash(right))",
            "",
            "    def test_invalid_types(self):",
            "        # Make sure invalid type strings raise an error",
            "",
            "        assert_raises(TypeError, np.dtype, 'O3')",
            "        assert_raises(TypeError, np.dtype, 'O5')",
            "        assert_raises(TypeError, np.dtype, 'O7')",
            "        assert_raises(TypeError, np.dtype, 'b3')",
            "        assert_raises(TypeError, np.dtype, 'h4')",
            "        assert_raises(TypeError, np.dtype, 'I5')",
            "        assert_raises(TypeError, np.dtype, 'e3')",
            "        assert_raises(TypeError, np.dtype, 'f5')",
            "",
            "        if np.dtype('g').itemsize == 8 or np.dtype('g').itemsize == 16:",
            "            assert_raises(TypeError, np.dtype, 'g12')",
            "        elif np.dtype('g').itemsize == 12:",
            "            assert_raises(TypeError, np.dtype, 'g16')",
            "",
            "        if np.dtype('l').itemsize == 8:",
            "            assert_raises(TypeError, np.dtype, 'l4')",
            "            assert_raises(TypeError, np.dtype, 'L4')",
            "        else:",
            "            assert_raises(TypeError, np.dtype, 'l8')",
            "            assert_raises(TypeError, np.dtype, 'L8')",
            "",
            "        if np.dtype('q').itemsize == 8:",
            "            assert_raises(TypeError, np.dtype, 'q4')",
            "            assert_raises(TypeError, np.dtype, 'Q4')",
            "        else:",
            "            assert_raises(TypeError, np.dtype, 'q8')",
            "            assert_raises(TypeError, np.dtype, 'Q8')",
            "",
            "    def test_richcompare_invalid_dtype_equality(self):",
            "        # Make sure objects that cannot be converted to valid",
            "        # dtypes results in False/True when compared to valid dtypes.",
            "        # Here 7 cannot be converted to dtype. No exceptions should be raised",
            "",
            "        assert not np.dtype(np.int32) == 7, \"dtype richcompare failed for ==\"",
            "        assert np.dtype(np.int32) != 7, \"dtype richcompare failed for !=\"",
            "",
            "    @pytest.mark.parametrize(",
            "        'operation',",
            "        [operator.le, operator.lt, operator.ge, operator.gt])",
            "    def test_richcompare_invalid_dtype_comparison(self, operation):",
            "        # Make sure TypeError is raised for comparison operators",
            "        # for invalid dtypes. Here 7 is an invalid dtype.",
            "",
            "        with pytest.raises(TypeError):",
            "            operation(np.dtype(np.int32), 7)",
            "",
            "    @pytest.mark.parametrize(\"dtype\",",
            "             ['Bool', 'Bytes0', 'Complex32', 'Complex64',",
            "              'Datetime64', 'Float16', 'Float32', 'Float64',",
            "              'Int8', 'Int16', 'Int32', 'Int64', ",
            "              'Object0', 'Str0', 'Timedelta64',",
            "              'UInt8', 'UInt16', 'Uint32', 'UInt32', ",
            "              'Uint64', 'UInt64', 'Void0',",
            "              \"Float128\", \"Complex128\"])",
            "    def test_numeric_style_types_are_invalid(self, dtype):",
            "        with assert_raises(TypeError):",
            "            np.dtype(dtype)",
            "",
            "    @pytest.mark.parametrize(",
            "        'value',",
            "        ['m8', 'M8', 'datetime64', 'timedelta64',",
            "         'i4, (2,3)f8, f4', 'a3, 3u8, (3,4)a10',",
            "         '>f', '<f', '=f', '|f',",
            "        ])",
            "    def test_dtype_bytes_str_equivalence(self, value):",
            "        bytes_value = value.encode('ascii')",
            "        from_bytes = np.dtype(bytes_value)",
            "        from_str = np.dtype(value)",
            "        assert_dtype_equal(from_bytes, from_str)",
            "",
            "    def test_dtype_from_bytes(self):",
            "        # Empty bytes object",
            "        assert_raises(TypeError, np.dtype, b'')",
            "        # Byte order indicator, but no type",
            "        assert_raises(TypeError, np.dtype, b'|')",
            "",
            "        # Single character with ordinal < NPY_NTYPES returns",
            "        # type by index into _builtin_descrs",
            "        assert_dtype_equal(np.dtype(bytes([0])), np.dtype('bool'))",
            "        assert_dtype_equal(np.dtype(bytes([17])), np.dtype(object))",
            "",
            "        # Single character where value is a valid type code",
            "        assert_dtype_equal(np.dtype(b'f'), np.dtype('float32'))",
            "",
            "        # Bytes with non-ascii values raise errors",
            "        assert_raises(TypeError, np.dtype, b'\\xff')",
            "        assert_raises(TypeError, np.dtype, b's\\xff')",
            "",
            "    def test_bad_param(self):",
            "        # Can't give a size that's too small",
            "        assert_raises(ValueError, np.dtype,",
            "                        {'names':['f0', 'f1'],",
            "                         'formats':['i4', 'i1'],",
            "                         'offsets':[0, 4],",
            "                         'itemsize':4})",
            "        # If alignment is enabled, the alignment (4) must divide the itemsize",
            "        assert_raises(ValueError, np.dtype,",
            "                        {'names':['f0', 'f1'],",
            "                         'formats':['i4', 'i1'],",
            "                         'offsets':[0, 4],",
            "                         'itemsize':9}, align=True)",
            "        # If alignment is enabled, the individual fields must be aligned",
            "        assert_raises(ValueError, np.dtype,",
            "                        {'names':['f0', 'f1'],",
            "                         'formats':['i1', 'f4'],",
            "                         'offsets':[0, 2]}, align=True)",
            "",
            "    def test_field_order_equality(self):",
            "        x = np.dtype({'names': ['A', 'B'],",
            "                      'formats': ['i4', 'f4'],",
            "                      'offsets': [0, 4]})",
            "        y = np.dtype({'names': ['B', 'A'],",
            "                      'formats': ['f4', 'i4'],",
            "                      'offsets': [4, 0]})",
            "        assert_equal(x == y, False)",
            "        # But it is currently an equivalent cast:",
            "        assert np.can_cast(x, y, casting=\"equiv\")",
            "",
            "",
            "class TestRecord:",
            "    def test_equivalent_record(self):",
            "        \"\"\"Test whether equivalent record dtypes hash the same.\"\"\"",
            "        a = np.dtype([('yo', int)])",
            "        b = np.dtype([('yo', int)])",
            "        assert_dtype_equal(a, b)",
            "",
            "    def test_different_names(self):",
            "        # In theory, they may hash the same (collision) ?",
            "        a = np.dtype([('yo', int)])",
            "        b = np.dtype([('ye', int)])",
            "        assert_dtype_not_equal(a, b)",
            "",
            "    def test_different_titles(self):",
            "        # In theory, they may hash the same (collision) ?",
            "        a = np.dtype({'names': ['r', 'b'],",
            "                      'formats': ['u1', 'u1'],",
            "                      'titles': ['Red pixel', 'Blue pixel']})",
            "        b = np.dtype({'names': ['r', 'b'],",
            "                      'formats': ['u1', 'u1'],",
            "                      'titles': ['RRed pixel', 'Blue pixel']})",
            "        assert_dtype_not_equal(a, b)",
            "",
            "    @pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")",
            "    def test_refcount_dictionary_setting(self):",
            "        names = [\"name1\"]",
            "        formats = [\"f8\"]",
            "        titles = [\"t1\"]",
            "        offsets = [0]",
            "        d = dict(names=names, formats=formats, titles=titles, offsets=offsets)",
            "        refcounts = {k: sys.getrefcount(i) for k, i in d.items()}",
            "        np.dtype(d)",
            "        refcounts_new = {k: sys.getrefcount(i) for k, i in d.items()}",
            "        assert refcounts == refcounts_new",
            "",
            "    def test_mutate(self):",
            "        # Mutating a dtype should reset the cached hash value",
            "        a = np.dtype([('yo', int)])",
            "        b = np.dtype([('yo', int)])",
            "        c = np.dtype([('ye', int)])",
            "        assert_dtype_equal(a, b)",
            "        assert_dtype_not_equal(a, c)",
            "        a.names = ['ye']",
            "        assert_dtype_equal(a, c)",
            "        assert_dtype_not_equal(a, b)",
            "        state = b.__reduce__()[2]",
            "        a.__setstate__(state)",
            "        assert_dtype_equal(a, b)",
            "        assert_dtype_not_equal(a, c)",
            "",
            "    def test_not_lists(self):",
            "        \"\"\"Test if an appropriate exception is raised when passing bad values to",
            "        the dtype constructor.",
            "        \"\"\"",
            "        assert_raises(TypeError, np.dtype,",
            "                      dict(names={'A', 'B'}, formats=['f8', 'i4']))",
            "        assert_raises(TypeError, np.dtype,",
            "                      dict(names=['A', 'B'], formats={'f8', 'i4'}))",
            "",
            "    def test_aligned_size(self):",
            "        # Check that structured dtypes get padded to an aligned size",
            "        dt = np.dtype('i4, i1', align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        dt = np.dtype([('f0', 'i4'), ('f1', 'i1')], align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        dt = np.dtype({'names':['f0', 'f1'],",
            "                       'formats':['i4', 'u1'],",
            "                       'offsets':[0, 4]}, align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        dt = np.dtype({'f0': ('i4', 0), 'f1':('u1', 4)}, align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        # Nesting should preserve that alignment",
            "        dt1 = np.dtype([('f0', 'i4'),",
            "                       ('f1', [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')]),",
            "                       ('f2', 'i1')], align=True)",
            "        assert_equal(dt1.itemsize, 20)",
            "        dt2 = np.dtype({'names':['f0', 'f1', 'f2'],",
            "                       'formats':['i4',",
            "                                  [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')],",
            "                                  'i1'],",
            "                       'offsets':[0, 4, 16]}, align=True)",
            "        assert_equal(dt2.itemsize, 20)",
            "        dt3 = np.dtype({'f0': ('i4', 0),",
            "                       'f1': ([('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')], 4),",
            "                       'f2': ('i1', 16)}, align=True)",
            "        assert_equal(dt3.itemsize, 20)",
            "        assert_equal(dt1, dt2)",
            "        assert_equal(dt2, dt3)",
            "        # Nesting should preserve packing",
            "        dt1 = np.dtype([('f0', 'i4'),",
            "                       ('f1', [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')]),",
            "                       ('f2', 'i1')], align=False)",
            "        assert_equal(dt1.itemsize, 11)",
            "        dt2 = np.dtype({'names':['f0', 'f1', 'f2'],",
            "                       'formats':['i4',",
            "                                  [('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')],",
            "                                  'i1'],",
            "                       'offsets':[0, 4, 10]}, align=False)",
            "        assert_equal(dt2.itemsize, 11)",
            "        dt3 = np.dtype({'f0': ('i4', 0),",
            "                       'f1': ([('f1', 'i1'), ('f2', 'i4'), ('f3', 'i1')], 4),",
            "                       'f2': ('i1', 10)}, align=False)",
            "        assert_equal(dt3.itemsize, 11)",
            "        assert_equal(dt1, dt2)",
            "        assert_equal(dt2, dt3)",
            "        # Array of subtype should preserve alignment",
            "        dt1 = np.dtype([('a', '|i1'),",
            "                        ('b', [('f0', '<i2'),",
            "                        ('f1', '<f4')], 2)], align=True)",
            "        assert_equal(dt1.descr, [('a', '|i1'), ('', '|V3'),",
            "                                 ('b', [('f0', '<i2'), ('', '|V2'),",
            "                                 ('f1', '<f4')], (2,))])",
            "",
            "    def test_union_struct(self):",
            "        # Should be able to create union dtypes",
            "        dt = np.dtype({'names':['f0', 'f1', 'f2'], 'formats':['<u4', '<u2', '<u2'],",
            "                        'offsets':[0, 0, 2]}, align=True)",
            "        assert_equal(dt.itemsize, 4)",
            "        a = np.array([3], dtype='<u4').view(dt)",
            "        a['f1'] = 10",
            "        a['f2'] = 36",
            "        assert_equal(a['f0'], 10 + 36*256*256)",
            "        # Should be able to specify fields out of order",
            "        dt = np.dtype({'names':['f0', 'f1', 'f2'], 'formats':['<u4', '<u2', '<u2'],",
            "                        'offsets':[4, 0, 2]}, align=True)",
            "        assert_equal(dt.itemsize, 8)",
            "        # field name should not matter: assignment is by position",
            "        dt2 = np.dtype({'names':['f2', 'f0', 'f1'],",
            "                        'formats':['<u4', '<u2', '<u2'],",
            "                        'offsets':[4, 0, 2]}, align=True)",
            "        vals = [(0, 1, 2), (3, -1, 4)]",
            "        vals2 = [(0, 1, 2), (3, -1, 4)]",
            "        a = np.array(vals, dt)",
            "        b = np.array(vals2, dt2)",
            "        assert_equal(a.astype(dt2), b)",
            "        assert_equal(b.astype(dt), a)",
            "        assert_equal(a.view(dt2), b)",
            "        assert_equal(b.view(dt), a)",
            "        # Should not be able to overlap objects with other types",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':['O', 'i1'],",
            "                 'offsets':[0, 2]})",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':['i4', 'O'],",
            "                 'offsets':[0, 3]})",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':[[('a', 'O')], 'i1'],",
            "                 'offsets':[0, 2]})",
            "        assert_raises(TypeError, np.dtype,",
            "                {'names':['f0', 'f1'],",
            "                 'formats':['i4', [('a', 'O')]],",
            "                 'offsets':[0, 3]})",
            "        # Out of order should still be ok, however",
            "        dt = np.dtype({'names':['f0', 'f1'],",
            "                       'formats':['i1', 'O'],",
            "                       'offsets':[np.dtype('intp').itemsize, 0]})",
            "",
            "    @pytest.mark.parametrize([\"obj\", \"dtype\", \"expected\"],",
            "        [([], (\"(2)f4,\"), np.empty((0, 2), dtype=\"f4\")),",
            "         (3, \"(3)f4,\", [3, 3, 3]),",
            "         (np.float64(2), \"(2)f4,\", [2, 2]),",
            "         ([((0, 1), (1, 2)), ((2,),)], '(2,2)f4', None),",
            "         ([\"1\", \"2\"], \"(2)i,\", None)])",
            "    def test_subarray_list(self, obj, dtype, expected):",
            "        dtype = np.dtype(dtype)",
            "        res = np.array(obj, dtype=dtype)",
            "",
            "        if expected is None:",
            "            # iterate the 1-d list to fill the array",
            "            expected = np.empty(len(obj), dtype=dtype)",
            "            for i in range(len(expected)):",
            "                expected[i] = obj[i]",
            "",
            "        assert_array_equal(res, expected)",
            "",
            "    def test_comma_datetime(self):",
            "        dt = np.dtype('M8[D],datetime64[Y],i8')",
            "        assert_equal(dt, np.dtype([('f0', 'M8[D]'),",
            "                                   ('f1', 'datetime64[Y]'),",
            "                                   ('f2', 'i8')]))",
            "",
            "    def test_from_dictproxy(self):",
            "        # Tests for PR #5920",
            "        dt = np.dtype({'names': ['a', 'b'], 'formats': ['i4', 'f4']})",
            "        assert_dtype_equal(dt, np.dtype(dt.fields))",
            "        dt2 = np.dtype((np.void, dt.fields))",
            "        assert_equal(dt2.fields, dt.fields)",
            "",
            "    def test_from_dict_with_zero_width_field(self):",
            "        # Regression test for #6430 / #2196",
            "        dt = np.dtype([('val1', np.float32, (0,)), ('val2', int)])",
            "        dt2 = np.dtype({'names': ['val1', 'val2'],",
            "                        'formats': [(np.float32, (0,)), int]})",
            "",
            "        assert_dtype_equal(dt, dt2)",
            "        assert_equal(dt.fields['val1'][0].itemsize, 0)",
            "        assert_equal(dt.itemsize, dt.fields['val2'][0].itemsize)",
            "",
            "    def test_bool_commastring(self):",
            "        d = np.dtype('?,?,?')  # raises?",
            "        assert_equal(len(d.names), 3)",
            "        for n in d.names:",
            "            assert_equal(d.fields[n][0], np.dtype('?'))",
            "",
            "    def test_nonint_offsets(self):",
            "        # gh-8059",
            "        def make_dtype(off):",
            "            return np.dtype({'names': ['A'], 'formats': ['i4'],",
            "                             'offsets': [off]})",
            "",
            "        assert_raises(TypeError, make_dtype, 'ASD')",
            "        assert_raises(OverflowError, make_dtype, 2**70)",
            "        assert_raises(TypeError, make_dtype, 2.3)",
            "        assert_raises(ValueError, make_dtype, -10)",
            "",
            "        # no errors here:",
            "        dt = make_dtype(np.uint32(0))",
            "        np.zeros(1, dtype=dt)[0].item()",
            "",
            "    def test_fields_by_index(self):",
            "        dt = np.dtype([('a', np.int8), ('b', np.float32, 3)])",
            "        assert_dtype_equal(dt[0], np.dtype(np.int8))",
            "        assert_dtype_equal(dt[1], np.dtype((np.float32, 3)))",
            "        assert_dtype_equal(dt[-1], dt[1])",
            "        assert_dtype_equal(dt[-2], dt[0])",
            "        assert_raises(IndexError, lambda: dt[-3])",
            "",
            "        assert_raises(TypeError, operator.getitem, dt, 3.0)",
            "",
            "        assert_equal(dt[1], dt[np.int8(1)])",
            "",
            "    @pytest.mark.parametrize('align_flag',[False, True])",
            "    def test_multifield_index(self, align_flag):",
            "        # indexing with a list produces subfields",
            "        # the align flag should be preserved",
            "        dt = np.dtype([",
            "            (('title', 'col1'), '<U20'), ('A', '<f8'), ('B', '<f8')",
            "        ], align=align_flag)",
            "",
            "        dt_sub = dt[['B', 'col1']]",
            "        assert_equal(",
            "            dt_sub,",
            "            np.dtype({",
            "                'names': ['B', 'col1'],",
            "                'formats': ['<f8', '<U20'],",
            "                'offsets': [88, 0],",
            "                'titles': [None, 'title'],",
            "                'itemsize': 96",
            "            })",
            "        )",
            "        assert_equal(dt_sub.isalignedstruct, align_flag)",
            "",
            "        dt_sub = dt[['B']]",
            "        assert_equal(",
            "            dt_sub,",
            "            np.dtype({",
            "                'names': ['B'],",
            "                'formats': ['<f8'],",
            "                'offsets': [88],",
            "                'itemsize': 96",
            "            })",
            "        )",
            "        assert_equal(dt_sub.isalignedstruct, align_flag)",
            "",
            "        dt_sub = dt[[]]",
            "        assert_equal(",
            "            dt_sub,",
            "            np.dtype({",
            "                'names': [],",
            "                'formats': [],",
            "                'offsets': [],",
            "                'itemsize': 96",
            "            })",
            "        )",
            "        assert_equal(dt_sub.isalignedstruct, align_flag)",
            "",
            "        assert_raises(TypeError, operator.getitem, dt, ())",
            "        assert_raises(TypeError, operator.getitem, dt, [1, 2, 3])",
            "        assert_raises(TypeError, operator.getitem, dt, ['col1', 2])",
            "        assert_raises(KeyError, operator.getitem, dt, ['fake'])",
            "        assert_raises(KeyError, operator.getitem, dt, ['title'])",
            "        assert_raises(ValueError, operator.getitem, dt, ['col1', 'col1'])",
            "",
            "    def test_partial_dict(self):",
            "        # 'names' is missing",
            "        assert_raises(ValueError, np.dtype,",
            "                {'formats': ['i4', 'i4'], 'f0': ('i4', 0), 'f1':('i4', 4)})",
            "",
            "    def test_fieldless_views(self):",
            "        a = np.zeros(2, dtype={'names':[], 'formats':[], 'offsets':[],",
            "                               'itemsize':8})",
            "        assert_raises(ValueError, a.view, np.dtype([]))",
            "",
            "        d = np.dtype((np.dtype([]), 10))",
            "        assert_equal(d.shape, (10,))",
            "        assert_equal(d.itemsize, 0)",
            "        assert_equal(d.base, np.dtype([]))",
            "",
            "        arr = np.fromiter((() for i in range(10)), [])",
            "        assert_equal(arr.dtype, np.dtype([]))",
            "        assert_raises(ValueError, np.frombuffer, b'', dtype=[])",
            "        assert_equal(np.frombuffer(b'', dtype=[], count=2),",
            "                     np.empty(2, dtype=[]))",
            "",
            "        assert_raises(ValueError, np.dtype, ([], 'f8'))",
            "        assert_raises(ValueError, np.zeros(1, dtype='i4').view, [])",
            "",
            "        assert_equal(np.zeros(2, dtype=[]) == np.zeros(2, dtype=[]),",
            "                     np.ones(2, dtype=bool))",
            "",
            "        assert_equal(np.zeros((1, 2), dtype=[]) == a,",
            "                     np.ones((1, 2), dtype=bool))",
            "",
            "",
            "class TestSubarray:",
            "    def test_single_subarray(self):",
            "        a = np.dtype((int, (2)))",
            "        b = np.dtype((int, (2,)))",
            "        assert_dtype_equal(a, b)",
            "",
            "        assert_equal(type(a.subdtype[1]), tuple)",
            "        assert_equal(type(b.subdtype[1]), tuple)",
            "",
            "    def test_equivalent_record(self):",
            "        \"\"\"Test whether equivalent subarray dtypes hash the same.\"\"\"",
            "        a = np.dtype((int, (2, 3)))",
            "        b = np.dtype((int, (2, 3)))",
            "        assert_dtype_equal(a, b)",
            "",
            "    def test_nonequivalent_record(self):",
            "        \"\"\"Test whether different subarray dtypes hash differently.\"\"\"",
            "        a = np.dtype((int, (2, 3)))",
            "        b = np.dtype((int, (3, 2)))",
            "        assert_dtype_not_equal(a, b)",
            "",
            "        a = np.dtype((int, (2, 3)))",
            "        b = np.dtype((int, (2, 2)))",
            "        assert_dtype_not_equal(a, b)",
            "",
            "        a = np.dtype((int, (1, 2, 3)))",
            "        b = np.dtype((int, (1, 2)))",
            "        assert_dtype_not_equal(a, b)",
            "",
            "    def test_shape_equal(self):",
            "        \"\"\"Test some data types that are equal\"\"\"",
            "        assert_dtype_equal(np.dtype('f8'), np.dtype(('f8', tuple())))",
            "        # FutureWarning during deprecation period; after it is passed this",
            "        # should instead check that \"(1)f8\" == \"1f8\" == (\"f8\", 1).",
            "        with pytest.warns(FutureWarning):",
            "            assert_dtype_equal(np.dtype('f8'), np.dtype(('f8', 1)))",
            "        assert_dtype_equal(np.dtype((int, 2)), np.dtype((int, (2,))))",
            "        assert_dtype_equal(np.dtype(('<f4', (3, 2))), np.dtype(('<f4', (3, 2))))",
            "        d = ([('a', 'f4', (1, 2)), ('b', 'f8', (3, 1))], (3, 2))",
            "        assert_dtype_equal(np.dtype(d), np.dtype(d))",
            "",
            "    def test_shape_simple(self):",
            "        \"\"\"Test some simple cases that shouldn't be equal\"\"\"",
            "        assert_dtype_not_equal(np.dtype('f8'), np.dtype(('f8', (1,))))",
            "        assert_dtype_not_equal(np.dtype(('f8', (1,))), np.dtype(('f8', (1, 1))))",
            "        assert_dtype_not_equal(np.dtype(('f4', (3, 2))), np.dtype(('f4', (2, 3))))",
            "",
            "    def test_shape_monster(self):",
            "        \"\"\"Test some more complicated cases that shouldn't be equal\"\"\"",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('a', 'f4', (1, 2)), ('b', 'f8', (1, 3))], (2, 2))))",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'i8', (1, 3))], (2, 2))))",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', 'f4', (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('e', 'f8', (1, 3)), ('d', 'f4', (2, 1))], (2, 2))))",
            "        assert_dtype_not_equal(",
            "            np.dtype(([('a', [('a', 'i4', 6)], (2, 1)), ('b', 'f8', (1, 3))], (2, 2))),",
            "            np.dtype(([('a', [('a', 'u4', 6)], (2, 1)), ('b', 'f8', (1, 3))], (2, 2))))",
            "",
            "    def test_shape_sequence(self):",
            "        # Any sequence of integers should work as shape, but the result",
            "        # should be a tuple (immutable) of base type integers.",
            "        a = np.array([1, 2, 3], dtype=np.int16)",
            "        l = [1, 2, 3]",
            "        # Array gets converted",
            "        dt = np.dtype([('a', 'f4', a)])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        assert_(isinstance(dt['a'].shape[0], int))",
            "        # List gets converted",
            "        dt = np.dtype([('a', 'f4', l)])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        #",
            "",
            "        class IntLike:",
            "            def __index__(self):",
            "                return 3",
            "",
            "            def __int__(self):",
            "                # (a PyNumber_Check fails without __int__)",
            "                return 3",
            "",
            "        dt = np.dtype([('a', 'f4', IntLike())])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        assert_(isinstance(dt['a'].shape[0], int))",
            "        dt = np.dtype([('a', 'f4', (IntLike(),))])",
            "        assert_(isinstance(dt['a'].shape, tuple))",
            "        assert_(isinstance(dt['a'].shape[0], int))",
            "",
            "    def test_shape_matches_ndim(self):",
            "        dt = np.dtype([('a', 'f4', ())])",
            "        assert_equal(dt['a'].shape, ())",
            "        assert_equal(dt['a'].ndim, 0)",
            "",
            "        dt = np.dtype([('a', 'f4')])",
            "        assert_equal(dt['a'].shape, ())",
            "        assert_equal(dt['a'].ndim, 0)",
            "",
            "        dt = np.dtype([('a', 'f4', 4)])",
            "        assert_equal(dt['a'].shape, (4,))",
            "        assert_equal(dt['a'].ndim, 1)",
            "",
            "        dt = np.dtype([('a', 'f4', (1, 2, 3))])",
            "        assert_equal(dt['a'].shape, (1, 2, 3))",
            "        assert_equal(dt['a'].ndim, 3)",
            "",
            "    def test_shape_invalid(self):",
            "        # Check that the shape is valid.",
            "        max_int = np.iinfo(np.intc).max",
            "        max_intp = np.iinfo(np.intp).max",
            "        # Too large values (the datatype is part of this)",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', max_int // 4 + 1)])",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', max_int + 1)])",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', (max_int, 2))])",
            "        # Takes a different code path (fails earlier:",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', max_intp + 1)])",
            "        # Negative values",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', -1)])",
            "        assert_raises(ValueError, np.dtype, [('a', 'f4', (-1, -1))])",
            "",
            "    def test_alignment(self):",
            "        #Check that subarrays are aligned",
            "        t1 = np.dtype('(1,)i4', align=True)",
            "        t2 = np.dtype('2i4', align=True)",
            "        assert_equal(t1.alignment, t2.alignment)",
            "",
            "",
            "def iter_struct_object_dtypes():",
            "    \"\"\"",
            "    Iterates over a few complex dtypes and object pattern which",
            "    fill the array with a given object (defaults to a singleton).",
            "",
            "    Yields",
            "    ------",
            "    dtype : dtype",
            "    pattern : tuple",
            "        Structured tuple for use with `np.array`.",
            "    count : int",
            "        Number of objects stored in the dtype.",
            "    singleton : object",
            "        A singleton object. The returned pattern is constructed so that",
            "        all objects inside the datatype are set to the singleton.",
            "    \"\"\"",
            "    obj = object()",
            "",
            "    dt = np.dtype([('b', 'O', (2, 3))])",
            "    p = ([[obj] * 3] * 2,)",
            "    yield pytest.param(dt, p, 6, obj, id=\"<subarray>\")",
            "",
            "    dt = np.dtype([('a', 'i4'), ('b', 'O', (2, 3))])",
            "    p = (0, [[obj] * 3] * 2)",
            "    yield pytest.param(dt, p, 6, obj, id=\"<subarray in field>\")",
            "",
            "    dt = np.dtype([('a', 'i4'),",
            "                   ('b', [('ba', 'O'), ('bb', 'i1')], (2, 3))])",
            "    p = (0, [[(obj, 0)] * 3] * 2)",
            "    yield pytest.param(dt, p, 6, obj, id=\"<structured subarray 1>\")",
            "",
            "    dt = np.dtype([('a', 'i4'),",
            "                   ('b', [('ba', 'O'), ('bb', 'O')], (2, 3))])",
            "    p = (0, [[(obj, obj)] * 3] * 2)",
            "    yield pytest.param(dt, p, 12, obj, id=\"<structured subarray 2>\")",
            "",
            "",
            "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")",
            "class TestStructuredObjectRefcounting:",
            "    \"\"\"These tests cover various uses of complicated structured types which",
            "    include objects and thus require reference counting.",
            "    \"\"\"",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    @pytest.mark.parametrize([\"creation_func\", \"creation_obj\"], [",
            "        pytest.param(np.empty, None,",
            "             # None is probably used for too many things",
            "             marks=pytest.mark.skip(\"unreliable due to python's behaviour\")),",
            "        (np.ones, 1),",
            "        (np.zeros, 0)])",
            "    def test_structured_object_create_delete(self, dt, pat, count, singleton,",
            "                                             creation_func, creation_obj):",
            "        \"\"\"Structured object reference counting in creation and deletion\"\"\"",
            "        # The test assumes that 0, 1, and None are singletons.",
            "        gc.collect()",
            "        before = sys.getrefcount(creation_obj)",
            "        arr = creation_func(3, dt)",
            "",
            "        now = sys.getrefcount(creation_obj)",
            "        assert now - before == count * 3",
            "        del arr",
            "        now = sys.getrefcount(creation_obj)",
            "        assert now == before",
            "",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    def test_structured_object_item_setting(self, dt, pat, count, singleton):",
            "        \"\"\"Structured object reference counting for simple item setting\"\"\"",
            "        one = 1",
            "",
            "        gc.collect()",
            "        before = sys.getrefcount(singleton)",
            "        arr = np.array([pat] * 3, dt)",
            "        assert sys.getrefcount(singleton) - before == count * 3",
            "        # Fill with `1` and check that it was replaced correctly:",
            "        before2 = sys.getrefcount(one)",
            "        arr[...] = one",
            "        after2 = sys.getrefcount(one)",
            "        assert after2 - before2 == count * 3",
            "        del arr",
            "        gc.collect()",
            "        assert sys.getrefcount(one) == before2",
            "        assert sys.getrefcount(singleton) == before",
            "",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    @pytest.mark.parametrize(",
            "        ['shape', 'index', 'items_changed'],",
            "        [((3,), ([0, 2],), 2),",
            "         ((3, 2), ([0, 2], slice(None)), 4),",
            "         ((3, 2), ([0, 2], [1]), 2),",
            "         ((3,), ([True, False, True]), 2)])",
            "    def test_structured_object_indexing(self, shape, index, items_changed,",
            "                                        dt, pat, count, singleton):",
            "        \"\"\"Structured object reference counting for advanced indexing.\"\"\"",
            "        zero = 0",
            "        one = 1",
            "",
            "        arr = np.zeros(shape, dt)",
            "",
            "        gc.collect()",
            "        before_zero = sys.getrefcount(zero)",
            "        before_one = sys.getrefcount(one)",
            "        # Test item getting:",
            "        part = arr[index]",
            "        after_zero = sys.getrefcount(zero)",
            "        assert after_zero - before_zero == count * items_changed",
            "        del part",
            "        # Test item setting:",
            "        arr[index] = one",
            "        gc.collect()",
            "        after_zero = sys.getrefcount(zero)",
            "        after_one = sys.getrefcount(one)",
            "        assert before_zero - after_zero == count * items_changed",
            "        assert after_one - before_one == count * items_changed",
            "",
            "    @pytest.mark.parametrize(['dt', 'pat', 'count', 'singleton'],",
            "                             iter_struct_object_dtypes())",
            "    def test_structured_object_take_and_repeat(self, dt, pat, count, singleton):",
            "        \"\"\"Structured object reference counting for specialized functions.",
            "        The older functions such as take and repeat use different code paths",
            "        then item setting (when writing this).",
            "        \"\"\"",
            "        indices = [0, 1]",
            "",
            "        arr = np.array([pat] * 3, dt)",
            "        gc.collect()",
            "        before = sys.getrefcount(singleton)",
            "        res = arr.take(indices)",
            "        after = sys.getrefcount(singleton)",
            "        assert after - before == count * 2",
            "        new = res.repeat(10)",
            "        gc.collect()",
            "        after_repeat = sys.getrefcount(singleton)",
            "        assert after_repeat - after == count * 2 * 10",
            "",
            "",
            "class TestStructuredDtypeSparseFields:",
            "    \"\"\"Tests subarray fields which contain sparse dtypes so that",
            "    not all memory is used by the dtype work. Such dtype's should",
            "    leave the underlying memory unchanged.",
            "    \"\"\"",
            "    dtype = np.dtype([('a', {'names':['aa', 'ab'], 'formats':['f', 'f'],",
            "                             'offsets':[0, 4]}, (2, 3))])",
            "    sparse_dtype = np.dtype([('a', {'names':['ab'], 'formats':['f'],",
            "                                    'offsets':[4]}, (2, 3))])",
            "",
            "    def test_sparse_field_assignment(self):",
            "        arr = np.zeros(3, self.dtype)",
            "        sparse_arr = arr.view(self.sparse_dtype)",
            "",
            "        sparse_arr[...] = np.finfo(np.float32).max",
            "        # dtype is reduced when accessing the field, so shape is (3, 2, 3):",
            "        assert_array_equal(arr[\"a\"][\"aa\"], np.zeros((3, 2, 3)))",
            "",
            "    def test_sparse_field_assignment_fancy(self):",
            "        # Fancy assignment goes to the copyswap function for complex types:",
            "        arr = np.zeros(3, self.dtype)",
            "        sparse_arr = arr.view(self.sparse_dtype)",
            "",
            "        sparse_arr[[0, 1, 2]] = np.finfo(np.float32).max",
            "        # dtype is reduced when accessing the field, so shape is (3, 2, 3):",
            "        assert_array_equal(arr[\"a\"][\"aa\"], np.zeros((3, 2, 3)))",
            "",
            "",
            "class TestMonsterType:",
            "    \"\"\"Test deeply nested subtypes.\"\"\"",
            "",
            "    def test1(self):",
            "        simple1 = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],",
            "            'titles': ['Red pixel', 'Blue pixel']})",
            "        a = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((int, (3, 2))))])",
            "        b = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((int, (3, 2))))])",
            "        assert_dtype_equal(a, b)",
            "",
            "        c = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((a, (3, 2))))])",
            "        d = np.dtype([('yo', int), ('ye', simple1),",
            "            ('yi', np.dtype((a, (3, 2))))])",
            "        assert_dtype_equal(c, d)",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_list_recursion(self):",
            "        l = list()",
            "        l.append(('f', l))",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(l)",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_tuple_recursion(self):",
            "        d = np.int32",
            "        for i in range(100000):",
            "            d = (d, (1,))",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(d)",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_dict_recursion(self):",
            "        d = dict(names=['self'], formats=[None], offsets=[0])",
            "        d['formats'][0] = d",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(d)",
            "",
            "",
            "class TestMetadata:",
            "    def test_no_metadata(self):",
            "        d = np.dtype(int)",
            "        assert_(d.metadata is None)",
            "",
            "    def test_metadata_takes_dict(self):",
            "        d = np.dtype(int, metadata={'datum': 1})",
            "        assert_(d.metadata == {'datum': 1})",
            "",
            "    def test_metadata_rejects_nondict(self):",
            "        assert_raises(TypeError, np.dtype, int, metadata='datum')",
            "        assert_raises(TypeError, np.dtype, int, metadata=1)",
            "        assert_raises(TypeError, np.dtype, int, metadata=None)",
            "",
            "    def test_nested_metadata(self):",
            "        d = np.dtype([('a', np.dtype(int, metadata={'datum': 1}))])",
            "        assert_(d['a'].metadata == {'datum': 1})",
            "",
            "    def test_base_metadata_copied(self):",
            "        d = np.dtype((np.void, np.dtype('i4,i4', metadata={'datum': 1})))",
            "        assert_(d.metadata == {'datum': 1})",
            "",
            "class TestString:",
            "    def test_complex_dtype_str(self):",
            "        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),",
            "                                ('rtile', '>f4', (64, 36))], (3,)),",
            "                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),",
            "                                   ('bright', '>f4', (8, 36))])])",
            "        assert_equal(str(dt),",
            "                     \"[('top', [('tiles', ('>f4', (64, 64)), (1,)), \"",
            "                     \"('rtile', '>f4', (64, 36))], (3,)), \"",
            "                     \"('bottom', [('bleft', ('>f4', (8, 64)), (1,)), \"",
            "                     \"('bright', '>f4', (8, 36))])]\")",
            "",
            "        # If the sticky aligned flag is set to True, it makes the",
            "        # str() function use a dict representation with an 'aligned' flag",
            "        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),",
            "                                ('rtile', '>f4', (64, 36))],",
            "                                (3,)),",
            "                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),",
            "                                   ('bright', '>f4', (8, 36))])],",
            "                       align=True)",
            "        assert_equal(str(dt),",
            "                    \"{'names':['top','bottom'], \"",
            "                     \"'formats':[([('tiles', ('>f4', (64, 64)), (1,)), \"",
            "                                  \"('rtile', '>f4', (64, 36))], (3,)),\"",
            "                                 \"[('bleft', ('>f4', (8, 64)), (1,)), \"",
            "                                  \"('bright', '>f4', (8, 36))]], \"",
            "                     \"'offsets':[0,76800], \"",
            "                     \"'itemsize':80000, \"",
            "                     \"'aligned':True}\")",
            "        assert_equal(np.dtype(eval(str(dt))), dt)",
            "",
            "        dt = np.dtype({'names': ['r', 'g', 'b'], 'formats': ['u1', 'u1', 'u1'],",
            "                        'offsets': [0, 1, 2],",
            "                        'titles': ['Red pixel', 'Green pixel', 'Blue pixel']})",
            "        assert_equal(str(dt),",
            "                    \"[(('Red pixel', 'r'), 'u1'), \"",
            "                    \"(('Green pixel', 'g'), 'u1'), \"",
            "                    \"(('Blue pixel', 'b'), 'u1')]\")",
            "",
            "        dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
            "                       'formats': ['<u4', 'u1', 'u1', 'u1'],",
            "                       'offsets': [0, 0, 1, 2],",
            "                       'titles': ['Color', 'Red pixel',",
            "                                  'Green pixel', 'Blue pixel']})",
            "        assert_equal(str(dt),",
            "                    \"{'names':['rgba','r','g','b'],\"",
            "                    \" 'formats':['<u4','u1','u1','u1'],\"",
            "                    \" 'offsets':[0,0,1,2],\"",
            "                    \" 'titles':['Color','Red pixel',\"",
            "                              \"'Green pixel','Blue pixel'],\"",
            "                    \" 'itemsize':4}\")",
            "",
            "        dt = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],",
            "                        'offsets': [0, 2],",
            "                        'titles': ['Red pixel', 'Blue pixel']})",
            "        assert_equal(str(dt),",
            "                    \"{'names':['r','b'],\"",
            "                    \" 'formats':['u1','u1'],\"",
            "                    \" 'offsets':[0,2],\"",
            "                    \" 'titles':['Red pixel','Blue pixel'],\"",
            "                    \" 'itemsize':3}\")",
            "",
            "        dt = np.dtype([('a', '<m8[D]'), ('b', '<M8[us]')])",
            "        assert_equal(str(dt),",
            "                    \"[('a', '<m8[D]'), ('b', '<M8[us]')]\")",
            "",
            "    def test_repr_structured(self):",
            "        dt = np.dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)),",
            "                                ('rtile', '>f4', (64, 36))], (3,)),",
            "                       ('bottom', [('bleft', ('>f4', (8, 64)), (1,)),",
            "                                   ('bright', '>f4', (8, 36))])])",
            "        assert_equal(repr(dt),",
            "                     \"dtype([('top', [('tiles', ('>f4', (64, 64)), (1,)), \"",
            "                     \"('rtile', '>f4', (64, 36))], (3,)), \"",
            "                     \"('bottom', [('bleft', ('>f4', (8, 64)), (1,)), \"",
            "                     \"('bright', '>f4', (8, 36))])])\")",
            "",
            "        dt = np.dtype({'names': ['r', 'g', 'b'], 'formats': ['u1', 'u1', 'u1'],",
            "                        'offsets': [0, 1, 2],",
            "                        'titles': ['Red pixel', 'Green pixel', 'Blue pixel']},",
            "                        align=True)",
            "        assert_equal(repr(dt),",
            "                    \"dtype([(('Red pixel', 'r'), 'u1'), \"",
            "                    \"(('Green pixel', 'g'), 'u1'), \"",
            "                    \"(('Blue pixel', 'b'), 'u1')], align=True)\")",
            "",
            "    def test_repr_structured_not_packed(self):",
            "        dt = np.dtype({'names': ['rgba', 'r', 'g', 'b'],",
            "                       'formats': ['<u4', 'u1', 'u1', 'u1'],",
            "                       'offsets': [0, 0, 1, 2],",
            "                       'titles': ['Color', 'Red pixel',",
            "                                  'Green pixel', 'Blue pixel']}, align=True)",
            "        assert_equal(repr(dt),",
            "                    \"dtype({'names':['rgba','r','g','b'],\"",
            "                    \" 'formats':['<u4','u1','u1','u1'],\"",
            "                    \" 'offsets':[0,0,1,2],\"",
            "                    \" 'titles':['Color','Red pixel',\"",
            "                              \"'Green pixel','Blue pixel'],\"",
            "                    \" 'itemsize':4}, align=True)\")",
            "",
            "        dt = np.dtype({'names': ['r', 'b'], 'formats': ['u1', 'u1'],",
            "                        'offsets': [0, 2],",
            "                        'titles': ['Red pixel', 'Blue pixel'],",
            "                        'itemsize': 4})",
            "        assert_equal(repr(dt),",
            "                    \"dtype({'names':['r','b'], \"",
            "                    \"'formats':['u1','u1'], \"",
            "                    \"'offsets':[0,2], \"",
            "                    \"'titles':['Red pixel','Blue pixel'], \"",
            "                    \"'itemsize':4})\")",
            "",
            "    def test_repr_structured_datetime(self):",
            "        dt = np.dtype([('a', '<M8[D]'), ('b', '<m8[us]')])",
            "        assert_equal(repr(dt),",
            "                    \"dtype([('a', '<M8[D]'), ('b', '<m8[us]')])\")",
            "",
            "    def test_repr_str_subarray(self):",
            "        dt = np.dtype(('<i2', (1,)))",
            "        assert_equal(repr(dt), \"dtype(('<i2', (1,)))\")",
            "        assert_equal(str(dt), \"('<i2', (1,))\")",
            "",
            "    def test_base_dtype_with_object_type(self):",
            "        # Issue gh-2798, should not error.",
            "        np.array(['a'], dtype=\"O\").astype((\"O\", [(\"name\", \"O\")]))",
            "",
            "    def test_empty_string_to_object(self):",
            "        # Pull request #4722",
            "        np.array([\"\", \"\"]).astype(object)",
            "",
            "    def test_void_subclass_unsized(self):",
            "        dt = np.dtype(np.record)",
            "        assert_equal(repr(dt), \"dtype('V')\")",
            "        assert_equal(str(dt), '|V0')",
            "        assert_equal(dt.name, 'record')",
            "",
            "    def test_void_subclass_sized(self):",
            "        dt = np.dtype((np.record, 2))",
            "        assert_equal(repr(dt), \"dtype('V2')\")",
            "        assert_equal(str(dt), '|V2')",
            "        assert_equal(dt.name, 'record16')",
            "",
            "    def test_void_subclass_fields(self):",
            "        dt = np.dtype((np.record, [('a', '<u2')]))",
            "        assert_equal(repr(dt), \"dtype((numpy.record, [('a', '<u2')]))\")",
            "        assert_equal(str(dt), \"(numpy.record, [('a', '<u2')])\")",
            "        assert_equal(dt.name, 'record16')",
            "",
            "",
            "class TestDtypeAttributeDeletion:",
            "",
            "    def test_dtype_non_writable_attributes_deletion(self):",
            "        dt = np.dtype(np.double)",
            "        attr = [\"subdtype\", \"descr\", \"str\", \"name\", \"base\", \"shape\",",
            "                \"isbuiltin\", \"isnative\", \"isalignedstruct\", \"fields\",",
            "                \"metadata\", \"hasobject\"]",
            "",
            "        for s in attr:",
            "            assert_raises(AttributeError, delattr, dt, s)",
            "",
            "    def test_dtype_writable_attributes_deletion(self):",
            "        dt = np.dtype(np.double)",
            "        attr = [\"names\"]",
            "        for s in attr:",
            "            assert_raises(AttributeError, delattr, dt, s)",
            "",
            "",
            "class TestDtypeAttributes:",
            "    def test_descr_has_trailing_void(self):",
            "        # see gh-6359",
            "        dtype = np.dtype({",
            "            'names': ['A', 'B'],",
            "            'formats': ['f4', 'f4'],",
            "            'offsets': [0, 8],",
            "            'itemsize': 16})",
            "        new_dtype = np.dtype(dtype.descr)",
            "        assert_equal(new_dtype.itemsize, 16)",
            "",
            "    def test_name_dtype_subclass(self):",
            "        # Ticket #4357",
            "        class user_def_subcls(np.void):",
            "            pass",
            "        assert_equal(np.dtype(user_def_subcls).name, 'user_def_subcls')",
            "",
            "",
            "class TestPickling:",
            "",
            "    def check_pickling(self, dtype):",
            "        for proto in range(pickle.HIGHEST_PROTOCOL + 1):",
            "            buf = pickle.dumps(dtype, proto)",
            "            # The dtype pickling itself pickles `np.dtype` if it is pickled",
            "            # as a singleton `dtype` should be stored in the buffer:",
            "            assert b\"_DType_reconstruct\" not in buf",
            "            assert b\"dtype\" in buf",
            "            pickled = pickle.loads(buf)",
            "            assert_equal(pickled, dtype)",
            "            assert_equal(pickled.descr, dtype.descr)",
            "            if dtype.metadata is not None:",
            "                assert_equal(pickled.metadata, dtype.metadata)",
            "            # Check the reconstructed dtype is functional",
            "            x = np.zeros(3, dtype=dtype)",
            "            y = np.zeros(3, dtype=pickled)",
            "            assert_equal(x, y)",
            "            assert_equal(x[0], y[0])",
            "",
            "    @pytest.mark.parametrize('t', [int, float, complex, np.int32, str, object,",
            "                                   np.compat.unicode, bool])",
            "    def test_builtin(self, t):",
            "        self.check_pickling(np.dtype(t))",
            "",
            "    def test_structured(self):",
            "        dt = np.dtype(([('a', '>f4', (2, 1)), ('b', '<f8', (1, 3))], (2, 2)))",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_aligned(self):",
            "        dt = np.dtype('i4, i1', align=True)",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_unaligned(self):",
            "        dt = np.dtype('i4, i1', align=False)",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_padded(self):",
            "        dt = np.dtype({",
            "            'names': ['A', 'B'],",
            "            'formats': ['f4', 'f4'],",
            "            'offsets': [0, 8],",
            "            'itemsize': 16})",
            "        self.check_pickling(dt)",
            "",
            "    def test_structured_titles(self):",
            "        dt = np.dtype({'names': ['r', 'b'],",
            "                       'formats': ['u1', 'u1'],",
            "                       'titles': ['Red pixel', 'Blue pixel']})",
            "        self.check_pickling(dt)",
            "",
            "    @pytest.mark.parametrize('base', ['m8', 'M8'])",
            "    @pytest.mark.parametrize('unit', ['', 'Y', 'M', 'W', 'D', 'h', 'm', 's',",
            "                                      'ms', 'us', 'ns', 'ps', 'fs', 'as'])",
            "    def test_datetime(self, base, unit):",
            "        dt = np.dtype('%s[%s]' % (base, unit) if unit else base)",
            "        self.check_pickling(dt)",
            "        if unit:",
            "            dt = np.dtype('%s[7%s]' % (base, unit))",
            "            self.check_pickling(dt)",
            "",
            "    def test_metadata(self):",
            "        dt = np.dtype(int, metadata={'datum': 1})",
            "        self.check_pickling(dt)",
            "",
            "    @pytest.mark.parametrize(\"DType\",",
            "        [type(np.dtype(t)) for t in np.typecodes['All']] +",
            "        [np.dtype(rational), np.dtype])",
            "    def test_pickle_types(self, DType):",
            "        # Check that DTypes (the classes/types) roundtrip when pickling",
            "        for proto in range(pickle.HIGHEST_PROTOCOL + 1):",
            "            roundtrip_DType = pickle.loads(pickle.dumps(DType, proto))",
            "            assert roundtrip_DType is DType",
            "",
            "",
            "class TestPromotion:",
            "    \"\"\"Test cases related to more complex DType promotions.  Further promotion",
            "    tests are defined in `test_numeric.py`",
            "    \"\"\"",
            "    @pytest.mark.parametrize([\"other\", \"expected\"],",
            "            [(2**16-1, np.complex64),",
            "             (2**32-1, np.complex128),",
            "             (np.float16(2), np.complex64),",
            "             (np.float32(2), np.complex64),",
            "             (np.longdouble(2), np.complex64),",
            "             # Base of the double value to sidestep any rounding issues:",
            "             (np.longdouble(np.nextafter(1.7e308, 0.)), np.complex128),",
            "             # Additionally use \"nextafter\" so the cast can't round down:",
            "             (np.longdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),",
            "             # repeat for complex scalars:",
            "             (np.complex64(2), np.complex64),",
            "             (np.clongdouble(2), np.complex64),",
            "             # Base of the double value to sidestep any rounding issues:",
            "             (np.clongdouble(np.nextafter(1.7e308, 0.) * 1j), np.complex128),",
            "             # Additionally use \"nextafter\" so the cast can't round down:",
            "             (np.clongdouble(np.nextafter(1.7e308, np.inf)), np.clongdouble),",
            "             ])",
            "    def test_complex_other_value_based(self, other, expected):",
            "        # This would change if we modify the value based promotion",
            "        min_complex = np.dtype(np.complex64)",
            "",
            "        res = np.result_type(other, min_complex)",
            "        assert res == expected",
            "        # Check the same for a simple ufunc call that uses the same logic:",
            "        res = np.minimum(other, np.ones(3, dtype=min_complex)).dtype",
            "        assert res == expected",
            "",
            "    @pytest.mark.parametrize([\"other\", \"expected\"],",
            "                 [(np.bool_, np.complex128),",
            "                  (np.int64, np.complex128),",
            "                  (np.float16, np.complex64),",
            "                  (np.float32, np.complex64),",
            "                  (np.float64, np.complex128),",
            "                  (np.longdouble, np.clongdouble),",
            "                  (np.complex64, np.complex64),",
            "                  (np.complex128, np.complex128),",
            "                  (np.clongdouble, np.clongdouble),",
            "                  ])",
            "    def test_complex_scalar_value_based(self, other, expected):",
            "        # This would change if we modify the value based promotion",
            "        complex_scalar = 1j",
            "",
            "        res = np.result_type(other, complex_scalar)",
            "        assert res == expected",
            "        # Check the same for a simple ufunc call that uses the same logic:",
            "        res = np.minimum(np.ones(3, dtype=other), complex_scalar).dtype",
            "        assert res == expected",
            "",
            "    def test_complex_pyscalar_promote_rational(self):",
            "        with pytest.raises(TypeError,",
            "                match=r\".* do not have a common DType\"):",
            "            np.result_type(1j, rational)",
            "",
            "        with pytest.raises(TypeError,",
            "                match=r\".* no common DType exists for the given inputs\"):",
            "            np.result_type(1j, rational(1, 2))",
            "",
            "    @pytest.mark.parametrize([\"other\", \"expected\"],",
            "            [(1, rational), (1., np.float64)])",
            "    def test_float_int_pyscalar_promote_rational(self, other, expected):",
            "        # Note that rationals are a bit akward as they promote with float64",
            "        # or default ints, but not float16 or uint8/int8 (which looks",
            "        # inconsistent here)",
            "        with pytest.raises(TypeError,",
            "                match=r\".* do not have a common DType\"):",
            "            np.result_type(other, rational)",
            "",
            "        assert np.result_type(other, rational(1, 2)) == expected",
            "",
            "    @pytest.mark.parametrize([\"dtypes\", \"expected\"], [",
            "             # These promotions are not associative/commutative:",
            "             ([np.uint16, np.int16, np.float16], np.float32),",
            "             ([np.uint16, np.int8, np.float16], np.float32),",
            "             ([np.uint8, np.int16, np.float16], np.float32),",
            "             # The following promotions are not ambiguous, but cover code",
            "             # paths of abstract promotion (no particular logic being tested)",
            "             ([1, 1, np.float64], np.float64),",
            "             ([1, 1., np.complex128], np.complex128),",
            "             ([1, 1j, np.float64], np.complex128),",
            "             ([1., 1., np.int64], np.float64),",
            "             ([1., 1j, np.float64], np.complex128),",
            "             ([1j, 1j, np.float64], np.complex128),",
            "             ([1, True, np.bool_], np.int_),",
            "            ])",
            "    def test_permutations_do_not_influence_result(self, dtypes, expected):",
            "        # Tests that most permutations do not influence the result.  In the",
            "        # above some uint and int combintations promote to a larger integer",
            "        # type, which would then promote to a larger than necessary float.",
            "        for perm in permutations(dtypes):",
            "            assert np.result_type(*perm) == expected",
            "",
            "",
            "def test_rational_dtype():",
            "    # test for bug gh-5719",
            "    a = np.array([1111], dtype=rational).astype",
            "    assert_raises(OverflowError, a, 'int8')",
            "",
            "    # test that dtype detection finds user-defined types",
            "    x = rational(1)",
            "    assert_equal(np.array([x,x]).dtype, np.dtype(rational))",
            "",
            "",
            "def test_dtypes_are_true():",
            "    # test for gh-6294",
            "    assert bool(np.dtype('f8'))",
            "    assert bool(np.dtype('i8'))",
            "    assert bool(np.dtype([('a', 'i8'), ('b', 'f4')]))",
            "",
            "",
            "def test_invalid_dtype_string():",
            "    # test for gh-10440",
            "    assert_raises(TypeError, np.dtype, 'f8,i8,[f8,i8]')",
            "    assert_raises(TypeError, np.dtype, u'Fl\\xfcgel')",
            "",
            "",
            "def test_keyword_argument():",
            "    # test for https://github.com/numpy/numpy/pull/16574#issuecomment-642660971",
            "    assert np.dtype(dtype=np.float64) == np.dtype(np.float64)",
            "",
            "",
            "class TestFromDTypeAttribute:",
            "    def test_simple(self):",
            "        class dt:",
            "            dtype = np.dtype(\"f8\")",
            "",
            "        assert np.dtype(dt) == np.float64",
            "        assert np.dtype(dt()) == np.float64",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_recursion(self):",
            "        class dt:",
            "            pass",
            "",
            "        dt.dtype = dt",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(dt)",
            "",
            "        dt_instance = dt()",
            "        dt_instance.dtype = dt",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(dt_instance)",
            "",
            "    def test_void_subtype(self):",
            "        class dt(np.void):",
            "            # This code path is fully untested before, so it is unclear",
            "            # what this should be useful for. Note that if np.void is used",
            "            # numpy will think we are deallocating a base type [1.17, 2019-02].",
            "            dtype = np.dtype(\"f,f\")",
            "",
            "        np.dtype(dt)",
            "        np.dtype(dt(1))",
            "",
            "    @pytest.mark.skipif(IS_PYSTON, reason=\"Pyston disables recursion checking\")",
            "    def test_void_subtype_recursion(self):",
            "        class vdt(np.void):",
            "            pass",
            "",
            "        vdt.dtype = vdt",
            "",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(vdt)",
            "",
            "        with pytest.raises(RecursionError):",
            "            np.dtype(vdt(1))",
            "",
            "",
            "class TestDTypeClasses:",
            "    @pytest.mark.parametrize(\"dtype\", list(np.typecodes['All']) + [rational])",
            "    def test_basic_dtypes_subclass_properties(self, dtype):",
            "        # Note: Except for the isinstance and type checks, these attributes",
            "        #       are considered currently private and may change.",
            "        dtype = np.dtype(dtype)",
            "        assert isinstance(dtype, np.dtype)",
            "        assert type(dtype) is not np.dtype",
            "        assert type(dtype).__name__ == f\"dtype[{dtype.type.__name__}]\"",
            "        assert type(dtype).__module__ == \"numpy\"",
            "        assert not type(dtype)._abstract",
            "",
            "        # the flexible dtypes and datetime/timedelta have additional parameters",
            "        # which are more than just storage information, these would need to be",
            "        # given when creating a dtype:",
            "        parametric = (np.void, np.str_, np.bytes_, np.datetime64, np.timedelta64)",
            "        if dtype.type not in parametric:",
            "            assert not type(dtype)._parametric",
            "            assert type(dtype)() is dtype",
            "        else:",
            "            assert type(dtype)._parametric",
            "            with assert_raises(TypeError):",
            "                type(dtype)()",
            "",
            "    def test_dtype_superclass(self):",
            "        assert type(np.dtype) is not type",
            "        assert isinstance(np.dtype, type)",
            "",
            "        assert type(np.dtype).__name__ == \"_DTypeMeta\"",
            "        assert type(np.dtype).__module__ == \"numpy\"",
            "        assert np.dtype._abstract",
            "",
            "",
            "class TestFromCTypes:",
            "",
            "    @staticmethod",
            "    def check(ctype, dtype):",
            "        dtype = np.dtype(dtype)",
            "        assert_equal(np.dtype(ctype), dtype)",
            "        assert_equal(np.dtype(ctype()), dtype)",
            "",
            "    def test_array(self):",
            "        c8 = ctypes.c_uint8",
            "        self.check(     3 * c8,  (np.uint8, (3,)))",
            "        self.check(     1 * c8,  (np.uint8, (1,)))",
            "        self.check(     0 * c8,  (np.uint8, (0,)))",
            "        self.check(1 * (3 * c8), ((np.uint8, (3,)), (1,)))",
            "        self.check(3 * (1 * c8), ((np.uint8, (1,)), (3,)))",
            "",
            "    def test_padded_structure(self):",
            "        class PaddedStruct(ctypes.Structure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', np.uint8),",
            "            ('b', np.uint16)",
            "        ], align=True)",
            "        self.check(PaddedStruct, expected)",
            "",
            "    def test_bit_fields(self):",
            "        class BitfieldStruct(ctypes.Structure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8, 7),",
            "                ('b', ctypes.c_uint8, 1)",
            "            ]",
            "        assert_raises(TypeError, np.dtype, BitfieldStruct)",
            "        assert_raises(TypeError, np.dtype, BitfieldStruct())",
            "",
            "    def test_pointer(self):",
            "        p_uint8 = ctypes.POINTER(ctypes.c_uint8)",
            "        assert_raises(TypeError, np.dtype, p_uint8)",
            "",
            "    def test_void_pointer(self):",
            "        self.check(ctypes.c_void_p, np.uintp)",
            "",
            "    def test_union(self):",
            "        class Union(ctypes.Union):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "            ]",
            "        expected = np.dtype(dict(",
            "            names=['a', 'b'],",
            "            formats=[np.uint8, np.uint16],",
            "            offsets=[0, 0],",
            "            itemsize=2",
            "        ))",
            "        self.check(Union, expected)",
            "",
            "    def test_union_with_struct_packed(self):",
            "        class Struct(ctypes.Structure):",
            "            _pack_ = 1",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "",
            "        class Union(ctypes.Union):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "                ('c', ctypes.c_uint32),",
            "                ('d', Struct),",
            "            ]",
            "        expected = np.dtype(dict(",
            "            names=['a', 'b', 'c', 'd'],",
            "            formats=['u1', np.uint16, np.uint32, [('one', 'u1'), ('two', np.uint32)]],",
            "            offsets=[0, 0, 0, 0],",
            "            itemsize=ctypes.sizeof(Union)",
            "        ))",
            "        self.check(Union, expected)",
            "",
            "    def test_union_packed(self):",
            "        class Struct(ctypes.Structure):",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "            _pack_ = 1",
            "        class Union(ctypes.Union):",
            "            _pack_ = 1",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "                ('c', ctypes.c_uint32),",
            "                ('d', Struct),",
            "            ]",
            "        expected = np.dtype(dict(",
            "            names=['a', 'b', 'c', 'd'],",
            "            formats=['u1', np.uint16, np.uint32, [('one', 'u1'), ('two', np.uint32)]],",
            "            offsets=[0, 0, 0, 0],",
            "            itemsize=ctypes.sizeof(Union)",
            "        ))",
            "        self.check(Union, expected)",
            "",
            "    def test_packed_structure(self):",
            "        class PackedStructure(ctypes.Structure):",
            "            _pack_ = 1",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', np.uint8),",
            "            ('b', np.uint16)",
            "        ])",
            "        self.check(PackedStructure, expected)",
            "",
            "    def test_large_packed_structure(self):",
            "        class PackedStructure(ctypes.Structure):",
            "            _pack_ = 2",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16),",
            "                ('c', ctypes.c_uint8),",
            "                ('d', ctypes.c_uint16),",
            "                ('e', ctypes.c_uint32),",
            "                ('f', ctypes.c_uint32),",
            "                ('g', ctypes.c_uint8)",
            "                ]",
            "        expected = np.dtype(dict(",
            "            formats=[np.uint8, np.uint16, np.uint8, np.uint16, np.uint32, np.uint32, np.uint8 ],",
            "            offsets=[0, 2, 4, 6, 8, 12, 16],",
            "            names=['a', 'b', 'c', 'd', 'e', 'f', 'g'],",
            "            itemsize=18))",
            "        self.check(PackedStructure, expected)",
            "",
            "    def test_big_endian_structure_packed(self):",
            "        class BigEndStruct(ctypes.BigEndianStructure):",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "            _pack_ = 1",
            "        expected = np.dtype([('one', 'u1'), ('two', '>u4')])",
            "        self.check(BigEndStruct, expected)",
            "",
            "    def test_little_endian_structure_packed(self):",
            "        class LittleEndStruct(ctypes.LittleEndianStructure):",
            "            _fields_ = [",
            "                ('one', ctypes.c_uint8),",
            "                ('two', ctypes.c_uint32)",
            "            ]",
            "            _pack_ = 1",
            "        expected = np.dtype([('one', 'u1'), ('two', '<u4')])",
            "        self.check(LittleEndStruct, expected)",
            "",
            "    def test_little_endian_structure(self):",
            "        class PaddedStruct(ctypes.LittleEndianStructure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', '<B'),",
            "            ('b', '<H')",
            "        ], align=True)",
            "        self.check(PaddedStruct, expected)",
            "",
            "    def test_big_endian_structure(self):",
            "        class PaddedStruct(ctypes.BigEndianStructure):",
            "            _fields_ = [",
            "                ('a', ctypes.c_uint8),",
            "                ('b', ctypes.c_uint16)",
            "            ]",
            "        expected = np.dtype([",
            "            ('a', '>B'),",
            "            ('b', '>H')",
            "        ], align=True)",
            "        self.check(PaddedStruct, expected)",
            "",
            "    def test_simple_endian_types(self):",
            "        self.check(ctypes.c_uint16.__ctype_le__, np.dtype('<u2'))",
            "        self.check(ctypes.c_uint16.__ctype_be__, np.dtype('>u2'))",
            "        self.check(ctypes.c_uint8.__ctype_le__, np.dtype('u1'))",
            "        self.check(ctypes.c_uint8.__ctype_be__, np.dtype('u1'))",
            "",
            "    all_types = set(np.typecodes['All'])",
            "    all_pairs = permutations(all_types, 2)",
            "",
            "    @pytest.mark.parametrize(\"pair\", all_pairs)",
            "    def test_pairs(self, pair):",
            "        \"\"\"",
            "        Check that np.dtype('x,y') matches [np.dtype('x'), np.dtype('y')]",
            "        Example: np.dtype('d,I') -> dtype([('f0', '<f8'), ('f1', '<u4')])",
            "        \"\"\"",
            "        # gh-5645: check that np.dtype('i,L') can be used",
            "        pair_type = np.dtype('{},{}'.format(*pair))",
            "        expected = np.dtype([('f0', pair[0]), ('f1', pair[1])])",
            "        assert_equal(pair_type, expected)",
            "",
            "",
            "class TestUserDType:",
            "    @pytest.mark.leaks_references(reason=\"dynamically creates custom dtype.\")",
            "    def test_custom_structured_dtype(self):",
            "        class mytype:",
            "            pass",
            "",
            "        blueprint = np.dtype([(\"field\", object)])",
            "        dt = create_custom_field_dtype(blueprint, mytype, 0)",
            "        assert dt.type == mytype",
            "        # We cannot (currently) *create* this dtype with `np.dtype` because",
            "        # mytype does not inherit from `np.generic`.  This seems like an",
            "        # unnecessary restriction, but one that has been around forever:",
            "        assert np.dtype(mytype) == np.dtype(\"O\")",
            "",
            "    def test_custom_structured_dtype_errors(self):",
            "        class mytype:",
            "            pass",
            "",
            "        blueprint = np.dtype([(\"field\", object)])",
            "",
            "        with pytest.raises(ValueError):",
            "            # Tests what happens if fields are unset during creation",
            "            # which is currently rejected due to the containing object",
            "            # (see PyArray_RegisterDataType).",
            "            create_custom_field_dtype(blueprint, mytype, 1)",
            "",
            "        with pytest.raises(RuntimeError):",
            "            # Tests that a dtype must have its type field set up to np.dtype",
            "            # or in this case a builtin instance.",
            "            create_custom_field_dtype(blueprint, mytype, 2)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "112": [
                "TestBuiltin"
            ],
            "113": [
                "TestBuiltin"
            ],
            "114": [
                "TestBuiltin"
            ]
        },
        "addLocation": []
    }
}